<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hubert&#39;s Blog</title>
  
  <subtitle> Hubert爱猫爱生活</subtitle>
  <link href="https://hubertwongcn.github.io/atom.xml" rel="self"/>
  
  <link href="https://hubertwongcn.github.io/"/>
  <updated>2023-12-27T19:10:32.000Z</updated>
  <id>https://hubertwongcn.github.io/</id>
  
  <author>
    <name>Hubert Wong</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>26.数据挖掘 - 10大算法汇总</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/26-shu-ju-wa-jue-10-da-suan-fa-hui-zong/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/26-shu-ju-wa-jue-10-da-suan-fa-hui-zong/</id>
    <published>2023-12-27T19:10:32.000Z</published>
    <updated>2023-12-27T19:10:32.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>国际权威的学术组织the IEEE International Conference on Data Mining (ICDM) 2006年12月评选出了数据挖掘领域的十大经典算法: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART。</p></blockquote><h2 id="推荐学习"><a href="#推荐学习" class="headerlink" title="推荐学习"></a>推荐学习</h2><ul><li>博客园@刘建平Pinard 的<a href="https://www.cnblogs.com/pinard/">机器学习，数据挖掘系列</a></li></ul><h2 id="数据挖掘十大经典算法"><a href="#数据挖掘十大经典算法" class="headerlink" title="数据挖掘十大经典算法"></a>数据挖掘十大经典算法</h2><h3 id="C4-5"><a href="#C4-5" class="headerlink" title="C4.5"></a>C4.5</h3><p>C4.5算法是机器学习算法中的一种分类决策树算法,其核心算法是ID3算法. C4.5算法继承了ID3算法的优点，并在以下几方面对ID3算法进行了改进:</p><ul><li>用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足；</li><li>在树构造过程中进行剪枝；</li><li>能够完成对连续属性的离散化处理；</li><li>能够对不完整数据进行处理。</li></ul><p>C4.5算法有如下优点: 产生的分类规则易于理解，准确率较高。其缺点是: 在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效(相对的CART算法只需要扫描两次数据集，以下仅为决策树优缺点)。</p><h3 id="The-k-means-algorithm-即K-Means算法"><a href="#The-k-means-algorithm-即K-Means算法" class="headerlink" title="The k-means algorithm 即K-Means算法"></a>The k-means algorithm 即K-Means算法</h3><p>k-means algorithm算法是一个聚类算法，把n的对象根据他们的属性分为k个分割，k &lt; n。它与处理混合正态分布的最大期望算法很相似，因为他们都试图找到数据中自然聚类的中心。它假设对象属性来自于空间向量，并且目标是使各个群组内部的均 方误差总和最小。</p><h3 id="Support-vector-machines"><a href="#Support-vector-machines" class="headerlink" title="Support vector machines"></a>Support vector machines</h3><p>支持向量机，英文为Support Vector Machine，简称SV机(论文中一般简称SVM)。它是一种監督式學習的方法，它广泛的应用于统计分类以及回归分析中。支持向量机将向量映射到一个更 高维的空间里，在这个空间里建立有一个最大间隔超平面。在分开数据的超平面的两边建有两个互相平行的超平面。分隔超平面使两个平行超平面的距离最大化。假 定平行超平面间的距离或差距越大，分类器的总误差越小。一个极好的指南是C.J.C Burges的《模式识别支持向量机指南》。van der Walt 和 Barnard 将支持向量机和其他分类器进行了比较。</p><h3 id="The-Apriori-algorithm"><a href="#The-Apriori-algorithm" class="headerlink" title="The Apriori algorithm"></a>The Apriori algorithm</h3><p>Apriori算法是一种最有影响的挖掘布尔关联规则频繁项集的算法。其核心是基于两阶段频集思想的递推算法。该关联规则在分类上属于单维、单层、布尔关联规则。在这里，所有支持度大于最小支持度的项集称为频繁项集，简称频集。</p><h3 id="最大期望-EM-算法"><a href="#最大期望-EM-算法" class="headerlink" title="最大期望(EM)算法"></a>最大期望(EM)算法</h3><p>在统计计算中，最大期望(EM，Expectation–Maximization)算法是在概率(probabilistic)模型中寻找参数最大似然 估计的算法，其中概率模型依赖于无法观测的隐藏变量(Latent Variabl)。最大期望经常用在机器学习和计算机视觉的数据集聚(Data Clustering)领域。</p><h3 id="PageRank"><a href="#PageRank" class="headerlink" title="PageRank"></a>PageRank</h3><p>PageRank是Google算法的重要内容。2001年9月被授予美国专利，专利人是Google创始人之一拉里·佩奇(Larry Page)。因此，PageRank里的page不是指网页，而是指佩奇，即这个等级方法是以佩奇来命名的。</p><p>PageRank根据网站的外部链接和内部链接的数量和质量俩衡量网站的价值。PageRank背后的概念是，每个到页面的链接都是对该页面的一次投票， 被链接的越多，就意味着被其他网站投票越多。这个就是所谓的“链接流行度”——衡量多少人愿意将他们的网站和你的网站挂钩。PageRank这个概念引自 学术中一篇论文的被引述的频度——即被别人引述的次数越多，一般判断这篇论文的权威性就越高。</p><h3 id="AdaBoost"><a href="#AdaBoost" class="headerlink" title="AdaBoost"></a>AdaBoost</h3><p>Adaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器 (强分类器)。其算法本身是通过改变数据分布来实现的，它根据每次训练集之中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权 值。将修改过权值的新数据集送给下层分类器进行训练，最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。</p><h3 id="kNN-k-nearest-neighbor-classification"><a href="#kNN-k-nearest-neighbor-classification" class="headerlink" title="kNN: k-nearest neighbor classification"></a>kNN: k-nearest neighbor classification</h3><p>K最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是: 如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。</p><h3 id="Naive-Bayes"><a href="#Naive-Bayes" class="headerlink" title="Naive Bayes"></a>Naive Bayes</h3><p>在众多的分类模型中，应用最为广泛的两种分类模型是决策树模型(Decision Tree Model)和朴素贝叶斯模型(Naive Bayesian Model，NBC)。 朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以 及稳定的分类效率。同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。理论上，NBC模型与其他分类方法相比具有最小的误差率。 但是实际上并非总是如此，这是因为NBC模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，这给NBC模型的正确分类带来了一定影响。在属 性个数比较多或者属性之间相关性较大时，NBC模型的分类效率比不上决策树模型。而在属性相关性较小时，NBC模型的性能最为良好。</p><h3 id="CART-分类与回归树"><a href="#CART-分类与回归树" class="headerlink" title="CART: 分类与回归树"></a>CART: 分类与回归树</h3><p>CART, Classification and Regression Trees。 在分类树下面有两个关键的思想。第一个是关于递归地划分自变量空间的想法(二元切分法)；第二个想法是用验证数据进行剪枝(预剪枝、后剪枝)。在回归树的基础上的模型树构建难度可能增加了，但同时其分类效果也有提升。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p>提示</p><p>本文主要来源于这里<a href="https://blog.csdn.net/qq_36523839/article/details/82383597%E3%80%82">https://blog.csdn.net/qq_36523839/article/details/82383597。</a></p><ul><li><a href="https://blog.csdn.net/qq_36523839/article/details/82383597">https://blog.csdn.net/qq_36523839/article/details/82383597</a></li><li><a href="https://blog.csdn.net/u010983763/article/details/70854469">https://blog.csdn.net/u010983763/article/details/70854469</a></li><li><a href="https://www.cnblogs.com/jchubby/p/5449404.html">https://www.cnblogs.com/jchubby/p/5449404.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;国际权威的学术组织the IEEE International Conference on Data Mining (ICDM) 2006年12月评选出了数据挖掘领域的十大经典算法: C4.5, k-Means, SVM, Apriori, EM,</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数据挖掘算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="数据挖掘算法" scheme="https://hubertwongcn.github.io/tags/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>25.推荐算法 - 汇总</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/25-tui-jian-suan-fa-hui-zong/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/25-tui-jian-suan-fa-hui-zong/</id>
    <published>2023-12-27T19:07:56.000Z</published>
    <updated>2023-12-27T19:07:56.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要对推荐算法整体知识点做汇总，做到总体的理解；深入理解需要再看专业的材料。</p></blockquote><h2 id="推荐算法的意义"><a href="#推荐算法的意义" class="headerlink" title="推荐算法的意义"></a>推荐算法的意义</h2><p>推荐根据用户兴趣和行为特点，向用户推荐所需的信息或商品，帮助用户在海量信息中快速发现真正所需的商品，提高用户黏性，促进信息点击和商品销售。</p><ul><li>帮助用户找到想要的商品(新闻&#x2F;音乐&#x2F;……)，发掘长尾</li></ul><p>帮用户找到想要的东西，谈何容易。商品茫茫多，甚至是我们自己，也经常点开淘宝，面对眼花缭乱的打折活动不知道要买啥。在经济学中，有一个著名理论叫长尾理论(The Long Tail)。套用在互联网领域中，指的就是最热的那一小部分资源将得到绝大部分的关注，而剩下的很大一部分资源却鲜少有人问津。这不仅造成了资源利用上的浪费，也让很多口味偏小众的用户无法找到自己感兴趣的内容。</p><ul><li>降低信息过载</li></ul><p>互联网时代信息量已然处于爆炸状态，若是将所有内容都放在网站首页上用户是无从阅读的，信息的利用率将会十分低下。因此我们需要推荐系统来帮助用户过滤掉低价值的信息。</p><ul><li>提高站点的点击率&#x2F;转化率</li></ul><p>好的推荐系统能让用户更频繁地访问一个站点，并且总是能为用户找到他想要购买的商品或者阅读的内容。</p><ul><li>加深对用户的了解，为用户提供定制化服务</li></ul><p>可以想见，每当系统成功推荐了一个用户感兴趣的内容后，我们对该用户的兴趣爱好等维度上的形象是越来越清晰的。当我们能够精确描绘出每个用户的形象之后，就可以为他们定制一系列服务，让拥有各种需求的用户都能在我们的平台上得到满足。</p><h2 id="推荐算法的输入"><a href="#推荐算法的输入" class="headerlink" title="推荐算法的输入"></a>推荐算法的输入</h2><p>推荐系统是基于海量数据挖掘分析的商业智能平台，推荐主要基于以下信息:</p><ul><li>热点信息或商品</li><li>用户Profile信息，如性别、年龄、职业、收入以及所在城市等等</li><li>用户历史浏览或行为记录</li><li>社会化关系</li></ul><h2 id="常见推荐算法"><a href="#常见推荐算法" class="headerlink" title="常见推荐算法"></a>常见推荐算法</h2><h3 id="基于流行度的算法"><a href="#基于流行度的算法" class="headerlink" title="基于流行度的算法"></a>基于流行度的算法</h3><p>基于流行度的算法非常简单粗暴，类似于各大新闻、微博热榜等，根据PV、UV、日均PV或分享率等数据来按某种热度排序来推荐给用户。</p><p>这种算法的优点是简单，适用于刚注册的新用户。缺点也很明显，它无法针对用户提供个性化的推荐。基于这种算法也可做一些优化，比如加入用户分群的流行度排序，例如把热榜上的体育内容优先推荐给体育迷，把政要热文推给热爱谈论政治的用户。</p><h3 id="基于用户行为数据的算法"><a href="#基于用户行为数据的算法" class="headerlink" title="基于用户行为数据的算法"></a>基于用户行为数据的算法</h3><p>CF算法主要有<code>基于用户的协同过滤算法(user-based CF)</code>，<code>基于项目的协同过滤(item-based CF)</code>以及<code>基于模型的协同过滤(model-based CF)</code>，它很简单而且很多时候推荐也是很准确的。</p><p>基于协同过滤的推荐机制是现今应用最为广泛的推荐机制，它有以下几个显著的优点:</p><ul><li>它不需要对物品或者用户进行严格的建模，而且不要求物品的描述是机器可理解的，所以这种方法也是领域无关的。</li><li>这种方法计算出来的推荐是开放的，可以共用他人的经验，很好的支持用户发现潜在的兴趣偏好。</li></ul><p>然后而它也存在以下几个问题:</p><ul><li>方法的核心是基于历史数据，所以对新物品和新用户都有“冷启动”的问题。</li><li>推荐的效果依赖于用户历史偏好数据的多少和准确性。</li><li>对于一些特殊品味的用户不能给予很好的推荐。</li><li>由于以历史数据为基础，抓取和建模用户的偏好后，很难修改或者根据用户的使用演变，从而导致这个方法不够灵活。</li><li>在大部分的实现中，用户历史偏好是用稀疏矩阵进行存储的，而稀疏矩阵上的计算有些明显的问题，包括可能少部分人的错误偏好会对推荐的准确度有很大的影响等等。</li></ul><p>对于矩阵稀疏的问题，有很多方法来改进CF算法。比如通过矩阵因子分解(如LFM)，我们可以把一个nm的矩阵分解为一个nk的矩阵乘以一个k*m的矩阵，这里的k可以是用户的特征、兴趣爱好与物品属性的一些联系，通过因子分解，可以找到用户和物品之间的一些潜在关联，从而填补之前矩阵中的缺失值。</p><h4 id="基于用户的协同过滤算法-user-based-CF"><a href="#基于用户的协同过滤算法-user-based-CF" class="headerlink" title="基于用户的协同过滤算法(user-based CF)"></a>基于用户的协同过滤算法(user-based CF)</h4><p>一个用户喜欢和他具有相似喜好的用户喜欢的项目， 两个用户喜欢的项目交集越大， 这两个用户越相似。 两个用户兴趣相似度的计算可以有多种方法， 常见的如 Pearson相关相似性和余弦相似度计算。</p><p>基于用户的CF原理如下:</p><ul><li>分析各个用户对item的评价(通过浏览记录、购买记录等)；</li><li>依据用户对item的评价计算得出所有用户之间的相似度；</li><li>选出与当前用户最相似的N个用户；</li><li>将这N个用户评价最高并且当前用户又没有浏览过的item推荐给当前用户。</li></ul><h4 id="基于项目的协同过滤-item-based-CF"><a href="#基于项目的协同过滤-item-based-CF" class="headerlink" title="基于项目的协同过滤(item-based CF)"></a>基于项目的协同过滤(item-based CF)</h4><p>基于项目的协同过滤推荐(item-based CF)基于这样的假设: 一个用户会喜欢与他之前喜欢的项目相似的项目。因此， 基于项目的协同过滤推荐关键在于计算物品之间的相似度。 基于用户的协同过滤和基于项目的协同过滤统称为基于邻域的推荐 (nearest neighbor recommendation)，也称作基于记忆的推荐算法(memory-based recommendation)。 基于邻域的推荐算法需要维护一个用户相似度矩阵或项目相似度矩阵， 因此对于项目的数目更新速度远远小于用户数目的增长速度的情况， 宜采用基于项目的推荐算法， 如 Amazon 建立的推荐系统正是基于项目的协同过滤推荐算法， 还有移动应用产品的推荐。另外， 有研究表明， 基于项目的算法一般在性能上要优于基于用户的算法。</p><p>基于领域的推荐算法不足之处在于数据稀疏性等问题， 难以处理大数据量下的即时结果。因此提出了基于模型的协同过滤推荐算法。</p><h4 id="基于模型的协同过滤-model-based-CF"><a href="#基于模型的协同过滤-model-based-CF" class="headerlink" title="基于模型的协同过滤(model-based CF)"></a>基于模型的协同过滤(model-based CF)</h4><p>基于模型的协同过滤推荐(model-based CF) 是采用机器学习或数据挖掘等算法， 用训练数据来学习识别复杂模式， 从而得到学习模型， 然后基于学习模型在数据集上进行智能预测。主要有以下模型:</p><ul><li>隐语义模型 (latent semantic CF models)&#x2F;矩阵分解模型(matrix factorization)</li><li>贝叶斯信念网协同过滤模型(Bayesian belief nets CF models)</li><li>聚类协同过滤模型 (clustering CF models)</li><li>概率因素模型(probabilistic factor models)</li></ul><h3 id="基于内容的算法"><a href="#基于内容的算法" class="headerlink" title="基于内容的算法"></a>基于内容的算法</h3><p>CF算法看起来很好很强大，通过改进也能克服各种缺点。那么问题来了，假如我是个《指环王》的忠实读者，我买过一本《双塔奇兵》，这时库里新进了第三部: 《王者归来》，那么显然我会很感兴趣。然而基于之前的算法，无论是用户评分还是书名的检索都不太好使，于是基于内容的推荐算法呼之欲出。</p><p>这种推荐仅需要得到两类信息: 项目特征的描述和用户过去的喜好信息。</p><ul><li>利用领域专家给项目打标签的方法， 也即<code>传统的分类系统(Taxonomy)</code>，</li><li>另一种是用户给项目打标签， 也即<code>大众分类系统 (Folksolomy)</code>。</li></ul><p>这种推荐系统的优点在于:</p><ul><li>易于实现，不需要用户数据因此不存在稀疏性和冷启动问题。</li><li>基于物品本身特征推荐，因此不存在过度推荐热门的问题。</li></ul><p>然而，缺点在于抽取的特征既要保证准确性又要具有一定的实际意义，否则很难保证推荐结果的相关性。豆瓣网采用人工维护tag的策略，依靠用户去维护内容的tag的准确性。</p><h3 id="基于关联规则的推荐"><a href="#基于关联规则的推荐" class="headerlink" title="基于关联规则的推荐"></a>基于关联规则的推荐</h3><p>基于关联规则的推荐更常见于电子商务系统中，并且也被证明行之有效。其实际的意义为购买了一些物品的用户更倾向于购买另一些物品。基于关联规则的推荐系统的首要目标是挖掘出关联规则，也就是那些同时被很多用户购买的物品集合，这些集合内的物品可以相互进行推荐。目前关联规则挖掘算法主要从<code>Apriori</code>和<code>FP-Growth</code>两个算法发展演变而来。</p><p>基于关联规则的推荐系统一般转化率较高，因为当用户已经购买了频繁集合中的若干项目后，购买该频繁集合中其他项目的可能性更高。该机制的缺点在于:</p><ul><li>计算量较大，但是可以离线计算，因此影响不大。</li><li>由于采用用户数据，不可避免的存在冷启动和稀疏性问题。</li><li>存在热门项目容易被过度推荐的问题。</li></ul><h3 id="基于效用推荐"><a href="#基于效用推荐" class="headerlink" title="基于效用推荐"></a>基于效用推荐</h3><p>基于效用的推荐(Utility-based Recommendation)是建立在对用户使用项目的效用情况上计算的，其核心问题是怎么样为每一个用户去创建一个效用函数，因此，用户资料模型很大程度上是由系统所采用的效用函数决定的。基于效用推荐的好处是它能把非产品的属性，如提供商的可靠性(Vendor Reliability)和产品的可得性(Product Availability)等考虑到效用计算中。</p><h3 id="基于知识推荐"><a href="#基于知识推荐" class="headerlink" title="基于知识推荐"></a>基于知识推荐</h3><p>基于知识的推荐(Knowledge-based Recommendation)在某种程度是可以看成是一种推理(Inference)技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因它们所用的功能知识不同而有明显区别。效用知识(Functional Knowledge)是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，所以用户资料可以是任何能支持推理的知识结构，它可以是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。</p><h3 id="组合推荐算法"><a href="#组合推荐算法" class="headerlink" title="组合推荐算法"></a>组合推荐算法</h3><p>由于各种推荐方法都有优缺点，所以在实际中，<code>组合推荐(Hybrid Recommendation)</code>经常被采用。研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预测结果，然后用某方法组合其结果。尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通过组合后要能避免或弥补各自推荐技术的弱点。</p><p>在组合方式上，有研究人员提出了七种组合思路:</p><ul><li><code>加权(Weight)</code>: 加权多种推荐技术结果。</li><li><code>变换(Switch)</code>: 根据问题背景和实际情况或要求决定变换采用不同的推荐技术。</li><li><code>混合(Mixed)</code>: 同时采用多种推荐技术给出多种推荐结果为用户提供参考。</li><li><code>特征组合(Feature combination)</code>: 组合来自不同推荐数据源的特征被另一种推荐算法所采用。</li><li><code>层叠(Cascade)</code>: 先用一种推荐技术产生一种粗糙的推荐结果，第二种推荐技术在此推荐结果的基础上进一步作出更精确的推荐。</li><li><code>特征扩充(Feature augmentation)</code>: 一种技术产生附加的特征信息嵌入到另一种推荐技术的特征输入中。</li><li><code>元级别(Meta-level)</code>: 用一种推荐方法产生的模型作为另一种推荐方法的输入。</li></ul><h2 id="推荐算法的评估"><a href="#推荐算法的评估" class="headerlink" title="推荐算法的评估"></a>推荐算法的评估</h2><p>当推荐算法完成后，怎样来评估这个算法的效果? <code>CTR(点击率)</code>、<code>CVR(转化率)</code>、<code>停留时间</code>等都是很直观的数据。在完成算法后，可以通过线下计算算法的<code>RMSE(均方根误差)</code>或者线上进行<code>ABTest</code>来对比效果。</p><h2 id="推荐算法的改进策略"><a href="#推荐算法的改进策略" class="headerlink" title="推荐算法的改进策略"></a>推荐算法的改进策略</h2><p>用户画像是最近经常被提及的一个名词，引入用户画像可以为推荐系统带来很多改进的余地，比如:</p><ul><li>打通公司各大业务平台，通过获取其他平台的用户数据，彻底解决冷启动问题；</li><li>在不同设备上同步用户数据，包括QQID、设备号、手机号等；</li><li>丰富用户的人口属性，包括年龄、职业、地域等；</li><li>更完善的用户兴趣状态，方便生成用户标签和匹配内容。</li></ul><p>另外，公司的优势——社交平台也是一个很好利用的地方。利用用户的社交网络，可以很方便地通过用户的好友、兴趣群的成员等更快捷地找到相似用户以及用户可能感兴趣的内容，提高推荐的准确度。</p><h2 id="业界一些推荐系统"><a href="#业界一些推荐系统" class="headerlink" title="业界一些推荐系统"></a>业界一些推荐系统</h2><h3 id="Yahoo-Resarch"><a href="#Yahoo-Resarch" class="headerlink" title="Yahoo Resarch"></a>Yahoo Resarch</h3><p>2011推荐系统论坛中，来自Yahoo！的Yehuda Koren分享了他对于互联网中推荐系统的经验, 他简单介绍了目前广泛流行的协同过滤推荐机制；另外分析了一些推荐系统中值得注意的一些问题:</p><ul><li>Bias Matters 在实际的应用中，用户并不是随机地选择物品去打分，而是只选择那些和他们兴趣相关的物品打分，绝大多数用户往往忽略了去给那些没有兴趣的物品打分。Koren通过分析Netflix Prize数据，Koren发现用户对视频的评分变化中，Bias可以解释其中的33%，而个性化只能解释其中的10%，剩下的57%暂时还得不到解释。</li><li>Eliciting user feedback Koren的目标是解决推荐系统的cold-start问题，例如，Yahoo！ Movie中，对于新用户，很难预测他们的喜好(对视频的评分)。那么，可以选一些视频让新用户打分，从而获取他们的兴趣数据。在此过程中，使用了决策树模型来引导用户评分，可以用尽量少的视频，最大程度地了解用户兴趣。</li><li>Estimating confidence in recommendations 在推荐系统中，我们需要对被推荐物品的可信度进行估计，从而得出更为可信的物品来进行推荐。Koren在这里提出了基于概率的可信度计算方法，也就是根据对评分(用户对物品)的概率预测，然后利用熵，标准方差，或是Gini不纯度等概率分布来对物品可信度进行评估。</li></ul><h3 id="淘宝推荐系统"><a href="#淘宝推荐系统" class="headerlink" title="淘宝推荐系统"></a>淘宝推荐系统</h3><p>淘宝推荐系统的目标就是要为各个产品提供商品，店铺，人，类目属性各种维度的推荐。它的核心就是以类目属性和社会属性为纽带，将人，商品和店铺建立起联系。</p><p>淘宝的宝贝推荐原则:</p><ul><li>基于内容的和关联规则</li><li>全网优质宝贝算分</li><li>根据推荐属性筛选TOP</li><li>基于推荐属性的关联关系</li><li>采用搜索引擎存储和检索优质宝贝</li><li>加入个性化用户信息</li></ul><p>根据用户的购买和收藏记录产生可推荐的关联规则。对优质宝贝的算分需要考虑商品的相关属性，包括描述，评价，名称，违规，收藏人气，累计销量，UV，以及PV等等。此外，推荐系统根据用户的浏览，收藏，购买行为以及反馈信息，在Hadoop上来计算用户带权重的标签，用于进行个性化推荐。</p><p>在个性化推荐之上，淘宝还实现了基于内容的广告投放。由于个性化推荐出来的物品是用户所感兴趣的，可以想象，基于此之上的广告投放也应该会行之有效。</p><p>众所周知，淘宝具有海量的数据和商品问题，这里列举了淘宝数据的一些参数: 超过8亿种在线商品，100万产品，4万属性，等等。在淘宝实现推荐系统可能遇到的各种各样的难题，其中有:</p><ul><li>商品种类繁多，生命周期短，很难及时收集到足够多的点击或购买数据，这使得基于用户行为的推荐方法，比如基于物品的推荐方法，发挥空间有限。</li><li>因为商品是由卖家而非网站登记的，数据的规范性差，这又给基于内容的推荐带来了很大的困难。</li><li>8亿种商品中，重复的商品种类应该非常多，需要尽量避免推荐重复种类的商品给用户，但在数据规范性差、区分度差的情况下，如何归并重复商品种类，这本身也是个很大的难题。</li><li>大多数推荐系统只需要考虑如何满足买家的需求，在淘宝，还要考虑卖家的需求。</li></ul><h3 id="豆瓣的推荐引擎-豆瓣猜"><a href="#豆瓣的推荐引擎-豆瓣猜" class="headerlink" title="豆瓣的推荐引擎 - 豆瓣猜"></a>豆瓣的推荐引擎 - 豆瓣猜</h3><p>豆瓣网在国内互联网行业美誉度很高，这是一家以帮助用户发现未知事物为己任的公司。它的“豆瓣猜”是一种个性化的推荐，其背后采用了基于用户的协同过滤技术。那么，豆瓣猜是如何向我们推荐产品的呢?</p><ul><li>首先，确定什么样的产品适合推荐? 豆瓣猜提出选择”具有媒体性的产品 (Media Product)“来进行推荐，即选择多样、口味很重要、单位成本不重要，同时能够广泛传播 (InformationCascade)的产品；接着在对真实的数据集进行定量分析后，进一步得出，应该是条目增长相对稳定、能够快速获得用户反馈，数据稀疏性与条目多样性、时效性比较平衡的产品，才是适合推荐的产品。</li><li>其次，豆瓣网的推荐引擎面对高成长性的挑战，通过降低存储空间，近似算法与分布式计算的设计，来实现对基于用户的协同过滤推荐系统的线性扩展。</li><li>最后，针对当前推荐系统面临的问题，包括倾向于给出平庸的推荐，有信息无结构，以及缺乏对用户的持续关注等黑盒推荐问题。豆瓣提出了分为 Prediction，Forecasting，Recommendation 三个阶段的下一代推荐系统，并探讨了一种下一代推荐引擎的构想——基于用户行为模型的、有记忆的、可进化的系统。</li></ul><h3 id="Hulu的个性化推荐"><a href="#Hulu的个性化推荐" class="headerlink" title="Hulu的个性化推荐"></a>Hulu的个性化推荐</h3><p>Hulu是一家美国的视频网站，它是由美国国家广播环球公司(NBC Universal)和福克斯广播公司(Fox)在2007年3月共同投资建立的。在美国，Hulu已是最受欢迎的视频网站之一。它拥有超过250个渠道合作伙伴，超过600个顶级广告客户，3千万的用户，3亿的视频，以及11亿的视频广告。广告是衡量视频网站成功与否的一个重要标准。事实证明，Hulu的广告效果非常好，若以每千人为单位对广告计费，Hulu的所得比电视台在黄金时段所得还高。那么，是什么让Hulu取得了这样的成功呢?</p><p>通过对视频和用户特点的分析，Hulu根据用户的个人信息，行为模型和反馈，设计出一个混合的个性化推荐系统。它包含了基于物品的协同过滤机制，基于内容的推荐，基于人口统计的推荐，从用户行为中提炼出来的主题模型，以及根据用户反馈信息对推荐系统的优化，等等。此个性化推荐系统也进而成为了一个产品，用于给用户推荐视频。这个产品通过问答的形式，与用户进行交互，获取用户的个人喜欢，进一步提高推荐的个性化。</p><p>Hulu把这种个性化推荐视频的思想放到了广告投放中，设计出了一套个性化广告推荐系统。那么，这种广告系统是如何实现个性化的呢?</p><ul><li>Hulu的用户对广告拥有一定控制权，在某些视频中你可以根据自己的喜好选择相应的广告，或者选择在开头看一段电影预告片来抵消广告。</li><li>Hulu收集用户对广告的反馈意见(评分)，例如，某个广告是否对收看用户有用?</li><li>根据人口统计的信息，来投放广告。例如，分析Hulu用户的年龄，性别特征来同方不同的视频及广告。</li><li>根据用户的行为模式，进一步增加广告投放的准确性。</li></ul><h2 id="推荐算法展望"><a href="#推荐算法展望" class="headerlink" title="推荐算法展望"></a>推荐算法展望</h2><p>从大数据的4V角度看， 主要的挑战及未来研究方向有以下几个方面:</p><ul><li>Volume(数据规模)。 数据量巨大加剧了数据稀疏性问题和长尾(long tail)问题。 在推荐系统中， 可获得的已打分数目通常远小于需要预测的打分数目。常用的数据集都非常稀疏， 当评分矩阵达到某种程度之后， 相比标准的协同过滤技术， 推荐质量会有所下降， 而且距离关系的计算代价很高， 很难实际应用到大规模评分数据上。 长尾是指那些原来不受到重视的销量小但种类多的产品或服务由于总量巨大， 累积起来的总收益超过主流产品的现象。</li><li>Variety (数据类型多样)。推荐系统可使用的数据复杂繁多， 如社交网络里面的信息、 地点位置信息和其他上下文感知信息都考虑进来， 不但数据量 增加， 计算复杂度亦会成倍增加。</li><li>Value (价值)。大数据本身的价值密度低， 但价值巨大。对推荐系统而言， 对用户兴趣建模， 并将用户可能感兴趣的项目推荐给他， 这里的项目相对用户而言， 是有价值的项目(数据)。</li><li>Velocity(时效性)。推荐系统对时效性要求较高， 想真正捕获最优的推荐机会， 时效性非常重要。如何将海量的用户数据应用到实时的用户交互中以提高用户体验， 这就涉及到推荐系统可扩展性(scalability)问题。</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://www.cnblogs.com/csxf/p/3600041.html">https://www.cnblogs.com/csxf/p/3600041.html</a></li><li><a href="http://blog.csdn.net/u014605728/article/details/51274814">http://blog.csdn.net/u014605728/article/details/51274814</a></li><li><a href="https://blog.csdn.net/wdr2003/article/details/80248148">https://blog.csdn.net/wdr2003/article/details/80248148</a></li><li><a href="https://blog.csdn.net/weixin_30912051/article/details/99331931">https://blog.csdn.net/weixin_30912051/article/details/99331931</a></li><li><a href="https://blog.csdn.net/fyq201749/article/details/81026950">https://blog.csdn.net/fyq201749/article/details/81026950</a></li><li><a href="https://blog.csdn.net/u012223913/article/details/52807717">https://blog.csdn.net/u012223913/article/details/52807717</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文主要对推荐算法整体知识点做汇总，做到总体的理解；深入理解需要再看专业的材料。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;推荐算法的意义&quot;&gt;&lt;a href=&quot;#推荐算法的意义&quot; class=&quot;headerlink&quot; title=&quot;推荐算</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="推荐算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="推荐算法" scheme="https://hubertwongcn.github.io/tags/%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>24.负载均衡算法 - 汇总</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/24-fu-zai-jun-heng-suan-fa-hui-zong/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/24-fu-zai-jun-heng-suan-fa-hui-zong/</id>
    <published>2023-12-27T19:06:10.000Z</published>
    <updated>2023-12-27T19:06:10.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍常用的负载均衡算法和Nginx中支持的负载均衡算法。</p></blockquote><h2 id="常见的负载均衡算法"><a href="#常见的负载均衡算法" class="headerlink" title="常见的负载均衡算法"></a>常见的负载均衡算法</h2><p>常见的负载均衡算法包含:</p><ul><li>轮询法(Round Robin)</li><li>加权轮询法(Weight Round Robin)</li><li>平滑加权轮询法(Smooth Weight Round Robin)</li><li>随机法(Random)</li><li>加权随机法(Weight Random)</li><li>源地址哈希法(Hash)</li><li>最小连接数法(Least Connections)</li></ul><h3 id="轮询法-Round-Robin"><a href="#轮询法-Round-Robin" class="headerlink" title="轮询法(Round Robin)"></a>轮询法(Round Robin)</h3><p>将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。</p><h3 id="加权轮询法-Weight-Round-Robin"><a href="#加权轮询法-Weight-Round-Robin" class="headerlink" title="加权轮询法(Weight Round Robin)"></a>加权轮询法(Weight Round Robin)</h3><p>不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。</p><h3 id="随机法-Random"><a href="#随机法-Random" class="headerlink" title="随机法(Random)"></a>随机法(Random)</h3><p>通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。</p><h3 id="加权随机法-Weight-Random"><a href="#加权随机法-Weight-Random" class="headerlink" title="加权随机法(Weight Random)"></a>加权随机法(Weight Random)</h3><p>与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。</p><h3 id="源地址哈希法-Hash"><a href="#源地址哈希法-Hash" class="headerlink" title="源地址哈希法(Hash)"></a>源地址哈希法(Hash)</h3><p>源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。</p><h3 id="最小连接数法-Least-Connections"><a href="#最小连接数法-Least-Connections" class="headerlink" title="最小连接数法(Least Connections)"></a>最小连接数法(Least Connections)</h3><p>最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。</p><h2 id="Nginx的5种负载均衡算法"><a href="#Nginx的5种负载均衡算法" class="headerlink" title="Nginx的5种负载均衡算法"></a>Nginx的5种负载均衡算法</h2><h3 id="轮询法-Round-Robin-默认"><a href="#轮询法-Round-Robin-默认" class="headerlink" title="轮询法(Round Robin)(默认)"></a>轮询法(Round Robin)(默认)</h3><p>每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。</p><h3 id="加权轮询法-Weight-Round-Robin-weight"><a href="#加权轮询法-Weight-Round-Robin-weight" class="headerlink" title="加权轮询法(Weight Round Robin)- weight"></a>加权轮询法(Weight Round Robin)- weight</h3><p>指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。</p><p>例如:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">upstream bakend &#123;  </span><br><span class="line">  server 192.168.0.14 weight=10;  </span><br><span class="line">  server 192.168.0.15 weight=10;  </span><br></pre></td></tr></table></figure><h3 id="源地址哈希法-Hash-ip-hash"><a href="#源地址哈希法-Hash-ip-hash" class="headerlink" title="源地址哈希法(Hash)- ip_hash"></a>源地址哈希法(Hash)- ip_hash</h3><p>每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。</p><p>例如:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream bakend &#123;  </span><br><span class="line">  ip_hash;  </span><br><span class="line">  server 192.168.0.14:88;  </span><br><span class="line">  server 192.168.0.15:80;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="fair-第三方"><a href="#fair-第三方" class="headerlink" title="fair(第三方)"></a>fair(第三方)</h3><p>按后端服务器的响应时间来分配请求，响应时间短的优先分配。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">upstream backend &#123;  </span><br><span class="line">  server server1;  </span><br><span class="line">  server server2;  </span><br><span class="line">  fair;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="url-hash-第三方"><a href="#url-hash-第三方" class="headerlink" title="url_hash(第三方)"></a>url_hash(第三方)</h3><p>按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。</p><p>例: 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">upstream backend &#123;  </span><br><span class="line">  server squid1:3128;  </span><br><span class="line">  server squid2:3128;  </span><br><span class="line">  <span class="built_in">hash</span> <span class="variable">$request_uri</span>;  </span><br><span class="line">  hash_method crc32;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>tips:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">upstream bakend&#123;<span class="comment">#定义负载均衡设备的Ip及设备状态  </span></span><br><span class="line">  ip_hash;  </span><br><span class="line">  server 127.0.0.1:9090 down;  </span><br><span class="line">  server 127.0.0.1:8080 weight=2;  </span><br><span class="line">  server 127.0.0.1:6060;  </span><br><span class="line">  server 127.0.0.1:7070 backup;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在需要使用负载均衡的server中增加</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">proxy_pass http://bakend/;</span><br></pre></td></tr></table></figure><p>每个设备的状态设置为:</p><ul><li>down 表示单前的server暂时不参与负载</li><li>weight 默认为1.weight越大，负载的权重就越大。</li><li>max_fails : 允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误</li><li>fail_timeout:max_fails次失败后，暂停的时间。</li><li>backup: 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。</li></ul><p>nginx支持同时设置多组的负载均衡，用来给不用的server来使用。</p><ul><li>client_body_in_file_only: 设置为On，可以讲client post过来的数据记录到文件中用来做debug。</li><li>client_body_temp_path: 设置记录文件的目录，可以设置最多3层目录。</li><li>location: 对URL进行匹配，可以进行重定向或者进行新的代理，负载均衡。</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://blog.csdn.net/youanyyou/article/details/78990133">https://blog.csdn.net/youanyyou/article/details/78990133</a></li><li><a href="https://blog.csdn.net/claram/article/details/90265243">https://blog.csdn.net/claram/article/details/90265243</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文主要介绍常用的负载均衡算法和Nginx中支持的负载均衡算法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;常见的负载均衡算法&quot;&gt;&lt;a href=&quot;#常见的负载均衡算法&quot; class=&quot;headerlink&quot; title=&quot;常见的负载均衡</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="负载均衡算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="负载均衡算法" scheme="https://hubertwongcn.github.io/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>23.分布式算法 - Snowflake算法</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/23-fen-bu-shi-suan-fa-snowflake-suan-fa/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/23-fen-bu-shi-suan-fa-snowflake-suan-fa/</id>
    <published>2023-12-27T19:04:46.000Z</published>
    <updated>2023-12-27T19:04:46.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。为什么如此重要？因为它提供了一种ID生成及生成的思路，当然这种方案就是需要考虑时钟回拨的问题以及做一些 buffer的缓冲设计提高性能。</p></blockquote><h2 id="雪花算法-Snowflake"><a href="#雪花算法-Snowflake" class="headerlink" title="雪花算法-Snowflake"></a>雪花算法-Snowflake</h2><p>Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。而 Java中64bit的整数是Long类型，所以在 Java 中 SnowFlake 算法生成的 ID 就是 long 来存储的。</p><ul><li><strong>第1位</strong>占用1bit，其值始终是0，可看做是符号位不使用。</li><li><strong>第2位</strong>开始的41位是时间戳，41-bit位可表示2^41个数，每个数代表毫秒，那么雪花算法可用的时间年限是<code>(1L&lt;&lt;41)/(1000L360024*365)</code>&#x3D;69 年的时间。</li><li><strong>中间的10-bit位</strong>可表示机器数，即2^10 &#x3D; 1024台机器，但是一般情况下我们不会部署这么台机器。如果我们对IDC（互联网数据中心）有需求，还可以将 10-bit 分 5-bit 给 IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，具体的划分可以根据自身需求定义。</li><li><strong>最后12-bit位</strong>是自增序列，可表示2^12 &#x3D; 4096个数。</li></ul><p>这样的划分之后相当于<strong>在一毫秒一个数据中心的一台机器上可产生4096个有序的不重复的ID</strong>。但是我们 IDC 和机器数肯定不止一个，所以毫秒内能生成的有序ID数是翻倍的。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280305186.png" alt="img"></p><p>Snowflake 的Twitter官方原版是用Scala写的，对Scala语言有研究的同学可以去阅读下，以下是 Java 版本的写法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.jajian.demo.distribute;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Twitter_Snowflake&lt;br&gt;</span></span><br><span class="line"><span class="comment"> * SnowFlake的结构如下(每部分用-分开):&lt;br&gt;</span></span><br><span class="line"><span class="comment"> * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt;</span></span><br><span class="line"><span class="comment"> * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt;</span></span><br><span class="line"><span class="comment"> * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截)</span></span><br><span class="line"><span class="comment"> * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt;</span></span><br><span class="line"><span class="comment"> * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt;</span></span><br><span class="line"><span class="comment"> * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt;</span></span><br><span class="line"><span class="comment"> * 加起来刚好64位，为一个Long型。&lt;br&gt;</span></span><br><span class="line"><span class="comment"> * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SnowflakeDistributeId</span> &#123;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// ==============================Fields===========================================</span></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 开始时间截 (2015-01-01)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">twepoch</span> <span class="operator">=</span> <span class="number">1420041600000L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 机器id所占的位数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">workerIdBits</span> <span class="operator">=</span> <span class="number">5L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数据标识id所占的位数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">datacenterIdBits</span> <span class="operator">=</span> <span class="number">5L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">maxWorkerId</span> <span class="operator">=</span> -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; workerIdBits);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 支持的最大数据标识id，结果是31</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">maxDatacenterId</span> <span class="operator">=</span> -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; datacenterIdBits);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 序列在id中占的位数</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">sequenceBits</span> <span class="operator">=</span> <span class="number">12L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 机器ID向左移12位</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">workerIdShift</span> <span class="operator">=</span> sequenceBits;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数据标识id向左移17位(12+5)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">datacenterIdShift</span> <span class="operator">=</span> sequenceBits + workerIdBits;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 时间截向左移22位(5+5+12)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">timestampLeftShift</span> <span class="operator">=</span> sequenceBits + workerIdBits + datacenterIdBits;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">long</span> <span class="variable">sequenceMask</span> <span class="operator">=</span> -<span class="number">1L</span> ^ (-<span class="number">1L</span> &lt;&lt; sequenceBits);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 工作机器ID(0~31)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> workerId;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 数据中心ID(0~31)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> datacenterId;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 毫秒内序列(0~4095)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> <span class="variable">sequence</span> <span class="operator">=</span> <span class="number">0L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 上次生成ID的时间截</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> <span class="variable">lastTimestamp</span> <span class="operator">=</span> -<span class="number">1L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//==============================Constructors=====================================</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 构造函数</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> workerId     工作ID (0~31)</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> datacenterId 数据中心ID (0~31)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">SnowflakeDistributeId</span><span class="params">(<span class="type">long</span> workerId, <span class="type">long</span> datacenterId)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (workerId &gt; maxWorkerId || workerId &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(String.format(<span class="string">&quot;worker Id can&#x27;t be greater than %d or less than 0&quot;</span>, maxWorkerId));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (datacenterId &gt; maxDatacenterId || datacenterId &lt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">IllegalArgumentException</span>(String.format(<span class="string">&quot;datacenter Id can&#x27;t be greater than %d or less than 0&quot;</span>, maxDatacenterId));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">this</span>.workerId = workerId;</span><br><span class="line">        <span class="built_in">this</span>.datacenterId = datacenterId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// ==============================Methods==========================================</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 获得下一个ID (该方法是线程安全的)</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> SnowflakeId</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="type">long</span> <span class="title function_">nextId</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">timestamp</span> <span class="operator">=</span> timeGen();</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常</span></span><br><span class="line">        <span class="keyword">if</span> (timestamp &lt; lastTimestamp) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(</span><br><span class="line">                    String.format(<span class="string">&quot;Clock moved backwards.  Refusing to generate id for %d milliseconds&quot;</span>, lastTimestamp - timestamp));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//如果是同一时间生成的，则进行毫秒内序列</span></span><br><span class="line">        <span class="keyword">if</span> (lastTimestamp == timestamp) &#123;</span><br><span class="line">            sequence = (sequence + <span class="number">1</span>) &amp; sequenceMask;</span><br><span class="line">            <span class="comment">//毫秒内序列溢出</span></span><br><span class="line">            <span class="keyword">if</span> (sequence == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="comment">//阻塞到下一个毫秒,获得新的时间戳</span></span><br><span class="line">                timestamp = tilNextMillis(lastTimestamp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//时间戳改变，毫秒内序列重置</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            sequence = <span class="number">0L</span>;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//上次生成ID的时间截</span></span><br><span class="line">        lastTimestamp = timestamp;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//移位并通过或运算拼到一起组成64位的ID</span></span><br><span class="line">        <span class="keyword">return</span> ((timestamp - twepoch) &lt;&lt; timestampLeftShift) <span class="comment">//</span></span><br><span class="line">                | (datacenterId &lt;&lt; datacenterIdShift) <span class="comment">//</span></span><br><span class="line">                | (workerId &lt;&lt; workerIdShift) <span class="comment">//</span></span><br><span class="line">                | sequence;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 阻塞到下一个毫秒，直到获得新的时间戳</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> lastTimestamp 上次生成ID的时间截</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 当前时间戳</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="type">long</span> <span class="title function_">tilNextMillis</span><span class="params">(<span class="type">long</span> lastTimestamp)</span> &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">timestamp</span> <span class="operator">=</span> timeGen();</span><br><span class="line">        <span class="keyword">while</span> (timestamp &lt;= lastTimestamp) &#123;</span><br><span class="line">            timestamp = timeGen();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> timestamp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 返回以毫秒为单位的当前时间</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@return</span> 当前时间(毫秒)</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">protected</span> <span class="type">long</span> <span class="title function_">timeGen</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>测试的代码如下</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">    <span class="type">SnowflakeDistributeId</span> <span class="variable">idWorker</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SnowflakeDistributeId</span>(<span class="number">0</span>, <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++) &#123;</span><br><span class="line">        <span class="type">long</span> <span class="variable">id</span> <span class="operator">=</span> idWorker.nextId();</span><br><span class="line"><span class="comment">//      System.out.println(Long.toBinaryString(id));</span></span><br><span class="line">        System.out.println(id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>雪花算法提供了一个很好的设计思想，雪花算法生成的ID是趋势递增，不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的，而且可以根据自身业务特性分配bit位，非常灵活</strong>。</p><p>但是雪花算法强<strong>依赖机器时钟</strong>，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。如果恰巧回退前生成过一些ID，而时间回退后，生成的ID就有可能重复。官方对于此并没有给出解决方案，而是简单的抛错处理，这样会造成在时间被追回之前的这段时间服务不可用。</p><p>很多其他类雪花算法也是在此思想上的设计然后改进规避它的缺陷，后面介绍的<code>百度 UidGenerator</code> 和 <code>美团分布式ID生成系统 Leaf</code> 中snowflake模式都是在 snowflake 的基础上演进出来的。</p><h2 id="其它相关算法"><a href="#其它相关算法" class="headerlink" title="其它相关算法"></a>其它相关算法</h2><p>在如下文章中已经包含了所有主流的全局唯一ID实现方案：</p><ul><li><a href="">分布式系统 - 全局唯一ID实现方案</a></li></ul><p>这里给出相关的链接：</p><ul><li><a href="">为什么需要全局唯一ID</a></li><li><a href="">UUID</a></li><li><a href="">数据库生成</a></li><li><a href="">使用redis实现</a></li><li><a href="">雪花算法-Snowflake</a></li><li>百度-UidGenerator<ul><li><a href="">DefaultUidGenerator 实现</a></li><li><a href="">CachedUidGenerator 实现</a></li></ul></li><li>美团Leaf<ul><li><a href="">Leaf-segment 数据库方案</a></li><li><a href="">Leaf-snowflake方案</a></li></ul></li><li><a href="">Mist 薄雾算法</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。为什么如此重</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    <category term="Snowflake算法" scheme="https://hubertwongcn.github.io/tags/Snowflake%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>22.分布式算法 - ZAB算法</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/22-fen-bu-shi-suan-fa-zab-suan-fa/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/22-fen-bu-shi-suan-fa-zab-suan-fa/</id>
    <published>2023-12-27T19:01:42.000Z</published>
    <updated>2023-12-27T19:01:42.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）, 它应该是所有一致性协议中生产环境中应用最多的了。为什么呢？因为它是为 Zookeeper 设计的分布式一致性协议！</p></blockquote><h2 id="什么是-ZAB-协议？-ZAB-协议介绍"><a href="#什么是-ZAB-协议？-ZAB-协议介绍" class="headerlink" title="什么是 ZAB 协议？ ZAB 协议介绍"></a>什么是 ZAB 协议？ ZAB 协议介绍</h2><blockquote><p>ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）。</p></blockquote><ol><li>Zookeeper 是一个为分布式应用提供高效且可靠的分布式协调服务。在解决分布式一致性方面，Zookeeper 并没有使用 Paxos ，而是采用了 ZAB 协议。</li><li>ZAB 协议定义：<strong>ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 <code>崩溃恢复</code> 和 <code>原子广播</code> 协议</strong>。下面我们会重点讲这两个东西。</li><li>基于该协议，Zookeeper 实现了一种 主备模式 的系统架构来保持集群中各个副本之间数据一致性。具体如下图所示：</li></ol><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280302719.png" alt="img"></p><p>上图显示了 Zookeeper 如何处理集群中的数据。所有客户端写入数据都是写入到 主进程（称为 Leader）中，然后，由 Leader 复制到备份进程（称为 Follower）中。从而保证数据一致性。从设计上看，和 Raft 类似。</p><ol><li>那么复制过程又是如何的呢？复制过程类似 2PC，ZAB 只需要 Follower 有一半以上返回 Ack 信息就可以执行提交，大大减小了同步阻塞。也提高了可用性。</li></ol><p>简单介绍完，开始重点介绍 <code>消息广播</code> 和 <code>崩溃恢复</code>。<strong>整个 Zookeeper 就是在这两个模式之间切换</strong>。 简而言之，当 Leader 服务可以正常使用，就进入消息广播模式，当 Leader 不可用时，则进入崩溃恢复模式。</p><h2 id="消息广播"><a href="#消息广播" class="headerlink" title="消息广播"></a>消息广播</h2><p>ZAB 协议的消息广播过程使用的是一个原子广播协议，类似一个 二阶段提交过程。对于客户端发送的写请求，全部由 Leader 接收，Leader 将请求封装成一个事务 Proposal，将其发送给所有 Follwer ，然后，根据所有 Follwer 的反馈，如果超过半数成功响应，则执行 commit 操作（先提交自己，再发送 commit 给所有 Follwer）。</p><p>基本上，整个广播流程分为 3 步骤：</p><p>1.将数据都复制到 Follwer 中</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280302775.png" alt="img"></p><p>等待 Follwer 回应 Ack，最低超过半数即成功</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280302807.png" alt="img"></p><p>当超过半数成功回应，则执行 commit ，同时提交自己</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280303912.png" alt="img"></p><p>通过以上 3 个步骤，就能够保持集群之间数据的一致性。实际上，在 Leader 和 Follwer 之间还有一个消息队列，用来解耦他们之间的耦合，避免同步，实现异步解耦。</p><p>还有一些细节：</p><ul><li>Leader 在收到客户端请求之后，会将这个请求封装成一个事务，并给这个事务分配一个全局递增的唯一 ID，称为事务ID（ZXID），ZAB 兮协议需要保证事务的顺序，因此必须将每一个事务按照 ZXID 进行先后排序然后处理。</li><li>在 Leader 和 Follwer 之间还有一个消息队列，用来解耦他们之间的耦合，解除同步阻塞。</li><li>zookeeper集群中为保证任何所有进程能够有序的顺序执行，只能是 Leader 服务器接受写请求，即使是 Follower 服务器接受到客户端的请求，也会转发到 Leader 服务器进行处理。</li><li>实际上，这是一种简化版本的 2PC，不能解决单点问题。等会我们会讲述 ZAB 如何解决单点问题（即 Leader 崩溃问题）。</li></ul><h2 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h2><p>刚刚我们说消息广播过程中，Leader 崩溃怎么办？还能保证数据一致吗？如果 Leader 先本地提交了，然后 commit 请求没有发送出去，怎么办？</p><p>实际上，当 Leader 崩溃，即进入我们开头所说的崩溃恢复模式（崩溃即：Leader 失去与过半 Follwer 的联系）。下面来详细讲述。</p><ul><li>假设1：Leader 在复制数据给所有 Follwer 之后崩溃，怎么办？</li><li>假设2：Leader 在收到 Ack 并提交了自己，同时发送了部分 commit 出去之后崩溃怎么办？</li></ul><p>针对这些问题，ZAB 定义了 2 个原则：</p><ul><li>ZAB 协议确保那些已经在 Leader 提交的事务最终会被所有服务器提交。</li><li>ZAB 协议确保丢弃那些只在 Leader 提出&#x2F;复制，但没有提交的事务。</li></ul><p>所以，ZAB 设计了下面这样一个选举算法：<strong>能够确保提交已经被 Leader 提交的事务，同时丢弃已经被跳过的事务</strong>。</p><p>针对这个要求，如果让 Leader 选举算法能够保证新选举出来的 Leader 服务器拥有集群总所有机器编号（即 ZXID 最大）的事务，那么就能够保证这个新选举出来的 Leader 一定具有所有已经提交的提案。</p><p>而且这么做有一个好处是：<strong>可以省去 Leader 服务器检查事务的提交和丢弃工作的这一步操作</strong>。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280303068.png" alt="img"></p><p>这样，我们刚刚假设的两个问题便能够解决。假设 1 最终会丢弃调用没有提交的数据，假设 2 最终会同步所有服务器的数据。这个时候，就引出了一个问题，如何同步？</p><h2 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h2><p>当崩溃恢复之后，需要在正式工作之前（接收客户端请求），Leader 服务器首先确认事务是否都已经被过半的 Follwer 提交了，即是否完成了数据同步。目的是为了保持数据一致。</p><p>当所有的 Follwer 服务器都成功同步之后，Leader 会将这些服务器加入到可用服务器列表中。</p><p>实际上，Leader 服务器处理或丢弃事务都是依赖着 ZXID 的，那么这个 ZXID 如何生成呢？</p><p>答：在 ZAB 协议的事务编号 ZXID 设计中，ZXID 是一个 64 位的数字，其中低 32 位可以看作是一个简单的递增的计数器，针对客户端的每一个事务请求，Leader 都会产生一个新的事务 Proposal 并对该计数器进行 + 1 操作。</p><p>而高 32 位则代表了 Leader 服务器上取出本地日志中最大事务 Proposal 的 ZXID，并从该 ZXID 中解析出对应的 epoch 值，然后再对这个值加一。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280304680.png" alt="img"></p><p>高 32 位代表了每代 Leader 的唯一性，低 32 代表了每代 Leader 中事务的唯一性。同时，也能让 Follwer 通过高 32 位识别不同的 Leader。简化了数据恢复流程。</p><p>基于这样的策略：当 Follower 链接上 Leader 之后，Leader 服务器会根据自己服务器上最后被提交的 ZXID 和 Follower 上的 ZXID 进行比对，比对结果要么回滚，要么和 Leader 同步。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>ZAB 协议和我们之前看的 Raft 协议实际上是有相似之处的，比如都有一个 Leader，用来保证一致性（Paxos 并没有使用 Leader 机制保证一致性）。再有采取过半即成功的机制保证服务可用（实际上 Paxos 和 Raft 都是这么做的）。</p><p>ZAB 让整个 Zookeeper 集群在两个模式之间转换，消息广播和崩溃恢复，消息广播可以说是一个简化版本的 2PC，通过崩溃恢复解决了 2PC 的单点问题，通过队列解决了 2PC 的同步阻塞问题。</p><p>而支持崩溃恢复后数据准确性的就是数据同步了，数据同步基于事务的 ZXID 的唯一性来保证。通过 + 1 操作可以辨别事务的先后顺序。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p>本文主要转载自如下，文章内容略有调整：</p><ul><li>作者：莫那·鲁道</li><li>原文链接：<a href="https://www.cnblogs.com/stateis0/p/9062133.html">https://www.cnblogs.com/stateis0/p/9062133.html</a></li><li>PS：转载请一并附带原出处</li></ul><p>其它我还推荐你看下如下相关的较为优秀的文章：</p><ul><li><a href="https://www.cnblogs.com/leesf456/p/6107600.html">Zookeeper的Leader选举在新窗口打开</a></li><li><a href="https://blog.csdn.net/a724888/article/details/80757503">https://blog.csdn.net/a724888/article/details/80757503</a></li><li><a href="https://www.cnblogs.com/stateis0/p/9062133.html">https://www.cnblogs.com/stateis0/p/9062133.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）, 它应该是所有一致性协议中生产环境中应用最多的了。为什么呢？因为它是为 Zookeeper 设计的分布式一致性协议！&lt;/p&gt;
&lt;/block</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    <category term="ZAB算法" scheme="https://hubertwongcn.github.io/tags/ZAB%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>21.分布式算法-Gossip 协议详解</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/21-fen-bu-shi-suan-fa-gossip-xie-yi-xiang-jie/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/21-fen-bu-shi-suan-fa-gossip-xie-yi-xiang-jie/</id>
    <published>2023-12-27T18:57:31.000Z</published>
    <updated>2023-12-27T18:57:31.000Z</updated>
    
    <content type="html"><![CDATA[<p>于是，<strong>分散式发散消息</strong> 的 <strong>Gossip 协议</strong> 就诞生了。</p><h2 id="Gossip-协议介绍"><a href="#Gossip-协议介绍" class="headerlink" title="Gossip 协议介绍"></a>Gossip 协议介绍</h2><p>Gossip 直译过来就是闲话、流言蜚语的意思。流言蜚语有什么特点呢？容易被传播且传播速度还快，你传我我传他，然后大家都知道了。</p><p><strong>Gossip 协议</strong> 也叫 Epidemic 协议（流行病协议）或者 Epidemic propagation 算法（疫情传播算法），别名很多。不过，这些名字的特点都具有 <strong>随机传播特性</strong> （联想一下病毒传播、癌细胞扩散等生活中常见的情景），这也正是 Gossip 协议最主要的特点。</p><p>Gossip 协议最早是在 ACM 上的一篇 1987 年发表的论文 <a href="https://dl.acm.org/doi/10.1145/41840.41841">《Epidemic Algorithms for Replicated Database Maintenance》</a>中被提出的。根据论文标题，我们大概就能知道 Gossip 协议当时提出的主要应用是在分布式数据库系统中各个副本节点同步数据。</p><p>正如 Gossip 协议其名一样，这是一种随机且带有传染性的方式将信息传播到整个网络中，并在一定时间内，使得系统内的所有节点数据一致。</p><p>在 Gossip 协议下，没有所谓的中心节点，每个节点周期性地随机找一个节点互相同步彼此的信息，理论上来说，各个节点的状态最终会保持一致。</p><p>下面我们来对 Gossip 协议的定义做一个总结：<strong>Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。</strong></p><h2 id="Gossip-协议应用"><a href="#Gossip-协议应用" class="headerlink" title="Gossip 协议应用"></a>Gossip 协议应用</h2><p>NoSQL 数据库 Redis 和 Apache Cassandra、服务网格解决方案 Consul 等知名项目都用到了 Gossip 协议，学习 Gossip 协议有助于我们搞清很多技术的底层原理。</p><p>我们这里以 Redis Cluster 为例说明 Gossip 协议的实际应用。</p><p>我们经常使用的分布式缓存 Redis 的官方集群解决方案（3.0 版本引入） Redis Cluster 就是基于 Gossip 协议来实现集群中各个节点数据的最终一致性。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280258381.png" alt="img"></p><p>Redis Cluster 是一个典型的分布式系统，分布式系统中的各个节点需要互相通信。既然要相互通信就要遵循一致的通信协议，Redis Cluster 中的各个节点基于 <strong>Gossip 协议</strong> 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息。</p><p>Redis Cluster 的节点之间会相互发送多种 Gossip 消息：</p><ul><li><strong>MEET</strong>：在 Redis Cluster 中的某个 Redis 节点上执行 <code>CLUSTER MEET ip port</code> 命令，可以向指定的 Redis 节点发送一条 MEET 信息，用于将其添加进 Redis Cluster 成为新的 Redis 节点。</li><li><strong>PING&#x2F;PONG</strong>：Redis Cluster 中的节点都会定时地向其他节点发送 PING 消息，来交换各个节点状态信息，检查各个节点状态，包括在线状态、疑似下线状态 PFAIL 和已下线状态 FAIL。</li><li><strong>FAIL</strong>：Redis Cluster 中的节点 A 发现 B 节点 PFAIL ，并且在下线报告的有效期限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 。</li><li>……</li></ul><p>下图就是主从架构的 Redis Cluster 的示意图，图中的虚线代表的就是各个节点之间使用 Gossip 进行通信 ，实线表示主从复制。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280258419.png" alt="img"></p><p>有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时可以自动切换。</p><p>关于 Redis Cluster 的详细介绍，可以查看这篇文章 <a href="https://javaguide.cn/database/redis/redis-cluster.html">Redis 集群详解(付费)</a> 。</p><h2 id="Gossip-协议消息传播模式"><a href="#Gossip-协议消息传播模式" class="headerlink" title="Gossip 协议消息传播模式"></a>Gossip 协议消息传播模式</h2><p>Gossip 设计了两种可能的消息传播模式：<strong>反熵（Anti-Entropy）</strong> 和 <strong>传谣（Rumor-Mongering）</strong>。</p><h3 id="反熵-Anti-entropy"><a href="#反熵-Anti-entropy" class="headerlink" title="反熵(Anti-entropy)"></a>反熵(Anti-entropy)</h3><p>根据维基百科：</p><p>熵的概念最早起源于<a href="https://zh.wikipedia.org/wiki/%E7%89%A9%E7%90%86%E5%AD%A6">物理学</a>，用于度量一个热力学系统的混乱程度。熵最好理解为不确定性的量度而不是确定性的量度，因为越随机的信源的熵越大。</p><p>在这里，你可以把反熵中的熵了解为节点之间数据的混乱程度&#x2F;差异性，反熵就是指消除不同节点中数据的差异，提升节点间数据的相似度，从而降低熵值。</p><p>具体是如何反熵的呢？集群中的节点，每隔段时间就随机选择某个其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异，实现数据的最终一致性。</p><p>在实现反熵的时候，主要有推、拉和推拉三种方式：</p><ul><li>推方式，就是将自己的所有副本数据，推给对方，修复对方副本中的熵。</li><li>拉方式，就是拉取对方的所有副本数据，修复自己副本中的熵。</li><li>推拉就是同时修复自己副本和对方副本中的熵。</li></ul><p>伪代码如下：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280258609.png" alt="img"></p><p>在我们实际应用场景中，一般不会采用随机的节点进行反熵，而是需要可以的设计一个闭环。这样的话，我们能够在一个确定的时间范围内实现各个节点数据的最终一致性，而不是基于随机的概率。像 InfluxDB 就是这样来实现反熵的。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280258626.png" alt="img"></p><ol><li>节点 A 推送数据给节点 B，节点 B 获取到节点 A 中的最新数据。</li><li>节点 B 推送数据给 C，节点 C 获取到节点 A，B 中的最新数据。</li><li>节点 C 推送数据给 A，节点 A 获取到节点 B，C 中的最新数据。</li><li>节点 A 再推送数据给 B 形成闭环，这样节点 B 就获取到节点 C 中的最新数据。</li></ol><p>虽然反熵很简单实用，但是，节点过多或者节点动态变化的话，反熵就不太适用了。这个时候，我们想要实现最终一致性就要靠 <strong>谣言传播(Rumor mongering)</strong> 。</p><h3 id="谣言传播-Rumor-mongering"><a href="#谣言传播-Rumor-mongering" class="headerlink" title="谣言传播(Rumor mongering)"></a>谣言传播(Rumor mongering)</h3><p>谣言传播指的是分布式系统中的一个节点一旦有了新数据之后，就会变为活跃节点，活跃节点会周期性地联系其他节点向其发送新数据，直到所有的节点都存储了该新数据。</p><p>如下图所示（下图来自于<a href="https://managementfromscratch.wordpress.com/2016/04/01/introduction-to-gossip/">INTRODUCTION TO GOSSIP</a> 这篇文章）：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280301390.webp" alt="work1080.gif-2.webp"></p><p>伪代码如下：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280258322.png" alt="img"></p><p>谣言传播比较适合节点数量比较多的情况，不过，这种模式下要尽量避免传播的信息包不能太大，避免网络消耗太大。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul><li>反熵（Anti-Entropy）会传播节点的所有数据，而谣言传播（Rumor-Mongering）只会传播节点新增的数据。</li><li>我们一般会给反熵设计一个闭环。</li><li>谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景。</li></ul><h2 id="Gossip-协议优势和缺陷"><a href="#Gossip-协议优势和缺陷" class="headerlink" title="Gossip 协议优势和缺陷"></a>Gossip 协议优势和缺陷</h2><p><strong>优势：</strong></p><p>1、相比于其他分布式协议&#x2F;算法来说，Gossip 协议理解起来非常简单。</p><p>2、能够容忍网络上节点的随意地增加或者减少，宕机或者重启，因为 Gossip 协议下这些节点都是平等的，去中心化的。新增加或者重启的节点在理想情况下最终是一定会和其他节点的状态达到一致。</p><p>3、速度相对较快。节点数量比较多的情况下，扩散速度比一个主节点向其他节点传播信息要更快（多播）。</p><p><strong>缺陷</strong> :</p><p>1、消息需要通过多个传播的轮次才能传播到整个网络中，因此，必然会出现各节点状态不一致的情况。毕竟，Gossip 协议强调的是最终一致，至于达到各个节点的状态一致需要多长时间，谁也无从得知。</p><p>2、由于拜占庭将军问题，不允许存在恶意节点。</p><p>3、可能会出现消息冗余的问题。由于消息传播的随机性，同一个节点可能会重复收到相同的消息。</p><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><ul><li>Gossip 协议是一种允许在分布式系统中共享状态的通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。</li><li>Gossip 协议被 Redis、Apache Cassandra、Consul 等项目应用。</li><li>谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景。</li></ul><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul><li>一万字详解 Redis Cluster Gossip 协议：<a href="https://segmentfault.com/a/1190000038373546">https://segmentfault.com/a/1190000038373546</a></li><li>《分布式协议与算法实战》</li><li>《Redis 设计与实现》</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;于是，&lt;strong&gt;分散式发散消息&lt;/strong&gt; 的 &lt;strong&gt;Gossip 协议&lt;/strong&gt; 就诞生了。&lt;/p&gt;
&lt;h2 id=&quot;Gossip-协议介绍&quot;&gt;&lt;a href=&quot;#Gossip-协议介绍&quot; class=&quot;headerlink&quot; title=&quot;</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    <category term="Gossip" scheme="https://hubertwongcn.github.io/tags/Gossip/"/>
    
  </entry>
  
  <entry>
    <title>20.分布式算法 - Raft算法</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/20-fen-bu-shi-suan-fa-raft-suan-fa/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/20-fen-bu-shi-suan-fa-raft-suan-fa/</id>
    <published>2023-12-27T18:49:38.000Z</published>
    <updated>2023-12-27T18:49:38.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Paxos是出了名的难懂，而Raft正是为了探索一种更易于理解的一致性算法而产生的。它的首要设计目的就是易于理解，所以在选主的冲突处理等方式上它都选择了非常简单明了的解决方案。</p></blockquote><h2 id="推荐阅读"><a href="#推荐阅读" class="headerlink" title="推荐阅读"></a>推荐阅读</h2><blockquote><p>提示</p><p>强烈推荐通过如下资料学习raft。 </p></blockquote><ul><li><a href="https://raft.github.io/">raft.github.io</a></li></ul><p>这里面有一个Raft Visualization:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280250473.png" alt="img"></p><ul><li><a href="https://raft.github.io/raft.pdf">In Search of an Understandable Consensus Algorithm</a></li><li><a href="http://thesecretlivesofdata.com/raft/">动画理解Raft神器</a></li></ul><h2 id="Raft算法简介"><a href="#Raft算法简介" class="headerlink" title="Raft算法简介"></a>Raft算法简介</h2><p>不同于Paxos算法直接从分布式一致性问题出发推导出来，Raft算法则是从多副本状态机的角度提出，用于管理多副本状态机的日志复制。Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题: Leader选举(Leader election)、日志同步(Log replication)、安全性(Safety)、日志压缩(Log compaction)、成员变更(Membership change)等。同时，Raft算法使用了更强的假设来减少了需要考虑的状态，使之变的易于理解和实现。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p>Raft将系统中的角色分为<code>领导者(Leader)</code>、<code>跟从者(Follower)</code>和<code>候选人(Candidate)</code>:</p><ul><li><code>Leader</code>: 接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。</li><li><code>Follower</code>: 接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。</li><li><code>Candidate</code>: Leader选举过程中的临时角色。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280251402.jpg" alt="img"></p><p>Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。</p><h3 id="角色状态转换"><a href="#角色状态转换" class="headerlink" title="角色状态转换"></a>角色状态转换</h3><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280251448.jpg" alt="img"></p><p>Follower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。收到大多数服务器投票的Candidate会成为新的Leader。Leader在宕机之前会一直保持Leader的状态。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280251952.jpg" alt="img"></p><p>Raft算法将时间分为一个个的任期(term)，每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。</p><h2 id="Raft算法子问题"><a href="#Raft算法子问题" class="headerlink" title="Raft算法子问题"></a>Raft算法子问题</h2><p>Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题: Leader选举(Leader election)、日志同步(Log replication)、安全性(Safety)、日志压缩(Log compaction)、成员变更(Membership change)等</p><h3 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h3><p>Raft 使用心跳(heartbeat)触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。</p><p>Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC (RPC细节参见八、Raft算法总结)。结果有以下三种情况:</p><ul><li>赢得了多数的选票，成功选举为Leader；</li><li>收到了Leader的消息，表示有其它服务器已经抢先当选了Leader；</li><li>没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280252166.jpg" alt="img"></p><p>选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。</p><p>Raft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。</p><h3 id="日志同步"><a href="#日志同步" class="headerlink" title="日志同步"></a>日志同步</h3><p>Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目(Log entries)加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC (RPC细节参见八、Raft算法总结)复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280252563.jpg" alt="img"></p><p>某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。</p><p>日志由有序编号(log index)的日志条目组成。每个日志条目包含它被创建时的任期号(term)，和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交(commit)了。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280252280.jpg" alt="img"></p><p>Raft日志同步保证如下两点:</p><ul><li>如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。</li><li>如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。</li></ul><p>第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。</p><p>第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。</p><p>一般情况下，Leader和Followers的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，Leader崩溃可能会导致日志不一致: 旧的Leader可能没有完全复制完日志中的所有条目。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280252953.jpg" alt="img"></p><p>上图阐述了一些Followers可能和新的Leader日志不同的情况。一个Follower可能会丢失掉Leader上的一些条目，也有可能包含一些Leader没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。</p><p>Leader通过强制Followers复制它的日志来处理日志的不一致，Followers上的不一致的日志会被Leader的日志覆盖。</p><p>Leader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目。</p><p>Leader会从后往前试，每次AppendEntries失败后尝试前一个日志条目，直到成功找到每个Follower的日志一致位点，然后向后逐条覆盖Followers在该位置之后的条目。</p><h2 id="安全性"><a href="#安全性" class="headerlink" title="安全性"></a>安全性</h2><p>Raft增加了如下两条限制以保证安全性:</p><ul><li>拥有最新的已提交的log entry的Follower才有资格成为Leader。</li></ul><p>这个保证是在RequestVote RPC中做的，Candidate在发送RequestVote RPC时，要带上自己的最后一条日志的term和log index，其他节点收到消息时，如果发现自己的日志比请求中携带的更新，则拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则log index更大的更新。</p><ul><li>Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交(log index 小于 commit index的日志被间接提交)。</li></ul><p>之所以要这样，是因为可能会出现已提交的日志又被覆盖的情况:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280252256.jpg" alt="img"></p><p>在阶段a，term为2，S1是Leader，且S1写入日志(term, index)为(2, 2)，并且日志被同步写入了S2；</p><p>在阶段b，S1离线，触发一次新的选主，此时S5被选为新的Leader，此时系统term为3，且写入了日志(term, index)为(3， 2);</p><p>S5尚未将日志推送到Followers就离线了，进而触发了一次新的选主，而之前离线的S1经过重新上线后被选中变成Leader，此时系统term为4，此时S1会将自己的日志同步到Followers，按照上图就是将日志(2， 2)同步到了S3，而此时由于该日志已经被同步到了多数节点(S1, S2, S3)，因此，此时日志(2，2)可以被提交了。；</p><p>在阶段d，S1又下线了，触发一次选主，而S5有可能被选为新的Leader(这是因为S5可以满足作为主的一切条件: 1. term &#x3D; 5 &gt; 4，2. 最新的日志为(3，2)，比大多数节点(如S2&#x2F;S3&#x2F;S4的日志都新)，然后S5会将自己的日志更新到Followers，于是S2、S3中已经被提交的日志(2，2)被截断了。</p><p>增加上述限制后，即使日志(2，2)已经被大多数节点(S1、S2、S3)确认了，但是它不能被提交，因为它是来自之前term(2)的日志，直到S1在当前term(4)产生的日志(4， 4)被大多数Followers确认，S1方可提交日志(4，4)这条日志，当然，根据Raft定义，(4，4)之前的所有日志也会被提交。此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的日志(4，4)。</p><h3 id="日志压缩"><a href="#日志压缩" class="headerlink" title="日志压缩"></a>日志压缩</h3><p>在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响可用性。Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃。</p><p>每个副本独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。</p><p>Snapshot中包含以下内容:</p><ul><li>日志元数据。最后一条已提交的 log entry的 log index和term。这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。</li><li>系统当前状态。</li></ul><p>当Leader要发给某个日志落后太多的Follower的log entry被丢弃，Leader会将snapshot发给Follower。或者当新加进一台机器时，也会发送snapshot给它。发送snapshot使用InstalledSnapshot RPC。</p><p>做snapshot既不要做的太频繁，否则消耗磁盘带宽， 也不要做的太不频繁，否则一旦节点重启需要回放大量日志，影响可用性。推荐当日志达到某个固定的大小做一次snapshot。</p><p>做一次snapshot可能耗时过长，会影响正常日志同步。可以通过使用copy-on-write技术避免snapshot过程影响正常日志同步。</p><h3 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h3><p>成员变更是在集群运行过程中副本发生变化，如增加&#x2F;减少副本数、节点替换等。</p><p>成员变更也是一个分布式一致性问题，既所有服务器对新成员达成一致。但是成员变更又有其特殊性，因为在成员变更的一致性达成的过程中，参与投票的进程会发生变化。</p><p>如果将成员变更当成一般的一致性问题，直接向Leader发送成员变更请求，Leader复制成员变更日志，达成多数派之后提交，各服务器提交成员变更日志后从旧成员配置(Cold)切换到新成员配置(Cnew)。</p><p>因为各个服务器提交成员变更日志的时刻可能不同，造成各个服务器从旧成员配置(Cold)切换到新成员配置(Cnew)的时刻不同。</p><p>成员变更不能影响服务的可用性，但是成员变更过程的某一时刻，可能出现在Cold和Cnew中同时存在两个不相交的多数派，进而可能选出两个Leader，形成不同的决议，破坏安全性。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280253188.jpg" alt="img"></p><p>由于成员变更的这一特殊性，成员变更不能当成一般的一致性问题去解决。</p><p>为了解决这一问题，Raft提出了两阶段的成员变更方法。集群先从旧成员配置Cold切换到一个过渡成员配置，称为共同一致(joint consensus)，共同一致是旧成员配置Cold和新成员配置Cnew的组合Cold U Cnew，一旦共同一致Cold U Cnew被提交，系统再切换到新成员配置Cnew。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280253881.jpg" alt="img"></p><p>Raft两阶段成员变更过程如下:</p><ul><li>Leader收到成员变更请求从Cold切成Cnew；</li><li>eader在本地生成一个新的log entry，其内容是Cold∪Cnew，代表当前时刻新旧成员配置共存，写入本地日志，同时将该log entry复制至Cold∪Cnew中的所有副本。在此之后新的日志同步需要保证得到Cold和Cnew两个多数派的确认；</li><li>Follower收到Cold∪Cnew的log entry后更新本地日志，并且此时就以该配置作为自己的成员配置；</li><li>如果Cold和Cnew中的两个多数派确认了Cold U Cnew这条日志，Leader就提交这条log entry；</li><li>接下来Leader生成一条新的log entry，其内容是新成员配置Cnew，同样将该log entry写入本地日志，同时复制到Follower上；</li><li>Follower收到新成员配置Cnew后，将其写入日志，并且从此刻起，就以该配置作为自己的成员配置，并且如果发现自己不在Cnew这个成员配置中会自动退出；</li><li>Leader收到Cnew的多数派确认后，表示成员变更成功，后续的日志只要得到Cnew多数派确认即可。Leader给客户端回复成员变更执行成功。</li></ul><p>异常分析:</p><ul><li>如果Leader的Cold U Cnew尚未推送到Follower，Leader就挂了，此后选出的新Leader并不包含这条日志，此时新Leader依然使用Cold作为自己的成员配置。</li><li>如果Leader的Cold U Cnew推送到大部分的Follower后就挂了，此后选出的新Leader可能是Cold也可能是Cnew中的某个Follower。</li><li>如果Leader在推送Cnew配置的过程中挂了，那么同样，新选出来的Leader可能是Cold也可能是Cnew中的某一个，此后客户端继续执行一次改变配置的命令即可。</li><li>如果大多数的Follower确认了Cnew这个消息后，那么接下来即使Leader挂了，新选出来的Leader肯定位于Cnew中。</li><li>两阶段成员变更比较通用且容易理解，但是实现比较复杂，同时两阶段的变更协议也会在一定程度上影响变更过程中的服务可用性，因此我们期望增强成员变更的限制，以简化操作流程。</li></ul><p>两阶段成员变更，之所以分为两个阶段，是因为对Cold与Cnew的关系没有做任何假设，为了避免Cold和Cnew各自形成不相交的多数派选出两个Leader，才引入了两阶段方案。</p><p>如果增强成员变更的限制，假设Cold与Cnew任意的多数派交集不为空，这两个成员配置就无法各自形成多数派，那么成员变更方案就可能简化为一阶段。</p><p>那么如何限制Cold与Cnew，使之任意的多数派交集不为空呢? 方法就是每次成员变更只允许增加或删除一个成员。</p><p>可从数学上严格证明，只要每次只允许增加或删除一个成员，Cold与Cnew不可能形成两个不相交的多数派。</p><p>一阶段成员变更:</p><ul><li>成员变更限制每次只能增加或删除一个成员(如果要变更多个成员，连续变更多次)。</li><li>成员变更由Leader发起，Cnew得到多数派确认后，返回客户端成员变更成功。</li><li>一次成员变更成功前不允许开始下一次成员变更，因此新任Leader在开始提供服务前要将自己本地保存的最新成员配置重新投票形成多数派确认。</li><li>Leader只要开始同步新成员配置，即可开始使用新的成员配置进行日志同步。</li></ul><h2 id="Raft与Multi-Paxos对比"><a href="#Raft与Multi-Paxos对比" class="headerlink" title="Raft与Multi-Paxos对比"></a>Raft与Multi-Paxos对比</h2><p>Raft与Multi-Paxos都是基于领导者的一致性算法，乍一看有很多地方相同，下面总结一下Raft与Multi-Paxos的异同。</p><p>Raft与Multi-Paxos中相似的概念:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280253267.jpg" alt="img"></p><p>Raft与Multi-Paxos的不同:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280254999.jpg" alt="img"></p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/32052223">Raft算法详解</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Paxos是出了名的难懂，而Raft正是为了探索一种更易于理解的一致性算法而产生的。它的首要设计目的就是易于理解，所以在选主的冲突处理等方式上它都选择了非常简单明了的解决方案。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;推荐阅读&quot;&gt;&lt;a </summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    <category term="Raft算法" scheme="https://hubertwongcn.github.io/tags/Raft%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>19.分布式算法 - Paxos算法</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/19-fen-bu-shi-suan-fa-paxos-suan-fa/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/19-fen-bu-shi-suan-fa-paxos-suan-fa/</id>
    <published>2023-12-27T18:45:58.000Z</published>
    <updated>2023-12-27T18:45:58.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性, 很多分布式一致性算法都由Paxos演变而来。</p></blockquote><h2 id="Paxos算法简介"><a href="#Paxos算法简介" class="headerlink" title="Paxos算法简介"></a>Paxos算法简介</h2><p>Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。</p><p>Paxos由Lamport于1998年在《The Part-Time Parliament》论文中首次公开，最初的描述使用希腊的一个小岛Paxos作为比喻，描述了Paxos小岛中通过决议的流程，并以此命名这个算法，但是这个描述理解起来比较有挑战性。后来在2001年，Lamport觉得同行不能理解他的幽默感，于是重新发表了朴实的算法描述版本《Paxos Made Simple》。</p><p>自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性。Google的很多大型分布式系统都采用了Paxos算法来解决分布式一致性问题，如Chubby、Megastore以及Spanner等。开源的ZooKeeper，以及MySQL 5.7推出的用来取代传统的主从复制的MySQL Group Replication等纷纷采用Paxos算法解决分布式一致性问题。</p><h2 id="Basic-Paxos算法实现"><a href="#Basic-Paxos算法实现" class="headerlink" title="Basic Paxos算法实现"></a>Basic Paxos算法实现</h2><p>Paxos算法解决的问题正是分布式一致性问题，即一个分布式系统中的各个进程如何就某个值(决议)达成一致。</p><p>Paxos算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。它利用大多数 (Majority) 机制保证了2F+1的容错能力，即2F+1个节点的系统最多允许F个节点同时出现故障。</p><p>一个或多个提议进程 (Proposer) 可以发起提案 (Proposal)，Paxos算法使所有提案中的某一个提案，在所有进程中达成一致。系统中的多数派同时认可该提案，即达成了一致。最多只针对一个确定的提案达成一致。</p><h3 id="角色"><a href="#角色" class="headerlink" title="角色"></a>角色</h3><p>Paxos将系统中的角色分为<code>提议者 (Proposer)</code>，<code>决策者 (Acceptor)</code>，和<code>最终决策学习者 (Learner)</code>:</p><ul><li><code>Proposer</code>: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。</li><li><code>Acceptor</code>: 参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。</li><li><code>Learner</code>: 不参与决策，从Proposers&#x2F;Acceptors学习最新达成一致的提案(Value)。</li></ul><p>在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280247242.jpg" alt="img"></p><blockquote><p>可以理解为人大代表(Proposer)在人大向其它代表(Acceptors)提案，通过后让老百姓(Learner)落实。</p></blockquote><h3 id="3个阶段"><a href="#3个阶段" class="headerlink" title="3个阶段"></a>3个阶段</h3><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280247868.jpg" alt="img"></p><h4 id="第一阶段-Prepare阶段"><a href="#第一阶段-Prepare阶段" class="headerlink" title="第一阶段: Prepare阶段"></a>第一阶段: Prepare阶段</h4><p>Proposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。</p><ul><li><code>Prepare</code>: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。</li><li><code>Promise</code>: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。<ul><li>承诺1: 不再接受Proposal ID小于等于(注意: 这里是&lt;&#x3D; )当前请求的Prepare请求;</li><li>承诺2: 不再接受Proposal ID小于(注意: 这里是&lt; )当前请求的Propose请求;</li><li>应答: 不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。</li></ul></li></ul><h4 id="第二阶段-Accept阶段"><a href="#第二阶段-Accept阶段" class="headerlink" title="第二阶段: Accept阶段"></a>第二阶段: Accept阶段</h4><p>Proposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。</p><ul><li><code>Propose</code>: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。</li><li><code>Accept</code>: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。</li></ul><h4 id="第三阶段-Learn阶段"><a href="#第三阶段-Learn阶段" class="headerlink" title="第三阶段: Learn阶段"></a>第三阶段: Learn阶段</h4><p>Proposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。</p><h3 id="伪代码"><a href="#伪代码" class="headerlink" title="伪代码"></a>伪代码</h3><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280247887.jpg" alt="img"></p><ul><li>获取一个Proposal ID n，为了保证Proposal ID唯一，可采用时间戳+Server ID生成；</li><li>Proposer向所有Acceptors广播Prepare(n)请求；</li><li>Acceptor比较n和minProposal，如果n&gt;minProposal，minProposal&#x3D;n，并且将 acceptedProposal 和 acceptedValue 返回；</li><li>Proposer接收到过半数回复后，如果发现有acceptedValue返回，将所有回复中acceptedProposal最大的acceptedValue作为本次提案的value，否则可以任意决定本次提案的value；</li><li>到这里可以进入第二阶段，广播Accept (n,value) 到所有节点；</li><li>Acceptor比较n和minProposal，如果n&gt;&#x3D;minProposal，则acceptedProposal&#x3D;minProposal&#x3D;n，acceptedValue&#x3D;value，本地持久化后，返回；否则，返回minProposal。</li><li>提议者接收到过半数请求后，如果发现有返回值result &gt;n，表示有更新的提议，跳转到1；否则value达成一致。</li></ul><h3 id="实现举例"><a href="#实现举例" class="headerlink" title="实现举例"></a>实现举例</h3><p>下面举几个例子，实例1如下图:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280247130.jpg" alt="img"></p><p>图中P代表Prepare阶段，A代表Accept阶段。3.1代表Proposal ID为3.1，其中3为时间戳，1为Server ID。X和Y代表提议Value。</p><p>实例1中P 3.1达成多数派，其Value(X)被Accept，然后P 4.5学习到Value(X)，并Accept。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280248875.jpg" alt="img"></p><p>实例2中P 3.1没有被多数派Accept(只有S3 Accept)，但是被P 4.5学习到，P 4.5将自己的Value由Y替换为X，Accept(X)。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280248619.jpg" alt="img"></p><p>实例3中P 3.1没有被多数派Accept(只有S1 Accept)，同时也没有被P 4.5学习到。由于P 4.5 Propose的所有应答，均未返回Value，则P 4.5可以Accept自己的Value (Y)。后续P 3.1的Accept (X) 会失败，已经Accept的S1，会被覆盖。</p><p>Paxos算法可能形成活锁而永远不会结束，如下图实例所示:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280248328.jpg" alt="img"></p><p>回顾两个承诺之一，Acceptor不再应答Proposal ID小于等于当前请求的Prepare请求。意味着需要应答Proposal ID大于当前请求的Prepare请求。</p><p>两个Proposers交替Prepare成功，而Accept失败，形成活锁(Livelock)。</p><h2 id="Paxos算法推导"><a href="#Paxos算法推导" class="headerlink" title="Paxos算法推导"></a>Paxos算法推导</h2><blockquote><p>通常说Paxos算法是复杂算法难以理解是指其推导过程复杂。理论证明一个Paxos的实现，比实现这个Paxos还要难。一个成熟的Paxos实现很难独立产生，往往需要和一个系统结合在一起，通过一个或者多个系统来验证其可靠性和完备性。</p></blockquote><p><a href="https://blog.csdn.net/yeqiuzs/article/details/76862026">https://blog.csdn.net/yeqiuzs/article/details/76862026</a></p><h2 id="Paxos算法拓展"><a href="#Paxos算法拓展" class="headerlink" title="Paxos算法拓展"></a>Paxos算法拓展</h2><h3 id="Multi-Paxos算法"><a href="#Multi-Paxos算法" class="headerlink" title="Multi-Paxos算法"></a>Multi-Paxos算法</h3><p>原始的Paxos算法(Basic Paxos)只能对一个值形成决议，决议的形成至少需要两次网络来回，在高并发情况下可能需要更多的网络来回，极端情况下甚至可能形成活锁。如果想连续确定多个值，Basic Paxos搞不定了。因此Basic Paxos几乎只是用来做理论研究，并不直接应用在实际工程中。</p><p>实际应用中几乎都需要连续确定多个值，而且希望能有更高的效率。Multi-Paxos正是为解决此问题而提出。Multi-Paxos基于Basic Paxos做了两点改进:</p><ul><li>针对每一个要确定的值，运行一次Paxos算法实例(Instance)，形成决议。每一个Paxos实例使用唯一的Instance ID标识。</li><li>在所有Proposers中选举一个Leader，由Leader唯一地提交Proposal给Acceptors进行表决。这样没有Proposer竞争，解决了活锁问题。在系统中仅有一个Leader进行Value提交的情况下，Prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280249230.jpg" alt="img"></p><p>Multi-Paxos首先需要选举Leader，Leader的确定也是一次决议的形成，所以可执行一次Basic Paxos实例来选举出一个Leader。选出Leader之后只能由Leader提交Proposal，在Leader宕机之后服务临时不可用，需要重新选举Leader继续服务。在系统中仅有一个Leader进行Proposal提交的情况下，Prepare阶段可以跳过。</p><p>Multi-Paxos通过改变Prepare阶段的作用范围至后面Leader提交的所有实例，从而使得Leader的连续提交只需要执行一次Prepare阶段，后续只需要执行Accept阶段，将两阶段变为一阶段，提高了效率。为了区分连续提交的多个实例，每个实例使用一个Instance ID标识，Instance ID由Leader本地递增生成即可。</p><p>Multi-Paxos允许有多个自认为是Leader的节点并发提交Proposal而不影响其安全性，这样的场景即退化为Basic Paxos。</p><p>Chubby和Boxwood均使用Multi-Paxos。ZooKeeper使用的Zab也是Multi-Paxos的变形。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://zhuanlan.zhihu.com/p/31780743">https://zhuanlan.zhihu.com/p/31780743</a></li><li><a href="https://www.jdon.com/artichect/paxos.html">https://www.jdon.com/artichect/paxos.html</a></li><li><a href="https://blog.csdn.net/yeqiuzs/article/details/76862026">https://blog.csdn.net/yeqiuzs/article/details/76862026</a></li><li><a href="https://blog.csdn.net/qq_35440678/article/details/78080431">https://blog.csdn.net/qq_35440678/article/details/78080431</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性, 很多分布式一致性算法都由Paxos演变而来。&lt;/p&gt;</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    <category term="Paxos算法" scheme="https://hubertwongcn.github.io/tags/Paxos%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>18.分布式算法 - 一致性Hash算法</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/18-fen-bu-shi-suan-fa-yi-zhi-xing-hash-suan-fa/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/18-fen-bu-shi-suan-fa-yi-zhi-xing-hash-suan-fa/</id>
    <published>2023-12-27T18:41:04.000Z</published>
    <updated>2023-12-27T18:40:09.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>致性Hash算法是个经典算法，Hash环的引入是为解决<code>单调性(Monotonicity)</code>的问题；虚拟节点的引入是为了解决<code>平衡性(Balance)</code>问题。</p></blockquote><h2 id="一致性Hash算法引入"><a href="#一致性Hash算法引入" class="headerlink" title="一致性Hash算法引入"></a>一致性Hash算法引入</h2><p>在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。</p><h2 id="一致性Hash算法简介"><a href="#一致性Hash算法简介" class="headerlink" title="一致性Hash算法简介"></a>一致性Hash算法简介</h2><p>一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希(DHT)实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希(DHT)可以在P2P环境中真正得到应用。</p><p>一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义:</p><ul><li><code>平衡性(Balance)</code>: 平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。</li><li><code>单调性(Monotonicity)</code>: 单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。</li><li><code>分散性(Spread)</code>: 在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。</li><li><code>负载(Load)</code>: 负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。</li></ul><h2 id="一致性Hash算法"><a href="#一致性Hash算法" class="headerlink" title="一致性Hash算法"></a>一致性Hash算法</h2><h3 id="Hash环"><a href="#Hash环" class="headerlink" title="Hash环"></a>Hash环</h3><p>使用常见的hash算法可以把一个key值哈希到一个具有2^32个桶的空间中。也可以理解成，将key值哈希到 [0, 2^32) 的一个数字空间中。 我们假设这个是个首尾连接的环形空间。如下图:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280242495.jpg" alt="img"></p><p>假设我们现在有key1,key2,key3,key4 4个key值，我们通过一定的hash算法，将其对应到上面的环形hash空间中。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">k1=<span class="built_in">hash</span>(key1);</span><br><span class="line">k2=<span class="built_in">hash</span>(key2);</span><br><span class="line">k3=<span class="built_in">hash</span>(key3);</span><br><span class="line">k4=<span class="built_in">hash</span>(key4);</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280242811.jpg" alt="img"></p><p>同样的，假设我们有3台cache服务器，把缓存服务器通过hash算法，加入到上述的环中。一般情况下是根据机器的IP地址或者唯一的计算机别名进行哈希。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">c1=<span class="built_in">hash</span>(cache1);</span><br><span class="line">c2=<span class="built_in">hash</span>(cache2);</span><br><span class="line">c3=<span class="built_in">hash</span>(cache3);</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280243915.jpg" alt="img"></p><p>接下来就是数据如何存储到cache服务器上了，key值哈希之后的结果顺时针找上述环形hash空间中，距离自己最近的机器节点，然后将数据存储到上面， 如上图所示，k1 存储到 c3 服务器上， k4,k3存储到c1服务器上， k2存储在c2服务器上。用图表示如下:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280243922.jpg" alt="img"></p><h3 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h3><p>假设cache3服务器宕机，这时候需要从集群中将其摘除。那么，之前存储再c3上的k1，将会顺时针寻找距离它最近的一个节点，也就是c1节点，这样，k1就会存储到c1上了，看一看下下面的图，比较清晰。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280243051.jpg" alt="img"></p><p>摘除c3节点之后，只影响到了原先存储再c3上的k1，而k3、k4、k2都没有受到影响，也就意味着解决了最开始的解决方案(hash(key)%N)中可能带来的雪崩问题。</p><h3 id="增加节点"><a href="#增加节点" class="headerlink" title="增加节点"></a>增加节点</h3><p>新增C4节点之后，原先存储到C1的k4，迁移到了C4，分担了C1上的存储压力和流量压力。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280244258.jpg" alt="img"></p><h3 id="不平衡的问题"><a href="#不平衡的问题" class="headerlink" title="不平衡的问题"></a>不平衡的问题</h3><p>上面的简单的一致性hash的方案在某些情况下但依旧存在问题: 一个节点宕机之后，数据需要落到距离他最近的节点上，会导致下个节点的压力突然增大，可能导致雪崩，整个服务挂掉。</p><p>如下图所示:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280244758.jpg" alt="img"></p><p>当节点C3摘除之后，之前再C3上的k1就要迁移到C1上，这时候带来了两部分的压力:</p><ul><li>之前请求到C3上的流量转嫁到了C1上,会导致C1的流量增加，如果之前C3上存在热点数据，则可能导致C1扛不住压力挂掉。</li><li>之前存储到C3上的key值转义到了C1，会导致C1的内容占用量增加，可能存在瓶颈。</li></ul><p>当上面两个压力发生的时候，可能导致C1节点也宕机了。那么压力便会传递到C2上，又出现了类似滚雪球的情况，服务压力出现了雪崩，导致整个服务不可用。这一点违背了最开始提到的四个原则中的 <code>平衡性</code>， 节点宕机之后，流量及内存的分配方式打破了原有的平衡。</p><h3 id="虚拟节点"><a href="#虚拟节点" class="headerlink" title="虚拟节点"></a>虚拟节点</h3><p>“虚拟节点”( virtual node )是实际节点(机器)在 hash 空间的复制品( replica )，一实际个节点(机器)对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。</p><p>依旧用图片来解释，假设存在以下的真实节点和虚拟节点的对应关系。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Visual100—&gt; Real1</span><br><span class="line">Visual101—&gt; Real1</span><br><span class="line">Visual200—&gt; Real2</span><br><span class="line">Visual201—&gt; Real2</span><br><span class="line">Visual300—&gt; Real3</span><br><span class="line">Visual301—&gt; Real3</span><br></pre></td></tr></table></figure><p>同样的，hash之后的结果如下:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">hash</span>(Visual100)—&gt; V100  —&gt; Real1</span><br><span class="line"><span class="built_in">hash</span>(Visual101)—&gt; V101  —&gt; Real1</span><br><span class="line"><span class="built_in">hash</span>(Visual200)—&gt; V200  —&gt; Real2</span><br><span class="line"><span class="built_in">hash</span>(Visual201)—&gt; V201  —&gt; Real2</span><br><span class="line"><span class="built_in">hash</span>(Visual300)—&gt; V300  —&gt; Real3</span><br><span class="line"><span class="built_in">hash</span>(Visual301)—&gt; V301  —&gt; Real3</span><br></pre></td></tr></table></figure><p>key值的hash结果如上，这里暂时不写了。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280245415.jpg" alt="img"></p><p>和之前介绍的不添加虚拟节点的类似，主要聊下如果宕机之后的情况。</p><p>假设Real1机器宕机，则会发生一下情况。</p><ul><li>原先存储在虚拟节点V100上的k1数据将迁移到V301上，也就意味着迁移到了Real3机器上。</li><li>原先存储再虚拟节点V101上的k4数据将迁移到V200上，也就意味着迁移到了Real2机器上。</li></ul><p>结果如下图:</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280245962.png" alt="img"></p><p>这个就解决之前的问题了，某个节点宕机之后，存储及流量压力并没有全部转移到某台机器上，而是分散到了多台节点上。解决了节点宕机可能存在的雪崩问题。</p><p>当物理节点多的时候，虚拟节点多，这个的雪崩可能就越小。</p><h2 id="一致性Hash的应用"><a href="#一致性Hash的应用" class="headerlink" title="一致性Hash的应用"></a>一致性Hash的应用</h2><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://blog.csdn.net/cywosp/article/details/23397179/">https://blog.csdn.net/cywosp/article/details/23397179/</a></li><li><a href="https://blog.csdn.net/losetowin/article/details/53743135">https://blog.csdn.net/losetowin/article/details/53743135</a></li><li><a href="https://blog.csdn.net/qq1076472549/article/details/81939328">https://blog.csdn.net/qq1076472549/article/details/81939328</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;致性Hash算法是个经典算法，Hash环的引入是为解决&lt;code&gt;单调性(Monotonicity)&lt;/code&gt;的问题；虚拟节点的引入是为了解决&lt;code&gt;平衡性(Balance)&lt;/code&gt;问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 </summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    <category term="一致性Hash算法" scheme="https://hubertwongcn.github.io/tags/%E4%B8%80%E8%87%B4%E6%80%A7Hash%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>17.分布式算法 - Overview</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/17-fen-bu-shi-suan-fa-overview/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/17-fen-bu-shi-suan-fa-overview/</id>
    <published>2023-12-27T18:40:09.000Z</published>
    <updated>2023-12-27T18:40:09.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文总结下常见的分布式算法，主要是分布式中的一致性算法。</p></blockquote><h2 id="常见的分布式算法"><a href="#常见的分布式算法" class="headerlink" title="常见的分布式算法"></a>常见的分布式算法</h2><ul><li><a href="/2023/12/28/18-fen-bu-shi-suan-fa-yi-zhi-xing-hash-suan-fa/" title="18.分布式算法 - 一致性Hash算法">分布式算法 - 一致性Hash算法</a><ul><li>一致性Hash算法是个经典算法，Hash环的引入是为解决<code>单调性(Monotonicity)</code>的问题；虚拟节点的引入是为了解决<code>平衡性(Balance)</code>问题</li></ul></li><li><a href="/2023/12/28/19-fen-bu-shi-suan-fa-paxos-suan-fa/" title="19.分布式算法 - Paxos算法">分布式算法 - Paxos算法</a><ul><li>Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性, 很多分布式一致性算法都由Paxos演变而来</li></ul></li><li><a href="/2023/12/28/20-fen-bu-shi-suan-fa-raft-suan-fa/" title="20.分布式算法 - Raft算法">分布式算法 - Raft算法</a><ul><li>Paxos是出了名的难懂，而Raft正是为了探索一种更易于理解的一致性算法而产生的。它的首要设计目的就是易于理解，所以在选主的冲突处理等方式上它都选择了非常简单明了的解决方案</li></ul></li><li><a href="/2023/12/28/21-fen-bu-shi-suan-fa-gossip-xie-yi-xiang-jie/" title="21.分布式算法-Gossip 协议详解">分布式算法-Gossip-协议详解</a><ul><li>Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员</li></ul></li><li><a href="/2023/12/28/22-fen-bu-shi-suan-fa-zab-suan-fa/" title="22.分布式算法 - ZAB算法">分布式算法 - ZAB算法</a><ul><li>ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）, 它应该是所有一致性协议中生产环境中应用最多的了。为什么呢？因为他是为 Zookeeper 设计的分布式一致性协议！</li></ul></li><li><a href="/2023/12/28/23-fen-bu-shi-suan-fa-snowflake-suan-fa/" title="23.分布式算法 - Snowflake算法">分布式算法 - Snowflake算法</a><ul><li>Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。为什么如此重要？因为它提供了一种ID生成及生成的思路，当然这种方案就是需要考虑时钟回拨的问题以及做一些 buffer的缓冲设计提高性能。</li></ul></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文总结下常见的分布式算法，主要是分布式中的一致性算法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;常见的分布式算法&quot;&gt;&lt;a href=&quot;#常见的分布式算法&quot; class=&quot;headerlink&quot; title=&quot;常见的分布式算法&quot;&gt;&lt;/a</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式算法" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"/>
    
  </entry>
  
  <entry>
    <title>16.大数据处理 - Map &amp; Reduce</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/16-da-shu-ju-chu-li-map-reduce/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/16-da-shu-ju-chu-li-map-reduce/</id>
    <published>2023-12-27T18:38:48.000Z</published>
    <updated>2023-12-27T18:38:48.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>MapReduce是一种计算模型, 本质上是<code>分治/hash_map/归并排序</code>这种方式在分布式下的延伸。</p></blockquote><h2 id="Map-Reduce简介"><a href="#Map-Reduce简介" class="headerlink" title="Map &amp; Reduce简介"></a>Map &amp; Reduce简介</h2><p>MapReduce是一种计算模型，简单的说就是将大批量的工作(数据)分解(MAP)执行，然后再将结果合并成最终结果(REDUCE)。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序。</p><ul><li><code>适用范围</code>: 数据量大，但是数据种类小可以放入内存</li><li><code>基本原理及要点</code>: 将数据交给不同的机器去处理，数据划分，结果归约。</li></ul><h2 id="相关题目"><a href="#相关题目" class="headerlink" title="相关题目"></a>相关题目</h2><ul><li>The canonical example application of MapReduce is a process to count the appearances of each different word in a set of documents:</li><li>海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。</li><li>一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)?</li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://blog.csdn.net/v_JULY_v/article/details/7382693">https://blog.csdn.net/v_JULY_v/article/details/7382693</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;MapReduce是一种计算模型, 本质上是&lt;code&gt;分治/hash_map/归并排序&lt;/code&gt;这种方式在分布式下的延伸。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Map-Reduce简介&quot;&gt;&lt;a href=&quot;#Map-Reduc</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    <category term="MapReduce" scheme="https://hubertwongcn.github.io/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>15.大数据处理 - 外（磁盘文件）排序</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/15-da-shu-ju-chu-li-wai-ci-pan-wen-jian-pai-xu/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/15-da-shu-ju-chu-li-wai-ci-pan-wen-jian-pai-xu/</id>
    <published>2023-12-27T18:34:56.000Z</published>
    <updated>2023-12-27T18:34:56.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>在编程珠玑中，描述了三种外部磁盘文件排序的解决方法，分别是</p><ul><li><strong>位图排序法</strong> - 在待排序文件中不含重复数的情况下，位图排序法是最高效的</li><li><strong>外排多路归并法</strong> - 在更一般的情况下，外排多路归并法具有通用性</li><li><strong>多通道排序法</strong> 所以本文主要介绍前两种。</li></ul></blockquote><h2 id="外排序介绍"><a href="#外排序介绍" class="headerlink" title="外排序介绍"></a>外排序介绍</h2><blockquote><p>外排序, 即借助外部存储进行排序.</p></blockquote><ul><li><code>适用范围</code>: 大数据的排序，去重</li><li><code>基本原理及要点</code>: 外排序的归并方法，置换选择败者树原理，最优归并树</li></ul><h2 id="相关问题引入和方案"><a href="#相关问题引入和方案" class="headerlink" title="相关问题引入和方案"></a>相关问题引入和方案</h2><p>问题描述如下：</p><ul><li><strong>输入</strong>：一个最多含有n个不重复的正整数（也就是说可能含有少于n个不重复正整数）的文件，其中每个数都小于等于n，且n&#x3D;10^7（1000万个）。</li><li><strong>输出</strong>：得到按从小到大升序排列的包含所有输入的整数的列表。</li><li><strong>条件</strong>：最多有大约1MB的内存空间可用，但磁盘空间足够。且要求运行时间在5分钟以下，10秒为最佳结果。</li></ul><p>在编程珠玑中，描述了三种解决方法，分别是</p><ul><li><strong>位图排序法</strong> - 在待排序文件中不含重复数的情况下，位图排序法是最高效的</li><li><strong>外排多路归并法</strong> - 在更一般的情况下，外排多路归并法具有通用性</li><li><strong>多通道排序法</strong></li></ul><p>所以本文主要介绍前两种。</p><h3 id="位图排序法"><a href="#位图排序法" class="headerlink" title="位图排序法"></a>位图排序法</h3><p>熟悉位图的朋友可能会想到用位图来表示这个文件集合。例如正如编程珠玑一书上所述，用一个20位长的字符串来表示一个所有元素都小于20的简单的非负整数集合，边框用如下字符串来表示集合<code>&#123;1,2,3,5,8,13&#125;</code>：<code>0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0</code>；上述集合中各数对应的位置则置1，没有对应的数的位置则置0。</p><blockquote><p>参考编程珠玑一书上的位图方案，针对我们的10^7个数据量的磁盘文件排序问题，我们可以这么考虑，由于每个7位十进制整数表示一个小于1000万的整数。我们可以使用一个具有1000万个位的字符串来表示这个文件，其中，当且仅当整数i在文件中存在时，第i位为1。采取这个位图的方案是因为我们面对的这个问题的特殊性：</p><ul><li>1、输入数据限制在相对较小的范围内</li><li>2、数据没有重复，</li><li>3、其中的每条记录都是单一的整数，没有任何其它与之关联的数据。</li></ul></blockquote><p>所以，此问题用位图的方案分为以下三步进行解决：</p><ul><li>第一步，将所有的位都置为0，从而将集合初始化为空。</li><li>第二步，通过读入文件中的每个整数来建立集合，将每个对应的位都置为1。</li><li>第三步，检验每一位，如果该位为1，就输出对应的整数。</li></ul><p>经过以上三步后，产生有序的输出文件。令n为位图向量中的位数（本例中为1000 0000），程序可以用伪代码表示如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">//磁盘文件排序位图方案的伪代码</span><br><span class="line">//copyright@ Jon Bentley</span><br><span class="line">//July、updated，2011.05.29。</span><br><span class="line"> </span><br><span class="line">//第一步，将所有的位都初始化为0</span><br><span class="line"><span class="keyword">for</span> i =&#123;0,....n&#125;    </span><br><span class="line">   bit[i]=0;</span><br><span class="line">//第二步，通过读入文件中的每个整数来建立集合，将每个对应的位都置为1。</span><br><span class="line"><span class="keyword">for</span> each i <span class="keyword">in</span> the input file   </span><br><span class="line">   bit[i]=1;</span><br><span class="line"> </span><br><span class="line">//第三步，检验每一位，如果该位为1，就输出对应的整数。</span><br><span class="line"><span class="keyword">for</span> i=&#123;0...n&#125;    </span><br><span class="line">  <span class="keyword">if</span> bit[i]==1      </span><br><span class="line">    write i on the output file</span><br></pre></td></tr></table></figure><p>上述的位图方案，共需要扫描输入数据两次，具体执行步骤如下：</p><ul><li>第一次，只处理1—4999999之间的数据，这些数都是小于5000000的，对这些数进行位图排序，只需要约5000000&#x2F;8&#x3D;625000Byte，也就是0.625M，排序后输出。</li><li>第二次，扫描输入文件时，只处理4999999-10000000的数据项，也只需要0.625M（可以使用第一次处理申请的内存）。</li></ul><p>因此，总共也只需要0.625M</p><blockquote><p>位图的的方法有必要强调一下，就是位图的适用范围为<strong>针对不重复的数据进行排序</strong>，若数据有重复，位图方案就不适用了。</p></blockquote><h3 id="多路归并排序"><a href="#多路归并排序" class="headerlink" title="多路归并排序"></a>多路归并排序</h3><blockquote><p>首先我们需要回顾下，什么是归并排序，请参考：<a href="/2023/12/27/8-pai-xu-gui-bing-pai-xu-merge-sort/" title="8.排序 - 归并排序(Merge Sort)">排序 - 归并排序(Merge Sort)</a></p></blockquote><p><strong>相对于多路归并排序，归并排序的本质是二路归并排序</strong>；我们已经知道，当数据量大到不适合在内存中排序时，可以利用多路归并算法对磁盘文件进行排序。</p><p>我们以一个包含很多个整数的大文件为例，来说明多路归并的外排序算法基本思想。假设文件中整数个数为N(N是亿级的)，整数之间用空格分开。首先分多次从该文件中读取M（十万级）个整数，每次将M个整数在内存中使用内部排序之后存入临时文件，这样就得到多个外部文件，对应于多个外部文件，我们可以利用多路归并将各个临时文件中的数据一边读入内存，一边进行归并输出到输出文件。显然，该排序算法需要对每个整数做2次磁盘读和2次磁盘写。（如果根据初始外部文件的个数设置归并的路数，则会对每个整数做多次读&#x2F;写，具体次数可参考严蔚敏书籍）</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280238365.png" alt="img"></p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280238956.png" alt="img"></p><p>我们来编程实现上述磁盘文件排序的问题，代码思路对应上面图由两部分构成：</p><ul><li><strong>内存排序</strong><ul><li>由于要求的可用内存为1MB，那么每次可以在内存中对250K的数据进行排序，然后将有序的数写入硬盘。</li><li>那么10M的数据需要循环40次，最终产生40个有序的文件。</li></ul></li><li><strong>归并排序</strong><ul><li>将每个文件最开始的数读入(由于有序，所以为该文件最小数)，存放在一个大小为40的first_data数组中；</li><li>选择first_data数组中最小的数min_data，及其对应的文件索引index；</li><li>将first_data数组中最小的数写入文件result，然后更新数组first_data(根据index读取该文件下一个数代替min_data)；</li><li>判断是否所有数据都读取完毕，否则返回2。</li></ul></li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><p>其中涉及的算法和具体的实现，请参看如下文章：</p><ul><li><a href="https://blog.csdn.net/v_JULY_v/article/details/7382693">https://blog.csdn.net/v_JULY_v/article/details/7382693</a></li><li><a href="https://www.cnblogs.com/harryshayne/archive/2011/07/02/2096196.html">https://www.cnblogs.com/harryshayne/archive/2011/07/02/2096196.html</a></li></ul><p>再次推荐下CSDN博主July，博客专注面试、算法、机器学习。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;在编程珠玑中，描述了三种外部磁盘文件排序的解决方法，分别是&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;位图排序法&lt;/strong&gt; - 在待排序文件中不含重复数的情况下，位图排序法是最高效的&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;外排多路归并法&lt;/st</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    <category term="外（磁盘文件）排序" scheme="https://hubertwongcn.github.io/tags/%E5%A4%96%EF%BC%88%E7%A3%81%E7%9B%98%E6%96%87%E4%BB%B6%EF%BC%89%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>4.MySQL - 索引(B+树)</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/4-mysql-suo-yin-b-shu/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/4-mysql-suo-yin-b-shu/</id>
    <published>2023-12-27T18:30:27.000Z</published>
    <updated>2023-12-27T18:30:27.000Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/xiaoxi/p/6894610.html">https://www.cnblogs.com/xiaoxi/p/6894610.html</a></p><h3 id="B-Tree-原理"><a href="#B-Tree-原理" class="headerlink" title="B+ Tree 原理"></a>B+ Tree 原理</h3><h4 id="1-数据结构"><a href="#1-数据结构" class="headerlink" title="1. 数据结构"></a>1. 数据结构</h4><p>B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。</p><p>B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。</p><p>在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280231811.png" alt="img"></p><h4 id="2-操作"><a href="#2-操作" class="headerlink" title="2. 操作"></a>2. 操作</h4><p>进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。</p><p>插入删除操作记录会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。</p><h4 id="3-与红黑树的比较"><a href="#3-与红黑树的比较" class="headerlink" title="3. 与红黑树的比较"></a>3. 与红黑树的比较</h4><p>红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因:</p><p>(一)更少的查找次数</p><p>平衡树查找操作的时间复杂度等于树高 h，而树高大致为 O(h)&#x3D;O(logdN)，其中 d 为每个节点的出度。</p><p>红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，检索的次数也就更多。</p><p>(二)利用计算机预读特性</p><p>为了减少磁盘 I&#x2F;O，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的旋转时间，因此速度会非常快。</p><p>操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I&#x2F;O 就能完全载入一个节点，并且可以利用预读特性，相邻的节点也能够被预先载入。</p><h3 id="MySQL-索引"><a href="#MySQL-索引" class="headerlink" title="MySQL 索引"></a>MySQL 索引</h3><p>索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。</p><h4 id="1-B-Tree-索引"><a href="#1-B-Tree-索引" class="headerlink" title="1. B+Tree 索引"></a>1. B+Tree 索引</h4><p>是大多数 MySQL 存储引擎的默认索引类型。</p><p>因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。除了用于查找，还可以用于排序和分组。</p><p>可以指定多个列作为索引列，多个索引列共同组成键。</p><p>适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。</p><p>InnoDB 的 B+Tree 索引分为主索引和辅助索引。</p><p>主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280232228.jpg" alt="img"></p><p>辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280232857.jpg" alt="img"></p><h4 id="2-哈希索引"><a href="#2-哈希索引" class="headerlink" title="2. 哈希索引"></a>2. 哈希索引</h4><p>哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制:</p><ul><li>无法用于排序与分组；</li><li>只支持精确查找，无法用于部分查找和范围查找。</li></ul><p>InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。</p><h4 id="3-全文索引"><a href="#3-全文索引" class="headerlink" title="3. 全文索引"></a>3. 全文索引</h4><p>MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。</p><p>全文索引一般使用倒排索引实现，它记录着关键词到其所在文档的映射。</p><p>InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。</p><h4 id="4-空间数据索引"><a href="#4-空间数据索引" class="headerlink" title="4. 空间数据索引"></a>4. 空间数据索引</h4><p>MyISAM 存储引擎支持空间数据索引(R-Tree)，可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。</p><p>必须使用 GIS 相关的函数来维护数据。</p><h3 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h3><h4 id="1-独立的列"><a href="#1-独立的列" class="headerlink" title="1. 独立的列"></a>1. 独立的列</h4><p>在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。</p><p>例如下面的查询不能使用 actor_id 列的索引:</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> actor_id <span class="keyword">FROM</span> sakila.actor <span class="keyword">WHERE</span> actor_id <span class="operator">+</span> <span class="number">1</span> <span class="operator">=</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure><h4 id="2-多列索引"><a href="#2-多列索引" class="headerlink" title="2. 多列索引"></a>2. 多列索引</h4><p>在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> film_id, actor_ id <span class="keyword">FROM</span> sakila.film_actor</span><br><span class="line"><span class="keyword">WHERE</span> actor_id <span class="operator">=</span> <span class="number">1</span> <span class="keyword">AND</span> film_id <span class="operator">=</span> <span class="number">1</span>;</span><br></pre></td></tr></table></figure><h4 id="3-索引列的顺序"><a href="#3-索引列的顺序" class="headerlink" title="3. 索引列的顺序"></a>3. 索引列的顺序</h4><p>让选择性最强的索引列放在前面，索引的选择性是指: 不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，查询效率也越高。</p><p>例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> staff_id)<span class="operator">/</span><span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> staff_id_selectivity,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="keyword">DISTINCT</span> customer_id)<span class="operator">/</span><span class="built_in">COUNT</span>(<span class="operator">*</span>) <span class="keyword">AS</span> customer_id_selectivity,</span><br><span class="line"><span class="built_in">COUNT</span>(<span class="operator">*</span>)</span><br><span class="line"><span class="keyword">FROM</span> payment;</span><br></pre></td></tr></table></figure><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">staff_id_selectivity: 0.0001</span><br><span class="line">customer_id_selectivity: 0.0373</span><br><span class="line">               COUNT(*): 16049</span><br></pre></td></tr></table></figure><h4 id="4-前缀索引"><a href="#4-前缀索引" class="headerlink" title="4. 前缀索引"></a>4. 前缀索引</h4><p>对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。</p><p>对于前缀长度的选取需要根据索引选择性来确定。</p><h4 id="5-覆盖索引"><a href="#5-覆盖索引" class="headerlink" title="5. 覆盖索引"></a>5. 覆盖索引</h4><p>索引包含所有需要查询的字段的值。</p><p>具有以下优点:</p><ul><li>索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。</li><li>一些存储引擎(例如 MyISAM)在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用(通常比较费时)。</li><li>对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。</li></ul><h3 id="索引的优点"><a href="#索引的优点" class="headerlink" title="索引的优点"></a>索引的优点</h3><ul><li>大大减少了服务器需要扫描的数据行数。</li><li>帮助服务器避免进行排序和分组，也就不需要创建临时表(B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表)。</li><li>将随机 I&#x2F;O 变为顺序 I&#x2F;O(B+Tree 索引是有序的，也就将相邻的数据都存储在一起)。</li></ul><h3 id="索引的使用场景"><a href="#索引的使用场景" class="headerlink" title="索引的使用场景"></a>索引的使用场景</h3><ul><li>对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。</li><li>对于中到大型的表，索引就非常有效。</li><li>但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://www.cnblogs.com/xiaoxi/p/6894610.html&quot;&gt;https://www.cnblogs.com/xiaoxi/p/6894610.html&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;B-Tree-原理&quot;&gt;&lt;a href=</summary>
      
    
    
    
    <category term="数据库" scheme="https://hubertwongcn.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MySQL" scheme="https://hubertwongcn.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL/"/>
    
    
    <category term="数据库" scheme="https://hubertwongcn.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    <category term="MySQL" scheme="https://hubertwongcn.github.io/tags/MySQL/"/>
    
    <category term="索引" scheme="https://hubertwongcn.github.io/tags/%E7%B4%A2%E5%BC%95/"/>
    
    <category term="B+树" scheme="https://hubertwongcn.github.io/tags/B-%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>14.大数据处理 - Trie树/数据库/倒排索引</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/14-da-shu-ju-chu-li-trie-shu-shu-ju-ku-dao-pai-suo-yin/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/14-da-shu-ju-chu-li-trie-shu-shu-ju-ku-dao-pai-suo-yin/</id>
    <published>2023-12-27T18:27:27.000Z</published>
    <updated>2023-12-27T18:27:27.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>大数据处理处理思想之 Trie树&#x2F;数据库&#x2F;倒排索引, 本文主要梳理下思路。</p></blockquote><h2 id="Trie树"><a href="#Trie树" class="headerlink" title="Trie树"></a>Trie树</h2><blockquote><p>Trie树的介绍和实现请参考 <a href="/2023/12/27/11-shu-qian-zhui-shu-trie-tree/" title="11.树 - 前缀树(Trie Tree)">树 - 前缀树(Trie)</a></p></blockquote><ul><li><code>适用范围</code>: 数据量大，重复多，但是数据种类小可以放入内存</li><li><code>基本原理及要点</code>: 实现方式，节点孩子的表示方式</li><li><code>扩展</code>: 压缩实现。</li></ul><p><strong>一些适用场景</strong>：</p><ul><li>寻找<strong>热门查询</strong>: 查询串的<strong>重复度比较高</strong>，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。</li><li>有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的<strong>query都可能重复</strong>。要你按照query的频度排序。</li><li>1000万字符串，其中有些是相同的(<strong>重复</strong>),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现?</li><li>一个文本文件，大约有一万行，每行一个词，要求统计出其中<strong>最频繁出现</strong>的前10个词。其解决方法是: 用trie树统计每个词出现的次数，时间复杂度是O(n*le)(le表示单词的平准长度)，然后是找出出现最频繁的前10个词。</li></ul><h2 id="数据库索引"><a href="#数据库索引" class="headerlink" title="数据库索引"></a>数据库索引</h2><blockquote><p>数据库索引相关，可以参看 <a href="/2023/12/28/4-mysql-suo-yin-b-shu/" title="4.MySQL - 索引(B+树)">MySQL - 索引(B+树)</a></p></blockquote><ul><li><code>适用范围</code>: 大数据量的增删改查</li><li><code>基本原理及要点</code>: 利用数据的设计实现方法，对海量数据的增删改查进行处理。</li></ul><h2 id="倒排索引-Inverted-index"><a href="#倒排索引-Inverted-index" class="headerlink" title="倒排索引(Inverted index)"></a>倒排索引(Inverted index)</h2><blockquote><p>倒排索引，可以参看 ElsaticSearch底层的实现。</p></blockquote><ul><li><code>适用范围</code>: 搜索引擎，关键字查询</li><li><code>基本原理及要点</code>: 为何叫倒排索引? 一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。</li></ul><p>以英文为例，下面是要被索引的文本:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">T0 = <span class="string">&quot;it is what it is&quot;</span></span><br><span class="line">T1 = <span class="string">&quot;what is it&quot;</span></span><br><span class="line">T2 = <span class="string">&quot;it is a banana&quot;</span></span><br><span class="line">// 我们就能得到下面的倒排索引: </span><br><span class="line"><span class="string">&quot;a&quot;</span>:      &#123;2&#125;</span><br><span class="line"><span class="string">&quot;banana&quot;</span>: &#123;2&#125;</span><br><span class="line"><span class="string">&quot;is&quot;</span>:     &#123;0, 1, 2&#125;</span><br><span class="line"><span class="string">&quot;it&quot;</span>:     &#123;0, 1, 2&#125;</span><br><span class="line"><span class="string">&quot;what&quot;</span>:   &#123;0, 1&#125;</span><br><span class="line">// 检索的条件<span class="string">&quot;what&quot;</span>,<span class="string">&quot;is&quot;</span>和<span class="string">&quot;it&quot;</span>将对应集合的交集。</span><br></pre></td></tr></table></figure><p>正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而<strong>倒排索引则是单词指向了包含它的文档，很容易看到这个反向的关系</strong>。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;大数据处理处理思想之 Trie树&amp;#x2F;数据库&amp;#x2F;倒排索引, 本文主要梳理下思路。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;Trie树&quot;&gt;&lt;a href=&quot;#Trie树&quot; class=&quot;headerlink&quot; title=&quot;</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    <category term="Trie树" scheme="https://hubertwongcn.github.io/tags/Trie%E6%A0%91/"/>
    
    <category term="数据库索引" scheme="https://hubertwongcn.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93%E7%B4%A2%E5%BC%95/"/>
    
    <category term="倒排索引" scheme="https://hubertwongcn.github.io/tags/%E5%80%92%E6%8E%92%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>13.大数据处理 - 双层桶划分</title>
    <link href="https://hubertwongcn.github.io/2023/12/28/13-da-shu-ju-chu-li-shuang-ceng-tong-hua-fen/"/>
    <id>https://hubertwongcn.github.io/2023/12/28/13-da-shu-ju-chu-li-shuang-ceng-tong-hua-fen/</id>
    <published>2023-12-27T18:25:49.000Z</published>
    <updated>2023-12-27T18:25:49.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍大数据处理之分桶处理。</p></blockquote><h2 id="分桶法简介"><a href="#分桶法简介" class="headerlink" title="分桶法简介"></a>分桶法简介</h2><p>其实本质上还是分而治之的思想，重在“分”的技巧上！</p><ul><li><code>适用范围</code>: 第k大，中位数，不重复或重复的数字</li><li><code>基本原理及要点</code>: 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。</li></ul><h2 id="相关题目"><a href="#相关题目" class="headerlink" title="相关题目"></a>相关题目</h2><h3 id="2-5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2-5亿个整数。"><a href="#2-5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2-5亿个整数。" class="headerlink" title="2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。"></a>2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。</h3><p>有点像鸽巢原理，整数个数为232,也就是，我们可以将这232个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。</p><h3 id="5亿个int找它们的中位数。"><a href="#5亿个int找它们的中位数。" class="headerlink" title="5亿个int找它们的中位数。"></a>5亿个int找它们的中位数。</h3><ul><li><strong>思路一</strong></li></ul><p>这个例子比上面那个更明显。首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。</p><p>实际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成224个区域，然后确定区域的第几大数，在将该区域分成220个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有2^20，就可以直接利用direct addr table进行统计了。</p><ul><li><strong>思路二</strong></li></ul><p>同样需要做两遍统计，如果数据存在硬盘上，就需要读取2次。</p><p>方法同基数排序有些像，开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况，也就是0-65535，都算作0,65536 - 131071都算作1。就相当于用该数除以65536。Int32 除以 65536的结果不会超过65536种情况，因此开一个长度为65536的数组计数就可以。每读取一个数，数组中对应的计数+1，考虑有负数的情况，需要将结果加32768后，记录在相应的数组内。</p><p>第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间，比如处于区间k，那么0- k-1的区间里数字的数量sum应该<code>&lt;n/2</code>(2.5亿)。而k+1 - 65535的计数和也<code>&lt;n/2</code>，第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，也就是说(x &#x2F; 65536) + 32768 &#x3D; k。统计只统计低16位的情况。并且利用刚才统计的sum，比如sum &#x3D; 2.49亿，那么现在就是要在低16位里面找100万个数(2.5亿-2.49亿)。这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文主要介绍大数据处理之分桶处理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;分桶法简介&quot;&gt;&lt;a href=&quot;#分桶法简介&quot; class=&quot;headerlink&quot; title=&quot;分桶法简介&quot;&gt;&lt;/a&gt;分桶法简介&lt;/h2&gt;&lt;p&gt;其实本质上还</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    <category term="双层桶划分" scheme="https://hubertwongcn.github.io/tags/%E5%8F%8C%E5%B1%82%E6%A1%B6%E5%88%92%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>12.大数据处理 - Bitmap &amp; Bloom Filter</title>
    <link href="https://hubertwongcn.github.io/2023/12/27/12-da-shu-ju-chu-li-bitmap-bloom-filter/"/>
    <id>https://hubertwongcn.github.io/2023/12/27/12-da-shu-ju-chu-li-bitmap-bloom-filter/</id>
    <published>2023-12-27T15:23:06.000Z</published>
    <updated>2023-12-27T15:23:06.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于这个集合的元素误认为不属于这个集合(False Negative)。</p></blockquote><h2 id="布隆过滤器由来"><a href="#布隆过滤器由来" class="headerlink" title="布隆过滤器由来"></a>布隆过滤器由来</h2><p>布隆在1970年提出了布隆过滤器(Bloom Filter)，是一个很长的二进制向量(可以想象成一个序列)和一系列随机映射函数(hash function)。可用于判断一个元素是否在一个集合中，查询效率很高(1-N，最优能逼近于1)。通常应用在一些需要快速判断某个元素是否属于集合，但是并不严格要求100%正确的场合。</p><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ul><li><code>优点</code>: 占用空间小，查询快</li><li><code>缺点</code>: 有误判，删除困难</li></ul><h3 id="几个专业术语"><a href="#几个专业术语" class="headerlink" title="几个专业术语"></a>几个专业术语</h3><p>这里有必要介绍一下<code>False Positive</code>和<code>False Negative</code>的概念:</p><ul><li><code>False Positive</code>: 中文可以理解为“假阳性”，在这里表示，有可能把不属于这个集合的元素误认为属于这个集合</li><li><code>False Negative</code>: 中文可以理解为“假阴性”，Bloom Filter是不存在false negatived的， 即不会把属于这个集合的元素误认为不属于这个集合(False Negative)。</li></ul><h2 id="布隆过滤器应用场景"><a href="#布隆过滤器应用场景" class="headerlink" title="布隆过滤器应用场景"></a>布隆过滤器应用场景</h2><ul><li><code>网页爬虫对URL的去重</code>: 避免爬取相同的URL地址；</li><li><code>反垃圾邮件</code>: 假设邮件服务器通过发送方的邮件域或者IP地址对垃圾邮件进行过滤，那么就需要判断当前的邮件域或者IP地址是否处于黑名单之中。如果邮件服务器的通信邮件数量非常大(也可以认为数据量级上亿)，那么也可以使用Bloom Filter算法；</li><li><code>缓存击穿</code>: 将已存在的缓存放到布隆中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉；</li><li><code>HTTP缓存服务器</code>: 当本地局域网中的PC发起一条HTTP请求时，缓存服务器会先查看一下这个URL是否已经存在于缓存之中，如果存在的话就没有必要去原始的服务器拉取数据了(为了简单起见，我们假设数据没有发生变化)，这样既能节省流量，还能加快访问速度，以提高用户体验。</li><li><code>黑/白名单</code>: 类似反垃圾邮件。</li><li><code>Bigtable</code>: Google 著名的分布式数据库 Bigtable 使用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的IO次数。</li><li><code>Squid</code>: 网页代理缓存服务器在 cachedigests 中使用了也布隆过滤器。</li><li><code>Venti 文档存储系统</code>: 也采用布隆过滤器来检测先前存储的数据。</li><li><code>SPIN 模型检测器</code>: 也使用布隆过滤器在大规模验证问题时跟踪可达状态空间。</li><li><code>Chrome加速安全浏览</code>: Google Chrome浏览器使用了布隆过滤器加速安全浏览服务。</li><li><code>Key-Value系统</code>: 在很多Key-Value系统中也使用了布隆过滤器来加快查询过程，如 Hbase，Accumulo，Leveldb，一般而言，Value 保存在磁盘中，访问磁盘需要花费大量时间，然而使用布隆过滤器可以快速判断某个Key对应的Value是否存在，因此可以避免很多不必要的磁盘IO操作，只是引入布隆过滤器会带来一定的内存消耗。</li><li><code>HTTP Proxy-Cache</code>: 在Internet Cache Protocol中的Proxy-Cache很多都是使用Bloom Filter存储URLs，除了高效的查询外，还能很方便得传输交换Cache信息。</li><li><code>网络应用</code>: P2P网络中查找资源操作，可以对每条网络通路保存Bloom Filter，当命中时，则选择该通路访问。广播消息时，可以检测某个IP是否已发包。检测广播消息包的环路，将Bloom Filter保存在包里，每个节点将自己添加入Bloom Filter。信息队列管理，使用Counter Bloom Filter管理信息流量。</li></ul><h2 id="布隆过滤器实现"><a href="#布隆过滤器实现" class="headerlink" title="布隆过滤器实现"></a>布隆过滤器实现</h2><p>Bloom Filter在很多开源框架都有实现，例如:</p><ul><li><code>Elasticsearch</code>: org.elasticsearch.common.util.BloomFilter</li><li><code>guava</code>: com.google.common.hash.BloomFilter</li><li><code>Hadoop</code>: org.apache.hadoop.util.bloom.BloomFilter(基于BitSet实现)</li></ul><h3 id="以BitSet-实现方式为例"><a href="#以BitSet-实现方式为例" class="headerlink" title="以BitSet 实现方式为例"></a>以BitSet 实现方式为例</h3><p>创建一个m位BitSet，先将所有位初始化为0，然后选择k个不同的哈希函数。第i个哈希函数对字符串str哈希的结果记为h(i，str)，且h(i，str)的范围是0到m-1 。</p><ul><li>加入字符串过程</li></ul><p>下面是每个字符串处理的过程，首先是将字符串str“记录”到BitSet中的过程: 对于字符串str，分别计算h(1，str)，h(2，str)…… h(k，str)。然后将BitSet的第h(1，str)、h(2，str)…… h(k，str)位设为1。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272324967.jpeg" alt="img"></p><p>这样就将字符串str映射到BitSet中的k个二进制位了。</p><ul><li>检查字符串是否存在的过程</li></ul><p>下面是检查字符串str是否被BitSet记录过的过程: 对于字符串str，分别计算h(1，str)，h(2，str)…… h(k，str)。然后检查BitSet的第h(1，str)、h(2，str)…… h(k，str)位是否为1，若其中任何一位不为1则可以判定str一定没有被记录过。若全部位都是1，则“认为”字符串str存在。 若一个字符串对应的Bit不全为1，则可以肯定该字符串一定没有被Bloom Filter记录过。(这是显然的，因为字符串被记录过，其对应的二进制位肯定全部被设为1了)</p><h3 id="以BitSet-实现代码"><a href="#以BitSet-实现代码" class="headerlink" title="以BitSet 实现代码"></a>以BitSet 实现代码</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> algorithm;</span><br><span class="line"><span class="keyword">import</span> java.util.BitSet;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">BloomFilter</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">/* BitSet初始分配2^24个bit */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span> <span class="variable">DEFAULT_SIZE</span> <span class="operator">=</span> <span class="number">1</span> &lt;&lt; <span class="number">25</span>;</span><br><span class="line">    <span class="comment">/* 不同哈希函数的种子，一般应取质数 */</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">int</span>[] seeds = <span class="keyword">new</span> <span class="title class_">int</span>[]&#123; <span class="number">5</span>, <span class="number">7</span>, <span class="number">11</span>, <span class="number">13</span>, <span class="number">31</span>, <span class="number">37</span>, <span class="number">61</span> &#125;;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">BitSet</span> <span class="variable">bits</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BitSet</span>(DEFAULT_SIZE);</span><br><span class="line">    <span class="comment">/* 哈希函数对象 */</span></span><br><span class="line">    <span class="keyword">private</span> SimpleHash[] func = <span class="keyword">new</span> <span class="title class_">SimpleHash</span>[seeds.length];</span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">BloomFilter</span><span class="params">()</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; seeds.length; i++)</span><br><span class="line">        &#123;</span><br><span class="line">            func[i] = <span class="keyword">new</span> <span class="title class_">SimpleHash</span>(DEFAULT_SIZE, seeds[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 将字符串标记到bits中</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">add</span><span class="params">(String value)</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">for</span> (SimpleHash f : func)</span><br><span class="line">        &#123;</span><br><span class="line">            bits.set(f.hash(value), <span class="literal">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">// 判断字符串是否已经被bits标记</span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">contains</span><span class="params">(String value)</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (value == <span class="literal">null</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="type">boolean</span> <span class="variable">ret</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">for</span> (SimpleHash f : func)</span><br><span class="line">        &#123;</span><br><span class="line">            ret = ret &amp;&amp; bits.get(f.hash(value));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> ret;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    <span class="comment">/* 哈希函数类 */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">SimpleHash</span></span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">int</span> cap;</span><br><span class="line">        <span class="keyword">private</span> <span class="type">int</span> seed;</span><br><span class="line"> </span><br><span class="line">        <span class="keyword">public</span> <span class="title function_">SimpleHash</span><span class="params">(<span class="type">int</span> cap, <span class="type">int</span> seed)</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="built_in">this</span>.cap = cap;</span><br><span class="line">            <span class="built_in">this</span>.seed = seed;</span><br><span class="line">        &#125;</span><br><span class="line"> </span><br><span class="line">        <span class="comment">// hash函数，采用简单的加权和hash</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hash</span><span class="params">(String value)</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">            <span class="type">int</span> <span class="variable">len</span> <span class="operator">=</span> value.length();</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; len; i++)</span><br><span class="line">            &#123;</span><br><span class="line">                result = seed * result + value.charAt(i);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> (cap - <span class="number">1</span>) &amp; result;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="误报率-False-Positive-Rate"><a href="#误报率-False-Positive-Rate" class="headerlink" title="误报率 - False Positive Rate"></a>误报率 - False Positive Rate</h2><p>原文地址：<a href="https://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html">https://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html</a></p><h3 id="误报率的产生"><a href="#误报率的产生" class="headerlink" title="误报率的产生"></a>误报率的产生</h3><p>初始状态下，Bloom Filter是一个m位的位数组，且数组被0所填充。同时，我们需要定义k个不同的hash函数，每一个hash函数都随机的将每一个输入元素映射到位数组中的一个位上。那么对于一个确定的输入，我们会得到k个索引。</p><p>插入元素: 经过k个hash函数的映射，我们会得到k个索引，我们把位数组中这k个位置全部置1(不管其中的位之前是0还是1)</p><p>查询元素: 输入元素经过k个hash函数的映射会得到k个索引，如果位数组中这k个索引任意一处是0，那么就说明这个元素不在集合之中；如果元素处于集合之中，那么当插入元素的时候这k个位都是1。但如果这k个索引处的位都是1，被查询的元素就一定在集合之中吗? 答案是不一定，也就是说出现了False Positive的情况(但Bloom Filter不会出现False Negative的情况)</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272325826.png" alt="img"></p><p>在上图中，当插入x、y、z这三个元素之后，再来查询w，会发现w不在集合之中，而如果w经过三个hash函数计算得出的结果所得索引处的位全是1，那么Bloom Filter就会告诉你，w在集合之中，实际上这里是误报，w并不在集合之中。</p><h3 id="误报率的计算"><a href="#误报率的计算" class="headerlink" title="误报率的计算"></a>误报率的计算</h3><p>Bloom Filter的误报率到底有多大? 下面在数学上进行一番推敲。假设HASH函数输出的索引值落在m位的数组上的每一位上都是等可能的。那么，对于一个给定的HASH函数，在进行某一个运算的时候，一个特定的位没有被设置为1的概率是<br>$$<br>1-\frac{1}{m}<br>$$</p><p>那么，对于所有的k个HASH函数，都没有把这个位设置为1的概率是<br>$$<br>(1-\frac{1}{m})^k<br>$$</p><p>如果我们已经插入了n个元素，那么对于一个给定的位，这个位仍然是0的概率是<br>$$<br>(1-\frac{1}{m})^{kn}<br>$$<br>那么，如果插入n个元素之后，这个位是1的概率是<br>$$<br>[1-(1-\frac{1}{m})^{kn}]^k<br>$$<br>如果对一个特定的元素存在误报，那么这个元素的经过HASH函数所得到的k个索引全部都是1，概率也就是<br>$$<br>[1-(1-\frac{1}{m})^{kn}]^k<br>$$<br>根据常数e的定义，可以近似的表示为:<br>$$<br>[1-(1+\frac{1}{(-m)})^{(-m)\frac{kn}{(-m)}}]^k\approx(1-e^{-\frac{kn}{m}})^k<br>$$</p><h3 id="减少误报率-最优的哈希函数个数"><a href="#减少误报率-最优的哈希函数个数" class="headerlink" title="减少误报率: 最优的哈希函数个数"></a>减少误报率: 最优的哈希函数个数</h3><p>既然Bloom Filter要靠多个哈希函数将集合映射到位数组中，那么应该选择几个哈希函数才能使元素查询时的错误率降到最低呢? 这里有两个互斥的理由: 如果哈希函数的个数多，那么在对一个不属于集合的元素进行查询时得到0的概率就大；但另一方面，如果哈希函数的个数少，那么位数组中的0就多。为了得到最优的哈希函数个数，我们需要根据上一小节中的错误率公式进行计算。</p><p>先用p和f进行计算。注意到$f&#x3D;e^{k\ln(1-e-\frac{kn}{m})}$ ，我们令$g&#x3D;k\ln(1-e-\frac{kn}{m})$，只要让g取到最小，f自然也取到最小。由于$p&#x3D;e-\frac{kn}{m}$，我们可以将g写成<br>$$<br>g&#x3D;-\frac{m}{n}\ln(p)\ln(1-p)<br>$$<br>根据对称性法则可以很容易看出当$p&#x3D;\frac{1}{2}$，也就是$k&#x3D;ln2\sqrt[m]{n}$时，g取得最小值。在这种情况下，最小错误率$f$等于$\frac{1}{2}k\approx0.6185^{\frac{m}{n}}$。另外，注意到$p$是位数组中某一位仍是0的概率，所以$p&#x3D;\frac{1}{2}$对应着位数组中0和1各一半。换句话说，要想保持错误率低，最好让位数组有一半还空着。</p><p>需要强调的一点是，$p&#x3D;\frac{1}{2}$时错误率最小这个结果并不依赖于近似值$p$和$f$。同样对于$f’&#x3D;e^{k\ln(1-(1-\frac{1}{m})kn)}$，$g’&#x3D;k\ln(1-(1-\frac{1}{m})kn)$，$p’&#x3D;(1-\frac{1}{m})kn$，我们可以将$g$’写成<br>$$<br>g’&#x3D;\frac{1}{n\ln(1-1&#x2F;m)}\ln(p’)\ln(1-p’)<br>$$</p><p>同样根据对称性法则可以得到当$p’&#x3D;\frac{1}{2}$时，$g’$取得最小值。</p><h3 id="减少误报率-位数组的大小"><a href="#减少误报率-位数组的大小" class="headerlink" title="减少误报率: 位数组的大小"></a>减少误报率: 位数组的大小</h3><p>在不超过一定错误率的情况下，Bloom Filter至少需要多少位才能表示全集中任意$n$个元素的集合? 假设全集中共有$u$个元素，允许的最大错误率为$\epsilon$，下面我们来求位数组的位数$m$。</p><p>假设$X$为全集中任取$n$个元素的集合，$F(X)$是表示$X$的位数组。那么对于集合$X$中任意一个元素$x$，在$s &#x3D; F(X)$中查询$x$都能得到肯定的结果，即$s$能够接受$x$。显然，由于Bloom Filter引入了错误，$s$能够接受的不仅仅是$X$中的元素，它还能够$\epsilon(u-n)$个false positive。因此，对于一个确定的位数组来说，它能够接受总共$n+ \epsilon(u-n)$个元素。在$n+ \epsilon(u-n)$个元素中，$s$真正表示的只有其中$n$个，所以一个确定的位数组可以表示<br>$$<br>\begin{pmatrix} n+\epsilon(u-n) \ n\ \end{pmatrix}<br>$$<br>个集合。$m$位的位数组共有$2^m$个不同的组合，进而可以推出，$m$位的位数组可以表示</p><p>$$<br>2^m\begin{pmatrix} n+\epsilon(u-n) \ n\ \end{pmatrix}<br>$$</p><p>个集合。全集中$n$个元素的集合总共有</p><p>$$<br>\begin{pmatrix} u \ n\ \end{pmatrix}<br>$$</p><p>个，因此要让$m$位的位数组能够表示所有$n$个元素的集合，必须有</p><p>$$<br>2^m\begin{pmatrix} n+\epsilon(u-n) \ n\ \end{pmatrix}\geq\begin{pmatrix} u \ n\ \end{pmatrix}<br>$$</p><p>即:</p><p>$$<br>m\geq\log_2 \frac{\begin{pmatrix} u \ n\ \end{pmatrix}}{\begin{pmatrix} n+\epsilon(u-n) \ n\ \end{pmatrix}}\approx\log_2\frac{\begin{pmatrix} u \ n\ \end{pmatrix}}{\begin{pmatrix} eu \ n\ \end{pmatrix}}\geq\log_2\epsilon^{-n}&#x3D;n\log_2\frac{1}{\epsilon}<br>$$</p><p>上式中的近似前提是$n$和$\epsilon u$相比很小，这也是实际情况中常常发生的。根据上式，我们得出结论: 在错误率不大于$\epsilon$的情况下，$m$至少要等于$n\log_2\frac{1}{\epsilon}$才能表示任意$n$个元素的集合。</p><p>上一小节中我们曾算出当$k&#x3D;ln2\sqrt[m]{n}$时错误率$f$最小，这时$f&#x3D;\frac{k}{2}&#x3D;\frac{\frac{m\ln2}{n}}{2}&#x3D;\frac{m\ln2}{2n}$。现在令$f\leq\epsilon$，可以推出<br>$$<br>m\geq n\frac{\log_2(\frac{1}{\epsilon})}{\ln2}&#x3D;n\log_2e.\log_2(\frac{1}{\epsilon})<br>$$<br>这个结果比前面我们算得的下界$n\log_2(\frac{1}{\epsilon})$大了$\log_2e\approx1.44$倍。这说明在哈希函数的个数取到最优时，要让错误率不超过$\epsilon$，$m$至少需要取到最小值的1.44倍。</p><h2 id="拓展-Counting-Bloom-Filter"><a href="#拓展-Counting-Bloom-Filter" class="headerlink" title="拓展: Counting Bloom Filter"></a>拓展: Counting Bloom Filter</h2><p>从前面对Bloom Filter的介绍可以看出，标准的Bloom Filter是一种很简单的数据结构，它只支持插入和查找两种操作。在所要表达的集合是静态集合的时候，标准Bloom Filter可以很好地工作，但是如果要表达的集合经常变动，标准Bloom Filter的弊端就显现出来了，因为它不支持删除操作。</p><p>Counting Bloom Filter的出现解决了这个问题，它将标准Bloom Filter位数组的每一位扩展为一个小的计数器(Counter)，在插入元素时给对应的k(k为哈希函数个数)个Counter的值分别加1，删除元素时给对应的k个Counter的值分别减1。Counting Bloom Filter通过多占用几倍的存储空间的代价，给Bloom Filter增加了删除操作。下一个问题自然就是，到底要多占用几倍呢?</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312280144953.jpeg" alt="img"></p><p>我们先计算第i个Counter被增加$j$次的概率，其中$n$为集合元素个数，$k$为哈希函数个数，$m$为Counter个数(对应着原来位数组的大小):</p><p>$$<br>P(c(i)&#x3D;j)&#x3D;\begin{pmatrix} nk \ n\ \end{pmatrix}\left(\frac{1}{m}\right)^j\left(1-\frac{1}{m}\right)^{nk-j}<br>$$<br>上面等式右端的表达式中，前一部分表示从$nk$次哈希中选择$j$次，中间部分表示$j$次哈希都选中了第$i$个Counter，后一部分表示其它$nk – j$次哈希都没有选中第i个Counter。因此，第$i$个Counter的值大于$j$的概率可以限定为:</p><p>$$<br>P(c(i)\geq j)\leq\begin{pmatrix} nk \ j\ \end{pmatrix}\frac{1}{m^j}\leq\left(\frac{enk}{jm}\right)^j<br>$$<br>上式第二步缩放中应用了估计阶乘的斯特林公式:<br>$$<br>n!\approx\left(\frac{n}{e}\right)^n\sqrt{2\pi n}<br>$$<br>在Bloom Filter概念和原理一文中，我们提到过k的最优值为$\frac{m\ln2}{n}$，现在我们限制$k\leq\frac{m\ln2}{n}$，就可以得到如下结论:</p><p>$$<br>Pr(max(c)\geq i)\leq m\left(\frac{e\ln2}{i}\right)^i<br>$$<br>如果每个Counter分配4位，那么当Counter的值达到16时就会溢出。这个概率为:</p><p>$$<br>Pr(max(c)\geq16)\leq1.37\times10^{-15}\times m<br>$$</p><p>这个值足够小，因此对于大多数应用程序来说，4位就足够了。</p><h2 id="拓展-其它"><a href="#拓展-其它" class="headerlink" title="拓展: 其它"></a>拓展: 其它</h2><h3 id="Data-synchronization"><a href="#Data-synchronization" class="headerlink" title="Data synchronization"></a>Data synchronization</h3><p>Byers等人提出了使用布隆过滤器近似数据同步。</p><h3 id="Bloomier-filters"><a href="#Bloomier-filters" class="headerlink" title="Bloomier filters"></a>Bloomier filters</h3><p>Chazelle 等人提出了一个通用的布隆过滤器，该布隆过滤器可以将某一值与每个已经插入的元素关联起来，并实现了一个关联数组Map。与普通的布隆过滤器一样，Chazelle实现的布隆过滤器也可以达到较低的空间消耗，但同时也会产生false positive，不过，在Bloomier filter中，某 key 如果不在 map 中，falsepositive在会返回时会被定义出的。该Map 结构不会返回与 key 相关的在 map 中的错误的值。</p><h3 id="Compact-approximators"><a href="#Compact-approximators" class="headerlink" title="Compact approximators"></a>Compact approximators</h3><h3 id="Stable-Bloom-filters"><a href="#Stable-Bloom-filters" class="headerlink" title="Stable Bloom filters"></a>Stable Bloom filters</h3><h3 id="Scalable-Bloom-filters"><a href="#Scalable-Bloom-filters" class="headerlink" title="Scalable Bloom filters"></a>Scalable Bloom filters</h3><h3 id="Attenuated-Bloom-filters"><a href="#Attenuated-Bloom-filters" class="headerlink" title="Attenuated Bloom filters"></a>Attenuated Bloom filters</h3><h2 id="相关题目"><a href="#相关题目" class="headerlink" title="相关题目"></a>相关题目</h2><h3 id="给你A-B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A-B文件共同的URL。如果是三个乃至n个文件呢"><a href="#给你A-B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A-B文件共同的URL。如果是三个乃至n个文件呢" class="headerlink" title="给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢?"></a>给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢?</h3><p>根据这个问题我们来计算下内存的占用，4G&#x3D;2^32大概是40亿*8大概是340亿，n&#x3D;50亿，如果按出错率0.01算需要的大概是650亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。</p><h3 id="给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url"><a href="#给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url" class="headerlink" title="给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?"></a>给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?</h3><p>如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url(注意会有一定的错误率)。”</p><h3 id="在2-5亿个整数中找出不重复的整数，注，内存不足以容纳这2-5亿个整数。"><a href="#在2-5亿个整数中找出不重复的整数，注，内存不足以容纳这2-5亿个整数。" class="headerlink" title="在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。"></a>在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。</h3><p><code>方案1</code>: 采用2-Bitmap(每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义)进行，共需内存2^32 * 2 bit&#x3D;1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。</p><p><code>方案2</code>: 也可采用分治，划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。</p><h3 id="给40亿个不重复的unsigned-int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中"><a href="#给40亿个不重复的unsigned-int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中" class="headerlink" title="给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中?"></a>给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中?</h3><p>用位图&#x2F;Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://my.oschina.net/kiwivip/blog/133498">https://my.oschina.net/kiwivip/blog/133498</a></li><li><a href="https://blog.csdn.net/h348592532/article/details/45364147">https://blog.csdn.net/h348592532/article/details/45364147</a></li><li><a href="https://blog.csdn.net/h348592532/article/details/45362661">https://blog.csdn.net/h348592532/article/details/45362661</a></li><li><a href="https://blog.csdn.net/qianshangding0708/article/details/48030057">https://blog.csdn.net/qianshangding0708/article/details/48030057</a></li><li><a href="https://blog.csdn.net/xf_87/article/details/51073678">https://blog.csdn.net/xf_87/article/details/51073678</a></li><li><a href="https://blog.csdn.net/weixin_34082695/article/details/90331258">https://blog.csdn.net/weixin_34082695/article/details/90331258</a></li><li><a href="https://blog.csdn.net/v_JULY_v/article/details/7382693">https://blog.csdn.net/v_JULY_v/article/details/7382693</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    <category term="Bitmap" scheme="https://hubertwongcn.github.io/tags/Bitmap/"/>
    
    <category term="Bloom Filter" scheme="https://hubertwongcn.github.io/tags/Bloom-Filter/"/>
    
  </entry>
  
  <entry>
    <title>11.大数据处理 - 分治/hash/排序</title>
    <link href="https://hubertwongcn.github.io/2023/12/27/11-da-shu-ju-chu-li-fen-zhi-hash-pai-xu/"/>
    <id>https://hubertwongcn.github.io/2023/12/27/11-da-shu-ju-chu-li-fen-zhi-hash-pai-xu/</id>
    <published>2023-12-27T15:20:24.000Z</published>
    <updated>2023-12-27T15:20:24.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>大数据处理思路: 分而治之&#x2F;Hash映射 + Hash_map统计 + 堆&#x2F;快速&#x2F;归并排序。</p></blockquote><h2 id="思路简介"><a href="#思路简介" class="headerlink" title="思路简介"></a>思路简介</h2><blockquote><p>分而治之&#x2F;hash映射 + hash统计 + 堆&#x2F;快速&#x2F;归并排序，说白了，就是先映射，而后统计，最后排序:</p></blockquote><ul><li><code>分而治之/hash映射</code>: 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件，即16字方针: 大而化小，各个击破，缩小规模，逐个解决</li><li><code>hash_map统计</code>: 当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。</li><li><code>堆/快速排序</code>: 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP。</li></ul><h2 id="案例分析"><a href="#案例分析" class="headerlink" title="案例分析"></a>案例分析</h2><h3 id="海量日志数据，提取出某日访问百度次数最多的那个IP"><a href="#海量日志数据，提取出某日访问百度次数最多的那个IP" class="headerlink" title="海量日志数据，提取出某日访问百度次数最多的那个IP"></a>海量日志数据，提取出某日访问百度次数最多的那个IP</h3><p>分析: “首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如%1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP(可以采用hash_map对那1000个文件中的所有IP进行频率统计，然后依次找出各个文件中频率最大的那个IP)及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。”</p><p>关于本题，还有几个问题，如下:</p><ul><li>Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中的情况，即这里采用的是mod1000算法，那么相同的IP在hash取模后，只可能落在同一个文件中，不可能被分散的。因为如果两个IP相等，那么经过Hash(IP)之后的哈希值是相同的，将此哈希值取模(如模1000)，必定仍然相等。</li><li>那到底什么是hash映射呢? 简单来说，就是为了便于计算机在有限的内存中处理big数据，从而通过一种映射散列的方式让数据均匀分布在对应的内存位置(如大数据通过取余的方式映射成小树存放在内存中，或大文件映射成多个小文件)，而这个映射散列方式便是我们通常所说的hash函数，设计的好的hash函数能让数据均匀分布而减少冲突。尽管数据映射到了另外一些不同的位置，但数据还是原来的数据，只是代替和表示这些原始数据的形式发生了变化而已。</li></ul><h3 id="寻找热门查询，300万个查询字符串中统计最热门的10个查询"><a href="#寻找热门查询，300万个查询字符串中统计最热门的10个查询" class="headerlink" title="寻找热门查询，300万个查询字符串中统计最热门的10个查询"></a>寻找热门查询，300万个查询字符串中统计最热门的10个查询</h3><p>原题: 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录(这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门)，请你统计最热门的10个查询串，要求使用的内存不能超过1G。</p><p>解答: 由上面第1题，我们知道，数据大则划为小的，如如一亿个Ip求Top 10，可先%1000将ip分到1000个小文件中去，并保证一种ip只出现在一个文件中，再对每个小文件中的ip进行hashmap计数统计并按数量排序，最后归并或者最小堆依次处理每个小文件的top10以得到最后的结。</p><p>但如果数据规模比较小，能一次性装入内存呢?比如这第2题，虽然有一千万个Query，但是由于重复度比较高，因此事实上只有300万的Query，每个Query255Byte，因此我们可以考虑把他们都放进内存中去(300万个字符串假设没有重复，都是最大长度，那么最多占用内存3M*1K&#x2F;4&#x3D;0.75G。所以可以将所有字符串都存放在内存中进行处理)，而现在只是需要一个合适的数据结构，在这里，HashTable绝对是我们优先的选择。</p><p>所以我们放弃分而治之&#x2F;hash映射的步骤，直接上hash统计，然后排序。So，针对此类典型的TOP K问题，采取的对策往往是: hashmap + 堆。如下所示:</p><ul><li><code>hash_map统计</code>: 先对这批海量数据预处理。具体方法是: 维护一个Key为Query字串，Value为该Query出现次数的HashTable，即hash_map(Query，Value)，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(N)的时间复杂度内用Hash表完成了统计； 堆排序: 第二步、借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。即借助堆结构，我们可以在log量级的时间内查找和调整&#x2F;移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。所以，我们最终的时间复杂度是: O(N) + N’ * O(logK)，(N为1000万，N’为300万)。</li></ul><p>别忘了这篇文章中所述的堆排序思路: “维护k个元素的最小堆，即用容量为k的最小堆存储最先遍历到的k个数，并假设它们即是最大的k个数，建堆费时O(k)，并调整堆(费时O(logk))后，有k1&gt;k2&gt;…kmin(kmin设为小顶堆中最小元素)。继续遍历数列，每次遍历一个元素x，与堆顶元素比较，若x&gt;kmin，则更新堆(x入堆，用时logk)，否则不更新堆。这样下来，总费时O(k*logk+(n-k)<em>logk)&#x3D;O(n</em>logk)。此方法得益于在堆中，查找等各项操作时间复杂度均为logk。”–第三章续、Top K算法问题的实现。   当然，你也可以采用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。</p><h3 id="有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。"><a href="#有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。" class="headerlink" title="有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。"></a>有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。</h3><ul><li><code>分而治之/hash映射</code>: 顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件(记为x0,x1,…x4999)中。这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。</li><li><code>hash_map统计</code>: 对每个小文件，采用trie树&#x2F;hash_map等统计每个文件中出现的词以及相应的频率。</li><li><code>堆/归并排序</code>: 取出出现频率最大的100个词(可以用含100个结点的最小堆)后，再把100个词及相应的频率存入文件，这样又得到了5000个文件。最后就是把这5000个文件进行归并(类似于归并排序)的过程了。</li></ul><h3 id="海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。"><a href="#海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。" class="headerlink" title="海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。"></a>海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。</h3><p>如果每个数据元素只出现一次，而且只出现在某一台机器中，那么可以采取以下步骤统计出现次数TOP10的数据元素:</p><ul><li><code>堆排序</code>: 在每台电脑上求出TOP10，可以采用包含10个元素的堆完成(TOP10小，用最大堆，TOP10大，用最小堆，比如求TOP10大，我们首先取前10个元素调整成最小堆，如果发现，然后扫描后面的数据，并与堆顶元素比较，如果比堆顶元素大，那么用该元素替换堆顶，然后再调整为最小堆。最后堆中的元素就是TOP10大)。 求出每台电脑上的TOP10后，然后把这100台电脑上的TOP10组合起来，共1000个数据，再利用上面类似的方法求出TOP10就可以了。</li></ul><p>但如果同一个元素重复出现在不同的电脑中呢，如下例子所述, 这个时候，你可以有两种方法:</p><ul><li>遍历一遍所有数据，重新hash取摸，如此使得同一个元素只出现在单独的一台电脑中，然后采用上面所说的方法，统计每台电脑中各个元素的出现次数找出TOP10，继而组合100台电脑上的TOP10，找出最终的TOP10。</li><li>或者，暴力求解: 直接统计统计每台电脑中各个元素的出现次数，然后把同一个元素在不同机器中的出现次数相加，最终从所有数据中找出TOP10。</li></ul><h3 id="有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。"><a href="#有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。" class="headerlink" title="有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。"></a>有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。</h3><p>方案1:</p><ul><li><code>hash映射</code>: 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件(记为a0,a1,..a9)中。这样新生成的文件每个的大小大约也1G(假设hash函数是随机的)。</li><li><code>hash_map统计</code>: 找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。注: hash_map(query,query_count)是用来统计每个query的出现次数，不是存储他们的值，出现一次，则count+1。 堆&#x2F;快速&#x2F;归并排序: 利用快速&#x2F;堆&#x2F;归并排序按照出现次数进行排序，将排序好的query和对应的query_cout输出到文件中，这样得到了10个排好序的文件(记为)。最后，对这10个文件进行归并排序(内排序与外排序相结合)。根据此方案1，这里有一份实现: <a href="https://github.com/ooooola/sortquery/blob/master/querysort.py%E3%80%82">https://github.com/ooooola/sortquery/blob/master/querysort.py。</a></li></ul><p>方案2: 一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树&#x2F;hash_map等直接来统计每个query出现的次数，然后按出现次数做快速&#x2F;堆&#x2F;归并排序就可以了。</p><p>方案3: 与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理(比如MapReduce)，最后再进行合并。</p><h3 id="给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url"><a href="#给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url" class="headerlink" title="给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?"></a>给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?</h3><p>可以估计每个文件安的大小为5G×64&#x3D;320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。</p><p><code>分而治之/hash映射</code>: 遍历文件a，对每个url求取，然后根据所取得的值将url分别存储到1000个小文件(记为，这里漏写个了a1)中。这样每个小文件的大约为300M。遍历文件b，采取和a相同的方式将url分别存储到1000小文件中(记为)。这样处理后，所有可能相同的url都在对应的小文件()中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。</p><p><code>hash_set统计</code>: 求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。</p><h3 id="怎么在海量数据中找出重复次数最多的一个"><a href="#怎么在海量数据中找出重复次数最多的一个" class="headerlink" title="怎么在海量数据中找出重复次数最多的一个?"></a>怎么在海量数据中找出重复次数最多的一个?</h3><p>方案: 先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。然后找出上一步求出的数据中重复次数最多的一个就是所求(具体参考前面的题)。</p><h3 id="上千万或上亿数据-有重复-，统计其中出现次数最多的前N个数据。"><a href="#上千万或上亿数据-有重复-，统计其中出现次数最多的前N个数据。" class="headerlink" title="上千万或上亿数据(有重复)，统计其中出现次数最多的前N个数据。"></a>上千万或上亿数据(有重复)，统计其中出现次数最多的前N个数据。</h3><p>方案: 上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map&#x2F;搜索二叉树&#x2F;红黑树等来进行统计次数。然后利用堆取出前N个出现次数最多的数据。</p><h3 id="一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。"><a href="#一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。" class="headerlink" title="一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。"></a>一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。</h3><p>方案1: 如果文件比较大，无法一次性读入内存，可以采用hash取模的方法，将大文件分解为多个小文件，对于单个小文件利用hash_map统计出每个小文件中10个最常出现的词，然后再进行归并处理，找出最终的10个最常出现的词。</p><p>方案2: 通过hash取模将大文件分解为多个小文件后，除了可以用hash_map统计出每个小文件中10个最常出现的词，也可以用trie树统计每个词出现的次数，时间复杂度是O(n<em>le)(le表示单词的平准长度)，最终同样找出出现最频繁的前10个词(可用堆来实现)，时间复杂度是O(n</em>lg10)。</p><h3 id="一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。"><a href="#一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。" class="headerlink" title="一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。"></a>一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。</h3><p>方案1: 首先根据用hash并求模，将文件分解为多个小文件，对于单个文件利用上题的方法求出每个文件件中10个最常出现的词。然后再进行归并处理，找出最终的10个最常出现的词。</p><h3 id="100w个数中找出最大的100个数。"><a href="#100w个数中找出最大的100个数。" class="headerlink" title="100w个数中找出最大的100个数。"></a>100w个数中找出最大的100个数。</h3><p>方案1: 采用局部淘汰法。选取前100个元素，并排序，记为序列L。然后一次扫描剩余的元素x，与排好序的100个元素中最小的元素比，如果比这个最小的要大，那么把这个最小的元素删除，并把x利用插入排序的思想，插入到序列L中。依次循环，知道扫描了所有的元素。复杂度为O(100w*100)。</p><p>方案2: 采用快速排序的思想，每次分割之后只考虑比轴大的一部分，知道比轴大的一部分在比100多的时候，采用传统排序算法排序，取前100个。复杂度为O(100w*100)。</p><p>方案3: 在前面的题中，我们已经提到了，用一个含100个元素的最小堆完成。复杂度为O(100w*lg100)。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;大数据处理思路: 分而治之&amp;#x2F;Hash映射 + Hash_map统计 + 堆&amp;#x2F;快速&amp;#x2F;归并排序。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;思路简介&quot;&gt;&lt;a href=&quot;#思路简介&quot; class=&quot;headerl</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    <category term="分治" scheme="https://hubertwongcn.github.io/tags/%E5%88%86%E6%B2%BB/"/>
    
    <category term="hash" scheme="https://hubertwongcn.github.io/tags/hash/"/>
    
    <category term="排序" scheme="https://hubertwongcn.github.io/tags/%E6%8E%92%E5%BA%8F/"/>
    
  </entry>
  
  <entry>
    <title>10.大数据处理 - Overview</title>
    <link href="https://hubertwongcn.github.io/2023/12/27/10-da-shu-ju-chu-li-overview/"/>
    <id>https://hubertwongcn.github.io/2023/12/27/10-da-shu-ju-chu-li-overview/</id>
    <published>2023-12-27T15:18:27.000Z</published>
    <updated>2023-12-27T15:18:27.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>本文主要介绍大数据处理的一些思路。</p></blockquote><h2 id="何谓海量数据处理"><a href="#何谓海量数据处理" class="headerlink" title="何谓海量数据处理?"></a>何谓海量数据处理?</h2><p>所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。</p><p>那解决办法呢?</p><ul><li><code>针对时间</code>: 我们可以采用巧妙的算法搭配合适的数据结构，如Bloom filter&#x2F;Hash&#x2F;bit-map&#x2F;堆&#x2F;数据库或倒排索引&#x2F;trie树；</li><li><code>针对空间</code>: 无非就一个办法: 大而化小，分而治之(hash映射);</li><li><code>集群|分布式</code>: 通俗点来讲，单机就是处理装载数据的机器有限(只要考虑cpu，内存，硬盘的数据交互); 而集群适合分布式处理，并行计算(更多考虑节点和节点间的数据交互)。</li></ul><h2 id="具体思路"><a href="#具体思路" class="headerlink" title="具体思路"></a>具体思路</h2><ul><li><a href="/2023/12/27/11-da-shu-ju-chu-li-fen-zhi-hash-pai-xu/" title="11.大数据处理 - 分治&#x2F;hash&#x2F;排序">大数据处理 - 分治&#x2F;hash&#x2F;排序</a><ul><li>就是先映射，而后统计，最后排序:</li><li><code>分而治之/hash映射</code>: 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件，即16字方针: 大而化小，各个击破，缩小规模，逐个解决</li><li><code>hash_map统计</code>: 当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。</li><li><code>堆/快速排序</code>: 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP。</li></ul></li><li><a href="/2023/12/27/12-da-shu-ju-chu-li-bitmap-bloom-filter/" title="12.大数据处理 - Bitmap &amp; Bloom Filter">大数据处理 - Bitmap &amp; Bloom Filter</a><ul><li>布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于这个集合的元素误认为不属于这个集合(False Negative)</li></ul></li><li><a href="/2023/12/28/13-da-shu-ju-chu-li-shuang-ceng-tong-hua-fen/" title="13.大数据处理 - 双层桶划分">大数据处理 - 双层桶划分</a><ul><li>其实本质上还是分而治之的思想，重在“分”的技巧上！<code>适用范围</code>: 第k大，中位数，不重复或重复的数字；<code>基本原理及要点</code>: 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。</li></ul></li><li><a href="/2023/12/28/14-da-shu-ju-chu-li-trie-shu-shu-ju-ku-dao-pai-suo-yin/" title="14.大数据处理 - Trie树&#x2F;数据库&#x2F;倒排索引">大数据处理 - Trie树&#x2F;数据库&#x2F;倒排索引</a><ul><li><code>适用范围</code>: 数据量大，重复多，但是数据种类小可以放入内存；<code>基本原理及要点</code>: 实现方式，节点孩子的表示方式；<code>扩展</code>: 压缩实现</li></ul></li><li><a href="/2023/12/28/15-da-shu-ju-chu-li-wai-ci-pan-wen-jian-pai-xu/" title="15.大数据处理 - 外（磁盘文件）排序">大数据处理 - 外排序</a><ul><li><code>适用范围</code>: 大数据的排序，去重；<code>基本原理及要点</code>: 外排序的归并方法，置换选择败者树原理，最优归并树</li></ul></li><li><a href="/2023/12/28/16-da-shu-ju-chu-li-map-reduce/" title="16.大数据处理 - Map &amp; Reduce">大数据处理 - Map &amp; Reduce</a><ul><li>MapReduce是一种计算模型，简单的说就是将大批量的工作(数据)分解(MAP)执行，然后再将结果合并成最终结果(REDUCE)。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序</li></ul></li></ul><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://blog.csdn.net/v_july_v/article/category/1106578">https://blog.csdn.net/v_july_v/article/category/1106578</a></li><li><a href="https://blog.csdn.net/v_JULY_v/article/details/6279498">https://blog.csdn.net/v_JULY_v/article/details/6279498</a></li><li><a href="https://blog.csdn.net/v_JULY_v/article/details/7382693">https://blog.csdn.net/v_JULY_v/article/details/7382693</a></li><li><a href="https://blog.csdn.net/meng984611383/article/details/80060096">https://blog.csdn.net/meng984611383/article/details/80060096</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;本文主要介绍大数据处理的一些思路。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;何谓海量数据处理&quot;&gt;&lt;a href=&quot;#何谓海量数据处理&quot; class=&quot;headerlink&quot; title=&quot;何谓海量数据处理?&quot;&gt;&lt;/a&gt;何谓海量数据处理?</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="大数据处理" scheme="https://hubertwongcn.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>9.字符串匹配 - 文本预处理：后缀树（Suffix Tree）</title>
    <link href="https://hubertwongcn.github.io/2023/12/27/9-zi-fu-chuan-pi-pei-wen-ben-yu-chu-li-hou-zhui-shu-suffix-tree/"/>
    <id>https://hubertwongcn.github.io/2023/12/27/9-zi-fu-chuan-pi-pei-wen-ben-yu-chu-li-hou-zhui-shu-suffix-tree/</id>
    <published>2023-12-27T15:07:51.000Z</published>
    <updated>2023-12-27T15:07:51.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>上述字符串匹配算法(朴素的字符串匹配算法, KMP 算法, Boyer-Moore算法)均是通过对<strong>模式（Pattern）字符串进行预处理</strong>的方式来加快搜索速度。对 Pattern 进行预处理的最优复杂度为 O(m)，其中 m 为 Pattern 字符串的长度。那么，有没有对文本（Text）进行预处理的算法呢？本文即将介绍一种<strong>对 Text 进行预处理</strong>的字符串匹配算法：后缀树（Suffix Tree）。</p></blockquote><h2 id="什么是后缀树"><a href="#什么是后缀树" class="headerlink" title="什么是后缀树"></a>什么是后缀树</h2><p>上述字符串匹配算法(朴素的字符串匹配算法, KMP 算法, Boyer-Moore算法)均是通过对<strong>模式（Pattern）字符串进行预处理</strong>的方式来加快搜索速度。对 Pattern 进行预处理的最优复杂度为 O(m)，其中 m 为 Pattern 字符串的长度。那么，有没有对文本（Text）进行预处理的算法呢？本文即将介绍一种<strong>对 Text 进行预处理</strong>的字符串匹配算法：后缀树（Suffix Tree）。</p><p><strong>后缀树的性质</strong>：</p><ul><li>存储所有 n(n-1)&#x2F;2 个后缀需要 O(n) 的空间，n 为的文本（Text）的长度；</li><li>构建后缀树需要 O(dn) 的时间，d 为字符集的长度（alphabet）；</li><li>对模式（Pattern）的查询需要 O(dm) 时间，m 为 Pattern 的长度；</li></ul><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272309225.png" alt="img"></p><p>在《<a href="/2023/12/27/11-shu-qian-zhui-shu-trie-tree/" title="11.树 - 前缀树(Trie Tree)">字典树(前缀树</a>》一文中，介绍了一种特殊的树状信息检索数据结构：字典树（Trie）。Trie 将关键词中的字符按顺序添加到树中的节点上，这样从根节点开始遍历，就可以确定指定的关键词是否存在于 Trie 中。</p><p>下面是根据集合 {bear, bell, bid, bull, buy, sell, stock, stop} 所构建的 Trie 树。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272310210.png" alt="img"></p><p>我们观察上面这颗 Trie，对于关键词 “bear”，字符 “a” 和 “r” 所在的节点没有其他子节点，所以可以考虑将这两个节点合并，如下图所示。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272310893.png" alt="img"></p><p>这样，我们就得到了一棵压缩过的 Trie，称为<strong>压缩字典树</strong>（Compressed Trie）。</p><p>而<strong>后缀树（Suffix Tree）则首先是一棵 Compressed Trie</strong>，其次，后缀树中存储的关键词为所有的后缀。这样，实际上我们也就得到了构建后缀树的抽象过程：</p><ul><li>根据文本 Text 生成所有后缀的集合；</li><li>将每个后缀作为一个单独的关键词，构建一棵 Compressed Trie。</li></ul><p>比如，对于文本 “banana\0”，其中 “\0” 作为文本结束符号。下面是该文本所对应的所有后缀。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">banana\0</span><br><span class="line">anana\0</span><br><span class="line">nana\0</span><br><span class="line">ana\0</span><br><span class="line">na\0</span><br><span class="line">a\0</span><br><span class="line">\0</span><br></pre></td></tr></table></figure><p>将每个后缀作为一个关键词，构建一棵 Trie。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272311414.png" alt="img"></p><p>然后，将独立的节点合并，形成 Compressed Trie。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272311838.png" alt="img"></p><p>则上面这棵树就是文本 “banana\0” 所对应的后缀树。</p><p>现在我们先熟悉两个概念：**显式后缀树（Explicit Suffix Tree）**和**隐式后缀树（Implicit Suffix Tree）**。</p><p>下面用字符串 “xabxa” 举例说明两者的区别，其包括后缀列表如下。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">xabxa</span><br><span class="line">abxa</span><br><span class="line">bxa</span><br><span class="line">xa</span><br><span class="line">a</span><br></pre></td></tr></table></figure><p>我们发现，后缀 “xa” 和 “a” 已经分别包含在后缀 “xabxa” 和 “abxa” 的前缀中，这样构造出来的后缀树称为隐式后缀树（Implicit Suffix Tree）。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272311580.png" alt="img"></p><p>而如果不希望这样的情形发生，可以在每个后缀的结尾加上一个特殊字符，比如 “$” 或 “#” 等，这样我们就可以使得后缀保持唯一性。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">xabxa$</span><br><span class="line">abxa$</span><br><span class="line">bxa$</span><br><span class="line">xa$</span><br><span class="line">a$</span><br><span class="line">$</span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272311433.jpg" alt="img"></p><p>在 1995 年，Esko Ukkonen 发表了论文《<a href="https://www.cs.helsinki.fi/u/ukkonen/SuffixT1withFigs.pdf">On-line construction of suffix trees</a>》，描述了在线性时间内构建后缀树的方法。下面尝试描述 Ukkonen 算法的基本实现原理，从简单的字符串开始描述，然后扩展到更复杂的情形。</p><p>Suffix Tree 与 Trie 的不同在于，边（Edge）不再只代表单个字符，而是通过一对整数 [from, to] 来表示。其中 from 和 to 所指向的是 Text 中的位置，这样每个边可以表示任意的长度，而且仅需两个指针，耗费 O(1) 的空间。</p><p>首先，我们从一个最简单的字符串 Text &#x3D; “abc” 开始实践构建后缀树，”abc” 中没有重复字符，使得构建过程更简单些。构建过程的步骤是：从左到右，对逐个字符进行操作。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abc</span><br></pre></td></tr></table></figure><p>第 1 个字符是 “a”，创建一条边从根节点（root）到叶节点，以 [0, #] 作为标签代表其在 Text 中的位置从 0 开始。使用 “#” 表示末尾，可以认为 “#” 在 “a” 的右侧，位置从 0 开始，则当前位置 “#” 在 1 位。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272312081.png" alt="img"></p><p>其代表的后缀意义如下。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272312504.png" alt="img"></p><p>第 1 个字符 “a” 处理完毕，开始处理第 2 个字符 “b”。涉及的操作包括：</p><ul><li>扩展已经存在的边 “a” 至 “ab”；</li><li>插入一条新边以表示 “b”；</li></ul><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272312352.png" alt="img"></p><p>其代表的后缀意义如下。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272312022.png" alt="img"></p><p>这里，我们观察到了两点：</p><ul><li>“ab” 边的表示 [0, #] 与之前是相同的，当 “#” 位置由 1 挪至 2 时，[0, #] 所代表的意义自动地发生了改变。</li><li>每条边的空间复杂度为 O(1)，即只消耗两个指针，而与边所代表的字符数量无关；</li></ul><p>接着再处理第 3 个字符 “c”，重复同样的操作，”#” 位置向后挪至第 3 位：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272312465.png" alt="img"></p><p>其代表的后缀意义如下。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272313073.png" alt="img"></p><p>此时，我们观察到：</p><ul><li>经过上面的步骤后，我们得到了一棵正确的后缀树；</li><li>操作步骤的数量与 Text 中的字符的数量一样多；</li><li>每个步骤的工作量是 O(1)，因为已存在的边都是依据 “#” 的挪动而自动更改的，仅需为最后一个字符添加一条新边，所以时间复杂度为 O(1)。则，对于一个长度为 n 的 Text，共需要 O(n) 的时间构建后缀树。</li></ul><p>当然，我们进展的这么顺利，完全是因为所操作的字符串 Text &#x3D; “abc” 太简单，没有任何重复的字符。那么现在我们来处理一个更复杂一些的字符串 Text &#x3D; “abcabxabcd”。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">abcabxabcd</span><br></pre></td></tr></table></figure><p>同上面的例子类似的是，这个新的 Text 同样以 “abc” 开头，但其后接着 “ab”,”x”,”abc”,”d” 等，并且出现了重复的字符。</p><p>前 3 个字符 “abc” 的操作步骤与上面介绍的相同，所以我们会得到下面这颗树：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272313021.png" alt="img"></p><p>当 “#” 继续向后挪动一位，即第 4 位时，隐含地意味着已有的边会自动的扩展为：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272313974.png" alt="img"></p><p>即 [0, #], [1, #], [2, #] 都进行了自动的扩展。按照上面的逻辑，此时应该为剩余后缀 “a” 创建一条单独的边。但，在做这件事之前，我们先引入两个概念。</p><ul><li><strong>活动点（active point）</strong>，是一个三元组，包括（active_node, active_edge, active_length）；</li><li><strong>剩余后缀数（remainder）</strong>，是一个整数，代表着还需要插入多少个新的后缀；</li></ul><p>如何使用这两个概念将在下面逐步地说明。不过，现在我们可以先确定两件事：</p><ul><li>在 Text &#x3D; “abc” 的例子中，活动点（active point）总是 (root, ‘\0x’, 0)。也就是说，活动节点（active_node）总是根节点（root），活动边（active_edge）是空字符 ‘\0x’ 所指定的边，活动长度（active_length）是 0。</li><li>在每个步骤开始时，剩余后缀数（remainder）总是 1。意味着，每次我们要插入的新的后缀数目为 1，即最后一个字符。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 3, active_point = (root, &#x27;\0x&#x27;, 1), remainder = 1</span></span><br></pre></td></tr></table></figure><p>当处理第 4 字符 “a” 时，我们注意到，事实上已经存在一条边 “abca” 的前缀包含了后缀 “a”。在这种情况下：</p><ul><li>我们不再向 root 插入一条全新的边，也就是 [3, #]。相反，既然后缀 “a” 已经被包含在树中的一条边上 “abca”，我们保留它们原来的样子。</li><li>设置 active point 为 (root, ‘a’, 1)，也就是说，active_node 仍为 root，active_edge 为 ‘a’，active_length 为 1。这就意味着，活动点现在是从根节点开始，活动边是以 ‘a’ 开头的某个边，而位置就是在这个边的第 1 位。这个活动边的首字符为 ‘a’，实际上，仅会有一个边是以一个特定字符开头的。</li><li>remainder 的值需要 +1，也就是 2。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 4, active_point = (root, &#x27;a&#x27;, 1), remainder = 2</span></span><br></pre></td></tr></table></figure><p>此时，我们还观察到：当我们要插入的后缀已经存在于树中时，这颗树实际上根本就没有改变，我们仅修改了 active point 和 remainder。那么，这颗树也就不再能准确地描述当前位置了，不过它却正确地包含了所有的后缀，即使是通过隐式的方式（Implicitly）。因此，处理修改变量，这一步没有其他工作，而修改变量的时间复杂度为 O(1)。</p><p>继续处理下一个字符 “b”，”#” 继续向后挪动一位，即第 5 位时，树被自动的更新为：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272314986.png" alt="img"></p><p>由于剩余后缀数（remainder）的值为 2，所以在当前位置，我们需要插入两个最终后缀 “ab” 和 “b”。这是因为：</p><ul><li>前一步的 “a” 实际上没有被真正的插入到树中，所以它被遗留了下来（remained），然而我们又向前迈了一步，所以它现在由 “a” 延长到 “ab”；</li><li>还有就是我们需要插入新的最终后缀 “b”；</li></ul><p>实际操作时，我们就是修改 active point，指向 “a” 后面的位置，并且要插入新的最终后缀 “b”。但是，同样的事情又发生了，”b” 事实上已经存在于树中一条边 “bcab” 的前缀上。那么，操作可以归纳为：</p><ul><li>修改活动点为 (root, ‘a’, 2)，实际还是与之前相同的边，只是将指向的位置向后挪到 “b”，修改了 active_length，即 “ab”。</li><li>增加剩余后缀数（remainder）为 3，因为我们又没有为 “b” 插入全新的边。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 5, active_point = (root, &#x27;a&#x27;, 2), remainder = 3</span></span><br></pre></td></tr></table></figure><p>再具体一点，我们本来准备插入两个最终后缀 “ab” 和 “b”，但因为 “ab” 已经存在于其他的边的前缀中，所以我们只修改了活动点。对于 “b”，我们甚至都没有考虑要插入，为什么呢？因为如果 “ab” 存在于树中，那么他的每个后缀都一定存在于树中。虽然仅仅是隐含性的，但却一定存在，因为我们一直以来就是按照这样的方式来构建这颗树的。</p><p>继续处理下一个字符 “x”，”#” 继续向后挪动一位，即第 6 位时，树被自动的更新为：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272314827.png" alt="img"></p><p>由于剩余后缀数（Remainder）的值为 3，所以在当前位置，我们需要插入 3 个最终后缀 “abx”, “bx” 和 “x”。</p><p>活动点告诉了我们之前 “ab” 结束的位置，所以仅需跳过这一位置，插入新的 “x” 后缀。”x” 在树中还不存在，因此我们分裂 “abcabx” 边，插入一个内部节点：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272314399.png" alt="img"></p><p>分裂和插入新的内部节点耗费 O(1) 时间。</p><p>现在，我们已经处理了 “abx”，并且把 remainder 减为 2。然后继续插入下一个后缀 “bx”，但做这个操作之前需要先更新活动点，这里我们先做下部分总结。</p><p>对于上面对边的分裂和插入新的边的操作，可以总结为 Rule 1，其应用于当 active_node 为 root 节点时。</p><blockquote><p>Rule 1</p><p>当向根节点插入时遵循：</p><ul><li>active_node 保持为 root；</li><li>active_edge 被设置为即将被插入的新后缀的首字符；</li><li>active_length 减 1；</li></ul></blockquote><p>因此，新的活动点为 (root, ‘b’, 1)，表明下一个插入一定会发生在边 “bcabx” 上，在 1 个字符之后，即 “b” 的后面。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 6, active_point = (root, &#x27;b&#x27;, 1), remainder = 2</span></span><br></pre></td></tr></table></figure><p>我们需要检查 “x” 是否在 “b” 后面出现，如果出现了，就是我们上面见到过的样子，可以什么都不做，只更新活动点。如果未出现，则需要分裂边并插入新的边。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272315789.png" alt="img"></p><p>同样，这次操作也花费了 O(1) 时间。然后将 remainder 更新为 1，依据 Rule 1 活动点更新为 (root, ‘x’, 0)。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 6, active_point = (root, &#x27;x&#x27;, 0), remainder = 1</span></span><br></pre></td></tr></table></figure><p>此时，我们将归纳出 Rule 2。</p><blockquote><p>Rule 2</p><ul><li>如果我们分裂（Split）一条边并且插入（Insert）一个新的节点，并且如果该新节点不是当前步骤中创建的第一个节点，则将先前插入的节点与该新节点通过一个特殊的指针连接，称为后缀连接（Suffix Link）。后缀连接通过一条虚线来表示。</li></ul></blockquote><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272315308.png" alt="img"></p><p>继续上面的操作，插入最终后缀 “x”。因为活动点中的 active_length 已经降到 0，所以插入操作将发生在 root 上。由于没有以 “x” 为前缀的边，所以插入一条新的边：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272315581.png" alt="img"></p><p>这样，这一步骤中的所有操作就完成了。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 6, active_point = (root, &#x27;\0x&#x27;, 0), remainder = 1</span></span><br></pre></td></tr></table></figure><p>继续处理下一个字符 “a”，”#” 继续向后挪动一位。发现后缀 “a” 已经存在于数中的边中，所以仅更新 active point 和 remainder。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 7, active_point = (root, &#x27;a&#x27;, 1), remainder = 2</span></span><br></pre></td></tr></table></figure><p>继续处理下一个字符 “b”，”#” 继续向后挪动一位。发现后缀 “ab” 和 “b” 都已经存在于树中，所以仅更新 active point 和 remainder。这里我们先称 “ab” 所在的边的节点为 node1。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 8, active_point = (root, &#x27;a&#x27;, 2), remainder = 3</span></span><br></pre></td></tr></table></figure><p>继续处理下一个字符 “c”，”#” 继续向后挪动一位。此时由于 remainder &#x3D; 3，所以需要插入 “abc”,”bc”,”c” 三个后缀。”c” 实际上已经存在于 node1 后的边上。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 9, active_point = (node1, &#x27;c&#x27;, 1), remainder = 4</span></span><br></pre></td></tr></table></figure><p>继续处理下一个字符 “d”，”#” 继续向后挪动一位。此时由于 remainder &#x3D; 4，所以需要插入 “abcd”,”bcd”,”cd”,”d” 四个后缀。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272316608.png" alt="img"></p><p>上图中的 active_node，当节点准备分裂时，被标记了红色。则归纳出了 Rule 3。</p><blockquote><p>Rule 3</p><ul><li>当从 active_node 不为 root 的节点分裂边时，我们沿着后缀连接（Suffix Link）的方向寻找节点，如果存在一个节点，则设置该节点为 active_noe；如果不存在，则设置 active_node 为 root。active_edge 和 active_length 保持不变。</li></ul></blockquote><p>所以，现在活动点为 (node2, ‘c’, 1)，其中 node2 为下图中的红色节点：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272316425.png" alt="img"></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 10, active_point = (node2, &#x27;c&#x27;, 1), remainder = 3</span></span><br></pre></td></tr></table></figure><p>由于对 “abcd” 的插入已经完成，所以将 remainder 的值减至 3，并且开始处理下一个剩余后缀 “bcd”。此时需要将边 “cabxabcd” 分裂，然后插入新的边 “d”。根据 Rule 2，我们需要在之前插入的节点与当前插入的节点间创建一条新的后缀连接。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272316357.png" alt="img"></p><p>此时，我们观察到，后缀连接（Suffix Link）让我们能够重置活动点，使得对下一个后缀的插入操作仅需 O(1) 时间。从上图也确认了，”ab” 连接的是其后缀 “b”，而 “abc” 连接的是其后缀 “bc”。</p><p>当前操作还没有完成，因为 remainder 是 2，根绝 Rule 3 我们需要重新设置活动点。因为上图中的红色 active_node 没有后缀连接（Suffix Link），所以活动点被设置为 root，也就是 (root, ‘c’, 1)。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 10, active_point = (root, &#x27;c&#x27;, 1), remainder = 2</span></span><br></pre></td></tr></table></figure><p>因此，下一个插入操作 “cd” 将从 Root 开始，寻找以 “c” 为前缀的边 “cabxabcd”，这也引起又一次分裂：</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272317602.png" alt="img"></p><p>由于此处又创建了一个新的内部节点，依据 Rule 2，我们需要建立一条与前一个被创建内节点的后缀连接。</p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272317719.png" alt="img"></p><p>然后，remainder 减为 1，active_node 为 root，根据 Rule 1 则活动点为 (root, ‘d’, 0)。也就是说，仅需在根节点上插入一条 “d” 新边。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># = 10, active_point = (root, &#x27;d&#x27;, 0), remainder = 1</span></span><br></pre></td></tr></table></figure><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272317653.png" alt="img"></p><p>整个步骤完成。</p><p><strong>总体上看，我们有一系列的观察结果</strong>：</p><ul><li>在每一步中将 “#” 向右移动 1 位时，所有叶节点自动更新的时间为 O(1)；</li><li>但实际上并没有处理这两种情况： <ul><li>从前一步中遗留的后缀；</li><li>当前步骤中的最终字符；</li></ul></li><li>remainder 告诉了我们还余下多少后缀需要插入。这些插入操作将逐个的与当前位置 “#” 之前的后缀进行对应，我们需要一个接着一个的处理。更重要的是，每次插入需要 O(1) 时间，活动点准确地告诉了我们改如何进行，并且也仅需在活动点中增加一个单独的字符。为什么？因为其他字符都隐式地被包含了，要不也就不需要 active point 了。</li><li>每次插入之后，remainder 都需要减少，如果存在后缀连接（Suffix Link）的话就续接至下一个节点，如果不存在则返回值 root 节点（Rule 3）。如果已经是在 root 节点了，则依据 Rule 1 来修改活动点。无论哪种情况，仅需 O(1) 时间。</li><li>如果这些插入操作中，如果发现要被插入的字符已经存在于树中，则什么也不做，即使 remainder &gt; 0。原因是要被插入的字符实际上已经隐式地被包含在了当前的树中。而 remainder &gt; 0 则确保了在后续的操作中会进行处理。</li><li>那么如果在算法结束时 remainder &gt; 0 该怎么办？这种情况说明了文本的尾部字符串在之前某处已经出现过。此时我们需要在尾部添加一个额外的从未出现过的字符，通常使用 “$” 符号。为什么要这么做呢？如果后续我们用已经完成的后缀树来查找后缀，匹配结果一定要出现在叶子节点，否则就会出现很多假匹配，因为很多字符串已经被隐式地包含在了树中，但实际并不是真正的后缀。同时，最后也强制 remainder &#x3D; 0，以此来保证所有的后缀都形成了叶子节点。尽管如此，如果想用后缀树搜索常规的子字符串，而不仅是搜索后缀，这么做就不是必要的了。</li><li>那么整个算法的复杂度是多少呢？如果 Text 的长度为 n，则有 n 步需要执行，算上 “$” 则有 n+1 步。在每一步中，我们要么什么也不做，要么执行 remainder 插入操作并消耗 O(1) 时间。因为 remainder 指示了在前一步中我们有多少无操作次数，在当前步骤中每次插入都会递减，所以总体的数量还是 n。因此**总体的复杂度为 O(n)**。</li><li>然而，还有一小件事我还没有进行适当的解释。那就是，当我们续接后缀连接时，更新 active point，会发现 active_length 可能与 active_node 协作的并不好。例如下面这种情况：</li></ul><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272318616.png" alt="img"></p><p>假设 active point 是红色节点 (red, ‘d’, 3)，因此它指向 “def” 边中 “f” 之后的位置。现在假设我们做了必要的更新，而且依据 Rule 3 续接了后缀连接并修改了活动点，新的 active point 是 (green, ‘d’, 3)。然而从绿色节点出发的 “d” 边是 “de”，这条边只有 2 个字符。为了找到合适的活动点，看起来我们需要添加一个到蓝色节点的边，然后重置活动点为 (blue, ‘f’, 1)。</p><p>在最坏的情况下，active_length 可以与 remainder 一样大，甚至可以与 n 一样大。而恰巧这种情况可能刚好在找活动点时发生，那么我们不仅需要跳过一个内部节点，可能是多个节点，最坏的情况是 n 个。由于每步里 remainder 是 O(n)，续接了后缀连接之后的对活动点的后续调整也是 O(n)，那么是否意味着整个算法潜在需要 O(n2) 时间呢？</p><p>我认为不是。理由是如果我们确实需要调整活动点（例如，上图中从绿色节点调整到蓝色节点），那么这就引入了一个拥有自己的后缀连接的新节点，而且 active_length 将减少。当我们沿着后缀连接向下走，就要插入剩余的后缀，且只是减少 active_length，使用这种方法可调整的活动点的数量不可能超过任何给定时刻的 active_length。由于 active_length 从来不会超过 remainder，而 remainder 不仅在每个单一步骤里是 O(n)，而且对整个处理过程进行的 remainder 递增的总数也是 O(n)，因此调整活动点的数目也就限制在了 O(n)。</p><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="https://www.cs.helsinki.fi/u/ukkonen/SuffixT1withFigs.pdf">https://www.cs.helsinki.fi/u/ukkonen/SuffixT1withFigs.pdf</a></li><li><a href="https://www.cnblogs.com/gaochundong/p/suffix_tree.html">https://www.cnblogs.com/gaochundong/p/suffix_tree.html</a></li><li><a href="https://blog.csdn.net/v_july_v/article/details/6897097">https://blog.csdn.net/v_july_v/article/details/6897097</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;上述字符串匹配算法(朴素的字符串匹配算法, KMP 算法, Boyer-Moore算法)均是通过对&lt;strong&gt;模式（Pattern）字符串进行预处理&lt;/strong&gt;的方式来加快搜索速度。对 Pattern 进行预处理的最优复杂度为 O(m)，</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="字符串匹配" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"/>
    
    <category term="模式预处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/%E6%A8%A1%E5%BC%8F%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="字符串匹配" scheme="https://hubertwongcn.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"/>
    
    <category term="模式预处理" scheme="https://hubertwongcn.github.io/tags/%E6%A8%A1%E5%BC%8F%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
    <category term="后缀树" scheme="https://hubertwongcn.github.io/tags/%E5%90%8E%E7%BC%80%E6%A0%91/"/>
    
    <category term="Suffix Tree" scheme="https://hubertwongcn.github.io/tags/Suffix-Tree/"/>
    
  </entry>
  
  <entry>
    <title>8.字符串匹配 - 模式预处理：BM 算法 (Boyer-Moore)</title>
    <link href="https://hubertwongcn.github.io/2023/12/27/8-zi-fu-chuan-pi-pei-mo-shi-yu-chu-li-bm-suan-fa-boyer-moore/"/>
    <id>https://hubertwongcn.github.io/2023/12/27/8-zi-fu-chuan-pi-pei-mo-shi-yu-chu-li-bm-suan-fa-boyer-moore/</id>
    <published>2023-12-27T15:01:46.000Z</published>
    <updated>2023-12-27T14:52:44.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>各种文本编辑器的”查找”功能（Ctrl+F），大多采用Boyer-Moore算法，效率非常高。</p></blockquote><h2 id="算法简介"><a href="#算法简介" class="headerlink" title="算法简介"></a>算法简介</h2><blockquote><p>在 1977 年，Robert S. Boyer (Stanford Research Institute) 和 J Strother Moore (Xerox Palo Alto Research Center) 共同发表了文章《A Fast String Searching Algorithm》，介绍了一种新的快速字符串匹配算法。这种算法在逻辑上相对于现有的算法有了显著的改进，它对要搜索的字符串进行倒序的字符比较，并且当字符比较不匹配时无需对整个模式串再进行搜索。</p></blockquote><p>Boyer-Moore 算法的主要特点有：</p><ul><li>对模式字符的比较顺序时从右向左；</li><li>预处理需要 O(m + σ) 的时间和空间复杂度；</li><li>匹配阶段需要 O(m × n) 的时间复杂度；</li><li>匹配阶段在最坏情况下需要 3n 次字符比较；</li><li>最优复杂度 O(n&#x2F;m)；</li></ul><p>在 Naive 算法中，对文本 T 和模式 P 字符串均未做预处理。而在 KMP 算法中则对模式 P 字符串进行了预处理操作，以预先计算模式串中各位置的最长相同前后缀长度的数组。Boyer–Moore 算法同样也是对模式 P 字符串进行预处理。</p><p>我们知道，在 Naive 算法中，如果发现模式 P 中的字符与文本 T 中的字符不匹配时，需要将文本 T 的比较位置向后滑动一位，模式 P 的比较位置归 0 并从头开始比较。而 KMP 算法则是根据预处理的结果进行判断以使模式 P 的比较位置可以向后滑动多个位置。Boyer–Moore 算法的预处理过程也是为了达到相同效果。</p><p>Boyer–Moore 算法在对模式 P 字符串进行预处理时，将采用两种不同的启发式方法。这两种启发式的预处理方法称为：</p><ul><li><code>坏字符（Bad Character Heuristic）</code>：当文本 T 中的某个字符跟模式 P 的某个字符不匹配时，我们称文本 T 中的这个失配字符为坏字符。</li><li><code>好后缀（Good Suffix Heuristic）</code>：当文本 T 中的某个字符跟模式 P 的某个字符不匹配时，我们称文本 T 中的已经匹配的字符串为好后缀。</li></ul><p>Boyer–Moore 算法在预处理时，将为两种不同的启发法结果创建不同的数组，分别称为<code> Bad-Character-Shift（or The Occurrence Shift）</code>和 <code>Good-Suffix-Shift（or Matching Shift）</code>。当进行字符匹配时，如果发现模式 P 中的字符与文本 T 中的字符不匹配时，将比较两种不同启发法所建议的移动位移长度，选择最大的一个值来对模式 P 的比较位置进行滑动。</p><p>此外，Naive 算法和 KMP 算法对模式 P 的比较方向是从前向后比较，而 Boyer–Moore 算法的设计则是从后向前比较，即从尾部向头部方向进行比较。</p><h2 id="图例分析"><a href="#图例分析" class="headerlink" title="图例分析"></a>图例分析</h2><blockquote><p>例子来源于阮一峰的 <a href="http://www.ruanyifeng.com/blog/2013/05/boyer-moore_string_search_algorithm.html">字符串匹配的Boyer-Moore算法</a></p></blockquote><p>下面，我根据Moore教授自己的例子来解释这种算法。</p><p>1. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272304706.png" alt="img"></p><p>假定字符串为”HERE IS A SIMPLE EXAMPLE”，搜索词为”EXAMPLE”。</p><p>2. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272304194.png" alt="img"></p><p>首先，”字符串”与”搜索词”头部对齐，从尾部开始比较。</p><p>这是一个很聪明的想法，因为如果尾部字符不匹配，那么只要一次比较，就可以知道前7个字符（整体上）肯定不是要找的结果。</p><p>我们看到，”S”与”E”不匹配。这时，”S”就被称为”坏字符”（bad character），即不匹配的字符。我们还发现，”S”不包含在搜索词”EXAMPLE”之中，这意味着可以把搜索词直接移到”S”的后一位。</p><p>3. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272304467.png" alt="img"></p><p>依然从尾部开始比较，发现”P”与”E”不匹配，所以”P”是”坏字符”。但是，”P”包含在搜索词”EXAMPLE”之中。所以，将搜索词后移两位，两个”P”对齐。</p><p>4. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272305324.png" alt="img"></p><p>我们由此总结出”坏字符规则”：</p><blockquote><p>后移位数 &#x3D; 坏字符的位置 - 搜索词中的上一次出现位置</p></blockquote><p>如果”坏字符”不包含在搜索词之中，则上一次出现位置为 -1。</p><p>以”P”为例，它作为”坏字符”，出现在搜索词的第6位（从0开始编号），在搜索词中的上一次出现位置为4，所以后移 6 - 4 &#x3D; 2位。再以前面第二步的”S”为例，它出现在第6位，上一次出现位置是 -1（即未出现），则整个搜索词后移 6 - (-1) &#x3D; 7位。</p><p>5. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272305598.png" alt="img"></p><p>依然从尾部开始比较，”E”与”E”匹配。</p><p>6. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272305914.png" alt="img"></p><p>比较前面一位，”LE”与”LE”匹配。</p><p>7. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272305344.png" alt="img"></p><p>比较前面一位，”PLE”与”PLE”匹配。</p><p>8. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272306632.png" alt="img"></p><p>比较前面一位，”MPLE”与”MPLE”匹配。我们把这种情况称为”好后缀”（good suffix），即所有尾部匹配的字符串。注意，”MPLE”、”PLE”、”LE”、”E”都是好后缀。</p><p>9. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272306275.png" alt="img"></p><p>比较前一位，发现”I”与”A”不匹配。所以，”I”是”坏字符”。</p><p>10. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272306597.png" alt="img"></p><p>根据”坏字符规则”，此时搜索词应该后移 2 - （-1）&#x3D; 3 位。问题是，此时有没有更好的移法？</p><p>11. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272306602.png" alt="img"></p><p>我们知道，此时存在”好后缀”。所以，可以采用”好后缀规则”：</p><blockquote><p>后移位数 &#x3D; 好后缀的位置 - 搜索词中的上一次出现位置</p></blockquote><p>举例来说，如果字符串”ABCDAB”的后一个”AB”是”好后缀”。那么它的位置是5（从0开始计算，取最后的”B”的值），在”搜索词中的上一次出现位置”是1（第一个”B”的位置），所以后移 5 - 1 &#x3D; 4位，前一个”AB”移到后一个”AB”的位置。</p><p>再举一个例子，如果字符串”ABCDEF”的”EF”是好后缀，则”EF”的位置是5 ，上一次出现的位置是 -1（即未出现），所以后移 5 - (-1) &#x3D; 6位，即整个字符串移到”F”的后一位。</p><p><strong>这个规则有三个注意点</strong>：</p><ul><li>“好后缀”的位置以最后一个字符为准。假定”ABCDEF”的”EF”是好后缀，则它的位置以”F”为准，即5（从0开始计算）。</li><li>如果”好后缀”在搜索词中只出现一次，则它的上一次出现位置为 -1。比如，”EF”在”ABCDEF”之中只出现一次，则它的上一次出现位置为-1（即未出现）。</li><li>如果”好后缀”有多个，则除了最长的那个”好后缀”，其他”好后缀”的上一次出现位置必须在头部。比如，假定”BABCDAB”的”好后缀”是”DAB”、”AB”、”B”，请问这时”好后缀”的上一次出现位置是什么？回答是，此时采用的好后缀是”B”，它的上一次出现位置是头部，即第0位。这个规则也可以这样表达：如果最长的那个”好后缀”只出现一次，则可以把搜索词改写成如下形式进行位置计算”(DA)BABCDAB”，即虚拟加入最前面的”DA”。</li></ul><p>回到上文的这个例子。此时，所有的”好后缀”（MPLE、PLE、LE、E）之中，只有”E”在”EXAMPLE”还出现在头部，所以后移 6 - 0 &#x3D; 6位。</p><p>12. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272306978.png" alt="img"></p><p>可以看到，”坏字符规则”只能移3位，”好后缀规则”可以移6位。所以，Boyer-Moore算法的基本思想是，每次后移这两个规则之中的较大值。</p><p>更巧妙的是，这两个规则的移动位数，只与搜索词有关，与原字符串无关。因此，可以预先计算生成《坏字符规则表》和《好后缀规则表》。使用时，只要查表比较一下就可以了。</p><p>13. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272307037.png" alt="img"></p><p>继续从尾部开始比较，”P”与”E”不匹配，因此”P”是”坏字符”。根据”坏字符规则”，后移 6 - 4 &#x3D; 2位。</p><p>14. </p><p><img src="https://cdn.jsdelivr.net/gh/HubertWongCN/image_host/img/202312272307051.png" alt="img"></p><p>从尾部开始逐位比较，发现全部匹配，于是搜索结束。如果还要继续查找（即找出全部匹配），则根据”好后缀规则”，后移 6 - 0 &#x3D; 6位，即头部的”E”移到尾部的”E”的位置。</p><blockquote><p>从上面的示例描述可以看出，Boyer–Moore 算法的精妙之处在于，其通过两种启示规则来计算后移位数，且其计算过程只与模式 P 有关，而与文本 T 无关。因此，在对模式 P 进行预处理时，可预先生成 “坏字符规则之向后位移表” 和 “好后缀规则之向后位移表”，在具体匹配时仅需查表比较两者中最大的位移即可。</p></blockquote><h2 id="参考文章"><a href="#参考文章" class="headerlink" title="参考文章"></a>参考文章</h2><ul><li><a href="http://www.ruanyifeng.com/blog/2013/05/boyer-moore_string_search_algorithm.html">http://www.ruanyifeng.com/blog/2013/05/boyer-moore_string_search_algorithm.html</a></li><li><a href="https://www.cnblogs.com/gaochundong/p/boyer_moore_string_matching_algorithm.html">https://www.cnblogs.com/gaochundong/p/boyer_moore_string_matching_algorithm.html</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;各种文本编辑器的”查找”功能（Ctrl+F），大多采用Boyer-Moore算法，效率非常高。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&quot;算法简介&quot;&gt;&lt;a href=&quot;#算法简介&quot; class=&quot;headerlink&quot; title=&quot;算法</summary>
      
    
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/"/>
    
    <category term="字符串匹配" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"/>
    
    <category term="模式预处理" scheme="https://hubertwongcn.github.io/categories/%E7%AE%97%E6%B3%95/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/%E6%A8%A1%E5%BC%8F%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
    
    <category term="算法" scheme="https://hubertwongcn.github.io/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="字符串匹配" scheme="https://hubertwongcn.github.io/tags/%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%8C%B9%E9%85%8D/"/>
    
    <category term="模式预处理" scheme="https://hubertwongcn.github.io/tags/%E6%A8%A1%E5%BC%8F%E9%A2%84%E5%A4%84%E7%90%86/"/>
    
    <category term="BM 算法" scheme="https://hubertwongcn.github.io/tags/BM-%E7%AE%97%E6%B3%95/"/>
    
    <category term="Boyer-Moore" scheme="https://hubertwongcn.github.io/tags/Boyer-Moore/"/>
    
  </entry>
  
</feed>
