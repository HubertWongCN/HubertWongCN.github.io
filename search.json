[{"title":"26.数据挖掘 - 10大算法汇总","path":"/2023/12/28/26-数据挖掘-10大算法汇总/","content":"国际权威的学术组织the IEEE International Conference on Data Mining (ICDM) 2006年12月评选出了数据挖掘领域的十大经典算法: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART。 推荐学习 博客园@刘建平Pinard 的机器学习，数据挖掘系列 数据挖掘十大经典算法C4.5C4.5算法是机器学习算法中的一种分类决策树算法,其核心算法是ID3算法. C4.5算法继承了ID3算法的优点，并在以下几方面对ID3算法进行了改进: 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足； 在树构造过程中进行剪枝； 能够完成对连续属性的离散化处理； 能够对不完整数据进行处理。 C4.5算法有如下优点: 产生的分类规则易于理解，准确率较高。其缺点是: 在构造树的过程中，需要对数据集进行多次的顺序扫描和排序，因而导致算法的低效(相对的CART算法只需要扫描两次数据集，以下仅为决策树优缺点)。 The k-means algorithm 即K-Means算法k-means algorithm算法是一个聚类算法，把n的对象根据他们的属性分为k个分割，k &lt; n。它与处理混合正态分布的最大期望算法很相似，因为他们都试图找到数据中自然聚类的中心。它假设对象属性来自于空间向量，并且目标是使各个群组内部的均 方误差总和最小。 Support vector machines支持向量机，英文为Support Vector Machine，简称SV机(论文中一般简称SVM)。它是一种監督式學習的方法，它广泛的应用于统计分类以及回归分析中。支持向量机将向量映射到一个更 高维的空间里，在这个空间里建立有一个最大间隔超平面。在分开数据的超平面的两边建有两个互相平行的超平面。分隔超平面使两个平行超平面的距离最大化。假 定平行超平面间的距离或差距越大，分类器的总误差越小。一个极好的指南是C.J.C Burges的《模式识别支持向量机指南》。van der Walt 和 Barnard 将支持向量机和其他分类器进行了比较。 The Apriori algorithmApriori算法是一种最有影响的挖掘布尔关联规则频繁项集的算法。其核心是基于两阶段频集思想的递推算法。该关联规则在分类上属于单维、单层、布尔关联规则。在这里，所有支持度大于最小支持度的项集称为频繁项集，简称频集。 最大期望(EM)算法在统计计算中，最大期望(EM，Expectation–Maximization)算法是在概率(probabilistic)模型中寻找参数最大似然 估计的算法，其中概率模型依赖于无法观测的隐藏变量(Latent Variabl)。最大期望经常用在机器学习和计算机视觉的数据集聚(Data Clustering)领域。 PageRankPageRank是Google算法的重要内容。2001年9月被授予美国专利，专利人是Google创始人之一拉里·佩奇(Larry Page)。因此，PageRank里的page不是指网页，而是指佩奇，即这个等级方法是以佩奇来命名的。 PageRank根据网站的外部链接和内部链接的数量和质量俩衡量网站的价值。PageRank背后的概念是，每个到页面的链接都是对该页面的一次投票， 被链接的越多，就意味着被其他网站投票越多。这个就是所谓的“链接流行度”——衡量多少人愿意将他们的网站和你的网站挂钩。PageRank这个概念引自 学术中一篇论文的被引述的频度——即被别人引述的次数越多，一般判断这篇论文的权威性就越高。 AdaBoostAdaboost是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器 (强分类器)。其算法本身是通过改变数据分布来实现的，它根据每次训练集之中每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权 值。将修改过权值的新数据集送给下层分类器进行训练，最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。 kNN: k-nearest neighbor classificationK最近邻(k-Nearest Neighbor，KNN)分类算法，是一个理论上比较成熟的方法，也是最简单的机器学习算法之一。该方法的思路是: 如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。 Naive Bayes在众多的分类模型中，应用最为广泛的两种分类模型是决策树模型(Decision Tree Model)和朴素贝叶斯模型(Naive Bayesian Model，NBC)。 朴素贝叶斯模型发源于古典数学理论，有着坚实的数学基础，以 及稳定的分类效率。同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。理论上，NBC模型与其他分类方法相比具有最小的误差率。 但是实际上并非总是如此，这是因为NBC模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的，这给NBC模型的正确分类带来了一定影响。在属 性个数比较多或者属性之间相关性较大时，NBC模型的分类效率比不上决策树模型。而在属性相关性较小时，NBC模型的性能最为良好。 CART: 分类与回归树CART, Classification and Regression Trees。 在分类树下面有两个关键的思想。第一个是关于递归地划分自变量空间的想法(二元切分法)；第二个想法是用验证数据进行剪枝(预剪枝、后剪枝)。在回归树的基础上的模型树构建难度可能增加了，但同时其分类效果也有提升。 参考文章提示 本文主要来源于这里https://blog.csdn.net/qq_36523839/article/details/82383597。 https://blog.csdn.net/qq_36523839/article/details/82383597 https://blog.csdn.net/u010983763/article/details/70854469 https://www.cnblogs.com/jchubby/p/5449404.html","tags":["算法","数据挖掘算法"],"categories":["算法","数据挖掘算法"]},{"title":"25.推荐算法 - 汇总","path":"/2023/12/28/25-推荐算法-汇总/","content":"本文主要对推荐算法整体知识点做汇总，做到总体的理解；深入理解需要再看专业的材料。 推荐算法的意义推荐根据用户兴趣和行为特点，向用户推荐所需的信息或商品，帮助用户在海量信息中快速发现真正所需的商品，提高用户黏性，促进信息点击和商品销售。 帮助用户找到想要的商品(新闻&#x2F;音乐&#x2F;……)，发掘长尾 帮用户找到想要的东西，谈何容易。商品茫茫多，甚至是我们自己，也经常点开淘宝，面对眼花缭乱的打折活动不知道要买啥。在经济学中，有一个著名理论叫长尾理论(The Long Tail)。套用在互联网领域中，指的就是最热的那一小部分资源将得到绝大部分的关注，而剩下的很大一部分资源却鲜少有人问津。这不仅造成了资源利用上的浪费，也让很多口味偏小众的用户无法找到自己感兴趣的内容。 降低信息过载 互联网时代信息量已然处于爆炸状态，若是将所有内容都放在网站首页上用户是无从阅读的，信息的利用率将会十分低下。因此我们需要推荐系统来帮助用户过滤掉低价值的信息。 提高站点的点击率&#x2F;转化率 好的推荐系统能让用户更频繁地访问一个站点，并且总是能为用户找到他想要购买的商品或者阅读的内容。 加深对用户的了解，为用户提供定制化服务 可以想见，每当系统成功推荐了一个用户感兴趣的内容后，我们对该用户的兴趣爱好等维度上的形象是越来越清晰的。当我们能够精确描绘出每个用户的形象之后，就可以为他们定制一系列服务，让拥有各种需求的用户都能在我们的平台上得到满足。 推荐算法的输入推荐系统是基于海量数据挖掘分析的商业智能平台，推荐主要基于以下信息: 热点信息或商品 用户Profile信息，如性别、年龄、职业、收入以及所在城市等等 用户历史浏览或行为记录 社会化关系 常见推荐算法基于流行度的算法基于流行度的算法非常简单粗暴，类似于各大新闻、微博热榜等，根据PV、UV、日均PV或分享率等数据来按某种热度排序来推荐给用户。 这种算法的优点是简单，适用于刚注册的新用户。缺点也很明显，它无法针对用户提供个性化的推荐。基于这种算法也可做一些优化，比如加入用户分群的流行度排序，例如把热榜上的体育内容优先推荐给体育迷，把政要热文推给热爱谈论政治的用户。 基于用户行为数据的算法CF算法主要有基于用户的协同过滤算法(user-based CF)，基于项目的协同过滤(item-based CF)以及基于模型的协同过滤(model-based CF)，它很简单而且很多时候推荐也是很准确的。 基于协同过滤的推荐机制是现今应用最为广泛的推荐机制，它有以下几个显著的优点: 它不需要对物品或者用户进行严格的建模，而且不要求物品的描述是机器可理解的，所以这种方法也是领域无关的。 这种方法计算出来的推荐是开放的，可以共用他人的经验，很好的支持用户发现潜在的兴趣偏好。 然后而它也存在以下几个问题: 方法的核心是基于历史数据，所以对新物品和新用户都有“冷启动”的问题。 推荐的效果依赖于用户历史偏好数据的多少和准确性。 对于一些特殊品味的用户不能给予很好的推荐。 由于以历史数据为基础，抓取和建模用户的偏好后，很难修改或者根据用户的使用演变，从而导致这个方法不够灵活。 在大部分的实现中，用户历史偏好是用稀疏矩阵进行存储的，而稀疏矩阵上的计算有些明显的问题，包括可能少部分人的错误偏好会对推荐的准确度有很大的影响等等。 对于矩阵稀疏的问题，有很多方法来改进CF算法。比如通过矩阵因子分解(如LFM)，我们可以把一个nm的矩阵分解为一个nk的矩阵乘以一个k*m的矩阵，这里的k可以是用户的特征、兴趣爱好与物品属性的一些联系，通过因子分解，可以找到用户和物品之间的一些潜在关联，从而填补之前矩阵中的缺失值。 基于用户的协同过滤算法(user-based CF)一个用户喜欢和他具有相似喜好的用户喜欢的项目， 两个用户喜欢的项目交集越大， 这两个用户越相似。 两个用户兴趣相似度的计算可以有多种方法， 常见的如 Pearson相关相似性和余弦相似度计算。 基于用户的CF原理如下: 分析各个用户对item的评价(通过浏览记录、购买记录等)； 依据用户对item的评价计算得出所有用户之间的相似度； 选出与当前用户最相似的N个用户； 将这N个用户评价最高并且当前用户又没有浏览过的item推荐给当前用户。 基于项目的协同过滤(item-based CF)基于项目的协同过滤推荐(item-based CF)基于这样的假设: 一个用户会喜欢与他之前喜欢的项目相似的项目。因此， 基于项目的协同过滤推荐关键在于计算物品之间的相似度。 基于用户的协同过滤和基于项目的协同过滤统称为基于邻域的推荐 (nearest neighbor recommendation)，也称作基于记忆的推荐算法(memory-based recommendation)。 基于邻域的推荐算法需要维护一个用户相似度矩阵或项目相似度矩阵， 因此对于项目的数目更新速度远远小于用户数目的增长速度的情况， 宜采用基于项目的推荐算法， 如 Amazon 建立的推荐系统正是基于项目的协同过滤推荐算法， 还有移动应用产品的推荐。另外， 有研究表明， 基于项目的算法一般在性能上要优于基于用户的算法。 基于领域的推荐算法不足之处在于数据稀疏性等问题， 难以处理大数据量下的即时结果。因此提出了基于模型的协同过滤推荐算法。 基于模型的协同过滤(model-based CF)基于模型的协同过滤推荐(model-based CF) 是采用机器学习或数据挖掘等算法， 用训练数据来学习识别复杂模式， 从而得到学习模型， 然后基于学习模型在数据集上进行智能预测。主要有以下模型: 隐语义模型 (latent semantic CF models)&#x2F;矩阵分解模型(matrix factorization) 贝叶斯信念网协同过滤模型(Bayesian belief nets CF models) 聚类协同过滤模型 (clustering CF models) 概率因素模型(probabilistic factor models) 基于内容的算法CF算法看起来很好很强大，通过改进也能克服各种缺点。那么问题来了，假如我是个《指环王》的忠实读者，我买过一本《双塔奇兵》，这时库里新进了第三部: 《王者归来》，那么显然我会很感兴趣。然而基于之前的算法，无论是用户评分还是书名的检索都不太好使，于是基于内容的推荐算法呼之欲出。 这种推荐仅需要得到两类信息: 项目特征的描述和用户过去的喜好信息。 利用领域专家给项目打标签的方法， 也即传统的分类系统(Taxonomy)， 另一种是用户给项目打标签， 也即大众分类系统 (Folksolomy)。 这种推荐系统的优点在于: 易于实现，不需要用户数据因此不存在稀疏性和冷启动问题。 基于物品本身特征推荐，因此不存在过度推荐热门的问题。 然而，缺点在于抽取的特征既要保证准确性又要具有一定的实际意义，否则很难保证推荐结果的相关性。豆瓣网采用人工维护tag的策略，依靠用户去维护内容的tag的准确性。 基于关联规则的推荐基于关联规则的推荐更常见于电子商务系统中，并且也被证明行之有效。其实际的意义为购买了一些物品的用户更倾向于购买另一些物品。基于关联规则的推荐系统的首要目标是挖掘出关联规则，也就是那些同时被很多用户购买的物品集合，这些集合内的物品可以相互进行推荐。目前关联规则挖掘算法主要从Apriori和FP-Growth两个算法发展演变而来。 基于关联规则的推荐系统一般转化率较高，因为当用户已经购买了频繁集合中的若干项目后，购买该频繁集合中其他项目的可能性更高。该机制的缺点在于: 计算量较大，但是可以离线计算，因此影响不大。 由于采用用户数据，不可避免的存在冷启动和稀疏性问题。 存在热门项目容易被过度推荐的问题。 基于效用推荐基于效用的推荐(Utility-based Recommendation)是建立在对用户使用项目的效用情况上计算的，其核心问题是怎么样为每一个用户去创建一个效用函数，因此，用户资料模型很大程度上是由系统所采用的效用函数决定的。基于效用推荐的好处是它能把非产品的属性，如提供商的可靠性(Vendor Reliability)和产品的可得性(Product Availability)等考虑到效用计算中。 基于知识推荐基于知识的推荐(Knowledge-based Recommendation)在某种程度是可以看成是一种推理(Inference)技术，它不是建立在用户需要和偏好基础上推荐的。基于知识的方法因它们所用的功能知识不同而有明显区别。效用知识(Functional Knowledge)是一种关于一个项目如何满足某一特定用户的知识，因此能解释需要和推荐的关系，所以用户资料可以是任何能支持推理的知识结构，它可以是用户已经规范化的查询，也可以是一个更详细的用户需要的表示。 组合推荐算法由于各种推荐方法都有优缺点，所以在实际中，组合推荐(Hybrid Recommendation)经常被采用。研究和应用最多的是内容推荐和协同过滤推荐的组合。最简单的做法就是分别用基于内容的方法和协同过滤推荐方法去产生一个推荐预测结果，然后用某方法组合其结果。尽管从理论上有很多种推荐组合方法，但在某一具体问题中并不见得都有效，组合推荐一个最重要原则就是通过组合后要能避免或弥补各自推荐技术的弱点。 在组合方式上，有研究人员提出了七种组合思路: 加权(Weight): 加权多种推荐技术结果。 变换(Switch): 根据问题背景和实际情况或要求决定变换采用不同的推荐技术。 混合(Mixed): 同时采用多种推荐技术给出多种推荐结果为用户提供参考。 特征组合(Feature combination): 组合来自不同推荐数据源的特征被另一种推荐算法所采用。 层叠(Cascade): 先用一种推荐技术产生一种粗糙的推荐结果，第二种推荐技术在此推荐结果的基础上进一步作出更精确的推荐。 特征扩充(Feature augmentation): 一种技术产生附加的特征信息嵌入到另一种推荐技术的特征输入中。 元级别(Meta-level): 用一种推荐方法产生的模型作为另一种推荐方法的输入。 推荐算法的评估当推荐算法完成后，怎样来评估这个算法的效果? CTR(点击率)、CVR(转化率)、停留时间等都是很直观的数据。在完成算法后，可以通过线下计算算法的RMSE(均方根误差)或者线上进行ABTest来对比效果。 推荐算法的改进策略用户画像是最近经常被提及的一个名词，引入用户画像可以为推荐系统带来很多改进的余地，比如: 打通公司各大业务平台，通过获取其他平台的用户数据，彻底解决冷启动问题； 在不同设备上同步用户数据，包括QQID、设备号、手机号等； 丰富用户的人口属性，包括年龄、职业、地域等； 更完善的用户兴趣状态，方便生成用户标签和匹配内容。 另外，公司的优势——社交平台也是一个很好利用的地方。利用用户的社交网络，可以很方便地通过用户的好友、兴趣群的成员等更快捷地找到相似用户以及用户可能感兴趣的内容，提高推荐的准确度。 业界一些推荐系统Yahoo Resarch2011推荐系统论坛中，来自Yahoo！的Yehuda Koren分享了他对于互联网中推荐系统的经验, 他简单介绍了目前广泛流行的协同过滤推荐机制；另外分析了一些推荐系统中值得注意的一些问题: Bias Matters 在实际的应用中，用户并不是随机地选择物品去打分，而是只选择那些和他们兴趣相关的物品打分，绝大多数用户往往忽略了去给那些没有兴趣的物品打分。Koren通过分析Netflix Prize数据，Koren发现用户对视频的评分变化中，Bias可以解释其中的33%，而个性化只能解释其中的10%，剩下的57%暂时还得不到解释。 Eliciting user feedback Koren的目标是解决推荐系统的cold-start问题，例如，Yahoo！ Movie中，对于新用户，很难预测他们的喜好(对视频的评分)。那么，可以选一些视频让新用户打分，从而获取他们的兴趣数据。在此过程中，使用了决策树模型来引导用户评分，可以用尽量少的视频，最大程度地了解用户兴趣。 Estimating confidence in recommendations 在推荐系统中，我们需要对被推荐物品的可信度进行估计，从而得出更为可信的物品来进行推荐。Koren在这里提出了基于概率的可信度计算方法，也就是根据对评分(用户对物品)的概率预测，然后利用熵，标准方差，或是Gini不纯度等概率分布来对物品可信度进行评估。 淘宝推荐系统淘宝推荐系统的目标就是要为各个产品提供商品，店铺，人，类目属性各种维度的推荐。它的核心就是以类目属性和社会属性为纽带，将人，商品和店铺建立起联系。 淘宝的宝贝推荐原则: 基于内容的和关联规则 全网优质宝贝算分 根据推荐属性筛选TOP 基于推荐属性的关联关系 采用搜索引擎存储和检索优质宝贝 加入个性化用户信息 根据用户的购买和收藏记录产生可推荐的关联规则。对优质宝贝的算分需要考虑商品的相关属性，包括描述，评价，名称，违规，收藏人气，累计销量，UV，以及PV等等。此外，推荐系统根据用户的浏览，收藏，购买行为以及反馈信息，在Hadoop上来计算用户带权重的标签，用于进行个性化推荐。 在个性化推荐之上，淘宝还实现了基于内容的广告投放。由于个性化推荐出来的物品是用户所感兴趣的，可以想象，基于此之上的广告投放也应该会行之有效。 众所周知，淘宝具有海量的数据和商品问题，这里列举了淘宝数据的一些参数: 超过8亿种在线商品，100万产品，4万属性，等等。在淘宝实现推荐系统可能遇到的各种各样的难题，其中有: 商品种类繁多，生命周期短，很难及时收集到足够多的点击或购买数据，这使得基于用户行为的推荐方法，比如基于物品的推荐方法，发挥空间有限。 因为商品是由卖家而非网站登记的，数据的规范性差，这又给基于内容的推荐带来了很大的困难。 8亿种商品中，重复的商品种类应该非常多，需要尽量避免推荐重复种类的商品给用户，但在数据规范性差、区分度差的情况下，如何归并重复商品种类，这本身也是个很大的难题。 大多数推荐系统只需要考虑如何满足买家的需求，在淘宝，还要考虑卖家的需求。 豆瓣的推荐引擎 - 豆瓣猜豆瓣网在国内互联网行业美誉度很高，这是一家以帮助用户发现未知事物为己任的公司。它的“豆瓣猜”是一种个性化的推荐，其背后采用了基于用户的协同过滤技术。那么，豆瓣猜是如何向我们推荐产品的呢? 首先，确定什么样的产品适合推荐? 豆瓣猜提出选择”具有媒体性的产品 (Media Product)“来进行推荐，即选择多样、口味很重要、单位成本不重要，同时能够广泛传播 (InformationCascade)的产品；接着在对真实的数据集进行定量分析后，进一步得出，应该是条目增长相对稳定、能够快速获得用户反馈，数据稀疏性与条目多样性、时效性比较平衡的产品，才是适合推荐的产品。 其次，豆瓣网的推荐引擎面对高成长性的挑战，通过降低存储空间，近似算法与分布式计算的设计，来实现对基于用户的协同过滤推荐系统的线性扩展。 最后，针对当前推荐系统面临的问题，包括倾向于给出平庸的推荐，有信息无结构，以及缺乏对用户的持续关注等黑盒推荐问题。豆瓣提出了分为 Prediction，Forecasting，Recommendation 三个阶段的下一代推荐系统，并探讨了一种下一代推荐引擎的构想——基于用户行为模型的、有记忆的、可进化的系统。 Hulu的个性化推荐Hulu是一家美国的视频网站，它是由美国国家广播环球公司(NBC Universal)和福克斯广播公司(Fox)在2007年3月共同投资建立的。在美国，Hulu已是最受欢迎的视频网站之一。它拥有超过250个渠道合作伙伴，超过600个顶级广告客户，3千万的用户，3亿的视频，以及11亿的视频广告。广告是衡量视频网站成功与否的一个重要标准。事实证明，Hulu的广告效果非常好，若以每千人为单位对广告计费，Hulu的所得比电视台在黄金时段所得还高。那么，是什么让Hulu取得了这样的成功呢? 通过对视频和用户特点的分析，Hulu根据用户的个人信息，行为模型和反馈，设计出一个混合的个性化推荐系统。它包含了基于物品的协同过滤机制，基于内容的推荐，基于人口统计的推荐，从用户行为中提炼出来的主题模型，以及根据用户反馈信息对推荐系统的优化，等等。此个性化推荐系统也进而成为了一个产品，用于给用户推荐视频。这个产品通过问答的形式，与用户进行交互，获取用户的个人喜欢，进一步提高推荐的个性化。 Hulu把这种个性化推荐视频的思想放到了广告投放中，设计出了一套个性化广告推荐系统。那么，这种广告系统是如何实现个性化的呢? Hulu的用户对广告拥有一定控制权，在某些视频中你可以根据自己的喜好选择相应的广告，或者选择在开头看一段电影预告片来抵消广告。 Hulu收集用户对广告的反馈意见(评分)，例如，某个广告是否对收看用户有用? 根据人口统计的信息，来投放广告。例如，分析Hulu用户的年龄，性别特征来同方不同的视频及广告。 根据用户的行为模式，进一步增加广告投放的准确性。 推荐算法展望从大数据的4V角度看， 主要的挑战及未来研究方向有以下几个方面: Volume(数据规模)。 数据量巨大加剧了数据稀疏性问题和长尾(long tail)问题。 在推荐系统中， 可获得的已打分数目通常远小于需要预测的打分数目。常用的数据集都非常稀疏， 当评分矩阵达到某种程度之后， 相比标准的协同过滤技术， 推荐质量会有所下降， 而且距离关系的计算代价很高， 很难实际应用到大规模评分数据上。 长尾是指那些原来不受到重视的销量小但种类多的产品或服务由于总量巨大， 累积起来的总收益超过主流产品的现象。 Variety (数据类型多样)。推荐系统可使用的数据复杂繁多， 如社交网络里面的信息、 地点位置信息和其他上下文感知信息都考虑进来， 不但数据量 增加， 计算复杂度亦会成倍增加。 Value (价值)。大数据本身的价值密度低， 但价值巨大。对推荐系统而言， 对用户兴趣建模， 并将用户可能感兴趣的项目推荐给他， 这里的项目相对用户而言， 是有价值的项目(数据)。 Velocity(时效性)。推荐系统对时效性要求较高， 想真正捕获最优的推荐机会， 时效性非常重要。如何将海量的用户数据应用到实时的用户交互中以提高用户体验， 这就涉及到推荐系统可扩展性(scalability)问题。 参考文章 https://www.cnblogs.com/csxf/p/3600041.html http://blog.csdn.net/u014605728/article/details/51274814 https://blog.csdn.net/wdr2003/article/details/80248148 https://blog.csdn.net/weixin_30912051/article/details/99331931 https://blog.csdn.net/fyq201749/article/details/81026950 https://blog.csdn.net/u012223913/article/details/52807717","tags":["算法","推荐算法"],"categories":["算法","推荐算法"]},{"title":"24.负载均衡算法 - 汇总","path":"/2023/12/28/24-负载均衡算法-汇总/","content":"本文主要介绍常用的负载均衡算法和Nginx中支持的负载均衡算法。 常见的负载均衡算法常见的负载均衡算法包含: 轮询法(Round Robin) 加权轮询法(Weight Round Robin) 平滑加权轮询法(Smooth Weight Round Robin) 随机法(Random) 加权随机法(Weight Random) 源地址哈希法(Hash) 最小连接数法(Least Connections) 轮询法(Round Robin)将请求按顺序轮流地分配到后端服务器上，它均衡地对待后端的每一台服务器，而不关心服务器实际的连接数和当前的系统负载。 加权轮询法(Weight Round Robin)不同的后端服务器可能机器的配置和当前系统的负载并不相同，因此它们的抗压能力也不相同。给配置高、负载低的机器配置更高的权重，让其处理更多的请；而配置低、负载高的机器，给其分配较低的权重，降低其系统负载，加权轮询能很好地处理这一问题，并将请求顺序且按照权重分配到后端。 随机法(Random)通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。由概率统计理论可以得知，随着客户端调用服务端的次数增多，其实际效果越来越接近于平均分配调用量到后端的每一台服务器，也就是轮询的结果。 加权随机法(Weight Random)与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。 源地址哈希法(Hash)源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客服端要访问服务器的序号。采用源地址哈希法进行负载均衡，同一IP地址的客户端，当后端服务器列表不变时，它每次都会映射到同一台后端服务器进行访问。 最小连接数法(Least Connections)最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。 Nginx的5种负载均衡算法轮询法(Round Robin)(默认)每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 加权轮询法(Weight Round Robin)- weight指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 例如: 123upstream bakend &#123; server 192.168.0.14 weight=10; server 192.168.0.15 weight=10; 源地址哈希法(Hash)- ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 例如: 12345upstream bakend &#123; ip_hash; server 192.168.0.14:88; server 192.168.0.15:80; &#125; fair(第三方)按后端服务器的响应时间来分配请求，响应时间短的优先分配。 12345upstream backend &#123; server server1; server server2; fair; &#125; url_hash(第三方)按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 例: 在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。 123456upstream backend &#123; server squid1:3128; server squid2:3128; hash $request_uri; hash_method crc32; &#125; tips: 1234567upstream bakend&#123;#定义负载均衡设备的Ip及设备状态 ip_hash; server 127.0.0.1:9090 down; server 127.0.0.1:8080 weight=2; server 127.0.0.1:6060; server 127.0.0.1:7070 backup; &#125; 在需要使用负载均衡的server中增加 1proxy_pass http://bakend/; 每个设备的状态设置为: down 表示单前的server暂时不参与负载 weight 默认为1.weight越大，负载的权重就越大。 max_fails : 允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误 fail_timeout:max_fails次失败后，暂停的时间。 backup: 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。 nginx支持同时设置多组的负载均衡，用来给不用的server来使用。 client_body_in_file_only: 设置为On，可以讲client post过来的数据记录到文件中用来做debug。 client_body_temp_path: 设置记录文件的目录，可以设置最多3层目录。 location: 对URL进行匹配，可以进行重定向或者进行新的代理，负载均衡。 参考文章 https://blog.csdn.net/youanyyou/article/details/78990133 https://blog.csdn.net/claram/article/details/90265243","tags":["算法","负载均衡算法"],"categories":["算法","负载均衡算法"]},{"title":"23.分布式算法 - Snowflake算法","path":"/2023/12/28/23-分布式算法-Snowflake算法/","content":"Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。为什么如此重要？因为它提供了一种ID生成及生成的思路，当然这种方案就是需要考虑时钟回拨的问题以及做一些 buffer的缓冲设计提高性能。 雪花算法-SnowflakeSnowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。而 Java中64bit的整数是Long类型，所以在 Java 中 SnowFlake 算法生成的 ID 就是 long 来存储的。 第1位占用1bit，其值始终是0，可看做是符号位不使用。 第2位开始的41位是时间戳，41-bit位可表示2^41个数，每个数代表毫秒，那么雪花算法可用的时间年限是(1L&lt;&lt;41)/(1000L360024*365)&#x3D;69 年的时间。 中间的10-bit位可表示机器数，即2^10 &#x3D; 1024台机器，但是一般情况下我们不会部署这么台机器。如果我们对IDC（互联网数据中心）有需求，还可以将 10-bit 分 5-bit 给 IDC，分5-bit给工作机器。这样就可以表示32个IDC，每个IDC下可以有32台机器，具体的划分可以根据自身需求定义。 最后12-bit位是自增序列，可表示2^12 &#x3D; 4096个数。 这样的划分之后相当于在一毫秒一个数据中心的一台机器上可产生4096个有序的不重复的ID。但是我们 IDC 和机器数肯定不止一个，所以毫秒内能生成的有序ID数是翻倍的。 Snowflake 的Twitter官方原版是用Scala写的，对Scala语言有研究的同学可以去阅读下，以下是 Java 版本的写法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170package com.jajian.demo.distribute;/** * Twitter_Snowflake&lt;br&gt; * SnowFlake的结构如下(每部分用-分开):&lt;br&gt; * 0 - 0000000000 0000000000 0000000000 0000000000 0 - 00000 - 00000 - 000000000000 &lt;br&gt; * 1位标识，由于long基本类型在Java中是带符号的，最高位是符号位，正数是0，负数是1，所以id一般是正数，最高位是0&lt;br&gt; * 41位时间截(毫秒级)，注意，41位时间截不是存储当前时间的时间截，而是存储时间截的差值（当前时间截 - 开始时间截) * 得到的值），这里的的开始时间截，一般是我们的id生成器开始使用的时间，由我们程序来指定的（如下下面程序IdWorker类的startTime属性）。41位的时间截，可以使用69年，年T = (1L &lt;&lt; 41) / (1000L * 60 * 60 * 24 * 365) = 69&lt;br&gt; * 10位的数据机器位，可以部署在1024个节点，包括5位datacenterId和5位workerId&lt;br&gt; * 12位序列，毫秒内的计数，12位的计数顺序号支持每个节点每毫秒(同一机器，同一时间截)产生4096个ID序号&lt;br&gt; * 加起来刚好64位，为一个Long型。&lt;br&gt; * SnowFlake的优点是，整体上按照时间自增排序，并且整个分布式系统内不会产生ID碰撞(由数据中心ID和机器ID作区分)，并且效率较高，经测试，SnowFlake每秒能够产生26万ID左右。 */public class SnowflakeDistributeId &#123; // ==============================Fields=========================================== /** * 开始时间截 (2015-01-01) */ private final long twepoch = 1420041600000L; /** * 机器id所占的位数 */ private final long workerIdBits = 5L; /** * 数据标识id所占的位数 */ private final long datacenterIdBits = 5L; /** * 支持的最大机器id，结果是31 (这个移位算法可以很快的计算出几位二进制数所能表示的最大十进制数) */ private final long maxWorkerId = -1L ^ (-1L &lt;&lt; workerIdBits); /** * 支持的最大数据标识id，结果是31 */ private final long maxDatacenterId = -1L ^ (-1L &lt;&lt; datacenterIdBits); /** * 序列在id中占的位数 */ private final long sequenceBits = 12L; /** * 机器ID向左移12位 */ private final long workerIdShift = sequenceBits; /** * 数据标识id向左移17位(12+5) */ private final long datacenterIdShift = sequenceBits + workerIdBits; /** * 时间截向左移22位(5+5+12) */ private final long timestampLeftShift = sequenceBits + workerIdBits + datacenterIdBits; /** * 生成序列的掩码，这里为4095 (0b111111111111=0xfff=4095) */ private final long sequenceMask = -1L ^ (-1L &lt;&lt; sequenceBits); /** * 工作机器ID(0~31) */ private long workerId; /** * 数据中心ID(0~31) */ private long datacenterId; /** * 毫秒内序列(0~4095) */ private long sequence = 0L; /** * 上次生成ID的时间截 */ private long lastTimestamp = -1L; //==============================Constructors===================================== /** * 构造函数 * * @param workerId 工作ID (0~31) * @param datacenterId 数据中心ID (0~31) */ public SnowflakeDistributeId(long workerId, long datacenterId) &#123; if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;worker Id can&#x27;t be greater than %d or less than 0&quot;, maxWorkerId)); &#125; if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123; throw new IllegalArgumentException(String.format(&quot;datacenter Id can&#x27;t be greater than %d or less than 0&quot;, maxDatacenterId)); &#125; this.workerId = workerId; this.datacenterId = datacenterId; &#125; // ==============================Methods========================================== /** * 获得下一个ID (该方法是线程安全的) * * @return SnowflakeId */ public synchronized long nextId() &#123; long timestamp = timeGen(); //如果当前时间小于上一次ID生成的时间戳，说明系统时钟回退过这个时候应当抛出异常 if (timestamp &lt; lastTimestamp) &#123; throw new RuntimeException( String.format(&quot;Clock moved backwards. Refusing to generate id for %d milliseconds&quot;, lastTimestamp - timestamp)); &#125; //如果是同一时间生成的，则进行毫秒内序列 if (lastTimestamp == timestamp) &#123; sequence = (sequence + 1) &amp; sequenceMask; //毫秒内序列溢出 if (sequence == 0) &#123; //阻塞到下一个毫秒,获得新的时间戳 timestamp = tilNextMillis(lastTimestamp); &#125; &#125; //时间戳改变，毫秒内序列重置 else &#123; sequence = 0L; &#125; //上次生成ID的时间截 lastTimestamp = timestamp; //移位并通过或运算拼到一起组成64位的ID return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) // | (datacenterId &lt;&lt; datacenterIdShift) // | (workerId &lt;&lt; workerIdShift) // | sequence; &#125; /** * 阻塞到下一个毫秒，直到获得新的时间戳 * * @param lastTimestamp 上次生成ID的时间截 * @return 当前时间戳 */ protected long tilNextMillis(long lastTimestamp) &#123; long timestamp = timeGen(); while (timestamp &lt;= lastTimestamp) &#123; timestamp = timeGen(); &#125; return timestamp; &#125; /** * 返回以毫秒为单位的当前时间 * * @return 当前时间(毫秒) */ protected long timeGen() &#123; return System.currentTimeMillis(); &#125;&#125; 测试的代码如下 12345678public static void main(String[] args) &#123; SnowflakeDistributeId idWorker = new SnowflakeDistributeId(0, 0); for (int i = 0; i &lt; 1000; i++) &#123; long id = idWorker.nextId();// System.out.println(Long.toBinaryString(id)); System.out.println(id); &#125;&#125; 雪花算法提供了一个很好的设计思想，雪花算法生成的ID是趋势递增，不依赖数据库等第三方系统，以服务的方式部署，稳定性更高，生成ID的性能也是非常高的，而且可以根据自身业务特性分配bit位，非常灵活。 但是雪花算法强依赖机器时钟，如果机器上时钟回拨，会导致发号重复或者服务会处于不可用状态。如果恰巧回退前生成过一些ID，而时间回退后，生成的ID就有可能重复。官方对于此并没有给出解决方案，而是简单的抛错处理，这样会造成在时间被追回之前的这段时间服务不可用。 很多其他类雪花算法也是在此思想上的设计然后改进规避它的缺陷，后面介绍的百度 UidGenerator 和 美团分布式ID生成系统 Leaf 中snowflake模式都是在 snowflake 的基础上演进出来的。 其它相关算法在如下文章中已经包含了所有主流的全局唯一ID实现方案： 分布式系统 - 全局唯一ID实现方案 这里给出相关的链接： 为什么需要全局唯一ID UUID 数据库生成 使用redis实现 雪花算法-Snowflake 百度-UidGenerator DefaultUidGenerator 实现 CachedUidGenerator 实现 美团Leaf Leaf-segment 数据库方案 Leaf-snowflake方案 Mist 薄雾算法","tags":["算法","分布式算法","Snowflake算法"],"categories":["算法","分布式算法"]},{"title":"22.分布式算法 - ZAB算法","path":"/2023/12/28/22-分布式算法-ZAB算法/","content":"ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）, 它应该是所有一致性协议中生产环境中应用最多的了。为什么呢？因为它是为 Zookeeper 设计的分布式一致性协议！ 什么是 ZAB 协议？ ZAB 协议介绍 ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）。 Zookeeper 是一个为分布式应用提供高效且可靠的分布式协调服务。在解决分布式一致性方面，Zookeeper 并没有使用 Paxos ，而是采用了 ZAB 协议。 ZAB 协议定义：ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 崩溃恢复 和 原子广播 协议。下面我们会重点讲这两个东西。 基于该协议，Zookeeper 实现了一种 主备模式 的系统架构来保持集群中各个副本之间数据一致性。具体如下图所示： 上图显示了 Zookeeper 如何处理集群中的数据。所有客户端写入数据都是写入到 主进程（称为 Leader）中，然后，由 Leader 复制到备份进程（称为 Follower）中。从而保证数据一致性。从设计上看，和 Raft 类似。 那么复制过程又是如何的呢？复制过程类似 2PC，ZAB 只需要 Follower 有一半以上返回 Ack 信息就可以执行提交，大大减小了同步阻塞。也提高了可用性。 简单介绍完，开始重点介绍 消息广播 和 崩溃恢复。整个 Zookeeper 就是在这两个模式之间切换。 简而言之，当 Leader 服务可以正常使用，就进入消息广播模式，当 Leader 不可用时，则进入崩溃恢复模式。 消息广播ZAB 协议的消息广播过程使用的是一个原子广播协议，类似一个 二阶段提交过程。对于客户端发送的写请求，全部由 Leader 接收，Leader 将请求封装成一个事务 Proposal，将其发送给所有 Follwer ，然后，根据所有 Follwer 的反馈，如果超过半数成功响应，则执行 commit 操作（先提交自己，再发送 commit 给所有 Follwer）。 基本上，整个广播流程分为 3 步骤： 1.将数据都复制到 Follwer 中 等待 Follwer 回应 Ack，最低超过半数即成功 当超过半数成功回应，则执行 commit ，同时提交自己 通过以上 3 个步骤，就能够保持集群之间数据的一致性。实际上，在 Leader 和 Follwer 之间还有一个消息队列，用来解耦他们之间的耦合，避免同步，实现异步解耦。 还有一些细节： Leader 在收到客户端请求之后，会将这个请求封装成一个事务，并给这个事务分配一个全局递增的唯一 ID，称为事务ID（ZXID），ZAB 兮协议需要保证事务的顺序，因此必须将每一个事务按照 ZXID 进行先后排序然后处理。 在 Leader 和 Follwer 之间还有一个消息队列，用来解耦他们之间的耦合，解除同步阻塞。 zookeeper集群中为保证任何所有进程能够有序的顺序执行，只能是 Leader 服务器接受写请求，即使是 Follower 服务器接受到客户端的请求，也会转发到 Leader 服务器进行处理。 实际上，这是一种简化版本的 2PC，不能解决单点问题。等会我们会讲述 ZAB 如何解决单点问题（即 Leader 崩溃问题）。 崩溃恢复刚刚我们说消息广播过程中，Leader 崩溃怎么办？还能保证数据一致吗？如果 Leader 先本地提交了，然后 commit 请求没有发送出去，怎么办？ 实际上，当 Leader 崩溃，即进入我们开头所说的崩溃恢复模式（崩溃即：Leader 失去与过半 Follwer 的联系）。下面来详细讲述。 假设1：Leader 在复制数据给所有 Follwer 之后崩溃，怎么办？ 假设2：Leader 在收到 Ack 并提交了自己，同时发送了部分 commit 出去之后崩溃怎么办？ 针对这些问题，ZAB 定义了 2 个原则： ZAB 协议确保那些已经在 Leader 提交的事务最终会被所有服务器提交。 ZAB 协议确保丢弃那些只在 Leader 提出&#x2F;复制，但没有提交的事务。 所以，ZAB 设计了下面这样一个选举算法：能够确保提交已经被 Leader 提交的事务，同时丢弃已经被跳过的事务。 针对这个要求，如果让 Leader 选举算法能够保证新选举出来的 Leader 服务器拥有集群总所有机器编号（即 ZXID 最大）的事务，那么就能够保证这个新选举出来的 Leader 一定具有所有已经提交的提案。 而且这么做有一个好处是：可以省去 Leader 服务器检查事务的提交和丢弃工作的这一步操作。 这样，我们刚刚假设的两个问题便能够解决。假设 1 最终会丢弃调用没有提交的数据，假设 2 最终会同步所有服务器的数据。这个时候，就引出了一个问题，如何同步？ 数据同步当崩溃恢复之后，需要在正式工作之前（接收客户端请求），Leader 服务器首先确认事务是否都已经被过半的 Follwer 提交了，即是否完成了数据同步。目的是为了保持数据一致。 当所有的 Follwer 服务器都成功同步之后，Leader 会将这些服务器加入到可用服务器列表中。 实际上，Leader 服务器处理或丢弃事务都是依赖着 ZXID 的，那么这个 ZXID 如何生成呢？ 答：在 ZAB 协议的事务编号 ZXID 设计中，ZXID 是一个 64 位的数字，其中低 32 位可以看作是一个简单的递增的计数器，针对客户端的每一个事务请求，Leader 都会产生一个新的事务 Proposal 并对该计数器进行 + 1 操作。 而高 32 位则代表了 Leader 服务器上取出本地日志中最大事务 Proposal 的 ZXID，并从该 ZXID 中解析出对应的 epoch 值，然后再对这个值加一。 高 32 位代表了每代 Leader 的唯一性，低 32 代表了每代 Leader 中事务的唯一性。同时，也能让 Follwer 通过高 32 位识别不同的 Leader。简化了数据恢复流程。 基于这样的策略：当 Follower 链接上 Leader 之后，Leader 服务器会根据自己服务器上最后被提交的 ZXID 和 Follower 上的 ZXID 进行比对，比对结果要么回滚，要么和 Leader 同步。 总结ZAB 协议和我们之前看的 Raft 协议实际上是有相似之处的，比如都有一个 Leader，用来保证一致性（Paxos 并没有使用 Leader 机制保证一致性）。再有采取过半即成功的机制保证服务可用（实际上 Paxos 和 Raft 都是这么做的）。 ZAB 让整个 Zookeeper 集群在两个模式之间转换，消息广播和崩溃恢复，消息广播可以说是一个简化版本的 2PC，通过崩溃恢复解决了 2PC 的单点问题，通过队列解决了 2PC 的同步阻塞问题。 而支持崩溃恢复后数据准确性的就是数据同步了，数据同步基于事务的 ZXID 的唯一性来保证。通过 + 1 操作可以辨别事务的先后顺序。 参考文章本文主要转载自如下，文章内容略有调整： 作者：莫那·鲁道 原文链接：https://www.cnblogs.com/stateis0/p/9062133.html PS：转载请一并附带原出处 其它我还推荐你看下如下相关的较为优秀的文章： Zookeeper的Leader选举在新窗口打开 https://blog.csdn.net/a724888/article/details/80757503 https://www.cnblogs.com/stateis0/p/9062133.html","tags":["算法","分布式算法","ZAB算法"],"categories":["算法","分布式算法"]},{"title":"21.分布式算法-Gossip 协议详解","path":"/2023/12/28/21-分布式算法-Gossip-协议详解/","content":"于是，分散式发散消息 的 Gossip 协议 就诞生了。 Gossip 协议介绍Gossip 直译过来就是闲话、流言蜚语的意思。流言蜚语有什么特点呢？容易被传播且传播速度还快，你传我我传他，然后大家都知道了。 Gossip 协议 也叫 Epidemic 协议（流行病协议）或者 Epidemic propagation 算法（疫情传播算法），别名很多。不过，这些名字的特点都具有 随机传播特性 （联想一下病毒传播、癌细胞扩散等生活中常见的情景），这也正是 Gossip 协议最主要的特点。 Gossip 协议最早是在 ACM 上的一篇 1987 年发表的论文 《Epidemic Algorithms for Replicated Database Maintenance》中被提出的。根据论文标题，我们大概就能知道 Gossip 协议当时提出的主要应用是在分布式数据库系统中各个副本节点同步数据。 正如 Gossip 协议其名一样，这是一种随机且带有传染性的方式将信息传播到整个网络中，并在一定时间内，使得系统内的所有节点数据一致。 在 Gossip 协议下，没有所谓的中心节点，每个节点周期性地随机找一个节点互相同步彼此的信息，理论上来说，各个节点的状态最终会保持一致。 下面我们来对 Gossip 协议的定义做一个总结：Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。 Gossip 协议应用NoSQL 数据库 Redis 和 Apache Cassandra、服务网格解决方案 Consul 等知名项目都用到了 Gossip 协议，学习 Gossip 协议有助于我们搞清很多技术的底层原理。 我们这里以 Redis Cluster 为例说明 Gossip 协议的实际应用。 我们经常使用的分布式缓存 Redis 的官方集群解决方案（3.0 版本引入） Redis Cluster 就是基于 Gossip 协议来实现集群中各个节点数据的最终一致性。 Redis Cluster 是一个典型的分布式系统，分布式系统中的各个节点需要互相通信。既然要相互通信就要遵循一致的通信协议，Redis Cluster 中的各个节点基于 Gossip 协议 来进行通信共享信息，每个 Redis 节点都维护了一份集群的状态信息。 Redis Cluster 的节点之间会相互发送多种 Gossip 消息： MEET：在 Redis Cluster 中的某个 Redis 节点上执行 CLUSTER MEET ip port 命令，可以向指定的 Redis 节点发送一条 MEET 信息，用于将其添加进 Redis Cluster 成为新的 Redis 节点。 PING&#x2F;PONG：Redis Cluster 中的节点都会定时地向其他节点发送 PING 消息，来交换各个节点状态信息，检查各个节点状态，包括在线状态、疑似下线状态 PFAIL 和已下线状态 FAIL。 FAIL：Redis Cluster 中的节点 A 发现 B 节点 PFAIL ，并且在下线报告的有效期限内集群中半数以上的节点将 B 节点标记为 PFAIL，节点 A 就会向集群广播一条 FAIL 消息，通知其他节点将故障节点 B 标记为 FAIL 。 …… 下图就是主从架构的 Redis Cluster 的示意图，图中的虚线代表的就是各个节点之间使用 Gossip 进行通信 ，实线表示主从复制。 有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时可以自动切换。 关于 Redis Cluster 的详细介绍，可以查看这篇文章 Redis 集群详解(付费) 。 Gossip 协议消息传播模式Gossip 设计了两种可能的消息传播模式：反熵（Anti-Entropy） 和 传谣（Rumor-Mongering）。 反熵(Anti-entropy)根据维基百科： 熵的概念最早起源于物理学，用于度量一个热力学系统的混乱程度。熵最好理解为不确定性的量度而不是确定性的量度，因为越随机的信源的熵越大。 在这里，你可以把反熵中的熵了解为节点之间数据的混乱程度&#x2F;差异性，反熵就是指消除不同节点中数据的差异，提升节点间数据的相似度，从而降低熵值。 具体是如何反熵的呢？集群中的节点，每隔段时间就随机选择某个其他节点，然后通过互相交换自己的所有数据来消除两者之间的差异，实现数据的最终一致性。 在实现反熵的时候，主要有推、拉和推拉三种方式： 推方式，就是将自己的所有副本数据，推给对方，修复对方副本中的熵。 拉方式，就是拉取对方的所有副本数据，修复自己副本中的熵。 推拉就是同时修复自己副本和对方副本中的熵。 伪代码如下： 在我们实际应用场景中，一般不会采用随机的节点进行反熵，而是需要可以的设计一个闭环。这样的话，我们能够在一个确定的时间范围内实现各个节点数据的最终一致性，而不是基于随机的概率。像 InfluxDB 就是这样来实现反熵的。 节点 A 推送数据给节点 B，节点 B 获取到节点 A 中的最新数据。 节点 B 推送数据给 C，节点 C 获取到节点 A，B 中的最新数据。 节点 C 推送数据给 A，节点 A 获取到节点 B，C 中的最新数据。 节点 A 再推送数据给 B 形成闭环，这样节点 B 就获取到节点 C 中的最新数据。 虽然反熵很简单实用，但是，节点过多或者节点动态变化的话，反熵就不太适用了。这个时候，我们想要实现最终一致性就要靠 谣言传播(Rumor mongering) 。 谣言传播(Rumor mongering)谣言传播指的是分布式系统中的一个节点一旦有了新数据之后，就会变为活跃节点，活跃节点会周期性地联系其他节点向其发送新数据，直到所有的节点都存储了该新数据。 如下图所示（下图来自于INTRODUCTION TO GOSSIP 这篇文章）： 伪代码如下： 谣言传播比较适合节点数量比较多的情况，不过，这种模式下要尽量避免传播的信息包不能太大，避免网络消耗太大。 总结 反熵（Anti-Entropy）会传播节点的所有数据，而谣言传播（Rumor-Mongering）只会传播节点新增的数据。 我们一般会给反熵设计一个闭环。 谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景。 Gossip 协议优势和缺陷优势： 1、相比于其他分布式协议&#x2F;算法来说，Gossip 协议理解起来非常简单。 2、能够容忍网络上节点的随意地增加或者减少，宕机或者重启，因为 Gossip 协议下这些节点都是平等的，去中心化的。新增加或者重启的节点在理想情况下最终是一定会和其他节点的状态达到一致。 3、速度相对较快。节点数量比较多的情况下，扩散速度比一个主节点向其他节点传播信息要更快（多播）。 缺陷 : 1、消息需要通过多个传播的轮次才能传播到整个网络中，因此，必然会出现各节点状态不一致的情况。毕竟，Gossip 协议强调的是最终一致，至于达到各个节点的状态一致需要多长时间，谁也无从得知。 2、由于拜占庭将军问题，不允许存在恶意节点。 3、可能会出现消息冗余的问题。由于消息传播的随机性，同一个节点可能会重复收到相同的消息。 总结 Gossip 协议是一种允许在分布式系统中共享状态的通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员。 Gossip 协议被 Redis、Apache Cassandra、Consul 等项目应用。 谣言传播（Rumor-Mongering）比较适合节点数量比较多或者节点动态变化的场景。 参考 一万字详解 Redis Cluster Gossip 协议：https://segmentfault.com/a/1190000038373546 《分布式协议与算法实战》 《Redis 设计与实现》","tags":["算法","分布式算法","Gossip"],"categories":["算法","分布式算法"]},{"title":"20.分布式算法 - Raft算法","path":"/2023/12/28/20-分布式算法-Raft算法/","content":"Paxos是出了名的难懂，而Raft正是为了探索一种更易于理解的一致性算法而产生的。它的首要设计目的就是易于理解，所以在选主的冲突处理等方式上它都选择了非常简单明了的解决方案。 推荐阅读 提示 强烈推荐通过如下资料学习raft。 raft.github.io 这里面有一个Raft Visualization: In Search of an Understandable Consensus Algorithm 动画理解Raft神器 Raft算法简介不同于Paxos算法直接从分布式一致性问题出发推导出来，Raft算法则是从多副本状态机的角度提出，用于管理多副本状态机的日志复制。Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题: Leader选举(Leader election)、日志同步(Log replication)、安全性(Safety)、日志压缩(Log compaction)、成员变更(Membership change)等。同时，Raft算法使用了更强的假设来减少了需要考虑的状态，使之变的易于理解和实现。 角色Raft将系统中的角色分为领导者(Leader)、跟从者(Follower)和候选人(Candidate): Leader: 接受客户端请求，并向Follower同步请求日志，当日志同步到大多数节点上后告诉Follower提交日志。 Follower: 接受并持久化Leader同步的日志，在Leader告之日志可以提交之后，提交日志。 Candidate: Leader选举过程中的临时角色。 Raft要求系统在任意时刻最多只有一个Leader，正常工作期间只有Leader和Followers。 角色状态转换 Follower只响应其他服务器的请求。如果Follower超时没有收到Leader的消息，它会成为一个Candidate并且开始一次Leader选举。收到大多数服务器投票的Candidate会成为新的Leader。Leader在宕机之前会一直保持Leader的状态。 Raft算法将时间分为一个个的任期(term)，每一个term的开始都是Leader选举。在成功选举Leader之后，Leader会在整个term内管理整个集群。如果Leader选举失败，该term就会因为没有Leader而结束。 Raft算法子问题Raft实现了和Paxos相同的功能，它将一致性分解为多个子问题: Leader选举(Leader election)、日志同步(Log replication)、安全性(Safety)、日志压缩(Log compaction)、成员变更(Membership change)等 Leader选举Raft 使用心跳(heartbeat)触发Leader选举。当服务器启动时，初始化为Follower。Leader向所有Followers周期性发送heartbeat。如果Follower在选举超时时间内没有收到Leader的heartbeat，就会等待一段随机的时间后发起一次Leader选举。 Follower将其当前term加一然后转换为Candidate。它首先给自己投票并且给集群中的其他服务器发送 RequestVote RPC (RPC细节参见八、Raft算法总结)。结果有以下三种情况: 赢得了多数的选票，成功选举为Leader； 收到了Leader的消息，表示有其它服务器已经抢先当选了Leader； 没有服务器赢得多数的选票，Leader选举失败，等待选举时间超时后发起下一次选举。 选举出Leader后，Leader通过定期向所有Followers发送心跳信息维持其统治。若Follower一段时间未收到Leader的心跳则认为Leader可能已经挂了，再次发起Leader选举过程。 Raft保证选举出的Leader上一定具有最新的已提交的日志，这一点将在四、安全性中说明。 日志同步Leader选出后，就开始接收客户端的请求。Leader把请求作为日志条目(Log entries)加入到它的日志中，然后并行的向其他服务器发起 AppendEntries RPC (RPC细节参见八、Raft算法总结)复制日志条目。当这条日志被复制到大多数服务器上，Leader将这条日志应用到它的状态机并向客户端返回执行结果。 某些Followers可能没有成功的复制日志，Leader会无限的重试 AppendEntries RPC直到所有的Followers最终存储了所有的日志条目。 日志由有序编号(log index)的日志条目组成。每个日志条目包含它被创建时的任期号(term)，和用于状态机执行的命令。如果一个日志条目被复制到大多数服务器上，就被认为可以提交(commit)了。 Raft日志同步保证如下两点: 如果不同日志中的两个条目有着相同的索引和任期号，则它们所存储的命令是相同的。 如果不同日志中的两个条目有着相同的索引和任期号，则它们之前的所有条目都是完全一样的。 第一条特性源于Leader在一个term内在给定的一个log index最多创建一条日志条目，同时该条目在日志中的位置也从来不会改变。 第二条特性源于 AppendEntries 的一个简单的一致性检查。当发送一个 AppendEntries RPC 时，Leader会把新日志条目紧接着之前的条目的log index和term都包含在里面。如果Follower没有在它的日志中找到log index和term都相同的日志，它就会拒绝新的日志条目。 一般情况下，Leader和Followers的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，Leader崩溃可能会导致日志不一致: 旧的Leader可能没有完全复制完日志中的所有条目。 上图阐述了一些Followers可能和新的Leader日志不同的情况。一个Follower可能会丢失掉Leader上的一些条目，也有可能包含一些Leader没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。 Leader通过强制Followers复制它的日志来处理日志的不一致，Followers上的不一致的日志会被Leader的日志覆盖。 Leader为了使Followers的日志同自己的一致，Leader需要找到Followers同它的日志一致的地方，然后覆盖Followers在该位置之后的条目。 Leader会从后往前试，每次AppendEntries失败后尝试前一个日志条目，直到成功找到每个Follower的日志一致位点，然后向后逐条覆盖Followers在该位置之后的条目。 安全性Raft增加了如下两条限制以保证安全性: 拥有最新的已提交的log entry的Follower才有资格成为Leader。 这个保证是在RequestVote RPC中做的，Candidate在发送RequestVote RPC时，要带上自己的最后一条日志的term和log index，其他节点收到消息时，如果发现自己的日志比请求中携带的更新，则拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term更大，则term大的更新，如果term一样大，则log index更大的更新。 Leader只能推进commit index来提交当前term的已经复制到大多数服务器上的日志，旧term日志的提交要等到提交当前term的日志来间接提交(log index 小于 commit index的日志被间接提交)。 之所以要这样，是因为可能会出现已提交的日志又被覆盖的情况: 在阶段a，term为2，S1是Leader，且S1写入日志(term, index)为(2, 2)，并且日志被同步写入了S2； 在阶段b，S1离线，触发一次新的选主，此时S5被选为新的Leader，此时系统term为3，且写入了日志(term, index)为(3， 2); S5尚未将日志推送到Followers就离线了，进而触发了一次新的选主，而之前离线的S1经过重新上线后被选中变成Leader，此时系统term为4，此时S1会将自己的日志同步到Followers，按照上图就是将日志(2， 2)同步到了S3，而此时由于该日志已经被同步到了多数节点(S1, S2, S3)，因此，此时日志(2，2)可以被提交了。； 在阶段d，S1又下线了，触发一次选主，而S5有可能被选为新的Leader(这是因为S5可以满足作为主的一切条件: 1. term &#x3D; 5 &gt; 4，2. 最新的日志为(3，2)，比大多数节点(如S2&#x2F;S3&#x2F;S4的日志都新)，然后S5会将自己的日志更新到Followers，于是S2、S3中已经被提交的日志(2，2)被截断了。 增加上述限制后，即使日志(2，2)已经被大多数节点(S1、S2、S3)确认了，但是它不能被提交，因为它是来自之前term(2)的日志，直到S1在当前term(4)产生的日志(4， 4)被大多数Followers确认，S1方可提交日志(4，4)这条日志，当然，根据Raft定义，(4，4)之前的所有日志也会被提交。此时即使S1再下线，重新选主时S5不可能成为Leader，因为它没有包含大多数节点已经拥有的日志(4，4)。 日志压缩在实际的系统中，不能让日志无限增长，否则系统重启时需要花很长的时间进行回放，从而影响可用性。Raft采用对整个系统进行snapshot来解决，snapshot之前的日志都可以丢弃。 每个副本独立的对自己的系统状态进行snapshot，并且只能对已经提交的日志记录进行snapshot。 Snapshot中包含以下内容: 日志元数据。最后一条已提交的 log entry的 log index和term。这两个值在snapshot之后的第一条log entry的AppendEntries RPC的完整性检查的时候会被用上。 系统当前状态。 当Leader要发给某个日志落后太多的Follower的log entry被丢弃，Leader会将snapshot发给Follower。或者当新加进一台机器时，也会发送snapshot给它。发送snapshot使用InstalledSnapshot RPC。 做snapshot既不要做的太频繁，否则消耗磁盘带宽， 也不要做的太不频繁，否则一旦节点重启需要回放大量日志，影响可用性。推荐当日志达到某个固定的大小做一次snapshot。 做一次snapshot可能耗时过长，会影响正常日志同步。可以通过使用copy-on-write技术避免snapshot过程影响正常日志同步。 成员变更成员变更是在集群运行过程中副本发生变化，如增加&#x2F;减少副本数、节点替换等。 成员变更也是一个分布式一致性问题，既所有服务器对新成员达成一致。但是成员变更又有其特殊性，因为在成员变更的一致性达成的过程中，参与投票的进程会发生变化。 如果将成员变更当成一般的一致性问题，直接向Leader发送成员变更请求，Leader复制成员变更日志，达成多数派之后提交，各服务器提交成员变更日志后从旧成员配置(Cold)切换到新成员配置(Cnew)。 因为各个服务器提交成员变更日志的时刻可能不同，造成各个服务器从旧成员配置(Cold)切换到新成员配置(Cnew)的时刻不同。 成员变更不能影响服务的可用性，但是成员变更过程的某一时刻，可能出现在Cold和Cnew中同时存在两个不相交的多数派，进而可能选出两个Leader，形成不同的决议，破坏安全性。 由于成员变更的这一特殊性，成员变更不能当成一般的一致性问题去解决。 为了解决这一问题，Raft提出了两阶段的成员变更方法。集群先从旧成员配置Cold切换到一个过渡成员配置，称为共同一致(joint consensus)，共同一致是旧成员配置Cold和新成员配置Cnew的组合Cold U Cnew，一旦共同一致Cold U Cnew被提交，系统再切换到新成员配置Cnew。 Raft两阶段成员变更过程如下: Leader收到成员变更请求从Cold切成Cnew； eader在本地生成一个新的log entry，其内容是Cold∪Cnew，代表当前时刻新旧成员配置共存，写入本地日志，同时将该log entry复制至Cold∪Cnew中的所有副本。在此之后新的日志同步需要保证得到Cold和Cnew两个多数派的确认； Follower收到Cold∪Cnew的log entry后更新本地日志，并且此时就以该配置作为自己的成员配置； 如果Cold和Cnew中的两个多数派确认了Cold U Cnew这条日志，Leader就提交这条log entry； 接下来Leader生成一条新的log entry，其内容是新成员配置Cnew，同样将该log entry写入本地日志，同时复制到Follower上； Follower收到新成员配置Cnew后，将其写入日志，并且从此刻起，就以该配置作为自己的成员配置，并且如果发现自己不在Cnew这个成员配置中会自动退出； Leader收到Cnew的多数派确认后，表示成员变更成功，后续的日志只要得到Cnew多数派确认即可。Leader给客户端回复成员变更执行成功。 异常分析: 如果Leader的Cold U Cnew尚未推送到Follower，Leader就挂了，此后选出的新Leader并不包含这条日志，此时新Leader依然使用Cold作为自己的成员配置。 如果Leader的Cold U Cnew推送到大部分的Follower后就挂了，此后选出的新Leader可能是Cold也可能是Cnew中的某个Follower。 如果Leader在推送Cnew配置的过程中挂了，那么同样，新选出来的Leader可能是Cold也可能是Cnew中的某一个，此后客户端继续执行一次改变配置的命令即可。 如果大多数的Follower确认了Cnew这个消息后，那么接下来即使Leader挂了，新选出来的Leader肯定位于Cnew中。 两阶段成员变更比较通用且容易理解，但是实现比较复杂，同时两阶段的变更协议也会在一定程度上影响变更过程中的服务可用性，因此我们期望增强成员变更的限制，以简化操作流程。 两阶段成员变更，之所以分为两个阶段，是因为对Cold与Cnew的关系没有做任何假设，为了避免Cold和Cnew各自形成不相交的多数派选出两个Leader，才引入了两阶段方案。 如果增强成员变更的限制，假设Cold与Cnew任意的多数派交集不为空，这两个成员配置就无法各自形成多数派，那么成员变更方案就可能简化为一阶段。 那么如何限制Cold与Cnew，使之任意的多数派交集不为空呢? 方法就是每次成员变更只允许增加或删除一个成员。 可从数学上严格证明，只要每次只允许增加或删除一个成员，Cold与Cnew不可能形成两个不相交的多数派。 一阶段成员变更: 成员变更限制每次只能增加或删除一个成员(如果要变更多个成员，连续变更多次)。 成员变更由Leader发起，Cnew得到多数派确认后，返回客户端成员变更成功。 一次成员变更成功前不允许开始下一次成员变更，因此新任Leader在开始提供服务前要将自己本地保存的最新成员配置重新投票形成多数派确认。 Leader只要开始同步新成员配置，即可开始使用新的成员配置进行日志同步。 Raft与Multi-Paxos对比Raft与Multi-Paxos都是基于领导者的一致性算法，乍一看有很多地方相同，下面总结一下Raft与Multi-Paxos的异同。 Raft与Multi-Paxos中相似的概念: Raft与Multi-Paxos的不同: 参考文章 Raft算法详解","tags":["算法","分布式算法","Raft算法"],"categories":["算法","分布式算法"]},{"title":"19.分布式算法 - Paxos算法","path":"/2023/12/28/19-分布式算法-Paxos算法/","content":"Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性, 很多分布式一致性算法都由Paxos演变而来。 Paxos算法简介Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。 Paxos由Lamport于1998年在《The Part-Time Parliament》论文中首次公开，最初的描述使用希腊的一个小岛Paxos作为比喻，描述了Paxos小岛中通过决议的流程，并以此命名这个算法，但是这个描述理解起来比较有挑战性。后来在2001年，Lamport觉得同行不能理解他的幽默感，于是重新发表了朴实的算法描述版本《Paxos Made Simple》。 自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性。Google的很多大型分布式系统都采用了Paxos算法来解决分布式一致性问题，如Chubby、Megastore以及Spanner等。开源的ZooKeeper，以及MySQL 5.7推出的用来取代传统的主从复制的MySQL Group Replication等纷纷采用Paxos算法解决分布式一致性问题。 Basic Paxos算法实现Paxos算法解决的问题正是分布式一致性问题，即一个分布式系统中的各个进程如何就某个值(决议)达成一致。 Paxos算法运行在允许宕机故障的异步系统中，不要求可靠的消息传递，可容忍消息丢失、延迟、乱序以及重复。它利用大多数 (Majority) 机制保证了2F+1的容错能力，即2F+1个节点的系统最多允许F个节点同时出现故障。 一个或多个提议进程 (Proposer) 可以发起提案 (Proposal)，Paxos算法使所有提案中的某一个提案，在所有进程中达成一致。系统中的多数派同时认可该提案，即达成了一致。最多只针对一个确定的提案达成一致。 角色Paxos将系统中的角色分为提议者 (Proposer)，决策者 (Acceptor)，和最终决策学习者 (Learner): Proposer: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。 Acceptor: 参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。 Learner: 不参与决策，从Proposers&#x2F;Acceptors学习最新达成一致的提案(Value)。 在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。 可以理解为人大代表(Proposer)在人大向其它代表(Acceptors)提案，通过后让老百姓(Learner)落实。 3个阶段 第一阶段: Prepare阶段Proposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。 Prepare: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。 Promise: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。 承诺1: 不再接受Proposal ID小于等于(注意: 这里是&lt;&#x3D; )当前请求的Prepare请求; 承诺2: 不再接受Proposal ID小于(注意: 这里是&lt; )当前请求的Propose请求; 应答: 不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。 第二阶段: Accept阶段Proposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。 Propose: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。 Accept: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。 第三阶段: Learn阶段Proposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。 伪代码 获取一个Proposal ID n，为了保证Proposal ID唯一，可采用时间戳+Server ID生成； Proposer向所有Acceptors广播Prepare(n)请求； Acceptor比较n和minProposal，如果n&gt;minProposal，minProposal&#x3D;n，并且将 acceptedProposal 和 acceptedValue 返回； Proposer接收到过半数回复后，如果发现有acceptedValue返回，将所有回复中acceptedProposal最大的acceptedValue作为本次提案的value，否则可以任意决定本次提案的value； 到这里可以进入第二阶段，广播Accept (n,value) 到所有节点； Acceptor比较n和minProposal，如果n&gt;&#x3D;minProposal，则acceptedProposal&#x3D;minProposal&#x3D;n，acceptedValue&#x3D;value，本地持久化后，返回；否则，返回minProposal。 提议者接收到过半数请求后，如果发现有返回值result &gt;n，表示有更新的提议，跳转到1；否则value达成一致。 实现举例下面举几个例子，实例1如下图: 图中P代表Prepare阶段，A代表Accept阶段。3.1代表Proposal ID为3.1，其中3为时间戳，1为Server ID。X和Y代表提议Value。 实例1中P 3.1达成多数派，其Value(X)被Accept，然后P 4.5学习到Value(X)，并Accept。 实例2中P 3.1没有被多数派Accept(只有S3 Accept)，但是被P 4.5学习到，P 4.5将自己的Value由Y替换为X，Accept(X)。 实例3中P 3.1没有被多数派Accept(只有S1 Accept)，同时也没有被P 4.5学习到。由于P 4.5 Propose的所有应答，均未返回Value，则P 4.5可以Accept自己的Value (Y)。后续P 3.1的Accept (X) 会失败，已经Accept的S1，会被覆盖。 Paxos算法可能形成活锁而永远不会结束，如下图实例所示: 回顾两个承诺之一，Acceptor不再应答Proposal ID小于等于当前请求的Prepare请求。意味着需要应答Proposal ID大于当前请求的Prepare请求。 两个Proposers交替Prepare成功，而Accept失败，形成活锁(Livelock)。 Paxos算法推导 通常说Paxos算法是复杂算法难以理解是指其推导过程复杂。理论证明一个Paxos的实现，比实现这个Paxos还要难。一个成熟的Paxos实现很难独立产生，往往需要和一个系统结合在一起，通过一个或者多个系统来验证其可靠性和完备性。 https://blog.csdn.net/yeqiuzs/article/details/76862026 Paxos算法拓展Multi-Paxos算法原始的Paxos算法(Basic Paxos)只能对一个值形成决议，决议的形成至少需要两次网络来回，在高并发情况下可能需要更多的网络来回，极端情况下甚至可能形成活锁。如果想连续确定多个值，Basic Paxos搞不定了。因此Basic Paxos几乎只是用来做理论研究，并不直接应用在实际工程中。 实际应用中几乎都需要连续确定多个值，而且希望能有更高的效率。Multi-Paxos正是为解决此问题而提出。Multi-Paxos基于Basic Paxos做了两点改进: 针对每一个要确定的值，运行一次Paxos算法实例(Instance)，形成决议。每一个Paxos实例使用唯一的Instance ID标识。 在所有Proposers中选举一个Leader，由Leader唯一地提交Proposal给Acceptors进行表决。这样没有Proposer竞争，解决了活锁问题。在系统中仅有一个Leader进行Value提交的情况下，Prepare阶段就可以跳过，从而将两阶段变为一阶段，提高效率。 Multi-Paxos首先需要选举Leader，Leader的确定也是一次决议的形成，所以可执行一次Basic Paxos实例来选举出一个Leader。选出Leader之后只能由Leader提交Proposal，在Leader宕机之后服务临时不可用，需要重新选举Leader继续服务。在系统中仅有一个Leader进行Proposal提交的情况下，Prepare阶段可以跳过。 Multi-Paxos通过改变Prepare阶段的作用范围至后面Leader提交的所有实例，从而使得Leader的连续提交只需要执行一次Prepare阶段，后续只需要执行Accept阶段，将两阶段变为一阶段，提高了效率。为了区分连续提交的多个实例，每个实例使用一个Instance ID标识，Instance ID由Leader本地递增生成即可。 Multi-Paxos允许有多个自认为是Leader的节点并发提交Proposal而不影响其安全性，这样的场景即退化为Basic Paxos。 Chubby和Boxwood均使用Multi-Paxos。ZooKeeper使用的Zab也是Multi-Paxos的变形。 参考文章 https://zhuanlan.zhihu.com/p/31780743 https://www.jdon.com/artichect/paxos.html https://blog.csdn.net/yeqiuzs/article/details/76862026 https://blog.csdn.net/qq_35440678/article/details/78080431","tags":["算法","分布式算法","Paxos算法"],"categories":["算法","分布式算法"]},{"title":"18.分布式算法 - 一致性Hash算法","path":"/2023/12/28/18-分布式算法-一致性Hash算法/","content":"致性Hash算法是个经典算法，Hash环的引入是为解决单调性(Monotonicity)的问题；虚拟节点的引入是为了解决平衡性(Balance)问题。 一致性Hash算法引入在分布式集群中，对机器的添加删除，或者机器故障后自动脱离集群这些操作是分布式集群管理最基本的功能。如果采用常用的hash(object)%N算法，那么在有机器添加或者删除后，很多原有的数据就无法找到了，这样严重的违反了单调性原则。 一致性Hash算法简介一致性哈希算法在1997年由麻省理工学院提出的一种分布式哈希(DHT)实现算法，设计目标是为了解决因特网中的热点(Hot spot)问题，初衷和CARP十分类似。一致性哈希修正了CARP使用的简 单哈希算法带来的问题，使得分布式哈希(DHT)可以在P2P环境中真正得到应用。 一致性hash算法提出了在动态变化的Cache环境中，判定哈希算法好坏的四个定义: 平衡性(Balance): 平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。很多哈希算法都能够满足这一条件。 单调性(Monotonicity): 单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的结果应能够保证原有已分配的内容可以被映射到原有的或者新的缓冲中去，而不会被映射到旧的缓冲集合中的其他缓冲区。 分散性(Spread): 在分布式环境中，终端有可能看不到所有的缓冲，而是只能看到其中的一部分。当终端希望通过哈希过程将内容映射到缓冲上时，由于不同终端所见的缓冲范围有可能不同，从而导致哈希的结果不一致，最终的结果是相同的内容被不同的终端映射到不同的缓冲区中。这种情况显然是应该避免的，因为它导致相同内容被存储到不同缓冲中去，降低了系统存储的效率。分散性的定义就是上述情况发生的严重程度。好的哈希算法应能够尽量避免不一致的情况发生，也就是尽量降低分散性。 负载(Load): 负载问题实际上是从另一个角度看待分散性问题。既然不同的终端可能将相同的内容映射到不同的缓冲区中，那么对于一个特定的缓冲区而言，也可能被不同的用户映射为不同 的内容。与分散性一样，这种情况也是应当避免的，因此好的哈希算法应能够尽量降低缓冲的负荷。 一致性Hash算法Hash环使用常见的hash算法可以把一个key值哈希到一个具有2^32个桶的空间中。也可以理解成，将key值哈希到 [0, 2^32) 的一个数字空间中。 我们假设这个是个首尾连接的环形空间。如下图: 假设我们现在有key1,key2,key3,key4 4个key值，我们通过一定的hash算法，将其对应到上面的环形hash空间中。 1234k1=hash(key1);k2=hash(key2);k3=hash(key3);k4=hash(key4); 同样的，假设我们有3台cache服务器，把缓存服务器通过hash算法，加入到上述的环中。一般情况下是根据机器的IP地址或者唯一的计算机别名进行哈希。 123c1=hash(cache1);c2=hash(cache2);c3=hash(cache3); 接下来就是数据如何存储到cache服务器上了，key值哈希之后的结果顺时针找上述环形hash空间中，距离自己最近的机器节点，然后将数据存储到上面， 如上图所示，k1 存储到 c3 服务器上， k4,k3存储到c1服务器上， k2存储在c2服务器上。用图表示如下: 删除节点假设cache3服务器宕机，这时候需要从集群中将其摘除。那么，之前存储再c3上的k1，将会顺时针寻找距离它最近的一个节点，也就是c1节点，这样，k1就会存储到c1上了，看一看下下面的图，比较清晰。 摘除c3节点之后，只影响到了原先存储再c3上的k1，而k3、k4、k2都没有受到影响，也就意味着解决了最开始的解决方案(hash(key)%N)中可能带来的雪崩问题。 增加节点新增C4节点之后，原先存储到C1的k4，迁移到了C4，分担了C1上的存储压力和流量压力。 不平衡的问题上面的简单的一致性hash的方案在某些情况下但依旧存在问题: 一个节点宕机之后，数据需要落到距离他最近的节点上，会导致下个节点的压力突然增大，可能导致雪崩，整个服务挂掉。 如下图所示: 当节点C3摘除之后，之前再C3上的k1就要迁移到C1上，这时候带来了两部分的压力: 之前请求到C3上的流量转嫁到了C1上,会导致C1的流量增加，如果之前C3上存在热点数据，则可能导致C1扛不住压力挂掉。 之前存储到C3上的key值转义到了C1，会导致C1的内容占用量增加，可能存在瓶颈。 当上面两个压力发生的时候，可能导致C1节点也宕机了。那么压力便会传递到C2上，又出现了类似滚雪球的情况，服务压力出现了雪崩，导致整个服务不可用。这一点违背了最开始提到的四个原则中的 平衡性， 节点宕机之后，流量及内存的分配方式打破了原有的平衡。 虚拟节点“虚拟节点”( virtual node )是实际节点(机器)在 hash 空间的复制品( replica )，一实际个节点(机器)对应了若干个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以hash值排列。 依旧用图片来解释，假设存在以下的真实节点和虚拟节点的对应关系。 123456Visual100—&gt; Real1Visual101—&gt; Real1Visual200—&gt; Real2Visual201—&gt; Real2Visual300—&gt; Real3Visual301—&gt; Real3 同样的，hash之后的结果如下: 123456hash(Visual100)—&gt; V100 —&gt; Real1hash(Visual101)—&gt; V101 —&gt; Real1hash(Visual200)—&gt; V200 —&gt; Real2hash(Visual201)—&gt; V201 —&gt; Real2hash(Visual300)—&gt; V300 —&gt; Real3hash(Visual301)—&gt; V301 —&gt; Real3 key值的hash结果如上，这里暂时不写了。 和之前介绍的不添加虚拟节点的类似，主要聊下如果宕机之后的情况。 假设Real1机器宕机，则会发生一下情况。 原先存储在虚拟节点V100上的k1数据将迁移到V301上，也就意味着迁移到了Real3机器上。 原先存储再虚拟节点V101上的k4数据将迁移到V200上，也就意味着迁移到了Real2机器上。 结果如下图: 这个就解决之前的问题了，某个节点宕机之后，存储及流量压力并没有全部转移到某台机器上，而是分散到了多台节点上。解决了节点宕机可能存在的雪崩问题。 当物理节点多的时候，虚拟节点多，这个的雪崩可能就越小。 一致性Hash的应用参考文章 https://blog.csdn.net/cywosp/article/details/23397179/ https://blog.csdn.net/losetowin/article/details/53743135 https://blog.csdn.net/qq1076472549/article/details/81939328","tags":["算法","分布式算法","一致性Hash算法"],"categories":["算法","分布式算法"]},{"title":"17.分布式算法 - Overview","path":"/2023/12/28/17-分布式算法-Overview/","content":"本文总结下常见的分布式算法，主要是分布式中的一致性算法。 常见的分布式算法 分布式算法 - 一致性Hash算法 一致性Hash算法是个经典算法，Hash环的引入是为解决单调性(Monotonicity)的问题；虚拟节点的引入是为了解决平衡性(Balance)问题 分布式算法 - Paxos算法 Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性, 很多分布式一致性算法都由Paxos演变而来 分布式算法 - Raft算法 Paxos是出了名的难懂，而Raft正是为了探索一种更易于理解的一致性算法而产生的。它的首要设计目的就是易于理解，所以在选主的冲突处理等方式上它都选择了非常简单明了的解决方案 分布式算法-Gossip-协议详解 Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员 分布式算法 - ZAB算法 ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）, 它应该是所有一致性协议中生产环境中应用最多的了。为什么呢？因为他是为 Zookeeper 设计的分布式一致性协议！ 分布式算法 - Snowflake算法 Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。为什么如此重要？因为它提供了一种ID生成及生成的思路，当然这种方案就是需要考虑时钟回拨的问题以及做一些 buffer的缓冲设计提高性能。","tags":["算法","分布式算法"],"categories":["算法","分布式算法"]},{"title":"16.大数据处理 - Map & Reduce","path":"/2023/12/28/16-大数据处理-Map-Reduce/","content":"MapReduce是一种计算模型, 本质上是分治/hash_map/归并排序这种方式在分布式下的延伸。 Map &amp; Reduce简介MapReduce是一种计算模型，简单的说就是将大批量的工作(数据)分解(MAP)执行，然后再将结果合并成最终结果(REDUCE)。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序。 适用范围: 数据量大，但是数据种类小可以放入内存 基本原理及要点: 将数据交给不同的机器去处理，数据划分，结果归约。 相关题目 The canonical example application of MapReduce is a process to count the appearances of each different word in a set of documents: 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。 一共有N个机器，每个机器上有N个数。每个机器最多存O(N)个数并对它们操作。如何找到N^2个数的中数(median)? 参考文章 https://blog.csdn.net/v_JULY_v/article/details/7382693","tags":["算法","大数据处理","MapReduce"],"categories":["算法","大数据处理"]},{"title":"15.大数据处理 - 外（磁盘文件）排序","path":"/2023/12/28/15-大数据处理-外（磁盘文件）排序/","content":"在编程珠玑中，描述了三种外部磁盘文件排序的解决方法，分别是 位图排序法 - 在待排序文件中不含重复数的情况下，位图排序法是最高效的 外排多路归并法 - 在更一般的情况下，外排多路归并法具有通用性 多通道排序法 所以本文主要介绍前两种。 外排序介绍 外排序, 即借助外部存储进行排序. 适用范围: 大数据的排序，去重 基本原理及要点: 外排序的归并方法，置换选择败者树原理，最优归并树 相关问题引入和方案问题描述如下： 输入：一个最多含有n个不重复的正整数（也就是说可能含有少于n个不重复正整数）的文件，其中每个数都小于等于n，且n&#x3D;10^7（1000万个）。 输出：得到按从小到大升序排列的包含所有输入的整数的列表。 条件：最多有大约1MB的内存空间可用，但磁盘空间足够。且要求运行时间在5分钟以下，10秒为最佳结果。 在编程珠玑中，描述了三种解决方法，分别是 位图排序法 - 在待排序文件中不含重复数的情况下，位图排序法是最高效的 外排多路归并法 - 在更一般的情况下，外排多路归并法具有通用性 多通道排序法 所以本文主要介绍前两种。 位图排序法熟悉位图的朋友可能会想到用位图来表示这个文件集合。例如正如编程珠玑一书上所述，用一个20位长的字符串来表示一个所有元素都小于20的简单的非负整数集合，边框用如下字符串来表示集合&#123;1,2,3,5,8,13&#125;：0 1 1 1 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0；上述集合中各数对应的位置则置1，没有对应的数的位置则置0。 参考编程珠玑一书上的位图方案，针对我们的10^7个数据量的磁盘文件排序问题，我们可以这么考虑，由于每个7位十进制整数表示一个小于1000万的整数。我们可以使用一个具有1000万个位的字符串来表示这个文件，其中，当且仅当整数i在文件中存在时，第i位为1。采取这个位图的方案是因为我们面对的这个问题的特殊性： 1、输入数据限制在相对较小的范围内 2、数据没有重复， 3、其中的每条记录都是单一的整数，没有任何其它与之关联的数据。 所以，此问题用位图的方案分为以下三步进行解决： 第一步，将所有的位都置为0，从而将集合初始化为空。 第二步，通过读入文件中的每个整数来建立集合，将每个对应的位都置为1。 第三步，检验每一位，如果该位为1，就输出对应的整数。 经过以上三步后，产生有序的输出文件。令n为位图向量中的位数（本例中为1000 0000），程序可以用伪代码表示如下： 123456789101112131415//磁盘文件排序位图方案的伪代码//copyright@ Jon Bentley//July、updated，2011.05.29。 //第一步，将所有的位都初始化为0for i =&#123;0,....n&#125; bit[i]=0;//第二步，通过读入文件中的每个整数来建立集合，将每个对应的位都置为1。for each i in the input file bit[i]=1; //第三步，检验每一位，如果该位为1，就输出对应的整数。for i=&#123;0...n&#125; if bit[i]==1 write i on the output file 上述的位图方案，共需要扫描输入数据两次，具体执行步骤如下： 第一次，只处理1—4999999之间的数据，这些数都是小于5000000的，对这些数进行位图排序，只需要约5000000&#x2F;8&#x3D;625000Byte，也就是0.625M，排序后输出。 第二次，扫描输入文件时，只处理4999999-10000000的数据项，也只需要0.625M（可以使用第一次处理申请的内存）。 因此，总共也只需要0.625M 位图的的方法有必要强调一下，就是位图的适用范围为针对不重复的数据进行排序，若数据有重复，位图方案就不适用了。 多路归并排序 首先我们需要回顾下，什么是归并排序，请参考：排序 - 归并排序(Merge Sort) 相对于多路归并排序，归并排序的本质是二路归并排序；我们已经知道，当数据量大到不适合在内存中排序时，可以利用多路归并算法对磁盘文件进行排序。 我们以一个包含很多个整数的大文件为例，来说明多路归并的外排序算法基本思想。假设文件中整数个数为N(N是亿级的)，整数之间用空格分开。首先分多次从该文件中读取M（十万级）个整数，每次将M个整数在内存中使用内部排序之后存入临时文件，这样就得到多个外部文件，对应于多个外部文件，我们可以利用多路归并将各个临时文件中的数据一边读入内存，一边进行归并输出到输出文件。显然，该排序算法需要对每个整数做2次磁盘读和2次磁盘写。（如果根据初始外部文件的个数设置归并的路数，则会对每个整数做多次读&#x2F;写，具体次数可参考严蔚敏书籍） 我们来编程实现上述磁盘文件排序的问题，代码思路对应上面图由两部分构成： 内存排序 由于要求的可用内存为1MB，那么每次可以在内存中对250K的数据进行排序，然后将有序的数写入硬盘。 那么10M的数据需要循环40次，最终产生40个有序的文件。 归并排序 将每个文件最开始的数读入(由于有序，所以为该文件最小数)，存放在一个大小为40的first_data数组中； 选择first_data数组中最小的数min_data，及其对应的文件索引index； 将first_data数组中最小的数写入文件result，然后更新数组first_data(根据index读取该文件下一个数代替min_data)； 判断是否所有数据都读取完毕，否则返回2。 参考文章其中涉及的算法和具体的实现，请参看如下文章： https://blog.csdn.net/v_JULY_v/article/details/7382693 https://www.cnblogs.com/harryshayne/archive/2011/07/02/2096196.html 再次推荐下CSDN博主July，博客专注面试、算法、机器学习。","tags":["算法","大数据处理","外（磁盘文件）排序"],"categories":["算法","大数据处理"]},{"title":"4.MySQL - 索引(B+树)","path":"/2023/12/28/4-MySQL-索引-B-树/","content":"https://www.cnblogs.com/xiaoxi/p/6894610.html B+ Tree 原理1. 数据结构B Tree 指的是 Balance Tree，也就是平衡树。平衡树是一颗查找树，并且所有叶子节点位于同一层。 B+ Tree 是基于 B Tree 和叶子节点顺序访问指针进行实现，它具有 B Tree 的平衡性，并且通过顺序访问指针来提高区间查询的性能。 在 B+ Tree 中，一个节点中的 key 从左到右非递减排列，如果某个指针的左右相邻 key 分别是 keyi 和 keyi+1，且不为 null，则该指针指向节点的所有 key 大于等于 keyi 且小于等于 keyi+1。 2. 操作进行查找操作时，首先在根节点进行二分查找，找到一个 key 所在的指针，然后递归地在指针所指向的节点进行查找。直到查找到叶子节点，然后在叶子节点上进行二分查找，找出 key 所对应的 data。 插入删除操作记录会破坏平衡树的平衡性，因此在插入删除操作之后，需要对树进行一个分裂、合并、旋转等操作来维护平衡性。 3. 与红黑树的比较红黑树等平衡树也可以用来实现索引，但是文件系统及数据库系统普遍采用 B+ Tree 作为索引结构，主要有以下两个原因: (一)更少的查找次数 平衡树查找操作的时间复杂度等于树高 h，而树高大致为 O(h)&#x3D;O(logdN)，其中 d 为每个节点的出度。 红黑树的出度为 2，而 B+ Tree 的出度一般都非常大，所以红黑树的树高 h 很明显比 B+ Tree 大非常多，检索的次数也就更多。 (二)利用计算机预读特性 为了减少磁盘 I&#x2F;O，磁盘往往不是严格按需读取，而是每次都会预读。预读过程中，磁盘进行顺序读取，顺序读取不需要进行磁盘寻道，并且只需要很短的旋转时间，因此速度会非常快。 操作系统一般将内存和磁盘分割成固态大小的块，每一块称为一页，内存与磁盘以页为单位交换数据。数据库系统将索引的一个节点的大小设置为页的大小，使得一次 I&#x2F;O 就能完全载入一个节点，并且可以利用预读特性，相邻的节点也能够被预先载入。 MySQL 索引索引是在存储引擎层实现的，而不是在服务器层实现的，所以不同存储引擎具有不同的索引类型和实现。 1. B+Tree 索引是大多数 MySQL 存储引擎的默认索引类型。 因为不再需要进行全表扫描，只需要对树进行搜索即可，因此查找速度快很多。除了用于查找，还可以用于排序和分组。 可以指定多个列作为索引列，多个索引列共同组成键。 适用于全键值、键值范围和键前缀查找，其中键前缀查找只适用于最左前缀查找。如果不是按照索引列的顺序进行查找，则无法使用索引。 InnoDB 的 B+Tree 索引分为主索引和辅助索引。 主索引的叶子节点 data 域记录着完整的数据记录，这种索引方式被称为聚簇索引。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。 辅助索引的叶子节点的 data 域记录着主键的值，因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找。 2. 哈希索引哈希索引能以 O(1) 时间进行查找，但是失去了有序性，它具有以下限制: 无法用于排序与分组； 只支持精确查找，无法用于部分查找和范围查找。 InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。 3. 全文索引MyISAM 存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。 全文索引一般使用倒排索引实现，它记录着关键词到其所在文档的映射。 InnoDB 存储引擎在 MySQL 5.6.4 版本中也开始支持全文索引。 4. 空间数据索引MyISAM 存储引擎支持空间数据索引(R-Tree)，可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。 必须使用 GIS 相关的函数来维护数据。 索引优化1. 独立的列在进行查询时，索引列不能是表达式的一部分，也不能是函数的参数，否则无法使用索引。 例如下面的查询不能使用 actor_id 列的索引: 1SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; 2. 多列索引在需要使用多个列作为条件进行查询时，使用多列索引比使用多个单列索引性能更好。例如下面的语句中，最好把 actor_id 和 film_id 设置为多列索引。 12SELECT film_id, actor_ id FROM sakila.film_actorWHERE actor_id = 1 AND film_id = 1; 3. 索引列的顺序让选择性最强的索引列放在前面，索引的选择性是指: 不重复的索引值和记录总数的比值。最大值为 1，此时每个记录都有唯一的索引与其对应。选择性越高，查询效率也越高。 例如下面显示的结果中 customer_id 的选择性比 staff_id 更高，因此最好把 customer_id 列放在多列索引的前面。 1234SELECT COUNT(DISTINCT staff_id)/COUNT(*) AS staff_id_selectivity,COUNT(DISTINCT customer_id)/COUNT(*) AS customer_id_selectivity,COUNT(*)FROM payment; 123staff_id_selectivity: 0.0001customer_id_selectivity: 0.0373 COUNT(*): 16049 4. 前缀索引对于 BLOB、TEXT 和 VARCHAR 类型的列，必须使用前缀索引，只索引开始的部分字符。 对于前缀长度的选取需要根据索引选择性来确定。 5. 覆盖索引索引包含所有需要查询的字段的值。 具有以下优点: 索引通常远小于数据行的大小，只读取索引能大大减少数据访问量。 一些存储引擎(例如 MyISAM)在内存中只缓存索引，而数据依赖于操作系统来缓存。因此，只访问索引可以不使用系统调用(通常比较费时)。 对于 InnoDB 引擎，若辅助索引能够覆盖查询，则无需访问主索引。 索引的优点 大大减少了服务器需要扫描的数据行数。 帮助服务器避免进行排序和分组，也就不需要创建临时表(B+Tree 索引是有序的，可以用于 ORDER BY 和 GROUP BY 操作。临时表主要是在排序和分组过程中创建，因为不需要排序和分组，也就不需要创建临时表)。 将随机 I&#x2F;O 变为顺序 I&#x2F;O(B+Tree 索引是有序的，也就将相邻的数据都存储在一起)。 索引的使用场景 对于非常小的表、大部分情况下简单的全表扫描比建立索引更高效。 对于中到大型的表，索引就非常有效。 但是对于特大型的表，建立和维护索引的代价将会随之增长。这种情况下，需要用到一种技术可以直接区分出需要查询的一组数据，而不是一条记录一条记录地匹配，例如可以使用分区技术。","tags":["MySQL","数据库","索引","B+树"],"categories":["数据库","MySQL"]},{"title":"14.大数据处理 - Trie树/数据库/倒排索引","path":"/2023/12/28/14-大数据处理-Trie树-数据库-倒排索引/","content":"大数据处理处理思想之 Trie树&#x2F;数据库&#x2F;倒排索引, 本文主要梳理下思路。 Trie树 Trie树的介绍和实现请参考 树 - 前缀树(Trie) 适用范围: 数据量大，重复多，但是数据种类小可以放入内存 基本原理及要点: 实现方式，节点孩子的表示方式 扩展: 压缩实现。 一些适用场景： 寻找热门查询: 查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个，每个不超过255字节。 有10个文件，每个文件1G，每个文件的每一行都存放的是用户的query，每个文件的query都可能重复。要你按照query的频度排序。 1000万字符串，其中有些是相同的(重复),需要把重复的全部去掉，保留没有重复的字符串。请问怎么设计和实现? 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词。其解决方法是: 用trie树统计每个词出现的次数，时间复杂度是O(n*le)(le表示单词的平准长度)，然后是找出出现最频繁的前10个词。 数据库索引 数据库索引相关，可以参看 MySQL - 索引(B+树) 适用范围: 大数据量的增删改查 基本原理及要点: 利用数据的设计实现方法，对海量数据的增删改查进行处理。 倒排索引(Inverted index) 倒排索引，可以参看 ElsaticSearch底层的实现。 适用范围: 搜索引擎，关键字查询 基本原理及要点: 为何叫倒排索引? 一种索引方法，被用来存储在全文搜索下某个单词在一个文档或者一组文档中的存储位置的映射。 以英文为例，下面是要被索引的文本: 12345678910T0 = &quot;it is what it is&quot;T1 = &quot;what is it&quot;T2 = &quot;it is a banana&quot;// 我们就能得到下面的倒排索引: &quot;a&quot;: &#123;2&#125;&quot;banana&quot;: &#123;2&#125;&quot;is&quot;: &#123;0, 1, 2&#125;&quot;it&quot;: &#123;0, 1, 2&#125;&quot;what&quot;: &#123;0, 1&#125;// 检索的条件&quot;what&quot;,&quot;is&quot;和&quot;it&quot;将对应集合的交集。 正向索引开发出来用来存储每个文档的单词的列表。正向索引的查询往往满足每个文档有序频繁的全文查询和每个单词在校验文档中的验证这样的查询。在正向索引中，文档占据了中心的位置，每个文档指向了一个它所包含的索引项的序列。也就是说文档指向了它包含的那些单词，而倒排索引则是单词指向了包含它的文档，很容易看到这个反向的关系。","tags":["算法","大数据处理","Trie树","数据库索引","倒排索引"],"categories":["算法","大数据处理"]},{"title":"13.大数据处理 - 双层桶划分","path":"/2023/12/28/13-大数据处理-双层桶划分/","content":"本文主要介绍大数据处理之分桶处理。 分桶法简介其实本质上还是分而治之的思想，重在“分”的技巧上！ 适用范围: 第k大，中位数，不重复或重复的数字 基本原理及要点: 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。 相关题目2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。有点像鸽巢原理，整数个数为232,也就是，我们可以将这232个数，划分为2^8个区域(比如用单个文件代表一个区域)，然后将数据分离到不同的区域，然后不同的区域在利用bitmap就可以直接解决了。也就是说只要有足够的磁盘空间，就可以很方便的解决。 5亿个int找它们的中位数。 思路一 这个例子比上面那个更明显。首先我们将int划分为2^16个区域，然后读取数据统计落到各个区域里的数的个数，之后我们根据统计结果就可以判断中位数落到那个区域，同时知道这个区域中的第几大数刚好是中位数。然后第二次扫描我们只统计落在这个区域中的那些数就可以了。 实际上，如果不是int是int64，我们可以经过3次这样的划分即可降低到可以接受的程度。即可以先将int64分成224个区域，然后确定区域的第几大数，在将该区域分成220个子区域，然后确定是子区域的第几大数，然后子区域里的数的个数只有2^20，就可以直接利用direct addr table进行统计了。 思路二 同样需要做两遍统计，如果数据存在硬盘上，就需要读取2次。 方法同基数排序有些像，开一个大小为65536的Int数组，第一遍读取，统计Int32的高16位的情况，也就是0-65535，都算作0,65536 - 131071都算作1。就相当于用该数除以65536。Int32 除以 65536的结果不会超过65536种情况，因此开一个长度为65536的数组计数就可以。每读取一个数，数组中对应的计数+1，考虑有负数的情况，需要将结果加32768后，记录在相应的数组内。 第一遍统计之后，遍历数组，逐个累加统计，看中位数处于哪个区间，比如处于区间k，那么0- k-1的区间里数字的数量sum应该&lt;n/2(2.5亿)。而k+1 - 65535的计数和也&lt;n/2，第二遍统计同上面的方法类似，但这次只统计处于区间k的情况，也就是说(x &#x2F; 65536) + 32768 &#x3D; k。统计只统计低16位的情况。并且利用刚才统计的sum，比如sum &#x3D; 2.49亿，那么现在就是要在低16位里面找100万个数(2.5亿-2.49亿)。这次计数之后，再统计一下，看中位数所处的区间，最后将高位和低位组合一下就是结果了。","tags":["算法","大数据处理","双层桶划分"],"categories":["算法","大数据处理"]},{"title":"12.大数据处理 - Bitmap & Bloom Filter","path":"/2023/12/27/12-大数据处理-Bitmap-Bloom-Filter/","content":"布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于这个集合的元素误认为不属于这个集合(False Negative)。 布隆过滤器由来布隆在1970年提出了布隆过滤器(Bloom Filter)，是一个很长的二进制向量(可以想象成一个序列)和一系列随机映射函数(hash function)。可用于判断一个元素是否在一个集合中，查询效率很高(1-N，最优能逼近于1)。通常应用在一些需要快速判断某个元素是否属于集合，但是并不严格要求100%正确的场合。 特点 优点: 占用空间小，查询快 缺点: 有误判，删除困难 几个专业术语这里有必要介绍一下False Positive和False Negative的概念: False Positive: 中文可以理解为“假阳性”，在这里表示，有可能把不属于这个集合的元素误认为属于这个集合 False Negative: 中文可以理解为“假阴性”，Bloom Filter是不存在false negatived的， 即不会把属于这个集合的元素误认为不属于这个集合(False Negative)。 布隆过滤器应用场景 网页爬虫对URL的去重: 避免爬取相同的URL地址； 反垃圾邮件: 假设邮件服务器通过发送方的邮件域或者IP地址对垃圾邮件进行过滤，那么就需要判断当前的邮件域或者IP地址是否处于黑名单之中。如果邮件服务器的通信邮件数量非常大(也可以认为数据量级上亿)，那么也可以使用Bloom Filter算法； 缓存击穿: 将已存在的缓存放到布隆中，当黑客访问不存在的缓存时迅速返回避免缓存及DB挂掉； HTTP缓存服务器: 当本地局域网中的PC发起一条HTTP请求时，缓存服务器会先查看一下这个URL是否已经存在于缓存之中，如果存在的话就没有必要去原始的服务器拉取数据了(为了简单起见，我们假设数据没有发生变化)，这样既能节省流量，还能加快访问速度，以提高用户体验。 黑/白名单: 类似反垃圾邮件。 Bigtable: Google 著名的分布式数据库 Bigtable 使用了布隆过滤器来查找不存在的行或列，以减少磁盘查找的IO次数。 Squid: 网页代理缓存服务器在 cachedigests 中使用了也布隆过滤器。 Venti 文档存储系统: 也采用布隆过滤器来检测先前存储的数据。 SPIN 模型检测器: 也使用布隆过滤器在大规模验证问题时跟踪可达状态空间。 Chrome加速安全浏览: Google Chrome浏览器使用了布隆过滤器加速安全浏览服务。 Key-Value系统: 在很多Key-Value系统中也使用了布隆过滤器来加快查询过程，如 Hbase，Accumulo，Leveldb，一般而言，Value 保存在磁盘中，访问磁盘需要花费大量时间，然而使用布隆过滤器可以快速判断某个Key对应的Value是否存在，因此可以避免很多不必要的磁盘IO操作，只是引入布隆过滤器会带来一定的内存消耗。 HTTP Proxy-Cache: 在Internet Cache Protocol中的Proxy-Cache很多都是使用Bloom Filter存储URLs，除了高效的查询外，还能很方便得传输交换Cache信息。 网络应用: P2P网络中查找资源操作，可以对每条网络通路保存Bloom Filter，当命中时，则选择该通路访问。广播消息时，可以检测某个IP是否已发包。检测广播消息包的环路，将Bloom Filter保存在包里，每个节点将自己添加入Bloom Filter。信息队列管理，使用Counter Bloom Filter管理信息流量。 布隆过滤器实现Bloom Filter在很多开源框架都有实现，例如: Elasticsearch: org.elasticsearch.common.util.BloomFilter guava: com.google.common.hash.BloomFilter Hadoop: org.apache.hadoop.util.bloom.BloomFilter(基于BitSet实现) 以BitSet 实现方式为例创建一个m位BitSet，先将所有位初始化为0，然后选择k个不同的哈希函数。第i个哈希函数对字符串str哈希的结果记为h(i，str)，且h(i，str)的范围是0到m-1 。 加入字符串过程 下面是每个字符串处理的过程，首先是将字符串str“记录”到BitSet中的过程: 对于字符串str，分别计算h(1，str)，h(2，str)…… h(k，str)。然后将BitSet的第h(1，str)、h(2，str)…… h(k，str)位设为1。 这样就将字符串str映射到BitSet中的k个二进制位了。 检查字符串是否存在的过程 下面是检查字符串str是否被BitSet记录过的过程: 对于字符串str，分别计算h(1，str)，h(2，str)…… h(k，str)。然后检查BitSet的第h(1，str)、h(2，str)…… h(k，str)位是否为1，若其中任何一位不为1则可以判定str一定没有被记录过。若全部位都是1，则“认为”字符串str存在。 若一个字符串对应的Bit不全为1，则可以肯定该字符串一定没有被Bloom Filter记录过。(这是显然的，因为字符串被记录过，其对应的二进制位肯定全部被设为1了) 以BitSet 实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package algorithm;import java.util.BitSet;public class BloomFilter&#123; /* BitSet初始分配2^24个bit */ private static final int DEFAULT_SIZE = 1 &lt;&lt; 25; /* 不同哈希函数的种子，一般应取质数 */ private static final int[] seeds = new int[]&#123; 5, 7, 11, 13, 31, 37, 61 &#125;; private BitSet bits = new BitSet(DEFAULT_SIZE); /* 哈希函数对象 */ private SimpleHash[] func = new SimpleHash[seeds.length]; public BloomFilter() &#123; for (int i = 0; i &lt; seeds.length; i++) &#123; func[i] = new SimpleHash(DEFAULT_SIZE, seeds[i]); &#125; &#125; // 将字符串标记到bits中 public void add(String value) &#123; for (SimpleHash f : func) &#123; bits.set(f.hash(value), true); &#125; &#125; // 判断字符串是否已经被bits标记 public boolean contains(String value) &#123; if (value == null) &#123; return false; &#125; boolean ret = true; for (SimpleHash f : func) &#123; ret = ret &amp;&amp; bits.get(f.hash(value)); &#125; return ret; &#125; /* 哈希函数类 */ public static class SimpleHash &#123; private int cap; private int seed; public SimpleHash(int cap, int seed) &#123; this.cap = cap; this.seed = seed; &#125; // hash函数，采用简单的加权和hash public int hash(String value) &#123; int result = 0; int len = value.length(); for (int i = 0; i &lt; len; i++) &#123; result = seed * result + value.charAt(i); &#125; return (cap - 1) &amp; result; &#125; &#125;&#125; 误报率 - False Positive Rate原文地址：https://pages.cs.wisc.edu/~cao/papers/summary-cache/node8.html 误报率的产生初始状态下，Bloom Filter是一个m位的位数组，且数组被0所填充。同时，我们需要定义k个不同的hash函数，每一个hash函数都随机的将每一个输入元素映射到位数组中的一个位上。那么对于一个确定的输入，我们会得到k个索引。 插入元素: 经过k个hash函数的映射，我们会得到k个索引，我们把位数组中这k个位置全部置1(不管其中的位之前是0还是1) 查询元素: 输入元素经过k个hash函数的映射会得到k个索引，如果位数组中这k个索引任意一处是0，那么就说明这个元素不在集合之中；如果元素处于集合之中，那么当插入元素的时候这k个位都是1。但如果这k个索引处的位都是1，被查询的元素就一定在集合之中吗? 答案是不一定，也就是说出现了False Positive的情况(但Bloom Filter不会出现False Negative的情况) 在上图中，当插入x、y、z这三个元素之后，再来查询w，会发现w不在集合之中，而如果w经过三个hash函数计算得出的结果所得索引处的位全是1，那么Bloom Filter就会告诉你，w在集合之中，实际上这里是误报，w并不在集合之中。 误报率的计算Bloom Filter的误报率到底有多大? 下面在数学上进行一番推敲。假设HASH函数输出的索引值落在m位的数组上的每一位上都是等可能的。那么，对于一个给定的HASH函数，在进行某一个运算的时候，一个特定的位没有被设置为1的概率是$$1-\\frac{1}{m}$$ 那么，对于所有的k个HASH函数，都没有把这个位设置为1的概率是$$(1-\\frac{1}{m})^k$$ 如果我们已经插入了n个元素，那么对于一个给定的位，这个位仍然是0的概率是$$(1-\\frac{1}{m})^{kn}$$那么，如果插入n个元素之后，这个位是1的概率是$$[1-(1-\\frac{1}{m})^{kn}]^k$$如果对一个特定的元素存在误报，那么这个元素的经过HASH函数所得到的k个索引全部都是1，概率也就是$$[1-(1-\\frac{1}{m})^{kn}]^k$$根据常数e的定义，可以近似的表示为:$$[1-(1+\\frac{1}{(-m)})^{(-m)\\frac{kn}{(-m)}}]^k\\approx(1-e^{-\\frac{kn}{m}})^k$$ 减少误报率: 最优的哈希函数个数既然Bloom Filter要靠多个哈希函数将集合映射到位数组中，那么应该选择几个哈希函数才能使元素查询时的错误率降到最低呢? 这里有两个互斥的理由: 如果哈希函数的个数多，那么在对一个不属于集合的元素进行查询时得到0的概率就大；但另一方面，如果哈希函数的个数少，那么位数组中的0就多。为了得到最优的哈希函数个数，我们需要根据上一小节中的错误率公式进行计算。 先用p和f进行计算。注意到$f&#x3D;e^{k\\ln(1-e-\\frac{kn}{m})}$ ，我们令$g&#x3D;k\\ln(1-e-\\frac{kn}{m})$，只要让g取到最小，f自然也取到最小。由于$p&#x3D;e-\\frac{kn}{m}$，我们可以将g写成$$g&#x3D;-\\frac{m}{n}\\ln(p)\\ln(1-p)$$根据对称性法则可以很容易看出当$p&#x3D;\\frac{1}{2}$，也就是$k&#x3D;ln2\\sqrt[m]{n}$时，g取得最小值。在这种情况下，最小错误率$f$等于$\\frac{1}{2}k\\approx0.6185^{\\frac{m}{n}}$。另外，注意到$p$是位数组中某一位仍是0的概率，所以$p&#x3D;\\frac{1}{2}$对应着位数组中0和1各一半。换句话说，要想保持错误率低，最好让位数组有一半还空着。 需要强调的一点是，$p&#x3D;\\frac{1}{2}$时错误率最小这个结果并不依赖于近似值$p$和$f$。同样对于$f’&#x3D;e^{k\\ln(1-(1-\\frac{1}{m})kn)}$，$g’&#x3D;k\\ln(1-(1-\\frac{1}{m})kn)$，$p’&#x3D;(1-\\frac{1}{m})kn$，我们可以将$g$’写成$$g’&#x3D;\\frac{1}{n\\ln(1-1&#x2F;m)}\\ln(p’)\\ln(1-p’)$$ 同样根据对称性法则可以得到当$p’&#x3D;\\frac{1}{2}$时，$g’$取得最小值。 减少误报率: 位数组的大小在不超过一定错误率的情况下，Bloom Filter至少需要多少位才能表示全集中任意$n$个元素的集合? 假设全集中共有$u$个元素，允许的最大错误率为$\\epsilon$，下面我们来求位数组的位数$m$。 假设$X$为全集中任取$n$个元素的集合，$F(X)$是表示$X$的位数组。那么对于集合$X$中任意一个元素$x$，在$s &#x3D; F(X)$中查询$x$都能得到肯定的结果，即$s$能够接受$x$。显然，由于Bloom Filter引入了错误，$s$能够接受的不仅仅是$X$中的元素，它还能够$\\epsilon(u-n)$个false positive。因此，对于一个确定的位数组来说，它能够接受总共$n+ \\epsilon(u-n)$个元素。在$n+ \\epsilon(u-n)$个元素中，$s$真正表示的只有其中$n$个，所以一个确定的位数组可以表示$$\\begin{pmatrix} n+\\epsilon(u-n) \\ n\\ \\end{pmatrix}$$个集合。$m$位的位数组共有$2^m$个不同的组合，进而可以推出，$m$位的位数组可以表示 $$2^m\\begin{pmatrix} n+\\epsilon(u-n) \\ n\\ \\end{pmatrix}$$ 个集合。全集中$n$个元素的集合总共有 $$\\begin{pmatrix} u \\ n\\ \\end{pmatrix}$$ 个，因此要让$m$位的位数组能够表示所有$n$个元素的集合，必须有 $$2^m\\begin{pmatrix} n+\\epsilon(u-n) \\ n\\ \\end{pmatrix}\\geq\\begin{pmatrix} u \\ n\\ \\end{pmatrix}$$ 即: $$m\\geq\\log_2 \\frac{\\begin{pmatrix} u \\ n\\ \\end{pmatrix}}{\\begin{pmatrix} n+\\epsilon(u-n) \\ n\\ \\end{pmatrix}}\\approx\\log_2\\frac{\\begin{pmatrix} u \\ n\\ \\end{pmatrix}}{\\begin{pmatrix} eu \\ n\\ \\end{pmatrix}}\\geq\\log_2\\epsilon^{-n}&#x3D;n\\log_2\\frac{1}{\\epsilon}$$ 上式中的近似前提是$n$和$\\epsilon u$相比很小，这也是实际情况中常常发生的。根据上式，我们得出结论: 在错误率不大于$\\epsilon$的情况下，$m$至少要等于$n\\log_2\\frac{1}{\\epsilon}$才能表示任意$n$个元素的集合。 上一小节中我们曾算出当$k&#x3D;ln2\\sqrt[m]{n}$时错误率$f$最小，这时$f&#x3D;\\frac{k}{2}&#x3D;\\frac{\\frac{m\\ln2}{n}}{2}&#x3D;\\frac{m\\ln2}{2n}$。现在令$f\\leq\\epsilon$，可以推出$$m\\geq n\\frac{\\log_2(\\frac{1}{\\epsilon})}{\\ln2}&#x3D;n\\log_2e.\\log_2(\\frac{1}{\\epsilon})$$这个结果比前面我们算得的下界$n\\log_2(\\frac{1}{\\epsilon})$大了$\\log_2e\\approx1.44$倍。这说明在哈希函数的个数取到最优时，要让错误率不超过$\\epsilon$，$m$至少需要取到最小值的1.44倍。 拓展: Counting Bloom Filter从前面对Bloom Filter的介绍可以看出，标准的Bloom Filter是一种很简单的数据结构，它只支持插入和查找两种操作。在所要表达的集合是静态集合的时候，标准Bloom Filter可以很好地工作，但是如果要表达的集合经常变动，标准Bloom Filter的弊端就显现出来了，因为它不支持删除操作。 Counting Bloom Filter的出现解决了这个问题，它将标准Bloom Filter位数组的每一位扩展为一个小的计数器(Counter)，在插入元素时给对应的k(k为哈希函数个数)个Counter的值分别加1，删除元素时给对应的k个Counter的值分别减1。Counting Bloom Filter通过多占用几倍的存储空间的代价，给Bloom Filter增加了删除操作。下一个问题自然就是，到底要多占用几倍呢? 我们先计算第i个Counter被增加$j$次的概率，其中$n$为集合元素个数，$k$为哈希函数个数，$m$为Counter个数(对应着原来位数组的大小): $$P(c(i)&#x3D;j)&#x3D;\\begin{pmatrix} nk \\ n\\ \\end{pmatrix}\\left(\\frac{1}{m}\\right)^j\\left(1-\\frac{1}{m}\\right)^{nk-j}$$上面等式右端的表达式中，前一部分表示从$nk$次哈希中选择$j$次，中间部分表示$j$次哈希都选中了第$i$个Counter，后一部分表示其它$nk – j$次哈希都没有选中第i个Counter。因此，第$i$个Counter的值大于$j$的概率可以限定为: $$P(c(i)\\geq j)\\leq\\begin{pmatrix} nk \\ j\\ \\end{pmatrix}\\frac{1}{m^j}\\leq\\left(\\frac{enk}{jm}\\right)^j$$上式第二步缩放中应用了估计阶乘的斯特林公式:$$n!\\approx\\left(\\frac{n}{e}\\right)^n\\sqrt{2\\pi n}$$在Bloom Filter概念和原理一文中，我们提到过k的最优值为$\\frac{m\\ln2}{n}$，现在我们限制$k\\leq\\frac{m\\ln2}{n}$，就可以得到如下结论: $$Pr(max(c)\\geq i)\\leq m\\left(\\frac{e\\ln2}{i}\\right)^i$$如果每个Counter分配4位，那么当Counter的值达到16时就会溢出。这个概率为: $$Pr(max(c)\\geq16)\\leq1.37\\times10^{-15}\\times m$$ 这个值足够小，因此对于大多数应用程序来说，4位就足够了。 拓展: 其它Data synchronizationByers等人提出了使用布隆过滤器近似数据同步。 Bloomier filtersChazelle 等人提出了一个通用的布隆过滤器，该布隆过滤器可以将某一值与每个已经插入的元素关联起来，并实现了一个关联数组Map。与普通的布隆过滤器一样，Chazelle实现的布隆过滤器也可以达到较低的空间消耗，但同时也会产生false positive，不过，在Bloomier filter中，某 key 如果不在 map 中，falsepositive在会返回时会被定义出的。该Map 结构不会返回与 key 相关的在 map 中的错误的值。 Compact approximatorsStable Bloom filtersScalable Bloom filtersAttenuated Bloom filters相关题目给你A,B两个文件，各存放50亿条URL，每条URL占用64字节，内存限制是4G，让你找出A,B文件共同的URL。如果是三个乃至n个文件呢?根据这个问题我们来计算下内存的占用，4G&#x3D;2^32大概是40亿*8大概是340亿，n&#x3D;50亿，如果按出错率0.01算需要的大概是650亿个bit。现在可用的是340亿，相差并不多，这样可能会使出错率上升些。另外如果这些urlip是一一对应的，就可以转换成ip，则大大简单了。 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?如果允许有一定的错误率，可以使用Bloom filter，4G内存大概可以表示340亿bit。将其中一个文件中的url使用Bloom filter映射为这340亿bit，然后挨个读取另外一个文件的url，检查是否与Bloom filter，如果是，那么该url应该是共同的url(注意会有一定的错误率)。” 在2.5亿个整数中找出不重复的整数，注，内存不足以容纳这2.5亿个整数。方案1: 采用2-Bitmap(每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义)进行，共需内存2^32 * 2 bit&#x3D;1 GB内存，还可以接受。然后扫描这2.5亿个整数，查看Bitmap中相对应位，如果是00变01，01变10，10保持不变。所描完事后，查看bitmap，把对应位是01的整数输出即可。 方案2: 也可采用分治，划分小文件的方法。然后在小文件中找出不重复的整数，并排序。然后再进行归并，注意去除重复的元素。 给40亿个不重复的unsigned int的整数，没排过序的，然后再给一个数，如何快速判断这个数是否在那40亿个数当中?用位图&#x2F;Bitmap的方法，申请512M的内存，一个bit位代表一个unsigned int值。读入40亿个数，设置相应的bit位，读入要查询的数，查看相应bit位是否为1，为1表示存在，为0表示不存在。 参考文章 https://my.oschina.net/kiwivip/blog/133498 https://blog.csdn.net/h348592532/article/details/45364147 https://blog.csdn.net/h348592532/article/details/45362661 https://blog.csdn.net/qianshangding0708/article/details/48030057 https://blog.csdn.net/xf_87/article/details/51073678 https://blog.csdn.net/weixin_34082695/article/details/90331258 https://blog.csdn.net/v_JULY_v/article/details/7382693","tags":["算法","大数据处理","Bitmap","Bloom Filter"],"categories":["算法","大数据处理"]},{"title":"11.大数据处理 - 分治/hash/排序","path":"/2023/12/27/11-大数据处理-分治-hash-排序/","content":"大数据处理思路: 分而治之&#x2F;Hash映射 + Hash_map统计 + 堆&#x2F;快速&#x2F;归并排序。 思路简介 分而治之&#x2F;hash映射 + hash统计 + 堆&#x2F;快速&#x2F;归并排序，说白了，就是先映射，而后统计，最后排序: 分而治之/hash映射: 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件，即16字方针: 大而化小，各个击破，缩小规模，逐个解决 hash_map统计: 当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。 堆/快速排序: 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP。 案例分析海量日志数据，提取出某日访问百度次数最多的那个IP分析: “首先是这一天，并且是访问百度的日志中的IP取出来，逐个写入到一个大文件中。注意到IP是32位的，最多有个2^32个IP。同样可以采用映射的方法，比如%1000，把整个大文件映射为1000个小文件，再找出每个小文中出现频率最大的IP(可以采用hash_map对那1000个文件中的所有IP进行频率统计，然后依次找出各个文件中频率最大的那个IP)及相应的频率。然后再在这1000个最大的IP中，找出那个频率最大的IP，即为所求。” 关于本题，还有几个问题，如下: Hash取模是一种等价映射，不会存在同一个元素分散到不同小文件中的情况，即这里采用的是mod1000算法，那么相同的IP在hash取模后，只可能落在同一个文件中，不可能被分散的。因为如果两个IP相等，那么经过Hash(IP)之后的哈希值是相同的，将此哈希值取模(如模1000)，必定仍然相等。 那到底什么是hash映射呢? 简单来说，就是为了便于计算机在有限的内存中处理big数据，从而通过一种映射散列的方式让数据均匀分布在对应的内存位置(如大数据通过取余的方式映射成小树存放在内存中，或大文件映射成多个小文件)，而这个映射散列方式便是我们通常所说的hash函数，设计的好的hash函数能让数据均匀分布而减少冲突。尽管数据映射到了另外一些不同的位置，但数据还是原来的数据，只是代替和表示这些原始数据的形式发生了变化而已。 寻找热门查询，300万个查询字符串中统计最热门的10个查询原题: 搜索引擎会通过日志文件把用户每次检索使用的所有检索串都记录下来，每个查询串的长度为1-255字节。假设目前有一千万个记录(这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门)，请你统计最热门的10个查询串，要求使用的内存不能超过1G。 解答: 由上面第1题，我们知道，数据大则划为小的，如如一亿个Ip求Top 10，可先%1000将ip分到1000个小文件中去，并保证一种ip只出现在一个文件中，再对每个小文件中的ip进行hashmap计数统计并按数量排序，最后归并或者最小堆依次处理每个小文件的top10以得到最后的结。 但如果数据规模比较小，能一次性装入内存呢?比如这第2题，虽然有一千万个Query，但是由于重复度比较高，因此事实上只有300万的Query，每个Query255Byte，因此我们可以考虑把他们都放进内存中去(300万个字符串假设没有重复，都是最大长度，那么最多占用内存3M*1K&#x2F;4&#x3D;0.75G。所以可以将所有字符串都存放在内存中进行处理)，而现在只是需要一个合适的数据结构，在这里，HashTable绝对是我们优先的选择。 所以我们放弃分而治之&#x2F;hash映射的步骤，直接上hash统计，然后排序。So，针对此类典型的TOP K问题，采取的对策往往是: hashmap + 堆。如下所示: hash_map统计: 先对这批海量数据预处理。具体方法是: 维护一个Key为Query字串，Value为该Query出现次数的HashTable，即hash_map(Query，Value)，每次读取一个Query，如果该字串不在Table中，那么加入该字串，并且将Value值设为1；如果该字串在Table中，那么将该字串的计数加一即可。最终我们在O(N)的时间复杂度内用Hash表完成了统计； 堆排序: 第二步、借助堆这个数据结构，找出Top K，时间复杂度为N‘logK。即借助堆结构，我们可以在log量级的时间内查找和调整&#x2F;移动。因此，维护一个K(该题目中是10)大小的小根堆，然后遍历300万的Query，分别和根元素进行对比。所以，我们最终的时间复杂度是: O(N) + N’ * O(logK)，(N为1000万，N’为300万)。 别忘了这篇文章中所述的堆排序思路: “维护k个元素的最小堆，即用容量为k的最小堆存储最先遍历到的k个数，并假设它们即是最大的k个数，建堆费时O(k)，并调整堆(费时O(logk))后，有k1&gt;k2&gt;…kmin(kmin设为小顶堆中最小元素)。继续遍历数列，每次遍历一个元素x，与堆顶元素比较，若x&gt;kmin，则更新堆(x入堆，用时logk)，否则不更新堆。这样下来，总费时O(k*logk+(n-k)logk)&#x3D;O(nlogk)。此方法得益于在堆中，查找等各项操作时间复杂度均为logk。”–第三章续、Top K算法问题的实现。 当然，你也可以采用trie树，关键字域存该查询串出现的次数，没有出现为0。最后用10个元素的最小推来对出现频率进行排序。 有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。 分而治之/hash映射: 顺序读文件中，对于每个词x，取hash(x)%5000，然后按照该值存到5000个小文件(记为x0,x1,…x4999)中。这样每个文件大概是200k左右。如果其中的有的文件超过了1M大小，还可以按照类似的方法继续往下分，直到分解得到的小文件的大小都不超过1M。 hash_map统计: 对每个小文件，采用trie树&#x2F;hash_map等统计每个文件中出现的词以及相应的频率。 堆/归并排序: 取出出现频率最大的100个词(可以用含100个结点的最小堆)后，再把100个词及相应的频率存入文件，这样又得到了5000个文件。最后就是把这5000个文件进行归并(类似于归并排序)的过程了。 海量数据分布在100台电脑中，想个办法高效统计出这批数据的TOP10。如果每个数据元素只出现一次，而且只出现在某一台机器中，那么可以采取以下步骤统计出现次数TOP10的数据元素: 堆排序: 在每台电脑上求出TOP10，可以采用包含10个元素的堆完成(TOP10小，用最大堆，TOP10大，用最小堆，比如求TOP10大，我们首先取前10个元素调整成最小堆，如果发现，然后扫描后面的数据，并与堆顶元素比较，如果比堆顶元素大，那么用该元素替换堆顶，然后再调整为最小堆。最后堆中的元素就是TOP10大)。 求出每台电脑上的TOP10后，然后把这100台电脑上的TOP10组合起来，共1000个数据，再利用上面类似的方法求出TOP10就可以了。 但如果同一个元素重复出现在不同的电脑中呢，如下例子所述, 这个时候，你可以有两种方法: 遍历一遍所有数据，重新hash取摸，如此使得同一个元素只出现在单独的一台电脑中，然后采用上面所说的方法，统计每台电脑中各个元素的出现次数找出TOP10，继而组合100台电脑上的TOP10，找出最终的TOP10。 或者，暴力求解: 直接统计统计每台电脑中各个元素的出现次数，然后把同一个元素在不同机器中的出现次数相加，最终从所有数据中找出TOP10。 有10个文件，每个文件1G，每个文件的每一行存放的都是用户的query，每个文件的query都可能重复。要求你按照query的频度排序。方案1: hash映射: 顺序读取10个文件，按照hash(query)%10的结果将query写入到另外10个文件(记为a0,a1,..a9)中。这样新生成的文件每个的大小大约也1G(假设hash函数是随机的)。 hash_map统计: 找一台内存在2G左右的机器，依次对用hash_map(query, query_count)来统计每个query出现的次数。注: hash_map(query,query_count)是用来统计每个query的出现次数，不是存储他们的值，出现一次，则count+1。 堆&#x2F;快速&#x2F;归并排序: 利用快速&#x2F;堆&#x2F;归并排序按照出现次数进行排序，将排序好的query和对应的query_cout输出到文件中，这样得到了10个排好序的文件(记为)。最后，对这10个文件进行归并排序(内排序与外排序相结合)。根据此方案1，这里有一份实现: https://github.com/ooooola/sortquery/blob/master/querysort.py。 方案2: 一般query的总量是有限的，只是重复的次数比较多而已，可能对于所有的query，一次性就可以加入到内存了。这样，我们就可以采用trie树&#x2F;hash_map等直接来统计每个query出现的次数，然后按出现次数做快速&#x2F;堆&#x2F;归并排序就可以了。 方案3: 与方案1类似，但在做完hash，分成多个文件后，可以交给多个文件来处理，采用分布式的架构来处理(比如MapReduce)，最后再进行合并。 给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url?可以估计每个文件安的大小为5G×64&#x3D;320G，远远大于内存限制的4G。所以不可能将其完全加载到内存中处理。考虑采取分而治之的方法。 分而治之/hash映射: 遍历文件a，对每个url求取，然后根据所取得的值将url分别存储到1000个小文件(记为，这里漏写个了a1)中。这样每个小文件的大约为300M。遍历文件b，采取和a相同的方式将url分别存储到1000小文件中(记为)。这样处理后，所有可能相同的url都在对应的小文件()中，不对应的小文件不可能有相同的url。然后我们只要求出1000对小文件中相同的url即可。 hash_set统计: 求每对小文件中相同的url时，可以把其中一个小文件的url存储到hash_set中。然后遍历另一个小文件的每个url，看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。 怎么在海量数据中找出重复次数最多的一个?方案: 先做hash，然后求模映射为小文件，求出每个小文件中重复次数最多的一个，并记录重复次数。然后找出上一步求出的数据中重复次数最多的一个就是所求(具体参考前面的题)。 上千万或上亿数据(有重复)，统计其中出现次数最多的前N个数据。方案: 上千万或上亿的数据，现在的机器的内存应该能存下。所以考虑采用hash_map&#x2F;搜索二叉树&#x2F;红黑树等来进行统计次数。然后利用堆取出前N个出现次数最多的数据。 一个文本文件，大约有一万行，每行一个词，要求统计出其中最频繁出现的前10个词，请给出思想，给出时间复杂度分析。方案1: 如果文件比较大，无法一次性读入内存，可以采用hash取模的方法，将大文件分解为多个小文件，对于单个小文件利用hash_map统计出每个小文件中10个最常出现的词，然后再进行归并处理，找出最终的10个最常出现的词。 方案2: 通过hash取模将大文件分解为多个小文件后，除了可以用hash_map统计出每个小文件中10个最常出现的词，也可以用trie树统计每个词出现的次数，时间复杂度是O(nle)(le表示单词的平准长度)，最终同样找出出现最频繁的前10个词(可用堆来实现)，时间复杂度是O(nlg10)。 一个文本文件，找出前10个经常出现的词，但这次文件比较长，说是上亿行或十亿行，总之无法一次读入内存，问最优解。方案1: 首先根据用hash并求模，将文件分解为多个小文件，对于单个文件利用上题的方法求出每个文件件中10个最常出现的词。然后再进行归并处理，找出最终的10个最常出现的词。 100w个数中找出最大的100个数。方案1: 采用局部淘汰法。选取前100个元素，并排序，记为序列L。然后一次扫描剩余的元素x，与排好序的100个元素中最小的元素比，如果比这个最小的要大，那么把这个最小的元素删除，并把x利用插入排序的思想，插入到序列L中。依次循环，知道扫描了所有的元素。复杂度为O(100w*100)。 方案2: 采用快速排序的思想，每次分割之后只考虑比轴大的一部分，知道比轴大的一部分在比100多的时候，采用传统排序算法排序，取前100个。复杂度为O(100w*100)。 方案3: 在前面的题中，我们已经提到了，用一个含100个元素的最小堆完成。复杂度为O(100w*lg100)。","tags":["算法","大数据处理","分治","hash","排序"],"categories":["算法","大数据处理"]},{"title":"10.大数据处理 - Overview","path":"/2023/12/27/10-大数据处理-Overview/","content":"本文主要介绍大数据处理的一些思路。 何谓海量数据处理?所谓海量数据处理，无非就是基于海量数据上的存储、处理、操作。何谓海量，就是数据量太大，所以导致要么是无法在较短时间内迅速解决，要么是数据太大，导致无法一次性装入内存。 那解决办法呢? 针对时间: 我们可以采用巧妙的算法搭配合适的数据结构，如Bloom filter&#x2F;Hash&#x2F;bit-map&#x2F;堆&#x2F;数据库或倒排索引&#x2F;trie树； 针对空间: 无非就一个办法: 大而化小，分而治之(hash映射); 集群|分布式: 通俗点来讲，单机就是处理装载数据的机器有限(只要考虑cpu，内存，硬盘的数据交互); 而集群适合分布式处理，并行计算(更多考虑节点和节点间的数据交互)。 具体思路 大数据处理 - 分治&#x2F;hash&#x2F;排序 就是先映射，而后统计，最后排序: 分而治之/hash映射: 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件，即16字方针: 大而化小，各个击破，缩小规模，逐个解决 hash_map统计: 当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。 堆/快速排序: 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP。 大数据处理 - Bitmap &amp; Bloom Filter 布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于这个集合的元素误认为不属于这个集合(False Negative) 大数据处理 - 双层桶划分 其实本质上还是分而治之的思想，重在“分”的技巧上！适用范围: 第k大，中位数，不重复或重复的数字；基本原理及要点: 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。 大数据处理 - Trie树&#x2F;数据库&#x2F;倒排索引 适用范围: 数据量大，重复多，但是数据种类小可以放入内存；基本原理及要点: 实现方式，节点孩子的表示方式；扩展: 压缩实现 大数据处理 - 外排序 适用范围: 大数据的排序，去重；基本原理及要点: 外排序的归并方法，置换选择败者树原理，最优归并树 大数据处理 - Map &amp; Reduce MapReduce是一种计算模型，简单的说就是将大批量的工作(数据)分解(MAP)执行，然后再将结果合并成最终结果(REDUCE)。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序 参考文章 https://blog.csdn.net/v_july_v/article/category/1106578 https://blog.csdn.net/v_JULY_v/article/details/6279498 https://blog.csdn.net/v_JULY_v/article/details/7382693 https://blog.csdn.net/meng984611383/article/details/80060096","tags":["算法","大数据处理"],"categories":["算法","大数据处理"]},{"title":"9.字符串匹配 - 文本预处理：后缀树（Suffix Tree）","path":"/2023/12/27/9-字符串匹配-文本预处理：后缀树（Suffix-Tree）/","content":"上述字符串匹配算法(朴素的字符串匹配算法, KMP 算法, Boyer-Moore算法)均是通过对模式（Pattern）字符串进行预处理的方式来加快搜索速度。对 Pattern 进行预处理的最优复杂度为 O(m)，其中 m 为 Pattern 字符串的长度。那么，有没有对文本（Text）进行预处理的算法呢？本文即将介绍一种对 Text 进行预处理的字符串匹配算法：后缀树（Suffix Tree）。 什么是后缀树上述字符串匹配算法(朴素的字符串匹配算法, KMP 算法, Boyer-Moore算法)均是通过对模式（Pattern）字符串进行预处理的方式来加快搜索速度。对 Pattern 进行预处理的最优复杂度为 O(m)，其中 m 为 Pattern 字符串的长度。那么，有没有对文本（Text）进行预处理的算法呢？本文即将介绍一种对 Text 进行预处理的字符串匹配算法：后缀树（Suffix Tree）。 后缀树的性质： 存储所有 n(n-1)&#x2F;2 个后缀需要 O(n) 的空间，n 为的文本（Text）的长度； 构建后缀树需要 O(dn) 的时间，d 为字符集的长度（alphabet）； 对模式（Pattern）的查询需要 O(dm) 时间，m 为 Pattern 的长度； 在《字典树(前缀树》一文中，介绍了一种特殊的树状信息检索数据结构：字典树（Trie）。Trie 将关键词中的字符按顺序添加到树中的节点上，这样从根节点开始遍历，就可以确定指定的关键词是否存在于 Trie 中。 下面是根据集合 {bear, bell, bid, bull, buy, sell, stock, stop} 所构建的 Trie 树。 我们观察上面这颗 Trie，对于关键词 “bear”，字符 “a” 和 “r” 所在的节点没有其他子节点，所以可以考虑将这两个节点合并，如下图所示。 这样，我们就得到了一棵压缩过的 Trie，称为压缩字典树（Compressed Trie）。 而后缀树（Suffix Tree）则首先是一棵 Compressed Trie，其次，后缀树中存储的关键词为所有的后缀。这样，实际上我们也就得到了构建后缀树的抽象过程： 根据文本 Text 生成所有后缀的集合； 将每个后缀作为一个单独的关键词，构建一棵 Compressed Trie。 比如，对于文本 “banana\\0”，其中 “\\0” 作为文本结束符号。下面是该文本所对应的所有后缀。 1234567banana\\0anana\\0nana\\0ana\\0na\\0a\\0\\0 将每个后缀作为一个关键词，构建一棵 Trie。 然后，将独立的节点合并，形成 Compressed Trie。 则上面这棵树就是文本 “banana\\0” 所对应的后缀树。 现在我们先熟悉两个概念：**显式后缀树（Explicit Suffix Tree）**和**隐式后缀树（Implicit Suffix Tree）**。 下面用字符串 “xabxa” 举例说明两者的区别，其包括后缀列表如下。 12345xabxaabxabxaxaa 我们发现，后缀 “xa” 和 “a” 已经分别包含在后缀 “xabxa” 和 “abxa” 的前缀中，这样构造出来的后缀树称为隐式后缀树（Implicit Suffix Tree）。 而如果不希望这样的情形发生，可以在每个后缀的结尾加上一个特殊字符，比如 “$” 或 “#” 等，这样我们就可以使得后缀保持唯一性。 123456xabxa$abxa$bxa$xa$a$$ 在 1995 年，Esko Ukkonen 发表了论文《On-line construction of suffix trees》，描述了在线性时间内构建后缀树的方法。下面尝试描述 Ukkonen 算法的基本实现原理，从简单的字符串开始描述，然后扩展到更复杂的情形。 Suffix Tree 与 Trie 的不同在于，边（Edge）不再只代表单个字符，而是通过一对整数 [from, to] 来表示。其中 from 和 to 所指向的是 Text 中的位置，这样每个边可以表示任意的长度，而且仅需两个指针，耗费 O(1) 的空间。 首先，我们从一个最简单的字符串 Text &#x3D; “abc” 开始实践构建后缀树，”abc” 中没有重复字符，使得构建过程更简单些。构建过程的步骤是：从左到右，对逐个字符进行操作。 1abc 第 1 个字符是 “a”，创建一条边从根节点（root）到叶节点，以 [0, #] 作为标签代表其在 Text 中的位置从 0 开始。使用 “#” 表示末尾，可以认为 “#” 在 “a” 的右侧，位置从 0 开始，则当前位置 “#” 在 1 位。 其代表的后缀意义如下。 第 1 个字符 “a” 处理完毕，开始处理第 2 个字符 “b”。涉及的操作包括： 扩展已经存在的边 “a” 至 “ab”； 插入一条新边以表示 “b”； 其代表的后缀意义如下。 这里，我们观察到了两点： “ab” 边的表示 [0, #] 与之前是相同的，当 “#” 位置由 1 挪至 2 时，[0, #] 所代表的意义自动地发生了改变。 每条边的空间复杂度为 O(1)，即只消耗两个指针，而与边所代表的字符数量无关； 接着再处理第 3 个字符 “c”，重复同样的操作，”#” 位置向后挪至第 3 位： 其代表的后缀意义如下。 此时，我们观察到： 经过上面的步骤后，我们得到了一棵正确的后缀树； 操作步骤的数量与 Text 中的字符的数量一样多； 每个步骤的工作量是 O(1)，因为已存在的边都是依据 “#” 的挪动而自动更改的，仅需为最后一个字符添加一条新边，所以时间复杂度为 O(1)。则，对于一个长度为 n 的 Text，共需要 O(n) 的时间构建后缀树。 当然，我们进展的这么顺利，完全是因为所操作的字符串 Text &#x3D; “abc” 太简单，没有任何重复的字符。那么现在我们来处理一个更复杂一些的字符串 Text &#x3D; “abcabxabcd”。 1abcabxabcd 同上面的例子类似的是，这个新的 Text 同样以 “abc” 开头，但其后接着 “ab”,”x”,”abc”,”d” 等，并且出现了重复的字符。 前 3 个字符 “abc” 的操作步骤与上面介绍的相同，所以我们会得到下面这颗树： 当 “#” 继续向后挪动一位，即第 4 位时，隐含地意味着已有的边会自动的扩展为： 即 [0, #], [1, #], [2, #] 都进行了自动的扩展。按照上面的逻辑，此时应该为剩余后缀 “a” 创建一条单独的边。但，在做这件事之前，我们先引入两个概念。 活动点（active point），是一个三元组，包括（active_node, active_edge, active_length）； 剩余后缀数（remainder），是一个整数，代表着还需要插入多少个新的后缀； 如何使用这两个概念将在下面逐步地说明。不过，现在我们可以先确定两件事： 在 Text &#x3D; “abc” 的例子中，活动点（active point）总是 (root, ‘\\0x’, 0)。也就是说，活动节点（active_node）总是根节点（root），活动边（active_edge）是空字符 ‘\\0x’ 所指定的边，活动长度（active_length）是 0。 在每个步骤开始时，剩余后缀数（remainder）总是 1。意味着，每次我们要插入的新的后缀数目为 1，即最后一个字符。 1# = 3, active_point = (root, &#x27;\\0x&#x27;, 1), remainder = 1 当处理第 4 字符 “a” 时，我们注意到，事实上已经存在一条边 “abca” 的前缀包含了后缀 “a”。在这种情况下： 我们不再向 root 插入一条全新的边，也就是 [3, #]。相反，既然后缀 “a” 已经被包含在树中的一条边上 “abca”，我们保留它们原来的样子。 设置 active point 为 (root, ‘a’, 1)，也就是说，active_node 仍为 root，active_edge 为 ‘a’，active_length 为 1。这就意味着，活动点现在是从根节点开始，活动边是以 ‘a’ 开头的某个边，而位置就是在这个边的第 1 位。这个活动边的首字符为 ‘a’，实际上，仅会有一个边是以一个特定字符开头的。 remainder 的值需要 +1，也就是 2。 1# = 4, active_point = (root, &#x27;a&#x27;, 1), remainder = 2 此时，我们还观察到：当我们要插入的后缀已经存在于树中时，这颗树实际上根本就没有改变，我们仅修改了 active point 和 remainder。那么，这颗树也就不再能准确地描述当前位置了，不过它却正确地包含了所有的后缀，即使是通过隐式的方式（Implicitly）。因此，处理修改变量，这一步没有其他工作，而修改变量的时间复杂度为 O(1)。 继续处理下一个字符 “b”，”#” 继续向后挪动一位，即第 5 位时，树被自动的更新为： 由于剩余后缀数（remainder）的值为 2，所以在当前位置，我们需要插入两个最终后缀 “ab” 和 “b”。这是因为： 前一步的 “a” 实际上没有被真正的插入到树中，所以它被遗留了下来（remained），然而我们又向前迈了一步，所以它现在由 “a” 延长到 “ab”； 还有就是我们需要插入新的最终后缀 “b”； 实际操作时，我们就是修改 active point，指向 “a” 后面的位置，并且要插入新的最终后缀 “b”。但是，同样的事情又发生了，”b” 事实上已经存在于树中一条边 “bcab” 的前缀上。那么，操作可以归纳为： 修改活动点为 (root, ‘a’, 2)，实际还是与之前相同的边，只是将指向的位置向后挪到 “b”，修改了 active_length，即 “ab”。 增加剩余后缀数（remainder）为 3，因为我们又没有为 “b” 插入全新的边。 1# = 5, active_point = (root, &#x27;a&#x27;, 2), remainder = 3 再具体一点，我们本来准备插入两个最终后缀 “ab” 和 “b”，但因为 “ab” 已经存在于其他的边的前缀中，所以我们只修改了活动点。对于 “b”，我们甚至都没有考虑要插入，为什么呢？因为如果 “ab” 存在于树中，那么他的每个后缀都一定存在于树中。虽然仅仅是隐含性的，但却一定存在，因为我们一直以来就是按照这样的方式来构建这颗树的。 继续处理下一个字符 “x”，”#” 继续向后挪动一位，即第 6 位时，树被自动的更新为： 由于剩余后缀数（Remainder）的值为 3，所以在当前位置，我们需要插入 3 个最终后缀 “abx”, “bx” 和 “x”。 活动点告诉了我们之前 “ab” 结束的位置，所以仅需跳过这一位置，插入新的 “x” 后缀。”x” 在树中还不存在，因此我们分裂 “abcabx” 边，插入一个内部节点： 分裂和插入新的内部节点耗费 O(1) 时间。 现在，我们已经处理了 “abx”，并且把 remainder 减为 2。然后继续插入下一个后缀 “bx”，但做这个操作之前需要先更新活动点，这里我们先做下部分总结。 对于上面对边的分裂和插入新的边的操作，可以总结为 Rule 1，其应用于当 active_node 为 root 节点时。 Rule 1 当向根节点插入时遵循： active_node 保持为 root； active_edge 被设置为即将被插入的新后缀的首字符； active_length 减 1； 因此，新的活动点为 (root, ‘b’, 1)，表明下一个插入一定会发生在边 “bcabx” 上，在 1 个字符之后，即 “b” 的后面。 1# = 6, active_point = (root, &#x27;b&#x27;, 1), remainder = 2 我们需要检查 “x” 是否在 “b” 后面出现，如果出现了，就是我们上面见到过的样子，可以什么都不做，只更新活动点。如果未出现，则需要分裂边并插入新的边。 同样，这次操作也花费了 O(1) 时间。然后将 remainder 更新为 1，依据 Rule 1 活动点更新为 (root, ‘x’, 0)。 1# = 6, active_point = (root, &#x27;x&#x27;, 0), remainder = 1 此时，我们将归纳出 Rule 2。 Rule 2 如果我们分裂（Split）一条边并且插入（Insert）一个新的节点，并且如果该新节点不是当前步骤中创建的第一个节点，则将先前插入的节点与该新节点通过一个特殊的指针连接，称为后缀连接（Suffix Link）。后缀连接通过一条虚线来表示。 继续上面的操作，插入最终后缀 “x”。因为活动点中的 active_length 已经降到 0，所以插入操作将发生在 root 上。由于没有以 “x” 为前缀的边，所以插入一条新的边： 这样，这一步骤中的所有操作就完成了。 1# = 6, active_point = (root, &#x27;\\0x&#x27;, 0), remainder = 1 继续处理下一个字符 “a”，”#” 继续向后挪动一位。发现后缀 “a” 已经存在于数中的边中，所以仅更新 active point 和 remainder。 1# = 7, active_point = (root, &#x27;a&#x27;, 1), remainder = 2 继续处理下一个字符 “b”，”#” 继续向后挪动一位。发现后缀 “ab” 和 “b” 都已经存在于树中，所以仅更新 active point 和 remainder。这里我们先称 “ab” 所在的边的节点为 node1。 1# = 8, active_point = (root, &#x27;a&#x27;, 2), remainder = 3 继续处理下一个字符 “c”，”#” 继续向后挪动一位。此时由于 remainder &#x3D; 3，所以需要插入 “abc”,”bc”,”c” 三个后缀。”c” 实际上已经存在于 node1 后的边上。 1# = 9, active_point = (node1, &#x27;c&#x27;, 1), remainder = 4 继续处理下一个字符 “d”，”#” 继续向后挪动一位。此时由于 remainder &#x3D; 4，所以需要插入 “abcd”,”bcd”,”cd”,”d” 四个后缀。 上图中的 active_node，当节点准备分裂时，被标记了红色。则归纳出了 Rule 3。 Rule 3 当从 active_node 不为 root 的节点分裂边时，我们沿着后缀连接（Suffix Link）的方向寻找节点，如果存在一个节点，则设置该节点为 active_noe；如果不存在，则设置 active_node 为 root。active_edge 和 active_length 保持不变。 所以，现在活动点为 (node2, ‘c’, 1)，其中 node2 为下图中的红色节点： 1# = 10, active_point = (node2, &#x27;c&#x27;, 1), remainder = 3 由于对 “abcd” 的插入已经完成，所以将 remainder 的值减至 3，并且开始处理下一个剩余后缀 “bcd”。此时需要将边 “cabxabcd” 分裂，然后插入新的边 “d”。根据 Rule 2，我们需要在之前插入的节点与当前插入的节点间创建一条新的后缀连接。 此时，我们观察到，后缀连接（Suffix Link）让我们能够重置活动点，使得对下一个后缀的插入操作仅需 O(1) 时间。从上图也确认了，”ab” 连接的是其后缀 “b”，而 “abc” 连接的是其后缀 “bc”。 当前操作还没有完成，因为 remainder 是 2，根绝 Rule 3 我们需要重新设置活动点。因为上图中的红色 active_node 没有后缀连接（Suffix Link），所以活动点被设置为 root，也就是 (root, ‘c’, 1)。 1# = 10, active_point = (root, &#x27;c&#x27;, 1), remainder = 2 因此，下一个插入操作 “cd” 将从 Root 开始，寻找以 “c” 为前缀的边 “cabxabcd”，这也引起又一次分裂： 由于此处又创建了一个新的内部节点，依据 Rule 2，我们需要建立一条与前一个被创建内节点的后缀连接。 然后，remainder 减为 1，active_node 为 root，根据 Rule 1 则活动点为 (root, ‘d’, 0)。也就是说，仅需在根节点上插入一条 “d” 新边。 1# = 10, active_point = (root, &#x27;d&#x27;, 0), remainder = 1 整个步骤完成。 总体上看，我们有一系列的观察结果： 在每一步中将 “#” 向右移动 1 位时，所有叶节点自动更新的时间为 O(1)； 但实际上并没有处理这两种情况： 从前一步中遗留的后缀； 当前步骤中的最终字符； remainder 告诉了我们还余下多少后缀需要插入。这些插入操作将逐个的与当前位置 “#” 之前的后缀进行对应，我们需要一个接着一个的处理。更重要的是，每次插入需要 O(1) 时间，活动点准确地告诉了我们改如何进行，并且也仅需在活动点中增加一个单独的字符。为什么？因为其他字符都隐式地被包含了，要不也就不需要 active point 了。 每次插入之后，remainder 都需要减少，如果存在后缀连接（Suffix Link）的话就续接至下一个节点，如果不存在则返回值 root 节点（Rule 3）。如果已经是在 root 节点了，则依据 Rule 1 来修改活动点。无论哪种情况，仅需 O(1) 时间。 如果这些插入操作中，如果发现要被插入的字符已经存在于树中，则什么也不做，即使 remainder &gt; 0。原因是要被插入的字符实际上已经隐式地被包含在了当前的树中。而 remainder &gt; 0 则确保了在后续的操作中会进行处理。 那么如果在算法结束时 remainder &gt; 0 该怎么办？这种情况说明了文本的尾部字符串在之前某处已经出现过。此时我们需要在尾部添加一个额外的从未出现过的字符，通常使用 “$” 符号。为什么要这么做呢？如果后续我们用已经完成的后缀树来查找后缀，匹配结果一定要出现在叶子节点，否则就会出现很多假匹配，因为很多字符串已经被隐式地包含在了树中，但实际并不是真正的后缀。同时，最后也强制 remainder &#x3D; 0，以此来保证所有的后缀都形成了叶子节点。尽管如此，如果想用后缀树搜索常规的子字符串，而不仅是搜索后缀，这么做就不是必要的了。 那么整个算法的复杂度是多少呢？如果 Text 的长度为 n，则有 n 步需要执行，算上 “$” 则有 n+1 步。在每一步中，我们要么什么也不做，要么执行 remainder 插入操作并消耗 O(1) 时间。因为 remainder 指示了在前一步中我们有多少无操作次数，在当前步骤中每次插入都会递减，所以总体的数量还是 n。因此**总体的复杂度为 O(n)**。 然而，还有一小件事我还没有进行适当的解释。那就是，当我们续接后缀连接时，更新 active point，会发现 active_length 可能与 active_node 协作的并不好。例如下面这种情况： 假设 active point 是红色节点 (red, ‘d’, 3)，因此它指向 “def” 边中 “f” 之后的位置。现在假设我们做了必要的更新，而且依据 Rule 3 续接了后缀连接并修改了活动点，新的 active point 是 (green, ‘d’, 3)。然而从绿色节点出发的 “d” 边是 “de”，这条边只有 2 个字符。为了找到合适的活动点，看起来我们需要添加一个到蓝色节点的边，然后重置活动点为 (blue, ‘f’, 1)。 在最坏的情况下，active_length 可以与 remainder 一样大，甚至可以与 n 一样大。而恰巧这种情况可能刚好在找活动点时发生，那么我们不仅需要跳过一个内部节点，可能是多个节点，最坏的情况是 n 个。由于每步里 remainder 是 O(n)，续接了后缀连接之后的对活动点的后续调整也是 O(n)，那么是否意味着整个算法潜在需要 O(n2) 时间呢？ 我认为不是。理由是如果我们确实需要调整活动点（例如，上图中从绿色节点调整到蓝色节点），那么这就引入了一个拥有自己的后缀连接的新节点，而且 active_length 将减少。当我们沿着后缀连接向下走，就要插入剩余的后缀，且只是减少 active_length，使用这种方法可调整的活动点的数量不可能超过任何给定时刻的 active_length。由于 active_length 从来不会超过 remainder，而 remainder 不仅在每个单一步骤里是 O(n)，而且对整个处理过程进行的 remainder 递增的总数也是 O(n)，因此调整活动点的数目也就限制在了 O(n)。 参考文章 https://www.cs.helsinki.fi/u/ukkonen/SuffixT1withFigs.pdf https://www.cnblogs.com/gaochundong/p/suffix_tree.html https://blog.csdn.net/v_july_v/article/details/6897097","tags":["算法","字符串匹配","模式预处理","后缀树","Suffix Tree"],"categories":["算法","字符串匹配","模式预处理"]},{"title":"8.字符串匹配 - 模式预处理：BM 算法 (Boyer-Moore)","path":"/2023/12/27/8-字符串匹配-模式预处理：BM-算法-Boyer-Moore/","content":"各种文本编辑器的”查找”功能（Ctrl+F），大多采用Boyer-Moore算法，效率非常高。 算法简介 在 1977 年，Robert S. Boyer (Stanford Research Institute) 和 J Strother Moore (Xerox Palo Alto Research Center) 共同发表了文章《A Fast String Searching Algorithm》，介绍了一种新的快速字符串匹配算法。这种算法在逻辑上相对于现有的算法有了显著的改进，它对要搜索的字符串进行倒序的字符比较，并且当字符比较不匹配时无需对整个模式串再进行搜索。 Boyer-Moore 算法的主要特点有： 对模式字符的比较顺序时从右向左； 预处理需要 O(m + σ) 的时间和空间复杂度； 匹配阶段需要 O(m × n) 的时间复杂度； 匹配阶段在最坏情况下需要 3n 次字符比较； 最优复杂度 O(n&#x2F;m)； 在 Naive 算法中，对文本 T 和模式 P 字符串均未做预处理。而在 KMP 算法中则对模式 P 字符串进行了预处理操作，以预先计算模式串中各位置的最长相同前后缀长度的数组。Boyer–Moore 算法同样也是对模式 P 字符串进行预处理。 我们知道，在 Naive 算法中，如果发现模式 P 中的字符与文本 T 中的字符不匹配时，需要将文本 T 的比较位置向后滑动一位，模式 P 的比较位置归 0 并从头开始比较。而 KMP 算法则是根据预处理的结果进行判断以使模式 P 的比较位置可以向后滑动多个位置。Boyer–Moore 算法的预处理过程也是为了达到相同效果。 Boyer–Moore 算法在对模式 P 字符串进行预处理时，将采用两种不同的启发式方法。这两种启发式的预处理方法称为： 坏字符（Bad Character Heuristic）：当文本 T 中的某个字符跟模式 P 的某个字符不匹配时，我们称文本 T 中的这个失配字符为坏字符。 好后缀（Good Suffix Heuristic）：当文本 T 中的某个字符跟模式 P 的某个字符不匹配时，我们称文本 T 中的已经匹配的字符串为好后缀。 Boyer–Moore 算法在预处理时，将为两种不同的启发法结果创建不同的数组，分别称为 Bad-Character-Shift（or The Occurrence Shift）和 Good-Suffix-Shift（or Matching Shift）。当进行字符匹配时，如果发现模式 P 中的字符与文本 T 中的字符不匹配时，将比较两种不同启发法所建议的移动位移长度，选择最大的一个值来对模式 P 的比较位置进行滑动。 此外，Naive 算法和 KMP 算法对模式 P 的比较方向是从前向后比较，而 Boyer–Moore 算法的设计则是从后向前比较，即从尾部向头部方向进行比较。 图例分析 例子来源于阮一峰的 字符串匹配的Boyer-Moore算法 下面，我根据Moore教授自己的例子来解释这种算法。 1. 假定字符串为”HERE IS A SIMPLE EXAMPLE”，搜索词为”EXAMPLE”。 2. 首先，”字符串”与”搜索词”头部对齐，从尾部开始比较。 这是一个很聪明的想法，因为如果尾部字符不匹配，那么只要一次比较，就可以知道前7个字符（整体上）肯定不是要找的结果。 我们看到，”S”与”E”不匹配。这时，”S”就被称为”坏字符”（bad character），即不匹配的字符。我们还发现，”S”不包含在搜索词”EXAMPLE”之中，这意味着可以把搜索词直接移到”S”的后一位。 3. 依然从尾部开始比较，发现”P”与”E”不匹配，所以”P”是”坏字符”。但是，”P”包含在搜索词”EXAMPLE”之中。所以，将搜索词后移两位，两个”P”对齐。 4. 我们由此总结出”坏字符规则”： 后移位数 &#x3D; 坏字符的位置 - 搜索词中的上一次出现位置 如果”坏字符”不包含在搜索词之中，则上一次出现位置为 -1。 以”P”为例，它作为”坏字符”，出现在搜索词的第6位（从0开始编号），在搜索词中的上一次出现位置为4，所以后移 6 - 4 &#x3D; 2位。再以前面第二步的”S”为例，它出现在第6位，上一次出现位置是 -1（即未出现），则整个搜索词后移 6 - (-1) &#x3D; 7位。 5. 依然从尾部开始比较，”E”与”E”匹配。 6. 比较前面一位，”LE”与”LE”匹配。 7. 比较前面一位，”PLE”与”PLE”匹配。 8. 比较前面一位，”MPLE”与”MPLE”匹配。我们把这种情况称为”好后缀”（good suffix），即所有尾部匹配的字符串。注意，”MPLE”、”PLE”、”LE”、”E”都是好后缀。 9. 比较前一位，发现”I”与”A”不匹配。所以，”I”是”坏字符”。 10. 根据”坏字符规则”，此时搜索词应该后移 2 - （-1）&#x3D; 3 位。问题是，此时有没有更好的移法？ 11. 我们知道，此时存在”好后缀”。所以，可以采用”好后缀规则”： 后移位数 &#x3D; 好后缀的位置 - 搜索词中的上一次出现位置 举例来说，如果字符串”ABCDAB”的后一个”AB”是”好后缀”。那么它的位置是5（从0开始计算，取最后的”B”的值），在”搜索词中的上一次出现位置”是1（第一个”B”的位置），所以后移 5 - 1 &#x3D; 4位，前一个”AB”移到后一个”AB”的位置。 再举一个例子，如果字符串”ABCDEF”的”EF”是好后缀，则”EF”的位置是5 ，上一次出现的位置是 -1（即未出现），所以后移 5 - (-1) &#x3D; 6位，即整个字符串移到”F”的后一位。 这个规则有三个注意点： “好后缀”的位置以最后一个字符为准。假定”ABCDEF”的”EF”是好后缀，则它的位置以”F”为准，即5（从0开始计算）。 如果”好后缀”在搜索词中只出现一次，则它的上一次出现位置为 -1。比如，”EF”在”ABCDEF”之中只出现一次，则它的上一次出现位置为-1（即未出现）。 如果”好后缀”有多个，则除了最长的那个”好后缀”，其他”好后缀”的上一次出现位置必须在头部。比如，假定”BABCDAB”的”好后缀”是”DAB”、”AB”、”B”，请问这时”好后缀”的上一次出现位置是什么？回答是，此时采用的好后缀是”B”，它的上一次出现位置是头部，即第0位。这个规则也可以这样表达：如果最长的那个”好后缀”只出现一次，则可以把搜索词改写成如下形式进行位置计算”(DA)BABCDAB”，即虚拟加入最前面的”DA”。 回到上文的这个例子。此时，所有的”好后缀”（MPLE、PLE、LE、E）之中，只有”E”在”EXAMPLE”还出现在头部，所以后移 6 - 0 &#x3D; 6位。 12. 可以看到，”坏字符规则”只能移3位，”好后缀规则”可以移6位。所以，Boyer-Moore算法的基本思想是，每次后移这两个规则之中的较大值。 更巧妙的是，这两个规则的移动位数，只与搜索词有关，与原字符串无关。因此，可以预先计算生成《坏字符规则表》和《好后缀规则表》。使用时，只要查表比较一下就可以了。 13. 继续从尾部开始比较，”P”与”E”不匹配，因此”P”是”坏字符”。根据”坏字符规则”，后移 6 - 4 &#x3D; 2位。 14. 从尾部开始逐位比较，发现全部匹配，于是搜索结束。如果还要继续查找（即找出全部匹配），则根据”好后缀规则”，后移 6 - 0 &#x3D; 6位，即头部的”E”移到尾部的”E”的位置。 从上面的示例描述可以看出，Boyer–Moore 算法的精妙之处在于，其通过两种启示规则来计算后移位数，且其计算过程只与模式 P 有关，而与文本 T 无关。因此，在对模式 P 进行预处理时，可预先生成 “坏字符规则之向后位移表” 和 “好后缀规则之向后位移表”，在具体匹配时仅需查表比较两者中最大的位移即可。 参考文章 http://www.ruanyifeng.com/blog/2013/05/boyer-moore_string_search_algorithm.html https://www.cnblogs.com/gaochundong/p/boyer_moore_string_matching_algorithm.html","tags":["算法","字符串匹配","模式预处理","BM 算法","Boyer-Moore"],"categories":["算法","字符串匹配","模式预处理"]},{"title":"7.字符串匹配 - 模式预处理：KMP 算法（Knuth-Morris-Pratt）","path":"/2023/12/27/7-字符串匹配-模式预处理：KMP-算法（Knuth-Morris-Pratt）/","content":"Knuth-Morris-Pratt算法（简称KMP）是最常用的字符串匹配算法之一。 算法简介 如下算法解释主要来源于这里，但是通常很难阅读完全，我推荐你直接进入下一节 图例解释部分。 我们来观察一下朴素的字符串匹配算法的操作过程。如下图（a）中所描述，在模式 P &#x3D; ababaca 和文本 T 的匹配过程中，模板的一个特定位移 s，q &#x3D; 5 个字符已经匹配成功，但模式 P 的第 6 个字符不能与相应的文本字符匹配。 此时，q 个字符已经匹配成功的信息确定了相应的文本字符，而知道这 q 个文本字符，就使我们能够立即确定某些位移是非法的。例如上图（a）中，我们可以判断位移 s+1 是非法的，因为模式 P 的第一个字符 a 将与模式的第二个字符 b 匹配的文本字符进行匹配，显然是不匹配的。而图（b）中则显示了位移 s’ &#x3D; s+2 处，使模式 P 的前三个字符和相应的三个文本字符对齐后必定会匹配。KMP 算法的基本思路就是设法利用这些已知信息，不要把 “搜索位置” 移回已经比较过的位置，而是继续把它向后面移，这样就提高了匹配效率。 The basic idea behind KMP’s algorithm is: whenever we detect a mismatch (after some matches), we already know some of the characters in the text (since they matched the pattern characters prior to the mismatch). We take advantage of this information to avoid matching the characters that we know will anyway match. 已知模式 P[1..q] 与文本 T[s+1..s+q] 匹配，那么满足 P[1..k] &#x3D; T[s’+1..s’+k] 其中 s’+k &#x3D; s+q 的最小位移 s’ &gt; s 是多少？这样的位移 s’ 是大于 s 的但未必非法的第一个位移，因为已知 T[s+1..s+q] 。在最好的情况下有 s’ &#x3D; s+q，因此立刻能排除掉位移 s+1, s+2 .. s+q-1。在任何情况下，对于新的位移 s’，无需把 P 的前 k 个字符与 T 中相应的字符进行比较，因为它们肯定匹配。 可以用模式 P 与其自身进行比较，以预先计算出这些必要的信息。例如上图（c）中所示，由于 T[s’+1..s’+k] 是文本中已经知道的部分，所以它是字符串 Pq 的一个后缀。 此处我们引入模式的前缀函数 π（Pai），π 包含有模式与其自身的位移进行匹配的信息。这些信息可用于避免在朴素的字符串匹配算法中，对无用位移进行测试。 1π[q] = max &#123;k : k &lt; q and Pk ⊐ Pq&#125; π[q] 代表当前字符之前的字符串中，最长的共同前缀后缀的长度。（π[q] is the length of the longest prefix of P that is a proper suffix of Pq.） 下图给出了关于模式 P &#x3D; ababababca 的完整前缀函数 π，可称为部分匹配表（Partial Match Table）。 计算过程： π[1] &#x3D; 0，a 仅一个字符，前缀和后缀为空集，共有元素最大长度为 0； π[2] &#x3D; 0，ab 的前缀 a，后缀 b，不匹配，共有元素最大长度为 0； π[3] &#x3D; 1，aba，前缀 a ab，后缀 ba a，共有元素最大长度为 1； π[4] &#x3D; 2，abab，前缀 a ab aba，后缀 bab ab b，共有元素最大长度为 2； π[5] &#x3D; 3，ababa，前缀 a ab aba abab，后缀 baba aba ba a，共有元素最大长度为 3； π[6] &#x3D; 4，ababab，前缀 a ab aba abab ababa，后缀 babab abab bab ab b，共有元素最大长度为 4； π[7] &#x3D; 5，abababa，前缀 a ab aba abab ababa ababab，后缀 bababa ababa baba aba ba a，共有元素最大长度为 5； π[8] &#x3D; 6，abababab，前缀 .. ababab ..，后缀 .. ababab ..，共有元素最大长度为 6； π[9] &#x3D; 0，ababababc，前缀和后缀不匹配，共有元素最大长度为 0； π[10] &#x3D; 1，ababababca，前缀 .. a ..，后缀 .. a ..，共有元素最大长度为 1； KMP 算法 KMP-MATCHER 中通过调用 COMPUTE-PREFIX-FUNCTION 函数来计算部分匹配表。 12345678910111213KMP-MATCHER(T, P)n ← length[T]m ← length[P]π ← COMPUTE-PREFIX-FUNCTION(P)q ← 0 //Number of characters matched.for i ← 1 to n //Scan the text from left to right. do while q &gt; 0 and P[q + 1] ≠ T[i] do q ← π[q] //Next character does not match. if P[q + 1] = T[i] then q ← q + 1 //Next character matches. if q = m //Is all of P matched? then print &quot;Pattern occurs with shift&quot; i - m q ← π[q] //Look for the next match. 1234567891011COMPUTE-PREFIX-FUNCTION(P)m ← length[P]π[1] ← 0k ← 0for q ← 2 to m do while k &gt; 0 and P[k + 1] ≠ P[q] do k ← π[k] if P[k + 1] = P[q] then k ← k + 1 π[q] ← kreturn π 预处理过程 COMPUTE-PREFIX-FUNCTION 的运行时间为 Θ(m)，KMP-MATCHER 的匹配时间为 Θ(n)。 相比较于 NAIVE-STRING-MATCHER，KMP-MATCHER 的主要优化点就是在当确定字符不匹配时对于 pattern 的位移。 NAIVE-STRING-MATCHER 的位移效果是：文本向后移一位，模式从头开始。 12s = s - j + 1;j = 0; KMP-MATCHER 首先对模式做了获取共同前缀后缀最大长度的预处理操作，位移过程是先将模式向后移 partial_match_length - table[partial_match_length - 1]，然后再判断是否匹配。这样通过对已匹配字符串的已知信息的利用，可以有效节省比较数量。 1234if (j != 0) j = lps[j - 1];else s++; 下面描述了当发现字符 j 与 c 不匹配时的位移效果。 1234567891011121314151617181920// partial_match_length - table[partial_match_length - 1]rrababababjjjjjiiooorababababcauuu ||||||||- ababababca// 8-6=2rrababababjjjjjiiooorababababcauuu xx||||||- ababababca// 6-4=2rrababababjjjjjiiooorababababcauuu xx||||- ababababca// 4-2=2rrababababjjjjjiiooorababababcauuu xx||- ababababca// 2-0=2rrababababjjjjjiiooorababababcauuu xx- ababababca 综上可知，KMP 算法的主要特点是： 需要对模式字符串做预处理； 预处理阶段需要额外的 O(m) 空间和复杂度； 匹配阶段与字符集的大小无关； 匹配阶段至多执行 2n - 1 次字符比较； 对模式中字符的比较顺序时从左到右； 算法图例 如下是阮一峰根据Jake Boxer的文章总结的图例。 下面，我用自己的语言，试图写一篇比较好懂的KMP算法解释。 1. 首先，字符串”BBC ABCDAB ABCDABCDABDE”的第一个字符与搜索词”ABCDABD”的第一个字符，进行比较。因为B与A不匹配，所以搜索词后移一位。 2. 因为B与A不匹配，搜索词再往后移。 3. 就这样，直到字符串有一个字符，与搜索词的第一个字符相同为止。 4. 接着比较字符串和搜索词的下一个字符，还是相同。 5. 直到字符串有一个字符，与搜索词对应的字符不相同为止。 6. 这时，最自然的反应是，将搜索词整个后移一位，再从头逐个比较。这样做虽然可行，但是效率很差，因为你要把”搜索位置”移到已经比较过的位置，重比一遍。 7. 一个基本事实是，当空格与D不匹配时，你其实知道前面六个字符是”ABCDAB”。KMP算法的想法是，设法利用这个已知信息，不要把”搜索位置”移回已经比较过的位置，继续把它向后移，这样就提高了效率。 8. 怎么做到这一点呢？可以针对搜索词，算出一张《部分匹配表》（Partial Match Table）。这张表是如何产生的，后面再介绍，这里只要会用就可以了。 9. 已知空格与D不匹配时，前面六个字符”ABCDAB”是匹配的。查表可知，最后一个匹配字符B对应的”部分匹配值”为2，因此按照下面的公式算出向后移动的位数： 移动位数 &#x3D; 已匹配的字符数 - 对应的部分匹配值 因为 6 - 2 等于4，所以将搜索词向后移动4位。 10. 因为空格与Ｃ不匹配，搜索词还要继续往后移。这时，已匹配的字符数为2（”AB”），对应的”部分匹配值”为0。所以，移动位数 &#x3D; 2 - 0，结果为 2，于是将搜索词向后移2位。 11. 因为空格与A不匹配，继续后移一位。 12. 逐位比较，直到发现C与D不匹配。于是，移动位数 &#x3D; 6 - 2，继续将搜索词向后移动4位。 13. 逐位比较，直到搜索词的最后一位，发现完全匹配，于是搜索完成。如果还要继续搜索（即找出全部匹配），移动位数 &#x3D; 7 - 0，再将搜索词向后移动7位，这里就不再重复了。 14. 下面介绍《部分匹配表》是如何产生的。 首先，要了解两个概念：”前缀”和”后缀”。 “前缀”指除了最后一个字符以外，一个字符串的全部头部组合；”后缀”指除了第一个字符以外，一个字符串的全部尾部组合。 15. “部分匹配值”就是”前缀”和”后缀”的最长的共有元素的长度。以”ABCDABD”为例， 12345678910111213 －　&quot;A&quot;的前缀和后缀都为空集，共有元素的长度为0； －　&quot;AB&quot;的前缀为[A]，后缀为[B]，共有元素的长度为0； －　&quot;ABC&quot;的前缀为[A, AB]，后缀为[BC, C]，共有元素的长度0； －　&quot;ABCD&quot;的前缀为[A, AB, ABC]，后缀为[BCD, CD, D]，共有元素的长度为0； －　&quot;ABCDA&quot;的前缀为[A, AB, ABC, ABCD]，后缀为[BCDA, CDA, DA, A]，共有元素为&quot;A&quot;，长度为1； －　&quot;ABCDAB&quot;的前缀为[A, AB, ABC, ABCD, ABCDA]，后缀为[BCDAB, CDAB, DAB, AB, B]，共有元素为&quot;AB&quot;，长度为2； －　&quot;ABCDABD&quot;的前缀为[A, AB, ABC, ABCD, ABCDA, ABCDAB]，后缀为[BCDABD, CDABD, DABD, ABD, BD, D]，共有元素的长度为0。 16. “部分匹配”的实质是，有时候，字符串头部和尾部会有重复。比如，”ABCDAB”之中有两个”AB”，那么它的”部分匹配值”就是2（”AB”的长度）。搜索词移动的时候，第一个”AB”向后移动4位（字符串长度-部分匹配值），就可以来到第二个”AB”的位置。 参考文章 http://jakeboxer.com/blog/2009/12/13/the-knuth-morris-pratt-algorithm-in-my-own-words/ https://www.cnblogs.com/gaochundong/p/string_matching.html#kmp_string_matching_algorithm http://www.ruanyifeng.com/blog/2013/05/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm.html","tags":["算法","字符串匹配","模式预处理","KMP 算法","Knuth-Morris-Pratt"],"categories":["算法","字符串匹配","模式预处理"]},{"title":"6.字符串匹配 - 模式预处理：朴素算法（Naive)(暴力破解)","path":"/2023/12/27/6-字符串匹配-模式预处理：朴素算法（Naive-暴力破解）/","content":"朴素的字符串匹配算法又称为暴力匹配算法（Brute Force Algorithm），最为简单的字符串匹配算法。 算法简介 朴素的字符串匹配算法又称为暴力匹配算法（Brute Force Algorithm），它的主要特点是： 没有预处理阶段； 滑动窗口总是后移 1 位； 对模式中的字符的比较顺序不限定，可以从前到后，也可以从后到前； 匹配阶段需要 O((n - m + 1)m) 的时间复杂度； 需要 2n 次的字符比较； 很显然，朴素的字符串匹配算法 NAIVE-STRING-MATCHER 是最原始的算法，它通过使用循环来检查是否在范围 n-m+1 中存在满足条件 P[1..m] &#x3D; T [s + 1..s + m] 的有效位移 s。 伪代码如下： 123456NAIVE-STRING-MATCHER(T, P) n ← length[T] m ← length[P] for s ← 0 to n - m do if P[1 .. m] = T[s + 1 .. s + m] then print &quot;Pattern occurs with shift&quot; s 如上图中，对于模式 P &#x3D; aab 和文本 T &#x3D; acaabc，将模式 P 沿着 T 从左到右滑动，逐个比较字符以判断模式 P 在文本 T 中是否存在。 可以看出，NAIVE-STRING-MATCHER 没有对模式 P 进行预处理，所以预处理的时间为 0。而匹配的时间在最坏情况下为 Θ((n-m+1)m)，如果 m &#x3D; [n&#x2F;2]，则为 Θ(n2)。 图例分析假设有两个字符串： M&#x3D;”abcdefabcdx”; T&#x3D;”abcdx”; 想要找到T串在M串中的位置，要怎么找呢？ 也就是说，从主串M的第一个字符开始分别与子串从开头进行比较，当发现不匹配时，主串回到这一轮开始的下一个字符，子串从头开始比较。直到子串所有的字符都匹配，返回所在主串中的下标。 算法复杂度假设S的长度是m，T的长度是n，暂不考虑pos，从字符串S的开头开始比较。 最好的情况是第一次就匹配了，需要比较的次数是n. 最坏的情况下，就是上面举的这种例子，需要把整个字符串都比较完，从下面的代码中就体现为把两层循环都跑了一遍。这时候，比较的次数就是t*(s-t+1). 所以这个算法的(最坏)时间复杂度就是o(t(s-t+1))，近似为o(n2). 参考文章 https://www.cnblogs.com/gaochundong/p/string_matching.html#kmp_string_matching_algorithm https://blog.csdn.net/u013301192/article/details/48507695","tags":["算法","字符串匹配","模式预处理","朴素算法","Naive"],"categories":["算法","字符串匹配","模式预处理","朴素算法","Naive"]},{"title":"5.字符串匹配 - Overview","path":"/2023/12/27/5-字符串匹配-Overview/","content":"字符串匹配 - Overview 字符串匹配(String Matchiing)也称字符串搜索(String Searching)是字符串算法中重要的一种，是指从一个大字符串或文本中找到模式串出现的位置。 字符串匹配概念 字符串匹配问题的形式定义： 文本（Text）是一个长度为 n 的数组 T[1..n]； 模式（Pattern）是一个长度为 m 且 m≤n 的数组 P[1..m]； T 和 P 中的元素都属于有限的字母表 Σ 表； 如果 0≤s≤n-m，并且 T[s+1..s+m] &#x3D; P[1..m]，即对 1≤j≤m，有 T[s+j] &#x3D; P[j]，则说模式 P 在文本 T 中出现且位移为 s，且称 s 是一个有效位移（Valid Shift）。 比如上图中，目标是找出所有在文本 T &#x3D; abcabaabcabac 中模式 P &#x3D; abaa 的所有出现。该模式在此文本中仅出现一次，即在位移 s &#x3D; 3 处，位移 s &#x3D; 3 是有效位移。 字符串匹配算法通常分为两个步骤：预处理（Preprocessing）和匹配（Matching）。所以算法的总运行时间为预处理和匹配的时间的总和。 上图描述了常见字符串匹配算法的预处理和匹配时间。 字符串匹配算法 解决字符串匹配的算法包括：朴素算法（Naive Algorithm） 即暴力破解、Rabin-Karp 算法、有限自动机算法（Finite Automation）、 Knuth-Morris-Pratt 算法（即 KMP Algorithm）、Boyer-Moore 算法、Simon 算法、Colussi 算法、Galil-Giancarlo 算法、Apostolico-Crochemore 算法、Horspool 算法和 Sunday 算法等。 朴素的字符串匹配算法（Naive String Matching Algorithm) 朴素的字符串匹配算法又称为暴力匹配算法（Brute Force Algorithm），最为简单的字符串匹配算法 Knuth-Morris-Pratt 字符串匹配算法（即 KMP 算法） Knuth-Morris-Pratt算法（简称KMP）是最常用的字符串匹配算法之一 Boyer-Moore 字符串匹配算法 各种文本编辑器的”查找”功能（Ctrl+F），大多采用Boyer-Moore算法，效率非常高 字符串匹配 - 文本预处理：后缀树（Suffix Tree） 上述字符串匹配算法(朴素的字符串匹配算法, KMP 算法, Boyer-Moore算法)均是通过对模式（Pattern）字符串进行预处理的方式来加快搜索速度。对 Pattern 进行预处理的最优复杂度为 O(m)，其中 m 为 Pattern 字符串的长度。那么，有没有对文本（Text）进行预处理的算法呢？本文即将介绍一种对 Text 进行预处理的字符串匹配算法：后缀树（Suffix Tree）","tags":["算法","字符串匹配"],"categories":["算法","字符串匹配"]},{"title":"4.安全算法 - 国密算法","path":"/2023/12/27/4-安全算法-国密算法/","content":"国密即国家密码局认定的国产密码算法。主要有SM1，SM2，SM3，SM4，SM7, SM9。 国密算法分类 国家标准官方网站如下：http://openstd.samr.gov.cn/bzgk/gb/ SM1 为对称加密。其加密强度与AES相当。该算法不公开，调用该算法时，需要通过加密芯片的接口进行调用。 SM2 非对称加密，基于ECC。该算法已公开。由于该算法基于ECC，故其签名速度与秘钥生成速度都快于RSA。ECC 256位（SM2采用的就是ECC 256位的一种）安全强度比RSA 2048位高，但运算速度快于RSA。 SM3 消息摘要。可以用MD5作为对比理解。该算法已公开。校验结果为256位。 SM4 无线局域网标准的分组数据算法。对称加密，密钥长度和分组长度均为128位。 SM7 是一种分组密码算法，分组长度为128比特，密钥长度为128比特。SM7适用于非接触式IC卡，应用包括身份识别类应用(门禁卡、工作证、参赛证)，票务类应用(大型赛事门票、展会门票)，支付与通卡类应用（积分消费卡、校园一卡通、企业一卡通等）。 SM9 不需要申请数字证书，适用于互联网应用的各种新兴应用的安全保障。如基于云技术的密码服务、电子邮件安全、智能终端保护、物联网安全、云存储安全等等。这些安全应用可采用手机号码或邮件地址作为公钥，实现数据加密、身份认证、通话加密、通道加密等安全应用，并具有使用方便，易于部署的特点，从而开启了普及密码算法的大门。 SM2算法 SM2算法：SM2椭圆曲线公钥密码算法是我国自主设计的公钥密码算法，包括SM2-1椭圆曲线数字签名算法，SM2-2椭圆曲线密钥交换协议，SM2-3椭圆曲线公钥加密算法，分别用于实现数字签名密钥协商和数据加密等功能。SM2算法与RSA算法不同的是，SM2算法是基于椭圆曲线上点群离散对数难题，相对于RSA算法，256位的SM2密码强度已经比2048位的RSA密码强度要高。 SM2公钥加密算法比RSA相对复杂，加密结果由3个部分组成，SM2加密过程中使用了随机数，因此同样的明文数据每一次加密结果都不一样。但是这并不能防御重放攻击，如果要防御重放攻击，需要服务端提供加密因子，通过SM2SM4混合算法来抵御重放攻击。 学习sm2算法，首先学习ECC算法 ECC算法描述： 1、用户A选定一条适合加密的椭圆曲线Ep(a,b)(如:y2&#x3D;x3+ax+b)，并取椭圆曲线上一点，作为基点G。 2、用户A选择一个私有密钥k，并生成公开密钥（公钥PB）K&#x3D;kG。 3、用户A将Ep(a,b)和点（公钥）K，G传给用户B。 4、用户B接到信息后 ，将待传输的明文（M）编码到Ep(a,b)上一点M，并产生一个随机整数r（r&lt;n）。加密开始 5、用户B计算点C1&#x3D;M+rK；C2&#x3D;rG。 6、用户B将C1、C2传给用户A。 7、用户A接到信息后，计算C1-kC2，结果就是点M。因为C1-kC2&#x3D;M+rK-k(rG)&#x3D;M+rK-r(kG)&#x3D;M; 再对点M进行解码就可以得到明文。 密码学中，描述一条Fp上的椭圆曲线，常用到六个参量：T&#x3D;(p,a,b,G,n,h)。（p 、a 、b 用来确定一条椭圆曲线，G为基点，n为点G的阶，h 是椭圆曲线上所有点的个数m与n相除的整数部分）这几个参量取值的选择，直接影响了加密的安全性。参量值一般要求满足以下几个条件： 1、p 当然越大越安全，但越大，计算速度会变慢，200位左右可以满足一般安全要求； 2、p≠n×h； 3、pt≠1 (mod n)，1≤t&lt;20； 4、4a3+27b2≠0 (mod p)； 5、n 为素数； 6、h≤4。 所以关于sm2算法的流程如图 SM2算法就是ECC椭圆曲线密码机制，但在签名、密钥交换方面不同于ECDSA、ECDH等国际标准，而是采取了更为安全的机制。另外，SM2推荐了一条256位的曲线作为标准曲线。 SM2标准包括总则，数字签名算法，密钥交换协议，公钥加密算法四个部分，并在每个部分的附录详细说明了实现的相关细节及示例。 SM2算法主要考虑素域Fp和F2m上的椭圆曲线，分别介绍了这两类域的表示，运算，以及域上的椭圆曲线的点的表示，运算和多倍点计算算法。然后介绍了编程语言中的数据转换，包括整数和字节串，字节串和比特串，域元素和比特串，域元素和整数，点和字节串之间的数据转换规则。 详细说明了有限域上椭圆曲线的参数生成以及验证，椭圆曲线的参数包括有限域的选取，椭圆曲线方程参数，椭圆曲线群基点的选取等，并给出了选取的标准以便于验证。最后给椭圆曲线上密钥对的生成以及公钥的验证，用户的密钥对为（s，sP），其中s为用户的私钥，sP为用户的公钥，由于离散对数问题从sP难以得到s，并针对素域和二元扩域给出了密钥对生成细节和验证方式。总则中的知识也适用于SM9算法。 在总则的基础上给出了数字签名算法（包括数字签名生成算法和验证算法），密钥交换协议以及公钥加密算法（包括加密算法和解密算法），并在每个部分给出了算法描述，算法流程和相关示例。 数字签名算法，密钥交换协议以及公钥加密算法都使用了国家密管理局批准的SM3密码杂凑算法和随机数发生器。数字签名算法，密钥交换协议以及公钥加密算法根据总则来选取有限域和椭圆曲线，并生成密钥对。 SM2算法在很多方面都优于RSA算法（RSA发展得早应用普遍，SM2领先也很自然），与RSA安全性对比如下图 SM3算法 SM3算法：SM3杂凑算法是我国自主设计的密码杂凑算法，适用于商用密码应用中的数字签名和验证消息认证码的生成与验证以及随机数的生成，可满足多种密码应用的安全需求。为了保证杂凑算法的安全性，其产生的杂凑值的长度不应太短，例如MD5输出128比特杂凑值，输出长度太短，影响其安全性SHA-1算法的输出长度为160比特，SM3算法的输出长度为256比特，因此SM3算法的安全性要高于MD5算法和SHA-1算法。 对长度为l(l&lt;2^64)比特的消息m，SM3杂凑算法经过填充和迭代压缩，生成杂凑值，杂凑值长度为256比特。 假设消息m的长度为l比特。首先将比特“1”添加到消息的末尾，再添加k个“0”，k是满足l+1+k448mod512的最小的非负整数。然后再添加一个64位比特串，该比特串是长度l的二进制表示。 填充后的消息m′的比特长度为512的倍数。 例如：对消息01100001 01100010 01100011，其长度l&#x3D;24，经填充得到比特串： 01100001 01100010 01100011 1 00…00（423比特）00…011000（64比特l的二进制表示） 下面的是实现了SM3的标准输出 SM4算法 此算法是一个分组算法，用于无线局域网产品。该算法的分组长度为128比特，密钥长度为128比特。加密算法与密钥扩展算法都采用32轮非线性迭代结构。解密算法与加密算法的结构相同，只是轮密钥的使用顺序相反，解密轮密钥是加密轮密钥的逆序。 此算法采用非线性迭代结构，每次迭代由一个轮函数给出，其中轮函数由一个非线性变换和线性变换复合而成，非线性变换由S盒所给出。其中rki为轮密钥，合成置换T组成轮函数。轮密钥的产生与上图流程类似，由加密密钥作为输入生成，轮函数中的线性变换不同，还有些参数的区别。 过程: 基本运算：SM4密码算法使用模2加和循环移位作为基本运算。 基本密码部件：SM4密码算法使用了S盒、非线性变换τ、线性变换部件L、合成变换T基本密码部件。 轮函数：SM4密码算法采用对基本轮函数进行迭代的结构。利用上述基本密码部件，便可构成轮函数。SM4密码算法的轮函数是一种以字为处理单位的密码函数。 加密算法：SM4密码算法是一个分组算法。数据分组长度为128比特，密钥长度为128比特。加密算法采用32轮迭代结构，每轮使用一个轮密钥。 解密算法：SM4密码算法是对合运算，因此解密算法与加密算法的结构相同，只是轮密铝的使用顺序相反，解密轮密钥是加密轮密钥的逆序。 密钥扩展算法：SM4密码算法使用128位的加密密钥，并采用32轮法代加密结构，每一轮加密使用一个32位的轮密钥，共使用32个轮密钥。因此需要使用密钥扩展算法，从加密密钥产生出32个轮密钥。 SM4的安全性：SM4密码算法经过我国专业密码机构的充分分析测试，可以抵抗差分攻击、线性攻击等现有攻击，因此是安全的。 SM4实例: SM7算法SM7算法，是一种分组密码算法，分组长度为128比特，密钥长度为128比特。SM7适用于非接触式IC卡，应用包括身份识别类应用(门禁卡、工作证、参赛证)，票务类应用(大型赛事门票、展会门票)，支付与通卡类应用（积分消费卡、校园一卡通、企业一卡通等）。 SM9算法为了降低公开密钥系统中密钥和证书管理的复杂性，以色列科学家、RSA算法发明人之一Adi Shamir在1984年提出了标识密码（Identity-Based Cryptography）的理念。标识密码将用户的标识（如邮件地址、手机号码、QQ号码等）作为公钥，省略了交换数字证书和公钥过程，使得安全系统变得易于部署和管理，非常适合端对端离线安全通讯、云端数据加密、基于属性加密、基于策略加密的各种场合。2008年标识密码算法正式获得国家密码管理局颁发的商密算法型号：SM9(商密九号算法)，为我国标识密码技术的应用奠定了坚实的基础。 SM9算法不需要申请数字证书，适用于互联网应用的各种新兴应用的安全保障。如基于云技术的密码服务、电子邮件安全、智能终端保护、物联网安全、云存储安全等等。这些安全应用可采用手机号码或邮件地址作为公钥，实现数据加密、身份认证、通话加密、通道加密等安全应用，并具有使用方便，易于部署的特点，从而开启了普及密码算法的大门。 相关工具GmSSLGmSSL是一个开源的密码工具箱，支持SM2&#x2F;SM3&#x2F;SM4&#x2F;SM9等国密(国家商用密码)算法、SM2国密数字证书及基于SM2证书的SSL&#x2F;TLS安全通信协议，支持国密硬件密码设备，提供符合国密规范的编程接口与命令行工具，可以用于构建PKI&#x2F;CA、安全通信、数据加密等符合国密标准的安全应用。GmSSL项目是OpenSSL项目的分支，并与OpenSSL保持接口兼容。因此GmSSL可以替代应用中的OpenSSL组件，并使应用自动具备基于国密的安全能力。GmSSL项目采用对商业应用友好的类BSD开源许可证，开源且可以用于闭源的商业应用。GmSSL项目由北京大学关志副研究员的密码学研究组开发维护，项目源码托管于GitHub。自2014年发布以来，GmSSL已经在多个项目和产品中获得部署与应用，并获得2015年度“一铭杯”中国Linux软件大赛二等奖(年度最高奖项)与开源中国密码类推荐项目。GmSSL项目的核心目标是通过开源的密码技术推动国内网络空间安全建设。 参考文章 《科普一下SM系列国密算法（从零开始学区块链）》 https://blog.csdn.net/qq_33430322/article/details/106687662","tags":["算法","安全算法","国密算法"],"categories":["算法","安全算法"]},{"title":"3.安全算法 - 加密算法","path":"/2023/12/27/3-安全算法-加密算法/","content":"本文主要介绍安全算法之加密算法。 数据加密的基本过程就是对原来为明文的文件或数据按某种算法进行处理，使其成为不可读的一段代码为“密文”，使其只能在输入相应的密钥之后才能显示出原容，通过这样的途径来达到保护数据不被非法人窃取、阅读的目的。 该过程的逆过程为解密，即将该编码信息转化为其原来数据的过程。 加密算法简介 加密技术包括两个元素: 加密算法和密钥。 加密算法是将普通的文本(或者可以理解的信息)与一串数字(密钥)的结合，产生不可理解的密文的步骤。 密钥是用来对数据进行编码和解码的一种算法。 在安全保密中，可通过适当的密钥加密技术和管理机制来保证网络的信息通讯安全。 加密算法分类密钥加密技术的密码体制分为对称密钥体制和非对称密钥体制两种。相应地，对数据加密的技术分为两类，即对称加密(私人密钥加密)和非对称加密(公开密钥加密)。 对称加密以数据加密标准(DES，Data Encryption Standard)算法为典型代表，非对称加密通常以RSA(Rivest Shamir Adleman)算法为代表。 对称加密的加密密钥和解密密钥相同。非对称加密的加密密钥和解密密钥不同，加密密钥可以公开而解密密钥需要保密 加密算法应用常被用在电子商务或者其他需要保证网络传输安全的范围。 对称加密加密密钥和解密密钥相同的加密算法。 对称加密算法使用起来简单快捷，密钥较短，且破译困难，除了数据加密标准(DES)， 另一个对称密钥加密系统是国际数据加密算法(IDEA)，它比DES的加密性好，而且对计算机功能要求也没有那么高。IDEA加密标准由PGP(Pretty Good Privacy)系统使用。 DESDES全称为Data Encryption Standard，即数据加密标准，是一种使用密钥加密的块算法，现在已经过时。 代码实现DES算法实现 : 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package com.snailclimb.ks.securityAlgorithm;import java.io.UnsupportedEncodingException;import java.security.SecureRandom;import javax.crypto.spec.DESKeySpec;import javax.crypto.SecretKeyFactory;import javax.crypto.SecretKey;import javax.crypto.Cipher;/ * DES加密介绍 DES是一种对称加密算法，所谓对称加密算法即: 加密和解密使用相同密钥的算法。DES加密算法出自IBM的研究， * 后来被美国政府正式采用，之后开始广泛流传，但是近些年使用越来越少，因为DES使用56位密钥，以现代计算能力， * 24小时内即可被破解。虽然如此，在某些简单应用中，我们还是可以使用DES加密算法，本文简单讲解DES的JAVA实现 。 * 注意: DES加密和解密过程中，密钥长度都必须是8的倍数 */public class DesDemo &#123;\tpublic DesDemo() &#123;\t&#125;\t// 测试\tpublic static void main(String args[]) &#123; // 待加密内容 String str = &quot;cryptology&quot;; // 密码，长度要是8的倍数 String password = &quot;95880288&quot;; byte[] result; try &#123; result = DesDemo.encrypt(str.getBytes(), password); System.out.println(&quot;加密后: &quot; + result); byte[] decryResult = DesDemo.decrypt(result, password); System.out.println(&quot;解密后: &quot; + new String(decryResult)); &#125; catch (UnsupportedEncodingException e2) &#123; // TODO Auto-generated catch block e2.printStackTrace(); &#125; catch (Exception e1) &#123; e1.printStackTrace(); &#125;\t&#125;\t// 直接将如上内容解密\t/ * 加密 * * @param datasource * byte[] * @param password * String * @return byte[] */\tpublic static byte[] encrypt(byte[] datasource, String password) &#123; try &#123; SecureRandom random = new SecureRandom(); DESKeySpec desKey = new DESKeySpec(password.getBytes()); // 创建一个密匙工厂，然后用它把DESKeySpec转换成 SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(&quot;DES&quot;); SecretKey securekey = keyFactory.generateSecret(desKey); // Cipher对象实际完成加密操作 Cipher cipher = Cipher.getInstance(&quot;DES&quot;); // 用密匙初始化Cipher对象,ENCRYPT_MODE用于将 Cipher 初始化为加密模式的常量 cipher.init(Cipher.ENCRYPT_MODE, securekey, random); // 现在，获取数据并加密 // 正式执行加密操作 return cipher.doFinal(datasource); // 按单部分操作加密或解密数据，或者结束一个多部分操作 &#125; catch (Throwable e) &#123; e.printStackTrace(); &#125; return null;\t&#125;\t/ * 解密 * * @param src * byte[] * @param password * String * @return byte[] * @throws Exception */\tpublic static byte[] decrypt(byte[] src, String password) throws Exception &#123; // DES算法要求有一个可信任的随机数源 SecureRandom random = new SecureRandom(); // 创建一个DESKeySpec对象 DESKeySpec desKey = new DESKeySpec(password.getBytes()); // 创建一个密匙工厂 SecretKeyFactory keyFactory = SecretKeyFactory.getInstance(&quot;DES&quot;);// 返回实现指定转换的 // Cipher // 对象 // 将DESKeySpec对象转换成SecretKey对象 SecretKey securekey = keyFactory.generateSecret(desKey); // Cipher对象实际完成解密操作 Cipher cipher = Cipher.getInstance(&quot;DES&quot;); // 用密匙初始化Cipher对象 cipher.init(Cipher.DECRYPT_MODE, securekey, random); // 真正开始解密操作 return cipher.doFinal(src);\t&#125;&#125; 结果: 12加密后: [B@50cbc42f解密后: cryptology IDEA 这种算法是在DES算法的基础上发展出来的，类似于三重DES。 发展IDEA也是因为感到DES具有密钥太短等缺点。 DEA的密钥为128位，这么长的密钥在今后若干年内应该是安全的。 在实际项目中用到的很少了解即可。 代码实现IDEA算法实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.snailclimb.ks.securityAlgorithm;import java.security.Key;import java.security.Security;import javax.crypto.Cipher;import javax.crypto.KeyGenerator;import javax.crypto.SecretKey;import javax.crypto.spec.SecretKeySpec;import org.apache.commons.codec.binary.Base64;import org.bouncycastle.jce.provider.BouncyCastleProvider;public class IDEADemo &#123;\tpublic static void main(String args[]) &#123; bcIDEA();\t&#125;\tpublic static void bcIDEA() &#123; String src = &quot;www.xttblog.com security idea&quot;; try &#123; Security.addProvider(new BouncyCastleProvider()); //生成key KeyGenerator keyGenerator = KeyGenerator.getInstance(&quot;IDEA&quot;); keyGenerator.init(128); SecretKey secretKey = keyGenerator.generateKey(); byte[] keyBytes = secretKey.getEncoded(); //转换密钥 Key key = new SecretKeySpec(keyBytes, &quot;IDEA&quot;); //加密 Cipher cipher = Cipher.getInstance(&quot;IDEA/ECB/ISO10126Padding&quot;); cipher.init(Cipher.ENCRYPT_MODE, key); byte[] result = cipher.doFinal(src.getBytes()); System.out.println(&quot;bc idea encrypt : &quot; + Base64.encodeBase64String(result)); //解密 cipher.init(Cipher.DECRYPT_MODE, key); result = cipher.doFinal(result); System.out.println(&quot;bc idea decrypt : &quot; + new String(result)); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;\t&#125;&#125; 非对称加密 与对称加密算法不同，非对称加密算法需要两个密钥: 公开密钥(publickey)和私有密钥 (privatekey)。 公开密钥与私有密钥是一对，如果用公开密钥对数据进行加密，只有用对应的私有密钥才能解密； 如果用私有密钥对数据进行加密，那么只有用对应的公开密钥才能解密。 因为加密和解密使用的是两个不同的密钥，所以这种算法叫作非对称加密算法。 RSARSA是目前最有影响力和最常用的公钥加密算法。它能够抵抗到目前为止已知的绝大多数密码攻击，已被ISO推荐为公钥数据加密标准。 代码实现RAS算法实现: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249package com.snailclimb.ks.securityAlgorithm;import org.apache.commons.codec.binary.Base64;import java.security.*;import java.security.spec.PKCS8EncodedKeySpec;import java.security.spec.X509EncodedKeySpec;import java.util.HashMap;import java.util.Map;import javax.crypto.Cipher;/ * Created by humf.需要依赖 commons-codec 包 */public class RSADemo &#123;\tpublic static void main(String[] args) throws Exception &#123; Map&lt;String, Key&gt; keyMap = initKey(); String publicKey = getPublicKey(keyMap); String privateKey = getPrivateKey(keyMap); System.out.println(keyMap); System.out.println(&quot;-----------------------------------&quot;); System.out.println(publicKey); System.out.println(&quot;-----------------------------------&quot;); System.out.println(privateKey); System.out.println(&quot;-----------------------------------&quot;); byte[] encryptByPrivateKey = encryptByPrivateKey(&quot;123456&quot;.getBytes(), privateKey); byte[] encryptByPublicKey = encryptByPublicKey(&quot;123456&quot;, publicKey); System.out.println(encryptByPrivateKey); System.out.println(&quot;-----------------------------------&quot;); System.out.println(encryptByPublicKey); System.out.println(&quot;-----------------------------------&quot;); String sign = sign(encryptByPrivateKey, privateKey); System.out.println(sign); System.out.println(&quot;-----------------------------------&quot;); boolean verify = verify(encryptByPrivateKey, publicKey, sign); System.out.println(verify); System.out.println(&quot;-----------------------------------&quot;); byte[] decryptByPublicKey = decryptByPublicKey(encryptByPrivateKey, publicKey); byte[] decryptByPrivateKey = decryptByPrivateKey(encryptByPublicKey, privateKey); System.out.println(decryptByPublicKey); System.out.println(&quot;-----------------------------------&quot;); System.out.println(decryptByPrivateKey);\t&#125;\tpublic static final String KEY_ALGORITHM = &quot;RSA&quot;;\tpublic static final String SIGNATURE_ALGORITHM = &quot;MD5withRSA&quot;;\tprivate static final String PUBLIC_KEY = &quot;RSAPublicKey&quot;;\tprivate static final String PRIVATE_KEY = &quot;RSAPrivateKey&quot;;\tpublic static byte[] decryptBASE64(String key) &#123; return Base64.decodeBase64(key);\t&#125;\tpublic static String encryptBASE64(byte[] bytes) &#123; return Base64.encodeBase64String(bytes);\t&#125;\t/ * 用私钥对信息生成数字签名 * * @param data * 加密数据 * @param privateKey * 私钥 * @return * @throws Exception */\tpublic static String sign(byte[] data, String privateKey) throws Exception &#123; // 解密由base64编码的私钥 byte[] keyBytes = decryptBASE64(privateKey); // 构造PKCS8EncodedKeySpec对象 PKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(keyBytes); // KEY_ALGORITHM 指定的加密算法 KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); // 取私钥匙对象 PrivateKey priKey = keyFactory.generatePrivate(pkcs8KeySpec); // 用私钥对信息生成数字签名 Signature signature = Signature.getInstance(SIGNATURE_ALGORITHM); signature.initSign(priKey); signature.update(data); return encryptBASE64(signature.sign());\t&#125;\t/ * 校验数字签名 * * @param data * 加密数据 * @param publicKey * 公钥 * @param sign * 数字签名 * @return 校验成功返回true 失败返回false * @throws Exception */\tpublic static boolean verify(byte[] data, String publicKey, String sign) throws Exception &#123; // 解密由base64编码的公钥 byte[] keyBytes = decryptBASE64(publicKey); // 构造X509EncodedKeySpec对象 X509EncodedKeySpec keySpec = new X509EncodedKeySpec(keyBytes); // KEY_ALGORITHM 指定的加密算法 KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); // 取公钥匙对象 PublicKey pubKey = keyFactory.generatePublic(keySpec); Signature signature = Signature.getInstance(SIGNATURE_ALGORITHM); signature.initVerify(pubKey); signature.update(data); // 验证签名是否正常 return signature.verify(decryptBASE64(sign));\t&#125;\tpublic static byte[] decryptByPrivateKey(byte[] data, String key) throws Exception &#123; // 对密钥解密 byte[] keyBytes = decryptBASE64(key); // 取得私钥 PKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); Key privateKey = keyFactory.generatePrivate(pkcs8KeySpec); // 对数据解密 Cipher cipher = Cipher.getInstance(keyFactory.getAlgorithm()); cipher.init(Cipher.DECRYPT_MODE, privateKey); return cipher.doFinal(data);\t&#125;\t/ * 解密&lt;br&gt; * 用私钥解密 * * @param data * @param key * @return * @throws Exception */\tpublic static byte[] decryptByPrivateKey(String data, String key) throws Exception &#123; return decryptByPrivateKey(decryptBASE64(data), key);\t&#125;\t/ * 解密&lt;br&gt; * 用公钥解密 * * @param data * @param key * @return * @throws Exception */\tpublic static byte[] decryptByPublicKey(byte[] data, String key) throws Exception &#123; // 对密钥解密 byte[] keyBytes = decryptBASE64(key); // 取得公钥 X509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); Key publicKey = keyFactory.generatePublic(x509KeySpec); // 对数据解密 Cipher cipher = Cipher.getInstance(keyFactory.getAlgorithm()); cipher.init(Cipher.DECRYPT_MODE, publicKey); return cipher.doFinal(data);\t&#125;\t/ * 加密&lt;br&gt; * 用公钥加密 * * @param data * @param key * @return * @throws Exception */\tpublic static byte[] encryptByPublicKey(String data, String key) throws Exception &#123; // 对公钥解密 byte[] keyBytes = decryptBASE64(key); // 取得公钥 X509EncodedKeySpec x509KeySpec = new X509EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); Key publicKey = keyFactory.generatePublic(x509KeySpec); // 对数据加密 Cipher cipher = Cipher.getInstance(keyFactory.getAlgorithm()); cipher.init(Cipher.ENCRYPT_MODE, publicKey); return cipher.doFinal(data.getBytes());\t&#125;\t/ * 加密&lt;br&gt; * 用私钥加密 * * @param data * @param key * @return * @throws Exception */\tpublic static byte[] encryptByPrivateKey(byte[] data, String key) throws Exception &#123; // 对密钥解密 byte[] keyBytes = decryptBASE64(key); // 取得私钥 PKCS8EncodedKeySpec pkcs8KeySpec = new PKCS8EncodedKeySpec(keyBytes); KeyFactory keyFactory = KeyFactory.getInstance(KEY_ALGORITHM); Key privateKey = keyFactory.generatePrivate(pkcs8KeySpec); // 对数据加密 Cipher cipher = Cipher.getInstance(keyFactory.getAlgorithm()); cipher.init(Cipher.ENCRYPT_MODE, privateKey); return cipher.doFinal(data);\t&#125;\t/ * 取得私钥 * * @param keyMap * @return * @throws Exception */\tpublic static String getPrivateKey(Map&lt;String, Key&gt; keyMap) throws Exception &#123; Key key = (Key) keyMap.get(PRIVATE_KEY); return encryptBASE64(key.getEncoded());\t&#125;\t/ * 取得公钥 * * @param keyMap * @return * @throws Exception */\tpublic static String getPublicKey(Map&lt;String, Key&gt; keyMap) throws Exception &#123; Key key = keyMap.get(PUBLIC_KEY); return encryptBASE64(key.getEncoded());\t&#125;\t/ * 初始化密钥 * * @return * @throws Exception */\tpublic static Map&lt;String, Key&gt; initKey() throws Exception &#123; KeyPairGenerator keyPairGen = KeyPairGenerator.getInstance(KEY_ALGORITHM); keyPairGen.initialize(1024); KeyPair keyPair = keyPairGen.generateKeyPair(); Map&lt;String, Key&gt; keyMap = new HashMap(2); keyMap.put(PUBLIC_KEY, keyPair.getPublic());// 公钥 keyMap.put(PRIVATE_KEY, keyPair.getPrivate());// 私钥 return keyMap;\t&#125;&#125; 结果: 12345678910111213141516171819&#123;RSAPublicKey=Sun RSA public key, 1024 bits modulus: 115328826086047873902606456571034976538836553998745367981848911677968062571831626674499650854318207280419960767020601253071739555161388135589487284843845439403614883967713749605268831336418001722701924537624573180276356615050309809260289965219855862692230362893996010057188170525719351126759886050891484226169 public exponent: 65537, RSAPrivateKey=sun.security.rsa.RSAPrivateCrtKeyImpl@93479&#125;-----------------------------------MIGfMA0GCSqGSIb3DQEBAQUAA4GNADCBiQKBgQCkO9PBTOFJQTkzznALN62PU7ixd9YFjXrt2dPOGj3wwhymbOU8HLoCztjwpLXHgbpBUJlGmbURV955M1BkZ1kr5dkZYR5x1gO4xOnu8rEipy4AAMcpFttfiarIZrtzL9pKEvEOxABltVN4yzFDr3IjBqY46aHna7YjwhXI0xHieQIDAQAB-----------------------------------MIICdQIBADANBgkqhkiG9w0BAQEFAASCAl8wggJbAgEAAoGBAKQ708FM4UlBOTPOcAs3rY9TuLF31gWNeu3Z084aPfDCHKZs5TwcugLO2PCktceBukFQmUaZtRFX3nkzUGRnWSvl2RlhHnHWA7jE6e7ysSKnLgAAxykW21+Jqshmu3Mv2koS8Q7EAGW1U3jLMUOvciMGpjjpoedrtiPCFcjTEeJ5AgMBAAECgYAK4sxOa8IjEOexv2U92Rrv/SSo3sCY7Z/QVDft2V9xrewoO9+V9HF/7iYDDWffKYInAiimvVl7JM/iSLxza0ZFv29VMpyDcr4TigYmWwBlk7ZbxSTkqLdNwxxldMmEoTn1py53MUm+1V1K3rzNvJjuZaZFAevU7vUnwQwD+JGQYQJBAM9HBaC+dF3PJ2mkXekHpDS1ZPaSFdrdzd/GvHFi/cJAMM+Uz6PmpkosNXRtOpSYWwlOMRamLZtrHhfQoqSk3S8CQQDK1qL1jGvVdqw5OjqxktR7MmOsWUVZdWiBN+6ojxBgA0yVn0n7vkdAAgEZBj89WG0VHPEu3hd4AgXFZHDfXeDXAkBvSn7nE9t/Et7ihfI2UHgGJO8UxNMfNMB5Skebyb7eMYEDs67ZHdpjMOFypcMyTatzj5wjwQ3zyMvblZX+ONbZAkAX4ysRy9WvL+icXLUo0Gfhkk+WrnSyUldaUGH0y9Rb2kecn0OxN/lgGlxSvB+ac910zRHCOTl+Uo6nbmq0g3PFAkAyqA4eT7G9GXfncakgW1Kdkn72w/ODpozgfhTLNX0SGw1ITML3c4THTtH5h3zLi3AF9zJO2O+K6ajRbV0szHHI-----------------------------------[B@387c703b-----------------------------------[B@224aed64-----------------------------------la4Hc4n/UbeBu0z9iLRuwKVv014SiOJMXkO5qdJvKBsw0MlnsrM+89a3p73yMrb1dAnCU/2kgO0PtFpvmG8pzxTe1u/5nX/25iIyUXALlwVRptJyjzFE83g2IX0XEv/Dxqr1RCRcrMHOLQM0oBoxZCaChmyw1Ub4wsSs6Ndxb9M=-----------------------------------true-----------------------------------[B@c39f790-----------------------------------[B@71e7a66b","tags":["算法","安全算法","加密算法"],"categories":["算法","安全算法"]},{"title":"2.安全算法 - 摘要算法","path":"/2023/12/27/2-安全算法-摘要算法/","content":"本文主要介绍安全算法 - 摘要算法相关的内容。消息摘要算法的主要特征是加密过程不需要密钥，并且经过加密的数据无法被解密，目前可以解密逆向的只有CRC32算法，只有输入相同的明文数据经过相同的消息摘要算法才能得到相同的密文。消息摘要算法不存在密钥的管理与分发问题，适合于分布式网络上使用。 摘要算法简介 消息摘要算法的主要特征是加密过程不需要密钥，并且经过加密的数据无法被解密 只有输入相同的明文数据经过相同的消息摘要算法才能得到相同的密文 消息摘要算法主要应用在“数字签名”领域，作为对明文的摘要算法 著名的摘要算法有RSA公司的MD5算法和SHA-1算法及其大量的变体 摘要算法特点 无论输入的消息有多长，计算出来的消息摘要的长度总是固定的 消息摘要看起来是“伪随机的”。也就是说对相同的信息求摘要结果相同 消息轻微改变生成的摘要变化会很大 只能进行正向的信息摘要，而无法从摘要中恢复出任何的消息，甚至根本就找不到任何与原信息相关的信息 摘要算法应用消息摘要算法最常用的场景就是数字签名以及数据(密码)加密了。(一般平时做项目用的比较多的就是使用MD5对用户密码进行加密) 何谓数字签名数字签名主要用到了非对称密钥加密技术与数字摘要技术。数字签名技术是将摘要信息用发送者的私钥加密，与原文一起传送给接收者。接收者只有用发送者的公钥才能解密被加密的摘要信息，然后用HASH函数对收到的原文产生一个摘要信息，与解密的摘要信息对比。 如果相同，则说明收到的信息是完整的，在传输过程中没有被修改，否则说明信息被修改过. 因此数字签名能够验证信息的完整性。 数字签名是个加密的过程，数字签名验证是个解密的过程。 常见消息&#x2F;数字摘要算法MD5简介:MD5的作用是让大容量信息在用数字签名软件签署私人密钥前被”压缩”成一种保密的格式 (也就是把一个任意长度的字节串变换成一定长的十六进制数字串)。 特点: 压缩性 : 任意长度的数据，算出的MD5值长度都是固定的。 容易计算 : 从原数据计算出MD5值很容易。 抗修改性 : 对原数据进行任何改动，哪怕只修改1个字节，所得到的MD5值都有很大区别。 强抗碰撞 : 已知原数据和其MD5值，想找到一个具有相同MD5值的数据(即伪造数据)是非常困难的。 代码实现:利用JDK提供java.security.MessageDigest类实现MD5算法: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950package com.snailclimb.ks.securityAlgorithm;import java.security.MessageDigest;public class MD5Demo &#123; // test public static void main(String[] args) &#123; System.out.println(getMD5Code(&quot;你若安好，便是晴天&quot;)); &#125; private MD5Demo() &#123; &#125; // md5加密 public static String getMD5Code(String message) &#123; String md5Str = &quot;&quot;; try &#123; //创建MD5算法消息摘要 MessageDigest md = MessageDigest.getInstance(&quot;MD5&quot;); //生成的哈希值的字节数组 byte[] md5Bytes = md.digest(message.getBytes()); md5Str = bytes2Hex(md5Bytes); &#125;catch(Exception e) &#123; e.printStackTrace(); &#125; return md5Str; &#125; // 2进制转16进制 public static String bytes2Hex(byte[] bytes) &#123; StringBuffer result = new StringBuffer(); int temp; try &#123; for (int i = 0; i &lt; bytes.length; i++) &#123; temp = bytes[i]; if(temp &lt; 0) &#123; temp += 256; &#125; if (temp &lt; 16) &#123; result.append(&quot;0&quot;); &#125; result.append(Integer.toHexString(temp)); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return result.toString(); &#125;&#125; 结果 16bab82679914f7cb480a120b532ffa80 注意MessageDigest类的几个方法 : 12static MessageDigest getInstance(String algorithm)//返回实现指定摘要算法的MessageDigest对象byte[] digest(byte[] input)//使用指定的字节数组对摘要执行最终更新，然后完成摘要计算。 不利用Java提供的java.security.MessageDigest类实现MD5算法:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160package com.snailclimb.ks.securityAlgorithm;public class MD5&#123; /* *四个链接变量 */ private final int A=0x67452301; private final int B=0xefcdab89; private final int C=0x98badcfe; private final int D=0x10325476; /* *ABCD的临时变量 */ private int Atemp,Btemp,Ctemp,Dtemp; /* *常量ti *公式:floor(abs(sin(i+1))×(2pow32) */ private final int K[]=&#123; 0xd76aa478,0xe8c7b756,0x242070db,0xc1bdceee, 0xf57c0faf,0x4787c62a,0xa8304613,0xfd469501,0x698098d8, 0x8b44f7af,0xffff5bb1,0x895cd7be,0x6b901122,0xfd987193, 0xa679438e,0x49b40821,0xf61e2562,0xc040b340,0x265e5a51, 0xe9b6c7aa,0xd62f105d,0x02441453,0xd8a1e681,0xe7d3fbc8, 0x21e1cde6,0xc33707d6,0xf4d50d87,0x455a14ed,0xa9e3e905, 0xfcefa3f8,0x676f02d9,0x8d2a4c8a,0xfffa3942,0x8771f681, 0x6d9d6122,0xfde5380c,0xa4beea44,0x4bdecfa9,0xf6bb4b60, 0xbebfbc70,0x289b7ec6,0xeaa127fa,0xd4ef3085,0x04881d05, 0xd9d4d039,0xe6db99e5,0x1fa27cf8,0xc4ac5665,0xf4292244, 0x432aff97,0xab9423a7,0xfc93a039,0x655b59c3,0x8f0ccc92, 0xffeff47d,0x85845dd1,0x6fa87e4f,0xfe2ce6e0,0xa3014314, 0x4e0811a1,0xf7537e82,0xbd3af235,0x2ad7d2bb,0xeb86d391&#125;; /* *向左位移数,计算方法未知 */ private final int s[]=&#123;7,12,17,22,7,12,17,22,7,12,17,22,7, 12,17,22,5,9,14,20,5,9,14,20,5,9,14,20,5,9,14,20, 4,11,16,23,4,11,16,23,4,11,16,23,4,11,16,23,6,10, 15,21,6,10,15,21,6,10,15,21,6,10,15,21&#125;; /* *初始化函数 */ private void init()&#123; Atemp=A; Btemp=B; Ctemp=C; Dtemp=D; &#125; /* *移动一定位数 */ private int shift(int a,int s)&#123; return(a&lt;&lt;s)|(a&gt;&gt;&gt;(32-s));//右移的时候，高位一定要补零，而不是补充符号位 &#125; /* *主循环 */ private void MainLoop(int M[])&#123; int F,g; int a=Atemp; int b=Btemp; int c=Ctemp; int d=Dtemp; for(int i = 0; i &lt; 64; i ++)&#123; if(i&lt;16)&#123; F=(b&amp;c)|((~b)&amp;d); g=i; &#125;else if(i&lt;32)&#123; F=(d&amp;b)|((~d)&amp;c); g=(5*i+1)%16; &#125;else if(i&lt;48)&#123; F=b^c^d; g=(3*i+5)%16; &#125;else&#123; F=c^(b|(~d)); g=(7*i)%16; &#125; int tmp=d; d=c; c=b; b=b+shift(a+F+K[i]+M[g],s[i]); a=tmp; &#125; Atemp=a+Atemp; Btemp=b+Btemp; Ctemp=c+Ctemp; Dtemp=d+Dtemp; &#125; /* *填充函数 *处理后应满足bits≡448(mod512),字节就是bytes≡56(mode64) *填充方式为先加一个0,其它位补零 *最后加上64位的原来长度 */ private int[] add(String str)&#123; int num=((str.length()+8)/64)+1;//以512位，64个字节为一组 int strByte[]=new int[num*16];//64/4=16，所以有16个整数 for(int i=0;i&lt;num*16;i++)&#123;//全部初始化0 strByte[i]=0; &#125; int i; for(i=0;i&lt;str.length();i++)&#123; strByte[i&gt;&gt;2]|=str.charAt(i)&lt;&lt;((i%4)*8);//一个整数存储四个字节，小端序 &#125; strByte[i&gt;&gt;2]|=0x80&lt;&lt;((i%4)*8);//尾部添加1 /* *添加原长度，长度指位的长度，所以要乘8，然后是小端序，所以放在倒数第二个,这里长度只用了32位 */ strByte[num*16-2]=str.length()*8; return strByte; &#125; /* *调用函数 */ public String getMD5(String source)&#123; init(); int strByte[]=add(source); for(int i=0;i&lt;strByte.length/16;i++)&#123; int num[]=new int[16]; for(int j=0;j&lt;16;j++)&#123; num[j]=strByte[i*16+j]; &#125; MainLoop(num); &#125; return changeHex(Atemp)+changeHex(Btemp)+changeHex(Ctemp)+changeHex(Dtemp); &#125; /* *整数变成16进制字符串 */ private String changeHex(int a)&#123; String str=&quot;&quot;; for(int i=0;i&lt;4;i++)&#123; str+=String.format(&quot;%2s&quot;, Integer.toHexString(((a&gt;&gt;i*8)%(1&lt;&lt;8))&amp;0xff)).replace(&#x27; &#x27;, &#x27;0&#x27;); &#125; return str; &#125; /* *单例 */ private static MD5 instance; public static MD5 getInstance()&#123; if(instance==null)&#123; instance=new MD5(); &#125; return instance; &#125; private MD5()&#123;&#125;; public static void main(String[] args)&#123; String str=MD5.getInstance().getMD5(&quot;你若安好，便是晴天&quot;); System.out.println(str); &#125;&#125; SHA1对于长度小于2^64位的消息，SHA1会产生一个160位(40个字符)的消息摘要。当接收到消息的时候，这个消息摘要可以用来验证数据的完整性。在传输的过程中，数据很可能会发生变化，那么这时候就会产生不同的消息摘要。 SHA1有如下特性: 不可以从消息摘要中复原信息； 两个不同的消息不会产生同样的消息摘要,(但会有1x10 ^ 48分之一的机率出现相同的消息摘要,一般使用时忽略)。 代码实现:利用JDK提供java.security.MessageDigest类实现SHA1算法: 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.snailclimb.ks.securityAlgorithm;import java.io.UnsupportedEncodingException;import java.security.MessageDigest;import java.security.NoSuchAlgorithmException;public class SHA1Demo &#123;\tpublic static void main(String[] args) &#123; // TODO Auto-generated method stub System.out.println(getSha1(&quot;你若安好，便是晴天&quot;)); &#125;\tpublic static String getSha1(String str) &#123; if (null == str || 0 == str.length()) &#123; return null; &#125; char[] hexDigits = &#123; &#x27;0&#x27;, &#x27;1&#x27;, &#x27;2&#x27;, &#x27;3&#x27;, &#x27;4&#x27;, &#x27;5&#x27;, &#x27;6&#x27;, &#x27;7&#x27;, &#x27;8&#x27;, &#x27;9&#x27;, &#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;, &#x27;d&#x27;, &#x27;e&#x27;, &#x27;f&#x27; &#125;; try &#123; //创建SHA1算法消息摘要对象 MessageDigest mdTemp = MessageDigest.getInstance(&quot;SHA1&quot;); //使用指定的字节数组更新摘要。 mdTemp.update(str.getBytes(&quot;UTF-8&quot;)); //生成的哈希值的字节数组 byte[] md = mdTemp.digest(); //SHA1算法生成信息摘要关键过程 int j = md.length; char[] buf = new char[j * 2]; int k = 0; for (int i = 0; i &lt; j; i++) &#123; byte byte0 = md[i]; buf[k++] = hexDigits[byte0 &gt;&gt;&gt; 4 &amp; 0xf]; buf[k++] = hexDigits[byte0 &amp; 0xf]; &#125; return new String(buf); &#125; catch (NoSuchAlgorithmException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; return &quot;0&quot;; &#125;&#125; 结果 : 18ce764110a42da9b08504b20e26b19c9e3382414","tags":["算法","安全算法","摘要算法"],"categories":["算法","安全算法"]},{"title":"1.一些领域算法知识体系","path":"/2023/12/27/1-一些领域算法知识体系/","content":"本系列主要总结下常见的某些领域的算法。 知识体系知识体系系统性梳理 相关文章 A. 领域算法 梳理知识点：在了解基础算法之后，我们还要学习和了解在不同专业领域有哪些特有的算法。这里不一定要求复杂度，而是要有知识面以及解决问题的思路。 一些领域算法 - Overview B. 领域算法之 安全算法：主要包括摘要算法和加密算法两大类。 安全算法 - 摘要算法 消息摘要算法的主要特征是加密过程不需要密钥，并且经过加密的数据无法被解密，目前可以解密逆向的只有CRC32算法，只有输入相同的明文数据经过相同的消息摘要算法才能得到相同的密文。消息摘要算法不存在密钥的管理与分发问题，适合于分布式网络上使用。 安全算法 - 加密算法 数据加密的基本过程就是对原来为明文的文件或数据按某种算法进行处理，使其成为不可读的一段代码为“密文”，使其只能在输入相应的密钥之后才能显示出原容，通过这样的途径来达到保护数据不被非法人窃取、阅读的目的。 该过程的逆过程为解密，即将该编码信息转化为其原来数据的过程 安全算法 - 国密算法 国密即国家密码局认定的国产密码算法。主要有SM1，SM2，SM3，SM4，SM7, SM9。 C. 领域算法之 字符串匹配算法：字符串匹配(String Matchiing)也称字符串搜索(String Searching)是字符串算法中重要的一种，是指从一个大字符串或文本中找到模式串出现的位置。 朴素的字符串匹配算法（Naive String Matching Algorithm) 朴素的字符串匹配算法又称为暴力匹配算法（Brute Force Algorithm），最为简单的字符串匹配算法 Knuth-Morris-Pratt 字符串匹配算法（即 KMP 算法） Knuth-Morris-Pratt算法（简称KMP）是最常用的字符串匹配算法之一 Boyer-Moore 字符串匹配算法 各种文本编辑器的”查找”功能（Ctrl+F），大多采用Boyer-Moore算法，效率非常高 字符串匹配 - 文本预处理：后缀树（Suffix Tree） 上述字符串匹配算法(朴素的字符串匹配算法, KMP 算法, Boyer-Moore算法)均是通过对模式（Pattern）字符串进行预处理的方式来加快搜索速度。对 Pattern 进行预处理的最优复杂度为 O(m)，其中 m 为 Pattern 字符串的长度。那么，有没有对文本（Text）进行预处理的算法呢？本文即将介绍一种对 Text 进行预处理的字符串匹配算法：后缀树（Suffix Tree） D. 领域算法之 大数据处理：这里其实想让大家理解的是大数据处理的常用思路，而不是算法本身。 大数据处理 - Overview 本文主要介绍大数据处理的一些思路 大数据处理 - 分治&#x2F;hash&#x2F;排序 就是先映射，而后统计，最后排序: 分而治之/hash映射: 针对数据太大，内存受限，只能是: 把大文件化成(取模映射)小文件，即16字方针: 大而化小，各个击破，缩小规模，逐个解决 hash_map统计: 当大文件转化了小文件，那么我们便可以采用常规的hash_map(ip，value)来进行频率统计。 堆/快速排序: 统计完了之后，便进行排序(可采取堆排序)，得到次数最多的IP。 大数据处理 - Bitmap &amp; Bloom Filter 布隆过滤器有着广泛的应用，对于大量数据的“存不存在”的问题在空间上有明显优势，但是在判断存不存在是有一定的错误率(false positive)，也就是说，有可能把不属于这个集合的元素误认为属于这个集合(False Positive)，但不会把属于这个集合的元素误认为不属于这个集合(False Negative) 大数据处理 - 双层桶划分 其实本质上还是分而治之的思想，重在“分”的技巧上！适用范围: 第k大，中位数，不重复或重复的数字；基本原理及要点: 因为元素范围很大，不能利用直接寻址表，所以通过多次划分，逐步确定范围，然后最后在一个可以接受的范围内进行。 大数据处理 - Trie树&#x2F;数据库&#x2F;倒排索引 适用范围: 数据量大，重复多，但是数据种类小可以放入内存；基本原理及要点: 实现方式，节点孩子的表示方式；扩展: 压缩实现 大数据处理 - 外排序 适用范围: 大数据的排序，去重；基本原理及要点: 外排序的归并方法，置换选择败者树原理，最优归并树 大数据处理 - Map &amp; Reduce MapReduce是一种计算模型，简单的说就是将大批量的工作(数据)分解(MAP)执行，然后再将结果合并成最终结果(REDUCE)。这样做的好处是可以在任务被分解后，可以通过大量机器进行并行计算，减少整个操作的时间。但如果你要我再通俗点介绍，那么，说白了，Mapreduce的原理就是一个归并排序 E. 领域算法之 分布式算法：接着向大家介绍分布式算法，包括一致性Hash算法，经典的Paxos算法，Raft算法，ZAB算法等；顺便也介绍了经典用于全局ID生成的Snowflake算法。 分布式算法 - Overview 本文总结下常见的分布式算法 分布式算法 - 一致性Hash算法 一致性Hash算法是个经典算法，Hash环的引入是为解决单调性(Monotonicity)的问题；虚拟节点的引入是为了解决平衡性(Balance)问题 分布式算法 - Paxos算法 Paxos算法是Lamport宗师提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性, 很多分布式一致性算法都由Paxos演变而来 分布式算法 - Raft算法 Paxos是出了名的难懂，而Raft正是为了探索一种更易于理解的一致性算法而产生的。它的首要设计目的就是易于理解，所以在选主的冲突处理等方式上它都选择了非常简单明了的解决方案 分布式算法-Gossip-协议详解 Gossip 协议是一种允许在分布式系统中共享状态的去中心化通信协议，通过这种通信协议，我们可以将信息传播给网络或集群中的所有成员 分布式算法 - ZAB算法 ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）, 它应该是所有一致性协议中生产环境中应用最多的了。为什么呢？因为他是为 Zookeeper 设计的分布式一致性协议！ 分布式算法 - Snowflake算法 Snowflake，雪花算法是由Twitter开源的分布式ID生成算法，以划分命名空间的方式将 64-bit位分割成多个部分，每个部分代表不同的含义。这种就是将64位划分为不同的段，每段代表不同的涵义，基本就是时间戳、机器ID和序列数。为什么如此重要？因为它提供了一种ID生成及生成的思路，当然这种方案就是需要考虑时钟回拨的问题以及做一些 buffer的缓冲设计提高性能。 F. 领域算法之 其它算法汇总：最后概要性的了解常见的其它算法：负载均衡算法，推荐算法，数据挖掘或机器学习算法。因为有其专业性，一般总体上了解就够了。 负载均衡算法 - 汇总 本文主要介绍常用的负载均衡算法和Nginx中支持的负载均衡算法：轮询法(Round Robin)，加权轮询法(Weight Round Robin)，平滑加权轮询法(Smooth Weight Round Robin)，随机法(Random)，加权随机法(Weight Random)，源地址哈希法(Hash)，最小连接数法(Least Connections) 推荐算法 - 汇总 本文主要对推荐算法整体知识点做汇总，做到总体的理解；深入理解需要再看专业的材料 数据挖掘 - 10大算法汇总 国际权威的学术组织the IEEE International Conference on Data Mining (ICDM) 2006年12月评选出了数据挖掘领域的十大经典算法: C4.5, k-Means, SVM, Apriori, EM, PageRank, AdaBoost, kNN, Naive Bayes, and CART 推荐学习 推荐博客园@刘建平Pinard 的机器学习，数据挖掘系列在新窗口打开 推荐CSDN@July 的[机器学习相关","tags":["算法","领域算法"],"categories":["算法","领域算法"]},{"title":"7.算法思想 - 回溯算法","path":"/2023/12/27/7-算法思想-回溯算法/","content":"Backtracking(回溯)属于 DFS, 本文主要介绍算法中Backtracking算法的思想。回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法 Backtracking 普通 DFS 主要用在 可达性问题 ，这种问题只需要执行到特点的位置然后返回即可。 而 Backtracking 主要用于求解 排列组合 问题，例如有 { ‘a’,’b’,’c’ } 三个字符，求解所有由这三个字符排列得到的字符串，这种问题在执行到特定的位置返回之后还会继续执行求解过程。 因为 Backtracking 不是立即就返回，而要继续求解，因此在程序实现时，需要注意对元素的标记问题: 在访问一个新元素进入新的递归调用时，需要将新元素标记为已经访问，这样才能在继续递归调用时不用重复访问该元素； 但是在递归返回时，需要将元素标记为未访问，因为只需要保证在一个递归链中不同时访问一个元素，可以访问已经访问过但是不在当前递归链中的元素。 数字键盘组合17. Letter Combinations of a Phone Number (Medium) 12Input:Digit string &quot;23&quot;Output: [&quot;ad&quot;, &quot;ae&quot;, &quot;af&quot;, &quot;bd&quot;, &quot;be&quot;, &quot;bf&quot;, &quot;cd&quot;, &quot;ce&quot;, &quot;cf&quot;]. 1234567891011121314151617181920212223private static final String[] KEYS = &#123;&quot;&quot;, &quot;&quot;, &quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;, &quot;jkl&quot;, &quot;mno&quot;, &quot;pqrs&quot;, &quot;tuv&quot;, &quot;wxyz&quot;&#125;;public List&lt;String&gt; letterCombinations(String digits) &#123; List&lt;String&gt; combinations = new ArrayList&lt;&gt;(); if (digits == null || digits.length() == 0) &#123; return combinations; &#125; doCombination(new StringBuilder(), combinations, digits); return combinations;&#125;private void doCombination(StringBuilder prefix, List&lt;String&gt; combinations, final String digits) &#123; if (prefix.length() == digits.length()) &#123; combinations.add(prefix.toString()); return; &#125; int curDigits = digits.charAt(prefix.length()) - &#x27;0&#x27;; String letters = KEYS[curDigits]; for (char c : letters.toCharArray()) &#123; prefix.append(c); // 添加 doCombination(prefix, combinations, digits); prefix.deleteCharAt(prefix.length() - 1); // 删除 &#125;&#125; IP 地址划分93. Restore IP Addresses(Medium) 12Given &quot;25525511135&quot;,return [&quot;255.255.11.135&quot;, &quot;255.255.111.35&quot;]. 1234567891011121314151617181920212223242526272829public List&lt;String&gt; restoreIpAddresses(String s) &#123; List&lt;String&gt; addresses = new ArrayList&lt;&gt;(); StringBuilder tempAddress = new StringBuilder(); doRestore(0, tempAddress, addresses, s); return addresses;&#125;private void doRestore(int k, StringBuilder tempAddress, List&lt;String&gt; addresses, String s) &#123; if (k == 4 || s.length() == 0) &#123; if (k == 4 &amp;&amp; s.length() == 0) &#123; addresses.add(tempAddress.toString()); &#125; return; &#125; for (int i = 0; i &lt; s.length() &amp;&amp; i &lt;= 2; i++) &#123; if (i != 0 &amp;&amp; s.charAt(0) == &#x27;0&#x27;) &#123; break; &#125; String part = s.substring(0, i + 1); if (Integer.valueOf(part) &lt;= 255) &#123; if (tempAddress.length() != 0) &#123; part = &quot;.&quot; + part; &#125; tempAddress.append(part); doRestore(k + 1, tempAddress, addresses, s.substring(i + 1)); tempAddress.delete(tempAddress.length() - part.length(), tempAddress.length()); &#125; &#125;&#125; 在矩阵中寻找字符串79. Word Search (Medium) 12345678910For example,Given board =[ [&#x27;A&#x27;,&#x27;B&#x27;,&#x27;C&#x27;,&#x27;E&#x27;], [&#x27;S&#x27;,&#x27;F&#x27;,&#x27;C&#x27;,&#x27;S&#x27;], [&#x27;A&#x27;,&#x27;D&#x27;,&#x27;E&#x27;,&#x27;E&#x27;]]word = &quot;ABCCED&quot;, -&gt; returns true,word = &quot;SEE&quot;, -&gt; returns true,word = &quot;ABCB&quot;, -&gt; returns false. 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private final static int[][] direction = &#123;&#123;1, 0&#125;, &#123;-1, 0&#125;, &#123;0, 1&#125;, &#123;0, -1&#125;&#125;;private int m;private int n;public boolean exist(char[][] board, String word) &#123; if (word == null || word.length() == 0) &#123; return true; &#125; if (board == null || board.length == 0 || board[0].length == 0) &#123; return false; &#125; m = board.length; n = board[0].length; boolean[][] hasVisited = new boolean[m][n]; for (int r = 0; r &lt; m; r++) &#123; for (int c = 0; c &lt; n; c++) &#123; if (backtracking(0, r, c, hasVisited, board, word)) &#123; return true; &#125; &#125; &#125; return false;&#125;private boolean backtracking(int curLen, int r, int c, boolean[][] visited, final char[][] board, final String word) &#123; if (curLen == word.length()) &#123; return true; &#125; if (r &lt; 0 || r &gt;= m || c &lt; 0 || c &gt;= n || board[r][c] != word.charAt(curLen) || visited[r][c]) &#123; return false; &#125; visited[r][c] = true; for (int[] d : direction) &#123; if (backtracking(curLen + 1, r + d[0], c + d[1], visited, board, word)) &#123; return true; &#125; &#125; visited[r][c] = false; return false;&#125; 输出二叉树中所有从根到叶子的路径257. Binary Tree Paths (Easy) 12345 1 / \\2 3 \\ 5 1[&quot;1-&gt;2-&gt;5&quot;, &quot;1-&gt;3&quot;] 1234567891011121314151617181920212223242526272829303132333435363738public List&lt;String&gt; binaryTreePaths(TreeNode root) &#123; List&lt;String&gt; paths = new ArrayList&lt;&gt;(); if (root == null) &#123; return paths; &#125; List&lt;Integer&gt; values = new ArrayList&lt;&gt;(); backtracking(root, values, paths); return paths;&#125;private void backtracking(TreeNode node, List&lt;Integer&gt; values, List&lt;String&gt; paths) &#123; if (node == null) &#123; return; &#125; values.add(node.val); if (isLeaf(node)) &#123; paths.add(buildPath(values)); &#125; else &#123; backtracking(node.left, values, paths); backtracking(node.right, values, paths); &#125; values.remove(values.size() - 1);&#125;private boolean isLeaf(TreeNode node) &#123; return node.left == null &amp;&amp; node.right == null;&#125;private String buildPath(List&lt;Integer&gt; values) &#123; StringBuilder str = new StringBuilder(); for (int i = 0; i &lt; values.size(); i++) &#123; str.append(values.get(i)); if (i != values.size() - 1) &#123; str.append(&quot;-&gt;&quot;); &#125; &#125; return str.toString();&#125; 排列46. Permutations (Medium) 123456789[1,2,3] have the following permutations:[ [1,2,3], [1,3,2], [2,1,3], [2,3,1], [3,1,2], [3,2,1]] 123456789101112131415161718192021222324public List&lt;List&lt;Integer&gt;&gt; permute(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; permutes = new ArrayList&lt;&gt;(); List&lt;Integer&gt; permuteList = new ArrayList&lt;&gt;(); boolean[] hasVisited = new boolean[nums.length]; backtracking(permuteList, permutes, hasVisited, nums); return permutes;&#125;private void backtracking(List&lt;Integer&gt; permuteList, List&lt;List&lt;Integer&gt;&gt; permutes, boolean[] visited, final int[] nums) &#123; if (permuteList.size() == nums.length) &#123; permutes.add(new ArrayList&lt;&gt;(permuteList)); // 重新构造一个 List return; &#125; for (int i = 0; i &lt; visited.length; i++) &#123; if (visited[i]) &#123; continue; &#125; visited[i] = true; permuteList.add(nums[i]); backtracking(permuteList, permutes, visited, nums); permuteList.remove(permuteList.size() - 1); visited[i] = false; &#125;&#125; 含有相同元素求排列47. Permutations II (Medium) 12[1,1,2] have the following unique permutations:[[1,1,2], [1,2,1], [2,1,1]] 数组元素可能含有相同的元素，进行排列时就有可能出现重复的排列，要求重复的排列只返回一个。 在实现上，和 Permutations 不同的是要先排序，然后在添加一个元素时，判断这个元素是否等于前一个元素，如果等于，并且前一个元素还未访问，那么就跳过这个元素。 1234567891011121314151617181920212223242526272829public List&lt;List&lt;Integer&gt;&gt; permuteUnique(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; permutes = new ArrayList&lt;&gt;(); List&lt;Integer&gt; permuteList = new ArrayList&lt;&gt;(); Arrays.sort(nums); // 排序 boolean[] hasVisited = new boolean[nums.length]; backtracking(permuteList, permutes, hasVisited, nums); return permutes;&#125;private void backtracking(List&lt;Integer&gt; permuteList, List&lt;List&lt;Integer&gt;&gt; permutes, boolean[] visited, final int[] nums) &#123; if (permuteList.size() == nums.length) &#123; permutes.add(new ArrayList&lt;&gt;(permuteList)); return; &#125; for (int i = 0; i &lt; visited.length; i++) &#123; if (i != 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !visited[i - 1]) &#123; continue; // 防止重复 &#125; if (visited[i])&#123; continue; &#125; visited[i] = true; permuteList.add(nums[i]); backtracking(permuteList, permutes, visited, nums); permuteList.remove(permuteList.size() - 1); visited[i] = false; &#125;&#125; 组合77. Combinations (Medium) 123456789If n = 4 and k = 2, a solution is:[ [2,4], [3,4], [2,3], [1,2], [1,3], [1,4],] 123456789101112131415161718public List&lt;List&lt;Integer&gt;&gt; combine(int n, int k) &#123; List&lt;List&lt;Integer&gt;&gt; combinations = new ArrayList&lt;&gt;(); List&lt;Integer&gt; combineList = new ArrayList&lt;&gt;(); backtracking(combineList, combinations, 1, k, n); return combinations;&#125;private void backtracking(List&lt;Integer&gt; combineList, List&lt;List&lt;Integer&gt;&gt; combinations, int start, int k, final int n) &#123; if (k == 0) &#123; combinations.add(new ArrayList&lt;&gt;(combineList)); return; &#125; for (int i = start; i &lt;= n - k + 1; i++) &#123; // 剪枝 combineList.add(i); backtracking(combineList, combinations, i + 1, k - 1, n); combineList.remove(combineList.size() - 1); &#125;&#125; 组合求和39. Combination Sum (Medium) 123given candidate set [2, 3, 6, 7] and target 7,A solution set is:[[7],[2, 2, 3]] 123456789101112131415161718192021public List&lt;List&lt;Integer&gt;&gt; combinationSum(int[] candidates, int target) &#123; List&lt;List&lt;Integer&gt;&gt; combinations = new ArrayList&lt;&gt;(); backtracking(new ArrayList&lt;&gt;(), combinations, 0, target, candidates); return combinations;&#125;private void backtracking(List&lt;Integer&gt; tempCombination, List&lt;List&lt;Integer&gt;&gt; combinations, int start, int target, final int[] candidates) &#123; if (target == 0) &#123; combinations.add(new ArrayList&lt;&gt;(tempCombination)); return; &#125; for (int i = start; i &lt; candidates.length; i++) &#123; if (candidates[i] &lt;= target) &#123; tempCombination.add(candidates[i]); backtracking(tempCombination, combinations, i, target - candidates[i], candidates); tempCombination.remove(tempCombination.size() - 1); &#125; &#125;&#125; 含有相同元素的求组合求和40. Combination Sum II (Medium) 12345678For example, given candidate set [10, 1, 2, 7, 6, 1, 5] and target 8,A solution set is:[ [1, 7], [1, 2, 5], [2, 6], [1, 1, 6]] 123456789101112131415161718192021222324252627public List&lt;List&lt;Integer&gt;&gt; combinationSum2(int[] candidates, int target) &#123; List&lt;List&lt;Integer&gt;&gt; combinations = new ArrayList&lt;&gt;(); Arrays.sort(candidates); backtracking(new ArrayList&lt;&gt;(), combinations, new boolean[candidates.length], 0, target, candidates); return combinations;&#125;private void backtracking(List&lt;Integer&gt; tempCombination, List&lt;List&lt;Integer&gt;&gt; combinations, boolean[] hasVisited, int start, int target, final int[] candidates) &#123; if (target == 0) &#123; combinations.add(new ArrayList&lt;&gt;(tempCombination)); return; &#125; for (int i = start; i &lt; candidates.length; i++) &#123; if (i != 0 &amp;&amp; candidates[i] == candidates[i - 1] &amp;&amp; !hasVisited[i - 1]) &#123; continue; &#125; if (candidates[i] &lt;= target) &#123; tempCombination.add(candidates[i]); hasVisited[i] = true; backtracking(tempCombination, combinations, hasVisited, i + 1, target - candidates[i], candidates); hasVisited[i] = false; tempCombination.remove(tempCombination.size() - 1); &#125; &#125;&#125; 1-9 数字的组合求和216. Combination Sum III (Medium) 12345Input: k = 3, n = 9Output:[[1,2,6], [1,3,5], [2,3,4]] 从 1-9 数字中选出 k 个数不重复的数，使得它们的和为 n。 1234567891011121314151617181920212223public List&lt;List&lt;Integer&gt;&gt; combinationSum3(int k, int n) &#123; List&lt;List&lt;Integer&gt;&gt; combinations = new ArrayList&lt;&gt;(); List&lt;Integer&gt; path = new ArrayList&lt;&gt;(); backtracking(k, n, 1, path, combinations); return combinations;&#125;private void backtracking(int k, int n, int start, List&lt;Integer&gt; tempCombination, List&lt;List&lt;Integer&gt;&gt; combinations) &#123; if (k == 0 &amp;&amp; n == 0) &#123; combinations.add(new ArrayList&lt;&gt;(tempCombination)); return; &#125; if (k == 0 || n == 0) &#123; return; &#125; for (int i = start; i &lt;= 9; i++) &#123; tempCombination.add(i); backtracking(k - 1, n - i, i + 1, tempCombination, combinations); tempCombination.remove(tempCombination.size() - 1); &#125;&#125; 子集78. Subsets (Medium) 找出集合的所有子集，子集不能重复，[1, 2] 和 [2, 1] 这种子集算重复 12345678910111213141516171819202122public List&lt;List&lt;Integer&gt;&gt; subsets(int[] nums) &#123; List&lt;List&lt;Integer&gt;&gt; subsets = new ArrayList&lt;&gt;(); List&lt;Integer&gt; tempSubset = new ArrayList&lt;&gt;(); for (int size = 0; size &lt;= nums.length; size++) &#123; backtracking(0, tempSubset, subsets, size, nums); // 不同的子集大小 &#125; return subsets;&#125;private void backtracking(int start, List&lt;Integer&gt; tempSubset, List&lt;List&lt;Integer&gt;&gt; subsets, final int size, final int[] nums) &#123; if (tempSubset.size() == size) &#123; subsets.add(new ArrayList&lt;&gt;(tempSubset)); return; &#125; for (int i = start; i &lt; nums.length; i++) &#123; tempSubset.add(nums[i]); backtracking(i + 1, tempSubset, subsets, size, nums); tempSubset.remove(tempSubset.size() - 1); &#125;&#125; 含有相同元素求子集90. Subsets II (Medium) 1234567891011For example,If nums = [1,2,2], a solution is:[ [2], [1], [1,2,2], [2,2], [1,2], []] 1234567891011121314151617181920212223242526272829public List&lt;List&lt;Integer&gt;&gt; subsetsWithDup(int[] nums) &#123; Arrays.sort(nums); List&lt;List&lt;Integer&gt;&gt; subsets = new ArrayList&lt;&gt;(); List&lt;Integer&gt; tempSubset = new ArrayList&lt;&gt;(); boolean[] hasVisited = new boolean[nums.length]; for (int size = 0; size &lt;= nums.length; size++) &#123; backtracking(0, tempSubset, subsets, hasVisited, size, nums); // 不同的子集大小 &#125; return subsets;&#125;private void backtracking(int start, List&lt;Integer&gt; tempSubset, List&lt;List&lt;Integer&gt;&gt; subsets, boolean[] hasVisited, final int size, final int[] nums) &#123; if (tempSubset.size() == size) &#123; subsets.add(new ArrayList&lt;&gt;(tempSubset)); return; &#125; for (int i = start; i &lt; nums.length; i++) &#123; if (i != 0 &amp;&amp; nums[i] == nums[i - 1] &amp;&amp; !hasVisited[i - 1]) &#123; continue; &#125; tempSubset.add(nums[i]); hasVisited[i] = true; backtracking(i + 1, tempSubset, subsets, hasVisited, size, nums); hasVisited[i] = false; tempSubset.remove(tempSubset.size() - 1); &#125;&#125; 分割字符串使得每个部分都是回文数131. Palindrome Partitioning (Medium) 1234567For example, given s = &quot;aab&quot;,Return[ [&quot;aa&quot;,&quot;b&quot;], [&quot;a&quot;,&quot;a&quot;,&quot;b&quot;]] 1234567891011121314151617181920212223242526272829public List&lt;List&lt;String&gt;&gt; partition(String s) &#123; List&lt;List&lt;String&gt;&gt; partitions = new ArrayList&lt;&gt;(); List&lt;String&gt; tempPartition = new ArrayList&lt;&gt;(); doPartition(s, partitions, tempPartition); return partitions;&#125;private void doPartition(String s, List&lt;List&lt;String&gt;&gt; partitions, List&lt;String&gt; tempPartition) &#123; if (s.length() == 0) &#123; partitions.add(new ArrayList&lt;&gt;(tempPartition)); return; &#125; for (int i = 0; i &lt; s.length(); i++) &#123; if (isPalindrome(s, 0, i)) &#123; tempPartition.add(s.substring(0, i + 1)); doPartition(s.substring(i + 1), partitions, tempPartition); tempPartition.remove(tempPartition.size() - 1); &#125; &#125;&#125;private boolean isPalindrome(String s, int begin, int end) &#123; while (begin &lt; end) &#123; if (s.charAt(begin++) != s.charAt(end--)) &#123; return false; &#125; &#125; return true;&#125; 数独37. Sudoku Solver (Hard) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private boolean[][] rowsUsed = new boolean[9][10];private boolean[][] colsUsed = new boolean[9][10];private boolean[][] cubesUsed = new boolean[9][10];private char[][] board;public void solveSudoku(char[][] board) &#123; this.board = board; for (int i = 0; i &lt; 9; i++) for (int j = 0; j &lt; 9; j++) &#123; if (board[i][j] == &#x27;.&#x27;) &#123; continue; &#125; int num = board[i][j] - &#x27;0&#x27;; rowsUsed[i][num] = true; colsUsed[j][num] = true; cubesUsed[cubeNum(i, j)][num] = true; &#125; for (int i = 0; i &lt; 9; i++) &#123; for (int j = 0; j &lt; 9; j++) &#123; backtracking(i, j); &#125; &#125;&#125;private boolean backtracking(int row, int col) &#123; while (row &lt; 9 &amp;&amp; board[row][col] != &#x27;.&#x27;) &#123; row = col == 8 ? row + 1 : row; col = col == 8 ? 0 : col + 1; &#125; if (row == 9) &#123; return true; &#125; for (int num = 1; num &lt;= 9; num++) &#123; if (rowsUsed[row][num] || colsUsed[col][num] || cubesUsed[cubeNum(row, col)][num]) &#123; continue; &#125; rowsUsed[row][num] = colsUsed[col][num] = cubesUsed[cubeNum(row, col)][num] = true; board[row][col] = (char) (num + &#x27;0&#x27;); if (backtracking(row, col)) &#123; return true; &#125; board[row][col] = &#x27;.&#x27;; rowsUsed[row][num] = colsUsed[col][num] = cubesUsed[cubeNum(row, col)][num] = false; &#125; return false;&#125;private int cubeNum(int i, int j) &#123; int r = i / 3; int c = j / 3; return r * 3 + c;&#125; N 皇后51. N-Queens (Hard) 在 n*n 的矩阵中摆放 n 个皇后，并且每个皇后不能在同一行，同一列，同一对角线上，求所有的 n 皇后的解。 一行一行地摆放，在确定一行中的那个皇后应该摆在哪一列时，需要用三个标记数组来确定某一列是否合法，这三个标记数组分别为: 列标记数组、45 度对角线标记数组和 135 度对角线标记数组。 45 度对角线标记数组的维度为 2 * n - 1，通过下图可以明确 (r, c) 的位置所在的数组下标为 r + c。 135 度对角线标记数组的维度也是 2 * n - 1，(r, c) 的位置所在的数组下标为 n - 1 - (r - c)。 1234567891011121314151617181920212223242526272829303132333435363738394041424344private List&lt;List&lt;String&gt;&gt; solutions;private char[][] nQueens;private boolean[] colUsed;private boolean[] diagonals45Used;private boolean[] diagonals135Used;private int n;public List&lt;List&lt;String&gt;&gt; solveNQueens(int n) &#123; solutions = new ArrayList&lt;&gt;(); nQueens = new char[n][n]; for (int i = 0; i &lt; n; i++) &#123; Arrays.fill(nQueens[i], &#x27;.&#x27;); &#125; colUsed = new boolean[n]; diagonals45Used = new boolean[2 * n - 1]; diagonals135Used = new boolean[2 * n - 1]; this.n = n; backtracking(0); return solutions;&#125;private void backtracking(int row) &#123; if (row == n) &#123; List&lt;String&gt; list = new ArrayList&lt;&gt;(); for (char[] chars : nQueens) &#123; list.add(new String(chars)); &#125; solutions.add(list); return; &#125; for (int col = 0; col &lt; n; col++) &#123; int diagonals45Idx = row + col; int diagonals135Idx = n - 1 - (row - col); if (colUsed[col] || diagonals45Used[diagonals45Idx] || diagonals135Used[diagonals135Idx]) &#123; continue; &#125; nQueens[row][col] = &#x27;Q&#x27;; colUsed[col] = diagonals45Used[diagonals45Idx] = diagonals135Used[diagonals135Idx] = true; backtracking(row + 1); colUsed[col] = diagonals45Used[diagonals45Idx] = diagonals135Used[diagonals135Idx] = false; nQueens[row][col] = &#x27;.&#x27;; &#125;&#125;","tags":["算法","算法思想","回溯算法"],"categories":["算法","算法思想"]},{"title":"6.算法思想 - 搜索算法","path":"/2023/12/27/6-算法思想-搜索算法/","content":"本文主要介绍算法中搜索算法的思想，主要包含BFS，DFS。 搜索相关题目深度优先搜索和广度优先搜索广泛运用于树和图中，但是它们的应用远远不止如此。 BFS 广度优先搜索的搜索过程有点像一层一层地进行遍历，每层遍历都以上一层遍历的结果作为起点，遍历一个距离能访问到的所有节点。需要注意的是，遍历过的节点不能再次被遍历。 第一层: 0 -&gt; {6,2,1,5}; 第二层: 6 -&gt; 2 -&gt; {} 1 -&gt; {} 5 -&gt; 第三层: 4 -&gt; {} 3 -&gt; {} 可以看到，每一层遍历的节点都与根节点距离相同。设 di 表示第 i 个节点与根节点的距离，推导出一个结论: 对于先遍历的节点 i 与后遍历的节点 j，有 di&lt;&#x3D;dj。利用这个结论，可以求解最短路径等 最优解 问题: 第一次遍历到目的节点，其所经过的路径为最短路径。应该注意的是，使用 BFS 只能求解无权图的最短路径。 在程序实现 BFS 时需要考虑以下问题: 队列: 用来存储每一轮遍历得到的节点； 标记: 对于遍历过的节点，应该将它标记，防止重复遍历。 计算在网格中从原点到特定点的最短路径长度1234[[1,1,0,1], [1,0,1,0], [1,1,1,1], [1,0,1,1]] 1 表示可以经过某个位置，求解从 (0, 0) 位置到 (tr, tc) 位置的最短路径长度。 1234567891011121314151617181920212223242526272829public int minPathLength(int[][] grids, int tr, int tc) &#123; final int[][] direction = &#123;&#123;1, 0&#125;, &#123;-1, 0&#125;, &#123;0, 1&#125;, &#123;0, -1&#125;&#125;; final int m = grids.length, n = grids[0].length; Queue&lt;Pair&lt;Integer, Integer&gt;&gt; queue = new LinkedList&lt;&gt;(); queue.add(new Pair&lt;&gt;(0, 0)); int pathLength = 0; while (!queue.isEmpty()) &#123; int size = queue.size(); pathLength++; while (size-- &gt; 0) &#123; Pair&lt;Integer, Integer&gt; cur = queue.poll(); for (int[] d : direction) &#123; int nr = cur.getKey() + d[0], nc = cur.getValue() + d[1]; Pair&lt;Integer, Integer&gt; next = new Pair&lt;&gt;(nr, nc); if (next.getKey() &lt; 0 || next.getValue() &gt;= m || next.getKey() &lt; 0 || next.getValue() &gt;= n) &#123; continue; &#125; grids[next.getKey()][next.getValue()] = 0; // 标记 if (next.getKey() == tr &amp;&amp; next.getValue() == tc) &#123; return pathLength; &#125; queue.add(next); &#125; &#125; &#125; return -1;&#125; 组成整数的最小平方数数量279. Perfect Squares (Medium) 1For example, given n = 12, return 3 because 12 = 4 + 4 + 4; given n = 13, return 2 because 13 = 4 + 9. 可以将每个整数看成图中的一个节点，如果两个整数之差为一个平方数，那么这两个整数所在的节点就有一条边。 要求解最小的平方数数量，就是求解从节点 n 到节点 0 的最短路径。 本题也可以用动态规划求解，在之后动态规划部分中会再次出现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public int numSquares(int n) &#123; List&lt;Integer&gt; squares = generateSquares(n); Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); boolean[] marked = new boolean[n + 1]; queue.add(n); marked[n] = true; int level = 0; while (!queue.isEmpty()) &#123; int size = queue.size(); level++; while (size-- &gt; 0) &#123; int cur = queue.poll(); for (int s : squares) &#123; int next = cur - s; if (next &lt; 0) &#123; break; &#125; if (next == 0) &#123; return level; &#125; if (marked[next]) &#123; continue; &#125; marked[next] = true; queue.add(cur - s); &#125; &#125; &#125; return n;&#125;/** * 生成小于 n 的平方数序列 * @return 1,4,9,... */private List&lt;Integer&gt; generateSquares(int n) &#123; List&lt;Integer&gt; squares = new ArrayList&lt;&gt;(); int square = 1; int diff = 3; while (square &lt;= n) &#123; squares.add(square); square += diff; diff += 2; &#125; return squares;&#125; 最短单词路径127. Word Ladder (Medium) 123456789Input:beginWord = &quot;hit&quot;,endWord = &quot;cog&quot;,wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;,&quot;cog&quot;]Output: 5Explanation: As one shortest transformation is &quot;hit&quot; -&gt; &quot;hot&quot; -&gt; &quot;dot&quot; -&gt; &quot;dog&quot; -&gt; &quot;cog&quot;,return its length 5. 12345678Input:beginWord = &quot;hit&quot;endWord = &quot;cog&quot;wordList = [&quot;hot&quot;,&quot;dot&quot;,&quot;dog&quot;,&quot;lot&quot;,&quot;log&quot;]Output: 0Explanation: The endWord &quot;cog&quot; is not in wordList, therefore no possible transformation. 找出一条从 beginWord 到 endWord 的最短路径，每次移动规定为改变一个字符，并且改变之后的字符串必须在 wordList 中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public int ladderLength(String beginWord, String endWord, List&lt;String&gt; wordList) &#123; wordList.add(beginWord); int N = wordList.size(); int start = N - 1; int end = 0; while (end &lt; N &amp;&amp; !wordList.get(end).equals(endWord)) &#123; end++; &#125; if (end == N) &#123; return 0; &#125; List&lt;Integer&gt;[] graphic = buildGraphic(wordList); return getShortestPath(graphic, start, end);&#125;private List&lt;Integer&gt;[] buildGraphic(List&lt;String&gt; wordList) &#123; int N = wordList.size(); List&lt;Integer&gt;[] graphic = new List[N]; for (int i = 0; i &lt; N; i++) &#123; graphic[i] = new ArrayList&lt;&gt;(); for (int j = 0; j &lt; N; j++) &#123; if (isConnect(wordList.get(i), wordList.get(j))) &#123; graphic[i].add(j); &#125; &#125; &#125; return graphic;&#125;private boolean isConnect(String s1, String s2) &#123; int diffCnt = 0; for (int i = 0; i &lt; s1.length() &amp;&amp; diffCnt &lt;= 1; i++) &#123; if (s1.charAt(i) != s2.charAt(i)) &#123; diffCnt++; &#125; &#125; return diffCnt == 1;&#125;private int getShortestPath(List&lt;Integer&gt;[] graphic, int start, int end) &#123; Queue&lt;Integer&gt; queue = new LinkedList&lt;&gt;(); boolean[] marked = new boolean[graphic.length]; queue.add(start); marked[start] = true; int path = 1; while (!queue.isEmpty()) &#123; int size = queue.size(); path++; while (size-- &gt; 0) &#123; int cur = queue.poll(); for (int next : graphic[cur]) &#123; if (next == end) &#123; return path; &#125; if (marked[next]) &#123; continue; &#125; marked[next] = true; queue.add(next); &#125; &#125; &#125; return 0;&#125; DFS 广度优先搜索一层一层遍历，每一层得到的所有新节点，要用队列存储起来以备下一层遍历的时候再遍历。 而深度优先搜索在得到一个新节点时立马对新节点进行遍历: 从节点 0 出发开始遍历，得到到新节点 6 时，立马对新节点 6 进行遍历，得到新节点 4；如此反复以这种方式遍历新节点，直到没有新节点了，此时返回。返回到根节点 0 的情况是，继续对根节点 0 进行遍历，得到新节点 2，然后继续以上步骤。 从一个节点出发，使用 DFS 对一个图进行遍历时，能够遍历到的节点都是从初始节点可达的，DFS 常用来求解这种 可达性 问题。 在程序实现 DFS 时需要考虑以下问题: 栈: 用栈来保存当前节点信息，当遍历新节点返回时能够继续遍历当前节点。可以使用递归栈。 标记: 和 BFS 一样同样需要对已经遍历过的节点进行标记。 查找最大的连通面积695. Max Area of Island (Easy) 12345678[[0,0,1,0,0,0,0,1,0,0,0,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,1,1,0,1,0,0,0,0,0,0,0,0], [0,1,0,0,1,1,0,0,1,0,1,0,0], [0,1,0,0,1,1,0,0,1,1,1,0,0], [0,0,0,0,0,0,0,0,0,0,1,0,0], [0,0,0,0,0,0,0,1,1,1,0,0,0], [0,0,0,0,0,0,0,1,1,0,0,0,0]] 1234567891011121314151617181920212223242526272829private int m, n;private int[][] direction = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;;public int maxAreaOfIsland(int[][] grid) &#123; if (grid == null || grid.length == 0) &#123; return 0; &#125; m = grid.length; n = grid[0].length; int maxArea = 0; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; maxArea = Math.max(maxArea, dfs(grid, i, j)); &#125; &#125; return maxArea;&#125;private int dfs(int[][] grid, int r, int c) &#123; if (r &lt; 0 || r &gt;= m || c &lt; 0 || c &gt;= n || grid[r][c] == 0) &#123; return 0; &#125; grid[r][c] = 0; int area = 1; for (int[] d : direction) &#123; area += dfs(grid, r + d[0], c + d[1]); &#125; return area;&#125; 矩阵中的连通分量数目200. Number of Islands (Medium) 1234567Input:11000110000010000011Output: 3 可以将矩阵表示看成一张有向图。 123456789101112131415161718192021222324252627282930private int m, n;private int[][] direction = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;;public int numIslands(char[][] grid) &#123; if (grid == null || grid.length == 0) &#123; return 0; &#125; m = grid.length; n = grid[0].length; int islandsNum = 0; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (grid[i][j] != &#x27;0&#x27;) &#123; dfs(grid, i, j); islandsNum++; &#125; &#125; &#125; return islandsNum;&#125;private void dfs(char[][] grid, int i, int j) &#123; if (i &lt; 0 || i &gt;= m || j &lt; 0 || j &gt;= n || grid[i][j] == &#x27;0&#x27;) &#123; return; &#125; grid[i][j] = &#x27;0&#x27;; for (int[] d : direction) &#123; dfs(grid, i + d[0], j + d[1]); &#125;&#125; 好友关系的连通分量数目547. Friend Circles (Medium) 1234567Input:[[1,1,0], [1,1,0], [0,0,1]]Output: 2Explanation:The 0th and 1st students are direct friends, so they are in a friend circle.The 2nd student himself is in a friend circle. So return 2. 好友关系可以看成是一个无向图，例如第 0 个人与第 1 个人是好友，那么 M[0][1] 和 M[1][0] 的值都为 1。 1234567891011121314151617181920212223private int n;public int findCircleNum(int[][] M) &#123; n = M.length; int circleNum = 0; boolean[] hasVisited = new boolean[n]; for (int i = 0; i &lt; n; i++) &#123; if (!hasVisited[i]) &#123; dfs(M, i, hasVisited); circleNum++; &#125; &#125; return circleNum;&#125;private void dfs(int[][] M, int i, boolean[] hasVisited) &#123; hasVisited[i] = true; for (int k = 0; k &lt; n; k++) &#123; if (M[i][k] == 1 &amp;&amp; !hasVisited[k]) &#123; dfs(M, k, hasVisited); &#125; &#125;&#125; 填充封闭区域130. Surrounded Regions (Medium) 1234567891011For example,X X X XX O O XX X O XX O X XAfter running your function, the board should be:X X X XX X X XX X X XX O X X 使被 ‘X’ 包围的 ‘O’ 转换为 ‘X’。 先填充最外侧，剩下的就是里侧了。 12345678910111213141516171819202122232425262728293031323334353637383940private int[][] direction = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;;private int m, n;public void solve(char[][] board) &#123; if (board == null || board.length == 0) &#123; return; &#125; m = board.length; n = board[0].length; for (int i = 0; i &lt; m; i++) &#123; dfs(board, i, 0); dfs(board, i, n - 1); &#125; for (int i = 0; i &lt; n; i++) &#123; dfs(board, 0, i); dfs(board, m - 1, i); &#125; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (board[i][j] == &#x27;T&#x27;) &#123; board[i][j] = &#x27;O&#x27;; &#125; else if (board[i][j] == &#x27;O&#x27;) &#123; board[i][j] = &#x27;X&#x27;; &#125; &#125; &#125;&#125;private void dfs(char[][] board, int r, int c) &#123; if (r &lt; 0 || r &gt;= m || c &lt; 0 || c &gt;= n || board[r][c] != &#x27;O&#x27;) &#123; return; &#125; board[r][c] = &#x27;T&#x27;; for (int[] d : direction) &#123; dfs(board, r + d[0], c + d[1]); &#125;&#125; 能到达的太平洋和大西洋的区域417. Pacific Atlantic Water Flow (Medium) 123456789101112Given the following 5x5 matrix: Pacific ~ ~ ~ ~ ~ ~ 1 2 2 3 (5) * ~ 3 2 3 (4) (4) * ~ 2 4 (5) 3 1 * ~ (6) (7) 1 4 5 * ~ (5) 1 1 2 4 * * * * * * AtlanticReturn:[[0, 4], [1, 3], [1, 4], [2, 2], [3, 0], [3, 1], [4, 0]] (positions with parentheses in above matrix). 左边和上边是太平洋，右边和下边是大西洋，内部的数字代表海拔，海拔高的地方的水能够流到低的地方，求解水能够流到太平洋和大西洋的所有位置。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152private int m, n;private int[][] matrix;private int[][] direction = &#123;&#123;0, 1&#125;, &#123;0, -1&#125;, &#123;1, 0&#125;, &#123;-1, 0&#125;&#125;;public List&lt;int[]&gt; pacificAtlantic(int[][] matrix) &#123; List&lt;int[]&gt; ret = new ArrayList&lt;&gt;(); if (matrix == null || matrix.length == 0) &#123; return ret; &#125; m = matrix.length; n = matrix[0].length; this.matrix = matrix; boolean[][] canReachP = new boolean[m][n]; boolean[][] canReachA = new boolean[m][n]; for (int i = 0; i &lt; m; i++) &#123; dfs(i, 0, canReachP); dfs(i, n - 1, canReachA); &#125; for (int i = 0; i &lt; n; i++) &#123; dfs(0, i, canReachP); dfs(m - 1, i, canReachA); &#125; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (canReachP[i][j] &amp;&amp; canReachA[i][j]) &#123; ret.add(new int[]&#123;i, j&#125;); &#125; &#125; &#125; return ret;&#125;private void dfs(int r, int c, boolean[][] canReach) &#123; if (canReach[r][c]) &#123; return; &#125; canReach[r][c] = true; for (int[] d : direction) &#123; int nextR = d[0] + r; int nextC = d[1] + c; if (nextR &lt; 0 || nextR &gt;= m || nextC &lt; 0 || nextC &gt;= n || matrix[r][c] &gt; matrix[nextR][nextC]) &#123; continue; &#125; dfs(nextR, nextC, canReach); &#125;&#125;","tags":["算法","算法思想","搜索算法"],"categories":["算法","算法思想"]},{"title":"5.算法思想 - 二分法","path":"/2023/12/27/5-算法思想-二分法/","content":"本文主要介绍算法思想中分治算法重要的二分法，比如二分查找；二分查找也称折半查找（Binary Search），它是一种效率较高的查找方法。但是，折半查找要求线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。 二分查找正常实现1234567891011121314public int binarySearch(int[] nums, int key) &#123; int l = 0, h = nums.length - 1; while (l &lt;= h) &#123; int m = l + (h - l) / 2; if (nums[m] == key) &#123; return m; &#125; else if (nums[m] &gt; key) &#123; h = m - 1; &#125; else &#123; l = m + 1; &#125; &#125; return -1;&#125; 时间复杂度二分查找也称为折半查找，每次都能将查找区间减半，这种折半特性的算法时间复杂度都为 O(logN)。 m 计算 有两种计算中值 m 的方式: m &#x3D; (l + h) &#x2F; 2 m &#x3D; l + (h - l) &#x2F; 2 l + h 可能出现加法溢出，最好使用第二种方式。 返回值 循环退出时如果仍然没有查找到 key，那么表示查找失败。可以有两种返回值: -1: 以一个错误码表示没有查找到 key l: 将 key 插入到 nums 中的正确位置 二分查找变种二分查找可以有很多变种，变种实现要注意边界值的判断。例如在一个有重复元素的数组中查找 key 的最左位置的实现如下: 123456789101112public int binarySearch(int[] nums, int key) &#123; int l = 0, h = nums.length - 1; while (l &lt; h) &#123; int m = l + (h - l) / 2; if (nums[m] &gt;= key) &#123; h = m; &#125; else &#123; l = m + 1; &#125; &#125; return l;&#125; 该实现和正常实现有以下不同: 循环条件为 l &lt; h h 的赋值表达式为 h &#x3D; m 最后返回 l 而不是 -1 在 nums[m] &gt;&#x3D; key 的情况下，可以推导出最左 key 位于 [l, m] 区间中，这是一个闭区间。h 的赋值表达式为 h &#x3D; m，因为 m 位置也可能是解。 在 h 的赋值表达式为 h &#x3D; mid 的情况下，如果循环条件为 l &lt;&#x3D; h，那么会出现循环无法退出的情况，因此循环条件只能是 l &lt; h。以下演示了循环条件为 l &lt;&#x3D; h 时循环无法退出的情况: 1234567nums = &#123;0, 1, 2&#125;, key = 1l m h0 1 2 nums[m] &gt;= key0 0 1 nums[m] &lt; key1 1 1 nums[m] &gt;= key1 1 1 nums[m] &gt;= key... 当循环体退出时，不表示没有查找到 key，因此最后返回的结果不应该为 -1。为了验证有没有查找到，需要在调用端判断一下返回位置上的值和 key 是否相等。 求开方69. Sqrt(x) (Easy) 123456Input: 4Output: 2Input: 8Output: 2Explanation: The square root of 8 is 2.82842..., and since we want to return an integer, the decimal part will be truncated. 一个数 x 的开方 sqrt 一定在 0 ~ x 之间，并且满足 sqrt &#x3D;&#x3D; x &#x2F; sqrt。可以利用二分查找在 0 ~ x 之间查找 sqrt。 对于 x &#x3D; 8，它的开方是 2.82842…，最后应该返回 2 而不是 3。在循环条件为 l &lt;&#x3D; h 并且循环退出时，h 总是比 l 小 1，也就是说 h &#x3D; 2，l &#x3D; 3，因此最后的返回值应该为 h 而不是 l。 123456789101112131415161718public int mySqrt(int x) &#123; if (x &lt;= 1) &#123; return x; &#125; int l = 1, h = x; while (l &lt;= h) &#123; int mid = l + (h - l) / 2; int sqrt = x / mid; if (sqrt == mid) &#123; return mid; &#125; else if (mid &gt; sqrt) &#123; h = mid - 1; &#125; else &#123; l = mid + 1; &#125; &#125; return h;&#125; 大于给定元素的最小元素744. Find Smallest Letter Greater Than Target (Easy) 123456789Input:letters = [&quot;c&quot;, &quot;f&quot;, &quot;j&quot;]target = &quot;d&quot;Output: &quot;f&quot;Input:letters = [&quot;c&quot;, &quot;f&quot;, &quot;j&quot;]target = &quot;k&quot;Output: &quot;c&quot; 题目描述: 给定一个有序的字符数组 letters 和一个字符 target，要求找出 letters 中大于 target 的最小字符，如果找不到就返回第 1 个字符。 12345678910111213public char nextGreatestLetter(char[] letters, char target) &#123; int n = letters.length; int l = 0, h = n - 1; while (l &lt;= h) &#123; int m = l + (h - l) / 2; if (letters[m] &lt;= target) &#123; l = m + 1; &#125; else &#123; h = m - 1; &#125; &#125; return l &lt; n ? letters[l] : letters[0];&#125; 有序数组的 Single Element540. Single Element in a Sorted Array (Medium) 12Input: [1,1,2,3,3,4,4,8,8]Output: 2 题目描述: 一个有序数组只有一个数不出现两次，找出这个数。要求以 O(logN) 时间复杂度进行求解。 令 index 为 Single Element 在数组中的位置。如果 m 为偶数，并且 m + 1 &lt; index，那么 nums[m] &#x3D;&#x3D; nums[m + 1]；m + 1 &gt;&#x3D; index，那么 nums[m] !&#x3D; nums[m + 1]。 从上面的规律可以知道，如果 nums[m] &#x3D;&#x3D; nums[m + 1]，那么 index 所在的数组位置为 [m + 2, h]，此时令 l &#x3D; m + 2；如果 nums[m] !&#x3D; nums[m + 1]，那么 index 所在的数组位置为 [l, m]，此时令 h &#x3D; m。 因为 h 的赋值表达式为 h &#x3D; m，那么循环条件也就只能使用 l &lt; h 这种形式。 123456789101112131415public int singleNonDuplicate(int[] nums) &#123; int l = 0, h = nums.length - 1; while (l &lt; h) &#123; int m = l + (h - l) / 2; if (m % 2 == 1) &#123; m--; // 保证 l/h/m 都在偶数位，使得查找区间大小一直都是奇数 &#125; if (nums[m] == nums[m + 1]) &#123; l = m + 2; &#125; else &#123; h = m; &#125; &#125; return nums[l];&#125; 第一个错误的版本278. First Bad Version (Easy) 题目描述: 给定一个元素 n 代表有 [1, 2, …, n] 版本，可以调用 isBadVersion(int x) 知道某个版本是否错误，要求找到第一个错误的版本。 如果第 m 个版本出错，则表示第一个错误的版本在 [l, m] 之间，令 h &#x3D; m；否则第一个错误的版本在 [m + 1, h] 之间，令 l &#x3D; m + 1。 因为 h 的赋值表达式为 h &#x3D; m，因此循环条件为 l &lt; h。 123456789101112public int firstBadVersion(int n) &#123; int l = 1, h = n; while (l &lt; h) &#123; int mid = l + (h - l) / 2; if (isBadVersion(mid)) &#123; h = mid; &#125; else &#123; l = mid + 1; &#125; &#125; return l;&#125; 旋转数组的最小数字153. Find Minimum in Rotated Sorted Array (Medium) 12Input: [3,4,5,1,2],Output: 1 123456789101112public int findMin(int[] nums) &#123; int l = 0, h = nums.length - 1; while (l &lt; h) &#123; int m = l + (h - l) / 2; if (nums[m] &lt;= nums[h]) &#123; h = m; &#125; else &#123; l = m + 1; &#125; &#125; return nums[l];&#125; 查找区间34. Search for a Range (Medium) 12345Input: nums = [5,7,7,8,8,10], target = 8Output: [3,4]Input: nums = [5,7,7,8,8,10], target = 6Output: [-1,-1] 12345678910111213141516171819202122public int[] searchRange(int[] nums, int target) &#123; int first = binarySearch(nums, target); int last = binarySearch(nums, target + 1) - 1; if (first == nums.length || nums[first] != target) &#123; return new int[]&#123;-1, -1&#125;; &#125; else &#123; return new int[]&#123;first, Math.max(first, last)&#125;; &#125;&#125;private int binarySearch(int[] nums, int target) &#123; int l = 0, h = nums.length; // 注意 h 的初始值 while (l &lt; h) &#123; int m = l + (h - l) / 2; if (nums[m] &gt;= target) &#123; h = m; &#125; else &#123; l = m + 1; &#125; &#125; return l;&#125;","tags":["算法","算法思想","二分法"],"categories":["算法","算法思想"]},{"title":"4.算法思想 - 贪心算法","path":"/2023/12/27/4-算法思想-贪心算法/","content":"本文主要介绍算法中贪心算法的思想: 保证每次操作都是局部最优的，并且最后得到的结果是全局最优的。 贪心思想相关题目分配饼干455. Assign Cookies (Easy) 123456Input: [1,2], [1,2,3]Output: 2Explanation: You have 2 children and 3 cookies. The greed factors of 2 children are 1, 2.You have 3 cookies and their sizes are big enough to gratify all of the children,You need to output 2. 题目描述: 每个孩子都有一个满足度，每个饼干都有一个大小，只有饼干的大小大于等于一个孩子的满足度，该孩子才会获得满足。求解最多可以获得满足的孩子数量。 给一个孩子的饼干应当尽量小又能满足该孩子，这样大饼干就能拿来给满足度比较大的孩子。因为最小的孩子最容易得到满足，所以先满足最小的孩子。 证明: 假设在某次选择中，贪心策略选择给当前满足度最小的孩子分配第 m 个饼干，第 m 个饼干为可以满足该孩子的最小饼干。假设存在一种最优策略，给该孩子分配第 n 个饼干，并且 m &lt; n。我们可以发现，经过这一轮分配，贪心策略分配后剩下的饼干一定有一个比最优策略来得大。因此在后续的分配中，贪心策略一定能满足更多的孩子。也就是说不存在比贪心策略更优的策略，即贪心策略就是最优策略。 123456789101112public int findContentChildren(int[] g, int[] s) &#123; Arrays.sort(g); Arrays.sort(s); int gi = 0, si = 0; while (gi &lt; g.length &amp;&amp; si &lt; s.length) &#123; if (g[gi] &lt;= s[si]) &#123; gi++; &#125; si++; &#125; return gi;&#125; 不重叠的区间个数435. Non-overlapping Intervals (Medium) 12345Input: [ [1,2], [1,2], [1,2] ]Output: 2Explanation: You need to remove two [1,2] to make the rest of intervals non-overlapping. 12345Input: [ [1,2], [2,3] ]Output: 0Explanation: You don&#x27;t need to remove any of the intervals since they&#x27;re already non-overlapping. 题目描述: 计算让一组区间不重叠所需要移除的区间个数。 计算最多能组成的不重叠区间个数，然后用区间总个数减去不重叠区间的个数。 在每次选择中，区间的结尾最为重要，选择的区间结尾越小，留给后面的区间的空间越大，那么后面能够选择的区间个数也就越大。 按区间的结尾进行排序，每次选择结尾最小，并且和前一个区间不重叠的区间。 12345678910111213141516public int eraseOverlapIntervals(Interval[] intervals) &#123; if (intervals.length == 0) &#123; return 0; &#125; Arrays.sort(intervals, Comparator.comparingInt(o -&gt; o.end)); int cnt = 1; int end = intervals[0].end; for (int i = 1; i &lt; intervals.length; i++) &#123; if (intervals[i].start &lt; end) &#123; continue; &#125; end = intervals[i].end; cnt++; &#125; return intervals.length - cnt;&#125; 使用 lambda 表示式创建 Comparator 会导致算法运行时间过长，如果注重运行时间，可以修改为普通创建 Comparator 语句: 123456Arrays.sort(intervals, new Comparator&lt;Interval&gt;() &#123; @Override public int compare(Interval o1, Interval o2) &#123; return o1.end - o2.end; &#125;&#125;); 投飞镖刺破气球452. Minimum Number of Arrows to Burst Balloons (Medium) 12345Input:[[10,16], [2,8], [1,6], [7,12]]Output:2 题目描述: 气球在一个水平数轴上摆放，可以重叠，飞镖垂直投向坐标轴，使得路径上的气球都会刺破。求解最小的投飞镖次数使所有气球都被刺破。 也是计算不重叠的区间个数，不过和 Non-overlapping Intervals 的区别在于，[1, 2] 和 [2, 3] 在本题中算是重叠区间。 123456789101112131415public int findMinArrowShots(int[][] points) &#123; if (points.length == 0) &#123; return 0; &#125; Arrays.sort(points, Comparator.comparingInt(o -&gt; o[1])); int cnt = 1, end = points[0][1]; for (int i = 1; i &lt; points.length; i++) &#123; if (points[i][0] &lt;= end) &#123; continue; &#125; cnt++; end = points[i][1]; &#125; return cnt;&#125; 根据身高和序号重组队列406. Queue Reconstruction by Height(Medium) 12345Input:[[7,0], [4,4], [7,1], [5,0], [6,1], [5,2]]Output:[[5,0], [7,0], [5,2], [6,1], [4,4], [7,1]] 题目描述: 一个学生用两个分量 (h, k) 描述，h 表示身高，k 表示排在前面的有 k 个学生的身高比他高或者和他一样高。 为了在每次插入操作时不影响后续的操作，身高较高的学生应该先做插入操作，否则身高较小的学生原先正确插入第 k 个位置可能会变成第 k+1 个位置。 身高降序、k 值升序，然后按排好序的顺序插入队列的第 k 个位置中。 1234567891011public int[][] reconstructQueue(int[][] people) &#123; if (people == null || people.length == 0 || people[0].length == 0) &#123; return new int[0][0]; &#125; Arrays.sort(people, (a, b) -&gt; (a[0] == b[0] ? a[1] - b[1] : b[0] - a[0])); List&lt;int[]&gt; queue = new ArrayList&lt;&gt;(); for (int[] p : people) &#123; queue.add(p[1], p); &#125; return queue.toArray(new int[queue.size()][]);&#125; 分隔字符串使同种字符出现在一起763. Partition Labels (Medium) 123456Input: S = &quot;ababcbacadefegdehijhklij&quot;Output: [9,7,8]Explanation:The partition is &quot;ababcbaca&quot;, &quot;defegde&quot;, &quot;hijhklij&quot;.This is a partition so that each letter appears in at most one part.A partition like &quot;ababcbacadefegde&quot;, &quot;hijhklij&quot; is incorrect, because it splits S into less parts. 123456789101112131415161718192021222324public List&lt;Integer&gt; partitionLabels(String S) &#123; int[] lastIndexsOfChar = new int[26]; for (int i = 0; i &lt; S.length(); i++) &#123; lastIndexsOfChar[char2Index(S.charAt(i))] = i; &#125; List&lt;Integer&gt; partitions = new ArrayList&lt;&gt;(); int firstIndex = 0; while (firstIndex &lt; S.length()) &#123; int lastIndex = firstIndex; for (int i = firstIndex; i &lt; S.length() &amp;&amp; i &lt;= lastIndex; i++) &#123; int index = lastIndexsOfChar[char2Index(S.charAt(i))]; if (index &gt; lastIndex) &#123; lastIndex = index; &#125; &#125; partitions.add(lastIndex - firstIndex + 1); firstIndex = lastIndex + 1; &#125; return partitions;&#125;private int char2Index(char c) &#123; return c - &#x27;a&#x27;;&#125; 种植花朵605. Can Place Flowers (Easy) 12Input: flowerbed = [1,0,0,0,1], n = 1Output: True 题目描述: 花朵之间至少需要一个单位的间隔，求解是否能种下 n 朵花。 12345678910111213141516public boolean canPlaceFlowers(int[] flowerbed, int n) &#123; int len = flowerbed.length; int cnt = 0; for (int i = 0; i &lt; len &amp;&amp; cnt &lt; n; i++) &#123; if (flowerbed[i] == 1) &#123; continue; &#125; int pre = i == 0 ? 0 : flowerbed[i - 1]; int next = i == len - 1 ? 0 : flowerbed[i + 1]; if (pre == 0 &amp;&amp; next == 0) &#123; cnt++; flowerbed[i] = 1; &#125; &#125; return cnt &gt;= n;&#125; 判断是否为子序列392. Is Subsequence (Medium) 12s = &quot;abc&quot;, t = &quot;ahbgdc&quot;Return true. 12345678910public boolean isSubsequence(String s, String t) &#123; int index = -1; for (char c : s.toCharArray()) &#123; index = t.indexOf(c, index + 1); if (index == -1) &#123; return false; &#125; &#125; return true;&#125; 修改一个数成为非递减数组665. Non-decreasing Array (Easy) 123Input: [4,2,3]Output: TrueExplanation: You could modify the first 4 to 1 to get a non-decreasing array. 题目描述: 判断一个数组能不能只修改一个数就成为非递减数组。 在出现 nums[i] &lt; nums[i - 1] 时，需要考虑的是应该修改数组的哪个数，使得本次修改能使 i 之前的数组成为非递减数组，并且 不影响后续的操作 。优先考虑令 nums[i - 1] &#x3D; nums[i]，因为如果修改 nums[i] &#x3D; nums[i - 1] 的话，那么 nums[i] 这个数会变大，就有可能比 nums[i + 1] 大，从而影响了后续操作。还有一个比较特别的情况就是 nums[i] &lt; nums[i - 2]，只修改 nums[i - 1] &#x3D; nums[i] 不能使数组成为非递减数组，只能修改 nums[i] &#x3D; nums[i - 1]。 123456789101112131415public boolean checkPossibility(int[] nums) &#123; int cnt = 0; for (int i = 1; i &lt; nums.length &amp;&amp; cnt &lt; 2; i++) &#123; if (nums[i] &gt;= nums[i - 1]) &#123; continue; &#125; cnt++; if (i - 2 &gt;= 0 &amp;&amp; nums[i - 2] &gt; nums[i]) &#123; nums[i] = nums[i - 1]; &#125; else &#123; nums[i - 1] = nums[i]; &#125; &#125; return cnt &lt;= 1;&#125; 股票的最大收益122. Best Time to Buy and Sell Stock II (Easy) 题目描述: 一次股票交易包含买入和卖出，多个交易之间不能交叉进行。 对于 [a, b, c, d]，如果有 a &lt;&#x3D; b &lt;&#x3D; c &lt;&#x3D; d ，那么最大收益为 d - a。而 d - a &#x3D; (d - c) + (c - b) + (b - a) ，因此当访问到一个 prices[i] 且 prices[i] - prices[i-1] &gt; 0，那么就把 prices[i] - prices[i-1] 添加到收益中，从而在局部最优的情况下也保证全局最优。 123456789public int maxProfit(int[] prices) &#123; int profit = 0; for (int i = 1; i &lt; prices.length; i++) &#123; if (prices[i] &gt; prices[i - 1]) &#123; profit += (prices[i] - prices[i - 1]); &#125; &#125; return profit;&#125;","tags":["算法","算法思想","贪心算法"],"categories":["算法","算法思想"]},{"title":"3.算法思想 - 动态规划算法","path":"/2023/12/27/3-算法思想-动态规划算法/","content":"动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。动态规划算法在算法思想中是极为重要的，需要重点掌握。 动态规划相关题目递归和动态规划都是将原问题拆成多个子问题然后求解，他们之间最本质的区别是，动态规划保存了子问题的解，避免重复计算。 斐波那契数列爬楼梯70. Climbing Stairs (Easy) 题目描述: 有 N 阶楼梯，每次可以上一阶或者两阶，求有多少种上楼梯的方法。 定义一个数组 dp 存储上楼梯的方法数(为了方便讨论，数组下标从 1 开始)，dp[i] 表示走到第 i 个楼梯的方法数目。 第 i 个楼梯可以从第 i-1 和 i-2 个楼梯再走一步到达，走到第 i 个楼梯的方法数为走到第 i-1 和第 i-2 个楼梯的方法数之和。 考虑到 dp[i] 只与 dp[i - 1] 和 dp[i - 2] 有关，因此可以只用两个变量来存储 dp[i - 1] 和 dp[i - 2]，使得原来的 O(N) 空间复杂度优化为 O(1) 复杂度。 123456789101112public int climbStairs(int n) &#123; if (n &lt;= 2) &#123; return n; &#125; int pre2 = 1, pre1 = 2; for (int i = 2; i &lt; n; i++) &#123; int cur = pre1 + pre2; pre2 = pre1; pre1 = cur; &#125; return pre1;&#125; 强盗抢劫198. House Robber (Easy) 题目描述: 抢劫一排住户，但是不能抢邻近的住户，求最大抢劫量。 定义 dp 数组用来存储最大的抢劫量，其中 dp[i] 表示抢到第 i 个住户时的最大抢劫量。 由于不能抢劫邻近住户，因此如果抢劫了第 i 个住户那么只能抢劫 i - 2 或者 i - 3 的住户，所以 1234567891011121314151617public int rob(int[] nums) &#123; int n = nums.length; if (n == 0) &#123; return 0; &#125; if (n == 1) &#123; return nums[0]; &#125; int pre3 = 0, pre2 = 0, pre1 = 0; for (int i = 0; i &lt; n; i++) &#123; int cur = Math.max(pre2, pre3) + nums[i]; pre3 = pre2; pre2 = pre1; pre1 = cur; &#125; return Math.max(pre1, pre2);&#125; 强盗在环形街区抢劫213. House Robber II (Medium) 123456789101112131415161718192021public int rob(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return 0; &#125; int n = nums.length; if (n == 1) &#123; return nums[0]; &#125; return Math.max(rob(nums, 0, n - 2), rob(nums, 1, n - 1));&#125;private int rob(int[] nums, int first, int last) &#123; int pre3 = 0, pre2 = 0, pre1 = 0; for (int i = first; i &lt;= last; i++) &#123; int cur = Math.max(pre3, pre2) + nums[i]; pre3 = pre2; pre2 = pre1; pre1 = cur; &#125; return Math.max(pre2, pre1);&#125; 信件错排题目描述: 有 N 个 信 和 信封，它们被打乱，求错误装信方式的数量。 定义一个数组 dp 存储错误方式数量，dp[i] 表示前 i 个信和信封的错误方式数量。假设第 i 个信装到第 j 个信封里面，而第 j 个信装到第 k 个信封里面。根据 i 和 k 是否相等，有两种情况: i&#x3D;&#x3D;k，交换 i 和 k 的信后，它们的信和信封在正确的位置，但是其余 i-2 封信有 dp[i-2] 种错误装信的方式。由于 j 有 i-1 种取值，因此共有 (i-1)*dp[i-2] 种错误装信方式。 i !&#x3D; k，交换 i 和 j 的信后，第 i 个信和信封在正确的位置，其余 i-1 封信有 dp[i-1] 种错误装信方式。由于 j 有 i-1 种取值，因此共有 (i-1)*dp[i-1] 种错误装信方式。 综上所述，错误装信数量方式数量为: 母牛生产题目描述: 假设农场中成熟的母牛每年都会生 1 头小母牛，并且永远不会死。第一年有 1 只小母牛，从第二年开始，母牛开始生小母牛。每只小母牛 3 年之后成熟又可以生小母牛。给定整数 N，求 N 年后牛的数量。 第 i 年成熟的牛的数量为: 矩阵路径矩阵的最小路径和64. Minimum Path Sum (Medium) 1234[[1,3,1], [1,5,1], [4,2,1]]Given the above grid map, return 7. Because the path 1→3→1→1→1 minimizes the sum. 题目描述: 求从矩阵的左上角到右下角的最小路径和，每次只能向右和向下移动。 123456789101112131415161718public int minPathSum(int[][] grid) &#123; if (grid.length == 0 || grid[0].length == 0) &#123; return 0; &#125; int m = grid.length, n = grid[0].length; int[] dp = new int[n]; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (i == 0) &#123; dp[j] = dp[j - 1]; &#125; else &#123; dp[j] = Math.min(dp[j - 1], dp[j]); &#125; dp[j] += grid[i][j]; &#125; &#125; return dp[n - 1];&#125; 矩阵的总路径数62. Unique Paths (Medium) 题目描述: 统计从矩阵左上角到右下角的路径总数，每次只能向右或者向下移动。 12345678910public int uniquePaths(int m, int n) &#123; int[] dp = new int[n]; Arrays.fill(dp, 1); for (int i = 1; i &lt; m; i++) &#123; for (int j = 1; j &lt; n; j++) &#123; dp[j] = dp[j] + dp[j - 1]; &#125; &#125; return dp[n - 1];&#125; 也可以直接用数学公式求解，这是一个组合问题。机器人总共移动的次数 S&#x3D;m+n-2，向下移动的次数 D&#x3D;m-1，那么问题可以看成从 S 从取出 D 个位置的组合数量，这个问题的解为 C(S, D)。 123456789public int uniquePaths(int m, int n) &#123; int S = m + n - 2; // 总共的移动次数 int D = m - 1; // 向下的移动次数 long ret = 1; for (int i = 1; i &lt;= D; i++) &#123; ret = ret * (S - D + i) / i; &#125; return (int) ret;&#125; 数组区间数组区间和303. Range Sum Query - Immutable (Easy) 12345Given nums = [-2, 0, 3, -5, 2, -1]sumRange(0, 2) -&gt; 1sumRange(2, 5) -&gt; -1sumRange(0, 5) -&gt; -3 求区间 i ~ j 的和，可以转换为 sum[j] - sum[i-1]，其中 sum[i] 为 0 ~ i 的和。 123456789101112131415class NumArray &#123; private int[] sums; public NumArray(int[] nums) &#123; sums = new int[nums.length + 1]; for (int i = 1; i &lt;= nums.length; i++) &#123; sums[i] = sums[i - 1] + nums[i - 1]; &#125; &#125; public int sumRange(int i, int j) &#123; return sums[j + 1] - sums[i]; &#125;&#125; 子数组最大的和53. Maximum Subarray (Easy) 12For example, given the array [-2,1,-3,4,-1,2,1,-5,4],the contiguous subarray [4,-1,2,1] has the largest sum = 6. 123456789101112public int maxSubArray(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return 0; &#125; int preSum = nums[0]; int maxSum = preSum; for (int i = 1; i &lt; nums.length; i++) &#123; preSum = preSum &gt; 0 ? preSum + nums[i] : nums[i]; maxSum = Math.max(maxSum, preSum); &#125; return maxSum;&#125; 数组中等差递增子区间的个数413. Arithmetic Slices (Medium) 12A = [1, 2, 3, 4]return: 3, for 3 arithmetic slices in A: [1, 2, 3], [2, 3, 4] and [1, 2, 3, 4] itself. dp[i] 表示以 A[i] 为结尾的等差递增子区间的个数。 在 A[i] - A[i - 1] &#x3D;&#x3D; A[i - 1] - A[i - 2] 的条件下，{A[i - 2], A[i - 1], A[i]} 是一个等差递增子区间。如果 {A[i - 3], A[i - 2], A[i - 1]} 是一个等差递增子区间，那么 {A[i - 3], A[i - 2], A[i - 1], A[i]} 也是等差递增子区间，dp[i] &#x3D; dp[i-1] + 1。 1234567891011121314151617public int numberOfArithmeticSlices(int[] A) &#123; if (A == null || A.length == 0) &#123; return 0; &#125; int n = A.length; int[] dp = new int[n]; for (int i = 2; i &lt; n; i++) &#123; if (A[i] - A[i - 1] == A[i - 1] - A[i - 2]) &#123; dp[i] = dp[i - 1] + 1; &#125; &#125; int total = 0; for (int cnt : dp) &#123; total += cnt; &#125; return total;&#125; 分割整数分割整数的最大乘积343. Integer Break (Medim) 题目描述: For example, given n &#x3D; 2, return 1 (2 &#x3D; 1 + 1); given n &#x3D; 10, return 36 (10 &#x3D; 3 + 3 + 4). 12345678910public int integerBreak(int n) &#123; int[] dp = new int[n + 1]; dp[1] = 1; for (int i = 2; i &lt;= n; i++) &#123; for (int j = 1; j &lt;= i - 1; j++) &#123; dp[i] = Math.max(dp[i], Math.max(j * dp[i - j], j * (i - j))); &#125; &#125; return dp[n];&#125; 按平方数来分割整数279. Perfect Squares(Medium) 题目描述: For example, given n &#x3D; 12, return 3 because 12 &#x3D; 4 + 4 + 4; given n &#x3D; 13, return 2 because 13 &#x3D; 4 + 9. 123456789101112131415161718192021222324252627public int numSquares(int n) &#123; List&lt;Integer&gt; squareList = generateSquareList(n); int[] dp = new int[n + 1]; for (int i = 1; i &lt;= n; i++) &#123; int min = Integer.MAX_VALUE; for (int square : squareList) &#123; if (square &gt; i) &#123; break; &#125; min = Math.min(min, dp[i - square] + 1); &#125; dp[i] = min; &#125; return dp[n];&#125;private List&lt;Integer&gt; generateSquareList(int n) &#123; List&lt;Integer&gt; squareList = new ArrayList&lt;&gt;(); int diff = 3; int square = 1; while (square &lt;= n) &#123; squareList.add(square); square += diff; diff += 2; &#125; return squareList;&#125; 分割整数构成字母字符串91. Decode Ways (Medium) 题目描述: Given encoded message “12”, it could be decoded as “AB” (1 2) or “L” (12). 1234567891011121314151617181920212223public int numDecodings(String s) &#123; if (s == null || s.length() == 0) &#123; return 0; &#125; int n = s.length(); int[] dp = new int[n + 1]; dp[0] = 1; dp[1] = s.charAt(0) == &#x27;0&#x27; ? 0 : 1; for (int i = 2; i &lt;= n; i++) &#123; int one = Integer.valueOf(s.substring(i - 1, i)); if (one != 0) &#123; dp[i] += dp[i - 1]; &#125; if (s.charAt(i - 2) == &#x27;0&#x27;) &#123; continue; &#125; int two = Integer.valueOf(s.substring(i - 2, i)); if (two &lt;= 26) &#123; dp[i] += dp[i - 2]; &#125; &#125; return dp[n];&#125; 最长递增子序列可以读一下这篇文章：https://zhuanlan.zhihu.com/p/78224512 已知一个序列 {S1, S2,…,Sn}，取出若干数组成新的序列 {Si1, Si2,…, Sim}，其中 i1、i2 … im 保持递增，即新序列中各个数仍然保持原数列中的先后顺序，称新序列为原序列的一个 子序列 。 如果在子序列中，当下标 ix &gt; iy 时，Six &gt; Siy，称子序列为原序列的一个 递增子序列 。 定义一个数组 dp 存储最长递增子序列的长度，dp[n] 表示以 Sn 结尾的序列的最长递增子序列长度。对于一个递增子序列 {Si1, Si2,…,Sim}，如果 im &lt; n 并且 Sim &lt; Sn，此时 {Si1, Si2,…, Sim, Sn} 为一个递增子序列，递增子序列的长度增加 1。满足上述条件的递增子序列中，长度最长的那个递增子序列就是要找的，在长度最长的递增子序列上加上 Sn 就构成了以 Sn 为结尾的最长递增子序列。因此 dp[n] &#x3D; max{ dp[i]+1 | Si &lt; Sn &amp;&amp; i &lt; n} 。 因为在求 dp[n] 时可能无法找到一个满足条件的递增子序列，此时 {Sn} 就构成了递增子序列，需要对前面的求解方程做修改，令 dp[n] 最小为 1，即: 12dp[i]=1 0≤i≤n-1dp[i]=max(dp[i]，dp[j]+1)\t若a[i]&gt;a[j]，0≤i≤n-1，0≤j≤i-1 对于一个长度为 N 的序列，最长递增子序列并不一定会以 SN 为结尾，因此 dp[N] 不是序列的最长递增子序列的长度，需要遍历 dp 数组找出最大值才是所要的结果，max{ dp[i] | 1 &lt;&#x3D; i &lt;&#x3D; N} 即为所求。 最长递增子序列300. Longest Increasing Subsequence (Medium) 1234567891011121314public int lengthOfLIS(int[] nums) &#123; int n = nums.length; int[] dp = new int[n]; for (int i = 0; i &lt; n; i++) &#123; int max = 1; for (int j = 0; j &lt; i; j++) &#123; if (nums[i] &gt; nums[j]) &#123; max = Math.max(max, dp[j] + 1); &#125; &#125; dp[i] = max; &#125; return Arrays.stream(dp).max().orElse(0);&#125; 使用 Stream 求最大值会导致运行时间过长，可以改成以下形式: 12345int ret = 0;for (int i = 0; i &lt; n; i++) &#123; ret = Math.max(ret, dp[i]);&#125;return ret; 以上解法的时间复杂度为 O(N²)，可以使用二分查找将时间复杂度降低为 O(NlogN)。 定义一个 tails 数组，其中 tails[i] 存储长度为 i + 1 的最长递增子序列的最后一个元素。对于一个元素 x， 如果它大于 tails 数组所有的值，那么把它添加到 tails 后面，表示最长递增子序列长度加 1； 如果 tails[i-1] &lt; x &lt;&#x3D; tails[i]，那么更新 tails[i-1] &#x3D; x。 例如对于数组 [4,3,6,5]，有: 123456tails len num[] 0 4[4] 1 3[3] 1 6[3,6] 2 5[3,5] 2 null 可以看出 tails 数组保持有序，因此在查找 Si 位于 tails 数组的位置时就可以使用二分查找。 12345678910111213141516171819202122232425262728public int lengthOfLIS(int[] nums) &#123; int n = nums.length; int[] tails = new int[n]; int len = 0; for (int num : nums) &#123; int index = binarySearch(tails, len, num); tails[index] = num; if (index == len) &#123; len++; &#125; &#125; return len;&#125;private int binarySearch(int[] tails, int len, int key) &#123; int l = 0, h = len; while (l &lt; h) &#123; int mid = l + (h - l) / 2; if (tails[mid] == key) &#123; return mid; &#125; else if (tails[mid] &gt; key) &#123; h = mid; &#125; else &#123; l = mid + 1; &#125; &#125; return l;&#125; 一组整数对能够构成的最长链646. Maximum Length of Pair Chain (Medium) 123Input: [[1,2], [2,3], [3,4]]Output: 2Explanation: The longest chain is [1,2] -&gt; [3,4] 题目描述: 对于 (a, b) 和 (c, d) ，如果 b &lt; c，则它们可以构成一条链。 1234567891011121314151617public int findLongestChain(int[][] pairs) &#123; if (pairs == null || pairs.length == 0) &#123; return 0; &#125; Arrays.sort(pairs, (a, b) -&gt; (a[0] - b[0])); int n = pairs.length; int[] dp = new int[n]; Arrays.fill(dp, 1); for (int i = 1; i &lt; n; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; if (pairs[j][1] &lt; pairs[i][0]) &#123; dp[i] = Math.max(dp[i], dp[j] + 1); &#125; &#125; &#125; return Arrays.stream(dp).max().orElse(0);&#125; 最长摆动子序列376. Wiggle Subsequence (Medium) 12345678910Input: [1,7,4,9,2,5]Output: 6The entire sequence is a wiggle sequence.Input: [1,17,5,10,13,15,10,5,16,8]Output: 7There are several subsequences that achieve this length. One is [1,17,10,13,10,16,8].Input: [1,2,3,4,5,6,7,8,9]Output: 2 要求: 使用 O(N) 时间复杂度求解。 1234567891011121314public int wiggleMaxLength(int[] nums) &#123; if (nums == null || nums.length == 0) &#123; return 0; &#125; int up = 1, down = 1; for (int i = 1; i &lt; nums.length; i++) &#123; if (nums[i] &gt; nums[i - 1]) &#123; up = down + 1; &#125; else if (nums[i] &lt; nums[i - 1]) &#123; down = up + 1; &#125; &#125; return Math.max(up, down);&#125; 最长公共子序列对于两个子序列 S1 和 S2，找出它们最长的公共子序列。 定义一个二维数组 dp 用来存储最长公共子序列的长度，其中 dp[i][j] 表示 S1 的前 i 个字符与 S2 的前 j 个字符最长公共子序列的长度。考虑 S1i 与 S2j 值是否相等，分为两种情况: 当 S1i&#x3D;&#x3D;S2j 时，那么就能在 S1 的前 i-1 个字符与 S2 的前 j-1 个字符最长公共子序列的基础上再加上 S1i 这个值，最长公共子序列长度加 1，即 dp[i][j] &#x3D; dp[i-1][j-1] + 1。 当 S1i !&#x3D; S2j 时，此时最长公共子序列为 S1 的前 i-1 个字符和 S2 的前 j 个字符最长公共子序列，或者 S1 的前 i 个字符和 S2 的前 j-1 个字符最长公共子序列，取它们的最大者，即 dp[i][j] &#x3D; max{ dp[i-1][j], dp[i][j-1] }。 综上，最长公共子序列的状态转移方程为: 123dp[i][j]=0 // 边界条件：i=0或j=0dp[i][j]=dp[i-1][j-1]+1 // a[i-1]=b[j-1]dp[i][j]=MAX(dp[i][j-1],dp[i-1][j]) // a[i-1]≠b[j-1] 对于长度为 N 的序列 S1 和长度为 M 的序列 S2，dp[N][M] 就是序列 S1 和序列 S2 的最长公共子序列长度。 与最长递增子序列相比，最长公共子序列有以下不同点: 针对的是两个序列，求它们的最长公共子序列。 在最长递增子序列中，dp[i] 表示以 Si 为结尾的最长递增子序列长度，子序列必须包含 Si ；在最长公共子序列中，dp[i][j] 表示 S1 中前 i 个字符与 S2 中前 j 个字符的最长公共子序列长度，不一定包含 S1i 和 S2j。 在求最终解时，最长公共子序列中 dp[N][M] 就是最终解，而最长递增子序列中 dp[N] 不是最终解，因为以 SN 为结尾的最长递增子序列不一定是整个序列最长递增子序列，需要遍历一遍 dp 数组找到最大者。 1234567891011121314public int lengthOfLCS(int[] nums1, int[] nums2) &#123; int n1 = nums1.length, n2 = nums2.length; int[][] dp = new int[n1 + 1][n2 + 1]; for (int i = 1; i &lt;= n1; i++) &#123; for (int j = 1; j &lt;= n2; j++) &#123; if (nums1[i - 1] == nums2[j - 1]) &#123; dp[i][j] = dp[i - 1][j - 1] + 1; &#125; else &#123; dp[i][j] = Math.max(dp[i - 1][j], dp[i][j - 1]); &#125; &#125; &#125; return dp[n1][n2];&#125; 0-1 背包有一个容量为 N 的背包，要用这个背包装下物品的价值最大，这些物品有两个属性: 体积 w 和价值 v。 定义一个二维数组 dp 存储最大价值，其中 dp[i][j] 表示前 i 件物品体积不超过 j 的情况下能达到的最大价值。设第 i 件物品体积为 w，价值为 v，根据第 i 件物品是否添加到背包中，可以分两种情况讨论: 第 i 件物品没添加到背包，总体积不超过 j 的前 i 件物品的最大价值就是总体积不超过 j 的前 i-1 件物品的最大价值，dp[i][j] &#x3D; dp[i-1][j]。 第 i 件物品添加到背包中，dp[i][j] &#x3D; dp[i-1][j-w] + v。 第 i 件物品可添加也可以不添加，取决于哪种情况下最大价值更大。因此，0-1 背包的状态转移方程为: 1234567891011121314public int knapsack(int W, int N, int[] weights, int[] values) &#123; int[][] dp = new int[N + 1][W + 1]; for (int i = 1; i &lt;= N; i++) &#123; int w = weights[i - 1], v = values[i - 1]; for (int j = 1; j &lt;= W; j++) &#123; if (j &gt;= w) &#123; dp[i][j] = Math.max(dp[i - 1][j], dp[i - 1][j - w] + v); &#125; else &#123; dp[i][j] = dp[i - 1][j]; &#125; &#125; &#125; return dp[N][W];&#125; 空间优化在程序实现时可以对 0-1 背包做优化。观察状态转移方程可以知道，前 i 件物品的状态仅与前 i-1 件物品的状态有关，因此可以将 dp 定义为一维数组，其中 dp[j] 既可以表示 dp[i-1][j] 也可以表示 dp[i][j]。此时， 因为 dp[j-w] 表示 dp[i-1][j-w]，因此不能先求 dp[i][j-w]，以防将 dp[i-1][j-w] 覆盖。也就是说要先计算 dp[i][j] 再计算 dp[i][j-w]，在程序实现时需要按倒序来循环求解。 123456789101112public int knapsack(int W, int N, int[] weights, int[] values) &#123; int[] dp = new int[W + 1]; for (int i = 1; i &lt;= N; i++) &#123; int w = weights[i - 1], v = values[i - 1]; for (int j = W; j &gt;= 1; j--) &#123; if (j &gt;= w) &#123; dp[j] = Math.max(dp[j], dp[j - w] + v); &#125; &#125; &#125; return dp[W];&#125; 无法使用贪心算法的解释 0-1 背包问题无法使用贪心算法来求解，也就是说不能按照先添加性价比最高的物品来达到最优，这是因为这种方式可能造成背包空间的浪费，从而无法达到最优。考虑下面的物品和一个容量为 5 的背包，如果先添加物品 0 再添加物品 1，那么只能存放的价值为 16，浪费了大小为 2 的空间。最优的方式是存放物品 1 和物品 2，价值为 22. id w v v&#x2F;w 0 1 6 6 1 2 10 5 2 3 12 4 变种 完全背包: 物品数量为无限个 多重背包: 物品数量有限制 多维费用背包: 物品不仅有重量，还有体积，同时考虑这两种限制 其它: 物品之间相互约束或者依赖 划分数组为和相等的两部分416. Partition Equal Subset Sum (Medium) 12345Input: [1, 5, 11, 5]Output: trueExplanation: The array can be partitioned as [1, 5, 5] and [11]. 可以看成一个背包大小为 sum&#x2F;2 的 0-1 背包问题。 123456789101112131415161718192021222324public boolean canPartition(int[] nums) &#123; int sum = computeArraySum(nums); if (sum % 2 != 0) &#123; return false; &#125; int W = sum / 2; boolean[] dp = new boolean[W + 1]; dp[0] = true; Arrays.sort(nums); for (int num : nums) &#123; // 0-1 背包一个物品只能用一次 for (int i = W; i &gt;= num; i--) &#123; // 从后往前，先计算 dp[i] 再计算 dp[i-num] dp[i] = dp[i] || dp[i - num]; &#125; &#125; return dp[W];&#125;private int computeArraySum(int[] nums) &#123; int sum = 0; for (int num : nums) &#123; sum += num; &#125; return sum;&#125; 改变一组数的正负号使得它们的和为一给定数494. Target Sum (Medium) 1234567891011Input: nums is [1, 1, 1, 1, 1], S is 3.Output: 5Explanation:-1+1+1+1+1 = 3+1-1+1+1+1 = 3+1+1-1+1+1 = 3+1+1+1-1+1 = 3+1+1+1+1-1 = 3There are 5 ways to assign symbols to make the sum of nums be target 3. 该问题可以转换为 Subset Sum 问题，从而使用 0-1 背包的方法来求解。 可以将这组数看成两部分，P 和 N，其中 P 使用正号，N 使用负号，有以下推导: 123 sum(P) - sum(N) = targetsum(P) + sum(N) + sum(P) - sum(N) = target + sum(P) + sum(N) 2 * sum(P) = target + sum(nums) 因此只要找到一个子集，令它们都取正号，并且和等于 (target + sum(nums))&#x2F;2，就证明存在解。 123456789101112131415161718192021222324public int findTargetSumWays(int[] nums, int S) &#123; int sum = computeArraySum(nums); if (sum &lt; S || (sum + S) % 2 == 1) &#123; return 0; &#125; int W = (sum + S) / 2; int[] dp = new int[W + 1]; dp[0] = 1; Arrays.sort(nums); for (int num : nums) &#123; for (int i = W; i &gt;= num; i--) &#123; dp[i] = dp[i] + dp[i - num]; &#125; &#125; return dp[W];&#125;private int computeArraySum(int[] nums) &#123; int sum = 0; for (int num : nums) &#123; sum += num; &#125; return sum;&#125; DFS 解法: 1234567891011public int findTargetSumWays(int[] nums, int S) &#123; return findTargetSumWays(nums, 0, S);&#125;private int findTargetSumWays(int[] nums, int start, int S) &#123; if (start == nums.length) &#123; return S == 0 ? 1 : 0; &#125; return findTargetSumWays(nums, start + 1, S + nums[start]) + findTargetSumWays(nums, start + 1, S - nums[start]);&#125; 字符串按单词列表分割139. Word Break (Medium) 123s = &quot;leetcode&quot;,dict = [&quot;leet&quot;, &quot;code&quot;].Return true because &quot;leetcode&quot; can be segmented as &quot;leet code&quot;. dict 中的单词没有使用次数的限制，因此这是一个完全背包问题。 0-1 背包和完全背包在实现上的不同之处是，0-1 背包对物品的迭代是在最外层，而完全背包对物品的迭代是在最里层。 1234567891011121314public boolean wordBreak(String s, List&lt;String&gt; wordDict) &#123; int n = s.length(); boolean[] dp = new boolean[n + 1]; dp[0] = true; for (int i = 1; i &lt;= n; i++) &#123; for (String word : wordDict) &#123; // 完全一个物品可以使用多次 int len = word.length(); if (len &lt;= i &amp;&amp; word.equals(s.substring(i - len, i))) &#123; dp[i] = dp[i] || dp[i - len]; &#125; &#125; &#125; return dp[n];&#125; 01 字符构成最多的字符串474. Ones and Zeroes (Medium) 1234Input: Array = &#123;&quot;10&quot;, &quot;0001&quot;, &quot;111001&quot;, &quot;1&quot;, &quot;0&quot;&#125;, m = 5, n = 3Output: 4Explanation: There are totally 4 strings can be formed by the using of 5 0s and 3 1s, which are &quot;10&quot;,&quot;0001&quot;,&quot;1&quot;,&quot;0&quot; 这是一个多维费用的 0-1 背包问题，有两个背包大小，0 的数量和 1 的数量。 12345678910111213141516171819202122public int findMaxForm(String[] strs, int m, int n) &#123; if (strs == null || strs.length == 0) &#123; return 0; &#125; int[][] dp = new int[m + 1][n + 1]; for (String s : strs) &#123; // 每个字符串只能用一次 int ones = 0, zeros = 0; for (char c : s.toCharArray()) &#123; if (c == &#x27;0&#x27;) &#123; zeros++; &#125; else &#123; ones++; &#125; &#125; for (int i = m; i &gt;= zeros; i--) &#123; for (int j = n; j &gt;= ones; j--) &#123; dp[i][j] = Math.max(dp[i][j], dp[i - zeros][j - ones] + 1); &#125; &#125; &#125; return dp[m][n];&#125; 找零钱的最少硬币数322. Coin Change (Medium) 1234567Example 1:coins = [1, 2, 5], amount = 11return 3 (11 = 5 + 5 + 1)Example 2:coins = [2], amount = 3return -1. 题目描述: 给一些面额的硬币，要求用这些硬币来组成给定面额的钱数，并且使得硬币数量最少。硬币可以重复使用。 物品: 硬币 物品大小: 面额 物品价值: 数量 因为硬币可以重复使用，因此这是一个完全背包问题。 123456789101112131415public int coinChange(int[] coins, int amount) &#123; if (coins == null || coins.length == 0) &#123; return 0; &#125; int[] minimum = new int[amount + 1]; Arrays.fill(minimum, amount + 1); minimum[0] = 0; Arrays.sort(coins); for (int i = 1; i &lt;= amount; i++) &#123; for (int j = 0; j &lt; coins.length &amp;&amp; coins[j] &lt;= i; j++) &#123; minimum[i] = Math.min(minimum[i], minimum[i - coins[j]] + 1); &#125; &#125; return minimum[amount] &gt; amount ? -1 : minimum[amount];&#125; 组合总和377. Combination Sum IV (Medium) 123456789101112131415nums = [1, 2, 3]target = 4The possible combination ways are:(1, 1, 1, 1)(1, 1, 2)(1, 2, 1)(1, 3)(2, 1, 1)(2, 2)(3, 1)Note that different sequences are counted as different combinations.Therefore the output is 7. 完全背包1234567891011121314public int combinationSum4(int[] nums, int target) &#123; if (nums == null || nums.length == 0) &#123; return 0; &#125; int[] maximum = new int[target + 1]; maximum[0] = 1; Arrays.sort(nums); for (int i = 1; i &lt;= target; i++) &#123; for (int j = 0; j &lt; nums.length &amp;&amp; nums[j] &lt;= i; j++) &#123; maximum[i] += maximum[i - nums[j]]; &#125; &#125; return maximum[target];&#125; 股票交易需要冷却期的股票交易309. Best Time to Buy and Sell Stock with Cooldown(Medium) 题目描述: 交易之后需要有一天的冷却时间。 12345678910111213141516171819public int maxProfit(int[] prices) &#123; if (prices == null || prices.length == 0) &#123; return 0; &#125; int N = prices.length; int[] buy = new int[N]; int[] s1 = new int[N]; int[] sell = new int[N]; int[] s2 = new int[N]; s1[0] = buy[0] = -prices[0]; sell[0] = s2[0] = 0; for (int i = 1; i &lt; N; i++) &#123; buy[i] = s2[i - 1] - prices[i]; s1[i] = Math.max(buy[i - 1], s1[i - 1]); sell[i] = Math.max(buy[i - 1], s1[i - 1]) + prices[i]; s2[i] = Math.max(s2[i - 1], sell[i - 1]); &#125; return Math.max(sell[N - 1], s2[N - 1]);&#125; 需要交易费用的股票交易714. Best Time to Buy and Sell Stock with Transaction Fee (Medium) 12345678Input: prices = [1, 3, 2, 8, 4, 9], fee = 2Output: 8Explanation: The maximum profit can be achieved by:Buying at prices[0] = 1Selling at prices[3] = 8Buying at prices[4] = 4Selling at prices[5] = 9The total profit is ((8 - 1) - 2) + ((9 - 4) - 2) = 8. 题目描述: 每交易一次，都要支付一定的费用。 12345678910111213141516public int maxProfit(int[] prices, int fee) &#123; int N = prices.length; int[] buy = new int[N]; int[] s1 = new int[N]; int[] sell = new int[N]; int[] s2 = new int[N]; s1[0] = buy[0] = -prices[0]; sell[0] = s2[0] = 0; for (int i = 1; i &lt; N; i++) &#123; buy[i] = Math.max(sell[i - 1], s2[i - 1]) - prices[i]; s1[i] = Math.max(buy[i - 1], s1[i - 1]); sell[i] = Math.max(buy[i - 1], s1[i - 1]) - fee + prices[i]; s2[i] = Math.max(s2[i - 1], sell[i - 1]); &#125; return Math.max(sell[N - 1], s2[N - 1]);&#125; 买入和售出股票最大的收益121. Best Time to Buy and Sell Stock (Easy) 题目描述: 只进行一次交易。 只要记录前面的最小价格，将这个最小价格作为买入价格，然后将当前的价格作为售出价格，查看当前收益是不是最大收益。 1234567891011public int maxProfit(int[] prices) &#123; int n = prices.length; if (n == 0) return 0; int soFarMin = prices[0]; int max = 0; for (int i = 1; i &lt; n; i++) &#123; if (soFarMin &gt; prices[i]) soFarMin = prices[i]; else max = Math.max(max, prices[i] - soFarMin); &#125; return max;&#125; 只能进行两次的股票交易123. Best Time to Buy and Sell Stock III (Hard) 12345678910111213141516171819public int maxProfit(int[] prices) &#123; int firstBuy = Integer.MIN_VALUE, firstSell = 0; int secondBuy = Integer.MIN_VALUE, secondSell = 0; for (int curPrice : prices) &#123; if (firstBuy &lt; -curPrice) &#123; firstBuy = -curPrice; &#125; if (firstSell &lt; firstBuy + curPrice) &#123; firstSell = firstBuy + curPrice; &#125; if (secondBuy &lt; firstSell - curPrice) &#123; secondBuy = firstSell - curPrice; &#125; if (secondSell &lt; secondBuy + curPrice) &#123; secondSell = secondBuy + curPrice; &#125; &#125; return secondSell;&#125; 只能进行 k 次的股票交易188. Best Time to Buy and Sell Stock IV (Hard) 123456789101112131415161718192021public int maxProfit(int k, int[] prices) &#123; int n = prices.length; if (k &gt;= n / 2) &#123; // 这种情况下该问题退化为普通的股票交易问题 int maxProfit = 0; for (int i = 1; i &lt; n; i++) &#123; if (prices[i] &gt; prices[i - 1]) &#123; maxProfit += prices[i] - prices[i - 1]; &#125; &#125; return maxProfit; &#125; int[][] maxProfit = new int[k + 1][n]; for (int i = 1; i &lt;= k; i++) &#123; int localMax = maxProfit[i - 1][0] - prices[0]; for (int j = 1; j &lt; n; j++) &#123; maxProfit[i][j] = Math.max(maxProfit[i][j - 1], prices[j] + localMax); localMax = Math.max(localMax, maxProfit[i - 1][j] - prices[j]); &#125; &#125; return maxProfit[k][n - 1];&#125; 字符串编辑删除两个字符串的字符使它们相等583. Delete Operation for Two Strings (Medium) 123Input: &quot;sea&quot;, &quot;eat&quot;Output: 2Explanation: You need one step to make &quot;sea&quot; to &quot;ea&quot; and another step to make &quot;eat&quot; to &quot;ea&quot;. 可以转换为求两个字符串的最长公共子序列问题。 1234567891011121314public int minDistance(String word1, String word2) &#123; int m = word1.length(), n = word2.length(); int[][] dp = new int[m + 1][n + 1]; for (int i = 1; i &lt;= m; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; if (word1.charAt(i - 1) == word2.charAt(j - 1)) &#123; dp[i][j] = dp[i - 1][j - 1] + 1; &#125; else &#123; dp[i][j] = Math.max(dp[i][j - 1], dp[i - 1][j]); &#125; &#125; &#125; return m + n - 2 * dp[m][n];&#125; 编辑距离72. Edit Distance (Hard) 123456789101112131415161718Example 1:Input: word1 = &quot;horse&quot;, word2 = &quot;ros&quot;Output: 3Explanation:horse -&gt; rorse (replace &#x27;h&#x27; with &#x27;r&#x27;)rorse -&gt; rose (remove &#x27;r&#x27;)rose -&gt; ros (remove &#x27;e&#x27;)Example 2:Input: word1 = &quot;intention&quot;, word2 = &quot;execution&quot;Output: 5Explanation:intention -&gt; inention (remove &#x27;t&#x27;)inention -&gt; enention (replace &#x27;i&#x27; with &#x27;e&#x27;)enention -&gt; exention (replace &#x27;n&#x27; with &#x27;x&#x27;)exention -&gt; exection (replace &#x27;n&#x27; with &#x27;c&#x27;)exection -&gt; execution (insert &#x27;u&#x27;) 题目描述: 修改一个字符串成为另一个字符串，使得修改次数最少。一次修改操作包括: 插入一个字符、删除一个字符、替换一个字符。 1234567891011121314151617181920212223public int minDistance(String word1, String word2) &#123; if (word1 == null || word2 == null) &#123; return 0; &#125; int m = word1.length(), n = word2.length(); int[][] dp = new int[m + 1][n + 1]; for (int i = 1; i &lt;= m; i++) &#123; dp[i][0] = i; &#125; for (int i = 1; i &lt;= n; i++) &#123; dp[0][i] = i; &#125; for (int i = 1; i &lt;= m; i++) &#123; for (int j = 1; j &lt;= n; j++) &#123; if (word1.charAt(i - 1) == word2.charAt(j - 1)) &#123; dp[i][j] = dp[i - 1][j - 1]; &#125; else &#123; dp[i][j] = Math.min(dp[i - 1][j - 1], Math.min(dp[i][j - 1], dp[i - 1][j])) + 1; &#125; &#125; &#125; return dp[m][n];&#125; 复制粘贴字符650. 2 Keys Keyboard (Medium) 题目描述: 最开始只有一个字符 A，问需要多少次操作能够得到 n 个字符 A，每次操作可以复制当前所有的字符，或者粘贴。 1234567Input: 3Output: 3Explanation:Intitally, we have one character &#x27;A&#x27;.In step 1, we use Copy All operation.In step 2, we use Paste operation to get &#x27;AA&#x27;.In step 3, we use Paste operation to get &#x27;AAA&#x27;. 1234567public int minSteps(int n) &#123; if (n == 1) return 0; for (int i = 2; i &lt;= Math.sqrt(n); i++) &#123; if (n % i == 0) return i + minSteps(n / i); &#125; return n;&#125; 1234567891011121314public int minSteps(int n) &#123; int[] dp = new int[n + 1]; int h = (int) Math.sqrt(n); for (int i = 2; i &lt;= n; i++) &#123; dp[i] = i; for (int j = 2; j &lt;= h; j++) &#123; if (i % j == 0) &#123; dp[i] = dp[j] + dp[i / j]; break; &#125; &#125; &#125; return dp[n];&#125;","tags":["算法","算法思想","动态规划"],"categories":["算法","算法思想"]},{"title":"1.算法思想知识体系详解","path":"/2023/12/27/1-算法思想知识体系详解/","content":"我们通过理解算法背后常用的算法思想，进行归纳总结，并通过leetcode练习来辅助理解和提升. 算法思想详解相关文章 算法思想 - 分治算法 分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解 算法思想 - 动态规划算法 动态规划算法通常用于求解具有某种最优性质的问题。在这类问题中，可能会有许多可行解。每一个解都对应于一个值，我们希望找到具有最优值的解。动态规划算法与分治法类似，其基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解 算法思想 - 贪心算法 本文主要介绍算法中贪心算法的思想: 保证每次操作都是局部最优的，并且最后得到的结果是全局最优的 算法思想 - 二分法 本文主要介绍算法思想中分治算法重要的二分法，比如二分查找；二分查找也称折半查找（Binary Search），它是一种效率较高的查找方法。但是，折半查找要求线性表必须采用顺序存储结构，而且表中元素按关键字有序排列。 算法思想 - 搜索算法 本文主要介绍算法中搜索算法的思想，主要包含BFS，DFS 算法思想 - 回溯算法 Backtracking(回溯)属于 DFS, 本文主要介绍算法中Backtracking算法的思想。回溯算法实际上一个类似枚举的搜索尝试过程，主要是在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法","tags":["算法","算法思想"],"categories":["算法","算法思想"]},{"title":"10.排序 - 基数排序(Radix Sort)","path":"/2023/12/27/10-排序-基数排序-Radix-Sort/","content":"基数排序(Radix Sort)是桶排序的扩展. 基数排序介绍它的基本思想是: 将整数按位数切割成不同的数字，然后按每个位数分别比较。 具体做法是: 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 基数排序实现通过基数排序对数组{53, 3, 542, 748, 14, 214, 154, 63, 616}，它的示意图如下: 在上图中，首先将所有待比较树脂统一为统一位数长度，接着从最低位开始，依次进行排序。 按照个位数进行排序。 按照十位数进行排序。 按照百位数进行排序。 排序后，数列就变成了一个有序序列。 下面简单介绍一下对数组{53, 3, 542, 748, 14, 214, 154, 63, 616}按个位数进行排序的流程。 个位的数值范围是[0,10)。因此，参见桶数组buckets[]，将数组按照个位数值添加到桶中。 接着是根据桶数组buckets[]来进行排序。假设将排序后的数组存在output[]中；找出output[]和buckets[]之间的联系就可以对数据进行排序了。 基数排序复杂度和稳定性基数排序复杂度时间复杂度：O(n * k) 空间复杂度：O(n + k) 基数排序稳定性稳定性：稳定，外排序 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899/** * 基数排序: Java * * @author skywang * @date 2014/03/15 */public class RadixSort &#123; /* * 获取数组a中最大值 * * 参数说明: * a -- 数组 * n -- 数组长度 */ private static int getMax(int[] a) &#123; int max; max = a[0]; for (int i = 1; i &lt; a.length; i++) if (a[i] &gt; max) max = a[i]; return max; &#125; /* * 对数组按照&quot;某个位数&quot;进行排序(桶排序) * * 参数说明: * a -- 数组 * exp -- 指数。对数组a按照该指数进行排序。 * * 例如，对于数组a=&#123;50, 3, 542, 745, 2014, 154, 63, 616&#125;； * (01) 当exp=1表示按照&quot;个位&quot;对数组a进行排序 * (02) 当exp=10表示按照&quot;十位&quot;对数组a进行排序 * (03) 当exp=100表示按照&quot;百位&quot;对数组a进行排序 * ... */ private static void countSort(int[] a, int exp) &#123; //int output[a.length]; // 存储&quot;被排序数据&quot;的临时数组 int[] output = new int[a.length]; // 存储&quot;被排序数据&quot;的临时数组 int[] buckets = new int[10]; // 将数据出现的次数存储在buckets[]中 for (int i = 0; i &lt; a.length; i++) buckets[ (a[i]/exp)%10 ]++; // 更改buckets[i]。目的是让更改后的buckets[i]的值，是该数据在output[]中的位置。 for (int i = 1; i &lt; 10; i++) buckets[i] += buckets[i - 1]; // 将数据存储到临时数组output[]中 for (int i = a.length - 1; i &gt;= 0; i--) &#123; output[buckets[ (a[i]/exp)%10 ] - 1] = a[i]; buckets[ (a[i]/exp)%10 ]--; &#125; // 将排序好的数据赋值给a[] for (int i = 0; i &lt; a.length; i++) a[i] = output[i]; output = null; buckets = null; &#125; /* * 基数排序 * * 参数说明: * a -- 数组 */ public static void radixSort(int[] a) &#123; int exp; // 指数。当对数组按各位进行排序时，exp=1；按十位进行排序时，exp=10；... int max = getMax(a); // 数组a中的最大值 // 从个位开始，对数组a按&quot;指数&quot;进行排序 for (exp = 1; max/exp &gt; 0; exp *= 10) countSort(a, exp); &#125; public static void main(String[] args) &#123; int i; int a[] = &#123;53, 3, 542, 748, 14, 214, 154, 63, 616&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); radixSort(a); // 基数排序 System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3603669.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","基数排序","Radix Sort"],"categories":["算法","排序算法"]},{"title":"9.排序 - 桶排序(Bucket Sort)","path":"/2023/12/27/9-排序-桶排序-Bucket-Sort/","content":"桶排序(Bucket Sort)的原理很简单，将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。 桶排序介绍假设待排序的数组a中共有N个整数，并且已知数组a中数据的范围[0, MAX)。在桶排序时，创建容量为MAX的桶数组r，并将桶数组元素都初始化为0；将容量为MAX的桶数组中的每一个单元都看作一个”桶”。 在排序时，逐个遍历数组a，将数组a的值，作为”桶数组r”的下标。当a中数据被读取时，就将桶的值加1。例如，读取到数组a[3]&#x3D;5，则将r[5]的值+1。 桶排序实现假设a&#x3D;{8,2,3,4,3,6,6,3,9}, max&#x3D;10。此时，将数组a的所有数据都放到需要为0-9的桶中。如下图: 在将数据放到桶中之后，再通过一定的算法，将桶中的数据提出出来并转换成有序数组。就得到我们想要的结果了。 桶排序复杂度和稳定性桶排序复杂度 平均时间复杂度: O(n + k) 最佳时间复杂度: O(n + k) 最差时间复杂度: O(n ^ 2) 空间复杂度: O(n * k) 桶排序最好情况下使用线性时间O(n)，桶排序的时间复杂度，取决与对各个桶之间数据进行排序的时间复杂度，因为其它部分的时间复杂度都为O(n)。很显然，桶划分的越小，各个桶之间的数据越少，排序所用的时间也会越少。但相应的空间消耗就会增大。 桶排序稳定性稳定性: 稳定 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 桶排序: Java * * @author skywang * @date 2014/03/13 */public class BucketSort &#123; /* * 桶排序 * * 参数说明: * a -- 待排序数组 * max -- 数组a中最大值的范围 */ public static void bucketSort(int[] a, int max) &#123; int[] buckets; if (a==null || max&lt;1) return ; // 创建一个容量为max的数组buckets，并且将buckets中的所有数据都初始化为0。 buckets = new int[max]; // 1. 计数 for(int i = 0; i &lt; a.length; i++) buckets[a[i]]++; // 2. 排序 for (int i = 0, j = 0; i &lt; max; i++) &#123; while( (buckets[i]--) &gt;0 ) &#123; a[j++] = i; &#125; &#125; buckets = null; &#125; public static void main(String[] args) &#123; int i; int a[] = &#123;8,2,3,4,3,6,6,3,9&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); bucketSort(a, 10); // 桶排序 System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3602737.html, 在此基础上做了内容的增改。 其它参考： https://www.cnblogs.com/bqwzx/p/11029264.html https://www.cnblogs.com/hokky/p/8529042.html","tags":["算法","排序算法","桶排序","Bucket Sort"],"categories":["算法","排序算法"]},{"title":"8.排序 - 归并排序(Merge Sort)","path":"/2023/12/27/8-排序-归并排序-Merge-Sort/","content":"将两个的有序数列合并成一个有序数列，我们称之为”归并”。归并排序(Merge Sort)就是利用归并思想对数列进行排序。 归并排序介绍根据具体的实现，归并排序包括”从上往下”和”从下往上”2种方式。 从下往上的归并排序将待排序的数列分成若干个长度为1的子数列，然后将这些数列两两合并；得到若干个长度为2的有序数列，再将这些数列两两合并；得到若干个长度为4的有序数列，再将它们两两合并；直接合并成一个数列为止。这样就得到了我们想要的排序结果。(参考下面的图片) 从上往下的归并排序它与”从下往上”在排序上是反方向的。它基本包括3步: 分解 – 将当前区间一分为二，即求分裂点 mid &#x3D; (low + high)&#x2F;2; 求解 – 递归地对两个子区间a[low…mid] 和 a[mid+1…high]进行归并排序。递归的终结条件是子区间长度为1。 合并 – 将已排序的两个子区间a[low…mid]和 a[mid+1…high]归并为一个有序的区间a[low…high]。 归并排序实现从上往下的归并排序从上往下的归并排序采用了递归的方式实现。它的原理非常简单，如下图: 通过”从上往下的归并排序”来对数组{80,30,60,40,20,10,50,70}进行排序时: 将数组{80,30,60,40,20,10,50,70}看作由两个有序的子数组{80,30,60,40}和{20,10,50,70}组成。对两个有序子树组进行排序即可。 将子数组{80,30,60,40}看作由两个有序的子数组{80,30}和{60,40}组成。 将子数组{20,10,50,70}看作由两个有序的子数组{20,10}和{50,70}组成。 将子数组{80,30}看作由两个有序的子数组{80}和{30}组成。 将子数组{60,40}看作由两个有序的子数组{60}和{40}组成。 将子数组{20,10}看作由两个有序的子数组{20}和{10}组成。 将子数组{50,70}看作由两个有序的子数组{50}和{70}组成。 从下往上的归并排序从下往上的归并排序的思想正好与”从下往上的归并排序”相反。如下图: 通过”从下往上的归并排序”来对数组{80,30,60,40,20,10,50,70}进行排序时: 将数组{80,30,60,40,20,10,50,70}看作由8个有序的子数组{80},{30},{60},{40},{20},{10},{50}和{70}组成。 将这8个有序的子数列两两合并。得到4个有序的子树列{30,80},{40,60},{10,20}和{50,70}。 将这4个有序的子数列两两合并。得到2个有序的子树列{30,40,60,80}和{10,20,50,70}。 将这2个有序的子数列两两合并。得到1个有序的子树列{10,20,30,40,50,60,70,80}。 归并排序的时间复杂度和稳定性归并排序时间复杂度归并排序的时间复杂度是O(N*lgN)。 假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢? 归并排序的形式就是一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的可以得出它的时间复杂度是O(N*lgN)。 归并排序稳定性归并排序是稳定的算法，它满足稳定算法的定义。 算法稳定性 – 假设在数列中存在a[i]&#x3D;a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121/** * 归并排序: Java * * @author skywang * @date 2014/03/12 */public class MergeSort &#123; /* * 将一个数组中的两个相邻有序区间合并成一个 * * 参数说明: * a -- 包含两个有序区间的数组 * start -- 第1个有序区间的起始地址。 * mid -- 第1个有序区间的结束地址。也是第2个有序区间的起始地址。 * end -- 第2个有序区间的结束地址。 */ public static void merge(int[] a, int start, int mid, int end) &#123; int[] tmp = new int[end-start+1]; // tmp是汇总2个有序区的临时区域 int i = start; // 第1个有序区的索引 int j = mid + 1; // 第2个有序区的索引 int k = 0; // 临时区域的索引 while(i &lt;= mid &amp;&amp; j &lt;= end) &#123; if (a[i] &lt;= a[j]) tmp[k++] = a[i++]; else tmp[k++] = a[j++]; &#125; while(i &lt;= mid) tmp[k++] = a[i++]; while(j &lt;= end) tmp[k++] = a[j++]; // 将排序后的元素，全部都整合到数组a中。 for (i = 0; i &lt; k; i++) a[start + i] = tmp[i]; tmp=null; &#125; /* * 归并排序(从上往下) * * 参数说明: * a -- 待排序的数组 * start -- 数组的起始地址 * endi -- 数组的结束地址 */ public static void mergeSortUp2Down(int[] a, int start, int end) &#123; if(a==null || start &gt;= end) return ; int mid = (end + start)/2; mergeSortUp2Down(a, start, mid); // 递归排序a[start...mid] mergeSortUp2Down(a, mid+1, end); // 递归排序a[mid+1...end] // a[start...mid] 和 a[mid...end]是两个有序空间， // 将它们排序成一个有序空间a[start...end] merge(a, start, mid, end); &#125; /* * 对数组a做若干次合并: 数组a的总长度为len，将它分为若干个长度为gap的子数组； * 将&quot;每2个相邻的子数组&quot; 进行合并排序。 * * 参数说明: * a -- 待排序的数组 * len -- 数组的长度 * gap -- 子数组的长度 */ public static void mergeGroups(int[] a, int len, int gap) &#123; int i; int twolen = 2 * gap; // 两个相邻的子数组的长度 // 将&quot;每2个相邻的子数组&quot; 进行合并排序。 for(i = 0; i+2*gap-1 &lt; len; i+=(2*gap)) merge(a, i, i+gap-1, i+2*gap-1); // 若 i+gap-1 &lt; len-1，则剩余一个子数组没有配对。 // 将该子数组合并到已排序的数组中。 if ( i+gap-1 &lt; len-1) merge(a, i, i + gap - 1, len - 1); &#125; /* * 归并排序(从下往上) * * 参数说明: * a -- 待排序的数组 */ public static void mergeSortDown2Up(int[] a) &#123; if (a==null) return ; for(int n = 1; n &lt; a.length; n*=2) mergeGroups(a, a.length, n); &#125; public static void main(String[] args) &#123; int i; int a[] = &#123;80,30,60,40,20,10,50,70&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); mergeSortUp2Down(a, 0, a.length-1); // 归并排序(从上往下) //mergeSortDown2Up(a); // 归并排序(从下往上) System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3602369.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","归并排序","Merge Sort"],"categories":["算法","排序算法"]},{"title":"7.排序 - 堆排序(Heap Sort)","path":"/2023/12/27/7-排序-堆排序-Heap-Sort/","content":"堆排序是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 堆排序介绍学习堆排序之前，有必要了解堆！若读者不熟悉堆，建议先了解堆(建议可以通过二叉堆，左倾堆，斜堆，二项堆或斐波那契堆等文章进行了解)，然后再来学习本章。 我们知道，堆分为”最大堆”和”最小堆”。最大堆通常被用来进行”升序”排序，而最小堆通常被用来进行”降序”排序。 鉴于最大堆和最小堆是对称关系，理解其中一种即可。本文将对最大堆实现的升序排序进行详细说明。 最大堆进行升序排序的基本思想: ① 初始化堆: 将数列a[1…n]构造成最大堆。 ② 交换数据: 将a[1]和a[n]交换，使a[n]是a[1…n]中的最大值；然后将a[1…n-1]重新调整为最大堆。 接着，将a[1]和a[n-1]交换，使a[n-1]是a[1…n-1]中的最大值；然后将a[1…n-2]重新调整为最大值。 依次类推，直到整个数列都是有序的。 下面，通过图文来解析堆排序的实现过程。注意实现中用到了”数组实现的二叉堆的性质”。 在第一个元素的索引为 0 的情形中: 性质一: 索引为i的左孩子的索引是 (2*i+1); 性质二: 索引为i的右孩子的索引是 (2*i+2); 性质三: 索引为i的父结点的索引是 floor((i-1)&#x2F;2); 例如，对于最大堆{110,100,90,40,80,20,60,10,30,50,70}而言: 索引为0的左孩子的所有是1；索引为0的右孩子是2；索引为8的父节点是3。 堆排序实现下面演示heap_sort_asc(a, n)对a&#x3D;{20,30,90,40,70,110,60,10,100,50,80}, n&#x3D;11进行堆排序过程。下面是数组a对应的初始化结构: 初始化堆在堆排序算法中，首先要将待排序的数组转化成二叉堆。 下面演示将数组{20,30,90,40,70,110,60,10,100,50,80}转换为最大堆{110,100,90,40,80,20,60,10,30,50,70}的步骤。 1.1 i&#x3D;11&#x2F;2-1，即i&#x3D;4 上面是maxheap_down(a, 4, 9)调整过程。maxheap_down(a, 4, 9)的作用是将a[4…9]进行下调；a[4]的左孩子是a[9]，右孩子是a[10]。调整时，选择左右孩子中较大的一个(即a[10])和a[4]交换。 1.2 i&#x3D;3 上面是maxheap_down(a, 3, 9)调整过程。maxheap_down(a, 3, 9)的作用是将a[3…9]进行下调；a[3]的左孩子是a[7]，右孩子是a[8]。调整时，选择左右孩子中较大的一个(即a[8])和a[4]交换。 1.3 i&#x3D;2 上面是maxheap_down(a, 2, 9)调整过程。maxheap_down(a, 2, 9)的作用是将a[2…9]进行下调；a[2]的左孩子是a[5]，右孩子是a[6]。调整时，选择左右孩子中较大的一个(即a[5])和a[2]交换。 1.4 i&#x3D;1 上面是maxheap_down(a, 1, 9)调整过程。maxheap_down(a, 1, 9)的作用是将a[1…9]进行下调；a[1]的左孩子是a[3]，右孩子是a[4]。调整时，选择左右孩子中较大的一个(即a[3])和a[1]交换。交换之后，a[3]为30，它比它的右孩子a[8]要大，接着，再将它们交换。 1.5 i&#x3D;0 上面是maxheap_down(a, 0, 9)调整过程。maxheap_down(a, 0, 9)的作用是将a[0…9]进行下调；a[0]的左孩子是a[1]，右孩子是a[2]。调整时，选择左右孩子中较大的一个(即a[2])和a[0]交换。交换之后，a[2]为20，它比它的左右孩子要大，选择较大的孩子(即左孩子)和a[2]交换。 调整完毕，就得到了最大堆。此时，数组{20,30,90,40,70,110,60,10,100,50,80}也就变成了{110,100,90,40,80,20,60,10,30,50,70}。 交换数据在将数组转换成最大堆之后，接着要进行交换数据，从而使数组成为一个真正的有序数组。 交换数据部分相对比较简单，下面仅仅给出将最大值放在数组末尾的示意图。 上面是当n&#x3D;10时，交换数据的示意图。 当n&#x3D;10时，首先交换a[0]和a[10]，使得a[10]是a[0…10]之间的最大值；然后，调整a[0…9]使它称为最大堆。交换之后: a[10]是有序的！ 当n&#x3D;9时， 首先交换a[0]和a[9]，使得a[9]是a[0…9]之间的最大值；然后，调整a[0…8]使它称为最大堆。交换之后: a[9…10]是有序的！ … 依此类推，直到a[0…10]是有序的。 堆排序复杂度和稳定性堆排序时间复杂度堆排序的时间复杂度是O(N*lgN)。 假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢? 堆排序是采用的二叉堆进行排序的，二叉堆就是一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的定义，它的深度至少是lg(N+1)。最多是多少呢? 由于二叉堆是完全二叉树，因此，它的深度最多也不会超过lg(2N)。因此，遍历一趟的时间复杂度是O(N)，而遍历次数介于lg(N+1)和lg(2N)之间；因此得出它的时间复杂度是O(N*lgN)。 堆排序稳定性堆排序是不稳定的算法，它不满足稳定算法的定义。它在交换数据的时候，是比较父结点和子节点之间的数据，所以，即便是存在两个数值相等的兄弟节点，它们的相对顺序在排序也可能发生变化。 算法稳定性 – 假设在数列中存在a[i]&#x3D;a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137/** * 堆排序: Java * * @author skywang * @date 2014/03/11 */public class HeapSort &#123; /* * (最大)堆的向下调整算法 * * 注: 数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。 * 其中，N为数组下标索引值，如数组中第1个数对应的N为0。 * * 参数说明: * a -- 待排序的数组 * start -- 被下调节点的起始位置(一般为0，表示从第1个开始) * end -- 截至范围(一般为数组中最后一个元素的索引) */ public static void maxHeapDown(int[] a, int start, int end) &#123; int c = start; // 当前(current)节点的位置 int l = 2*c + 1; // 左(left)孩子的位置 int tmp = a[c]; // 当前(current)节点的大小 for (; l &lt;= end; c=l,l=2*l+1) &#123; // &quot;l&quot;是左孩子，&quot;l+1&quot;是右孩子 if ( l &lt; end &amp;&amp; a[l] &lt; a[l+1]) l++; // 左右两孩子中选择较大者，即m_heap[l+1] if (tmp &gt;= a[l]) break; // 调整结束 else &#123; // 交换值 a[c] = a[l]; a[l]= tmp; &#125; &#125; &#125; /* * 堆排序(从小到大) * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void heapSortAsc(int[] a, int n) &#123; int i,tmp; // 从(n/2-1) --&gt; 0逐次遍历。遍历之后，得到的数组实际上是一个(最大)二叉堆。 for (i = n / 2 - 1; i &gt;= 0; i--) maxHeapDown(a, i, n-1); // 从最后一个元素开始对序列进行调整，不断的缩小调整的范围直到第一个元素 for (i = n - 1; i &gt; 0; i--) &#123; // 交换a[0]和a[i]。交换后，a[i]是a[0...i]中最大的。 tmp = a[0]; a[0] = a[i]; a[i] = tmp; // 调整a[0...i-1]，使得a[0...i-1]仍然是一个最大堆。 // 即，保证a[i-1]是a[0...i-1]中的最大值。 maxHeapDown(a, 0, i-1); &#125; &#125; /* * (最小)堆的向下调整算法 * * 注: 数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。 * 其中，N为数组下标索引值，如数组中第1个数对应的N为0。 * * 参数说明: * a -- 待排序的数组 * start -- 被下调节点的起始位置(一般为0，表示从第1个开始) * end -- 截至范围(一般为数组中最后一个元素的索引) */ public static void minHeapDown(int[] a, int start, int end) &#123; int c = start; // 当前(current)节点的位置 int l = 2*c + 1; // 左(left)孩子的位置 int tmp = a[c]; // 当前(current)节点的大小 for (; l &lt;= end; c=l,l=2*l+1) &#123; // &quot;l&quot;是左孩子，&quot;l+1&quot;是右孩子 if ( l &lt; end &amp;&amp; a[l] &gt; a[l+1]) l++; // 左右两孩子中选择较小者 if (tmp &lt;= a[l]) break; // 调整结束 else &#123; // 交换值 a[c] = a[l]; a[l]= tmp; &#125; &#125; &#125; /* * 堆排序(从大到小) * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void heapSortDesc(int[] a, int n) &#123; int i,tmp; // 从(n/2-1) --&gt; 0逐次遍历每。遍历之后，得到的数组实际上是一个最小堆。 for (i = n / 2 - 1; i &gt;= 0; i--) minHeapDown(a, i, n-1); // 从最后一个元素开始对序列进行调整，不断的缩小调整的范围直到第一个元素 for (i = n - 1; i &gt; 0; i--) &#123; // 交换a[0]和a[i]。交换后，a[i]是a[0...i]中最小的。 tmp = a[0]; a[0] = a[i]; a[i] = tmp; // 调整a[0...i-1]，使得a[0...i-1]仍然是一个最小堆。 // 即，保证a[i-1]是a[0...i-1]中的最小值。 minHeapDown(a, 0, i-1); &#125; &#125; public static void main(String[] args) &#123; int i; int a[] = &#123;20,30,90,40,70,110,60,10,100,50,80&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); heapSortAsc(a, a.length); // 升序排列 //heapSortDesc(a, a.length); // 降序排列 System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3602162.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","堆排序","Heap Sort"],"categories":["算法","排序算法"]},{"title":"6.排序 - 选择排序(Selection sort)","path":"/2023/12/27/6-排序-选择排序-Selection-sort/","content":"选择排序(Selection sort)是一种简单直观的排序算法。 选择排序介绍它的基本思想是: 首先在未排序的数列中找到最小(or最大)元素，然后将其存放到数列的起始位置；接着，再从剩余未排序的元素中继续寻找最小(or最大)元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 选择排序实现下面以数列{20,40,30,10,60,50}为例，演示它的选择排序过程(如下图)。 排序流程 第1趟: i&#x3D;0。找出a[1…5]中的最小值a[3]&#x3D;10，然后将a[0]和a[3]互换。 数列变化: 20,40,30,10,60,50 – &gt; 10,40,30,20,60,50 第2趟: i&#x3D;1。找出a[2…5]中的最小值a[3]&#x3D;20，然后将a[1]和a[3]互换。 数列变化: 10,40,30,20,60,50 – &gt; 10,20,30,40,60,50 第3趟: i&#x3D;2。找出a[3…5]中的最小值，由于该最小值大于a[2]，该趟不做任何处理。 第4趟: i&#x3D;3。找出a[4…5]中的最小值，由于该最小值大于a[3]，该趟不做任何处理。 第5趟: i&#x3D;4。交换a[4]和a[5]的数据。 数列变化: 10,20,30,40,60,50 – &gt; 10,20,30,40,50,60 选择排序的时间复杂度和稳定性选择排序时间复杂度选择排序的时间复杂度是O(N2)。 假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢? N-1！因此，选择排序的时间复杂度是O(N2)。 选择排序稳定性 选择排序的稳定性是有一些争议的，不过一般提到排序算法，往往默认是数组实现，所以通常认为选择排序是不稳定的。知乎上有个讨论可以看下。 回顾：什么是排序算法的稳定性？ 假定在待排序的记录序列中，存在多个具有相同的关键字的记录，若经过排序，这些记录的相对次序保持不变，即在原序列中，r[i]&#x3D;r[j]，且r[i]在r[j]之前，而在排序后的序列中，r[i]仍在r[j]之前，则称这种排序算法是稳定的；否则称为不稳定的。 数组实现和链表实现的差异 用数组实现的选择排序是不稳定的，用链表实现的选择排序是稳定的。 不过，一般提到排序算法时，大家往往会默认是数组实现，所以选择排序是不稳定的。 此外，排序算法的稳定性也是可以改变的，只是需要额外的时间和空间 有很多办法可以将任意排序算法变成稳定的，但是，往往需要额外的时间或者空间；而我们默认情况谈算法的稳定性是不考虑这种实现的。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 选择排序: Java * * @author skywang * @date 2014/03/11 */public class SelectSort &#123; /* * 选择排序 * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void selectSort(int[] a, int n) &#123; int i; // 有序区的末尾位置 int j; // 无序区的起始位置 int min; // 无序区中最小元素位置 for(i=0; i&lt;n; i++) &#123; min=i; // 找出&quot;a[i+1] ... a[n]&quot;之间的最小元素，并赋值给min。 for(j=i+1; j&lt;n; j++) &#123; if(a[j] &lt; a[min]) min=j; &#125; // 若min!=i，则交换 a[i] 和 a[min]。 // 交换之后，保证了a[0] ... a[i] 之间的元素是有序的。 if(min != i) &#123; int tmp = a[i]; a[i] = a[min]; a[min] = tmp; &#125; &#125; &#125; public static void main(String[] args) &#123; int i; int[] a = &#123;20,40,30,10,60,50&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); selectSort(a, a.length); System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3597641.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","选择排序","Selection sort"],"categories":["算法","排序算法"]},{"title":"5.排序 - 希尔排序(Shell Sort)","path":"/2023/12/27/5-排序-希尔排序-Shell-Sort/","content":"希尔排序(Shell Sort)是插入排序的一种，它是针对直接插入排序算法的改进。 希尔排序介绍希尔排序实质上是一种分组插入方法。它的基本思想是: 对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；然后，对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap&#x3D;1时，整个数列就是有序的。 希尔排序实现下面以数列{80,30,60,40,20,10,50,70}为例，演示它的希尔排序过程。 第1趟: (gap&#x3D;4) 当gap&#x3D;4时,意味着将数列分为4个组: {80,20},{30,10},{60,50},{40,70}。 对应数列: {80,30,60,40,20,10,50,70} 对这4个组分别进行排序，排序结果: {20,80},{10,30},{50,60},{40,70}。 对应数列: 第2趟: (gap&#x3D;2) 当gap&#x3D;2时,意味着将数列分为2个组: {20,50,80,60}, {10,40,30,70}。 对应数列: {20,10,50,40,80,30,60,70} 注意: {20,50,80,60}实际上有两个有序的数列{20,80}和{50,60}组成。 {10,40,30,70}实际上有两个有序的数列{10,30}和{40,70}组成。 对这2个组分别进行排序，排序结果: {20,50,60,80}, {10,30,40,70}。 对应数列: 第3趟: (gap&#x3D;1) 当gap&#x3D;1时,意味着将数列分为1个组: {20,10,50,30,60,40,80,70} 注意: {20,10,50,30,60,40,80,70}实际上有两个有序的数列{20,50,60,80}和{10,30,40,70}组成。 对这1个组分别进行排序，排序结果: 希尔排序的时间复杂度和稳定性希尔排序时间复杂度希尔排序的时间复杂度与增量(即，步长gap)的选取有关。例如，当增量为1时，希尔排序退化成了直接插入排序，此时的时间复杂度为O(N²)，而Hibbard增量的希尔排序的时间复杂度为O(N3&#x2F;2)。 希尔排序稳定性希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比O(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 算法稳定性 – 假设在数列中存在a[i]&#x3D;a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/** * 希尔排序: Java * * @author skywang * @date 2014/03/11 */public class ShellSort &#123; /** * 希尔排序 * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void shellSort1(int[] a, int n) &#123; // gap为步长，每次减为原来的一半。 for (int gap = n / 2; gap &gt; 0; gap /= 2) &#123; // 共gap个组，对每一组都执行直接插入排序 for (int i = 0 ;i &lt; gap; i++) &#123; for (int j = i + gap; j &lt; n; j += gap) &#123; // 如果a[j] &lt; a[j-gap]，则寻找a[j]位置，并将后面数据的位置都后移。 if (a[j] &lt; a[j - gap]) &#123; int tmp = a[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; a[k] &gt; tmp) &#123; a[k + gap] = a[k]; k -= gap; &#125; a[k + gap] = tmp; &#125; &#125; &#125; &#125; &#125; /** * 对希尔排序中的单个组进行排序 * * 参数说明: * a -- 待排序的数组 * n -- 数组总的长度 * i -- 组的起始位置 * gap -- 组的步长 * * 组是&quot;从i开始，将相隔gap长度的数都取出&quot;所组成的！ */ public static void groupSort(int[] a, int n, int i,int gap) &#123; for (int j = i + gap; j &lt; n; j += gap) &#123; // 如果a[j] &lt; a[j-gap]，则寻找a[j]位置，并将后面数据的位置都后移。 if (a[j] &lt; a[j - gap]) &#123; int tmp = a[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; a[k] &gt; tmp) &#123; a[k + gap] = a[k]; k -= gap; &#125; a[k + gap] = tmp; &#125; &#125; &#125; /** * 希尔排序 * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void shellSort2(int[] a, int n) &#123; // gap为步长，每次减为原来的一半。 for (int gap = n / 2; gap &gt; 0; gap /= 2) &#123; // 共gap个组，对每一组都执行直接插入排序 for (int i = 0 ;i &lt; gap; i++) groupSort(a, n, i, gap); &#125; &#125; public static void main(String[] args) &#123; int i; int a[] = &#123;80,30,60,40,20,10,50,70&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); shellSort1(a, a.length); //shellSort2(a, a.length); System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3597597.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","希尔排序","Shell Sort"],"categories":["算法","排序算法"]},{"title":"4.排序 - 插入排序(Insertion Sort)","path":"/2023/12/27/4-排序-插入排序-Insertion-Sort/","content":"本文主要介绍插入排序。 插入排序介绍直接插入排序(Straight Insertion Sort)的基本思想是: 把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。 插入排序实现下面选取直接插入排序的一个中间过程对其进行说明。假设{20,30,40,10,60,50}中的前3个数已经排列过，是有序的了；接下来对10进行排列。示意图如下: 图中将数列分为有序区和无序区。我们需要做的工作只有两个: (1)取出无序区中的第1个数，并找出它在有序区对应的位置。(2)将无序区的数据插入到有序区；若有必要的话，则对有序区中的相关数据进行移位。 插入排序的时间复杂度和稳定性插入排序时间复杂度直接插入排序的时间复杂度是O(N2)。 假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢? N-1！因此，直接插入排序的时间复杂度是O(N2)。 插入排序稳定性直接插入排序是稳定的算法，它满足稳定算法的定义。 算法稳定性 – 假设在数列中存在a[i]&#x3D;a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455/** * 直接插入排序: Java * * @author skywang * @date 2014/03/11 */public class InsertSort &#123; /* * 直接插入排序 * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void insertSort(int[] a, int n) &#123; int i, j, k; for (i = 1; i &lt; n; i++) &#123; //为a[i]在前面的a[0...i-1]有序区间中找一个合适的位置 for (j = i - 1; j &gt;= 0; j--) if (a[j] &lt; a[i]) break; //如找到了一个合适的位置 if (j != i - 1) &#123; //将比a[i]大的数据向后移 int temp = a[i]; for (k = i - 1; k &gt; j; k--) a[k + 1] = a[k]; //将a[i]放到正确位置上 a[k + 1] = temp; &#125; &#125; &#125; public static void main(String[] args) &#123; int i; int[] a = &#123;20,40,30,10,60,50&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); insertSort(a, a.length); System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3596881.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","插入排序","Insertion Sort"],"categories":["算法","排序算法"]},{"title":"3.排序 - 快速排序(Quick Sort)","path":"/2023/12/27/3-排序-快速排序-Quick-Sort/","content":"快速排序(Quick Sort)使用分治法算法思想。 快速排序介绍它的基本思想是: 选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 快速排序实现 从数列中挑出一个基准值。 将所有比基准值小的摆放在基准前面，所有比基准值大的摆在基准的后面(相同的数可以到任一边)；在这个分区退出之后，该基准就处于数列的中间位置。 递归地把”基准值前面的子数列”和”基准值后面的子数列”进行排序。 下面以数列a&#x3D;{30,40,60,10,20,50}为例，演示它的快速排序过程(如下图)。 上图只是给出了第1趟快速排序的流程。在第1趟中，设置x&#x3D;a[i]，即x&#x3D;30。 从”右 –&gt; 左”查找小于x的数: 找到满足条件的数a[j]&#x3D;20，此时j&#x3D;4；然后将a[j]赋值a[i]，此时i&#x3D;0；接着从左往右遍历。 从”左 –&gt; 右”查找大于x的数: 找到满足条件的数a[i]&#x3D;40，此时i&#x3D;1；然后将a[i]赋值a[j]，此时j&#x3D;4；接着从右往左遍历。 从”右 –&gt; 左”查找小于x的数: 找到满足条件的数a[j]&#x3D;10，此时j&#x3D;3；然后将a[j]赋值a[i]，此时i&#x3D;1；接着从左往右遍历。 从”左 –&gt; 右”查找大于x的数: 找到满足条件的数a[i]&#x3D;60，此时i&#x3D;2；然后将a[i]赋值a[j]，此时j&#x3D;3；接着从右往左遍历。 从”右 –&gt; 左”查找小于x的数: 没有找到满足条件的数。当i&gt;&#x3D;j时，停止查找；然后将x赋值给a[i]。此趟遍历结束！ 按照同样的方法，对子数列进行递归遍历。最后得到有序数组！ 快速排序时间复杂度和稳定性快速排序稳定性快速排序是不稳定的算法，它不满足稳定算法的定义。 算法稳定性 – 假设在数列中存在a[i]&#x3D;a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 快速排序时间复杂度 快速排序的时间复杂度在最坏情况下是O(N2)，平均的时间复杂度是O(N*lgN)。 这句话很好理解: 假设被排序的数列中有N个数。遍历一次的时间复杂度是O(N)，需要遍历多少次呢? 至少lg(N+1)次，最多N次。 为什么最少是lg(N+1)次? 快速排序是采用的分治法进行遍历的，我们将它看作一棵二叉树，它需要遍历的次数就是二叉树的深度，而根据完全二叉树的定义，它的深度至少是lg(N+1)。因此，快速排序的遍历次数最少是lg(N+1)次。 为什么最多是N次? 这个应该非常简单，还是将快速排序看作一棵二叉树，它的深度最大是N。因此，快读排序的遍历次数最多是N次。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 快速排序: Java * * @author skywang * @date 2014/03/11 */public class QuickSort &#123; /* * 快速排序 * * 参数说明: * a -- 待排序的数组 * l -- 数组的左边界(例如，从起始位置开始排序，则l=0) * r -- 数组的右边界(例如，排序截至到数组末尾，则r=a.length-1) */ public static void quickSort(int[] a, int l, int r) &#123; if (l &lt; r) &#123; int i,j,x; i = l; j = r; x = a[i]; while (i &lt; j) &#123; while(i &lt; j &amp;&amp; a[j] &gt; x) j--; // 从右向左找第一个小于x的数 if(i &lt; j) a[i++] = a[j]; while(i &lt; j &amp;&amp; a[i] &lt; x) i++; // 从左向右找第一个大于x的数 if(i &lt; j) a[j--] = a[i]; &#125; a[i] = x; quickSort(a, l, i-1); /* 递归调用 */ quickSort(a, i+1, r); /* 递归调用 */ &#125; &#125; public static void main(String[] args) &#123; int i; int a[] = &#123;30,40,60,10,20,50&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); quickSort(a, 0, a.length-1); System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3596746.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","快速排序","Quick Sort"],"categories":["算法","排序算法"]},{"title":"2.排序 - 冒泡排序(Bubble Sort)","path":"/2023/12/27/2-排序-冒泡排序-Bubble-Sort/","content":"最简单和最基本的排序。 冒泡排序介绍它是一种较简单的排序算法。它会遍历若干次要排序的数列，每次遍历时，它都会从前往后依次的比较相邻两个数的大小；如果前者比后者大，则交换它们的位置。这样，一次遍历之后，最大的元素就在数列的末尾！ 采用相同的方法再次遍历时，第二大的元素就被排列在最大元素之前。重复此操作，直到整个数列都有序为止！ 冒泡排序实现下面以数列{20,40,30,10,60,50}为例，演示它的冒泡排序过程(如下图)。 我们先分析第1趟排序 当i&#x3D;5,j&#x3D;0时，a[0]&lt;a[1]。此时，不做任何处理！ 当i&#x3D;5,j&#x3D;1时，a[1]&gt;a[2]。此时，交换a[1]和a[2]的值；交换之后，a[1]&#x3D;30，a[2]&#x3D;40。 当i&#x3D;5,j&#x3D;2时，a[2]&gt;a[3]。此时，交换a[2]和a[3]的值；交换之后，a[2]&#x3D;10，a[3]&#x3D;40。 当i&#x3D;5,j&#x3D;3时，a[3]&lt;a[4]。此时，不做任何处理！ 当i&#x3D;5,j&#x3D;4时，a[4]&gt;a[5]。此时，交换a[4]和a[5]的值；交换之后，a[4]&#x3D;50，a[3]&#x3D;60。 于是，第1趟排序完之后，数列{20,40,30,10,60,50}变成了{20,30,10,40,50,60}。此时，数列末尾的值最大。 根据这种方法: 第2趟排序完之后，数列中a[5…6]是有序的。 第3趟排序完之后，数列中a[4…6]是有序的。 第4趟排序完之后，数列中a[3…6]是有序的。 第5趟排序完之后，数列中a[1…6]是有序的。整个数列也就是有序的了。 复杂度和稳定性冒泡排序时间复杂度冒泡排序的时间复杂度是O(N2)。 假设被排序的数列中有N个数。遍历一趟的时间复杂度是O(N)，需要遍历多少次呢? N-1次！因此，冒泡排序的时间复杂度是O(N2)。 冒泡排序稳定性冒泡排序是稳定的算法，它满足稳定算法的定义。 算法稳定性 – 假设在数列中存在a[i]&#x3D;a[j]，若在排序之前，a[i]在a[j]前面；并且排序之后，a[i]仍然在a[j]前面。则这个排序算法是稳定的！ 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * 冒泡排序: Java * * @author skywang * @date 2014/03/11 */public class BubbleSort &#123; /* * 冒泡排序 * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void bubbleSort1(int[] a, int n) &#123; int i,j; for (i=n-1; i&gt;0; i--) &#123; // 将a[0...i]中最大的数据放在末尾 for (j=0; j&lt;i; j++) &#123; if (a[j] &gt; a[j+1]) &#123; // 交换a[j]和a[j+1] int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; &#125; &#125; &#125; &#125; /* * 冒泡排序(改进版) * * 参数说明: * a -- 待排序的数组 * n -- 数组的长度 */ public static void bubbleSort2(int[] a, int n) &#123; int i,j; int flag; // 标记 for (i=n-1; i&gt;0; i--) &#123; flag = 0; // 初始化标记为0 // 将a[0...i]中最大的数据放在末尾 for (j=0; j&lt;i; j++) &#123; if (a[j] &gt; a[j+1]) &#123; // 交换a[j]和a[j+1] int tmp = a[j]; a[j] = a[j+1]; a[j+1] = tmp; flag = 1; // 若发生交换，则设标记为1 &#125; &#125; if (flag==0) break; // 若没发生交换，则说明数列已有序。 &#125; &#125; public static void main(String[] args) &#123; int i; int[] a = &#123;20,40,30,10,60,50&#125;; System.out.printf(&quot;before sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); bubbleSort1(a, a.length); //bubbleSort2(a, a.length); System.out.printf(&quot;after sort:&quot;); for (i=0; i&lt;a.length; i++) System.out.printf(&quot;%d &quot;, a[i]); System.out.printf(&quot; &quot;); &#125;&#125; 参考文章 提示 本文主要参考至 https://www.cnblogs.com/skywang12345/p/3596232.html, 在此基础上做了内容的增改。","tags":["算法","排序算法","冒泡排序","Bubble Sort"],"categories":["算法","排序算法"]},{"title":"1.常见排序算法知识体系详解","path":"/2023/12/27/1-常见排序算法知识体系详解/","content":"本章主要介绍排序总结。 知识体系文章知识体系系统性梳理 相关文章 A. 常见排序概要：重点理解几个排序之间的对比，时间和空间复杂度，以及应用。PS：越简单越要提高认知效率，做到战略上藐视战术上重视。 排序 - Overview B. 常见排序详解：具体分析各种排序及其复杂度，查漏补缺；在综合复杂度及稳定性情况下，通常希尔, 快排和 归并需要重点掌握。 排序 - 冒泡排序(Bubble Sort) 它是一种较简单的排序算法。它会遍历若干次要排序的数列，每次遍历时，它都会从前往后依次的比较相邻两个数的大小；如果前者比后者大，则交换它们的位置。这样，一次遍历之后，最大的元素就在数列的末尾！ 采用相同的方法再次遍历时，第二大的元素就被排列在最大元素之前。重复此操作，直到整个数列都有序为止 排序 - 快速排序(Quick Sort) 它的基本思想是: 选择一个基准数，通过一趟排序将要排序的数据分割成独立的两部分；其中一部分的所有数据都比另外一部分的所有数据都要小。然后，再按此方法对这两部分数据分别进行快速排序，整个排序过程可以递归进行，以此达到整个数据变成有序序列。 排序 - 插入排序(Insertion Sort) 直接插入排序(Straight Insertion Sort)的基本思想是: 把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。 排序 - Shell排序(Shell Sort) 希尔排序实质上是一种分组插入方法。它的基本思想是: 对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；然后，对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap&#x3D;1时，整个数列就是有序的。 排序 - 选择排序(Selection sort) 它的基本思想是: 首先在未排序的数列中找到最小(or最大)元素，然后将其存放到数列的起始位置；接着，再从剩余未排序的元素中继续寻找最小(or最大)元素，然后放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。 排序 - 堆排序(Heap Sort) 堆排序是指利用堆这种数据结构所设计的一种排序算法。堆是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。 排序 - 归并排序(Merge Sort) 将两个的有序数列合并成一个有序数列，我们称之为”归并”。归并排序(Merge Sort)就是利用归并思想对数列进行排序。 排序 - 桶排序(Bucket Sort) 桶排序(Bucket Sort)的原理很简单，将数组分到有限数量的桶子里。每个桶子再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序） 排序 - 基数排序(Radix Sort) 它的基本思想是: 将整数按位数切割成不同的数字，然后按每个位数分别比较。具体做法是: 将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列 学习推荐 学习排序 - 动画展示排序 整体性比较好系列 - @skywang12345 不同情况下排序选择在不同的情形下，排序速度前三名也不尽相同: 排序场景 排序效率 Random 希尔&gt;快排&gt;归并 Few unique 快排&gt;希尔&gt;归并 Reversed 快排&gt;希尔&gt;归并 Almost sorted 插入排序&gt;基数排序&gt;快排&gt;希尔&gt;归并 总结来看: 快速排序和希尔排序在排序速度上表现是比较优秀的,而归并排序稍微次之. 参考文章 https://www.cnblogs.com/hokky/p/8529042.html","tags":["算法","排序算法"],"categories":["算法","排序算法"]},{"title":"17.图 - AOE & 关键路径","path":"/2023/12/27/17-图-AOE-关键路径/","content":"关键路径在项目管理计算工期等方面有广泛等应用，提升工期就是所见缩减所有关键路径上的工期，并且在实现时需要应用到之前拓扑排序的算法(前提: 有向无环图，有依赖关系)。 关键路径相关名词相关术语: AOV网络(Activity On Vertex Network): 有向图，用顶点表示活动，用弧表示活动的先后顺序 AOE网络(Activity On Edge): 有向图，用顶点表示事件，用弧表示活动，用权值表示活动消耗时间(带权的有向无环图) 活动: 业务逻辑中的行为，用边表示 事件: 活动的结果或者触发条件 关键路径: 具有最大路径长度(权重)的路径，可能不止一条 活动的两个属性: e(i)最早开始时间，l(i)最晚开始时间 事件的两个属性: ve(j)最早开始时间，vl(j)最晚开始时间 AOV和AOE的对比: 虽然都是用来对工程建模，但是还是有很大不同。主要体现在: AOV网是顶点表示活动的网，他只描述活动之间的制约更新， AOE网是用边表示活动的网，边上的权值表示活动持续的时间 关键路径的实现4个关键概念事件最早发生时间事件最早发生时间etv(earliest time of vertex)，即顶点Vk的最早发生时间。 事件最晚发生时间事件最晚发生时间ltv(lastest time of vertex)，即顶点Vk的最晚发生时间，也就是每个顶点对应的事件最晚需要开始的事件，超出此事件将会延误整个工期。 活动的最早开工时间活动的最早开工时间ete(earliest time of edge)，即弧ak的最早发生时间。 活动的最晚开工时间活动的最晚开工时间lte(lastest time if edge)，即弧的最晚发生时间，也就是不推迟工期的最晚开工时间。 4个时间的关系我们可以由事件的最早发生时间和事件的最晚发生时间求出活动的最早和最晚开工时间。 由1,2可以求得3,4，然后在根据ete[k]是否与lte[k]相等来判断ak是否是关键活动。 算法实现 推演图 etv从左向右推导 ltv从右向左推导 ete: 活动最早开工时间需要和etv事件最早发生时间结合 lte: 活动最晚开工时间需要和ltv事件最晚发生时间结合(都是倒序获得) 推演的步骤具体可以参考 这里 参考文章 https://blog.csdn.net/qq_25508039/article/details/75390192 https://www.cnblogs.com/ssyfj/p/9496969.html https://www.cnblogs.com/Braveliu/p/3461649.html https://www.cnblogs.com/lisen10/p/10876110.html","tags":["数据结构","图","AOE","关键路径"],"categories":["数据结构","图"]},{"title":"16.图 - 拓扑排序(Topological sort)","path":"/2023/12/27/16-图-拓扑排序-Topological-sort/","content":"拓扑排序主要用来解决有向图中的依赖解析(dependency resolution)问题。 拓扑排序介绍对于任何有向图而言，其拓扑排序为其所有结点的一个线性排序(对于同一个有向图而言可能存在多个这样的结点排序)。该排序满足这样的条件——对于图中的任意两个结点u和v，若存在一条有向边从u指向v，则在拓扑排序中u一定出现在v前面。 例如一个有向无环图如下: 结点1必须在结点2、3之前 结点2必须在结点3、4之前 结点3必须在结点4、5之前 结点4必须在结点5之前 则一个满足条件的拓扑排序为[1, 2, 3, 4, 5]。 拓扑排序前提当且仅当一个有向图为有向无环图(directed acyclic graph，或称DAG)时，才能得到对应于该图的拓扑排序。这里有两点要注意: 对于有环图，必然会造成循环依赖(circular dependency)，不符合拓扑排序定义； 对于每一个有向无环图都至少存在一种拓扑排序； 不唯一的情况: 上图中若我们删 4、5结点之前的有向边，上图变为如下所示: 则我们可得到两个不同的拓扑排序结果: [1, 2, 3, 4, 5]和[1, 2, 3, 5, 4]。 拓扑排序算法为了说明如何得到一个有向无环图的拓扑排序，我们首先需要了解有向图结点的入度(indegree)和出度(outdegree)的概念。 假设有向图中不存在起点和终点为同一结点的有向边。 入度: 设有向图中有一结点v，其入度即为当前所有从其他结点出发，终点为v的的边的数目。也就是所有指向v的有向边的数目。 出度: 设有向图中有一结点v，其出度即为当前所有起点为v，指向其他结点的边的数目。也就是所有由v发出的边的数目。 在了解了入度和出度的概念之后，再根据拓扑排序的定义，我们自然就能够得出结论: 要想完成拓扑排序，我们每次都应当从入度为0的结点开始遍历。因为只有入度为0的结点才能够成为拓扑排序的起点。否则根据拓扑排序的定义，只要一个结点v的入度不为0，则至少有一条边起始于其他结点而指向v，那么这条边的起点在拓扑排序的顺序中应当位于v之前，则v不能成为当前遍历的起点。 由此我们可以进一步得出一个改进的深度优先遍历或广度优先遍历算法来完成拓扑排序。以广度优先遍历为例，这一改进后的算法与普通的广度优先遍历唯一的区别在于我们应当保存每一个结点对应的入度，并在遍历的每一层选取入度为0的结点开始遍历(而普通的广度优先遍历则无此限制，可以从该吃呢个任意一个结点开始遍历)。这个算法描述如下: 初始化一个int[] inDegree保存每一个结点的入度。 对于图中的每一个结点的子结点，将其子结点的入度加1。 选取入度为0的结点开始遍历，并将该节点加入输出。 对于遍历过的每个结点，更新其子结点的入度: 将子结点的入度减1。 重复步骤3，直到遍历完所有的结点。 如果无法遍历完所有的结点，则意味着当前的图不是有向无环图。不存在拓扑排序。 拓扑排序代码实现广度优先遍历拓扑排序的Java代码如下: 12345678910111213141516171819202122232425262728293031323334353637public class TopologicalSort &#123; /** * Get topological ordering of the input directed graph * @param n number of nodes in the graph * @param adjacencyList adjacency list representation of the input directed graph * @return topological ordering of the graph stored in an List&lt;Integer&gt;. */ public List&lt;Integer&gt; topologicalSort(int n, int[][] adjacencyList) &#123; List&lt;Integer&gt; topoRes = new ArrayList&lt;&gt;(); int[] inDegree = new int[n]; for (int[] parent : adjacencyList) &#123; for (int child : parent) &#123; inDegree[child]++; &#125; &#125; Deque&lt;Integer&gt; deque = new ArrayDeque&lt;&gt;(); // start from nodes whose indegree are 0 for (int i = 0; i &lt; n; i++) &#123; if (inDegree[i] == 0) deque.offer(i); &#125; while (!deque.isEmpty()) &#123; int curr = deque.poll(); topoRes.add(curr); for (int child : adjacencyList[curr]) &#123; inDegree[child]--; if (inDegree[child] == 0) &#123; deque.offer(child); &#125; &#125; &#125; return topoRes.size() == n ? topoRes : new ArrayList&lt;&gt;(); &#125;&#125; 复杂度时间复杂度: O(n + e)，其中n为图中的结点数目，e为图中的边的数目 空间复杂度: O(n) 参考文章 https://www.jianshu.com/p/3347f54a3187","tags":["数据结构","图","拓扑排序","Topological sort"],"categories":["数据结构","图"]},{"title":"15.图 - 最短路径(Dijkstra & Frolyd)","path":"/2023/12/27/15-图-最短路径-Dijkstra-Frolyd/","content":"最短路径有着广泛的应用，比如地图两点间距离计算，公交查询系统，路由选择等。 最短路径介绍最短路径问题是图论研究中的一个经典算法问题，旨在寻找图(由结点和路径组成的)中两结点之间的最短路径。最短路径不一定是经过边最少的路径，但在这些最短路径中，长度最短的那一条路径上只有一条边，且它的权值在从源点出发的所有边的权值最小。 从图中某一顶点(称为源点)到达另一顶点(称为终点)的路径可能不止一条，如何找到一条路径使得沿此路径上各边上的权值总和达到最小，例: 公交查询系统。 路径长度最短的最短路径的特点: 在这条路径上，必定只含一条弧，并且这条弧的权值最小。 下一条路径长度次短的最短路径的特点: 它只可能有两种情况: 或者是直接从源点到该点(只含一条弧)； 或者是从源点经过顶点v1，再到达该顶点(由两条弧组成)。 问题解法: 求从某个源点到其余各点的最短路径 — Dijkstra算法 每一对顶点之间的最短路径 — Floyd算法 最短路径算法Dijkstra算法1.定义概览Dijkstra(迪杰斯特拉)算法是典型的单源最短路径算法，用于计算一个节点到其他所有节点的最短路径。主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。Dijkstra算法是很有代表性的最短路径算法，在很多专业课程中都作为基本内容有详细的介绍，如数据结构，图论，运筹学等等。注意该算法要求图中不存在负权边。 问题描述: 在无向图 G&#x3D;(V,E) 中，假设每条边 E[i] 的长度为 w[i]，找到由顶点 V0 到其余各点的最短路径。(单源最短路径) 2.算法描述1)算法思想: 设G&#x3D;(V,E)是一个带权有向图，把图中顶点集合V分成两组，第一组为已求出最短路径的顶点集合(用S表示，初始时S中只有一个源点，以后每求得一条最短路径 , 就将加入到集合S中，直到全部顶点都加入到S中，算法就结束了)，第二组为其余未确定最短路径的顶点集合(用U表示)，按最短路径长度的递增次序依次把第二组的顶点加入S中。在加入的过程中，总保持从源点v到S中各顶点的最短路径长度不大于从源点v到U中任何顶点的最短路径长度。此外，每个顶点对应一个距离，S中的顶点的距离就是从v到此顶点的最短路径长度，U中的顶点的距离，是从v到此顶点只包括S中的顶点为中间顶点的当前最短路径长度。 2)算法步骤: a.初始时，S只包含源点，即S＝{v}，v的距离为0。U包含除v外的其他顶点，即:U&#x3D;{其余顶点}，若v与U中顶点u有边，则&lt;u,v&gt;正常有权值，若u不是v的出边邻接点，则&lt;u,v&gt;权值为∞。 b.从U中选取一个距离v最小的顶点k，把k，加入S中(该选定的距离就是v到k的最短路径长度)。 c.以k为新考虑的中间点，修改U中各顶点的距离；若从源点v到顶点u的距离(经过顶点k)比原来距离(不经过顶点k)短，则修改顶点u的距离值，修改后的距离值的顶点k的距离加上边上的权。 d.重复步骤b和c直到所有顶点都包含在S中。 Floyd算法转载自 Floyd算法详解 通俗易懂 Floyd 算法是一个基于「贪心」、「动态规划」求一个图中 所有点到所有点 最短路径的算法，时间复杂度 O(n3) 1. 要点以每个点为「中转站」，刷新所有「入度」和「出度」的距离。 Dijkstra 算法：每次从「未求出最短路径」的点中 取出 最短路径的点，并通过这个点为「中转站」刷新剩下「未求出最短路径」的距离。Dijkstra 的算法在图中的效果像是：以起点为中心像是一个涟漪一样在水面上铺开。Floyd 算法在图中的效果像是：一个一个多点的小涟漪，最后小涟漪铺满整个水面。 2.图解案例分析 案例：求所有点到所有点的最短距离 邻接矩阵图 12345int[][] graph = new int[][]&#123;&#123;0 , 2, ∞, 6&#125;&#123;2 , 0, 3, 2&#125;&#123;∞ , 3, 0, 2&#125;&#123;6 , 2, 2, 0&#125;&#125;; （重点）算法要点 **distance[][]**：用来储存每个点到其他点的最短距离 **path[][]**：用来储存每个点到其他点最短距离的路径 要点：以每个点为「中转站」，刷新所有「入度」和「出度」的距离。所以我们要：遍历每一个顶点 –&gt; 遍历点的每一个入度 –&gt; 遍历每一个点的出度，以这个点为「中转站」距离更短就刷新距离（比如 B 点为中转站 AB + BD &lt; AD 就刷新 A 到 D 的距离） 2.1. 初始化：初始化距离 distance 为图结构 graph，初始化路径 path 为初始图结构的路径如下 12345678910====distance==== 0 2 -1 6 2 0 3 2 -1 3 0 2 6 2 2 0 ====path====0 1 2 3 0 1 2 3 0 1 2 3 0 1 2 3 2.2. 以 A 为「中转站」，刷新所有「入度」和「出度」的距离A 的入度有 B 、D 2点，A 的出度也是 B、D 2点 BA + AD &gt; BD DA + AB &gt; DB 所以没有更小的距离，不能「刷新距离」，distance[][] 和 path[][] 不刷新 2.3. （重点）以 B 为「中转站」，刷新所有的「入度」和「出度」的距离B 的入度有 A、C、D；B 的出度有 A、C、D。（所以一共有 6 种组合） AB + BC &lt; AC （ 2 + 3 &lt; 无穷大，这里的 -1 代表无穷大） 刷新距离： 刷新距离：将 AB + BC 的距离 5 赋值给 AC 距离 -1，即 distance[0][2] = distance[0][1] +distance[1][2] 刷新最短路径：AC 的最短距离不再是直线 AC 的最短距离，引入「中转站」B 点，即 path[0][2] = 1 AB + BD &lt; AD （ 2 + 2 &lt; 6） 刷新距离： 刷新距离：将 AB + BD &#x3D; 4 的值赋值给 AD，即 distance[0][3] = distance[0][1] +distance[1][3] 刷新最短路径：AD的最短距离不再是直线 AD 的最短距离，引入「中转站」B 点，即 path[0][3] = 1 CB + BA &lt; CA（ 2 + 3 &lt; 无穷大 同理第一个 AB + BC &lt; AC ，刷新距离） CB + BD &gt; CD（3 + 2 &gt; 2，不用刷新距离） DB + BA &lt; DA （2 + 2 &lt; 6，同理第二个 AB + BD &lt; AD， 刷新距离） DB + BC &lt; DC（2 + 3 &lt; 2 ，不用刷新距离） 刷新后的 distance[][] 和 path[][] 入下所示 12345678910====distance====0 2 5 4 2 0 3 2 5 3 0 2 4 2 2 0 ====path====0 1 1 1 0 1 2 3 1 1 2 3 1 1 2 3 2.4. 以 C 点为「中转站」，刷新所有「出度」和「入度」的距离类似 3 步骤，这里不赘述 2.5. 以 D 点为「中转站」，刷新所有「出度」和「入度」的距离类似 3 步骤，这里不赘述，结束算法 3. 代码这里使用 -1 表无穷大，下面是 Java 代码和测试案例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package floyd;/** * @author Jarvan * @version 1.0 * @create 2020/12/25 11:01 */public class Floyd &#123; /** * 距离矩阵 */ public static int[][] distance; /** * 路径矩阵 */ public static int[][] path; public static void floyd(int[][] graph) &#123; //初始化距离矩阵 distance distance = graph; //初始化路径 path = new int[graph.length][graph.length]; for (int i = 0; i &lt; graph.length; i++) &#123; for (int j = 0; j &lt; graph[i].length; j++) &#123; path[i][j] = j; &#125; &#125; //开始 Floyd 算法 //每个点为中转 for (int i = 0; i &lt; graph.length; i++) &#123; //所有入度 for (int j = 0; j &lt; graph.length; j++) &#123; //所有出度 for (int k = 0; k &lt; graph[j].length; k++) &#123; //以每个点为「中转」，刷新所有出度和入度之间的距离 //例如 AB + BC &lt; AC 就刷新距离 if (graph[j][i] != -1 &amp;&amp; graph[i][k] != -1) &#123; int newDistance = graph[j][i] + graph[i][k]; if (newDistance &lt; graph[j][k] || graph[j][k] == -1) &#123; //刷新距离 graph[j][k] = newDistance; //刷新路径 path[j][k] = i; &#125; &#125; &#125; &#125; &#125; &#125; /** * 测试 */ public static void main(String[] args) &#123; char[] vertices = new char[]&#123;&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;&#125;; int[][] graph = new int[][]&#123; &#123;0, 2, -1, 6&#125; , &#123;2, 0, 3, 2&#125; , &#123;-1, 3, 0, 2&#125; , &#123;6, 2, 2, 0&#125;&#125;; floyd(graph); System.out.println(&quot;====distance====&quot;); for (int[] ints : distance) &#123; for (int anInt : ints) &#123; System.out.print(anInt + &quot; &quot;); &#125; System.out.println(); &#125; System.out.println(&quot;====path====&quot;); for (int[] ints : path) &#123; for (int anInt : ints) &#123; System.out.print(anInt + &quot; &quot;); &#125; System.out.println(); &#125; &#125;&#125; 测试结果 12345678910====distance====0 2 5 4 2 0 3 2 5 3 0 2 4 2 2 0 ====path====0 1 1 1 0 1 2 3 1 1 2 3 1 1 2 3 参考文章 https://www.cnblogs.com/lisen10/p/10876132.html https://www.cnblogs.com/biyeymyhjob/archive/2012/07/31/2615833.html https://www.cnblogs.com/idreamo/p/9472295.html https://segmentfault.com/a/1190000015440278 https://zhuanlan.zhihu.com/p/339542626","tags":["数据结构","图","最短路径","Dijkstra & Frolyd"],"categories":["数据结构","图"]},{"title":"14.图 - 最小生成树(Prim & Kruskal)","path":"/2023/12/27/14-图-最小生成树-Prim-Kruskal/","content":"Kruskal算法是从最小权重边着手，将森林里的树逐渐合并；prim算法是从顶点出发，在根结点的基础上建起一棵树。 最小生成树相关名词 连通图: 在无向图中，若任意两个顶点vivi与vjvj都有路径相通，则称该无向图为连通图。 强连通图: 在有向图中，若任意两个顶点vivi与vjvj都有路径相通，则称该有向图为强连通图。 连通网: 在连通图中，若图的边具有一定的意义，每一条边都对应着一个数，称为权；权代表着连接连个顶点的代价，称这种连通图叫做连通网。 生成树: 一个连通图的生成树是指一个连通子图，它含有图中全部n个顶点，但只有足以构成一棵树的n-1条边。一颗有n个顶点的生成树有且仅有n-1条边，如果生成树中再添加一条边，则必定成环。 最小生成树: 在连通网的所有生成树中，所有边的代价和最小的生成树，称为最小生成树。 最小生成树算法Kruskal算法此算法可以称为“加边法”，初始最小生成树边数为0，每迭代一次就选择一条满足条件的最小代价边，加入到最小生成树的边集合里。 把图中的所有边按代价从小到大排序； 把图中的n个顶点看成独立的n棵树组成的森林； 按权值从小到大选择边，所选的边连接的两个顶点ui,viui,vi,应属于两颗不同的树，则成为最小生成树的一条边，并将这两颗树合并作为一颗树。 重复(3),直到所有顶点都在一颗树内或者有n-1条边为止。 Prim算法此算法可以称为“加点法”，每次迭代选择代价最小的边对应的点，加入到最小生成树中。算法从某一个顶点s开始，逐渐长大覆盖整个连通网的所有顶点。 图的所有顶点集合为VV；初始令集合u&#x3D;{s},v&#x3D;V−uu&#x3D;{s},v&#x3D;V−u; 在两个集合u,vu,v能够组成的边中，选择一条代价最小的边(u0,v0)(u0,v0)，加入到最小生成树中，并把v0v0并入到集合u中。 重复上述步骤，直到最小生成树有n-1条边或者n个顶点为止。 由于不断向集合u中加点，所以最小代价边必须同步更新；需要建立一个辅助数组closedge,用来维护集合v中每个顶点与集合u中最小代价边信息，: 总结因为Kruskal涉及大量对边的操作，所以它适用于稀疏图；普通的prim算法适用于稠密图，但堆优化的prim算法更适用于稀疏图，因为其时间复杂度是由边的数量决定的。 参考文章 https://blog.csdn.net/luoshixian099/article/details/51908175 https://www.cnblogs.com/wuxiangnong/p/10885129.html","tags":["数据结构","图","最小生成树","Prim & Kruskal"],"categories":["数据结构","图"]},{"title":"13.图 - 遍历(BFS & DFS)","path":"/2023/12/27/13-图-遍历-BFS-DFS/","content":"图的深度优先搜索(Depth First Search)，和树的先序遍历比较类似; 广度优先搜索算法(Breadth First Search)，又称为”宽度优先搜索”或”横向优先搜索”。 深度优先搜索深度优先搜索介绍它的思想: 假设初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。 显然，深度优先搜索是一个递归的过程。 深度优先搜索图解无向图的深度优先搜索下面以”无向图”为例，来对深度优先搜索进行演示。 对上面的图G1进行深度优先遍历，从顶点A开始。 第1步: 访问A。 第2步: 访问(A的邻接点)C。 在第1步访问A之后，接下来应该访问的是A的邻接点，即”C,D,F”中的一个。但在本文的实现中，顶点ABCDEFG是按照顺序存储，C在”D和F”的前面，因此，先访问C。 第3步: 访问(C的邻接点)B。 在第2步访问C之后，接下来应该访问C的邻接点，即”B和D”中一个(A已经被访问过，就不算在内)。而由于B在D之前，先访问B。 第4步: 访问(C的邻接点)D。 在第3步访问了C的邻接点B之后，B没有未被访问的邻接点；因此，返回到访问C的另一个邻接点D。 第5步: 访问(A的邻接点)F。 前面已经访问了A，并且访问完了”A的邻接点B的所有邻接点(包括递归的邻接点在内)”；因此，此时返回到访问A的另一个邻接点F。 第6步: 访问(F的邻接点)G。 第7步: 访问(G的邻接点)E。 因此访问顺序是: A -&gt; C -&gt; B -&gt; D -&gt; F -&gt; G -&gt; E 有向图的深度优先搜索下面以”有向图”为例，来对深度优先搜索进行演示。 对上面的图G2进行深度优先遍历，从顶点A开始。 第1步: 访问A。 第2步: 访问B。 在访问了A之后，接下来应该访问的是A的出边的另一个顶点，即顶点B。 第3步: 访问C。 在访问了B之后，接下来应该访问的是B的出边的另一个顶点，即顶点C,E,F。在本文实现的图中，顶点ABCDEFG按照顺序存储，因此先访问C。 第4步: 访问E。 接下来访问C的出边的另一个顶点，即顶点E。 第5步: 访问D。 接下来访问E的出边的另一个顶点，即顶点B,D。顶点B已经被访问过，因此访问顶点D。 第6步: 访问F。 接下应该回溯”访问A的出边的另一个顶点F”。 第7步: 访问G。 因此访问顺序是: A -&gt; B -&gt; C -&gt; E -&gt; D -&gt; F -&gt; G 广度优先搜索广度优先搜索介绍广度优先搜索算法(Breadth First Search)，又称为”宽度优先搜索”或”横向优先搜索”，简称BFS。 它的思想是: 从图中某顶点v出发，在访问了v之后依次访问v的各个未曾访问过的邻接点，然后分别从这些邻接点出发依次访问它们的邻接点，并使得“先被访问的顶点的邻接点先于后被访问的顶点的邻接点被访问，直至图中所有已被访问的顶点的邻接点都被访问到。如果此时图中尚有顶点未被访问，则需要另选一个未曾被访问过的顶点作为新的起始点，重复上述过程，直至图中所有顶点都被访问到为止。 换句话说，广度优先搜索遍历图的过程是以v为起点，由近至远，依次访问和v有路径相通且路径长度为1,2…的顶点。 广度优先搜索图解无向图的广度优先搜索下面以”无向图”为例，来对广度优先搜索进行演示。还是以上面的图G1为例进行说明。 第1步: 访问A。 第2步: 依次访问C,D,F。 在访问了A之后，接下来访问A的邻接点。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，C在”D和F”的前面，因此，先访问C。再访问完C之后，再依次访问D,F。 第3步: 依次访问B,G。 在第2步访问完C,D,F之后，再依次访问它们的邻接点。首先访问C的邻接点B，再访问F的邻接点G。 第4步: 访问E。 在第3步访问完B,G之后，再依次访问它们的邻接点。只有G有邻接点E，因此访问G的邻接点E。 因此访问顺序是: A -&gt; C -&gt; D -&gt; F -&gt; B -&gt; G -&gt; E 有向图的广度优先搜索下面以”有向图”为例，来对广度优先搜索进行演示。还是以上面的图G2为例进行说明。 第1步: 访问A。 第2步: 访问B。 第3步: 依次访问C,E,F。 在访问了B之后，接下来访问B的出边的另一个顶点，即C,E,F。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，因此会先访问C，再依次访问E,F。 第4步: 依次访问D,G。 在访问完C,E,F之后，再依次访问它们的出边的另一个顶点。还是按照C,E,F的顺序访问，C的已经全部访问过了，那么就只剩下E,F；先访问E的邻接点D，再访问F的邻接点G。 因此访问顺序是: A -&gt; B -&gt; C -&gt; E -&gt; F -&gt; D -&gt; G 相关实现邻接矩阵实现无向图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245import java.io.IOException;import java.util.Scanner;public class MatrixUDG &#123; private char[] mVexs; // 顶点集合 private int[][] mMatrix; // 邻接矩阵 /* * 创建图(自己输入数据) */ public MatrixUDG() &#123; // 输入&quot;顶点数&quot;和&quot;边数&quot; System.out.printf(&quot;input vertex number: &quot;); int vlen = readInt(); System.out.printf(&quot;input edge number: &quot;); int elen = readInt(); if ( vlen &lt; 1 || elen &lt; 1 || (elen &gt; (vlen*(vlen - 1)))) &#123; System.out.printf(&quot;input error: invalid parameters! &quot;); return ; &#125; // 初始化&quot;顶点&quot; mVexs = new char[vlen]; for (int i = 0; i &lt; mVexs.length; i++) &#123; System.out.printf(&quot;vertex(%d): &quot;, i); mVexs[i] = readChar(); &#125; // 初始化&quot;边&quot; mMatrix = new int[vlen][vlen]; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 System.out.printf(&quot;edge(%d):&quot;, i); char c1 = readChar(); char c2 = readChar(); int p1 = getPosition(c1); int p2 = getPosition(c2); if (p1==-1 || p2==-1) &#123; System.out.printf(&quot;input error: invalid edge! &quot;); return ; &#125; mMatrix[p1][p2] = 1; mMatrix[p2][p1] = 1; &#125; &#125; /* * 创建图(用已提供的矩阵) * * 参数说明： * vexs -- 顶点数组 * edges -- 边数组 */ public MatrixUDG(char[] vexs, char[][] edges) &#123; // 初始化&quot;顶点数&quot;和&quot;边数&quot; int vlen = vexs.length; int elen = edges.length; // 初始化&quot;顶点&quot; mVexs = new char[vlen]; for (int i = 0; i &lt; mVexs.length; i++) mVexs[i] = vexs[i]; // 初始化&quot;边&quot; mMatrix = new int[vlen][vlen]; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 int p1 = getPosition(edges[i][0]); int p2 = getPosition(edges[i][1]); mMatrix[p1][p2] = 1; mMatrix[p2][p1] = 1; &#125; &#125; /* * 返回ch位置 */ private int getPosition(char ch) &#123; for(int i=0; i&lt;mVexs.length; i++) if(mVexs[i]==ch) return i; return -1; &#125; /* * 读取一个输入字符 */ private char readChar() &#123; char ch=&#x27;0&#x27;; do &#123; try &#123; ch = (char)System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; while(!((ch&gt;=&#x27;a&#x27;&amp;&amp;ch&lt;=&#x27;z&#x27;) || (ch&gt;=&#x27;A&#x27;&amp;&amp;ch&lt;=&#x27;Z&#x27;))); return ch; &#125; /* * 读取一个输入字符 */ private int readInt() &#123; Scanner scanner = new Scanner(System.in); return scanner.nextInt(); &#125; /* * 返回顶点v的第一个邻接顶点的索引，失败则返回-1 */ private int firstVertex(int v) &#123; if (v&lt;0 || v&gt;(mVexs.length-1)) return -1; for (int i = 0; i &lt; mVexs.length; i++) if (mMatrix[v][i] == 1) return i; return -1; &#125; /* * 返回顶点v相对于w的下一个邻接顶点的索引，失败则返回-1 */ private int nextVertex(int v, int w) &#123; if (v&lt;0 || v&gt;(mVexs.length-1) || w&lt;0 || w&gt;(mVexs.length-1)) return -1; for (int i = w + 1; i &lt; mVexs.length; i++) if (mMatrix[v][i] == 1) return i; return -1; &#125; /* * 深度优先搜索遍历图的递归实现 */ private void DFS(int i, boolean[] visited) &#123; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i]); // 遍历该顶点的所有邻接顶点。若是没有访问过，那么继续往下走 for (int w = firstVertex(i); w &gt;= 0; w = nextVertex(i, w)) &#123; if (!visited[w]) DFS(w, visited); &#125; &#125; /* * 深度优先搜索遍历图 */ public void DFS() &#123; boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 // 初始化所有顶点都没有被访问 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;DFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) DFS(i, visited); &#125; System.out.printf(&quot; &quot;); &#125; /* * 广度优先搜索（类似于树的层次遍历） */ public void BFS() &#123; int head = 0; int rear = 0; int[] queue = new int[mVexs.length]; // 辅组队列 boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;BFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) &#123; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i]); queue[rear++] = i; // 入队列 &#125; while (head != rear) &#123; int j = queue[head++]; // 出队列 for (int k = firstVertex(j); k &gt;= 0; k = nextVertex(j, k)) &#123; //k是为访问的邻接顶点 if (!visited[k]) &#123; visited[k] = true; System.out.printf(&quot;%c &quot;, mVexs[k]); queue[rear++] = k; &#125; &#125; &#125; &#125; System.out.printf(&quot; &quot;); &#125; /* * 打印矩阵队列图 */ public void print() &#123; System.out.printf(&quot;Martix Graph: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; for (int j = 0; j &lt; mVexs.length; j++) System.out.printf(&quot;%d &quot;, mMatrix[i][j]); System.out.printf(&quot; &quot;); &#125; &#125; public static void main(String[] args) &#123; char[] vexs = &#123;&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;&#125;; char[][] edges = new char[][]&#123; &#123;&#x27;A&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;A&#x27;, &#x27;D&#x27;&#125;, &#123;&#x27;A&#x27;, &#x27;F&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;C&#x27;, &#x27;D&#x27;&#125;, &#123;&#x27;E&#x27;, &#x27;G&#x27;&#125;, &#123;&#x27;F&#x27;, &#x27;G&#x27;&#125;&#125;; MatrixUDG pG; // 自定义&quot;图&quot;(输入矩阵队列) //pG = new MatrixUDG(); // 采用已有的&quot;图&quot; pG = new MatrixUDG(vexs, edges); pG.print(); // 打印图 pG.DFS(); // 深度优先遍历 pG.BFS(); // 广度优先遍历 &#125;&#125; 邻接表实现的无向图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276import java.io.IOException;import java.util.Scanner;public class ListUDG &#123; // 邻接表中表对应的链表的顶点 private class ENode &#123; int ivex; // 该边所指向的顶点的位置 ENode nextEdge; // 指向下一条弧的指针 &#125; // 邻接表中表的顶点 private class VNode &#123; char data; // 顶点信息 ENode firstEdge; // 指向第一条依附该顶点的弧 &#125;; private VNode[] mVexs; // 顶点数组 /* * 创建图(自己输入数据) */ public ListUDG() &#123; // 输入&quot;顶点数&quot;和&quot;边数&quot; System.out.printf(&quot;input vertex number: &quot;); int vlen = readInt(); System.out.printf(&quot;input edge number: &quot;); int elen = readInt(); if ( vlen &lt; 1 || elen &lt; 1 || (elen &gt; (vlen*(vlen - 1)))) &#123; System.out.printf(&quot;input error: invalid parameters! &quot;); return ; &#125; // 初始化&quot;顶点&quot; mVexs = new VNode[vlen]; for (int i = 0; i &lt; mVexs.length; i++) &#123; System.out.printf(&quot;vertex(%d): &quot;, i); mVexs[i] = new VNode(); mVexs[i].data = readChar(); mVexs[i].firstEdge = null; &#125; // 初始化&quot;边&quot; //mMatrix = new int[vlen][vlen]; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 System.out.printf(&quot;edge(%d):&quot;, i); char c1 = readChar(); char c2 = readChar(); int p1 = getPosition(c1); int p2 = getPosition(c2); // 初始化node1 ENode node1 = new ENode(); node1.ivex = p2; // 将node1链接到&quot;p1所在链表的末尾&quot; if(mVexs[p1].firstEdge == null) mVexs[p1].firstEdge = node1; else linkLast(mVexs[p1].firstEdge, node1); // 初始化node2 ENode node2 = new ENode(); node2.ivex = p1; // 将node2链接到&quot;p2所在链表的末尾&quot; if(mVexs[p2].firstEdge == null) mVexs[p2].firstEdge = node2; else linkLast(mVexs[p2].firstEdge, node2); &#125; &#125; /* * 创建图(用已提供的矩阵) * * 参数说明： * vexs -- 顶点数组 * edges -- 边数组 */ public ListUDG(char[] vexs, char[][] edges) &#123; // 初始化&quot;顶点数&quot;和&quot;边数&quot; int vlen = vexs.length; int elen = edges.length; // 初始化&quot;顶点&quot; mVexs = new VNode[vlen]; for (int i = 0; i &lt; mVexs.length; i++) &#123; mVexs[i] = new VNode(); mVexs[i].data = vexs[i]; mVexs[i].firstEdge = null; &#125; // 初始化&quot;边&quot; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 char c1 = edges[i][0]; char c2 = edges[i][1]; // 读取边的起始顶点和结束顶点 int p1 = getPosition(edges[i][0]); int p2 = getPosition(edges[i][1]); // 初始化node1 ENode node1 = new ENode(); node1.ivex = p2; // 将node1链接到&quot;p1所在链表的末尾&quot; if(mVexs[p1].firstEdge == null) mVexs[p1].firstEdge = node1; else linkLast(mVexs[p1].firstEdge, node1); // 初始化node2 ENode node2 = new ENode(); node2.ivex = p1; // 将node2链接到&quot;p2所在链表的末尾&quot; if(mVexs[p2].firstEdge == null) mVexs[p2].firstEdge = node2; else linkLast(mVexs[p2].firstEdge, node2); &#125; &#125; /* * 将node节点链接到list的最后 */ private void linkLast(ENode list, ENode node) &#123; ENode p = list; while(p.nextEdge!=null) p = p.nextEdge; p.nextEdge = node; &#125; /* * 返回ch位置 */ private int getPosition(char ch) &#123; for(int i=0; i&lt;mVexs.length; i++) if(mVexs[i].data==ch) return i; return -1; &#125; /* * 读取一个输入字符 */ private char readChar() &#123; char ch=&#x27;0&#x27;; do &#123; try &#123; ch = (char)System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; while(!((ch&gt;=&#x27;a&#x27;&amp;&amp;ch&lt;=&#x27;z&#x27;) || (ch&gt;=&#x27;A&#x27;&amp;&amp;ch&lt;=&#x27;Z&#x27;))); return ch; &#125; /* * 读取一个输入字符 */ private int readInt() &#123; Scanner scanner = new Scanner(System.in); return scanner.nextInt(); &#125; /* * 深度优先搜索遍历图的递归实现 */ private void DFS(int i, boolean[] visited) &#123; ENode node; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i].data); node = mVexs[i].firstEdge; while (node != null) &#123; if (!visited[node.ivex]) DFS(node.ivex, visited); node = node.nextEdge; &#125; &#125; /* * 深度优先搜索遍历图 */ public void DFS() &#123; boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 // 初始化所有顶点都没有被访问 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;DFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) DFS(i, visited); &#125; System.out.printf(&quot; &quot;); &#125; /* * 广度优先搜索（类似于树的层次遍历） */ public void BFS() &#123; int head = 0; int rear = 0; int[] queue = new int[mVexs.length]; // 辅组队列 boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;BFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) &#123; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i].data); queue[rear++] = i; // 入队列 &#125; while (head != rear) &#123; int j = queue[head++]; // 出队列 ENode node = mVexs[j].firstEdge; while (node != null) &#123; int k = node.ivex; if (!visited[k]) &#123; visited[k] = true; System.out.printf(&quot;%c &quot;, mVexs[k].data); queue[rear++] = k; &#125; node = node.nextEdge; &#125; &#125; &#125; System.out.printf(&quot; &quot;); &#125; /* * 打印矩阵队列图 */ public void print() &#123; System.out.printf(&quot;List Graph: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; System.out.printf(&quot;%d(%c): &quot;, i, mVexs[i].data); ENode node = mVexs[i].firstEdge; while (node != null) &#123; System.out.printf(&quot;%d(%c) &quot;, node.ivex, mVexs[node.ivex].data); node = node.nextEdge; &#125; System.out.printf(&quot; &quot;); &#125; &#125; public static void main(String[] args) &#123; char[] vexs = &#123;&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;&#125;; char[][] edges = new char[][]&#123; &#123;&#x27;A&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;A&#x27;, &#x27;D&#x27;&#125;, &#123;&#x27;A&#x27;, &#x27;F&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;C&#x27;, &#x27;D&#x27;&#125;, &#123;&#x27;E&#x27;, &#x27;G&#x27;&#125;, &#123;&#x27;F&#x27;, &#x27;G&#x27;&#125;&#125;; ListUDG pG; // 自定义&quot;图&quot;(输入矩阵队列) //pG = new ListUDG(); // 采用已有的&quot;图&quot; pG = new ListUDG(vexs, edges); pG.print(); // 打印图 pG.DFS(); // 深度优先遍历 pG.BFS(); // 广度优先遍历 &#125;&#125; 邻接矩阵实现的有向图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245import java.io.IOException;import java.util.Scanner;public class MatrixDG &#123; private char[] mVexs; // 顶点集合 private int[][] mMatrix; // 邻接矩阵 /* * 创建图(自己输入数据) */ public MatrixDG() &#123; // 输入&quot;顶点数&quot;和&quot;边数&quot; System.out.printf(&quot;input vertex number: &quot;); int vlen = readInt(); System.out.printf(&quot;input edge number: &quot;); int elen = readInt(); if ( vlen &lt; 1 || elen &lt; 1 || (elen &gt; (vlen*(vlen - 1)))) &#123; System.out.printf(&quot;input error: invalid parameters! &quot;); return ; &#125; // 初始化&quot;顶点&quot; mVexs = new char[vlen]; for (int i = 0; i &lt; mVexs.length; i++) &#123; System.out.printf(&quot;vertex(%d): &quot;, i); mVexs[i] = readChar(); &#125; // 初始化&quot;边&quot; mMatrix = new int[vlen][vlen]; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 System.out.printf(&quot;edge(%d):&quot;, i); char c1 = readChar(); char c2 = readChar(); int p1 = getPosition(c1); int p2 = getPosition(c2); if (p1==-1 || p2==-1) &#123; System.out.printf(&quot;input error: invalid edge! &quot;); return ; &#125; mMatrix[p1][p2] = 1; &#125; &#125; /* * 创建图(用已提供的矩阵) * * 参数说明： * vexs -- 顶点数组 * edges -- 边数组 */ public MatrixDG(char[] vexs, char[][] edges) &#123; // 初始化&quot;顶点数&quot;和&quot;边数&quot; int vlen = vexs.length; int elen = edges.length; // 初始化&quot;顶点&quot; mVexs = new char[vlen]; for (int i = 0; i &lt; mVexs.length; i++) mVexs[i] = vexs[i]; // 初始化&quot;边&quot; mMatrix = new int[vlen][vlen]; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 int p1 = getPosition(edges[i][0]); int p2 = getPosition(edges[i][1]); mMatrix[p1][p2] = 1; &#125; &#125; /* * 返回ch位置 */ private int getPosition(char ch) &#123; for(int i=0; i&lt;mVexs.length; i++) if(mVexs[i]==ch) return i; return -1; &#125; /* * 读取一个输入字符 */ private char readChar() &#123; char ch=&#x27;0&#x27;; do &#123; try &#123; ch = (char)System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; while(!((ch&gt;=&#x27;a&#x27;&amp;&amp;ch&lt;=&#x27;z&#x27;) || (ch&gt;=&#x27;A&#x27;&amp;&amp;ch&lt;=&#x27;Z&#x27;))); return ch; &#125; /* * 读取一个输入字符 */ private int readInt() &#123; Scanner scanner = new Scanner(System.in); return scanner.nextInt(); &#125; /* * 返回顶点v的第一个邻接顶点的索引，失败则返回-1 */ private int firstVertex(int v) &#123; if (v&lt;0 || v&gt;(mVexs.length-1)) return -1; for (int i = 0; i &lt; mVexs.length; i++) if (mMatrix[v][i] == 1) return i; return -1; &#125; /* * 返回顶点v相对于w的下一个邻接顶点的索引，失败则返回-1 */ private int nextVertex(int v, int w) &#123; if (v&lt;0 || v&gt;(mVexs.length-1) || w&lt;0 || w&gt;(mVexs.length-1)) return -1; for (int i = w + 1; i &lt; mVexs.length; i++) if (mMatrix[v][i] == 1) return i; return -1; &#125; /* * 深度优先搜索遍历图的递归实现 */ private void DFS(int i, boolean[] visited) &#123; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i]); // 遍历该顶点的所有邻接顶点。若是没有访问过，那么继续往下走 for (int w = firstVertex(i); w &gt;= 0; w = nextVertex(i, w)) &#123; if (!visited[w]) DFS(w, visited); &#125; &#125; /* * 深度优先搜索遍历图 */ public void DFS() &#123; boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 // 初始化所有顶点都没有被访问 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;DFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) DFS(i, visited); &#125; System.out.printf(&quot; &quot;); &#125; /* * 广度优先搜索（类似于树的层次遍历） */ public void BFS() &#123; int head = 0; int rear = 0; int[] queue = new int[mVexs.length]; // 辅组队列 boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;BFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) &#123; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i]); queue[rear++] = i; // 入队列 &#125; while (head != rear) &#123; int j = queue[head++]; // 出队列 for (int k = firstVertex(j); k &gt;= 0; k = nextVertex(j, k)) &#123; //k是为访问的邻接顶点 if (!visited[k]) &#123; visited[k] = true; System.out.printf(&quot;%c &quot;, mVexs[k]); queue[rear++] = k; &#125; &#125; &#125; &#125; System.out.printf(&quot; &quot;); &#125; /* * 打印矩阵队列图 */ public void print() &#123; System.out.printf(&quot;Martix Graph: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; for (int j = 0; j &lt; mVexs.length; j++) System.out.printf(&quot;%d &quot;, mMatrix[i][j]); System.out.printf(&quot; &quot;); &#125; &#125; public static void main(String[] args) &#123; char[] vexs = &#123;&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;&#125;; char[][] edges = new char[][]&#123; &#123;&#x27;A&#x27;, &#x27;B&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;E&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;F&#x27;&#125;, &#123;&#x27;C&#x27;, &#x27;E&#x27;&#125;, &#123;&#x27;D&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;E&#x27;, &#x27;B&#x27;&#125;, &#123;&#x27;E&#x27;, &#x27;D&#x27;&#125;, &#123;&#x27;F&#x27;, &#x27;G&#x27;&#125;&#125;; MatrixDG pG; // 自定义&quot;图&quot;(输入矩阵队列) //pG = new MatrixDG(); // 采用已有的&quot;图&quot; pG = new MatrixDG(vexs, edges); pG.print(); // 打印图 pG.DFS(); // 深度优先遍历 pG.BFS(); // 广度优先遍历 &#125;&#125; 邻接表实现的有向图123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262import java.io.IOException;import java.util.Scanner;public class ListDG &#123; // 邻接表中表对应的链表的顶点 private class ENode &#123; int ivex; // 该边所指向的顶点的位置 ENode nextEdge; // 指向下一条弧的指针 &#125; // 邻接表中表的顶点 private class VNode &#123; char data; // 顶点信息 ENode firstEdge; // 指向第一条依附该顶点的弧 &#125;; private VNode[] mVexs; // 顶点数组 /* * 创建图(自己输入数据) */ public ListDG() &#123; // 输入&quot;顶点数&quot;和&quot;边数&quot; System.out.printf(&quot;input vertex number: &quot;); int vlen = readInt(); System.out.printf(&quot;input edge number: &quot;); int elen = readInt(); if ( vlen &lt; 1 || elen &lt; 1 || (elen &gt; (vlen*(vlen - 1)))) &#123; System.out.printf(&quot;input error: invalid parameters! &quot;); return ; &#125; // 初始化&quot;顶点&quot; mVexs = new VNode[vlen]; for (int i = 0; i &lt; mVexs.length; i++) &#123; System.out.printf(&quot;vertex(%d): &quot;, i); mVexs[i] = new VNode(); mVexs[i].data = readChar(); mVexs[i].firstEdge = null; &#125; // 初始化&quot;边&quot; //mMatrix = new int[vlen][vlen]; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 System.out.printf(&quot;edge(%d):&quot;, i); char c1 = readChar(); char c2 = readChar(); int p1 = getPosition(c1); int p2 = getPosition(c2); // 初始化node1 ENode node1 = new ENode(); node1.ivex = p2; // 将node1链接到&quot;p1所在链表的末尾&quot; if(mVexs[p1].firstEdge == null) mVexs[p1].firstEdge = node1; else linkLast(mVexs[p1].firstEdge, node1); &#125; &#125; /* * 创建图(用已提供的矩阵) * * 参数说明： * vexs -- 顶点数组 * edges -- 边数组 */ public ListDG(char[] vexs, char[][] edges) &#123; // 初始化&quot;顶点数&quot;和&quot;边数&quot; int vlen = vexs.length; int elen = edges.length; // 初始化&quot;顶点&quot; mVexs = new VNode[vlen]; for (int i = 0; i &lt; mVexs.length; i++) &#123; mVexs[i] = new VNode(); mVexs[i].data = vexs[i]; mVexs[i].firstEdge = null; &#125; // 初始化&quot;边&quot; for (int i = 0; i &lt; elen; i++) &#123; // 读取边的起始顶点和结束顶点 char c1 = edges[i][0]; char c2 = edges[i][1]; // 读取边的起始顶点和结束顶点 int p1 = getPosition(edges[i][0]); int p2 = getPosition(edges[i][1]); // 初始化node1 ENode node1 = new ENode(); node1.ivex = p2; // 将node1链接到&quot;p1所在链表的末尾&quot; if(mVexs[p1].firstEdge == null) mVexs[p1].firstEdge = node1; else linkLast(mVexs[p1].firstEdge, node1); &#125; &#125; /* * 将node节点链接到list的最后 */ private void linkLast(ENode list, ENode node) &#123; ENode p = list; while(p.nextEdge!=null) p = p.nextEdge; p.nextEdge = node; &#125; /* * 返回ch位置 */ private int getPosition(char ch) &#123; for(int i=0; i&lt;mVexs.length; i++) if(mVexs[i].data==ch) return i; return -1; &#125; /* * 读取一个输入字符 */ private char readChar() &#123; char ch=&#x27;0&#x27;; do &#123; try &#123; ch = (char)System.in.read(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; while(!((ch&gt;=&#x27;a&#x27;&amp;&amp;ch&lt;=&#x27;z&#x27;) || (ch&gt;=&#x27;A&#x27;&amp;&amp;ch&lt;=&#x27;Z&#x27;))); return ch; &#125; /* * 读取一个输入字符 */ private int readInt() &#123; Scanner scanner = new Scanner(System.in); return scanner.nextInt(); &#125; /* * 深度优先搜索遍历图的递归实现 */ private void DFS(int i, boolean[] visited) &#123; ENode node; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i].data); node = mVexs[i].firstEdge; while (node != null) &#123; if (!visited[node.ivex]) DFS(node.ivex, visited); node = node.nextEdge; &#125; &#125; /* * 深度优先搜索遍历图 */ public void DFS() &#123; boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 // 初始化所有顶点都没有被访问 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;DFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) DFS(i, visited); &#125; System.out.printf(&quot; &quot;); &#125; /* * 广度优先搜索（类似于树的层次遍历） */ public void BFS() &#123; int head = 0; int rear = 0; int[] queue = new int[mVexs.length]; // 辅组队列 boolean[] visited = new boolean[mVexs.length]; // 顶点访问标记 for (int i = 0; i &lt; mVexs.length; i++) visited[i] = false; System.out.printf(&quot;BFS: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; if (!visited[i]) &#123; visited[i] = true; System.out.printf(&quot;%c &quot;, mVexs[i].data); queue[rear++] = i; // 入队列 &#125; while (head != rear) &#123; int j = queue[head++]; // 出队列 ENode node = mVexs[j].firstEdge; while (node != null) &#123; int k = node.ivex; if (!visited[k]) &#123; visited[k] = true; System.out.printf(&quot;%c &quot;, mVexs[k].data); queue[rear++] = k; &#125; node = node.nextEdge; &#125; &#125; &#125; System.out.printf(&quot; &quot;); &#125; /* * 打印矩阵队列图 */ public void print() &#123; System.out.printf(&quot;List Graph: &quot;); for (int i = 0; i &lt; mVexs.length; i++) &#123; System.out.printf(&quot;%d(%c): &quot;, i, mVexs[i].data); ENode node = mVexs[i].firstEdge; while (node != null) &#123; System.out.printf(&quot;%d(%c) &quot;, node.ivex, mVexs[node.ivex].data); node = node.nextEdge; &#125; System.out.printf(&quot; &quot;); &#125; &#125; public static void main(String[] args) &#123; char[] vexs = &#123;&#x27;A&#x27;, &#x27;B&#x27;, &#x27;C&#x27;, &#x27;D&#x27;, &#x27;E&#x27;, &#x27;F&#x27;, &#x27;G&#x27;&#125;; char[][] edges = new char[][]&#123; &#123;&#x27;A&#x27;, &#x27;B&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;E&#x27;&#125;, &#123;&#x27;B&#x27;, &#x27;F&#x27;&#125;, &#123;&#x27;C&#x27;, &#x27;E&#x27;&#125;, &#123;&#x27;D&#x27;, &#x27;C&#x27;&#125;, &#123;&#x27;E&#x27;, &#x27;B&#x27;&#125;, &#123;&#x27;E&#x27;, &#x27;D&#x27;&#125;, &#123;&#x27;F&#x27;, &#x27;G&#x27;&#125;&#125;; ListDG pG; // 自定义&quot;图&quot;(输入矩阵队列) //pG = new ListDG(); // 采用已有的&quot;图&quot; pG = new ListDG(vexs, edges); pG.print(); // 打印图 pG.DFS(); // 深度优先遍历 pG.BFS(); // 广度优先遍历 &#125;&#125; 参考文章本文主要参考至 https://www.cnblogs.com/skywang12345/p/3711483.html, 在此基础上做了内容的增改。","tags":["数据结构","图","BFS","DFS"],"categories":["数据结构","图"]},{"title":"12.图 - 基础和Overview","path":"/2023/12/27/12-图-基础和Overview/","content":"图的基础 图(Graph)是由顶点和连接顶点的边构成的离散结构。在计算机科学中，图是最灵活的数据结构之一，很多问题都可以使用图模型进行建模求解。例如: 生态环境中不同物种的相互竞争、人与人之间的社交与关系网络、化学上用图区分结构不同但分子式相同的同分异构体、分析计算机网络的拓扑结构确定两台计算机是否可以通信、找到两个城市之间的最短路径等等。 定义图(Graph)是由顶点的有穷非空集合和顶点之间边的集合组成，通常表示为: G(V,E)，其中，G表示一个图，V是图G中顶点的集合，E是图G中边的集合。 和线性表，树的差异: 线性表中我们把数据元素叫元素，树中将数据元素叫结点，在图中数据元素，我们则称之为顶点(Vertex)。 线性表可以没有元素，称为空表；树中可以没有节点，称为空树；但是，在图中不允许没有顶点(有穷非空性)。 线性表中的各元素是线性关系，树中的各元素是层次关系，而图中各顶点的关系是用边来表示(边集可以为空)。 相关术语 顶点的度 顶点Vi的度(Degree)是指在图中与Vi相关联的边的条数。对于有向图来说，有入度(In-degree)和出度(Out-degree)之分，有向图顶点的度等于该顶点的入度和出度之和。 邻接 若无向图中的两个顶点V1和V2存在一条边(V1,V2)，则称顶点V1和V2邻接(Adjacent)； 若有向图中存在一条边&lt;V3,V2&gt;，则称顶点V3与顶点V2邻接，且是V3邻接到V2或V2邻接直V3； 路径 在无向图中，若从顶点Vi出发有一组边可到达顶点Vj，则称顶点Vi到顶点Vj的顶点序列为从顶点Vi到顶点Vj的路径(Path)。 连通 若从Vi到Vj有路径可通，则称顶点Vi和顶点Vj是连通(Connected)的。 权(Weight) 有些图的边或弧具有与它相关的数字，这种与图的边或弧相关的数叫做权(Weight)。 类型无向图如果图中任意两个顶点之间的边都是无向边(简而言之就是没有方向的边)，则称该图为无向图(Undirected graphs)。 无向图中的边使用小括号“()”表示; 比如 (V1,V2); 有向图如果图中任意两个顶点之间的边都是有向边(简而言之就是有方向的边)，则称该图为有向图(Directed graphs)。 有向图中的边使用尖括号“&lt;&gt;”表示; 比如&#x2F;&lt;V1,V2&gt; 完全图 无向完全图: 在无向图中，如果任意两个顶点之间都存在边，则称该图为无向完全图。(含有n个顶点的无向完全图有(n×(n-1))&#x2F;2条边) 有向完全图: 在有向图中，如果任意两个顶点之间都存在方向互为相反的两条弧，则称该图为有向完全图。(含有n个顶点的有向完全图有n×(n-1)条边) 图的存储结构邻接矩阵表示法图的邻接矩阵(Adjacency Matrix)存储方式是用两个数组来表示图。一个一维数组存储图中顶点信息，一个二维数组(称为邻接矩阵)存储图中的边或弧的信息。 无向图: 我们可以设置两个数组，顶点数组为vertex[4]=&#123;v0,v1,v2,v3&#125;，边数组arc[4][4]为上图右边这样的一个矩阵。对于矩阵的主对角线的值，即arc[0][0]、arc[1][1]、arc[2][2]、arc[3][3]，全为0是因为不存在顶点的边。 有向图: 我们再来看一个有向图样例，如下图所示的左边。顶点数组为vertex[4]=&#123;v0,v1,v2,v3&#125;，弧数组arc[4][4]为下图右边这样的一个矩阵。主对角线上数值依然为0。但因为是有向图，所以此矩阵并不对称，比如由v1到v0有弧，得到arc[1][0]=1，而v到v没有弧，因此arc[0][1]=0。 不足: 由于存在n个顶点的图需要n*n个数组元素进行存储，当图为稀疏图时，使用邻接矩阵存储方法将会出现大量0元素，这会造成极大的空间浪费。这时，可以考虑使用邻接表表示法来存储图中的数据 邻接表表示法首先，回忆我们在线性表时谈到，顺序存储结构就存在预先分配内存可能造成存储空间浪费的问题，于是引出了链式存储的结构。同样的，我们也可以考虑对边或弧使用链式存储的方式来避免空间浪费的问题。 邻接表由表头节点和表节点两部分组成，图中每个顶点均对应一个存储在数组中的表头节点。如果这个表头节点所对应的顶点存在邻接节点，则把邻接节点依次存放于表头节点所指向的单向链表中。 无向图 下图所示的就是一个无向图的邻接表结构。 从上图中我们知道，顶点表的各个结点由data和firstedge两个域表示，data是数据域，存储顶点的信息，firstedge是指针域，指向边表的第一个结点，即此顶点的第一个邻接点。边表结点由adjvex和next两个域组成。adjvex是邻接点域，存储某顶点的邻接点在顶点表中的下标，next则存储指向边表中下一个结点的指针。例如: v1顶点与v0、v2互为邻接点，则在v1的边表中，adjvex分别为v0的0和v2的2。 PS: 对于无向图来说，使用邻接表进行存储也会出现数据冗余的现象。例如上图中，顶点V0所指向的链表中存在一个指向顶点V3的同事，顶点V3所指向的链表中也会存在一个指向V0的顶点。 有向图 若是有向图，邻接表结构是类似的，但要注意的是有向图由于有方向的。因此，有向图的邻接表分为出边表和入边表(又称逆邻接表)，出边表的表节点存放的是从表头节点出发的有向边所指的尾节点；入边表的表节点存放的则是指向表头节点的某个顶点，如下图所示。 带权图 对于带权值的网图，可以在边表结点定义中再增加一个weight的数据域，存储权值信息即可，如下图所示。 图相关题目二分图如果可以用两种颜色对图中的节点进行着色，并且保证相邻的节点颜色不同，那么这个图就是二分图。 判断是否为二分图 785. Is Graph Bipartite? (Medium) 123456789Input: [[1,3], [0,2], [1,3], [0,2]]Output: trueExplanation:The graph looks like this:0----1| || |3----2We can divide the vertices into two groups: &#123;0, 2&#125; and &#123;1, 3&#125;. 12345678910Example 2:Input: [[1,2,3], [0,2], [0,1,3], [0,2]]Output: falseExplanation:The graph looks like this:0----1| \\ || \\ |3----2We cannot find a way to divide the set of nodes into two independent subsets. 1234567891011121314151617181920212223public boolean isBipartite(int[][] graph) &#123; int[] colors = new int[graph.length]; Arrays.fill(colors, -1); for (int i = 0; i &lt; graph.length; i++) &#123; // 处理图不是连通的情况 if (colors[i] == -1 &amp;&amp; !isBipartite(i, 0, colors, graph)) &#123; return false; &#125; &#125; return true;&#125;private boolean isBipartite(int curNode, int curColor, int[] colors, int[][] graph) &#123; if (colors[curNode] != -1) &#123; return colors[curNode] == curColor; &#125; colors[curNode] = curColor; for (int nextNode : graph[curNode]) &#123; if (!isBipartite(nextNode, 1 - curColor, colors, graph)) &#123; return false; &#125; &#125; return true;&#125; 拓扑排序常用于在具有先序关系的任务规划中。 课程安排的合法性 207. Course Schedule (Medium) 122, [[1,0]]return true 122, [[1,0],[0,1]]return false 题目描述: 一个课程可能会先修课程，判断给定的先修课程规定是否合法。 本题不需要使用拓扑排序，只需要检测有向图是否存在环即可。 12345678910111213141516171819202122232425262728293031323334353637public boolean canFinish(int numCourses, int[][] prerequisites) &#123; List&lt;Integer&gt;[] graphic = new List[numCourses]; for (int i = 0; i &lt; numCourses; i++) &#123; graphic[i] = new ArrayList&lt;&gt;(); &#125; for (int[] pre : prerequisites) &#123; graphic[pre[0]].add(pre[1]); &#125; boolean[] globalMarked = new boolean[numCourses]; boolean[] localMarked = new boolean[numCourses]; for (int i = 0; i &lt; numCourses; i++) &#123; if (hasCycle(globalMarked, localMarked, graphic, i)) &#123; return false; &#125; &#125; return true;&#125;private boolean hasCycle(boolean[] globalMarked, boolean[] localMarked, List&lt;Integer&gt;[] graphic, int curNode) &#123; if (localMarked[curNode]) &#123; return true; &#125; if (globalMarked[curNode]) &#123; return false; &#125; globalMarked[curNode] = true; localMarked[curNode] = true; for (int nextNode : graphic[curNode]) &#123; if (hasCycle(globalMarked, localMarked, graphic, nextNode)) &#123; return true; &#125; &#125; localMarked[curNode] = false; return false;&#125; 课程安排的顺序 210. Course Schedule II (Medium) 124, [[1,0],[2,0],[3,1],[3,2]]There are a total of 4 courses to take. To take course 3 you should have finished both courses 1 and 2. Both courses 1 and 2 should be taken after you finished course 0. So one correct course order is [0,1,2,3]. Another correct ordering is[0,2,1,3]. 使用 DFS 来实现拓扑排序，使用一个栈存储后序遍历结果，这个栈的逆序结果就是拓扑排序结果。 证明: 对于任何先序关系: v-&gt;w，后序遍历结果可以保证 w 先进入栈中，因此栈的逆序结果中 v 会在 w 之前。 12345678910111213141516171819202122232425262728293031323334353637383940414243public int[] findOrder(int numCourses, int[][] prerequisites) &#123; List&lt;Integer&gt;[] graphic = new List[numCourses]; for (int i = 0; i &lt; numCourses; i++) &#123; graphic[i] = new ArrayList&lt;&gt;(); &#125; for (int[] pre : prerequisites) &#123; graphic[pre[0]].add(pre[1]); &#125; Stack&lt;Integer&gt; postOrder = new Stack&lt;&gt;(); boolean[] globalMarked = new boolean[numCourses]; boolean[] localMarked = new boolean[numCourses]; for (int i = 0; i &lt; numCourses; i++) &#123; if (hasCycle(globalMarked, localMarked, graphic, i, postOrder)) &#123; return new int[0]; &#125; &#125; int[] orders = new int[numCourses]; for (int i = numCourses - 1; i &gt;= 0; i--) &#123; orders[i] = postOrder.pop(); &#125; return orders;&#125;private boolean hasCycle(boolean[] globalMarked, boolean[] localMarked, List&lt;Integer&gt;[] graphic, int curNode, Stack&lt;Integer&gt; postOrder) &#123; if (localMarked[curNode]) &#123; return true; &#125; if (globalMarked[curNode]) &#123; return false; &#125; globalMarked[curNode] = true; localMarked[curNode] = true; for (int nextNode : graphic[curNode]) &#123; if (hasCycle(globalMarked, localMarked, graphic, nextNode, postOrder)) &#123; return true; &#125; &#125; localMarked[curNode] = false; postOrder.push(curNode); return false;&#125; 并查集并查集可以动态地连通两个点，并且可以非常快速地判断两个点是否连通。 冗余连接 684. Redundant Connection (Medium) 123456Input: [[1,2], [1,3], [2,3]]Output: [2,3]Explanation: The given undirected graph will be like this: 1 / \\2 - 3 题目描述: 有一系列的边连成的图，找出一条边，移除它之后该图能够成为一棵树。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public int[] findRedundantConnection(int[][] edges) &#123; int N = edges.length; UF uf = new UF(N); for (int[] e : edges) &#123; int u = e[0], v = e[1]; if (uf.connect(u, v)) &#123; return e; &#125; uf.union(u, v); &#125; return new int[]&#123;-1, -1&#125;;&#125;private class UF &#123; private int[] id; UF(int N) &#123; id = new int[N + 1]; for (int i = 0; i &lt; id.length; i++) &#123; id[i] = i; &#125; &#125; void union(int u, int v) &#123; int uID = find(u); int vID = find(v); if (uID == vID) &#123; return; &#125; for (int i = 0; i &lt; id.length; i++) &#123; if (id[i] == uID) &#123; id[i] = vID; &#125; &#125; &#125; int find(int p) &#123; return id[p]; &#125; boolean connect(int u, int v) &#123; return find(u) == find(v); &#125;&#125;","tags":["数据结构","图"],"categories":["数据结构","图"]},{"title":"11.树 - 前缀树(Trie Tree)","path":"/2023/12/27/11-树-前缀树-Trie-Tree/","content":"Trie，又称字典树、单词查找树或键树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 什么是前缀树在计算机科学中，trie，又称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。与二叉查找树不同，键不是直接保存在节点中，而是由节点在树中的位置决定。一个节点的所有子孙都有相同的前缀，也就是这个节点对应的字符串，而根节点对应空字符串。一般情况下，不是所有的节点都有对应的值，只有叶子节点和部分内部节点所对应的键才有相关的值。 Trie 这个术语来自于 retrieval。根据词源学，trie 的发明者 Edward Fredkin 把它读作&#x2F;ˈtriː&#x2F; “tree”。但是，其他作者把它读作&#x2F;ˈtraɪ&#x2F; “try”。trie 中的键通常是字符串，但也可以是其它的结构。trie 的算法可以很容易地修改为处理其它结构的有序序列，比如一串数字或者形状的排列。比如，bitwise trie 中的键是一串位元，可以用于表示整数或者内存地址。trie 树常用于搜索提示。如当输入一个网址，可以自动搜索出可能的选择。当没有完全匹配的搜索结果，可以返回前缀最相似的可能。 上图是一棵Trie树，表示了关键字集合{“a”, “to”, “tea”, “ted”, “ten”, “i”, “in”, “inn”} 。从上图可以归纳出Trie树的基本性质： 根节点不包含字符，除根节点外的每一个子节点都包含一个字符。 从根节点到某一个节点，路径上经过的字符连接起来，为该节点对应的字符串。 每个节点的所有子节点包含的字符互不相同。 从第一字符开始有连续重复的字符只占用一个节点，比如上面的to，和ten，中重复的单词t只占用了一个节点。 前缀树的实现 重点在于节点数据结构，重要的插入和查找方法，以及递归和非递归两种形式。@pdai 节点数据结构定义Node节点中使用map较为高效，用于映射到下一个节点： 1234567891011121314151617181920212223242526272829303132333435public class Trie &#123; private class Node&#123; public boolean isWord; // 是否是某个单词的结束 public TreeMap&lt;Character, Node&gt; next; //到下一个节点的映射 public Node(boolean isWord)&#123; this.isWord = isWord; //初始化字典树 next = new TreeMap&lt;&gt;(); &#125; public Node()&#123; this(false); &#125; &#125; //根节点 private Node root; //Trie单词个数 private int size; public Trie()&#123; root = new Node(); size = 0; &#125; // 获得Trie中存储的单词数量 public int getSize()&#123; return size; &#125;&#125; 插入方法 非递归方式 向Trie中添加一个新的单词word: 将单词拆分成一个个字符c，然后从根节点开始往下添加 123456789101112131415161718192021public void add(String word)&#123; Node cur = root; //循环判断新的cur节点是否包含下一个字符到下一个节点的映射 for(int i = 0 ; i &lt; word.length() ; i ++)&#123; //将c当成一个节点插入Trie中 char c = word.charAt(i); //判断cur.next是不是已经指向我们要找的c字符相应的节点 if(cur.next.get(c) == null)&#123; //新建节点 cur.next.put(c, new Node()); &#125; //否则，就直接走到该节点位置即可 cur = cur.next.get(c); &#125; //判断该单词并不表示任何一个单词的结尾 if(!cur.isWord)&#123; //确定cur是新的单词 cur.isWord = true; size ++; &#125; 递归方式 12345678910111213141516171819202122232425262728293031323334/** * 向Trie中添加一个新的单词word(递归写法接口) * * @param word */public void recursionAdd(String word) &#123; Node cur = root; add(root, word, 0);&#125;/** * 递归写法调用方法实现递归添加 * * @param node 传入要进行添加的节点 * @param word 传入要进行添加的单词 */public void add(Node node, String word, int index) &#123; // 确定终止条件,这个终止条件在没加index这个参数时,很难确定 // 此时一个单词已经遍历完成了,如果这个结束节点没有标记为单词,就标记为单词 if (!node.isWord &amp;&amp; index == word.length()) &#123; node.isWord = true; size++; &#125; if (word.length() &gt; index) &#123; char addLetter = word.charAt(index); // 判断trie的下个节点组中是否有查询的字符,如果没有,就添加 if (node.next.get(addLetter) == null) &#123; node.next.put(addLetter, new Node()); &#125; // 基于已经存在的字符进行下个字符的递归查询 add(node.next.get(addLetter), word, index + 1); &#125;&#125; 查询单词方法 非递归方式 123456789101112131415161718/** * 查询单词word是否在Trie中(非递归写法) * * @param word * @return */public boolean contains(String word) &#123; Node cur = root; for (int i = 0; i &lt; word.length(); i++) &#123; char c = word.charAt(i); if (cur.next.get(c) == null) &#123; return false; &#125; else &#123; cur = cur.next.get(c); &#125; &#125; return cur.isWord;&#125; 递归方式 123456789101112131415161718192021222324252627282930/** * 查询单词word中是否在Trie中接口(递归写法) * * @param word * @return */public boolean recursionContains(String word) &#123; Node cur = root; return contains(root, word, 0);&#125;/** * 查询word中是否在Trie中递归写法 * * @param node * @param word * @param index * @return */private boolean contains(Node node, String word, int index) &#123; if (index == word.length()) &#123; return node.isWord; &#125; char c = word.charAt(index); if (node.next.get(c) == null) &#123; return false; &#125; else &#123; return contains(node.next.get(c), word, index + 1); &#125;&#125; 查询前缀方法 非递归方式 1234567891011121314151617/** * 查询是否在Trie中有单词一prefix为前缀 * * @param prefix * @return */public boolean isPrefix(String prefix) &#123; Node cur = root; for (int i = 0; i &lt; prefix.length(); i++) &#123; char c = prefix.charAt(i); if (cur.next.get(c) == null) &#123; return false; &#125; cur = cur.next.get(c); &#125; return true;&#125; 递归方式 123456789101112131415161718192021222324252627/** * 查询是否在Trie中有单词一prefix为前缀(递归调用) * * @param prefix * @return */public boolean recursionIsPrefix(String prefix) &#123; Node node = root; return recursionIsPrefix(root, prefix, 0);&#125;/** * 查询是否在Trie中有单词一prefix为前缀(递归实现) * * @return */public boolean recursionIsPrefix(Node root, String prefix, int index) &#123; if (prefix.length() == index) &#123; return true; &#125; char c = prefix.charAt(index); if (root.next.get(c) == null) &#123; return false; &#125; else &#123; return recursionIsPrefix(root.next.get(c), prefix, ++index); &#125;&#125; 前缀树的拓展 再深入理解下前缀树。 前缀树的复杂度设平均查询的query词长n， 白名单m条记录，平均长度k, 简单单词查询：一个query，需要遍历每一个白名单，调用query是否contains方法，contains方法遍历前词，找到头元素一致，再遍历判断尾序列，contains的复杂度是O(n)，整体复杂度是O(mn) 前缀树查询: 一个query，将这个query从头到尾遍历，每个元素在前缀树中判断，操作都是取下一个节点和判断是否是end，时间复杂度是O(1)，整体时间复杂度是O(n) 前缀树有哪些应用这个比较简单，就简单列下： 前缀匹配 字符串检索， 比如 敏感词过滤，黑白名单等 词频统计 字符串排序 前缀树的压缩：基数树在计算机科学中，基数树，或称压缩前缀树，是一种更节省空间的 Trie（前缀树）。对于基数树的每个节点，如果该节点是确定的子树的话，就和父节点合并。基数树可用来构建关联数组。 用于 IP 路由。 信息检索中用于文本文档的倒排索引。 基数树可看做是以二进制位串为关键字的 trie 树，是一种多叉树形结构，同时又类似多层索引表，每个中间节点包含指向多个子节点的指针数组，叶子节点包含指向实际的对象的指针(由于对象不具备树节点结构，因此将其父节点看做叶节点)。基数树也被设计成多道树，以提高磁盘交互性能。同时，基数树也是按照字典序来组织叶节点的，这种特点使之适合持久化改造，加上它的多道特点，灵活性较强，适合作为区块链的基础数据结构，构建持久性区块时较好地映射各类数据集合上。基数树支持插入、删除、查找操作。查找包括完全匹配、前缀匹配、前驱查找、后继查找。所有这些操作都是 O(k)复杂度，其中 k 是所有字符串中最大的长度。 双数组Trie树(DoubleArrayTrie)双数组Trie树(DoubleArrayTrie)是一种空间复杂度低的Trie树，应用于字符区间大的语言（如中文、日文等）分词领域。 双数组Trie (Double-Array Trie)结构由日本人JUN-ICHI AOE于1989年提出的，是Trie结构的压缩形式，仅用两个线性数组来表示Trie树，该结构有效结合了数字搜索树(Digital Search Tree)检索时间高效的特点和链式表示的Trie空间结构紧凑的特点。双数组Trie的本质是一个确定有限状态自动机（DFA），每个节点代表自动机的一个状态，根据变量不同，进行状态转移，当到达结束状态或无法转移时，完成一次查询操作。在双数组所有键中包含的字符之间的联系都是通过简单的数学加法运算表示，不仅提高了检索速度，而且省去了链式结构中使用的大量指针，节省了存储空间。——《基于双数组 Trie 树算法的字典改进和实现》 具体可以看这篇文章 参考文章 https://blog.csdn.net/v_july_v/article/details/6897097 https://www.cnblogs.com/bonelee/p/8830825.html https://blog.csdn.net/forever_dreams/article/details/81009580 https://www.jianshu.com/p/b9b8bf82fcd5 https://bestqiang.blog.csdn.net/article/details/89103524 https://java-sword.blog.csdn.net/article/details/89373156","tags":["数据结构","树","前缀树","Trie Tree"],"categories":["数据结构","树"]},{"title":"10.树 - 哈夫曼树(Huffman Tree)","path":"/2023/12/27/10-树-哈夫曼树-Huffman-Tree/","content":"哈夫曼又称最优二叉树, 是一种带权路径长度最短的二叉树。(注意带权路径WPL是指叶子节点，很多网上的文章有误导) 哈夫曼树相关名词先看一棵哈夫曼树: (哈夫曼树推理是通过叶子节点，所以理解的时候需要忽略非叶子节点，很多文章在这点上有误导) 路径与路径长度: 从树中一个节点到另一个节点之间的分支构成了两个节点之间的路径，路径上的分支数目称作路径长度。若规定根节点位于第一层，则根节点到第H层的节点的路径长度为H-1。如到40 的路径长度为1；30的路径长度为2；20的路径长度为3。 节点的权: 将树中的节点赋予一个某种含义的数值作为该节点的权值，该值称为节点的权； 带权路径长度: 从根节点到某个节点之间的路径长度与该节点的权的乘积。例如上图节点10的路径长度为3,它的带权路径长度为10 * 3 &#x3D; 30； 树的带权路径长度: 树的带权路径长度为所有叶子节点的带权路径长度之和，称为WPL。上图的WPL = 1x40+2x30+3x10+3x20 = 190，而哈夫曼树就是树的带权路径最小的二叉树。 哈夫曼树的构建假设有n个权值，则构造出的哈夫曼树有n个叶子结点。 n个权值分别设为 w1、w2、…、wn，哈夫曼树的构造规则为: 将w1、w2、…，wn看成是有n 棵树的森林(每棵树仅有一个结点)； 在森林中选出根结点的权值最小的两棵树进行合并，作为一棵新树的左、右子树，且新树的根结点权值为其左、右子树根结点权值之和； 从森林中删除选取的两棵树，并将新树加入森林； 重复上面两步，直到森林中只剩一棵树为止，该树即为所求得的哈夫曼树。 上图中，它的叶子节点为{10，20，30，40}，以这4个权值构建哈夫曼树的过程为: 哈夫曼编码为{10，20，30，40}这四个权值构建了哈夫曼编码后，我们可以由如下规则获得它们的哈夫曼编码: 从根节点到每一个叶子节点的路径上，左分支记为0，右分支记为1，将这些0与1连起来即为叶子节点的哈夫曼编码。如下图: (字母)权值 编码 10 100 20 101 30 11 40 0 由此可见，出现频率越高的字母(也即权值越大)，其编码越短。这便使编码之后的字符串的平均长度、期望值降低，从而达到无损压缩数据的目的。 具体流程如下: 哈夫曼树的实现哈夫曼树的重点是如何构造哈夫曼树。本文构造哈夫曼时，用到了”(二叉堆)最小堆”。下面对哈夫曼树进行讲解。 哈夫曼树节点 12345678910111213141516171819202122232425262728293031public class HuffmanNode implements Comparable, Cloneable &#123; protected int key; // 权值 protected HuffmanNode left; // 左孩子 protected HuffmanNode right; // 右孩子 protected HuffmanNode parent; // 父结点 protected HuffmanNode(int key, HuffmanNode left, HuffmanNode right, HuffmanNode parent) &#123; this.key = key; this.left = left; this.right = right; this.parent = parent; &#125; @Override public Object clone() &#123; Object obj=null; try &#123; obj = (HuffmanNode)super.clone();//Object 中的clone()识别出你要复制的是哪一个对象。 &#125; catch(CloneNotSupportedException e) &#123; System.out.println(e.toString()); &#125; return obj; &#125; @Override public int compareTo(Object obj) &#123; return this.key - ((HuffmanNode)obj).key; &#125;&#125; 哈夫曼树 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134import java.util.List;import java.util.ArrayList;import java.util.Collections;public class Huffman &#123;\tprivate HuffmanNode mRoot;\t// 根结点\t/* * 创建Huffman树 * * @param 权值数组 */\tpublic Huffman(int a[]) &#123; HuffmanNode parent = null; MinHeap heap; // 建立数组a对应的最小堆 heap = new MinHeap(a); for(int i=0; i&lt;a.length-1; i++) &#123; HuffmanNode left = heap.dumpFromMinimum(); // 最小节点是左孩子 HuffmanNode right = heap.dumpFromMinimum(); // 其次才是右孩子 // 新建parent节点，左右孩子分别是left/right； // parent的大小是左右孩子之和 parent = new HuffmanNode(left.key+right.key, left, right, null); left.parent = parent; right.parent = parent; // 将parent节点数据拷贝到&quot;最小堆&quot;中 heap.insert(parent); &#125; mRoot = parent; // 销毁最小堆 heap.destroy();\t&#125;\t/* * 前序遍历&quot;Huffman树&quot; */\tprivate void preOrder(HuffmanNode tree) &#123; if(tree != null) &#123; System.out.print(tree.key+&quot; &quot;); preOrder(tree.left); preOrder(tree.right); &#125;\t&#125;\tpublic void preOrder() &#123; preOrder(mRoot);\t&#125;\t/* * 中序遍历&quot;Huffman树&quot; */\tprivate void inOrder(HuffmanNode tree) &#123; if(tree != null) &#123; inOrder(tree.left); System.out.print(tree.key+&quot; &quot;); inOrder(tree.right); &#125;\t&#125;\tpublic void inOrder() &#123; inOrder(mRoot);\t&#125;\t/* * 后序遍历&quot;Huffman树&quot; */\tprivate void postOrder(HuffmanNode tree) &#123; if(tree != null) &#123; postOrder(tree.left); postOrder(tree.right); System.out.print(tree.key+&quot; &quot;); &#125;\t&#125;\tpublic void postOrder() &#123; postOrder(mRoot);\t&#125;\t/* * 销毁Huffman树 */\tprivate void destroy(HuffmanNode tree) &#123; if (tree==null) return ; if (tree.left != null) destroy(tree.left); if (tree.right != null) destroy(tree.right); tree=null;\t&#125;\tpublic void destroy() &#123; destroy(mRoot); mRoot = null;\t&#125;\t/* * 打印&quot;Huffman树&quot; * * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */\tprivate void print(HuffmanNode tree, int key, int direction) &#123; if(tree != null) &#123; if(direction==0)\t// tree是根节点 System.out.printf(&quot;%2d is root &quot;, tree.key); else // tree是分支节点 System.out.printf(&quot;%2d is %2d&#x27;s %6s child &quot;, tree.key, key, direction==1?&quot;right&quot; : &quot;left&quot;); print(tree.left, tree.key, -1); print(tree.right,tree.key, 1); &#125;\t&#125;\tpublic void print() &#123; if (mRoot != null) print(mRoot, mRoot.key, 0);\t&#125;&#125; 最小堆 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136import java.util.ArrayList;import java.util.List;public class MinHeap &#123;\tprivate List&lt;HuffmanNode&gt; mHeap; // 存放堆的数组\t/* * 创建最小堆 * * 参数说明： * a -- 数据所在的数组 */\tprotected MinHeap(int a[]) &#123; mHeap = new ArrayList&lt;HuffmanNode&gt;(); // 初始化数组 for(int i=0; i&lt;a.length; i++) &#123; HuffmanNode node = new HuffmanNode(a[i], null, null, null); mHeap.add(node); &#125; // 从(size/2-1) --&gt; 0逐次遍历。遍历之后，得到的数组实际上是一个最小堆。 for (int i = a.length / 2 - 1; i &gt;= 0; i--) filterdown(i, a.length-1);\t&#125;\t/* * 最小堆的向下调整算法 * * 注：数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。 * * 参数说明： * start -- 被下调节点的起始位置(一般为0，表示从第1个开始) * end -- 截至范围(一般为数组中最后一个元素的索引) */\tprotected void filterdown(int start, int end) &#123; int c = start; // 当前(current)节点的位置 int l = 2*c + 1; // 左(left)孩子的位置 HuffmanNode tmp = mHeap.get(c);\t// 当前(current)节点 while(l &lt;= end) &#123; // &quot;l&quot;是左孩子，&quot;l+1&quot;是右孩子 if(l &lt; end &amp;&amp; (mHeap.get(l).compareTo(mHeap.get(l+1))&gt;0)) l++; // 左右两孩子中选择较小者，即mHeap[l+1] int cmp = tmp.compareTo(mHeap.get(l)); if(cmp &lt;= 0) break; //调整结束 else &#123; mHeap.set(c, mHeap.get(l)); c = l; l = 2*l + 1; &#125; &#125; mHeap.set(c, tmp);\t&#125; /* * 最小堆的向上调整算法(从start开始向上直到0，调整堆) * * 注：数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。 * * 参数说明： * start -- 被上调节点的起始位置(一般为数组中最后一个元素的索引) */\tprotected void filterup(int start) &#123; int c = start; // 当前节点(current)的位置 int p = (c-1)/2; // 父(parent)结点的位置 HuffmanNode tmp = mHeap.get(c);\t// 当前(current)节点 while(c &gt; 0) &#123; int cmp = mHeap.get(p).compareTo(tmp); if(cmp &lt;= 0) break; else &#123; mHeap.set(c, mHeap.get(p)); c = p; p = (p-1)/2; &#125; &#125; mHeap.set(c, tmp);\t&#125; /* * 将node插入到二叉堆中 */\tprotected void insert(HuffmanNode node) &#123; int size = mHeap.size(); mHeap.add(node);\t// 将&quot;数组&quot;插在表尾 filterup(size); // 向上调整堆\t&#125;\t/* * 交换两个HuffmanNode节点的全部数据 */\tprivate void swapNode(int i, int j) &#123; HuffmanNode tmp = mHeap.get(i); mHeap.set(i, mHeap.get(j)); mHeap.set(j, tmp);\t&#125;\t/* * 新建一个节点，并将最小堆中最小节点的数据复制给该节点。 * 然后除最小节点之外的数据重新构造成最小堆。 * * 返回值： * 失败返回null。 */\tprotected HuffmanNode dumpFromMinimum() &#123; int size = mHeap.size(); // 如果&quot;堆&quot;已空，则返回 if(size == 0) return null; // 将&quot;最小节点&quot;克隆一份，将克隆得到的对象赋值给node HuffmanNode node = (HuffmanNode)mHeap.get(0).clone(); // 交换&quot;最小节点&quot;和&quot;最后一个节点&quot; mHeap.set(0, mHeap.get(size-1)); // 删除最后的元素 mHeap.remove(size-1); if (mHeap.size() &gt; 1) filterdown(0, mHeap.size()-1); return node;\t&#125;\t// 销毁最小堆\tprotected void destroy() &#123; mHeap.clear(); mHeap = null;\t&#125;&#125; 哈夫曼树测试1234567891011121314151617181920212223242526272829303132public class HuffmanTest &#123;\tprivate static final int a[]= &#123;5,6,8,7,15&#125;;\tpublic static void main(String[] args) &#123; int i; Huffman tree; System.out.print(&quot;== 添加数组: &quot;); for(i=0; i&lt;a.length; i++) System.out.print(a[i]+&quot; &quot;); // 创建数组a对应的Huffman树 tree = new Huffman(a); System.out.print(&quot; == 前序遍历: &quot;); tree.preOrder(); System.out.print(&quot; == 中序遍历: &quot;); tree.inOrder(); System.out.print(&quot; == 后序遍历: &quot;); tree.postOrder(); System.out.println(); System.out.println(&quot;== 树的详细信息: &quot;); tree.print(); // 销毁二叉树 tree.destroy();\t&#125;&#125; 参考文章 https://www.cnblogs.com/QG-whz/p/5175485.html https://www.cnblogs.com/skywang12345/p/3706833.html http://c.biancheng.net/view/3398.html","tags":["数据结构","树","哈夫曼树","Huffman Tree"],"categories":["数据结构","树"]},{"title":"9.树 - 红黑树(R-B Tree)","path":"/2023/12/27/9-树-红黑树-R-B-Tree/","content":"红黑树（Red Black Tree） 是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组，是平衡二叉树和AVL树的折中。 提示 红黑树的讲解在JDK TreeMap&amp;TreeSet源码解读中有详细的展示 。这里再补充一些其它内容。 为什么要有红黑树我们在上一篇博客认识到了平衡二叉树(AVLTree)，了解到AVL树的性质，其实平衡二叉树最大的作用就是查找,AVL树的查找、插入和删除在平均和最坏情况下都是O(logn)。AVL树的效率就是高在这个地方。如果在AVL树中插入或删除节点后，使得高度之差大于1。此时，AVL树的平衡状态就被破坏，它就不再是一棵二叉树；为了让它重新维持在一个平衡状态，就需要对其进行旋转处理, 那么创建一颗平衡二叉树的成本其实不小. 这个时候就有人开始思考，并且提出了红黑树的理论，那么红黑树到底比AVL树好在哪里? 红黑树与AVL树的比较: 1.AVL树的时间复杂度虽然优于红黑树，但是对于现在的计算机，cpu太快，可以忽略性能差异 2.红黑树的插入删除比AVL树更便于控制操作 3.红黑树整体性能略优于AVL树(红黑树旋转情况少于AVL树) 红黑树的性质: 红黑树是一棵二叉搜索树，它在每个节点增加了一个存储位记录节点的颜色，可以是RED,也可以是BLACK；通过任意一条从根到叶子简单路径上颜色的约束，红黑树保证最长路径不超过最短路径的二倍，因而近似平衡。 具体性质如下: 每个节点颜色不是黑色，就是红色 根节点是黑色的 如果一个节点是红色，那么它的两个子节点就是黑色的(没有连续的红节点) 对于每个节点，从该节点到其后代叶节点的简单路径上，均包含相同数目的黑色节点 应用场景 Java ConcurrentHashMap &amp; TreeMap C++ STL: map &amp; set linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块 epoll在内核中的实现，用红黑树管理事件块 nginx中，用红黑树管理timer等 其它参考 @skywang12345写的红黑树实现 https://www.cnblogs.com/skywang12345/p/3245399.html 30张图带你彻底理解红黑树 https://www.cnblogs.com/kumufengchun/p/11169138.html 浅析红黑树(RBTree)原理及实现 https://blog.csdn.net/tanrui519521/article/details/80980135","tags":["数据结构","树","红黑树","R-B Tree"],"categories":["数据结构","树"]},{"title":"8.树 - 平衡二叉树(AVL)","path":"/2023/12/27/8-树-平衡二叉树-AVL/","content":"平衡二叉树（Balanced Binary Tree）具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等。 最小二叉平衡树的节点的公式如下 F(n)&#x3D;F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 什么是AVL树AVL树是高度平衡的二叉树。它的特点是: AVL树中任何节点的两个子树的高度最大差别为1。 上面的两张图片，左边的是AVL树，它的任何节点的两个子树的高度差别都&lt;&#x3D;1；而右边的不是AVL树，因为7的两颗子树的高度相差为2(以2为根节点的树的高度是3，而以8为根节点的树的高度是1)。 动画效果请参考 AVL Tree AVL树的实现节点节点定义AVLTree是AVL树对应的类，而AVLTreeNode是AVL树节点，它是AVLTree的内部类。AVLTree包含了AVL树的根节点，AVL树的基本操作也定义在AVL树中。AVLTreeNode包括的几个组成对象: key – 是关键字，是用来对AVL树的节点进行排序的。 left – 是左孩子。 right – 是右孩子。 height – 是高度。 1234567891011121314151617181920public class AVLTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private AVLTreeNode&lt;T&gt; mRoot; // 根结点 // AVL树的节点(内部类) class AVLTreeNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; T key; // 关键字(键值) int height; // 高度 AVLTreeNode&lt;T&gt; left; // 左孩子 AVLTreeNode&lt;T&gt; right; // 右孩子 public AVLTreeNode(T key, AVLTreeNode&lt;T&gt; left, AVLTreeNode&lt;T&gt; right) &#123; this.key = key; this.left = left; this.right = right; this.height = 0; &#125; &#125; ......&#125; 树的高度关于高度，有的地方将”空二叉树的高度是-1”，而本文采用维基百科上的定义: 树的高度为最大层次。即空的二叉树的高度是0，非空树的高度等于它的最大层次(根的层次为1，根的子节点为第2层，依次类推)。 12345678910111213/* * 获取树的高度 */private int height(AVLTreeNode&lt;T&gt; tree) &#123; if (tree != null) return tree.height; return 0;&#125;public int height() &#123; return height(mRoot);&#125; 比较大小123456/* * 比较两个值的大小 */private int max(int a, int b) &#123; return a&gt;b ? a : b;&#125; 旋转如果在AVL树中进行插入或删除节点后，可能导致AVL树失去平衡。这种失去平衡的可以概括为4种姿态: LL(左左)，LR(左右)，RR(右右)和RL(右左)。下面给出它们的示意图: 上图中的4棵树都是”失去平衡的AVL树”，从左往右的情况依次是: LL、LR、RL、RR。除了上面的情况之外，还有其它的失去平衡的AVL树，如下图: 上面的两张图都是为了便于理解，而列举的关于”失去平衡的AVL树”的例子。总的来说，AVL树失去平衡时的情况一定是LL、LR、RL、RR这4种之一，它们都由各自的定义: (1) LL: LeftLeft，也称为”左左”。插入或删除一个节点后，根节点的左子树的左子树还有非空子节点，导致”根的左子树的高度”比”根的右子树的高度”大2，导致AVL树失去了平衡。 例如，在上面LL情况中，由于”根节点(8)的左子树(4)的左子树(2)还有非空子节点”，而”根节点(8)的右子树(12)没有子节点”；导致”根节点(8)的左子树(4)高度”比”根节点(8)的右子树(12)”高2。 (2) LR: LeftRight，也称为”左右”。插入或删除一个节点后，根节点的左子树的右子树还有非空子节点，导致”根的左子树的高度”比”根的右子树的高度”大2，导致AVL树失去了平衡。 例如，在上面LR情况中，由于”根节点(8)的左子树(4)的左子树(6)还有非空子节点”，而”根节点(8)的右子树(12)没有子节点”；导致”根节点(8)的左子树(4)高度”比”根节点(8)的右子树(12)”高2。 (3) RL: RightLeft，称为”右左”。插入或删除一个节点后，根节点的右子树的左子树还有非空子节点，导致”根的右子树的高度”比”根的左子树的高度”大2，导致AVL树失去了平衡。 例如，在上面RL情况中，由于”根节点(8)的右子树(12)的左子树(10)还有非空子节点”，而”根节点(8)的左子树(4)没有子节点”；导致”根节点(8)的右子树(12)高度”比”根节点(8)的左子树(4)”高2。 (4) RR: RightRight，称为”右右”。插入或删除一个节点后，根节点的右子树的右子树还有非空子节点，导致”根的右子树的高度”比”根的左子树的高度”大2，导致AVL树失去了平衡。 例如，在上面RR情况中，由于”根节点(8)的右子树(12)的右子树(14)还有非空子节点”，而”根节点(8)的左子树(4)没有子节点”；导致”根节点(8)的右子树(12)高度”比”根节点(8)的左子树(4)”高2。 如果在AVL树中进行插入或删除节点后，可能导致AVL树失去平衡。AVL失去平衡之后，可以通过旋转使其恢复平衡，下面分别介绍”LL(左左)，LR(左右)，RR(右右)和RL(右左)”这4种情况对应的旋转方法。 LL的旋转LL失去平衡的情况，可以通过一次旋转让AVL树恢复平衡。如下图: 图中左边是旋转之前的树，右边是旋转之后的树。从中可以发现，旋转之后的树又变成了AVL树，而且该旋转只需要一次即可完成。 对于LL旋转，你可以这样理解为: LL旋转是围绕”失去平衡的AVL根节点”进行的，也就是节点k2；而且由于是LL情况，即左左情况，就用手抓着”左孩子，即k1”使劲摇。将k1变成根节点，k2变成k1的右子树，”k1的右子树”变成”k2的左子树”。 1234567891011121314151617/* * LL: 左左对应的情况(左单旋转)。 * * 返回值: 旋转后的根节点 */private AVLTreeNode&lt;T&gt; leftLeftRotation(AVLTreeNode&lt;T&gt; k2) &#123; AVLTreeNode&lt;T&gt; k1; k1 = k2.left; k2.left = k1.right; k1.right = k2; k2.height = max( height(k2.left), height(k2.right)) + 1; k1.height = max( height(k1.left), k2.height) + 1; return k1;&#125; RR的旋转理解了LL之后，RR就相当容易理解了。RR是与LL对称的情况！RR恢复平衡的旋转方法如下: 图中左边是旋转之前的树，右边是旋转之后的树。RR旋转也只需要一次即可完成。 1234567891011121314151617/* * RR: 右右对应的情况(右单旋转)。 * * 返回值: 旋转后的根节点 */private AVLTreeNode&lt;T&gt; rightRightRotation(AVLTreeNode&lt;T&gt; k1) &#123; AVLTreeNode&lt;T&gt; k2; k2 = k1.right; k1.right = k2.left; k2.left = k1; k1.height = max( height(k1.left), height(k1.right)) + 1; k2.height = max( height(k2.right), k1.height) + 1; return k2;&#125; LR的旋转LR失去平衡的情况，需要经过两次旋转才能让AVL树恢复平衡。如下图: 第一次旋转是围绕”k1”进行的”RR旋转”，第二次是围绕”k3”进行的”LL旋转”。 12345678910/* * LR: 左右对应的情况(左双旋转)。 * * 返回值: 旋转后的根节点 */private AVLTreeNode&lt;T&gt; leftRightRotation(AVLTreeNode&lt;T&gt; k3) &#123; k3.left = rightRightRotation(k3.left); return leftLeftRotation(k3);&#125; RL的旋转RL是与LR的对称情况！RL恢复平衡的旋转方法如下: 第一次旋转是围绕”k3”进行的”LL旋转”，第二次是围绕”k1”进行的”RR旋转”。 12345678910/* * RL: 右左对应的情况(右双旋转)。 * * 返回值: 旋转后的根节点 */private AVLTreeNode&lt;T&gt; rightLeftRotation(AVLTreeNode&lt;T&gt; k1) &#123; k1.right = leftLeftRotation(k1.right); return rightRightRotation(k1);&#125; 插入插入节点的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * 将结点插入到AVL树中，并返回根节点 * * 参数说明: * tree AVL树的根结点 * key 插入的结点的键值 * 返回值: * 根节点 */private AVLTreeNode&lt;T&gt; insert(AVLTreeNode&lt;T&gt; tree, T key) &#123; if (tree == null) &#123; // 新建节点 tree = new AVLTreeNode&lt;T&gt;(key, null, null); if (tree==null) &#123; System.out.println(&quot;ERROR: create avltree node failed!&quot;); return null; &#125; &#125; else &#123; int cmp = key.compareTo(tree.key); if (cmp &lt; 0) &#123; // 应该将key插入到&quot;tree的左子树&quot;的情况 tree.left = insert(tree.left, key); // 插入节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.left) - height(tree.right) == 2) &#123; if (key.compareTo(tree.left.key) &lt; 0) tree = leftLeftRotation(tree); else tree = leftRightRotation(tree); &#125; &#125; else if (cmp &gt; 0) &#123; // 应该将key插入到&quot;tree的右子树&quot;的情况 tree.right = insert(tree.right, key); // 插入节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.right) - height(tree.left) == 2) &#123; if (key.compareTo(tree.right.key) &gt; 0) tree = rightRightRotation(tree); else tree = rightLeftRotation(tree); &#125; &#125; else &#123; // cmp==0 System.out.println(&quot;添加失败: 不允许添加相同的节点！&quot;); &#125; &#125; tree.height = max( height(tree.left), height(tree.right)) + 1; return tree;&#125;public void insert(T key) &#123; mRoot = insert(mRoot, key);&#125; 删除删除节点的代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/* * 删除结点(z)，返回根节点 * * 参数说明: * tree AVL树的根结点 * z 待删除的结点 * 返回值: * 根节点 */private AVLTreeNode&lt;T&gt; remove(AVLTreeNode&lt;T&gt; tree, AVLTreeNode&lt;T&gt; z) &#123; // 根为空 或者 没有要删除的节点，直接返回null。 if (tree==null || z==null) return null; int cmp = z.key.compareTo(tree.key); if (cmp &lt; 0) &#123; // 待删除的节点在&quot;tree的左子树&quot;中 tree.left = remove(tree.left, z); // 删除节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.right) - height(tree.left) == 2) &#123; AVLTreeNode&lt;T&gt; r = tree.right; if (height(r.left) &gt; height(r.right)) tree = rightLeftRotation(tree); else tree = rightRightRotation(tree); &#125; &#125; else if (cmp &gt; 0) &#123; // 待删除的节点在&quot;tree的右子树&quot;中 tree.right = remove(tree.right, z); // 删除节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.left) - height(tree.right) == 2) &#123; AVLTreeNode&lt;T&gt; l = tree.left; if (height(l.right) &gt; height(l.left)) tree = leftRightRotation(tree); else tree = leftLeftRotation(tree); &#125; &#125; else &#123; // tree是对应要删除的节点。 // tree的左右孩子都非空 if ((tree.left!=null) &amp;&amp; (tree.right!=null)) &#123; if (height(tree.left) &gt; height(tree.right)) &#123; // 如果tree的左子树比右子树高； // 则(01)找出tree的左子树中的最大节点 // (02)将该最大节点的值赋值给tree。 // (03)删除该最大节点。 // 这类似于用&quot;tree的左子树中最大节点&quot;做&quot;tree&quot;的替身； // 采用这种方式的好处是: 删除&quot;tree的左子树中最大节点&quot;之后，AVL树仍然是平衡的。 AVLTreeNode&lt;T&gt; max = maximum(tree.left); tree.key = max.key; tree.left = remove(tree.left, max); &#125; else &#123; // 如果tree的左子树不比右子树高(即它们相等，或右子树比左子树高1) // 则(01)找出tree的右子树中的最小节点 // (02)将该最小节点的值赋值给tree。 // (03)删除该最小节点。 // 这类似于用&quot;tree的右子树中最小节点&quot;做&quot;tree&quot;的替身； // 采用这种方式的好处是: 删除&quot;tree的右子树中最小节点&quot;之后，AVL树仍然是平衡的。 AVLTreeNode&lt;T&gt; min = maximum(tree.right); tree.key = min.key; tree.right = remove(tree.right, min); &#125; &#125; else &#123; AVLTreeNode&lt;T&gt; tmp = tree; tree = (tree.left!=null) ? tree.left : tree.right; tmp = null; &#125; &#125; return tree;&#125;public void remove(T key) &#123; AVLTreeNode&lt;T&gt; z; if ((z = search(mRoot, key)) != null) mRoot = remove(mRoot, z);&#125; AVL树测试 新建AVL树 依次添加”3,2,1,4,5,6,7,16,15,14,13,12,11,10,8,9” 到AVL树中。 添加3,2 添加3,2都不会破坏AVL树的平衡性。 添加1 添加1之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下: 添加4 添加4不会破坏AVL树的平衡性。 添加5 添加5之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下: 添加6 添加6之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下: 添加7 添加7之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下: 添加16 添加16不会破坏AVL树的平衡性。 添加15 添加15之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下: 添加14 添加14之后，AVL树失去平衡(RL)，此时需要对AVL树进行旋转(RL旋转)。旋转过程如下: 添加13 添加13之后，AVL树失去平衡(RR)，此时需要对AVL树进行旋转(RR旋转)。旋转过程如下: 添加12 添加12之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下: 添加11 添加11之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下: 添加10 添加10之后，AVL树失去平衡(LL)，此时需要对AVL树进行旋转(LL旋转)。旋转过程如下: 添加8 添加8不会破坏AVL树的平衡性。 添加9 但是添加9之后，AVL树失去平衡(LR)，此时需要对AVL树进行旋转(LR旋转)。旋转过程如下: 打印树的信息 输出下面树的信息: 123456前序遍历: 7 4 2 1 3 6 5 13 11 9 8 10 12 15 14 16 中序遍历: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 后序遍历: 1 3 2 5 6 4 8 10 9 12 11 14 16 15 13 7 高度: 5最小值: 1最大值: 16 删除节点8 删除操作并不会造成AVL树的不平衡。 删除节点8之后，再打印该AVL树的信息。 12高度: 5中序遍历: 1 2 3 4 5 6 7 9 10 11 12 13 14 15 16 完整实现和测试的代码AVL 完整实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411/** * Java 语言: AVL树 * * @author skywang * @date 2013/11/07 */public class AVLTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private AVLTreeNode&lt;T&gt; mRoot; // 根结点 // AVL树的节点(内部类) class AVLTreeNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; T key; // 关键字(键值) int height; // 高度 AVLTreeNode&lt;T&gt; left; // 左孩子 AVLTreeNode&lt;T&gt; right; // 右孩子 public AVLTreeNode(T key, AVLTreeNode&lt;T&gt; left, AVLTreeNode&lt;T&gt; right) &#123; this.key = key; this.left = left; this.right = right; this.height = 0; &#125; &#125; // 构造函数 public AVLTree() &#123; mRoot = null; &#125; /* * 获取树的高度 */ private int height(AVLTreeNode&lt;T&gt; tree) &#123; if (tree != null) return tree.height; return 0; &#125; public int height() &#123; return height(mRoot); &#125; /* * 比较两个值的大小 */ private int max(int a, int b) &#123; return a&gt;b ? a : b; &#125; /* * 前序遍历&quot;AVL树&quot; */ private void preOrder(AVLTreeNode&lt;T&gt; tree) &#123; if(tree != null) &#123; System.out.print(tree.key+&quot; &quot;); preOrder(tree.left); preOrder(tree.right); &#125; &#125; public void preOrder() &#123; preOrder(mRoot); &#125; /* * 中序遍历&quot;AVL树&quot; */ private void inOrder(AVLTreeNode&lt;T&gt; tree) &#123; if(tree != null) &#123; inOrder(tree.left); System.out.print(tree.key+&quot; &quot;); inOrder(tree.right); &#125; &#125; public void inOrder() &#123; inOrder(mRoot); &#125; /* * 后序遍历&quot;AVL树&quot; */ private void postOrder(AVLTreeNode&lt;T&gt; tree) &#123; if(tree != null) &#123; postOrder(tree.left); postOrder(tree.right); System.out.print(tree.key+&quot; &quot;); &#125; &#125; public void postOrder() &#123; postOrder(mRoot); &#125; /* * (递归实现)查找&quot;AVL树x&quot;中键值为key的节点 */ private AVLTreeNode&lt;T&gt; search(AVLTreeNode&lt;T&gt; x, T key) &#123; if (x==null) return x; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return search(x.left, key); else if (cmp &gt; 0) return search(x.right, key); else return x; &#125; public AVLTreeNode&lt;T&gt; search(T key) &#123; return search(mRoot, key); &#125; /* * (非递归实现)查找&quot;AVL树x&quot;中键值为key的节点 */ private AVLTreeNode&lt;T&gt; iterativeSearch(AVLTreeNode&lt;T&gt; x, T key) &#123; while (x!=null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x; &#125; return x; &#125; public AVLTreeNode&lt;T&gt; iterativeSearch(T key) &#123; return iterativeSearch(mRoot, key); &#125; /* * 查找最小结点: 返回tree为根结点的AVL树的最小结点。 */ private AVLTreeNode&lt;T&gt; minimum(AVLTreeNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.left != null) tree = tree.left; return tree; &#125; public T minimum() &#123; AVLTreeNode&lt;T&gt; p = minimum(mRoot); if (p != null) return p.key; return null; &#125; /* * 查找最大结点: 返回tree为根结点的AVL树的最大结点。 */ private AVLTreeNode&lt;T&gt; maximum(AVLTreeNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.right != null) tree = tree.right; return tree; &#125; public T maximum() &#123; AVLTreeNode&lt;T&gt; p = maximum(mRoot); if (p != null) return p.key; return null; &#125; /* * LL: 左左对应的情况(左单旋转)。 * * 返回值: 旋转后的根节点 */ private AVLTreeNode&lt;T&gt; leftLeftRotation(AVLTreeNode&lt;T&gt; k2) &#123; AVLTreeNode&lt;T&gt; k1; k1 = k2.left; k2.left = k1.right; k1.right = k2; k2.height = max( height(k2.left), height(k2.right)) + 1; k1.height = max( height(k1.left), k2.height) + 1; return k1; &#125; /* * RR: 右右对应的情况(右单旋转)。 * * 返回值: 旋转后的根节点 */ private AVLTreeNode&lt;T&gt; rightRightRotation(AVLTreeNode&lt;T&gt; k1) &#123; AVLTreeNode&lt;T&gt; k2; k2 = k1.right; k1.right = k2.left; k2.left = k1; k1.height = max( height(k1.left), height(k1.right)) + 1; k2.height = max( height(k2.right), k1.height) + 1; return k2; &#125; /* * LR: 左右对应的情况(左双旋转)。 * * 返回值: 旋转后的根节点 */ private AVLTreeNode&lt;T&gt; leftRightRotation(AVLTreeNode&lt;T&gt; k3) &#123; k3.left = rightRightRotation(k3.left); return leftLeftRotation(k3); &#125; /* * RL: 右左对应的情况(右双旋转)。 * * 返回值: 旋转后的根节点 */ private AVLTreeNode&lt;T&gt; rightLeftRotation(AVLTreeNode&lt;T&gt; k1) &#123; k1.right = leftLeftRotation(k1.right); return rightRightRotation(k1); &#125; /* * 将结点插入到AVL树中，并返回根节点 * * 参数说明: * tree AVL树的根结点 * key 插入的结点的键值 * 返回值: * 根节点 */ private AVLTreeNode&lt;T&gt; insert(AVLTreeNode&lt;T&gt; tree, T key) &#123; if (tree == null) &#123; // 新建节点 tree = new AVLTreeNode&lt;T&gt;(key, null, null); if (tree==null) &#123; System.out.println(&quot;ERROR: create avltree node failed!&quot;); return null; &#125; &#125; else &#123; int cmp = key.compareTo(tree.key); if (cmp &lt; 0) &#123; // 应该将key插入到&quot;tree的左子树&quot;的情况 tree.left = insert(tree.left, key); // 插入节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.left) - height(tree.right) == 2) &#123; if (key.compareTo(tree.left.key) &lt; 0) tree = leftLeftRotation(tree); else tree = leftRightRotation(tree); &#125; &#125; else if (cmp &gt; 0) &#123; // 应该将key插入到&quot;tree的右子树&quot;的情况 tree.right = insert(tree.right, key); // 插入节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.right) - height(tree.left) == 2) &#123; if (key.compareTo(tree.right.key) &gt; 0) tree = rightRightRotation(tree); else tree = rightLeftRotation(tree); &#125; &#125; else &#123; // cmp==0 System.out.println(&quot;添加失败: 不允许添加相同的节点！&quot;); &#125; &#125; tree.height = max( height(tree.left), height(tree.right)) + 1; return tree; &#125; public void insert(T key) &#123; mRoot = insert(mRoot, key); &#125; /* * 删除结点(z)，返回根节点 * * 参数说明: * tree AVL树的根结点 * z 待删除的结点 * 返回值: * 根节点 */ private AVLTreeNode&lt;T&gt; remove(AVLTreeNode&lt;T&gt; tree, AVLTreeNode&lt;T&gt; z) &#123; // 根为空 或者 没有要删除的节点，直接返回null。 if (tree==null || z==null) return null; int cmp = z.key.compareTo(tree.key); if (cmp &lt; 0) &#123; // 待删除的节点在&quot;tree的左子树&quot;中 tree.left = remove(tree.left, z); // 删除节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.right) - height(tree.left) == 2) &#123; AVLTreeNode&lt;T&gt; r = tree.right; if (height(r.left) &gt; height(r.right)) tree = rightLeftRotation(tree); else tree = rightRightRotation(tree); &#125; &#125; else if (cmp &gt; 0) &#123; // 待删除的节点在&quot;tree的右子树&quot;中 tree.right = remove(tree.right, z); // 删除节点后，若AVL树失去平衡，则进行相应的调节。 if (height(tree.left) - height(tree.right) == 2) &#123; AVLTreeNode&lt;T&gt; l = tree.left; if (height(l.right) &gt; height(l.left)) tree = leftRightRotation(tree); else tree = leftLeftRotation(tree); &#125; &#125; else &#123; // tree是对应要删除的节点。 // tree的左右孩子都非空 if ((tree.left!=null) &amp;&amp; (tree.right!=null)) &#123; if (height(tree.left) &gt; height(tree.right)) &#123; // 如果tree的左子树比右子树高； // 则(01)找出tree的左子树中的最大节点 // (02)将该最大节点的值赋值给tree。 // (03)删除该最大节点。 // 这类似于用&quot;tree的左子树中最大节点&quot;做&quot;tree&quot;的替身； // 采用这种方式的好处是: 删除&quot;tree的左子树中最大节点&quot;之后，AVL树仍然是平衡的。 AVLTreeNode&lt;T&gt; max = maximum(tree.left); tree.key = max.key; tree.left = remove(tree.left, max); &#125; else &#123; // 如果tree的左子树不比右子树高(即它们相等，或右子树比左子树高1) // 则(01)找出tree的右子树中的最小节点 // (02)将该最小节点的值赋值给tree。 // (03)删除该最小节点。 // 这类似于用&quot;tree的右子树中最小节点&quot;做&quot;tree&quot;的替身； // 采用这种方式的好处是: 删除&quot;tree的右子树中最小节点&quot;之后，AVL树仍然是平衡的。 AVLTreeNode&lt;T&gt; min = minimum(tree.right); tree.key = min.key; tree.right = remove(tree.right, min); &#125; &#125; else &#123; AVLTreeNode&lt;T&gt; tmp = tree; tree = (tree.left!=null) ? tree.left : tree.right; tmp = null; &#125; &#125; tree.height = max(height(tree.left), height(tree.right)) + 1; return tree; &#125; public void remove(T key) &#123; AVLTreeNode&lt;T&gt; z; if ((z = search(mRoot, key)) != null) mRoot = remove(mRoot, z); &#125; /* * 销毁AVL树 */ private void destroy(AVLTreeNode&lt;T&gt; tree) &#123; if (tree==null) return ; if (tree.left != null) destroy(tree.left); if (tree.right != null) destroy(tree.right); tree = null; &#125; public void destroy() &#123; destroy(mRoot); &#125; /* * 打印&quot;二叉查找树&quot; * * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */ private void print(AVLTreeNode&lt;T&gt; tree, T key, int direction) &#123; if(tree != null) &#123; if(direction==0) // tree是根节点 System.out.printf(&quot;%2d is root &quot;, tree.key, key); else // tree是分支节点 System.out.printf(&quot;%2d is %2d&#x27;s %6s child &quot;, tree.key, key, direction==1?&quot;right&quot; : &quot;left&quot;); print(tree.left, tree.key, -1); print(tree.right,tree.key, 1); &#125; &#125; public void print() &#123; if (mRoot != null) print(mRoot, mRoot.key, 0); &#125;&#125; AVL 完整测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * Java 语言: AVL树 * * @author skywang * @date 2013/11/07 */public class AVLTreeTest &#123; private static int arr[]= &#123;3,2,1,4,5,6,7,16,15,14,13,12,11,10,8,9&#125;; public static void main(String[] args) &#123; int i; AVLTree&lt;Integer&gt; tree = new AVLTree&lt;Integer&gt;(); System.out.printf(&quot;== 依次添加: &quot;); for(i=0; i&lt;arr.length; i++) &#123; System.out.printf(&quot;%d &quot;, arr[i]); tree.insert(arr[i]); &#125; System.out.printf(&quot; == 前序遍历: &quot;); tree.preOrder(); System.out.printf(&quot; == 中序遍历: &quot;); tree.inOrder(); System.out.printf(&quot; == 后序遍历: &quot;); tree.postOrder(); System.out.printf(&quot; &quot;); System.out.printf(&quot;== 高度: %d &quot;, tree.height()); System.out.printf(&quot;== 最小值: %d &quot;, tree.minimum()); System.out.printf(&quot;== 最大值: %d &quot;, tree.maximum()); System.out.printf(&quot;== 树的详细信息: &quot;); tree.print(); i = 8; System.out.printf(&quot; == 删除根节点: %d&quot;, i); tree.remove(i); System.out.printf(&quot; == 高度: %d&quot;, tree.height()); System.out.printf(&quot; == 中序遍历: &quot;); tree.inOrder(); System.out.printf(&quot; == 树的详细信息: &quot;); tree.print(); // 销毁二叉树 tree.destroy(); &#125;&#125; 测试结果1234567891011121314151617181920212223242526272829303132333435363738394041424344== 依次添加: 3 2 1 4 5 6 7 16 15 14 13 12 11 10 8 9 == 前序遍历: 7 4 2 1 3 6 5 13 11 9 8 10 12 15 14 16 == 中序遍历: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 == 后序遍历: 1 3 2 5 6 4 8 10 9 12 11 14 16 15 13 7 == 高度: 5== 最小值: 1== 最大值: 16== 树的详细信息: 7 is root 4 is 7&#x27;s left child 2 is 4&#x27;s left child 1 is 2&#x27;s left child 3 is 2&#x27;s right child 6 is 4&#x27;s right child 5 is 6&#x27;s left child13 is 7&#x27;s right child11 is 13&#x27;s left child 9 is 11&#x27;s left child 8 is 9&#x27;s left child10 is 9&#x27;s right child12 is 11&#x27;s right child15 is 13&#x27;s right child14 is 15&#x27;s left child16 is 15&#x27;s right child== 删除根节点: 8== 高度: 5== 中序遍历: 1 2 3 4 5 6 7 9 10 11 12 13 14 15 16 == 树的详细信息: 7 is root 4 is 7&#x27;s left child 2 is 4&#x27;s left child 1 is 2&#x27;s left child 3 is 2&#x27;s right child 6 is 4&#x27;s right child 5 is 6&#x27;s left child13 is 7&#x27;s right child11 is 13&#x27;s left child 9 is 11&#x27;s left child10 is 9&#x27;s right child12 is 11&#x27;s right child15 is 13&#x27;s right child14 is 15&#x27;s left child16 is 15&#x27;s right child 参考文章 本文主要来源于@skywang12345的https://www.cnblogs.com/skywang12345/p/3577479.html，在此基础上重新组织和增加了内容。 其它参考 https://blog.csdn.net/m0_37609579/article/details/99690222","tags":["数据结构","树","平衡二叉树","AVL"],"categories":["数据结构","树"]},{"title":"7.树 - 二叉搜索树(BST)","path":"/2023/12/27/7-树-二叉搜索树-BST/","content":"本文主要介绍 二叉树中最基本的二叉查找树（Binary Search Tree），（又：二叉搜索树，二叉排序树）它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树。 BST的定义在二叉查找树中: 若任意节点的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 任意节点的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 任意节点的左、右子树也分别为二叉查找树。 没有键值相等的节点。 动画效果请参考 BST BST的实现节点BSTree是二叉树，它保存了二叉树的根节点mRoot；mRoot是BSTNode类型，而BSTNode是二叉查找树的节点，它是BSTree的内部类。BSTNode包含二叉查找树的几个基本信息: key – 它是关键字，是用来对二叉查找树的节点进行排序的。 left – 它指向当前节点的左孩子。 right – 它指向当前节点的右孩子。 parent – 它指向当前节点的父结点。 1234567891011121314151617181920public class BSTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private BSTNode&lt;T&gt; mRoot; // 根结点 public class BSTNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; T key; // 关键字(键值) BSTNode&lt;T&gt; left; // 左孩子 BSTNode&lt;T&gt; right; // 右孩子 BSTNode&lt;T&gt; parent; // 父结点 public BSTNode(T key, BSTNode&lt;T&gt; parent, BSTNode&lt;T&gt; left, BSTNode&lt;T&gt; right) &#123; this.key = key; this.parent = parent; this.left = left; this.right = right; &#125; &#125; ......&#125; 遍历这里讲解前序遍历、中序遍历、后序遍历3种方式。 前序遍历若二叉树非空，则执行以下操作: 访问根结点； 先序遍历左子树； 先序遍历右子树。 1234567891011private void preOrder(BSTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; System.out.print(tree.key+&quot; &quot;); preOrder(tree.left); preOrder(tree.right); &#125;&#125;public void preOrder() &#123; preOrder(mRoot);&#125; 中序遍历若二叉树非空，则执行以下操作: 中序遍历左子树； 访问根结点； 中序遍历右子树。 1234567891011private void inOrder(BSTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; inOrder(tree.left); System.out.print(tree.key+&quot; &quot;); inOrder(tree.right); &#125;&#125;public void inOrder() &#123; inOrder(mRoot);&#125; 后序遍历若二叉树非空，则执行以下操作: 后序遍历左子树； 后序遍历右子树； 访问根结点。 123456789101112private void postOrder(BSTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; postOrder(tree.left); postOrder(tree.right); System.out.print(tree.key+&quot; &quot;); &#125;&#125;public void postOrder() &#123; postOrder(mRoot);&#125; 看看下面这颗树的各种遍历方式: 对于上面的二叉树而言， 前序遍历结果: 8 3 1 6 4 7 10 14 13 中序遍历结果: 1 3 4 6 7 8 10 13 14 后序遍历结果: 1 4 7 6 3 13 14 10 8 查找 递归版本的代码 12345678910111213141516171819/* * (递归实现)查找&quot;二叉树x&quot;中键值为key的节点 */private BSTNode&lt;T&gt; search(BSTNode&lt;T&gt; x, T key) &#123; if (x==null) return x; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return search(x.left, key); else if (cmp &gt; 0) return search(x.right, key); else return x;&#125;public BSTNode&lt;T&gt; search(T key) &#123; return search(mRoot, key);&#125; 非递归版本的代码 123456789101112131415161718192021/* * (非递归实现)查找&quot;二叉树x&quot;中键值为key的节点 */private BSTNode&lt;T&gt; iterativeSearch(BSTNode&lt;T&gt; x, T key) &#123; while (x!=null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x; &#125; return x;&#125;public BSTNode&lt;T&gt; iterativeSearch(T key) &#123; return iterativeSearch(mRoot, key);&#125; 最大值和最小值 查找最大结点 12345678910111213141516171819/* * 查找最大结点: 返回tree为根结点的二叉树的最大结点。 */private BSTNode&lt;T&gt; maximum(BSTNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.right != null) tree = tree.right; return tree;&#125;public T maximum() &#123; BSTNode&lt;T&gt; p = maximum(mRoot); if (p != null) return p.key; return null;&#125; 查找最小结点 12345678910111213141516171819/* * 查找最小结点: 返回tree为根结点的二叉树的最小结点。 */private BSTNode&lt;T&gt; minimum(BSTNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.left != null) tree = tree.left; return tree;&#125;public T minimum() &#123; BSTNode&lt;T&gt; p = minimum(mRoot); if (p != null) return p.key; return null;&#125; 前驱和后继节点的前驱: 是该节点的左子树中的最大节点。 节点的后继: 是该节点的右子树中的最小节点。 查找前驱节点 12345678910111213141516171819/* * 找结点(x)的前驱结点。即，查找&quot;二叉树中数据值小于该结点&quot;的&quot;最大结点&quot;。 */public BSTNode&lt;T&gt; predecessor(BSTNode&lt;T&gt; x) &#123; // 如果x存在左孩子，则&quot;x的前驱结点&quot;为 &quot;以其左孩子为根的子树的最大结点&quot;。 if (x.left != null) return maximum(x.left); // 如果x没有左孩子。则x有以下两种可能: // (01) x是&quot;一个右孩子&quot;，则&quot;x的前驱结点&quot;为 &quot;它的父结点&quot;。 // (01) x是&quot;一个左孩子&quot;，则查找&quot;x的最低的父结点，并且该父结点要具有右孩子&quot;，找到的这个&quot;最低的父结点&quot;就是&quot;x的前驱结点&quot;。 BSTNode&lt;T&gt; y = x.parent; while ((y!=null) &amp;&amp; (x==y.left)) &#123; x = y; y = y.parent; &#125; return y;&#125; 查找后继节点 12345678910111213141516171819/* * 找结点(x)的后继结点。即，查找&quot;二叉树中数据值大于该结点&quot;的&quot;最小结点&quot;。 */public BSTNode&lt;T&gt; successor(BSTNode&lt;T&gt; x) &#123; // 如果x存在右孩子，则&quot;x的后继结点&quot;为 &quot;以其右孩子为根的子树的最小结点&quot;。 if (x.right != null) return minimum(x.right); // 如果x没有右孩子。则x有以下两种可能: // (01) x是&quot;一个左孩子&quot;，则&quot;x的后继结点&quot;为 &quot;它的父结点&quot;。 // (02) x是&quot;一个右孩子&quot;，则查找&quot;x的最低的父结点，并且该父结点要具有左孩子&quot;，找到的这个&quot;最低的父结点&quot;就是&quot;x的后继结点&quot;。 BSTNode&lt;T&gt; y = x.parent; while ((y!=null) &amp;&amp; (x==y.right)) &#123; x = y; y = y.parent; &#125; return y;&#125; 插入 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* * 将结点插入到二叉树中 * * 参数说明: * tree 二叉树的 * z 插入的结点 */private void insert(BSTree&lt;T&gt; bst, BSTNode&lt;T&gt; z) &#123; int cmp; BSTNode&lt;T&gt; y = null; BSTNode&lt;T&gt; x = bst.mRoot; // 查找z的插入位置 while (x != null) &#123; y = x; cmp = z.key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else x = x.right; &#125; z.parent = y; if (y==null) bst.mRoot = z; else &#123; cmp = z.key.compareTo(y.key); if (cmp &lt; 0) y.left = z; else y.right = z; &#125;&#125;/* * 新建结点(key)，并将其插入到二叉树中 * * 参数说明: * tree 二叉树的根结点 * key 插入结点的键值 */public void insert(T key) &#123; BSTNode&lt;T&gt; z=new BSTNode&lt;T&gt;(key,null,null,null); // 如果新建结点失败，则返回。 if (z != null) insert(this, z);&#125; 删除 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/* * 删除结点(z)，并返回被删除的结点 * * 参数说明: * bst 二叉树 * z 删除的结点 */private BSTNode&lt;T&gt; remove(BSTree&lt;T&gt; bst, BSTNode&lt;T&gt; z) &#123; BSTNode&lt;T&gt; x=null; BSTNode&lt;T&gt; y=null; if ((z.left == null) || (z.right == null) ) y = z; else y = successor(z); if (y.left != null) x = y.left; else x = y.right; if (x != null) x.parent = y.parent; if (y.parent == null) bst.mRoot = x; else if (y == y.parent.left) y.parent.left = x; else y.parent.right = x; if (y != z) z.key = y.key; return y;&#125;/* * 删除结点(z)，并返回被删除的结点 * * 参数说明: * tree 二叉树的根结点 * z 删除的结点 */public void remove(T key) &#123; BSTNode&lt;T&gt; z, node; if ((z = search(mRoot, key)) != null) if ( (node = remove(this, z)) != null) node = null;&#125; 打印1234567891011121314151617181920212223242526/* * 打印&quot;二叉查找树&quot; * * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */private void print(BSTNode&lt;T&gt; tree, T key, int direction) &#123; if(tree != null) &#123; if(direction==0) // tree是根节点 System.out.printf(&quot;%2d is root &quot;, tree.key); else // tree是分支节点 System.out.printf(&quot;%2d is %2d&#x27;s %6s child &quot;, tree.key, key, direction==1?&quot;right&quot; : &quot;left&quot;); print(tree.left, tree.key, -1); print(tree.right,tree.key, 1); &#125;&#125;public void print() &#123; if (mRoot != null) print(mRoot, mRoot.key, 0);&#125; 销毁12345678910111213141516171819/* * 销毁二叉树 */private void destroy(BSTNode&lt;T&gt; tree) &#123; if (tree==null) return ; if (tree.left != null) destroy(tree.left); if (tree.right != null) destroy(tree.right); tree=null;&#125;public void clear() &#123; destroy(mRoot); mRoot = null;&#125; 测试程序下面对测试程序的流程进行分析！ 新建”二叉查找树”root。 向二叉查找树中依次插入1,5,4,3,2,6 。如下图所示: 遍历和查找 插入1,5,4,3,2,6之后，得到的二叉查找树如下: 1234前序遍历结果: 1 5 4 3 2 6 中序遍历结果: 1 2 3 4 5 6 后序遍历结果: 2 3 4 6 5 1 最小值是1，而最大值是6。 删除节点4。如下图所示: 重新遍历该二叉查找树。 中序遍历结果: 1 2 4 5 6 代码和测试代码代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355/** * Java 语言: 二叉查找树 * * @author skywang * @date 2013/11/07 */public class BSTree&lt;T extends Comparable&lt;T&gt;&gt; &#123; private BSTNode&lt;T&gt; mRoot; // 根结点 public class BSTNode&lt;T extends Comparable&lt;T&gt;&gt; &#123; T key; // 关键字(键值) BSTNode&lt;T&gt; left; // 左孩子 BSTNode&lt;T&gt; right; // 右孩子 BSTNode&lt;T&gt; parent; // 父结点 public BSTNode(T key, BSTNode&lt;T&gt; parent, BSTNode&lt;T&gt; left, BSTNode&lt;T&gt; right) &#123; this.key = key; this.parent = parent; this.left = left; this.right = right; &#125; public T getKey() &#123; return key; &#125; public String toString() &#123; return &quot;key:&quot;+key; &#125; &#125; public BSTree() &#123; mRoot=null; &#125; /* * 前序遍历&quot;二叉树&quot; */ private void preOrder(BSTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; System.out.print(tree.key+&quot; &quot;); preOrder(tree.left); preOrder(tree.right); &#125; &#125; public void preOrder() &#123; preOrder(mRoot); &#125; /* * 中序遍历&quot;二叉树&quot; */ private void inOrder(BSTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; inOrder(tree.left); System.out.print(tree.key+&quot; &quot;); inOrder(tree.right); &#125; &#125; public void inOrder() &#123; inOrder(mRoot); &#125; /* * 后序遍历&quot;二叉树&quot; */ private void postOrder(BSTNode&lt;T&gt; tree) &#123; if(tree != null) &#123; postOrder(tree.left); postOrder(tree.right); System.out.print(tree.key+&quot; &quot;); &#125; &#125; public void postOrder() &#123; postOrder(mRoot); &#125; /* * (递归实现)查找&quot;二叉树x&quot;中键值为key的节点 */ private BSTNode&lt;T&gt; search(BSTNode&lt;T&gt; x, T key) &#123; if (x==null) return x; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return search(x.left, key); else if (cmp &gt; 0) return search(x.right, key); else return x; &#125; public BSTNode&lt;T&gt; search(T key) &#123; return search(mRoot, key); &#125; /* * (非递归实现)查找&quot;二叉树x&quot;中键值为key的节点 */ private BSTNode&lt;T&gt; iterativeSearch(BSTNode&lt;T&gt; x, T key) &#123; while (x!=null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x; &#125; return x; &#125; public BSTNode&lt;T&gt; iterativeSearch(T key) &#123; return iterativeSearch(mRoot, key); &#125; /* * 查找最小结点: 返回tree为根结点的二叉树的最小结点。 */ private BSTNode&lt;T&gt; minimum(BSTNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.left != null) tree = tree.left; return tree; &#125; public T minimum() &#123; BSTNode&lt;T&gt; p = minimum(mRoot); if (p != null) return p.key; return null; &#125; /* * 查找最大结点: 返回tree为根结点的二叉树的最大结点。 */ private BSTNode&lt;T&gt; maximum(BSTNode&lt;T&gt; tree) &#123; if (tree == null) return null; while(tree.right != null) tree = tree.right; return tree; &#125; public T maximum() &#123; BSTNode&lt;T&gt; p = maximum(mRoot); if (p != null) return p.key; return null; &#125; /* * 找结点(x)的后继结点。即，查找&quot;二叉树中数据值大于该结点&quot;的&quot;最小结点&quot;。 */ public BSTNode&lt;T&gt; successor(BSTNode&lt;T&gt; x) &#123; // 如果x存在右孩子，则&quot;x的后继结点&quot;为 &quot;以其右孩子为根的子树的最小结点&quot;。 if (x.right != null) return minimum(x.right); // 如果x没有右孩子。则x有以下两种可能: // (01) x是&quot;一个左孩子&quot;，则&quot;x的后继结点&quot;为 &quot;它的父结点&quot;。 // (02) x是&quot;一个右孩子&quot;，则查找&quot;x的最低的父结点，并且该父结点要具有左孩子&quot;，找到的这个&quot;最低的父结点&quot;就是&quot;x的后继结点&quot;。 BSTNode&lt;T&gt; y = x.parent; while ((y!=null) &amp;&amp; (x==y.right)) &#123; x = y; y = y.parent; &#125; return y; &#125; /* * 找结点(x)的前驱结点。即，查找&quot;二叉树中数据值小于该结点&quot;的&quot;最大结点&quot;。 */ public BSTNode&lt;T&gt; predecessor(BSTNode&lt;T&gt; x) &#123; // 如果x存在左孩子，则&quot;x的前驱结点&quot;为 &quot;以其左孩子为根的子树的最大结点&quot;。 if (x.left != null) return maximum(x.left); // 如果x没有左孩子。则x有以下两种可能: // (01) x是&quot;一个右孩子&quot;，则&quot;x的前驱结点&quot;为 &quot;它的父结点&quot;。 // (01) x是&quot;一个左孩子&quot;，则查找&quot;x的最低的父结点，并且该父结点要具有右孩子&quot;，找到的这个&quot;最低的父结点&quot;就是&quot;x的前驱结点&quot;。 BSTNode&lt;T&gt; y = x.parent; while ((y!=null) &amp;&amp; (x==y.left)) &#123; x = y; y = y.parent; &#125; return y; &#125; /* * 将结点插入到二叉树中 * * 参数说明: * tree 二叉树的 * z 插入的结点 */ private void insert(BSTree&lt;T&gt; bst, BSTNode&lt;T&gt; z) &#123; int cmp; BSTNode&lt;T&gt; y = null; BSTNode&lt;T&gt; x = bst.mRoot; // 查找z的插入位置 while (x != null) &#123; y = x; cmp = z.key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else x = x.right; &#125; z.parent = y; if (y==null) bst.mRoot = z; else &#123; cmp = z.key.compareTo(y.key); if (cmp &lt; 0) y.left = z; else y.right = z; &#125; &#125; /* * 新建结点(key)，并将其插入到二叉树中 * * 参数说明: * tree 二叉树的根结点 * key 插入结点的键值 */ public void insert(T key) &#123; BSTNode&lt;T&gt; z=new BSTNode&lt;T&gt;(key,null,null,null); // 如果新建结点失败，则返回。 if (z != null) insert(this, z); &#125; /* * 删除结点(z)，并返回被删除的结点 * * 参数说明: * bst 二叉树 * z 删除的结点 */ private BSTNode&lt;T&gt; remove(BSTree&lt;T&gt; bst, BSTNode&lt;T&gt; z) &#123; BSTNode&lt;T&gt; x=null; BSTNode&lt;T&gt; y=null; if ((z.left == null) || (z.right == null) ) y = z; else y = successor(z); if (y.left != null) x = y.left; else x = y.right; if (x != null) x.parent = y.parent; if (y.parent == null) bst.mRoot = x; else if (y == y.parent.left) y.parent.left = x; else y.parent.right = x; if (y != z) z.key = y.key; return y; &#125; /* * 删除结点(z)，并返回被删除的结点 * * 参数说明: * tree 二叉树的根结点 * z 删除的结点 */ public void remove(T key) &#123; BSTNode&lt;T&gt; z, node; if ((z = search(mRoot, key)) != null) if ( (node = remove(this, z)) != null) node = null; &#125; /* * 销毁二叉树 */ private void destroy(BSTNode&lt;T&gt; tree) &#123; if (tree==null) return ; if (tree.left != null) destroy(tree.left); if (tree.right != null) destroy(tree.right); tree=null; &#125; public void clear() &#123; destroy(mRoot); mRoot = null; &#125; /* * 打印&quot;二叉查找树&quot; * * key -- 节点的键值 * direction -- 0，表示该节点是根节点; * -1，表示该节点是它的父结点的左孩子; * 1，表示该节点是它的父结点的右孩子。 */ private void print(BSTNode&lt;T&gt; tree, T key, int direction) &#123; if(tree != null) &#123; if(direction==0) // tree是根节点 System.out.printf(&quot;%2d is root &quot;, tree.key); else // tree是分支节点 System.out.printf(&quot;%2d is %2d&#x27;s %6s child &quot;, tree.key, key, direction==1?&quot;right&quot; : &quot;left&quot;); print(tree.left, tree.key, -1); print(tree.right,tree.key, 1); &#125; &#125; public void print() &#123; if (mRoot != null) print(mRoot, mRoot.key, 0); &#125;&#125; 测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * Java 语言: 二叉查找树 * * @author skywang * @date 2013/11/07 */public class BSTreeTest &#123; private static final int arr[] = &#123;1,5,4,3,2,6&#125;; public static void main(String[] args) &#123; int i, ilen; BSTree&lt;Integer&gt; tree=new BSTree&lt;Integer&gt;(); System.out.print(&quot;== 依次添加: &quot;); ilen = arr.length; for(i=0; i&lt;ilen; i++) &#123; System.out.print(arr[i]+&quot; &quot;); tree.insert(arr[i]); &#125; System.out.print(&quot; == 前序遍历: &quot;); tree.preOrder(); System.out.print(&quot; == 中序遍历: &quot;); tree.inOrder(); System.out.print(&quot; == 后序遍历: &quot;); tree.postOrder(); System.out.println(); System.out.println(&quot;== 最小值: &quot;+ tree.minimum()); System.out.println(&quot;== 最大值: &quot;+ tree.maximum()); System.out.println(&quot;== 树的详细信息: &quot;); tree.print(); System.out.print(&quot; == 删除根节点: &quot;+ arr[3]); tree.remove(arr[3]); System.out.print(&quot; == 中序遍历: &quot;); tree.inOrder(); System.out.println(); // 销毁二叉树 tree.clear(); &#125;&#125; 测试结果12345678910111213141516== 依次添加: 1 5 4 3 2 6 == 前序遍历: 1 5 4 3 2 6 == 中序遍历: 1 2 3 4 5 6 == 后序遍历: 2 3 4 6 5 1 == 最小值: 1== 最大值: 6== 树的详细信息: is rootis 1&#x27;s right childis 5&#x27;s left childis 4&#x27;s left childis 3&#x27;s left childis 5&#x27;s right child== 删除根节点: 3== 中序遍历: 1 2 4 5 6 BST相关题目二叉查找树(BST): 根节点大于等于左子树所有节点，小于等于右子树所有节点。 二叉查找树中序遍历有序。 修剪二叉查找树 669. Trim a Binary Search Tree (Easy) 1234567891011121314151617181920Input: 3 / \\ 0 4 \\ 2 / 1 L = 1 R = 3Output: 3 / 2 / 1 题目描述: 只保留值在 L ~ R 之间的节点 12345678public TreeNode trimBST(TreeNode root, int L, int R) &#123; if (root == null) return null; if (root.val &gt; R) return trimBST(root.left, L, R); if (root.val &lt; L) return trimBST(root.right, L, R); root.left = trimBST(root.left, L, R); root.right = trimBST(root.right, L, R); return root;&#125; 寻找二叉查找树的第 k 个元素 230. Kth Smallest Element in a BST (Medium) 中序遍历解法: 123456789101112131415161718private int cnt = 0;private int val;public int kthSmallest(TreeNode root, int k) &#123; inOrder(root, k); return val;&#125;private void inOrder(TreeNode node, int k) &#123; if (node == null) return; inOrder(node.left, k); cnt++; if (cnt == k) &#123; val = node.val; return; &#125; inOrder(node.right, k);&#125; 递归解法: 1234567891011public int kthSmallest(TreeNode root, int k) &#123; int leftCnt = count(root.left); if (leftCnt == k - 1) return root.val; if (leftCnt &gt; k - 1) return kthSmallest(root.left, k); return kthSmallest(root.right, k - leftCnt - 1);&#125;private int count(TreeNode node) &#123; if (node == null) return 0; return 1 + count(node.left) + count(node.right);&#125; 把二叉查找树每个节点的值都加上比它大的节点的值 Convert BST to Greater Tree (Easy) 1234567891011Input: The root of a Binary Search Tree like this: 5 / \\ 2 13Output: The root of a Greater Tree like this: 18 / \\ 20 13 先遍历右子树。 1234567891011121314private int sum = 0;public TreeNode convertBST(TreeNode root) &#123; traver(root); return root;&#125;private void traver(TreeNode node) &#123; if (node == null) return; traver(node.right); sum += node.val; node.val = sum; traver(node.left);&#125; 二叉查找树的最近公共祖先 235. Lowest Common Ancestor of a Binary Search Tree (Easy) 1234567891011121314 _______6______ / \\ ___2__ ___8__ / \\ / \\0 4 7 9 / \\ 3 5For example, the lowest common ancestor (LCA) of nodes 2 and 8 is 6. Another example is LCA of nodes 2 and 4 is 2, since a node can be a descendant of itself according to the LCA definition.public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if (root.val &gt; p.val &amp;&amp; root.val &gt; q.val) return lowestCommonAncestor(root.left, p, q); if (root.val &lt; p.val &amp;&amp; root.val &lt; q.val) return lowestCommonAncestor(root.right, p, q); return root;&#125; 二叉树的最近公共祖先 236. Lowest Common Ancestor of a Binary Tree (Medium) 123456789101112131415 _______3______ / \\ ___5__ ___1__ / \\ / \\6 2 0 8 / \\ 7 4For example, the lowest common ancestor (LCA) of nodes 5 and 1 is 3. Another example is LCA of nodes 5 and 4 is 5, since a node can be a descendant of itself according to the LCA definition.public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if (root == null || root == p || root == q) return root; TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); return left == null ? right : right == null ? left : root;&#125; 从有序数组中构造二叉查找树 108. Convert Sorted Array to Binary Search Tree (Easy) 123456789101112public TreeNode sortedArrayToBST(int[] nums) &#123; return toBST(nums, 0, nums.length - 1);&#125;private TreeNode toBST(int[] nums, int sIdx, int eIdx)&#123; if (sIdx &gt; eIdx) return null; int mIdx = (sIdx + eIdx) / 2; TreeNode root = new TreeNode(nums[mIdx]); root.left = toBST(nums, sIdx, mIdx - 1); root.right = toBST(nums, mIdx + 1, eIdx); return root;&#125; 根据有序链表构造平衡的二叉查找树 109. Convert Sorted List to Binary Search Tree (Medium) 12345678910111213141516171819202122232425262728293031Given the sorted linked list: [-10,-3,0,5,9],One possible answer is: [0,-3,9,-10,null,5], which represents the following height balanced BST: 0 / \\ -3 9 / / -10 5public TreeNode sortedListToBST(ListNode head) &#123; if (head == null) return null; if (head.next == null) return new TreeNode(head.val); ListNode preMid = preMid(head); ListNode mid = preMid.next; preMid.next = null; // 断开链表 TreeNode t = new TreeNode(mid.val); t.left = sortedListToBST(head); t.right = sortedListToBST(mid.next); return t;&#125;private ListNode preMid(ListNode head) &#123; ListNode slow = head, fast = head.next; ListNode pre = head; while (fast != null &amp;&amp; fast.next != null) &#123; pre = slow; slow = slow.next; fast = fast.next.next; &#125; return pre;&#125; 在二叉查找树中寻找两个节点，使它们的和为一个给定值 653. Two Sum IV - Input is a BST (Easy) 1234567891011Input: 5 / \\ 3 6 / \\ \\2 4 7Target = 9Output: True 使用中序遍历得到有序数组之后，再利用双指针对数组进行查找。 应该注意到，这一题不能用分别在左右子树两部分来处理这种思想，因为两个待求的节点可能分别在左右子树中。 12345678910111213141516171819public boolean findTarget(TreeNode root, int k) &#123; List&lt;Integer&gt; nums = new ArrayList&lt;&gt;(); inOrder(root, nums); int i = 0, j = nums.size() - 1; while (i &lt; j) &#123; int sum = nums.get(i) + nums.get(j); if (sum == k) return true; if (sum &lt; k) i++; else j--; &#125; return false;&#125;private void inOrder(TreeNode root, List&lt;Integer&gt; nums) &#123; if (root == null) return; inOrder(root.left, nums); nums.add(root.val); inOrder(root.right, nums);&#125; 在二叉查找树中查找两个节点之差的最小绝对值 530. Minimum Absolute Difference in BST (Easy) 1234567891011Input: 1 \\ 3 / 2Output:1 利用二叉查找树的中序遍历为有序的性质，计算中序遍历中临近的两个节点之差的绝对值，取最小值。 123456789101112131415private int minDiff = Integer.MAX_VALUE;private TreeNode preNode = null;public int getMinimumDifference(TreeNode root) &#123; inOrder(root); return minDiff;&#125;private void inOrder(TreeNode node) &#123; if (node == null) return; inOrder(node.left); if (preNode != null) minDiff = Math.min(minDiff, node.val - preNode.val); preNode = node; inOrder(node.right);&#125; 寻找二叉查找树中出现次数最多的值 501. Find Mode in Binary Search Tree (Easy) 1234567 1 \\ 2 / 2return [2]. 答案可能不止一个，也就是有多个值出现的次数一样多。 1234567891011121314151617181920212223242526272829303132private int curCnt = 1;private int maxCnt = 1;private TreeNode preNode = null;public int[] findMode(TreeNode root) &#123; List&lt;Integer&gt; maxCntNums = new ArrayList&lt;&gt;(); inOrder(root, maxCntNums); int[] ret = new int[maxCntNums.size()]; int idx = 0; for (int num : maxCntNums) &#123; ret[idx++] = num; &#125; return ret;&#125;private void inOrder(TreeNode node, List&lt;Integer&gt; nums) &#123; if (node == null) return; inOrder(node.left, nums); if (preNode != null) &#123; if (preNode.val == node.val) curCnt++; else curCnt = 1; &#125; if (curCnt &gt; maxCnt) &#123; maxCnt = curCnt; nums.clear(); nums.add(node.val); &#125; else if (curCnt == maxCnt) &#123; nums.add(node.val); &#125; preNode = node; inOrder(node.right, nums);&#125; 参考文章 本文主要来源于@skywang12345的https://www.cnblogs.com/skywang12345/p/3576452.html，在此基础上重新组织和增加了内容。 http://www.sohu.com/a/113502963_464041 https://www.cnblogs.com/QG-whz/p/5168620.html https://blog.csdn.net/isea533/article/details/80345507","tags":["数据结构","树","二叉树"],"categories":["数据结构","树","二叉树"]},{"title":"6.树 - 基础和Overview","path":"/2023/12/27/6-树-基础和Overview/","content":"树在数据结构中至关重要，这里展示树的整体知识体系结构和几种常见树类型。 知识体系结构 树树是一种数据结构，它是n(n&gt;&#x3D;0)个节点的有限集。n&#x3D;0时称为空树。n&gt;0时，有限集的元素构成一个具有层次感的数据结构。 区别于线性表一对一的元素关系，树中的节点是一对多的关系。树具有以下特点: n&gt;0时，根节点是唯一的，不可能存在多个根节点。 每个节点有零个至多个子节点；除了根节点外，每个节点有且仅有一个父节点。根节点没有父节点。 树的相关概念树有许多相关的术语与概念，在学习树的结构之前，我们要熟悉这些概念。 子树: 除了根节点外，每个子节点都可以分为多个不相交的子树。(图二) 孩子与双亲: 若一个结点有子树，那么该结点称为子树根的”双亲”，子树的根是该结点的”孩子”。在图一中，B、H是A的孩子，A是B、H的双亲。 兄弟: 具有相同双亲的节点互为兄弟，例如B与H互为兄弟。 节点的度: 一个节点拥有子树的数目。例如A的度为2，B的度为1，C的度为3. 叶子: 没有子树，也即是度为0的节点。 分支节点: 除了叶子节点之外的节点，也即是度不为0的节点。 内部节点: 除了根节点之外的分支节点。 层次: 根节点为第一层，其余节点的层次等于其双亲节点的层次加1. 树的高度: 也称为树的深度，树中节点的最大层次。 有序树: 树中节点各子树之间的次序是重要的，不可以随意交换位置。 无序树: 树种节点各子树之间的次序是不重要的。可以随意交换位置。 森林: 0或多棵互不相交的树的集合。例如图二中的两棵树为森林。 二叉树、完全二叉树、满二叉树 二叉树: 最多有两棵子树的树被称为二叉树 斜树: 所有节点都只有左子树的二叉树叫做左斜树，所有节点都只有右子树的二叉树叫做右斜树。(本质就是链表) 满二叉树: 二叉树中所有非叶子结点的度都是2，且叶子结点都在同一层次上 完全二叉树: 如果一个二叉树与满二叉树前m个节点的结构相同，这样的二叉树被称为完全二叉树 二叉查找树 - BST二叉查找树(Binary Search Tree)是指一棵空树或者具有下列性质的二叉树: 若任意节点的左子树不空，则左子树上所有节点的值均小于它的根节点的值； 若任意节点的右子树不空，则右子树上所有节点的值均大于它的根节点的值； 任意节点的左、右子树也分别为二叉查找树； 没有键值相等的节点。 二叉查找树相比于其他数据结构的优势在于查找、插入的时间复杂度较低为 O ( log ⁡ n ) 。二叉查找树是基础性数据结构，用于构建更为抽象的数据结构，如集合、多重集、关联数组等。 平衡二叉树 - AVL含有相同节点的二叉查找树可以有不同的形态，而二叉查找树的平均查找长度与树的深度有关，所以需要找出一个查找平均长度最小的一棵，那就是平衡二叉树，具有以下性质: 要么是棵空树，要么其根节点左右子树的深度之差的绝对值不超过1； 其左右子树也都是平衡二叉树； 二叉树节点的平衡因子定义为该节点的左子树的深度减去右子树的深度。则平衡二叉树的所有节点的平衡因子只可能是-1,0,1。 红黑树红黑树也是一种自平衡的二叉查找树。 每个结点要么是红的要么是黑的。(红或黑) 根结点是黑的。 (根黑) 每个叶结点(叶结点即指树尾端NIL指针或NULL结点)都是黑的。 (叶黑) 如果一个结点是红的，那么它的两个儿子都是黑的。 (红子黑) 对于任意结点而言，其到叶结点树尾端NIL指针的每条路径都包含相同数目的黑结点。(路径下黑相同) 用法最广: Java ConcurrentHashMap &amp; TreeMap C++ STL: map &amp; set linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块 epoll在内核中的实现，用红黑树管理事件块 nginx中，用红黑树管理timer等 哈弗曼树哈夫曼又称最优二叉树。是一种带权路径长度最短的二叉树，一般可以按下面步骤构建: 将所有左，右子树都为空的作为根节点。 在森林中选出两棵根节点的权值最小的树作为一棵新树的左，右子树，且置新树的附加根节点的权值为其左，右子树上根节点的权值之和。注意，左子树的权值应小于右子树的权值。 从森林中删除这两棵树，同时把新树加入到森林中。 重复2，3步骤，直到森林中只有一棵树为止，此树便是哈夫曼树。 B树B树(英语: B-tree)是一种自平衡的树，能够保持数据有序。这种数据结构能够让查找数据、顺序访问、插入数据及删除的动作，都在对数时间内完成。B树，概括来说是一种自平衡的m阶树，与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。 根结点至少有两个子女。 每个中间节点都包含k-1个元素和k个孩子，其中 m&#x2F;2 &lt;&#x3D; k &lt;&#x3D; m 每一个叶子节点都包含k-1个元素，其中 m&#x2F;2 &lt;&#x3D; k &lt;&#x3D; m 所有的叶子结点都位于同一层。 每个节点中的元素从小到大排列，节点当中k-1个元素正好是k个孩子包含的元素的值域分划。 B-Tree中的每个节点根据实际情况可以包含大量的关键字信息和分支，如下图所示为一个3阶的B-Tree: B+树B+ 树是一种树数据结构，通常用于关系型数据库(如Mysql)和操作系统的文件系统中。B+ 树的特点是能够保持数据稳定有序，其插入与修改拥有较稳定的对数时间复杂度。B+ 树元素自底向上插入，这与二叉树恰好相反。 在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。 b+树的非叶子节点不保存数据，只保存子树的临界值(最大或者最小)，所以同样大小的节点，b+树相对于b树能够有更多的分支，使得这棵树更加矮胖，查询时做的IO操作次数也更少。 将上一节中的B-Tree优化，由于B+Tree的非叶子节点只存储键值信息，假设每个磁盘块能存储4个键值及指针信息，则变成B+Tree后其结构如下图所示: R树R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 R树的核心思想是聚合距离相近的节点并在树结构的上一层将其表示为这些节点的最小外接矩形(MBR)，这个最小外接矩形就成为上一层的一个节点。因为所有节点都在它们的最小外接矩形中，所以跟某个矩形不相交的查询就一定跟这个矩形中的所有节点都不相交。叶子节点上的每个矩形都代表一个对象，节点都是对象的聚合，并且越往上层聚合的对象就越多。也可以把每一层看做是对数据集的近似，叶子节点层是最细粒度的近似，与数据集相似度100%，越往上层越粗糙。 总结我们知道，实际应用当中，我们经常使用的是查找和排序操作，这在我们的各种管理系统、数据库系统、操作系统等当中，十分常用。 数组的下标寻址十分迅速，但计算机的内存是有限的，故数组的长度也是有限的，实际应用当中的数据往往十分庞大；而且无序数组的查找最坏情况需要遍历整个数组；后来人们提出了二分查找，二分查找要求数组的构造一定有序，二分法查找解决了普通数组查找复杂度过高的问题。任何一种数组无法解决的问题就是插入、删除操作比较复杂，因此，在一个增删查改比较频繁的数据结构中，数组不会被优先考虑 普通链表由于它的结构特点被证明根本不适合进行查找 哈希表是数组和链表的折中，同时它的设计依赖散列函数的设计，数组不能无限长、链表也不适合查找，所以也不适合大规模的查找 二叉查找树因为可能退化成链表，同样不适合进行查找 AVL树是为了解决可能退化成链表问题，但是AVL树的旋转过程非常麻烦，因此插入和删除很慢，也就是构建AVL树比较麻烦 红黑树是平衡二叉树和AVL树的折中，因此是比较合适的。集合类中的Map、关联数组具有较高的查询效率，它们的底层实现就是红黑树。 多路查找树 是大规模数据存储中，实现索引查询这样一个实际背景下，树节点存储的元素数量是有限的(如果元素数量非常多的话，查找就退化成节点内部的线性查找了)，这样导致二叉查找树结构由于树的深度过大而造成磁盘I&#x2F;O读写过于频繁，进而导致查询效率低下。 B树与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。它的应用是文件系统及部分非关系型数据库索引。 B+树在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。通常用于关系型数据库(如Mysql)和操作系统的文件系统中。 B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针, 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1&#x2F;2提高到2&#x2F;3。 R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 Trie树是自然语言处理中最常用的数据结构，很多字符串处理任务都会用到。Trie树本身是一种有限状态自动机，还有很多变体。什么模式匹配、正则表达式，都与这有关。 针对大量数据，如果在内存中作业优先考虑红黑树(map,set之类多为RB-tree实现)，如果在硬盘中作业优先考虑B系列树(B+, B, B*) 参考文章 文章中一些图片和内容来源: 数据结构图文解析之: 树的简介及二叉排序树C++模板实现. https://www.it610.com/article/3607922.htm 各种二叉树的介绍 https://www.cnblogs.com/aspirant/p/9019396.html 二叉树、二叉搜索树、平衡二叉树、B树、B+树的精确定义和区别探究 https://www.cnblogs.com/williamjie/p/11081096.html 数据结构之树 https://blog.csdn.net/wannuoge4766/article/details/83998377 B+Tree原理及mysql的索引分析 https://www.cnblogs.com/xiaoxi/p/6894610.html","tags":["数据结构","树"],"categories":["数据结构","树"]},{"title":"5.线性表 - 栈和队列","path":"/2023/12/27/5-线性表-栈和队列/","content":"数组和链表都是线性存储结构的基础，栈和队列都是线性存储结构的应用。 知识点栈 - LIFO示意图 实现 使用数组实现的叫静态栈 使用链表实现的叫动态栈 队列 - FIFO示意图 实现 使用数组实现的叫静态队列 使用链表实现的叫动态队列 JDK中实现《Java - Stack &amp; Queue 源码解析》 栈和队列相关题目用栈实现队列 232. Implement Queue using Stacks (Easy) 栈的顺序为后进先出，而队列的顺序为先进先出。使用两个栈实现队列，一个元素需要经过两个栈才能出队列，在经过第一个栈时元素顺序被反转，经过第二个栈时再次被反转，此时就是先进先出顺序。 12345678910111213141516171819202122232425262728293031class MyQueue &#123; private Stack&lt;Integer&gt; in = new Stack&lt;&gt;(); private Stack&lt;Integer&gt; out = new Stack&lt;&gt;(); public void push(int x) &#123; in.push(x); &#125; public int pop() &#123; in2out(); return out.pop(); &#125; public int peek() &#123; in2out(); return out.peek(); &#125; private void in2out() &#123; if (out.isEmpty()) &#123; while (!in.isEmpty()) &#123; out.push(in.pop()); &#125; &#125; &#125; public boolean empty() &#123; return in.isEmpty() &amp;&amp; out.isEmpty(); &#125;&#125; 用队列实现栈 225. Implement Stack using Queues (Easy) 在将一个元素 x 插入队列时，为了维护原来的后进先出顺序，需要让 x 插入队列首部。而队列的默认插入顺序是队列尾部，因此在将 x 插入队列尾部之后，需要让除了 x 之外的所有元素出队列，再入队列。 12345678910111213141516171819202122232425262728class MyStack &#123; private Queue&lt;Integer&gt; queue; public MyStack() &#123; queue = new LinkedList&lt;&gt;(); &#125; public void push(int x) &#123; queue.add(x); int cnt = queue.size(); while (cnt-- &gt; 1) &#123; queue.add(queue.poll()); &#125; &#125; public int pop() &#123; return queue.remove(); &#125; public int top() &#123; return queue.peek(); &#125; public boolean empty() &#123; return queue.isEmpty(); &#125;&#125; 最小值栈 155. Min Stack (Easy) 1234567891011121314151617181920212223242526272829303132class MinStack &#123; private Stack&lt;Integer&gt; dataStack; private Stack&lt;Integer&gt; minStack; private int min; public MinStack() &#123; dataStack = new Stack&lt;&gt;(); minStack = new Stack&lt;&gt;(); min = Integer.MAX_VALUE; &#125; public void push(int x) &#123; dataStack.add(x); min = Math.min(min, x); minStack.add(min); &#125; public void pop() &#123; dataStack.pop(); minStack.pop(); min = minStack.isEmpty() ? Integer.MAX_VALUE : minStack.peek(); &#125; public int top() &#123; return dataStack.peek(); &#125; public int getMin() &#123; return minStack.peek(); &#125;&#125; 对于实现最小值队列问题，可以先将队列使用栈来实现，然后就将问题转换为最小值栈，这个问题出现在 编程之美: 3.7。 用栈实现括号匹配 20. Valid Parentheses (Easy) 123&quot;()[]&#123;&#125;&quot;Output : true 1234567891011121314151617181920public boolean isValid(String s) &#123; Stack&lt;Character&gt; stack = new Stack&lt;&gt;(); for (char c : s.toCharArray()) &#123; if (c == &#x27;(&#x27; || c == &#x27;&#123;&#x27; || c == &#x27;[&#x27;) &#123; stack.push(c); &#125; else &#123; if (stack.isEmpty()) &#123; return false; &#125; char cStack = stack.pop(); boolean b1 = c == &#x27;)&#x27; &amp;&amp; cStack != &#x27;(&#x27;; boolean b2 = c == &#x27;]&#x27; &amp;&amp; cStack != &#x27;[&#x27;; boolean b3 = c == &#x27;&#125;&#x27; &amp;&amp; cStack != &#x27;&#123;&#x27;; if (b1 || b2 || b3) &#123; return false; &#125; &#125; &#125; return stack.isEmpty();&#125; 数组中元素与下一个比它大的元素之间的距离 739. Daily Temperatures (Medium) 12Input: [73, 74, 75, 71, 69, 72, 76, 73]Output: [1, 1, 4, 2, 1, 1, 0, 0] 在遍历数组时用栈把数组中的数存起来，如果当前遍历的数比栈顶元素来的大，说明栈顶元素的下一个比它大的数就是当前元素。 12345678910111213public int[] dailyTemperatures(int[] temperatures) &#123; int n = temperatures.length; int[] dist = new int[n]; Stack&lt;Integer&gt; indexs = new Stack&lt;&gt;(); for (int curIndex = 0; curIndex &lt; n; curIndex++) &#123; while (!indexs.isEmpty() &amp;&amp; temperatures[curIndex] &gt; temperatures[indexs.peek()]) &#123; int preIndex = indexs.pop(); dist[preIndex] = curIndex - preIndex; &#125; indexs.add(curIndex); &#125; return dist;&#125; 循环数组中比当前元素大的下一个元素 503. Next Greater Element II (Medium) 12345Input: [1,2,1]Output: [2,-1,2]Explanation: The first 1&#x27;s next greater number is 2;The number 2 can&#x27;t find next greater number;The second 1&#x27;s next greater number needs to search circularly, which is also 2. 与 739. Daily Temperatures (Medium) 不同的是，数组是循环数组，并且最后要求的不是距离而是下一个元素。 12345678910111213141516public int[] nextGreaterElements(int[] nums) &#123; int n = nums.length; int[] next = new int[n]; Arrays.fill(next, -1); Stack&lt;Integer&gt; pre = new Stack&lt;&gt;(); for (int i = 0; i &lt; n * 2; i++) &#123; int num = nums[i % n]; while (!pre.isEmpty() &amp;&amp; nums[pre.peek()] &lt; num) &#123; next[pre.pop()] = num; &#125; if (i &lt; n)&#123; pre.push(i); &#125; &#125; return next;&#125; 参考文章 https://www.cnblogs.com/QG-whz/p/5170418.html https://www.cnblogs.com/QG-whz/p/5171123.html","tags":["数据结构","线性表","栈和队列"],"categories":["数据结构","线性表"]},{"title":"4.线性表(散列) - 哈希表","path":"/2023/12/27/4-线性表-散列-哈希表/","content":"散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。 哈希表相关题目哈希表使用 O(N) 空间复杂度存储数据，并且以 O(1) 时间复杂度求解问题。 Java 中的 HashSet 用于存储一个集合，可以查找元素是否在集合中。如果元素有穷，并且范围不大，那么可以用一个布尔数组来存储一个元素是否存在。例如对于只有小写字符的元素，就可以用一个长度为 26 的布尔数组来存储一个字符集合，使得空间复杂度降低为 O(1)。 Java 中的 HashMap 主要用于映射关系，从而把两个元素联系起来。HashMap 也可以用来对元素进行计数统计，此时键为元素，值为计数。和 HashSet 类似，如果元素有穷并且范围不大，可以用整型数组来进行统计。在对一个内容进行压缩或者其它转换时，利用 HashMap 可以把原始内容和转换后的内容联系起来。例如在一个简化 url 的系统中 Leetcdoe : 535. Encode and Decode TinyURL (Medium)，利用 HashMap 就可以存储精简后的 url 到原始 url 的映射，使得不仅可以显示简化的 url，也可以根据简化的 url 得到原始 url 从而定位到正确的资源。 数组中两个数的和为给定值 1. Two Sum (Easy) 可以先对数组进行排序，然后使用双指针方法或者二分查找方法。这样做的时间复杂度为 O(NlogN)，空间复杂度为 O(1)。 用 HashMap 存储数组元素和索引的映射，在访问到 nums[i] 时，判断 HashMap 中是否存在 target - nums[i]，如果存在说明 target - nums[i] 所在的索引和 i 就是要找的两个数。该方法的时间复杂度为 O(N)，空间复杂度为 O(N)，使用空间来换取时间。 1234567891011public int[] twoSum(int[] nums, int target) &#123; HashMap&lt;Integer, Integer&gt; indexForNum = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; if (indexForNum.containsKey(target - nums[i])) &#123; return new int[]&#123;indexForNum.get(target - nums[i]), i&#125;; &#125; else &#123; indexForNum.put(nums[i], i); &#125; &#125; return null;&#125; 判断数组是否含有重复元素 217. Contains Duplicate (Easy) 1234567public boolean containsDuplicate(int[] nums) &#123; Set&lt;Integer&gt; set = new HashSet&lt;&gt;(); for (int num : nums) &#123; set.add(num); &#125; return set.size() &lt; nums.length;&#125; 最长和谐序列 594. Longest Harmonious Subsequence (Easy) 123Input: [1,3,2,2,5,2,3,7]Output: 5Explanation: The longest harmonious subsequence is [3,2,2,2,3]. 和谐序列中最大数和最小数只差正好为 1，应该注意的是序列的元素不一定是数组的连续元素。 12345678910111213public int findLHS(int[] nums) &#123; Map&lt;Integer, Integer&gt; countForNum = new HashMap&lt;&gt;(); for (int num : nums) &#123; countForNum.put(num, countForNum.getOrDefault(num, 0) + 1); &#125; int longest = 0; for (int num : countForNum.keySet()) &#123; if (countForNum.containsKey(num + 1)) &#123; longest = Math.max(longest, countForNum.get(num + 1) + countForNum.get(num)); &#125; &#125; return longest;&#125; 最长连续序列 128. Longest Consecutive Sequence (Hard) 12Given [100, 4, 200, 1, 3, 2],The longest consecutive elements sequence is [1, 2, 3, 4]. Return its length: 4. 要求以 O(N) 的时间复杂度求解。 12345678910111213141516171819202122232425262728293031public int longestConsecutive(int[] nums) &#123; Map&lt;Integer, Integer&gt; countForNum = new HashMap&lt;&gt;(); for (int num : nums) &#123; countForNum.put(num, 1); &#125; for (int num : nums) &#123; forward(countForNum, num); &#125; return maxCount(countForNum);&#125;private int forward(Map&lt;Integer, Integer&gt; countForNum, int num) &#123; if (!countForNum.containsKey(num)) &#123; return 0; &#125; int cnt = countForNum.get(num); if (cnt &gt; 1) &#123; return cnt; &#125; cnt = forward(countForNum, num + 1) + 1; countForNum.put(num, cnt); return cnt;&#125;private int maxCount(Map&lt;Integer, Integer&gt; countForNum) &#123; int max = 0; for (int num : countForNum.keySet()) &#123; max = Math.max(max, countForNum.get(num)); &#125; return max;&#125;","tags":["数据结构","哈希表","线性表"],"categories":["数据结构","线性表"]},{"title":"3.线性表 - 链表","path":"/2023/12/27/3-线性表-链表/","content":"n个节点离散分配，彼此通过指针相连，每个节点只有一个前驱节点，每个节点只有一个后续节点，首节点没有前驱节点，尾节点没有后续节点。确定一个链表我们只需要头指针，通过头指针就可以把整个链表都能推出来。 知识点优缺点链表优点 空间没有限制 插入删除元素很快 链表缺点 存取速度很慢 分类 单向链表 一个节点指向下一个节点。 双向链表 一个节点有两个指针域。 循环链表 能通过任何一个节点找到其他所有的节点，将两种(双向&#x2F;单向)链表的最后一个结点指向第一个结点从而实现循环。 实现 节点 12345678910111213141516public class Node &#123; //数据域 public int data; //指针域，指向下一个节点 public Node next; public Node() &#123; &#125; public Node(int data) &#123; this.data = data; &#125; public Node(int data, Node next) &#123; this.data = data; this.next = next; &#125;&#125; 如上，一个链表节点对象就创建完成了，但理解链表本身并不难，但做相关的操作却并非易事，其算法包括且不限于: 插入节点 遍历 查找 清空 销毁 求长度 排序 删除节点 去重 JDK中关于链表的实现，请参考: 《Java - LinkedList 源码解析》 链表相关题目链表是空节点，或者有一个值和一个指向下一个链表的指针，因此很多链表问题可以用递归来处理。 找出两个链表的交点 160. Intersection of Two Linked Lists (Easy) 12345A: a1 → a2 ↘ c1 → c2 → c3 ↗B: b1 → b2 → b3 要求: 时间复杂度为 O(N)，空间复杂度为 O(1) 设 A 的长度为 a + c，B 的长度为 b + c，其中 c 为尾部公共部分长度，可知 a + c + b &#x3D; b + c + a。 当访问 A 链表的指针访问到链表尾部时，令它从链表 B 的头部开始访问链表 B；同样地，当访问 B 链表的指针访问到链表尾部时，令它从链表 A 的头部开始访问链表 A。这样就能控制访问 A 和 B 两个链表的指针能同时访问到交点。 12345678public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; ListNode l1 = headA, l2 = headB; while (l1 != l2) &#123; l1 = (l1 == null) ? headB : l1.next; l2 = (l2 == null) ? headA : l2.next; &#125; return l1;&#125; 如果只是判断是否存在交点，那么就是另一个问题，即 编程之美 3.6 的问题。有两种解法: 把第一个链表的结尾连接到第二个链表的开头，看第二个链表是否存在环； 或者直接比较两个链表的最后一个节点是否相同。 链表反转 206. Reverse Linked List (Easy) 递归 12345678910public ListNode reverseList(ListNode head) &#123; if (head == null || head.next == null) &#123; return head; &#125; ListNode next = head.next; ListNode newHead = reverseList(next); next.next = head; head.next = null; return newHead;&#125; 头插法 12345678910public ListNode reverseList(ListNode head) &#123; ListNode newHead = new ListNode(-1); while (head != null) &#123; ListNode next = head.next; head.next = newHead.next; newHead.next = head; head = next; &#125; return newHead.next;&#125; 归并两个有序的链表 21. Merge Two Sorted Lists (Easy) 1234567891011public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; if (l1 == null) return l2; if (l2 == null) return l1; if (l1.val &lt; l2.val) &#123; l1.next = mergeTwoLists(l1.next, l2); return l1; &#125; else &#123; l2.next = mergeTwoLists(l1, l2.next); return l2; &#125;&#125; 从有序链表中删除重复节点 83. Remove Duplicates from Sorted List (Easy) 12Given 1-&gt;1-&gt;2, return 1-&gt;2.Given 1-&gt;1-&gt;2-&gt;3-&gt;3, return 1-&gt;2-&gt;3. 12345public ListNode deleteDuplicates(ListNode head) &#123; if (head == null || head.next == null) return head; head.next = deleteDuplicates(head.next); return head.val == head.next.val ? head.next : head;&#125; 删除链表的倒数第 n 个节点 19. Remove Nth Node From End of List (Medium) 12Given linked list: 1-&gt;2-&gt;3-&gt;4-&gt;5, and n = 2.After removing the second node from the end, the linked list becomes 1-&gt;2-&gt;3-&gt;5. 1234567891011121314public ListNode removeNthFromEnd(ListNode head, int n) &#123; ListNode fast = head; while (n-- &gt; 0) &#123; fast = fast.next; &#125; if (fast == null) return head.next; ListNode slow = head; while (fast.next != null) &#123; fast = fast.next; slow = slow.next; &#125; slow.next = slow.next.next; return head;&#125; 交换链表中的相邻结点 24. Swap Nodes in Pairs (Medium) 1Given 1-&gt;2-&gt;3-&gt;4, you should return the list as 2-&gt;1-&gt;4-&gt;3. 题目要求: 不能修改结点的 val 值，O(1) 空间复杂度。 123456789101112131415public ListNode swapPairs(ListNode head) &#123; ListNode node = new ListNode(-1); node.next = head; ListNode pre = node; while (pre.next != null &amp;&amp; pre.next.next != null) &#123; ListNode l1 = pre.next, l2 = pre.next.next; ListNode next = l2.next; l1.next = next; l2.next = l1; pre.next = l2; pre = l1; &#125; return node.next;&#125; 链表求和 445. Add Two Numbers II (Medium) 12Input: (7 -&gt; 2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)Output: 7 -&gt; 8 -&gt; 0 -&gt; 7 题目要求: 不能修改原始链表。 12345678910111213141516171819202122232425public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123; Stack&lt;Integer&gt; l1Stack = buildStack(l1); Stack&lt;Integer&gt; l2Stack = buildStack(l2); ListNode head = new ListNode(-1); int carry = 0; while (!l1Stack.isEmpty() || !l2Stack.isEmpty() || carry != 0) &#123; int x = l1Stack.isEmpty() ? 0 : l1Stack.pop(); int y = l2Stack.isEmpty() ? 0 : l2Stack.pop(); int sum = x + y + carry; ListNode node = new ListNode(sum % 10); node.next = head.next; head.next = node; carry = sum / 10; &#125; return head.next;&#125;private Stack&lt;Integer&gt; buildStack(ListNode l) &#123; Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); while (l != null) &#123; stack.push(l.val); l = l.next; &#125; return stack;&#125; 回文链表 234. Palindrome Linked List (Easy) 题目要求: 以 O(1) 的空间复杂度来求解。 切成两半，把后半段反转，然后比较两半是否相等。 1234567891011121314151617181920212223242526272829303132333435363738public boolean isPalindrome(ListNode head) &#123; if (head == null || head.next == null) return true; ListNode slow = head, fast = head.next; while (fast != null &amp;&amp; fast.next != null) &#123; slow = slow.next; fast = fast.next.next; &#125; if (fast != null) slow = slow.next; // 偶数节点，让 slow 指向下一个节点 cut(head, slow); // 切成两个链表 return isEqual(head, reverse(slow));&#125;private void cut(ListNode head, ListNode cutNode) &#123; while (head.next != cutNode) &#123; head = head.next; &#125; head.next = null;&#125;private ListNode reverse(ListNode head) &#123; ListNode newHead = null; while (head != null) &#123; ListNode nextNode = head.next; head.next = newHead; newHead = head; head = nextNode; &#125; return newHead;&#125;private boolean isEqual(ListNode l1, ListNode l2) &#123; while (l1 != null &amp;&amp; l2 != null) &#123; if (l1.val != l2.val) return false; l1 = l1.next; l2 = l2.next; &#125; return true;&#125; 分隔链表 725. Split Linked List in Parts(Medium) 12345Input:root = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], k = 3Output: [[1, 2, 3, 4], [5, 6, 7], [8, 9, 10]]Explanation:The input has been split into consecutive parts with size difference at most 1, and earlier parts are a larger size than the later parts. 题目描述: 把链表分隔成 k 部分，每部分的长度都应该尽可能相同，排在前面的长度应该大于等于后面的。 1234567891011121314151617181920212223public ListNode[] splitListToParts(ListNode root, int k) &#123; int N = 0; ListNode cur = root; while (cur != null) &#123; N++; cur = cur.next; &#125; int mod = N % k; int size = N / k; ListNode[] ret = new ListNode[k]; cur = root; for (int i = 0; cur != null &amp;&amp; i &lt; k; i++) &#123; ret[i] = cur; int curSize = size + (mod-- &gt; 0 ? 1 : 0); for (int j = 0; j &lt; curSize - 1; j++) &#123; cur = cur.next; &#125; ListNode next = cur.next; cur.next = null; cur = next; &#125; return ret;&#125; 链表元素按奇偶聚集 328. Odd Even Linked List (Medium) 1234567891011121314151617Example:Given 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL,return 1-&gt;3-&gt;5-&gt;2-&gt;4-&gt;NULL.public ListNode oddEvenList(ListNode head) &#123; if (head == null) &#123; return head; &#125; ListNode odd = head, even = head.next, evenHead = even; while (even != null &amp;&amp; even.next != null) &#123; odd.next = odd.next.next; odd = odd.next; even.next = even.next.next; even = even.next; &#125; odd.next = evenHead; return head;&#125;","tags":["数据结构","线性表","链表"],"categories":["数据结构","线性表"]},{"title":"2.线性表 - 数组和矩阵","path":"/2023/12/27/2-线性表-数组和矩阵/","content":"数组是一种连续存储线性结构，元素类型相同，大小相等，数组是多维的，通过使用整型索引值来访问他们的元素，数组尺寸不能改变。 知识点数组的优点: 存取速度快 数组的缺点: 事先必须知道数组的长度 插入删除元素很慢 空间通常是有限制的 需要大块连续的内存块 插入删除元素的效率很低 JDK中关于ArrayList的实现，请参考: 《Java - ArrayList 源码解析》 数组与矩阵相关题目把数组中的 0 移到末尾 283. Move Zeroes (Easy) 1For example, given nums = [0, 1, 0, 3, 12], after calling your function, nums should be [1, 3, 12, 0, 0]. 1234567891011public void moveZeroes(int[] nums) &#123; int idx = 0; for (int num : nums) &#123; if (num != 0) &#123; nums[idx++] = num; &#125; &#125; while (idx &lt; nums.length) &#123; nums[idx++] = 0; &#125;&#125; 改变矩阵维度 566. Reshape the Matrix (Easy) 1234567891011Input:nums =[[1,2], [3,4]]r = 1, c = 4Output:[[1,2,3,4]]Explanation:The row-traversing of nums is [1,2,3,4]. The new reshaped matrix is a 1 * 4 matrix, fill it row by row by using the previous list. 123456789101112131415public int[][] matrixReshape(int[][] nums, int r, int c) &#123; int m = nums.length, n = nums[0].length; if (m * n != r * c) &#123; return nums; &#125; int[][] reshapedNums = new int[r][c]; int index = 0; for (int i = 0; i &lt; r; i++) &#123; for (int j = 0; j &lt; c; j++) &#123; reshapedNums[i][j] = nums[index / n][index % n]; index++; &#125; &#125; return reshapedNums;&#125; 找出数组中最长的连续 485. Max Consecutive Ones (Easy) 12345678public int findMaxConsecutiveOnes(int[] nums) &#123; int max = 0, cur = 0; for (int x : nums) &#123; cur = x == 0 ? 0 : cur + 1; max = Math.max(max, cur); &#125; return max;&#125; 有序矩阵查找 240. Search a 2D Matrix II (Medium) 12345[ [ 1, 5, 9], [10, 11, 13], [12, 13, 15]] 1234567891011public boolean searchMatrix(int[][] matrix, int target) &#123; if (matrix == null || matrix.length == 0 || matrix[0].length == 0) return false; int m = matrix.length, n = matrix[0].length; int row = 0, col = n - 1; while (row &lt; m &amp;&amp; col &gt;= 0) &#123; if (target == matrix[row][col]) return true; else if (target &lt; matrix[row][col]) col--; else row++; &#125; return false;&#125; 有序矩阵的 Kth Element 378. Kth Smallest Element in a Sorted Matrix ((Medium)) 12345678matrix = [ [ 1, 5, 9], [10, 11, 13], [12, 13, 15]],k = 8,return 13. 解题参考: Share my thoughts and Clean Java Code 二分查找解法: 12345678910111213141516public int kthSmallest(int[][] matrix, int k) &#123; int m = matrix.length, n = matrix[0].length; int lo = matrix[0][0], hi = matrix[m - 1][n - 1]; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; int cnt = 0; for (int i = 0; i &lt; m; i++) &#123; for (int j = 0; j &lt; n &amp;&amp; matrix[i][j] &lt;= mid; j++) &#123; cnt++; &#125; &#125; if (cnt &lt; k) lo = mid + 1; else hi = mid - 1; &#125; return lo;&#125; 堆解法: 1234567891011121314151617181920212223public int kthSmallest(int[][] matrix, int k) &#123; int m = matrix.length, n = matrix[0].length; PriorityQueue&lt;Tuple&gt; pq = new PriorityQueue&lt;Tuple&gt;(); for(int j = 0; j &lt; n; j++) pq.offer(new Tuple(0, j, matrix[0][j])); for(int i = 0; i &lt; k - 1; i++) &#123; // 小根堆，去掉 k - 1 个堆顶元素，此时堆顶元素就是第 k 的数 Tuple t = pq.poll(); if(t.x == m - 1) continue; pq.offer(new Tuple(t.x + 1, t.y, matrix[t.x + 1][t.y])); &#125; return pq.poll().val;&#125;class Tuple implements Comparable&lt;Tuple&gt; &#123; int x, y, val; public Tuple(int x, int y, int val) &#123; this.x = x; this.y = y; this.val = val; &#125; @Override public int compareTo(Tuple that) &#123; return this.val - that.val; &#125;&#125; 一个数组元素在 [1, n] 之间，其中一个数被替换为另一个数，找出重复的数和丢失的数 645. Set Mismatch (Easy) 12Input: nums = [1,2,2,4]Output: [2,3] 12Input: nums = [1,2,2,4]Output: [2,3] 最直接的方法是先对数组进行排序，这种方法时间复杂度为 O(NlogN)。本题可以以 O(N) 的时间复杂度、O(1) 空间复杂度来求解。 主要思想是通过交换数组元素，使得数组上的元素在正确的位置上。 12345678910111213141516171819public int[] findErrorNums(int[] nums) &#123; for (int i = 0; i &lt; nums.length; i++) &#123; while (nums[i] != i + 1 &amp;&amp; nums[nums[i] - 1] != nums[i]) &#123; swap(nums, i, nums[i] - 1); &#125; &#125; for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] != i + 1) &#123; return new int[]&#123;nums[i], i + 1&#125;; &#125; &#125; return null;&#125;private void swap(int[] nums, int i, int j) &#123; int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp;&#125; 类似题目: 448. Find All Numbers Disappeared in an Array (Easy)，寻找所有丢失的元素 442. Find All Duplicates in an Array (Medium)，寻找所有重复的元素。 找出数组中重复的数，数组值在 [1, n] 之间 287. Find the Duplicate Number (Medium) 要求不能修改数组，也不能使用额外的空间。 二分查找解法: 12345678910111213public int findDuplicate(int[] nums) &#123; int l = 1, h = nums.length - 1; while (l &lt;= h) &#123; int mid = l + (h - l) / 2; int cnt = 0; for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] &lt;= mid) cnt++; &#125; if (cnt &gt; mid) h = mid - 1; else l = mid + 1; &#125; return l;&#125; 双指针解法，类似于有环链表中找出环的入口: 12345678910111213public int findDuplicate(int[] nums) &#123; int slow = nums[0], fast = nums[nums[0]]; while (slow != fast) &#123; slow = nums[slow]; fast = nums[nums[fast]]; &#125; fast = 0; while (slow != fast) &#123; slow = nums[slow]; fast = nums[fast]; &#125; return slow;&#125; 数组相邻差值的个数 667. Beautiful Arrangement II (Medium) 123Input: n = 3, k = 2Output: [1, 3, 2]Explanation: The [1, 3, 2] has three different positive integers ranging from 1 to 3, and the [2, 1] has exactly 2 distinct integers: 1 and 2. 题目描述: 数组元素为 1~n 的整数，要求构建数组，使得相邻元素的差值不相同的个数为 k。 让前 k+1 个元素构建出 k 个不相同的差值，序列为: 1 k+1 2 k 3 k-1 … k&#x2F;2 k&#x2F;2+1. 1234567891011public int[] constructArray(int n, int k) &#123; int[] ret = new int[n]; ret[0] = 1; for (int i = 1, interval = k; i &lt;= k; i++, interval--) &#123; ret[i] = i % 2 == 1 ? ret[i - 1] + interval : ret[i - 1] - interval; &#125; for (int i = k + 1; i &lt; n; i++) &#123; ret[i] = i + 1; &#125; return ret;&#125; 数组的度 697. Degree of an Array (Easy) 12Input: [1,2,2,3,1,4,2]Output: 6 题目描述: 数组的度定义为元素出现的最高频率，例如上面的数组度为 3。要求找到一个最小的子数组，这个子数组的度和原数组一样。 12345678910111213141516171819202122232425public int findShortestSubArray(int[] nums) &#123; Map&lt;Integer, Integer&gt; numsCnt = new HashMap&lt;&gt;(); Map&lt;Integer, Integer&gt; numsLastIndex = new HashMap&lt;&gt;(); Map&lt;Integer, Integer&gt; numsFirstIndex = new HashMap&lt;&gt;(); for (int i = 0; i &lt; nums.length; i++) &#123; int num = nums[i]; numsCnt.put(num, numsCnt.getOrDefault(num, 0) + 1); numsLastIndex.put(num, i); if (!numsFirstIndex.containsKey(num)) &#123; numsFirstIndex.put(num, i); &#125; &#125; int maxCnt = 0; for (int num : nums) &#123; maxCnt = Math.max(maxCnt, numsCnt.get(num)); &#125; int ret = nums.length; for (int i = 0; i &lt; nums.length; i++) &#123; int num = nums[i]; int cnt = numsCnt.get(num); if (cnt != maxCnt) continue; ret = Math.min(ret, numsLastIndex.get(num) - numsFirstIndex.get(num) + 1); &#125; return ret;&#125; 对角元素相等的矩阵 766. Toeplitz Matrix (Easy) 12345123451239512In the above grid, the diagonals are &quot;[9]&quot;, &quot;[5, 5]&quot;, &quot;[1, 1, 1]&quot;, &quot;[2, 2, 2]&quot;, &quot;[3, 3]&quot;, &quot;[4]&quot;, and in each diagonal all elements are the same, so the answer is True. 1234567891011121314151617181920212223public boolean isToeplitzMatrix(int[][] matrix) &#123; for (int i = 0; i &lt; matrix[0].length; i++) &#123; if (!check(matrix, matrix[0][i], 0, i)) &#123; return false; &#125; &#125; for (int i = 0; i &lt; matrix.length; i++) &#123; if (!check(matrix, matrix[i][0], i, 0)) &#123; return false; &#125; &#125; return true;&#125;private boolean check(int[][] matrix, int expectValue, int row, int col) &#123; if (row &gt;= matrix.length || col &gt;= matrix[0].length) &#123; return true; &#125; if (matrix[row][col] != expectValue) &#123; return false; &#125; return check(matrix, expectValue, row + 1, col + 1);&#125; 嵌套数组 565. Array Nesting (Medium) 1234567Input: A = [5,4,0,3,1,6,2]Output: 4Explanation:A[0] = 5, A[1] = 4, A[2] = 0, A[3] = 3, A[4] = 1, A[5] = 6, A[6] = 2.One of the longest S[K]:S[0] = &#123;A[0], A[5], A[6], A[2]&#125; = &#123;5, 6, 2, 0&#125; 题目描述: S[i] 表示一个集合，集合的第一个元素是 A[i]，第二个元素是 A[A[i]]，如此嵌套下去。求最大的 S[i]。 123456789101112131415public int arrayNesting(int[] nums) &#123; int max = 0; for (int i = 0; i &lt; nums.length; i++) &#123; int cnt = 0; for (int j = i; nums[j] != -1; ) &#123; cnt++; int t = nums[j]; nums[j] = -1; // 标记该位置已经被访问 j = t; &#125; max = Math.max(max, cnt); &#125; return max;&#125; 分隔数组 769. Max Chunks To Make Sorted (Medium) 12345Input: arr = [1,0,2,3,4]Output: 4Explanation:We can split into two chunks, such as [1, 0], [2, 3, 4].However, splitting into [1, 0], [2], [3], [4] is the highest number of chunks possible. 题目描述: 分隔数组，使得对每部分排序后数组就为有序。 12345678910public int maxChunksToSorted(int[] arr) &#123; if (arr == null) return 0; int ret = 0; int right = arr[0]; for (int i = 0; i &lt; arr.length; i++) &#123; right = Math.max(right, arr[i]); if (right == i) ret++; &#125; return ret;&#125;","tags":["数据结构","线性表","数组和矩阵"],"categories":["数据结构","线性表"]},{"title":"1.数据结构基础知识体系详解","path":"/2023/12/27/1-数据结构基础知识体系详解/","content":"提示 对于数据结构这种基础内容，在构建其知识体系时要避免自己再造轮子，需要高一点层次整体上去理解它(格局要大一点，不要盯着代码)，要了解算法思想，性能及适用场景，用一些工具和别人梳理的结果帮助自己构建知识体系等。 知识体系知识体系系统性梳理 学习思路 避免孤立的学习知识点，要关联学习。比如实际应用当中，我们经常使用的是查找和排序操作，这在我们的各种管理系统、数据库系统、操作系统等当中，十分常用，我们通过这个线索将知识点串联起来： 数组的下标寻址十分迅速，但计算机的内存是有限的，故数组的长度也是有限的，实际应用当中的数据往往十分庞大；而且无序数组的查找最坏情况需要遍历整个数组；后来人们提出了二分查找，二分查找要求数组的构造一定有序，二分法查找解决了普通数组查找复杂度过高的问题。任何一种数组无法解决的问题就是插入、删除操作比较复杂，因此，在一个增删查改比较频繁的数据结构中，数组不会被优先考虑 普通链表由于它的结构特点被证明根本不适合进行查找 哈希表是数组和链表的折中，同时它的设计依赖散列函数的设计，数组不能无限长、链表也不适合查找，所以也不适合大规模的查找 二叉查找树因为可能退化成链表，同样不适合进行查找 AVL树是为了解决可能退化成链表问题，但是AVL树的旋转过程非常麻烦，因此插入和删除很慢，也就是构建AVL树比较麻烦 红黑树是平衡二叉树和AVL树的折中，因此是比较合适的。集合类中的Map、关联数组具有较高的查询效率，它们的底层实现就是红黑树。 多路查找树 是大规模数据存储中，实现索引查询这样一个实际背景下，树节点存储的元素数量是有限的(如果元素数量非常多的话，查找就退化成节点内部的线性查找了)，这样导致二叉查找树结构由于树的深度过大而造成磁盘I&#x2F;O读写过于频繁，进而导致查询效率低下。 B树与自平衡二叉查找树不同，B树适用于读写相对大的数据块的存储系统，例如磁盘。它的应用是文件系统及部分非关系型数据库索引。 B+树在B树基础上，为叶子结点增加链表指针(B树+叶子有序链表)，所有关键字都在叶子结点 中出现，非叶子结点作为叶子结点的索引；B+树总是到叶子结点才命中。通常用于关系型数据库(如Mysql)和操作系统的文件系统中。 B*树是B+树的变体，在B+树的非根和非叶子结点再增加指向兄弟的指针, 在B+树基础上，为非叶子结点也增加链表指针，将结点的最低利用率从1&#x2F;2提高到2&#x2F;3。 R树是用来做空间数据存储的树状数据结构。例如给地理位置，矩形和多边形这类多维数据建立索引。 Trie树是自然语言处理中最常用的数据结构，很多字符串处理任务都会用到。Trie树本身是一种有限状态自动机，还有很多变体。什么模式匹配、正则表达式，都与这有关。 相关文章 A. 数据结构 知识点：数据结构是基础中的基础，任何进阶都逃不开这些知识点。 数据结构 - Overview B. 数据结构之 线性结构：首先理解数据结构中线性结构及其延伸：数组和矩阵，链表，栈和队列等。 线性表 - 数组和矩阵 数组是一种连续存储线性结构，元素类型相同，大小相等，数组是多维的，通过使用整型索引值来访问他们的元素，数组尺寸不能改变 线性表 - 链表 n个节点离散分配，彼此通过指针相连，每个节点只有一个前驱节点，每个节点只有一个后续节点，首节点没有前驱节点，尾节点没有后续节点。确定一个链表我们只需要头指针，通过头指针就可以把整个链表都能推出来 线性表(散列) - 哈希表 散列表（Hash table，也叫哈希表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。@pdai 线性表 - 栈和队列 数组和链表都是线性存储结构的基础，栈和队列都是线性存储结构的应用 C. 数据结构之 逻辑结构：树：然后理解数据结构中逻辑结构之树：二叉搜索树(BST)，平衡二叉树(AVL)，红黑树(R-B Tree)，哈夫曼树，前缀树(Trie)等。 树 - 基础和Overview 树在数据结构中至关重要，这里展示树的整体知识体系结构和几种常见树类型 树 - 二叉搜索树(BST) 本文主要介绍 二叉树中最基本的二叉查找树（Binary Search Tree），（又：二叉搜索树，二叉排序树）它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉排序树。 树 - 平衡二叉树(AVL) 平衡二叉树（Balanced Binary Tree）具有以下性质：它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。平衡二叉树的常用实现方法有红黑树、AVL、替罪羊树、Treap、伸展树等。 最小二叉平衡树的节点的公式如下 F(n)&#x3D;F(n-1)+F(n-2)+1 这个类似于一个递归的数列，可以参考Fibonacci数列，1是根节点，F(n-1)是左子树的节点数量，F(n-2)是右子树的节点数量。 树 - 红黑树(R-B Tree) 红黑树（Red Black Tree） 是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型的用途是实现关联数组，是平衡二叉树和AVL树的折中。 树 - 哈夫曼树 哈夫曼又称最优二叉树, 是一种带权路径长度最短的二叉树。 树 - 前缀树(Trie) Trie，又称字典树、单词查找树或键树，是一种树形结构，是一种哈希树的变种。典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。它的优点是：利用字符串的公共前缀来减少查询时间，最大限度地减少无谓的字符串比较，查询效率比哈希树高。 D. 数据结构之 逻辑结构：图：最后理解数据结构中逻辑结构之图：图基础，图的遍历，最小生成树(Prim &amp; Kruskal)，最短路径(Dijkstra &amp; Frolyd)，拓扑排序(Topological sort)，AOE &amp; 关键路径等。 图 - 基础和Overview 图(Graph)是由顶点和连接顶点的边构成的离散结构。在计算机科学中，图是最灵活的数据结构之一，很多问题都可以使用图模型进行建模求解。例如: 生态环境中不同物种的相互竞争、人与人之间的社交与关系网络、化学上用图区分结构不同但分子式相同的同分异构体、分析计算机网络的拓扑结构确定两台计算机是否可以通信、找到两个城市之间的最短路径等等。 图 - 遍历(BFS &amp; DFS) 图的深度优先搜索(Depth First Search)，和树的先序遍历比较类似; 广度优先搜索算法(Breadth First Search)，又称为”宽度优先搜索”或”横向优先搜索” 图 - 最小生成树(Prim &amp; Kruskal) Kruskal算法是从最小权重边着手，将森林里的树逐渐合并；prim算法是从顶点出发，在根结点的基础上建起一棵树 图 - 最短路径(Dijkstra &amp; Frolyd) 最短路径有着广泛的应用，比如地图两点间距离计算，公交查询系统，路由选择等 图 - 拓扑排序(Topological sort) 拓扑排序主要用来解决有向图中的依赖解析(dependency resolution)问题 图 - AOE &amp; 关键路径 关键路径在项目管理计算工期等方面有广泛等应用，提升工期就是所见缩减所有关键路径上的工期，并且在实现时需要应用到之前拓扑排序的算法(前提: 有向无环图，有依赖关系) 入门推荐 强烈推荐用动画学习算法 Data Structure Visualizations 推荐一个学习数据结构的英文网站 Java Point - DS 推荐Github上java算法集合 TheAlgorithms - Java 推荐@skywang12345写的数据结构 skywang12345 - DS 推荐@QG-whz数据结构图画的好(本章节中有部分图源于这位作者) QG-whz 推荐@亦海数据结构的文章，写的很清晰 亦海 - DS 进阶推荐 首推@July结构之法 算法之道 July - 结构之法 算法之道 参考文章 https://www.cnblogs.com/small-boy/p/8039007.html https://www.jianshu.com/p/5c84f7b6c354 https://blog.csdn.net/flowing_wind/article/details/81431354","tags":["算法","数据结构"],"categories":["数据结构"]},{"title":"21.调试排错 - Java动态调试技术原理","path":"/2023/12/27/21-调试排错-Java动态调试技术原理/","content":"本文转载自 美团技术团队胡健的Java 动态调试技术原理及实践, 通过学习java agent方式进行动态调试了解目前很多大厂开源的一些基于此的调试工具。 简介断点调试是我们最常使用的调试手段，它可以获取到方法执行过程中的变量信息，并可以观察到方法的执行路径。但断点调试会在断点位置停顿，使得整个应用停止响应。在线上停顿应用是致命的，动态调试技术给了我们创造新的调试模式的想象空间。本文将研究Java语言中的动态调试技术，首先概括Java动态调试所涉及的技术基础，接着介绍我们在Java动态调试领域的思考及实践，通过结合实际业务场景，设计并实现了一种具备动态性的断点调试工具Java-debug-tool，显著提高了故障排查效率。 JVMTI (JVM Tool Interface)是Java虚拟机对外提供的Native编程接口，通过JVMTI，外部进程可以获取到运行时JVM的诸多信息，比如线程、GC等。Agent是一个运行在目标JVM的特定程序，它的职责是负责从目标JVM中获取数据，然后将数据传递给外部进程。加载Agent的时机可以是目标JVM启动之时，也可以是在目标JVM运行时进行加载，而在目标JVM运行时进行Agent加载具备动态性，对于时机未知的Debug场景来说非常实用。下面将详细分析Java Agent技术的实现细节。 Agent的实现模式JVMTI是一套Native接口，在Java SE 5之前，要实现一个Agent只能通过编写Native代码来实现。从Java SE 5开始，可以使用Java的Instrumentation接口(java.lang.instrument)来编写Agent。无论是通过Native的方式还是通过Java Instrumentation接口的方式来编写Agent，它们的工作都是借助JVMTI来进行完成，下面介绍通过Java Instrumentation接口编写Agent的方法。 通过Java Instrumentation API 实现Agent启动方法 Java Agent支持目标JVM启动时加载，也支持在目标JVM运行时加载，这两种不同的加载模式会使用不同的入口函数，如果需要在目标JVM启动的同时加载Agent，那么可以选择实现下面的方法： 12[1] public static void premain(String agentArgs, Instrumentation inst);[2] public static void premain(String agentArgs); JVM将首先寻找[1]，如果没有发现[1]，再寻找[2]。如果希望在目标JVM运行时加载Agent，则需要实现下面的方法： 12[1] public static void agentmain(String agentArgs, Instrumentation inst);[2] public static void agentmain(String agentArgs); 这两组方法的第一个参数AgentArgs是随同 “– javaagent”一起传入的程序参数，如果这个字符串代表了多个参数，就需要自己解析这些参数。inst是Instrumentation类型的对象，是JVM自动传入的，我们可以拿这个参数进行类增强等操作。 指定Main-Class Agent需要打包成一个jar包，在ManiFest属性中指定“Premain-Class”或者“Agent-Class”： 12Premain-Class: classAgent-Class: class 挂载到目标JVM 将编写的Agent打成jar包后，就可以挂载到目标JVM上去了。如果选择在目标JVM启动时加载Agent，则可以使用 “-javaagent:[&#x3D;]“，具体的使用方法可以使用“Java -Help”来查看。如果想要在运行时挂载Agent到目标JVM，就需要做一些额外的开发了。 com.sun.tools.attach.VirtualMachine 这个类代表一个JVM抽象，可以通过这个类找到目标JVM，并且将Agent挂载到目标JVM上。下面是使用com.sun.tools.attach.VirtualMachine进行动态挂载Agent的一般实现： 12345678910111213141516171819202122private void attachAgentToTargetJVM() throws Exception &#123; List&lt;VirtualMachineDescriptor&gt; virtualMachineDescriptors = VirtualMachine.list(); VirtualMachineDescriptor targetVM = null; for (VirtualMachineDescriptor descriptor : virtualMachineDescriptors) &#123; if (descriptor.id().equals(configure.getPid())) &#123; targetVM = descriptor; break; &#125; &#125; if (targetVM == null) &#123; throw new IllegalArgumentException(&quot;could not find the target jvm by process id:&quot; + configure.getPid()); &#125; VirtualMachine virtualMachine = null; try &#123; virtualMachine = VirtualMachine.attach(targetVM); virtualMachine.loadAgent(&quot;&#123;agent&#125;&quot;, &quot;&#123;params&#125;&quot;); &#125; catch (Exception e) &#123; if (virtualMachine != null) &#123; virtualMachine.detach(); &#125; &#125;&#125; 首先通过指定的进程ID找到目标JVM，然后通过Attach挂载到目标JVM上，执行加载Agent操作。VirtualMachine的Attach方法就是用来将Agent挂载到目标JVM上去的，而Detach则是将Agent从目标JVM卸载。关于Agent是如何挂载到目标JVM上的具体技术细节，将在下文中进行分析。 启动时加载Agent参数解析创建JVM时，JVM会进行参数解析，即解析那些用来配置JVM启动的参数，比如堆大小、GC等；本文主要关注解析的参数为-agentlib、 -agentpath、 -javaagent，这几个参数用来指定Agent，JVM会根据这几个参数加载Agent。下面来分析一下JVM是如何解析这几个参数的。 12345678910111213141516171819202122232425262728293031323334353637383940 // -agentlib and -agentpath if (match_option(option, &quot;-agentlib:&quot;, &amp;tail) || (is_absolute_path = match_option(option, &quot;-agentpath:&quot;, &amp;tail))) &#123; if(tail != NULL) &#123; const char* pos = strchr(tail, &#x27;=&#x27;); size_t len = (pos == NULL) ? strlen(tail) : pos - tail; char* name = strncpy(NEW_C_HEAP_ARRAY(char, len + 1, mtArguments), tail, len); name[len] = &#x27;\\0&#x27;; char *options = NULL; if(pos != NULL) &#123; options = os::strdup_check_oom(pos + 1, mtArguments); &#125;#if !INCLUDE_JVMTI if (valid_jdwp_agent(name, is_absolute_path)) &#123; jio_fprintf(defaultStream::error_stream(), &quot;Debugging agents are not supported in this VM &quot;); return JNI_ERR; &#125;#endif // !INCLUDE_JVMTI add_init_agent(name, options, is_absolute_path); &#125; // -javaagent &#125; else if (match_option(option, &quot;-javaagent:&quot;, &amp;tail)) &#123;#if !INCLUDE_JVMTI jio_fprintf(defaultStream::error_stream(), &quot;Instrumentation agents are not supported in this VM &quot;); return JNI_ERR;#else if (tail != NULL) &#123; size_t length = strlen(tail) + 1; char *options = NEW_C_HEAP_ARRAY(char, length, mtArguments); jio_snprintf(options, length, &quot;%s&quot;, tail); add_init_agent(&quot;instrument&quot;, options, false); // java agents need module java.instrument if (!create_numbered_property(&quot;jdk.module.addmods&quot;, &quot;java.instrument&quot;, addmods_count++)) &#123; return JNI_ENOMEM; &#125; &#125;#endif // !INCLUDE_JVMTI &#125; 上面的代码片段截取自hotspot&#x2F;src&#x2F;share&#x2F;vm&#x2F;runtime&#x2F;arguments.cpp中的 Arguments::parse_each_vm_init_arg(const JavaVMInitArgs* args, bool* patch_mod_javabase, Flag::Flags origin) 函数，该函数用来解析一个具体的JVM参数。这段代码的主要功能是解析出需要加载的Agent路径，然后调用add_init_agent函数进行解析结果的存储。下面先看一下add_init_agent函数的具体实现： 1234// -agentlib and -agentpath argumentsstatic AgentLibraryList _agentList;static void add_init_agent(const char* name, char* options, bool absolute_path) &#123; _agentList.add(new AgentLibrary(name, options, absolute_path, NULL)); &#125; AgentLibraryList是一个简单的链表结构，add_init_agent函数将解析好的、需要加载的Agent添加到这个链表中，等待后续的处理。 这里需要注意，解析-javaagent参数有一些特别之处，这个参数用来指定一个我们通过Java Instrumentation API来编写的Agent，Java Instrumentation API底层依赖的是JVMTI，对-JavaAgent的处理也说明了这一点，在调用add_init_agent函数时第一个参数是“instrument”，关于加载Agent这个问题在下一小节进行展开。到此，我们知道在启动JVM时指定的Agent已经被JVM解析完存放在了一个链表结构中。下面来分析一下JVM是如何加载这些Agent的。 执行加载操作在创建JVM进程的函数中，解析完JVM参数之后，下面的这段代码和加载Agent相关： 1234567// Launch -agentlib/-agentpath and converted -Xrun agentsif (Arguments::init_agents_at_startup()) &#123; create_vm_init_agents();&#125;static bool init_agents_at_startup() &#123; return !_agentList.is_empty(); &#125; 当JVM判断出上一小节中解析出来的Agent不为空的时候，就要去调用函数create_vm_init_agents来加载Agent，下面来分析一下create_vm_init_agents函数是如何加载Agent的。 12345678910void Threads::create_vm_init_agents() &#123; AgentLibrary* agent; for (agent = Arguments::agents(); agent != NULL; agent = agent-&gt;next()) &#123; OnLoadEntry_t on_load_entry = lookup_agent_on_load(agent); if (on_load_entry != NULL) &#123; // Invoke the Agent_OnLoad function jint err = (*on_load_entry)(&amp;main_vm, agent-&gt;options(), NULL); &#125; &#125;&#125; create_vm_init_agents这个函数通过遍历Agent链表来逐个加载Agent。通过这段代码可以看出，首先通过lookup_agent_on_load来加载Agent并且找到Agent_OnLoad函数，这个函数是Agent的入口函数。如果没找到这个函数，则认为是加载了一个不合法的Agent，则什么也不做，否则调用这个函数，这样Agent的代码就开始执行起来了。对于使用Java Instrumentation API来编写Agent的方式来说，在解析阶段观察到在add_init_agent函数里面传递进去的是一个叫做”instrument”的字符串，其实这是一个动态链接库。在Linux里面，这个库叫做libinstrument.so，在BSD系统中叫做libinstrument.dylib，该动态链接库在{JAVA_HOME}&#x2F;jre&#x2F;lib&#x2F;目录下。 instrument动态链接库libinstrument用来支持使用Java Instrumentation API来编写Agent，在libinstrument中有一个非常重要的类称为：JPLISAgent(Java Programming Language Instrumentation Services Agent)，它的作用是初始化所有通过Java Instrumentation API编写的Agent，并且也承担着通过JVMTI实现Java Instrumentation中暴露API的责任。 我们已经知道，在JVM启动的时候，JVM会通过-javaagent参数加载Agent。最开始加载的是libinstrument动态链接库，然后在动态链接库里面找到JVMTI的入口方法：Agent_OnLoad。下面就来分析一下在libinstrument动态链接库中，Agent_OnLoad函数是怎么实现的。 1234567891011121314151617181920212223JNIEXPORT jint JNICALLDEF_Agent_OnLoad(JavaVM *vm, char *tail, void * reserved) &#123; initerror = createNewJPLISAgent(vm, &amp;agent); if ( initerror == JPLIS_INIT_ERROR_NONE ) &#123; if (parseArgumentTail(tail, &amp;jarfile, &amp;options) != 0) &#123; fprintf(stderr, &quot;-javaagent: memory allocation failure. &quot;); return JNI_ERR; &#125; attributes = readAttributes(jarfile); premainClass = getAttribute(attributes, &quot;Premain-Class&quot;); /* Save the jarfile name */ agent-&gt;mJarfile = jarfile; /* * Convert JAR attributes into agent capabilities */ convertCapabilityAttributes(attributes, agent); /* * Track (record) the agent class name and options data */ initerror = recordCommandLineData(agent, premainClass, options); &#125; return result;&#125; 上述代码片段是经过精简的libinstrument中Agent_OnLoad实现的，大概的流程就是：先创建一个JPLISAgent，然后将ManiFest中设定的一些参数解析出来， 比如(Premain-Class)等。创建了JPLISAgent之后，调用initializeJPLISAgent对这个Agent进行初始化操作。跟进initializeJPLISAgent看一下是如何初始化的： 1234567891011121314151617JPLISInitializationError initializeJPLISAgent(JPLISAgent *agent, JavaVM *vm, jvmtiEnv *jvmtienv) &#123; /* check what capabilities are available */ checkCapabilities(agent); /* check phase - if live phase then we don&#x27;t need the VMInit event */ jvmtierror = (*jvmtienv)-&gt;GetPhase(jvmtienv, &amp;phase); /* now turn on the VMInit event */ if ( jvmtierror == JVMTI_ERROR_NONE ) &#123; jvmtiEventCallbacks callbacks; memset(&amp;callbacks, 0, sizeof(callbacks)); callbacks.VMInit = &amp;eventHandlerVMInit; jvmtierror = (*jvmtienv)-&gt;SetEventCallbacks(jvmtienv,&amp;callbacks,sizeof(callbacks)); &#125; if ( jvmtierror == JVMTI_ERROR_NONE ) &#123; jvmtierror = (*jvmtienv)-&gt;SetEventNotificationMode(jvmtienv,JVMTI_ENABLE,JVMTI_EVENT_VM_INIT,NULL); &#125; return (jvmtierror == JVMTI_ERROR_NONE)? JPLIS_INIT_ERROR_NONE : JPLIS_INIT_ERROR_FAILURE;&#125; 这里，我们关注callbacks.VMInit &#x3D; &eventHandlerVMInit;这行代码，这里设置了一个VMInit事件的回调函数，表示在JVM初始化的时候会回调eventHandlerVMInit函数。下面来看一下这个函数的实现细节，猜测就是在这里调用了Premain方法： 1234567891011121314151617181920void JNICALL eventHandlerVMInit( jvmtiEnv *jvmtienv,JNIEnv *jnienv,jthread thread) &#123; // ... success = processJavaStart( environment-&gt;mAgent, jnienv); // ...&#125;jboolean processJavaStart(JPLISAgent *agent,JNIEnv *jnienv) &#123; result = createInstrumentationImpl(jnienv, agent); /* * Load the Java agent, and call the premain. */ if ( result ) &#123; result = startJavaAgent(agent, jnienv, agent-&gt;mAgentClassName, agent-&gt;mOptionsString, agent-&gt;mPremainCaller); &#125; return result;&#125;jboolean startJavaAgent( JPLISAgent *agent,JNIEnv *jnienv,const char *classname,const char *optionsString,jmethodID agentMainMethod) &#123; // ... invokeJavaAgentMainMethod(jnienv,agent-&gt;mInstrumentationImpl,agentMainMethod, classNameObject,optionsStringObject); // ...&#125; 看到这里，Instrument已经实例化，invokeJavaAgentMainMethod这个方法将我们的premain方法执行起来了。接着，我们就可以根据Instrument实例来做我们想要做的事情了。 运行时加载Agent比起JVM启动时加载Agent，运行时加载Agent就比较有诱惑力了，因为运行时加载Agent的能力给我们提供了很强的动态性，我们可以在需要的时候加载Agent来进行一些工作。因为是动态的，我们可以按照需求来加载所需要的Agent，下面来分析一下动态加载Agent的相关技术细节。 AttachListenerAttach机制通过Attach Listener线程来进行相关事务的处理，下面来看一下Attach Listener线程是如何初始化的。 12345678910// Starts the Attach Listener threadvoid AttachListener::init() &#123; // 创建线程相关部分代码被去掉了 const char thread_name[] = &quot;Attach Listener&quot;; Handle string = java_lang_String::create_from_str(thread_name, THREAD); &#123; MutexLocker mu(Threads_lock); JavaThread* listener_thread = new JavaThread(&amp;attach_listener_thread_entry); // ... &#125;&#125; 我们知道，一个线程启动之后都需要指定一个入口来执行代码，Attach Listener线程的入口是attach_listener_thread_entry，下面看一下这个函数的具体实现： 12345678910111213141516static void attach_listener_thread_entry(JavaThread* thread, TRAPS) &#123; AttachListener::set_initialized(); for (;;) &#123; AttachOperation* op = AttachListener::dequeue(); // find the function to dispatch too AttachOperationFunctionInfo* info = NULL; for (int i=0; funcs[i].name != NULL; i++) &#123; const char* name = funcs[i].name; if (strcmp(op-&gt;name(), name) == 0) &#123; info = &amp;(funcs[i]); break; &#125;&#125; // dispatch to the function that implements this operation res = (info-&gt;func)(op, &amp;st); //... &#125;&#125; 整个函数执行逻辑，大概是这样的： 拉取一个需要执行的任务：AttachListener::dequeue。 查询匹配的命令处理函数。 执行匹配到的命令执行函数。 其中第二步里面存在一个命令函数表，整个表如下： 12345678910111213static AttachOperationFunctionInfo funcs[] = &#123; &#123; &quot;agentProperties&quot;, get_agent_properties &#125;, &#123; &quot;datadump&quot;, data_dump &#125;, &#123; &quot;dumpheap&quot;, dump_heap &#125;, &#123; &quot;load&quot;, load_agent &#125;, &#123; &quot;properties&quot;, get_system_properties &#125;, &#123; &quot;threaddump&quot;, thread_dump &#125;, &#123; &quot;inspectheap&quot;, heap_inspection &#125;, &#123; &quot;setflag&quot;, set_flag &#125;, &#123; &quot;printflag&quot;, print_flag &#125;, &#123; &quot;jcmd&quot;, jcmd &#125;, &#123; NULL, NULL &#125;&#125;; 对于加载Agent来说，命令就是“load”。现在，我们知道了Attach Listener大概的工作模式，但是还是不太清楚任务从哪来，这个秘密就藏在AttachListener::dequeue这行代码里面，接下来我们来分析一下dequeue这个函数： 12345678910111213141516171819LinuxAttachOperation* LinuxAttachListener::dequeue() &#123; for (;;) &#123; // wait for client to connect struct sockaddr addr; socklen_t len = sizeof(addr); RESTARTABLE(::accept(listener(), &amp;addr, &amp;len), s); // get the credentials of the peer and check the effective uid/guid // - check with jeff on this. struct ucred cred_info; socklen_t optlen = sizeof(cred_info); if (::getsockopt(s, SOL_SOCKET, SO_PEERCRED, (void*)&amp;cred_info, &amp;optlen) == -1) &#123; ::close(s); continue; &#125; // peer credential look okay so we read the request LinuxAttachOperation* op = read_request(s); return op; &#125;&#125; 这是Linux上的实现，不同的操作系统实现方式不太一样。上面的代码表面，Attach Listener在某个端口监听着，通过accept来接收一个连接，然后从这个连接里面将请求读取出来，然后将请求包装成一个AttachOperation类型的对象，之后就会从表里查询对应的处理函数，然后进行处理。 Attach Listener使用一种被称为“懒加载”的策略进行初始化，也就是说，JVM启动的时候Attach Listener并不一定会启动起来。下面我们来分析一下这种“懒加载”策略的具体实现方案。 12345678910111213141516 // Start Attach Listener if +StartAttachListener or it can&#x27;t be started lazily if (!DisableAttachMechanism) &#123; AttachListener::vm_start(); if (StartAttachListener || AttachListener::init_at_startup()) &#123; AttachListener::init(); &#125; &#125;// Attach Listener is started lazily except in the case when// +ReduseSignalUsage is usedbool AttachListener::init_at_startup() &#123; if (ReduceSignalUsage) &#123; return true; &#125; else &#123; return false; &#125;&#125; 上面的代码截取自create_vm函数，DisableAttachMechanism、StartAttachListener和ReduceSignalUsage这三个变量默认都是false，所以AttachListener::init();这行代码不会在create_vm的时候执行，而vm_start会执行。下面来看一下这个函数的实现细节： 123456789101112131415void AttachListener::vm_start() &#123; char fn[UNIX_PATH_MAX]; struct stat64 st; int ret; int n = snprintf(fn, UNIX_PATH_MAX, &quot;%s/.java_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); assert(n &lt; (int)UNIX_PATH_MAX, &quot;java_pid file name buffer overflow&quot;); RESTARTABLE(::stat64(fn, &amp;st), ret); if (ret == 0) &#123; ret = ::unlink(fn); if (ret == -1) &#123; log_debug(attach)(&quot;Failed to remove stale attach pid file at %s&quot;, fn); &#125; &#125;&#125; 这是在Linux上的实现，是将&#x2F;tmp&#x2F;目录下的.java_pid{pid}文件删除，后面在创建Attach Listener线程的时候会创建出来这个文件。上面说到，AttachListener::init()这行代码不会在create_vm的时候执行，这行代码的实现已经在上文中分析了，就是创建Attach Listener线程，并监听其他JVM的命令请求。现在来分析一下这行代码是什么时候被调用的，也就是“懒加载”到底是怎么加载起来的。 12// Signal Dispatcher needs to be started before VMInit event is postedos::signal_init(); 这是create_vm中的一段代码，看起来跟信号相关，其实Attach机制就是使用信号来实现“懒加载“的。下面我们来仔细地分析一下这个过程。 12345678910111213141516171819202122232425void os::signal_init() &#123; if (!ReduceSignalUsage) &#123; // Setup JavaThread for processing signals EXCEPTION_MARK; Klass* k = SystemDictionary::resolve_or_fail(vmSymbols::java_lang_Thread(), true, CHECK); instanceKlassHandle klass (THREAD, k); instanceHandle thread_oop = klass-&gt;allocate_instance_handle(CHECK); const char thread_name[] = &quot;Signal Dispatcher&quot;; Handle string = java_lang_String::create_from_str(thread_name, CHECK); // Initialize thread_oop to put it into the system threadGroup Handle thread_group (THREAD, Universe::system_thread_group()); JavaValue result(T_VOID); JavaCalls::call_special(&amp;result, thread_oop,klass,vmSymbols::object_initializer_name(),vmSymbols::threadgroup_string_void_signature(), thread_group,string,CHECK); KlassHandle group(THREAD, SystemDictionary::ThreadGroup_klass()); JavaCalls::call_special(&amp;result,thread_group,group,vmSymbols::add_method_name(),vmSymbols::thread_void_signature(),thread_oop,CHECK); os::signal_init_pd(); &#123; MutexLocker mu(Threads_lock); JavaThread* signal_thread = new JavaThread(&amp;signal_thread_entry); // ... &#125; // Handle ^BREAK os::signal(SIGBREAK, os::user_handler()); &#125;&#125; JVM创建了一个新的进程来实现信号处理，这个线程叫“Signal Dispatcher”，一个线程创建之后需要有一个入口，“Signal Dispatcher”的入口是signal_thread_entry： 这段代码截取自signal_thread_entry函数，截取中的内容是和Attach机制信号处理相关的代码。这段代码的意思是，当接收到“SIGBREAK”信号，就执行接下来的代码，这个信号是需要Attach到JVM上的信号发出来，这个后面会再分析。我们先来看一句关键的代码：AttachListener::is_init_trigger()： 123456789101112131415161718192021222324bool AttachListener::is_init_trigger() &#123; if (init_at_startup() || is_initialized()) &#123; return false; // initialized at startup or already initialized &#125; char fn[PATH_MAX+1]; sprintf(fn, &quot;.attach_pid%d&quot;, os::current_process_id()); int ret; struct stat64 st; RESTARTABLE(::stat64(fn, &amp;st), ret); if (ret == -1) &#123; log_trace(attach)(&quot;Failed to find attach file: %s, trying alternate&quot;, fn); snprintf(fn, sizeof(fn), &quot;%s/.attach_pid%d&quot;, os::get_temp_directory(), os::current_process_id()); RESTARTABLE(::stat64(fn, &amp;st), ret); &#125; if (ret == 0) &#123; // simple check to avoid starting the attach mechanism when // a bogus user creates the file if (st.st_uid == geteuid()) &#123; init(); return true; &#125; &#125; return false;&#125; 首先检查了一下是否在JVM启动时启动了Attach Listener，或者是否已经启动过。如果没有，才继续执行，在&#x2F;tmp目录下创建一个叫做.attach_pid%d的文件，然后执行AttachListener的init函数，这个函数就是用来创建Attach Listener线程的函数，上面已经提到多次并进行了分析。到此，我们知道Attach机制的奥秘所在，也就是Attach Listener线程的创建依靠Signal Dispatcher线程，Signal Dispatcher是用来处理信号的线程，当Signal Dispatcher线程接收到“SIGBREAK”信号之后，就会执行初始化Attach Listener的工作。 运行时加载Agent的实现我们继续分析，到底是如何将一个Agent挂载到运行着的目标JVM上，在上文中提到了一段代码，用来进行运行时挂载Agent，可以参考上文中展示的关于“attachAgentToTargetJvm”方法的代码。这个方法里面的关键是调用VirtualMachine的attach方法进行Agent挂载的功能。下面我们就来分析一下VirtualMachine的attach方法具体是怎么实现的。 12345678910111213141516171819202122public static VirtualMachine attach(String var0) throws AttachNotSupportedException, IOException &#123; if (var0 == null) &#123; throw new NullPointerException(&quot;id cannot be null&quot;); &#125; else &#123; List var1 = AttachProvider.providers(); if (var1.size() == 0) &#123; throw new AttachNotSupportedException(&quot;no providers installed&quot;); &#125; else &#123; AttachNotSupportedException var2 = null; Iterator var3 = var1.iterator(); while(var3.hasNext()) &#123; AttachProvider var4 = (AttachProvider)var3.next(); try &#123; return var4.attachVirtualMachine(var0); &#125; catch (AttachNotSupportedException var6) &#123; var2 = var6; &#125; &#125; throw var2; &#125; &#125;&#125; 这个方法通过attachVirtualMachine方法进行attach操作，在MacOS系统中，AttachProvider的实现类是BsdAttachProvider。我们来看一下BsdAttachProvider的attachVirtualMachine方法是如何实现的： 12345678910111213141516171819202122232425262728293031323334353637public VirtualMachine attachVirtualMachine(String var1) throws AttachNotSupportedException, IOException &#123; this.checkAttachPermission(); this.testAttachable(var1); return new BsdVirtualMachine(this, var1);&#125;BsdVirtualMachine(AttachProvider var1, String var2) throws AttachNotSupportedException, IOException &#123; int var3 = Integer.parseInt(var2); this.path = this.findSocketFile(var3); if (this.path == null) &#123; File var4 = new File(tmpdir, &quot;.attach_pid&quot; + var3); createAttachFile(var4.getPath()); try &#123; sendQuitTo(var3); int var5 = 0; long var6 = 200L; int var8 = (int)(this.attachTimeout() / var6); do &#123; try &#123; Thread.sleep(var6); &#125; catch (InterruptedException var21) &#123; ; &#125; this.path = this.findSocketFile(var3); ++var5; &#125; while(var5 &lt;= var8 &amp;&amp; this.path == null); &#125; finally &#123; var4.delete(); &#125; &#125; int var24 = socket(); connect(var24, this.path);&#125;private String findSocketFile(int var1) &#123; String var2 = &quot;.java_pid&quot; + var1; File var3 = new File(tmpdir, var2); return var3.exists() ? var3.getPath() : null;&#125; findSocketFile方法用来查询目标JVM上是否已经启动了Attach Listener，它通过检查”tmp&#x2F;“目录下是否存在java_pid{pid}来进行实现。如果已经存在了，则说明Attach机制已经准备就绪，可以接受客户端的命令了，这个时候客户端就可以通过connect连接到目标JVM进行命令的发送，比如可以发送“load”命令来加载Agent。如果java_pid{pid}文件还不存在，则需要通过sendQuitTo方法向目标JVM发送一个“SIGBREAK”信号，让它初始化Attach Listener线程并准备接受客户端连接。可以看到，发送了信号之后客户端会循环等待java_pid{pid}这个文件，之后再通过connect连接到目标JVM上。 load命令的实现下面来分析一下，“load”命令在JVM层面的实现： 1234567891011121314151617static jint load_agent(AttachOperation* op, outputStream* out) &#123; // get agent name and options const char* agent = op-&gt;arg(0); const char* absParam = op-&gt;arg(1); const char* options = op-&gt;arg(2); // If loading a java agent then need to ensure that the java.instrument module is loaded if (strcmp(agent, &quot;instrument&quot;) == 0) &#123; Thread* THREAD = Thread::current(); ResourceMark rm(THREAD); HandleMark hm(THREAD); JavaValue result(T_OBJECT); Handle h_module_name = java_lang_String::create_from_str(&quot;java.instrument&quot;, THREAD); JavaCalls::call_static(&amp;result,SystemDictionary::module_Modules_klass(),vmSymbols::loadModule_name(), vmSymbols::loadModule_signature(),h_module_name,THREAD); &#125; return JvmtiExport::load_agent_library(agent, absParam, options, out);&#125; 这个函数先确保加载了java.instrument模块，之后真正执行Agent加载的函数是 load_agent_library ,这个函数的套路就是加载Agent动态链接库，如果是通过Java instrument API实现的Agent，则加载的是libinstrument动态链接库，然后通过libinstrument里面的代码实现运行agentmain方法的逻辑，这一部分内容和libinstrument实现premain方法运行的逻辑其实差不多，这里不再做分析。至此，我们对Java Agent技术已经有了一个全面而细致的了解。 动态字节码修改的限制上文中已经详细分析了Agent技术的实现，我们使用Java Instrumentation API来完成动态类修改的功能，在Instrumentation接口中，通过addTransformer方法来增加一个类转换器，类转换器由类ClassFileTransformer接口实现。ClassFileTransformer接口中唯一的方法transform用于实现类转换，当类被加载的时候，就会调用transform方法，进行类转换。在运行时，我们可以通过Instrumentation的redefineClasses方法进行类重定义，在方法上有一段注释需要特别注意： 123456* The redefinition may change method bodies, the constant pool and attributes.* The redefinition must not add, remove or rename fields or methods, change the* signatures of methods, or change inheritance. These restrictions maybe be* lifted in future versions. The class file bytes are not checked, verified and installed* until after the transformations have been applied, if the resultant bytes are in* error this method will throw an exception. 这里面提到，我们不可以增加、删除或者重命名字段和方法，改变方法的签名或者类的继承关系。认识到这一点很重要，当我们通过ASM获取到增强的字节码之后，如果增强后的字节码没有遵守这些规则，那么调用redefineClasses方法来进行类的重定义就会失败。那redefineClasses方法具体是怎么实现类的重定义的呢? 它对运行时的JVM会造成什么样的影响呢? 下面来分析redefineClasses的实现细节。 重定义类字节码的实现细节上文中我们提到，libinstrument动态链接库中，JPLISAgent不仅实现了Agent入口代码执行的路由，而且还是Java代码与JVMTI之间的一道桥梁。我们在Java代码中调用Java Instrumentation API的redefineClasses，其实会调用libinstrument中的相关代码，我们来分析一下这条路径。 1234567891011121314151617public void redefineClasses(ClassDefinition... var1) throws ClassNotFoundException &#123; if (!this.isRedefineClassesSupported()) &#123; throw new UnsupportedOperationException(&quot;redefineClasses is not supported in this environment&quot;); &#125; else if (var1 == null) &#123; throw new NullPointerException(&quot;null passed as &#x27;definitions&#x27; in redefineClasses&quot;); &#125; else &#123; for(int var2 = 0; var2 &lt; var1.length; ++var2) &#123; if (var1[var2] == null) &#123; throw new NullPointerException(&quot;element of &#x27;definitions&#x27; is null in redefineClasses&quot;); &#125; &#125; if (var1.length != 0) &#123; this.redefineClasses0(this.mNativeAgent, var1); &#125; &#125;&#125;private native void redefineClasses0(long var1, ClassDefinition[] var3) throws ClassNotFoundException; 这是InstrumentationImpl中的redefineClasses实现，该方法的具体实现依赖一个Native方法redefineClasses()，我们可以在libinstrument中找到这个Native方法的实现： 1234JNIEXPORT void JNICALL Java_sun_instrument_InstrumentationImpl_redefineClasses0 (JNIEnv * jnienv, jobject implThis, jlong agent, jobjectArray classDefinitions) &#123; redefineClasses(jnienv, (JPLISAgent*)(intptr_t)agent, classDefinitions);&#125; redefineClasses这个函数的实现比较复杂，代码很长。下面是一段关键的代码片段： 可以看到，其实是调用了JVMTI的RetransformClasses函数来完成类的重定义细节。 12345678// class_count - pre-checked to be greater than or equal to 0// class_definitions - pre-checked for NULLjvmtiError JvmtiEnv::RedefineClasses(jint class_count, const jvmtiClassDefinition* class_definitions) &#123;//TODO: add locking VM_RedefineClasses op(class_count, class_definitions, jvmti_class_load_kind_redefine); VMThread::execute(&amp;op); return (op.check_error());&#125; /* end RedefineClasses */ 重定义类的请求会被JVM包装成一个VM_RedefineClasses类型的VM_Operation，VM_Operation是JVM内部的一些操作的基类，包括GC操作等。VM_Operation由VMThread来执行，新的VM_Operation操作会被添加到VMThread的运行队列中去，VMThread会不断从队列里面拉取VM_Operation并调用其doit等函数执行具体的操作。VM_RedefineClasses函数的流程较为复杂，下面是VM_RedefineClasses的大致流程： 加载新的字节码，合并常量池，并且对新的字节码进行校验工作 12345// Load the caller&#x27;s new class definition(s) into _scratch_classes.// Constant pool merging work is done here as needed. Also calls// compare_and_normalize_class_versions() to verify the class// definition(s).jvmtiError load_new_class_versions(TRAPS); 清除方法上的断点 123// Remove all breakpoints in methods of this classJvmtiBreakpoints&amp; jvmti_breakpoints = JvmtiCurrentBreakpoints::get_jvmti_breakpoints();jvmti_breakpoints.clearall_in_class_at_safepoint(the_class()); JIT逆优化 12// Deoptimize all compiled code that depends on this classflush_dependent_code(the_class, THREAD); 进行字节码替换工作，需要进行更新类itable&#x2F;vtable等操作 进行类重定义通知 1SystemDictionary::notice_modification(); VM_RedefineClasses实现比较复杂的，详细实现可以参考 RedefineClasses的实现。 Java-debug-toolJava-debug-tool是一个使用Java Instrument API来实现的动态调试工具，它通过在目标JVM上启动一个TcpServer来和调试客户端通信。调试客户端通过命令行来发送调试命令给TcpServer，TcpServer中有专门用来处理命令的handler，handler处理完命令之后会将结果发送回客户端，客户端通过处理将调试结果展示出来。下面将详细介绍Java-debug-tool的整体设计和实现。 Java-debug-tool整体架构Java-debug-tool包括一个Java Agent和一个用于处理调试命令的核心API，核心API通过一个自定义的类加载器加载进来，以保证目标JVM的类不会被污染。整体上Java-debug-tool的设计是一个Client-Server的架构，命令客户端需要完整的完成一个命令之后才能继续执行下一个调试命令。Java-debug-tool支持多人同时进行调试，下面是整体架构图： 下面对每一层做简单介绍： 交互层：负责将程序员的输入转换成调试交互协议，并且将调试信息呈现出来。 连接管理层：负责管理客户端连接，从连接中读调试协议数据并解码，对调试结果编码并将其写到连接中去；同时将那些超时未活动的连接关闭。 业务逻辑层：实现调试命令处理，包括命令分发、数据收集、数据处理等过程。 基础实现层：Java-debug-tool实现的底层依赖，通过Java Instrumentation提供的API进行类查找、类重定义等能力，Java Instrumentation底层依赖JVMTI来完成具体的功能。 在Agent被挂载到目标JVM上之后，Java-debug-tool会安排一个Spy在目标JVM内活动，这个Spy负责将目标JVM内部的相关调试数据转移到命令处理模块，命令处理模块会处理这些数据，然后给客户端返回调试结果。命令处理模块会增强目标类的字节码来达到数据获取的目的，多个客户端可以共享一份增强过的字节码，无需重复增强。下面从Java-debug-tool的字节码增强方案、命令设计与实现等角度详细说明。 Java-debug-tool的字节码增强方案Java-debug-tool使用字节码增强来获取到方法运行时的信息，比如方法入参、出参等，可以在不同的字节码位置进行增强，这种行为可以称为“插桩”，每个“桩”用于获取数据并将他转储出去。Java-debug-tool具备强大的插桩能力，不同的桩负责获取不同类别的数据，下面是Java-debug-tool目前所支持的“桩”： 方法进入点：用于获取方法入参信息。 Fields获取点1：在方法执行前获取到对象的字段信息。 变量存储点：获取局部变量信息。 Fields获取点2：在方法退出前获取到对象的字段信息。 方法退出点：用于获取方法返回值。 抛出异常点：用于获取方法抛出的异常信息。 通过上面这些代码桩，Java-debug-tool可以收集到丰富的方法执行信息，经过处理可以返回更加可视化的调试结果。 字节码增强Java-debug-tool在实现上使用了ASM工具来进行字节码增强，并且每个插桩点都可以进行配置，如果不想要什么信息，则没必要进行对应的插桩操作。这种可配置的设计是非常有必要的，因为有时候我们仅仅是想要知道方法的入参和出参，但Java-debug-tool却给我们返回了所有的调试信息，这样我们就得在众多的输出中找到我们所关注的内容。如果可以进行配置，则除了入参点和出参点外其他的桩都不插，那么就可以快速看到我们想要的调试数据，这种设计的本质是为了让调试者更加专注。下面是Java-debug-tool的字节码增强工作方式： 如图所示，当调试者发出调试命令之后，Java-debug-tool会识别命令并判断是否需要进行字节码增强，如果命令需要增强字节码，则判断当前类+当前方法是否已经被增强过。上文已经提到，字节码替换是有一定损耗的，这种具有损耗的操作发生的次数越少越好，所以字节码替换操作会被记录起来，后续命令直接使用即可，不需要重复进行字节码增强，字节码增强还涉及多个调试客户端的协同工作问题，当一个客户端增强了一个类的字节码之后，这个客户端就锁定了该字节码，其他客户端变成只读，无法对该类进行字节码增强，只有当持有锁的客户端主动释放锁或者断开连接之后，其他客户端才能继续增强该类的字节码。 字节码增强模块收到字节码增强请求之后，会判断每个增强点是否需要插桩，这个判断的根据就是上文提到的插桩配置，之后字节码增强模块会生成新的字节码，Java-debug-tool将执行字节码替换操作，之后就可以进行调试数据收集了。 经过字节码增强之后，原来的方法中会插入收集运行时数据的代码，这些代码在方法被调用的时候执行，获取到诸如方法入参、局部变量等信息，这些信息将传递给数据收集装置进行处理。数据收集的工作通过Advice完成，每个客户端同一时间只能注册一个Advice到Java-debug-tool调试模块上，多个客户端可以同时注册自己的Advice到调试模块上。Advice负责收集数据并进行判断，如果当前数据符合调试命令的要求，Java-debug-tool就会卸载这个Advice，Advice的数据就会被转移到Java-debug-tool的命令结果处理模块进行处理，并将结果发送到客户端。 Advice的工作方式Advice是调试数据收集器，不同的调试策略会对应不同的Advice。Advice是工作在目标JVM的线程内部的，它需要轻量级和高效，意味着Advice不能做太过于复杂的事情，它的核心接口“match”用来判断本次收集到的调试数据是否满足调试需求。如果满足，那么Java-debug-tool就会将其卸载，否则会继续让他收集调试数据，这种“加载Advice” -&gt; “卸载Advice”的工作模式具备很好的灵活性。 关于Advice，需要说明的另外一点就是线程安全，因为它加载之后会运行在目标JVM的线程中，目标JVM的方法极有可能是多线程访问的，这也就是说，Advice需要有能力处理多个线程同时访问方法的能力，如果Advice处理不当，则可能会收集到杂乱无章的调试数据。下面的图片展示了Advice和Java-debug-tool调试分析模块、目标方法执行以及调试客户端等模块的关系。 Advice的首次挂载由Java-debug-tool的命令处理器完成，当一次调试数据收集完成之后，调试数据处理模块会自动卸载Advice，然后进行判断，如果调试数据符合Advice的策略，则直接将数据交由数据处理模块进行处理，否则会清空调试数据，并再次将Advice挂载到目标方法上去，等待下一次调试数据。非首次挂载由调试数据处理模块进行，它借助Advice按需取数据，如果不符合需求，则继续挂载Advice来获取数据，否则对调试数据进行处理并返回给客户端。 Java-debug-tool的命令设计与实现命令执行上文已经完整的描述了Java-debug-tool的设计以及核心技术方案，本小节将详细介绍Java-debug-tool的命令设计与实现。首先需要将一个调试命令的执行流程描述清楚，下面是一张用来表示命令请求处理流程的图片： 上图简单的描述了Java-debug-tool的命令处理方式，客户端连接到服务端之后，会进行一些协议解析、协议认证、协议填充等工作，之后将进行命令分发。服务端如果发现客户端的命令不合法，则会立即返回错误信息，否则再进行命令处理。命令处理属于典型的三段式处理，前置命令处理、命令处理以及后置命令处理，同时会对命令处理过程中的异常信息进行捕获处理，三段式处理的好处是命令处理被拆成了多个阶段，多个阶段负责不同的职责。前置命令处理用来做一些命令权限控制的工作，并填充一些类似命令处理开始时间戳等信息，命令处理就是通过字节码增强，挂载Advice进行数据收集，再经过数据处理来产生命令结果的过程，后置处理则用来处理一些连接关闭、字节码解锁等事项。 Java-debug-tool允许客户端设置一个命令执行超时时间，超过这个时间则认为命令没有结果，如果客户端没有设置自己的超时时间，就使用默认的超时时间进行超时控制。Java-debug-tool通过设计了两阶段的超时检测机制来实现命令执行超时功能：首先，第一阶段超时触发，则Java-debug-tool会友好的警告命令处理模块处理时间已经超时，需要立即停止命令执行，这允许命令自己做一些现场清理工作，当然需要命令执行线程自己感知到这种超时警告；当第二阶段超时触发，则Java-debug-tool认为命令必须结束执行，会强行打断命令执行线程。超时机制的目的是为了不让命令执行太长时间，命令如果长时间没有收集到调试数据，则应该停止执行，并思考是否调试了一个错误的方法。当然，超时机制还可以定期清理那些因为未知原因断开连接的客户端持有的调试资源，比如字节码锁。 获取方法执行视图Java-debug-tool通过下面的信息来向调试者呈现出一次方法执行的视图： 正在调试的方法信息。 方法调用堆栈。 调试耗时，包括对目标JVM造成的STW时间。 方法入参，包括入参的类型及参数值。 方法的执行路径。 代码执行耗时。 局部变量信息。 方法返回结果。 方法抛出的异常。 对象字段值快照。 下图展示了Java-debug-tool获取到正在运行的方法的执行视图的信息。 Java-debug-tool与同类产品对比分析Java-debug-tool的同类产品主要是greys，其他类似的工具大部分都是基于greys进行的二次开发，所以直接选择greys来和Java-debug-tool进行对比。 本文详细剖析了Java动态调试关键技术的实现细节，并介绍了我们基于Java动态调试技术结合实际故障排查场景进行的一点探索实践；动态调试技术为研发人员进行线上问题排查提供了一种新的思路，我们基于动态调试技术解决了传统断点调试存在的问题，使得可以将断点调试这种技术应用在线上，以线下调试的思维来进行线上调试，提高问题排查效率。 参考文献 ASM 4 guide Java Virtual Machine Specification JVM Tool Interface alibaba arthas openjdk","tags":["Java","JVM","调试排错","Java动态调试"],"categories":["Java","JVM","调试排错","Java动态调试"]},{"title":"20.调试排错 - Java 问题排查之使用IDEA本地调试和远程调试","path":"/2023/12/27/20-调试排错-Java-问题排查之使用IDEA本地调试和远程调试/","content":"Debug用来追踪代码的运行流程，通常在程序运行过程中出现异常，启用Debug模式可以分析定位异常发生的位置，以及在运行过程中参数的变化；并且在实际的排错过程中，还会用到Remote Debug。IDEA 相比 Eclipse&#x2F;STS效率更高，本文主要介绍基于IDEA的Debug和Remote Debug的技巧。 Debug开篇 首先看下IDEA中Debug模式下的界面。 如下是在IDEA中启动Debug模式，进入断点后的界面，我这里是Windows，可能和Mac的图标等会有些不一样。就简单说下图中标注的8个地方： ① 以Debug模式启动服务，左边的一个按钮则是以Run模式启动。在开发中，我一般会直接启动Debug模式，方便随时调试代码。 ② 断点：在左边行号栏单击左键，或者快捷键Ctrl+F8 打上&#x2F;取消断点，断点行的颜色可自己去设置。 ③ Debug窗口：访问请求到达第一个断点后，会自动激活Debug窗口。如果没有自动激活，可以去设置里设置，如图1.2。 ④ 调试按钮：一共有8个按钮，调试的主要功能就对应着这几个按钮，鼠标悬停在按钮上可以查看对应的快捷键。在菜单栏Run里可以找到同样的对应的功能，如图1.4。 ⑤ 服务按钮：可以在这里关闭&#x2F;启动服务，设置断点等。 ⑥ 方法调用栈：这里显示了该线程调试所经过的所有方法，勾选右上角的[Show All Frames]按钮，就不会显示其它类库的方法了，否则这里会有一大堆的方法。 ⑦ Variables：在变量区可以查看当前断点之前的当前方法内的变量。 ⑧ Watches：查看变量，可以将Variables区中的变量拖到Watches中查看 在设置里勾选Show debug window on breakpoint，则请求进入到断点后自动激活Debug窗口 如果你的IDEA底部没有显示工具栏或状态栏，可以在View里打开，显示出工具栏会方便我们使用。可以自己去尝试下这四个选项。 在菜单栏Run里有调试对应的功能，同时可以查看对应的快捷键。 基本用法&amp;快捷键Debug调试的功能主要对应着图一中4和5两组按钮： 首先说第一组按钮，共8个按钮，从左到右依次如下： Show Execution Point (Alt + F10)：如果你的光标在其它行或其它页面，点击这个按钮可跳转到当前代码执行的行。 Step Over (F8)：步过，一行一行地往下走，如果这一行上有方法不会进入方法。 Step Into (F7)：步入，如果当前行有方法，可以进入方法内部，一般用于进入自定义方法内，不会进入官方类库的方法，如第25行的put方法。 Force Step Into (Alt + Shift + F7)：强制步入，能进入任何方法，查看底层源码的时候可以用这个进入官方类库的方法。 Step Out (Shift + F8)：步出，从步入的方法内退出到方法调用处，此时方法已执行完毕，只是还没有完成赋值。 Drop Frame (默认无)：回退断点，后面章节详细说明。 Run to Cursor (Alt + F9)：运行到光标处，你可以将光标定位到你需要查看的那一行，然后使用这个功能，代码会运行至光标行，而不需要打断点。 Evaluate Expression (Alt + F8)：计算表达式，后面章节详细说明。 第二组按钮，共7个按钮，从上到下依次如下： Rerun &#39;xxxx&#39;：重新运行程序，会关闭服务后重新启动程序。 Update &#39;tech&#39; application (Ctrl + F5)：更新程序，一般在你的代码有改动后可执行这个功能。而这个功能对应的操作则是在服务配置里，如图2.3。 Resume Program (F9)：恢复程序，比如，你在第20行和25行有两个断点，当前运行至第20行，按F9，则运行到下一个断点(即第25行)，再按F9，则运行完整个流程，因为后面已经没有断点了。 Pause Program：暂停程序，启用Debug。目前没发现具体用法。 Stop &#39;xxx&#39; (Ctrl + F2)：连续按两下，关闭程序。有时候你会发现关闭服务再启动时，报端口被占用，这是因为没完全关闭服务的原因，你就需要查杀所有JVM进程了。 View Breakpoints (Ctrl + Shift + F8)：查看所有断点，后面章节会涉及到。 Mute Breakpoints：哑的断点，选择这个后，所有断点变为灰色，断点失效，按F9则可以直接运行完程序。再次点击，断点变为红色，有效。如果只想使某一个断点失效，可以在断点上右键取消Enabled，则该行断点失效。 更新程序 On &#39;Update&#39; actions，执行更新操作时所做的事情，一般选择&#39;Update classes and resources&#39;，即更新类和资源文件。 一般配合热部署插件会更好用，如JRebel，这样就不用每次更改代码后还要去重新启动服务。如何激活JRebel，在最后章节附上。 下面的On frame deactivation，在IDEA窗口失去焦点时触发，即一般你从idea切换到浏览器的时候，idea会自动帮你做的事情，一般可以设置Do nothing，频繁切换会比较消耗资源的。 变量查看 在Debug过程中，跟踪查看变量的变化是非常必要的，这里就简单说下IDEA中可以查看变量的几个地方，相信大部分人都了解。 如下，在IDEA中，参数所在行后面会显示当前变量的值。 光标悬停到参数上，显示当前变量信息。点击打开详情如下图。我一般会使用这种方式，快捷方便。 在Variables里查看，这里显示当前方法里的所有变量。 在Watches里，点击New Watch，输入需要查看的变量。或者可以从Variables里拖到Watche里查看。 如果你发现你没有Watches，可能在下图所在的地方。 计算表达式 在前面提到的计算表达式如下图的按钮，Evaluate Expression (Alt + F8) 。可以使用这个操作在调试过程中计算某个表达式的值，而不用再去打印信息。 按Alt + F8或按钮，或者，你可以选中某个表达式再Alt + F8，弹出计算表达式的窗口，如下，回车或点击Evaluate计算表达式的值。 这个表达式不仅可以是一般变量或参数，也可以是方法，当你的一行代码中调用了几个方法时，就可以通过这种方式查看查看某个方法的返回值。 设置变量，在计算表达式的框里，可以改变变量的值，这样有时候就能很方便我们去调试各种值的情况了不是。 智能步入 想想，一行代码里有好几个方法，怎么只选择某一个方法进入。之前提到过使用Step Into (Alt + F7) 或者 Force Step Into (Alt + Shift + F7)进入到方法内部，但这两个操作会根据方法调用顺序依次进入，这比较麻烦。 那么智能步入就很方便了，智能步入，这个功能在Run里可以看到，Smart Step Into (Shift + F7)，如下图 按Shift + F7，会自动定位到当前断点行，并列出需要进入的方法，如图5.2，点击方法进入方法内部。 如果只有一个方法，则直接进入，类似Force Step Into。 断点条件设置 通过设置断点条件，在满足条件时，才停在断点处，否则直接运行。 通常，当我们在遍历一个比较大的集合或数组时，在循环内设置了一个断点，难道我们要一个一个去看变量的值？那肯定很累，说不定你还错过这个值得重新来一次。 在断点上右键直接设置当前断点的条件，如下图设置exist为true时断点才生效。 点击View Breakpoints (Ctrl + Shift + F8)，查看所有断点。 Java Line Breakpoints 显示了所有的断点，在右边勾选Condition，设置断点的条件。 勾选Log message to console，则会将当前断点行输出到控制台，如图6.3 勾选Evaluate and log，可以在执行这行代码是计算表达式的值，并将结果输出到控制台。 再说说右边的Filters过滤 ，这些一般情况下不常用，简单说下意思。 Instance filters：实例过滤，输入实例ID(如下图中的实例ID)，但是我这里没有成功，不知道什么原因，知道的朋友留个言。 Class filters：类过滤，根据类名过滤，同样没有成功…. Pass count：用于循环中，如果断点在循环中，可以设置该值，循环多少次后停在断点处，之后的循环都会停在断点处。 异常断点，通过设置异常断点，在程序中出现需要拦截的异常时，会自动定位到异常行。 如下图，点击+号添加Java Exception Breakpoints，添加异常断点。然后输入需要断点的异常类 之后可以在Java Exception Breakpoints里看到添加的异常断点。 这里添加了一个NullPointerException异常断点，出现空指针异常后，自动定位在空指针异常行。 多线程调试 一般情况下我们调试的时候是在一个线程中的，一步一步往下走。但有时候你会发现在Debug的时候，想发起另外一个请求都无法进行了？ 那是因为IDEA在Debug时默认阻塞级别是ALL，会阻塞其它线程，只有在当前调试线程走完时才会走其它线程。可以在View Breakpoints里选择Thread，如图7.1，然后点击Make Default设置为默认选项。 切换线程，在下图中Frames的下拉列表里，可以切换当前的线程，如下我这里有两个Debug的线程，切换另外一个则进入另一个Debug的线程。 回退断点 在调试的时候，想要重新走一下流程而不用再次发起一个请求？ 首先认识下这个方法调用栈，如图首先请求进入DemoController的insertDemo方法，然后调用insert方法，其它的invoke我们且先不管，最上面的方法是当前断点所在的方法。 断点回退 所谓的断点回退，其实就是回退到上一个方法调用的开始处，在IDEA里测试无法一行一行地回退或回到到上一个断点处，而是回到上一个方法。 回退的方式有两种，一种是Drop Frame按钮，按调用的方法逐步回退，包括三方类库的其它方法 取消Show All Frames按钮会显示三方类库的方法 第二种方式，在调用栈方法上选择要回退的方法，右键选择Drop Frame，回退到该方法的上一个方法调用处，此时再按F9(Resume Program)，可以看到程序进入到该方法的断点处了。 但有一点需要注意，断点回退只能重新走一下流程，之前的某些参数&#x2F;数据的状态已经改变了的是无法回退到之前的状态的，如对象、集合、更新了数据库数据等等。 中断Debug 想要在Debug的时候，中断请求，不要再走剩余的流程了？ 有些时候，我们看到传入的参数有误后，不想走后面的流程了，怎么中断这次请求呢(后面的流程要删除数据库数据呢….)，难道要关闭服务重新启动程序？嗯，我以前也是这么干的。 确切的说，我也没发现可以直接中断请求的方式(除了关闭服务)，但可以通过Force Return，即强制返回来避免后续的流程，如图 点击Force Return，弹出Return Value的窗口，我这个方法的返回类型为Map，所以，我这里直接返回 results，来强制返回，从而不再进行后续的流程。或者你可以new HashMap&lt;&gt;()。 远程调试(Remote Debug) 有时候，本地调试的时候没有问题，打包部署到测试环境的时候却爆出一堆莫名其妙的问题，这时该怎么办呢？ 使用特定JVM参数运行服务端代码要让远程服务器运行的代码支持远程调试，则启动的时候必须加上特定的JVM参数，这些参数是： 1-Xdebug -Xrunjdwp:transport=dt_socket,suspend=n,server=y,address=$&#123;debug_port&#125; 其中的$&#123;debug_port&#125;是用户自定义的，为debug端口，本例以5555端口为例。 本人在这里踩过一个坑，必须要说一下。在使用公司内部的自动化部署平台NDP进行应用部署时，该平台号称支持远程调试，只需要在某个配置页面配置一下调试端口号（没有填写任何IP相关的信息），并且重新发布一下应用即可。事实上也可以发现，上述JVM参数中唯一可变的就是${debug_port}。但是实际在本地连接时发现却始终连不上5555 的调试端口，仔细排查才发现，下面截取了NDP发布的应用所有JVM参数列表中与远程调试相关的JVM启动参数如下： 1-Xdebug -Xrunjdwp:transport=dt_socket,suspend=n,server=y,address=127.0.0.1:5555 将address设置为127.0.0.1:5555，表示将调试端口限制为本地访问，远程无法访问，这个应该是NDP平台的一个bug，我们在自己设置JVM的启动参数时也需要格外注意。 如果只是临时调试，在端口号前面不要加上限制访问的IP地址，调试完成之后，将上述JVM参数去除掉之后重新发布下，防范开放远程调试端口可能带来的安全风险。 本地连接远程服务器debug端口打开Intellij IDEA，在顶部靠右的地方选择”Edit Configurations…”，进去之后点击+号，选择”Remote”，按照下图的只是填写红框内的内容，其中Name填写名称，这里为remote webserver，host为远程代码运行的机器的ip&#x2F;hostname，port为上一步指定的debug_port，本例是5555。然后点击Apply，最后点击OK即可 现在在上一步选择”Edit Configurations…”的下拉框的位置选择上一步创建的remote webserver，然后点击右边的debug按钮(长的像臭虫那个)，看控制台日志，如果出现类似“Connected to the target VM, address: ‘xx.xx.xx.xx:5555’, transport: ‘socket’”的字样，就表示连接成功过了。我这里实际显示的内容如下： 1Connected to the target VM, address: &#x27;10.185.0.192:15555&#x27;, transport: &#x27;socket&#x27; 设置断点，开始调试远程debug模式已经开启，现在可以在需要调试的代码中打断点了，比如： 如图中所示，如果断点内有√，则表示选取的断点正确。 现在在本地发送一个到远程服务器的请求，看本地控制台的bug界面，划到debugger这个标签，可以看到当前远程服务的内部状态（各种变量）已经全部显示出来了，并且在刚才设置了断点的地方，也显示了该行的变量值。 备注：需要注意的是，用于远程debug的代码必须与远程部署的代码完全一致，不能发生任何的修改，否则打上的断点将无法命中，切记切记。 参考文章 前面9个部分，主要总结自 https://www.cnblogs.com/diaobiyong/p/10682996.html 远程调试，主要整理自 https://www.jianshu.com/p/302dc10217c0","tags":["Java","JVM","调试排错","问题排查","IDEA"],"categories":["Java","JVM","调试排错","问题排查"]},{"title":"19.调试排错 - Java 问题排查之应用在线调试Arthas","path":"/2023/12/27/19-调试排错-Java-问题排查之应用在线调试Arthas/","content":"本文主要介绍Alibaba开源的Java诊断工具，开源到现在已经几万个点赞了，深受开发者喜爱。 Arthas简介 在学习Arthas之前，推荐先看上一篇美团技术团队的Java 动态调试技术原理及实践，这样你会对它最底层技术有个了解。可以看下文中最后有个对比图：Greys(Arthas也是基于它做的二次开发)和Java-debug-tool。 Arthas是什么Arthas 是Alibaba开源的Java诊断工具，深受开发者喜爱。 Arthas能解决什么问题当你遇到以下类似问题而束手无策时，Arthas可以帮助你解决： 这个类从哪个 jar 包加载的? 为什么会报各种类相关的 Exception? 我改的代码为什么没有执行到? 难道是我没 commit? 分支搞错了? 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗? 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况? 有什么办法可以监控到JVM的实时运行状态? Arthas支持JDK 6+，支持Linux&#x2F;Mac&#x2F;Windows，采用命令行交互模式，同时提供丰富的 Tab 自动补全功能，进一步方便进行问题的定位和诊断。 Arthas资源推荐 用户文档 官方在线教程(推荐) 快速入门 进阶使用 命令列表 WebConsole Docker 用户案例 常见问题 Arthas基于了哪些工具上发展而来 greys-anatomy: Arthas代码基于Greys二次开发而来，非常感谢Greys之前所有的工作，以及Greys原作者对Arthas提出的意见和建议！ termd: Arthas的命令行实现基于termd开发，是一款优秀的命令行程序开发框架，感谢termd提供了优秀的框架。 crash: Arthas的文本渲染功能基于crash中的文本渲染功能开发，可以从这里看到源码，感谢crash在这方面所做的优秀工作。 cli: Arthas的命令行界面基于vert.x提供的cli库进行开发，感谢vert.x在这方面做的优秀工作。 compiler Arthas里的内存编绎器代码来源 Apache Commons Net Arthas里的Telnet Client代码来源 JavaAgent：运行在 main方法之前的拦截器，它内定的方法名叫 premain ，也就是说先执行 premain 方法然后再执行 main 方法 ASM：一个通用的Java字节码操作和分析框架。它可以用于修改现有的类或直接以二进制形式动态生成类。ASM提供了一些常见的字节码转换和分析算法，可以从它们构建定制的复杂转换和代码分析工具。ASM提供了与其他Java字节码框架类似的功能，但是主要关注性能。因为它被设计和实现得尽可能小和快，所以非常适合在动态系统中使用(当然也可以以静态方式使用，例如在编译器中) 同类工具有哪些 BTrace 美团 Java-debug-tool 去哪儿Bistoury: 一个集成了Arthas的项目 一个使用MVEL脚本的fork Arthas入门Arthas 上手前推荐先在线使用下arthas：官方在线教程(推荐) Arthas 安装下载arthas-boot.jar，然后用java -jar的方式启动： 12curl -O https://alibaba.github.io/arthas/arthas-boot.jarjava -jar arthas-boot.jar Arthas 官方案例展示Dashboard https://alibaba.github.io/arthas/dashboard Thread一目了然的了解系统的状态，哪些线程比较占cpu? 他们到底在做什么? 123456789101112131415161718192021222324$ thread -n 3&quot;as-command-execute-daemon&quot; Id=29 cpuUsage=75% RUNNABLE at sun.management.ThreadImpl.dumpThreads0(Native Method) at sun.management.ThreadImpl.getThreadInfo(ThreadImpl.java:440) at com.taobao.arthas.core.command.monitor200.ThreadCommand$1.action(ThreadCommand.java:58) at com.taobao.arthas.core.command.handler.AbstractCommandHandler.execute(AbstractCommandHandler.java:238) at com.taobao.arthas.core.command.handler.DefaultCommandHandler.handleCommand(DefaultCommandHandler.java:67) at com.taobao.arthas.core.server.ArthasServer$4.run(ArthasServer.java:276) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) Number of locked synchronizers = 1 - java.util.concurrent.ThreadPoolExecutor$Worker@6cd0b6f8&quot;as-session-expire-daemon&quot; Id=25 cpuUsage=24% TIMED_WAITING at java.lang.Thread.sleep(Native Method) at com.taobao.arthas.core.server.DefaultSessionManager$2.run(DefaultSessionManager.java:85)&quot;Reference Handler&quot; Id=2 cpuUsage=0% WAITING on java.lang.ref.Reference$Lock@69ba0f27 at java.lang.Object.wait(Native Method) - waiting on java.lang.ref.Reference$Lock@69ba0f27 at java.lang.Object.wait(Object.java:503) at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:133) jad对类进行反编译: 1234567891011121314151617181920212223242526272829303132$ jad javax.servlet.ServletClassLoader:+-java.net.URLClassLoader@6108b2d7 +-sun.misc.Launcher$AppClassLoader@18b4aac2 +-sun.misc.Launcher$ExtClassLoader@1ddf84b8Location:/Users/xxx/work/test/lib/servlet-api.jar/* * Decompiled with CFR 0_122. */package javax.servlet;import java.io.IOException;import javax.servlet.ServletConfig;import javax.servlet.ServletException;import javax.servlet.ServletRequest;import javax.servlet.ServletResponse;public interface Servlet &#123; public void init(ServletConfig var1) throws ServletException; public ServletConfig getServletConfig(); public void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException; public String getServletInfo(); public void destroy();&#125; mcMemory Compiler&#x2F;内存编译器，编译.java文件生成.class。 1mc /tmp/Test.java redefine加载外部的.class文件，redefine jvm已加载的类。 12redefine /tmp/Test.classredefine -c 327a647b /tmp/Test.class /tmp/Test\\$Inner.class sc查找JVM中已经加载的类 12345678910111213141516171819202122232425262728$ sc -d org.springframework.web.context.support.XmlWebApplicationContext class-info org.springframework.web.context.support.XmlWebApplicationContext code-source /Users/xxx/work/test/WEB-INF/lib/spring-web-3.2.11.RELEASE.jar name org.springframework.web.context.support.XmlWebApplicationContext isInterface false isAnnotation false isEnum false isAnonymousClass false isArray false isLocalClass false isMemberClass false isPrimitive false isSynthetic false simple-name XmlWebApplicationContext modifier public annotation interfaces super-class +-org.springframework.web.context.support.AbstractRefreshableWebApplicationContext +-org.springframework.context.support.AbstractRefreshableConfigApplicationContext +-org.springframework.context.support.AbstractRefreshableApplicationContext +-org.springframework.context.support.AbstractApplicationContext +-org.springframework.core.io.DefaultResourceLoader +-java.lang.Object class-loader +-org.apache.catalina.loader.ParallelWebappClassLoader +-java.net.URLClassLoader@6108b2d7 +-sun.misc.Launcher$AppClassLoader@18b4aac2 +-sun.misc.Launcher$ExtClassLoader@1ddf84b8 classLoaderHash 25131501 stack查看方法 test.arthas.TestStack#doGet 的调用堆栈： 12345678910111213141516171819202122232425262728$ stack test.arthas.TestStack doGetPress Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 286 ms.ts=2018-09-18 10:11:45;thread_name=http-bio-8080-exec-10;id=d9;is_daemon=true;priority=5;TCCL=org.apache.catalina.loader.ParallelWebappClassLoader@25131501 @test.arthas.TestStack.doGet() at javax.servlet.http.HttpServlet.service(HttpServlet.java:624) at javax.servlet.http.HttpServlet.service(HttpServlet.java:731) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241) at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208) at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220) at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:110) ... at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:169) at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103) at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116) at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:451) at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1121) at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:637) at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:316) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) at java.lang.Thread.run(Thread.java:745) Trace观察方法执行的时候哪个子调用比较慢: Watch观察方法 test.arthas.TestWatch#doGet 执行的入参，仅当方法抛出异常时才输出。 1234567$ watch test.arthas.TestWatch doGet &#123;params[0], throwExp&#125; -ePress Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 65 ms.ts=2018-09-18 10:26:28;result=@ArrayList[ @RequestFacade[org.apache.catalina.connector.RequestFacade@79f922b2], @NullPointerException[java.lang.NullPointerException],] Monitor监控某个特殊方法的调用统计数据，包括总调用次数，平均rt，成功率等信息，每隔5秒输出一次。 1234567891011121314$ monitor -c 5 org.apache.dubbo.demo.provider.DemoServiceImpl sayHelloPress Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 109 ms. timestamp class method total success fail avg-rt(ms) fail-rate---------------------------------------------------------------------------------------------------------------------------- 2018-09-20 09:45:32 org.apache.dubbo.demo.provider.DemoServiceImpl sayHello 5 5 0 0.67 0.00% timestamp class method total success fail avg-rt(ms) fail-rate---------------------------------------------------------------------------------------------------------------------------- 2018-09-20 09:45:37 org.apache.dubbo.demo.provider.DemoServiceImpl sayHello 5 5 0 1.00 0.00% timestamp class method total success fail avg-rt(ms) fail-rate---------------------------------------------------------------------------------------------------------------------------- 2018-09-20 09:45:42 org.apache.dubbo.demo.provider.DemoServiceImpl sayHello 5 5 0 0.43 0.00% Time Tunnel(tt)记录方法调用信息，支持事后查看方法调用的参数，返回值，抛出的异常等信息，仿佛穿越时空隧道回到调用现场一般。 1234567891011121314$ tt -t org.apache.dubbo.demo.provider.DemoServiceImpl sayHelloPress Ctrl+C to abort.Affect(class-cnt:1 , method-cnt:1) cost in 75 ms. INDEX TIMESTAMP COST(ms) IS-RET IS-EXP OBJECT CLASS METHOD------------------------------------------------------------------------------------------------------------------------------------- 1000 2018-09-20 09:54:10 1.971195 true false 0x55965cca DemoServiceImpl sayHello 1001 2018-09-20 09:54:11 0.215685 true false 0x55965cca DemoServiceImpl sayHello 1002 2018-09-20 09:54:12 0.236303 true false 0x55965cca DemoServiceImpl sayHello 1003 2018-09-20 09:54:13 0.159598 true false 0x55965cca DemoServiceImpl sayHello 1004 2018-09-20 09:54:14 0.201982 true false 0x55965cca DemoServiceImpl sayHello 1005 2018-09-20 09:54:15 0.214205 true false 0x55965cca DemoServiceImpl sayHello 1006 2018-09-20 09:54:16 0.241863 true false 0x55965cca DemoServiceImpl sayHello 1007 2018-09-20 09:54:17 0.305747 true false 0x55965cca DemoServiceImpl sayHello 1008 2018-09-20 09:54:18 0.18468 true false 0x55965cca DemoServiceImpl sayHello Classloader了解当前系统中有多少类加载器，以及每个加载器加载的类数量，帮助您判断是否有类加载器泄露。 123456789101112$ classloader name numberOfInstances loadedCountTotal BootstrapClassLoader 1 3346 com.taobao.arthas.agent.ArthasClassloader 1 1262 java.net.URLClassLoader 2 1033 org.apache.catalina.loader.ParallelWebappClassLoader 1 628 sun.reflect.DelegatingClassLoader 166 166 sun.misc.Launcher$AppClassLoader 1 31 com.alibaba.fastjson.util.ASMClassLoader 6 15 sun.misc.Launcher$ExtClassLoader 1 7 org.jvnet.hk2.internal.DelegatingClassLoader 2 2 sun.reflect.misc.MethodUtil 1 1 Web Console https://alibaba.github.io/arthas/web-console Arthas 命令集基础命令 help——查看命令帮助信息 cat——打印文件内容，和linux里的cat命令类似 grep——匹配查找，和linux里的grep命令类似 pwd——返回当前的工作目录，和linux命令类似 cls——清空当前屏幕区域 session——查看当前会话的信息 reset——重置增强类，将被 Arthas 增强过的类全部还原，Arthas 服务端关闭时会重置所有增强过的类 version——输出当前目标 Java 进程所加载的 Arthas 版本号 history——打印命令历史 quit——退出当前 Arthas 客户端，其他 Arthas 客户端不受影响 stop&#x2F;shutdown——关闭 Arthas 服务端，所有 Arthas 客户端全部退出 keymap——Arthas快捷键列表及自定义快捷键 jvm相关 dashboard——当前系统的实时数据面板 thread——查看当前 JVM 的线程堆栈信息 jvm——查看当前 JVM 的信息 sysprop——查看和修改JVM的系统属性 sysenv——查看JVM的环境变量 vmoption——查看和修改JVM里诊断相关的option logger——查看和修改logger getstatic——查看类的静态属性 ognl——执行ognl表达式 mbean——查看 Mbean 的信息 heapdump——dump java heap, 类似jmap命令的heap dump功能 class&#x2F;classloader相关 sc——查看JVM已加载的类信息 sm——查看已加载类的方法信息 jad——反编译指定已加载类的源码 mc——内存编绎器，内存编绎.java文件为.class文件 redefine——加载外部的.class文件，redefine到JVM里 dump——dump 已加载类的 byte code 到特定目录 classloader——查看classloader的继承树，urls，类加载信息，使用classloader去getResource monitor&#x2F;watch&#x2F;trace相关 请注意，这些命令，都通过字节码增强技术来实现的，会在指定类的方法中插入一些切面来实现数据统计和观测，因此在线上、预发使用时，请尽量明确需要观测的类、方法以及条件，诊断结束要执行 shutdown 或将增强过的类执行 reset 命令。 monitor——方法执行监控 watch——方法执行数据观测 trace——方法内部调用路径，并输出方法路径上的每个节点上耗时 stack——输出当前方法被调用的调用路径 tt——方法执行数据的时空隧道，记录下指定方法每次调用的入参和返回信息，并能对这些不同的时间下调用进行观测 options options——查看或设置Arthas全局开关 管道Arthas支持使用管道对上述命令的结果进行进一步的处理，如sm java.lang.String * | grep &#39;index&#39; grep——搜索满足条件的结果 plaintext——将命令的结果去除ANSI颜色 wc——按行统计输出结果 后台异步任务当线上出现偶发的问题，比如需要watch某个条件，而这个条件一天可能才会出现一次时，异步后台任务就派上用场了，详情请参考这里 使用 &gt; 将结果重写向到日志文件，使用 &amp; 指定命令是后台运行，session断开不影响任务执行(生命周期默认为1天) jobs——列出所有job kill——强制终止任务 fg——将暂停的任务拉到前台执行 bg——将暂停的任务放到后台执行 Web Console通过websocket连接Arthas。 Web Console 用户数据回报在3.1.4版本后，增加了用户数据回报功能，方便统一做安全或者历史数据统计。 在启动时，指定stat-url，就会回报执行的每一行命令，比如： ./as.sh --stat-url &#39;http://192.168.10.11:8080/api/stat&#39; 在tunnel server里有一个示例的回报代码，用户可以自己在服务器上实现。 StatController.java 其他特性 异步命令支持 执行结果存日志 批处理的支持 ognl表达式的用法说明 Arthas场景实战查看最繁忙的线程，以及是否有阻塞情况发生? 场景：我想看下查看最繁忙的线程，以及是否有阻塞情况发生? 常规查看线程，一般我们可以通过 top 等系统命令进行查看，但是那毕竟要很多个步骤，很麻烦。 123thread -n 3 # 查看最繁忙的三个线程栈信息thread # 以直观的方式展现所有的线程情况thread -b #找出当前阻塞其他线程的线程 确认某个类是否已被系统加载? 场景：我新写了一个类或者一个方法，我想知道新写的代码是否被部署了? 12345678# 即可以找到需要的类全路径，如果存在的话sc *MyServlet# 查看这个某个类所有的方法sm org.tech.servlet.TestMyServlet *# 查看某个方法的信息，如果存在的话sm org.tech.servlet.TestMyServlet testMethod 如何查看一个class类的源码信息? 场景：我新修改的内容在方法内部，而上一个步骤只能看到方法，这时候可以反编译看下源码 12# 直接反编译出java 源代码，包含一此额外信息的jad org.tech.servlet.TestMyServlet 重要：如何跟踪某个方法的返回值、入参…. ? 场景：我想看下我新加的方法在线运行的参数和返回值? 12# 同时监控入参，返回值，及异常watch org.tech.servlet.TestMyServlet testMethod &quot;&#123;params, returnObj, throwExp&#125;&quot; -e -x 2 具体看watch命令。 如何看方法调用栈的信息? 场景：我想看下某个方法的调用栈的信息? 1stack org.tech.servlet.TestMyServlet testMethod 运行此命令之后需要即时触发方法才会有响应的信息打印在控制台上 重要：找到最耗时的方法调用? 场景：testMethod这个方法入口响应很慢，如何找到最耗时的子调用? 12# 执行的时候每个子调用的运行时长，可以找到最耗时的子调用。trace org.tech.servlet.TestMyServlet testMethod 运行此命令之后需要即时触发方法才会有响应的信息打印在控制台上，然后一层一层看子调用。 重要：如何临时更改代码运行? 场景：我找到了问题所在，能否线上直接修改测试，而不需要在本地改了代码后，重新打包部署，然后重启观察效果? 12345678# 先反编译出class源码jad --source-only com.example.demo.arthas.user.UserController &gt; /tmp/UserController.java # 然后使用外部工具编辑内容mc /tmp/UserController.java -d /tmp # 再编译成class# 最后，重新载入定义的类，就可以实时验证你的猜测了redefine /tmp/com/example/demo/arthas/user/UserController.class 如上，是直接更改线上代码的方式，但是一般好像是编译不成功的。所以，最好是本地ide编译成 class文件后，再上传替换为好！ 总之，已经完全不用重启和发布了！这个功能真的很方便，比起重启带来的代价，真的是不可比的。比如，重启时可能导致负载重分配，选主等等问题，就不是你能控制的了。 我如何测试某个方法的性能问题? 场景：我想看下某个方法的性能 1monitor -c 5 demo.MathGame primeFactors 更多请参考: 官方Issue墙 Arthas源码首先我们先放出一张整体宏观的模块调用图： 源码理解可以看移步这两篇文章: 什么是 Arthas Arthas阅读 参考资料 https://www.cnblogs.com/muxuanchan/p/10097639.html https://www.cnblogs.com/yougewe/p/10770690.html https://help.aliyun.com/document_detail/112975.html","tags":["Java","JVM","调试排错","问题排查","Arthas"],"categories":["Java","JVM","调试排错","问题排查"]},{"title":"18.调试排错 - Java 问题排查之JVM可视化工具","path":"/2023/12/27/18-调试排错-Java-问题排查之JVM可视化工具/","content":"本文主要梳理常见的JVM可视化的分析工具，主要包括JConsole, Visual VM, Vusial GC, JProfile 和 MAT等。 JConsole Jconsole （Java Monitoring and Management Console），JDK自带的基于JMX的可视化监视、管理工具。 官方文档可以参考这里 找到jconsole工具 12345678pdai@MacBook-Pro bin % lsjaotc jcmd jinfo jshell rmidjar jconsole(这里)\tjjs jstack rmiregistryjarsigner\tjdb jlink jstat serialverjava jdeprscan\tjmap jstatd unpack200javac jdeps jmod keytooljavadoc jhsdb jps pack200javap jimage jrunscript\trmic 打开jconsole 选择 查看概述、内存、线程、类、VM概要、MBean 概述 内存 线程 类 VM概要 MBean Visual VM VisualVM 是一款免费的，集成了多个 JDK 命令行工具的可视化工具，它能为您提供强大的分析能力，对 Java 应用程序做性能分析和调优。这些功能包括生成和分析海量数据、跟踪内存泄漏、监控垃圾回收器、执行内存和 CPU 分析，同时它还支持在 MBeans 上进行浏览和操作。 Overview Monitor 线程 Sampler Visual GC visual gc 是 visualvm 中的图形化查看 gc 状况的插件。官方文档可以参考这里 比如我在IDEA中使用visual GC 插件来看GC状况。 JProfile Profiler 是一个商业的主要用于检查和跟踪系统（限于Java开发的）的性能的工具。JProfiler可以通过时时的监控系统的内存使用情况，随时监视垃圾回收，线程运行状况等手段，从而很好的监视JVM运行情况及其性能。 JProfiler 是一个全功能的Java剖析工具（profiler），专用于分析J2SE和J2EE应用程序。它把CPU、执行绪和内存的剖析组合在一个强大的应用中。 JProfiler可提供许多IDE整合和应用服务器整合用途。JProfiler直觉式的GUI让你可以找到效能瓶颈、抓出内存漏失(memory leaks)、并解决执行绪的问题。它让你得以对heap walker作资源回收器的root analysis，可以轻易找出内存漏失；heap快照（snapshot）模式让未被参照（reference）的对象、稍微被参照的对象、或在终结（finalization）队列的对象都会被移除；整合精灵以便剖析浏览器的Java外挂功能。 核心组件JProfiler 包含用于采集目标 JVM 分析数据的 JProfiler agent、用于可视化分析数据的 JProfiler UI、提供各种功能的命令行工具，它们之间的关系如下图所示。 JProfiler agent JProfiler agent 是一个本地库，它可以在 JVM 启动时通过参数-agentpath:&lt;path to native library&gt;进行加载或者在程序运行时通过JVM Attach 机制进行加载。Agent 被成功加载后，会设置 JVMTI 环境，监听虚拟机产生的事件，如类加载、线程创建等。例如，当它监听到类加载事件后，会给这些类注入用于执行度量操作的字节码。 JProfiler UI JProfiler UI 是一个可独立部署的组件，它通过 socket 和 agent 建立连接。这意味着不论目标 JVM 运行在本地还是远端，JProfiler UI 和 agent 间的通信机制都是一样的。 JProfiler UI 的主要功能是展示通过 agent 采集上来的分析数据，此外还可以通过它控制 agent 的采集行为，将快照保存至磁盘，展示保存的快照。 命令行工具 JProfiler 提供了一系列命令行工具以实现不同的功能。 jpcontroller - 用于控制 agent 的采集行为。它通过 agent 注册的 JProfiler MBean 向 agent 传递命令。 jpenable - 用于将 agent 加载到一个正在运行的 JVM 上。 jpdump - 用于获取正在运行的 JVM 的堆快照。 jpexport &amp; jpcompare - 用于从保存的快照中提取数据并创建 HTML 报告。 运行测试我们运行一个SpringBoot测试工程，选择attach到JVM 选择指定的进程 设置数据采集模式 JProfier 提供两种数据采集模式 Sampling 和 Instrumentation。 Sampling - 适合于不要求数据完全精确的场景。优点是对系统性能的影响较小，缺点是某些特性不支持（如方法级别的统计信息）。 Instrumentation - 完整功能模式，统计信息也是精确的。缺点是如果需要分析的类比较多，对应用性能影响较大。为了降低影响，往往需要和 Filter 一起使用。 由于我们需要获取方法级别的统计信息，这里选择了 Instrumentation 模式。 概览 内存 实时内存分布（类对象） dump 堆内存 dump完会直接打开显示 线程存储 导出HTML报告 CPU 调用树 线程历史 JEE &amp; 探针 MBeans Eclipse Memory Analyzer (MAT) MAT 是一种快速且功能丰富的 Java 堆分析器，可帮助你发现内存泄漏并减少内存消耗。 MAT在的堆内存分析问题使用极为广泛，需要重点掌握。 可以在这里下载， 官方文档可以看这里 Overview 包含内存分布，以及潜在的问题推测 Histogram 可以列出内存中的对象，对象的个数以及大小。 具体需要重点理解如下两个概念，可参考官网文档的解释 Shallow Heap ：一个对象内存的消耗大小，不包含对其他对象的引用 Retained Heap ：是shallow Heap的总和，也就是该对象被GC之后所能回收到内存的总和 Dominator Tree 可以列出那个线程，以及线程下面的那些对象占用的空间。 Top consumers 通过图形列出最大的object。 Leak Suspects 自动分析潜在可能的泄漏。","tags":["Java","JVM","调试排错","问题排查","JVM可视化工具"],"categories":["Java","JVM","调试排错","问题排查"]},{"title":"17.调试排错 - Java 问题排查之工具单","path":"/2023/12/27/17-调试排错-Java-问题排查之工具单/","content":"Java 在线问题排查主要分两篇：本文是第二篇，通过java调试&#x2F;排查工具进行问题定位。 Java 调试入门工具jps jps是jdk提供的一个查看当前java进程的小工具， 可以看做是JavaVirtual Machine Process Status Tool的缩写。 jps常用命令 123456jps # 显示进程的ID 和 类的名称jps –l # 输出输出完全的包名，应用主类名，jar的完全路径名 jps –v # 输出jvm参数jps –q # 显示java进程号jps -m # main 方法jps -l xxx.xxx.xx.xx # 远程查看 jps参数 123456-q：仅输出VM标识符，不包括classname,jar name,arguments in main method -m：输出main method的参数 -l：输出完全的包名，应用主类名，jar的完全路径名 -v：输出jvm参数 -V：输出通过flag文件传递到JVM中的参数(.hotspotrc文件或-XX:Flags=所指定的文件 -Joption：传递参数到vm,例如:-J-Xms512m jps原理 java程序在启动以后，会在java.io.tmpdir指定的目录下，就是临时文件夹里，生成一个类似于hsperfdata_User的文件夹，这个文件夹里（在Linux中为&#x2F;tmp&#x2F;hsperfdata_{userName}&#x2F;），有几个文件，名字就是java进程的pid，因此列出当前运行的java进程，只是把这个目录里的文件名列一下而已。 至于系统的参数什么，就可以解析这几个文件获得。 更多请参考 jps - Java Virtual Machine Process Status Tool jstack jstack是jdk自带的线程堆栈分析工具，使用该命令可以查看或导出 Java 应用程序中线程堆栈信息。 jstack常用命令: 12345678# 基本jstack 2815# java和native c/c++框架的所有栈信息jstack -m 2815# 额外的锁信息列表，查看是否死锁jstack -l 2815 jstack参数： 1234567-l 长列表. 打印关于锁的附加信息,例如属于java.util.concurrent 的 ownable synchronizers列表.-F 当’jstack [-l] pid’没有相应的时候强制打印栈信息-m 打印java和native c/c++框架的所有栈信息.-h | -help 打印帮助信息 更多请参考: jvm 性能调优工具之 jstack jinfo jinfo 是 JDK 自带的命令，可以用来查看正在运行的 java 应用程序的扩展参数，包括Java System属性和JVM命令行参数；也可以动态的修改正在运行的 JVM 一些参数。当系统崩溃时，jinfo可以从core文件里面知道崩溃的Java应用程序的配置信息 jinfo常用命令: 1234567891011121314151617# 输出当前 jvm 进程的全部参数和系统属性jinfo 2815# 输出所有的参数jinfo -flags 2815# 查看指定的 jvm 参数的值jinfo -flag PrintGC 2815# 开启/关闭指定的JVM参数jinfo -flag +PrintGC 2815# 设置flag的参数jinfo -flag name=value 2815# 输出当前 jvm 进行的全部的系统属性jinfo -sysprops 2815 jinfo参数： 123456no option 输出全部的参数和系统属性-flag name 输出对应名称的参数-flag [+|-]name 开启或者关闭对应名称的参数-flag name=value 设定对应名称的参数-flags 输出全部的参数-sysprops 输出系统属性 更多请参考：jvm 性能调优工具之 jinfo jmap 命令jmap是一个多功能的命令。它可以生成 java 程序的 dump 文件， 也可以查看堆内对象示例的统计信息、查看 ClassLoader 的信息以及 finalizer 队列。 两个用途 123456789# 查看堆的情况jmap -heap 2815# dumpjmap -dump:live,format=b,file=/tmp/heap2.bin 2815jmap -dump:format=b,file=/tmp/heap3.bin 2815# 查看堆的占用jmap -histo 2815 | head -10 jmap参数 123456789no option： 查看进程的内存映像信息,类似 Solaris pmap 命令。heap： 显示Java堆详细信息histo[:live]： 显示堆中对象的统计信息clstats：打印类加载器信息finalizerinfo： 显示在F-Queue队列等待Finalizer线程执行finalizer方法的对象dump:&lt;dump-options&gt;：生成堆转储快照F： 当-dump没有响应时，使用-dump或者-histo参数. 在这个模式下,live子参数无效.help：打印帮助信息J&lt;flag&gt;：指定传递给运行jmap的JVM的参数 更多请参考：jvm 性能调优工具之 jmap 和 jmap - Memory Map jstatjstat参数众多，但是使用一个就够了 1jstat -gcutil 2815 1000 jdbjdb可以用来预发debug,假设你预发的java_home是&#x2F;opt&#x2F;java&#x2F;，远程调试端口是8000.那么 1jdb -attach 8000 出现以上代表jdb启动成功。后续可以进行设置断点进行调试。 具体参数可见oracle官方说明jdb - The Java Debugger CHLSDBCHLSDB感觉很多情况下可以看到更好玩的东西，不详细叙述了。 查询资料听说jstack和jmap等工具就是基于它的。 1java -classpath /opt/taobao/java/lib/sa-jdi.jar sun.jvm.hotspot.CLHSDB 更详细的可见R大此贴 http://rednaxelafx.iteye.com/blog/1847971 Java 调试进阶工具btrace首当其冲的要说的是btrace。真是生产环境&amp;预发的排查问题大杀器。 简介什么的就不说了。直接上代码干 查看当前谁调用了ArrayList的add方法，同时只打印当前ArrayList的size大于500的线程调用栈 1234567891011@OnMethod(clazz = &quot;java.util.ArrayList&quot;, method=&quot;add&quot;, location = @Location(value = Kind.CALL, clazz = &quot;/./&quot;, method = &quot;/./&quot;))public static void m(@ProbeClassName String probeClass, @ProbeMethodName String probeMethod, @TargetInstance Object instance, @TargetMethodOrField String method) &#123; if(getInt(field(&quot;java.util.ArrayList&quot;, &quot;size&quot;), instance) &gt; 479)&#123; println(&quot;check who ArrayList.add method:&quot; + probeClass + &quot;#&quot; + probeMethod + &quot;, method:&quot; + method + &quot;, size:&quot; + getInt(field(&quot;java.util.ArrayList&quot;, &quot;size&quot;), instance)); jstack(); println(); println(&quot;===========================&quot;); println(); &#125;&#125; 监控当前服务方法被调用时返回的值以及请求的参数 12345@OnMethod(clazz = &quot;com.taobao.sellerhome.transfer.biz.impl.C2CApplyerServiceImpl&quot;, method=&quot;nav&quot;, location = @Location(value = Kind.RETURN))public static void mt(long userId, int current, int relation, String check, String redirectUrl, @Return AnyType result) &#123; println(&quot;parameter# userId:&quot; + userId + &quot;, current:&quot; + current + &quot;, relation:&quot; + relation + &quot;, check:&quot; + check + &quot;, redirectUrl:&quot; + redirectUrl + &quot;, result:&quot; + result);&#125; btrace 具体可以参考这里：https://github.com/btraceio/btrace 注意: 经过观察，1.3.9的release输出不稳定，要多触发几次才能看到正确的结果 正则表达式匹配trace类时范围一定要控制，否则极有可能出现跑满CPU导致应用卡死的情况 由于是字节码注入的原理，想要应用恢复到正常情况，需要重启应用。 GreysGreys是@杜琨的大作吧。说几个挺棒的功能(部分功能和btrace重合): sc -df xxx: 输出当前类的详情,包括源码位置和classloader结构 trace class method: 打印出当前方法调用的耗时情况，细分到每个方法, 对排查方法性能时很有帮助。 Arthas Arthas是基于Greys。 具体请参考：调试排错 - Java应用在线调试Arthas javOSize就说一个功能: classes：通过修改了字节码，改变了类的内容，即时生效。 所以可以做到快速的在某个地方打个日志看看输出，缺点是对代码的侵入性太大。但是如果自己知道自己在干嘛，的确是不错的玩意儿。 其他功能Greys和btrace都能很轻易做的到，不说了。 更多请参考：官网 JProfiler之前判断许多问题要通过JProfiler，但是现在Greys和btrace基本都能搞定了。再加上出问题的基本上都是生产环境(网络隔离)，所以基本不怎么使用了，但是还是要标记一下。 更多请参考：官网 其它工具dmesg如果发现自己的java进程悄无声息的消失了，几乎没有留下任何线索，那么dmesg一发，很有可能有你想要的。 sudo dmesg|grep -i kill|less 去找关键字oom_killer。找到的结果类似如下: 12345[6710782.021013] java invoked oom-killer: gfp_mask=0xd0, order=0, oom_adj=0, oom_scoe_adj=0[6710782.070639] [&lt;ffffffff81118898&gt;] ? oom_kill_process+0x68/0x140 [6710782.257588] Task in /LXC011175068174 killed as a result of limit of /LXC011175068174 [6710784.698347] Memory cgroup out of memory: Kill process 215701 (java) score 854 or sacrifice child [6710784.707978] Killed process 215701, UID 679, (java) total-vm:11017300kB, anon-rss:7152432kB, file-rss:1232kB 以上表明，对应的java进程被系统的OOM Killer给干掉了，得分为854. 解释一下OOM killer（Out-Of-Memory killer），该机制会监控机器的内存资源消耗。当机器内存耗尽前，该机制会扫描所有的进程（按照一定规则计算，内存占用，时间等），挑选出得分最高的进程，然后杀死，从而保护机器。 dmesg日志时间转换公式: log实际时间&#x3D;格林威治1970-01-01+(当前时间秒数-系统启动至今的秒数+dmesg打印的log时间)秒数： date -d “1970-01-01 UTC echo &quot;$(date +%s)-$(cat /proc/uptime|cut -f 1 -d&#39; &#39;)+12288812.926194&quot;|bc seconds” 剩下的，就是看看为什么内存这么大，触发了OOM-Killer了。 参考文章 文章主要参考了如下， 在此基础上重新整理，和添加新内容。 作者：红魔七号 文章来源：https://yq.aliyun.com/articles/69520 https://www.cnblogs.com/xuchunlin/p/5671572.html","tags":["Java","JVM","调试排错","问题排查","工具单"],"categories":["Java","JVM","调试排错","问题排查"]},{"title":"16.调试排错 - Java 问题排查之Linux命令","path":"/2023/12/27/16-调试排错-Java-问题排查之Linux命令/","content":"Java 在线问题排查主要分两篇：本文是第一篇，通过linux常用命令排查。 文本操作文本查找 - grepgrep常用命令： 12345678910111213141516# 基本使用grep yoursearchkeyword f.txt #文件查找grep &#x27;KeyWord otherKeyWord&#x27; f.txt cpf.txt #多文件查找, 含空格加引号grep &#x27;KeyWord&#x27; /home/admin -r -n #目录下查找所有符合关键字的文件grep &#x27;keyword&#x27; /home/admin -r -n -i # -i 忽略大小写grep &#x27;KeyWord&#x27; /home/admin -r -n --include *.&#123;vm,java&#125; #指定文件后缀grep &#x27;KeyWord&#x27; /home/admin -r -n --exclude *.&#123;vm,java&#125; #反匹配# cat + grepcat f.txt | grep -i keyword # 查找所有keyword且不分大小写 cat f.txt | grep -c &#x27;KeyWord&#x27; # 统计Keyword次数# seq + grepseq 10 | grep 5 -A 3 #上匹配seq 10 | grep 5 -B 3 #下匹配seq 10 | grep 5 -C 3 #上下匹配，平时用这个就妥了 Grep的参数： 12345678910111213--color=auto：显示颜色;-i, --ignore-case：忽略字符大小写;-o, --only-matching：只显示匹配到的部分;-n, --line-number：显示行号;-v, --invert-match：反向显示,显示未匹配到的行;-E, --extended-regexp：支持使用扩展的正则表达式;-q, --quiet, --silent：静默模式,即不输出任何信息;-w, --word-regexp：整行匹配整个单词;-c, --count：统计匹配到的行数; print a count of matching lines;-B, --before-context=NUM：print NUM lines of leading context 后#行 -A, --after-context=NUM：print NUM lines of trailing context 前#行 -C, --context=NUM：print NUM lines of output context 前后各#行 文本分析 - awkawk基本命令： 12345678910111213# 基本使用awk &#x27;&#123;print $4,$6&#125;&#x27; f.txtawk &#x27;&#123;print NR,$0&#125;&#x27; f.txt cpf.txt awk &#x27;&#123;print FNR,$0&#125;&#x27; f.txt cpf.txtawk &#x27;&#123;print FNR,FILENAME,$0&#125;&#x27; f.txt cpf.txtawk &#x27;&#123;print FILENAME,&quot;NR=&quot;NR,&quot;FNR=&quot;FNR,&quot;$&quot;NF&quot;=&quot;$NF&#125;&#x27; f.txt cpf.txtecho 1:2:3:4 | awk -F: &#x27;&#123;print $1,$2,$3,$4&#125;&#x27;# 匹配awk &#x27;/ldb/ &#123;print&#125;&#x27; f.txt #匹配ldbawk &#x27;!/ldb/ &#123;print&#125;&#x27; f.txt #不匹配ldbawk &#x27;/ldb/ &amp;&amp; /LISTEN/ &#123;print&#125;&#x27; f.txt #匹配ldb和LISTENawk &#x27;$5 ~ /ldb/ &#123;print&#125;&#x27; f.txt #第五列匹配ldb 内建变量 12345`NR`: NR表示从awk开始执行后，按照记录分隔符读取的数据次数，默认的记录分隔符为换行符，因此默认的就是读取的数据行数，NR可以理解为Number of Record的缩写。`FNR`: 在awk处理多个输入文件的时候，在处理完第一个文件后，NR并不会从1开始，而是继续累加，因此就出现了FNR，每当处理一个新文件的时候，FNR就从1开始计数，FNR可以理解为File Number of Record。`NF`: NF表示目前的记录被分割的字段的数目，NF可以理解为Number of Field。 更多请参考：Linux awk 命令 文本处理 - sedsed常用： 1234567891011121314151617181920212223242526# 文本打印sed -n &#x27;3p&#x27; xxx.log #只打印第三行sed -n &#x27;$p&#x27; xxx.log #只打印最后一行sed -n &#x27;3,9p&#x27; xxx.log #只查看文件的第3行到第9行sed -n -e &#x27;3,9p&#x27; -e &#x27;=&#x27; xxx.log #打印3-9行，并显示行号sed -n &#x27;/root/p&#x27; xxx.log #显示包含root的行sed -n &#x27;/hhh/,/omc/p&#x27; xxx.log # 显示包含&quot;hhh&quot;的行到包含&quot;omc&quot;的行之间的行# 文本替换sed -i &#x27;s/root/world/g&#x27; xxx.log # 用world 替换xxx.log文件中的root; s==search 查找并替换, g==global 全部替换, -i: implace# 文本插入sed &#x27;1,4i hahaha&#x27; xxx.log # 在文件第一行和第四行的每行下面添加hahahased -e &#x27;1i happy&#x27; -e &#x27;$a new year&#x27; xxx.log #【界面显示】在文件第一行添加happy,文件结尾添加new yearsed -i -e &#x27;1i happy&#x27; -e &#x27;$a new year&#x27; xxx.log #【真实写入文件】在文件第一行添加happy,文件结尾添加new year# 文本删除sed &#x27;3,9d&#x27; xxx.log # 删除第3到第9行,只是不显示而已sed &#x27;/hhh/,/omc/d&#x27; xxx.log # 删除包含&quot;hhh&quot;的行到包含&quot;omc&quot;的行之间的行sed &#x27;/omc/,10d&#x27; xxx.log # 删除包含&quot;omc&quot;的行到第十行的内容# 与find结合find . -name &quot;*.txt&quot; |xargs sed -i &#x27;s/hhhh/\\hHHh/g&#x27;find . -name &quot;*.txt&quot; |xargs sed -i &#x27;s#hhhh#hHHh#g&#x27;find . -name &quot;*.txt&quot; -exec sed -i &#x27;s/hhhh/\\hHHh/g&#x27; &#123;&#125; \\;find . -name &quot;*.txt&quot; |xargs cat 更多请参考：Linux sed 命令 或者 Linux sed命令详解 文件操作文件监听 - tail最常用的tail -f filename 1234567# 基本使用tail -f xxx.log # 循环监听文件tail -300f xxx.log #倒数300行并追踪文件tail +20 xxx.log #从第 20 行至文件末尾显示文件内容# tailf使用tailf xxx.log #等同于tail -f -n 10 打印最后10行，然后追踪文件 tail -f 与tail F 与tailf三者区别 12345`tail -f ` 等于--follow=descriptor，根据文件描述进行追踪，当文件改名或删除后，停止追踪。`tail -F` 等于 --follow=name ==retry，根据文件名字进行追踪，当文件改名或删除后，保持重试，当有新的文件和他同名时，继续追踪`tailf` 等于tail -f -n 10（tail -f或-F默认也是打印最后10行，然后追踪文件），与tail -f不同的是，如果文件不增长，它不会去访问磁盘文件，所以tailf特别适合那些便携机上跟踪日志文件，因为它减少了磁盘访问，可以省电。 tail的参数 12345678-f 循环读取-q 不显示处理信息-v 显示详细的处理信息-c&lt;数目&gt; 显示的字节数-n&lt;行数&gt; 显示文件的尾部 n 行内容--pid=PID 与-f合用,表示在进程ID,PID死掉之后结束-q, --quiet, --silent 从不输出给出文件名的首部-s, --sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 文件查找 - find12345678910111213sudo -u admin find /home/admin /tmp /usr -name \\*.log(多个目录去找)find . -iname \\*.txt(大小写都匹配)find . -type d(当前目录下的所有子目录)find /usr -type l(当前目录下所有的符号链接)find /usr -type l -name &quot;z*&quot; -ls(符号链接的详细信息 eg:inode,目录)find /home/admin -size +250000k(超过250000k的文件，当然+改成-就是小于了)find /home/admin f -perm 777 -exec ls -l &#123;&#125; \\; (按照权限查询文件)find /home/admin -atime -1 1天内访问过的文件find /home/admin -ctime -1 1天内状态改变过的文件 find /home/admin -mtime -1 1天内修改过的文件find /home/admin -amin -1 1分钟内访问过的文件find /home/admin -cmin -1 1分钟内状态改变过的文件 find /home/admin -mmin -1 1分钟内修改过的文件 pgm批量查询vm-shopbase满足条件的日志 1pgm -A -f vm-shopbase &#x27;cat /home/admin/shopbase/logs/shopbase.log.2017-01-17|grep 2069861630&#x27; 查看网络和进程查看所有网络接口的属性12345678910111213141516[root@pdai.tech ~]# ifconfigeth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 172.31.165.194 netmask 255.255.240.0 broadcast 172.31.175.255 ether 00:16:3e:08:c1:ea txqueuelen 1000 (Ethernet) RX packets 21213152 bytes 2812084823 (2.6 GiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 25264438 bytes 46566724676 (43.3 GiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0lo: flags=73&lt;UP,LOOPBACK,RUNNING&gt; mtu 65536 inet 127.0.0.1 netmask 255.0.0.0 loop txqueuelen 1000 (Local Loopback) RX packets 502 bytes 86350 (84.3 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 502 bytes 86350 (84.3 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 查看防火墙设置123456789[root@pdai.tech ~]# iptables -LChain INPUT (policy ACCEPT)target prot opt source destinationChain FORWARD (policy ACCEPT)target prot opt source destinationChain OUTPUT (policy ACCEPT)target prot opt source destination 查看路由表123456[root@pdai.tech ~]# route -nKernel IP routing tableDestination Gateway Genmask Flags Metric Ref Use Iface0.0.0.0 172.31.175.253 0.0.0.0 UG 0 0 0 eth0169.254.0.0 0.0.0.0 255.255.0.0 U 1002 0 0 eth0172.31.160.0 0.0.0.0 255.255.240.0 U 0 0 0 eth0 netstat查看所有监听端口 12345678[root@pdai.tech ~]# netstat -lntpActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 970/nginx: master ptcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN 1249/java tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 970/nginx: master ptcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1547/sshd tcp6 0 0 :::3306 :::* LISTEN 1894/mysqld 查看所有已经建立的连接 12345678910[root@pdai.tech ~]# netstat -antpActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:443 0.0.0.0:* LISTEN 970/nginx: master ptcp 0 0 0.0.0.0:9999 0.0.0.0:* LISTEN 1249/javatcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 970/nginx: master ptcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1547/sshdtcp 0 0 172.31.165.194:53874 100.100.30.25:80 ESTABLISHED 18041/AliYunDuntcp 0 64 172.31.165.194:22 xxx.194.1.200:2649 ESTABLISHED 32516/sshd: root@pttcp6 0 0 :::3306 :::* LISTEN 1894/m 查看当前连接 12345[root@pdai.tech ~]# netstat -nat|awk &#x27;&#123;print $6&#125;&#x27;|sort|uniq -c|sort -rn 5 LISTEN 2 ESTABLISHED 1 Foreign 1 established) 查看网络统计信息进程 1234567891011121314151617181920212223242526272829303132333435363738[root@pdai.tech ~]# netstat -sIp: 21017132 total packets received 0 forwarded 0 incoming packets discarded 21017131 incoming packets delivered 25114367 requests sent out 324 dropped because of missing routeIcmp: 18088 ICMP messages received 692 input ICMP message failed. ICMP input histogram: destination unreachable: 4241 timeout in transit: 19 echo requests: 13791 echo replies: 4 timestamp request: 33 13825 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 1 echo replies: 13791 timestamp replies: 33IcmpMsg: InType0: 4 InType3: 4241 InType8: 13791 InType11: 19 InType13: 33 OutType0: 13791 OutType3: 1 OutType14: 33Tcp: 12210 active connections openings 208820 passive connection openings 54198 failed connection attempts 9805 connection resets received... netstat 请参考这篇文章: Linux netstat命令详解 查看所有进程123[root@pdai.tech ~]# ps -ef | grep javaroot 1249 1 0 Nov04 ? 00:58:05 java -jar /opt/tech_doc/bin/tech_arch-0.0.1-RELEASE.jar --server.port=9999root 32718 32518 0 08:36 pts/0 00:00:00 grep --color=auto java toptop除了看一些基本信息之外，剩下的就是配合来查询vm的各种问题了 123456789101112# top -H -p pidtop - 08:37:51 up 45 days, 18:45, 1 user, load average: 0.01, 0.03, 0.05Threads: 28 total, 0 running, 28 sleeping, 0 stopped, 0 zombie%Cpu(s): 0.7 us, 0.7 sy, 0.0 ni, 98.6 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 1882088 total, 74608 free, 202228 used, 1605252 buff/cacheKiB Swap: 2097148 total, 1835392 free, 261756 used. 1502036 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1347 root 20 0 2553808 113752 1024 S 0.3 6.0 48:46.74 VM Periodic Tas 1249 root 20 0 2553808 113752 1024 S 0.0 6.0 0:00.00 java 1289 root 20 0 2553808 113752 1024 S 0.0 6.0 0:03.74 java... 查看磁盘和内存相关查看内存使用 - free -m1234[root@pdai.tech ~]# free -m total used free shared buff/cache availableMem: 1837 196 824 0 816 1469Swap: 2047 255 1792 查看各分区使用情况12345678[root@pdai.tech ~]# df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 909M 0 909M 0% /devtmpfs 919M 0 919M 0% /dev/shmtmpfs 919M 452K 919M 1% /runtmpfs 919M 0 919M 0% /sys/fs/cgroup/dev/vda1 40G 15G 23G 40% /tmpfs 184M 0 184M 0% /run/user/0 查看指定目录的大小12[root@pdai.tech ~]# du -sh803M 查看内存总量12[root@pdai.tech ~]# grep MemTotal /proc/meminfoMemTotal: 1882088 kB 查看空闲内存量12[root@pdai.tech ~]# grep MemFree /proc/meminfoMemFree: 74120 kB 查看系统负载磁盘和分区12[root@pdai.tech ~]# grep MemFree /proc/meminfoMemFree: 74120 kB 查看系统负载磁盘和分区12[root@pdai.tech ~]# cat /proc/loadavg0.01 0.04 0.05 2/174 32751 查看挂接的分区状态123456[root@pdai.tech ~]# mount | column -tsysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime)proc on /proc type proc (rw,nosuid,nodev,noexec,relatime)devtmpfs on /dev type devtmpfs (rw,nosuid,size=930732k,nr_inodes=232683,mode=755)securityfs on /sys/kernel/security type securityfs (rw,nosuid,nodev,noexec,relatime)... 查看所有分区1234567891011[root@pdai.tech ~]# fdisk -lDisk /dev/vda: 42.9 GB, 42949672960 bytes, 83886080 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x0008d73a Device Boot Start End Blocks Id System/dev/vda1 * 2048 83884031 41940992 83 Linux 查看所有交换分区123[root@pdai.tech ~]# swapon -sFilename Type Size Used Priority/etc/swap file 2097148 261756 -2 查看硬盘大小1234[root@pdai.tech ~]# fdisk -l |grep DiskDisk /dev/vda: 42.9 GB, 42949672960 bytes, 83886080 sectorsDisk label type: dosDisk identifier: 0x0008d73a 查看用户和组相关查看活动用户1234[root@pdai.tech ~]# w 08:47:20 up 45 days, 18:54, 1 user, load average: 0.01, 0.03, 0.05USER TTY FROM LOGIN@ IDLE JCPU PCPU WHATroot pts/0 xxx.194.1.200 08:32 0.00s 0.32s 0.32s -bash 查看指定用户信息12[root@pdai.tech ~]# iduid=0(root) gid=0(root) groups=0(root) 查看用户登录日志1234567[root@pdai.tech ~]# lastroot pts/0 xxx.194.1.200 Fri Dec 20 08:32 still logged inroot pts/0 xxx.73.164.60 Thu Dec 19 21:47 - 00:28 (02:41)root pts/0 xxx.106.236.255 Thu Dec 19 16:00 - 18:24 (02:23)root pts/1 xxx.194.3.173 Tue Dec 17 13:35 - 17:37 (04:01)root pts/0 xxx.194.3.173 Tue Dec 17 13:35 - 17:37 (04:02)... 查看系统所有用户123456[root@pdai.tech ~]# cut -d: -f1 /etc/passwdrootbindaemonadm... 查看系统所有组1cut -d: -f1 /etc/group 查看服务，模块和包相关1234567891011121314# 查看当前用户的计划任务服务crontab -l # 列出所有系统服务chkconfig –list # 列出所有启动的系统服务程序chkconfig –list | grep on # 查看所有安装的软件包rpm -qa # 列出加载的内核模块lsmod 查看系统，设备，环境信息123456789101112131415161718# 常用env # 查看环境变量资源uptime # 查看系统运行时间、用户数、负载lsusb -tv # 列出所有USB设备的linux系统信息命令lspci -tv # 列出所有PCI设备head -n 1 /etc/issue # 查看操作系统版本，是数字1不是字母Luname -a # 查看内核/操作系统/CPU信息的linux系统信息命令# /proc/cat /proc/cpuinfo ：查看CPU相关参数的linux系统命令cat /proc/partitions ：查看linux硬盘和分区信息的系统信息命令cat /proc/meminfo ：查看linux系统内存信息的linux系统命令cat /proc/version ：查看版本，类似uname -rcat /proc/ioports ：查看设备io端口cat /proc/interrupts ：查看中断cat /proc/pci ：查看pci设备的信息cat /proc/swaps ：查看所有swap分区的信息cat /proc/cpuinfo |grep &quot;model name&quot; &amp;&amp; cat /proc/cpuinfo |grep &quot;physical id&quot; tsartsar是淘宝开源的的采集工具。很好用, 将历史收集到的数据持久化在磁盘上，所以我们快速来查询历史的系统数据。当然实时的应用情况也是可以查询的啦。大部分机器上都有安装。 123456tsar ##可以查看最近一天的各项指标tsar --live ##可以查看实时指标，默认五秒一刷tsar -d 20161218 ##指定查看某天的数据，貌似最多只能看四个月的数据tsar --memtsar --loadtsar --cpu ##当然这个也可以和-d参数配合来查询某天的单个指标的情况 具体可以看这篇文章：linux 淘宝开源监控工具tsar","tags":["Java","JVM","调试排错","问题排查","Linux命令"],"categories":["Java","JVM","调试排错","问题排查"]},{"title":"15.调试排错 - Java 线程分析之线程Dump分析","path":"/2023/12/27/15-调试排错-Java-线程分析之线程Dump分析/","content":"Thread Dump是非常有用的诊断Java应用问题的工具。 Thread Dump介绍什么是Thread DumpThread Dump是非常有用的诊断Java应用问题的工具。每一个Java虚拟机都有及时生成所有线程在某一点状态的thread-dump的能力，虽然各个 Java虚拟机打印的thread dump略有不同，但是 大多都提供了当前活动线程的快照，及JVM中所有Java线程的堆栈跟踪信息，堆栈信息一般包含完整的类名及所执行的方法，如果可能的话还有源代码的行数。 Thread Dump特点 能在各种操作系统下使用； 能在各种Java应用服务器下使用； 能在生产环境下使用而不影响系统的性能； 能将问题直接定位到应用程序的代码行上； Thread Dump抓取一般当服务器挂起，崩溃或者性能低下时，就需要抓取服务器的线程堆栈（Thread Dump）用于后续的分析。在实际运行中，往往一次 dump的信息，还不足以确认问题。为了反映线程状态的动态变化，需要接连多次做thread dump，每次间隔10-20s，建议至少产生三次 dump信息，如果每次 dump都指向同一个问题，我们才确定问题的典型性。 操作系统命令获取ThreadDump 12ps –ef | grep javakill -3 &lt;pid&gt; 注意： 一定要谨慎, 一步不慎就可能让服务器进程被杀死。kill -9 命令会杀死进程。 JVM 自带的工具获取线程堆栈 12jps 或 ps –ef | grep java （获取PID）jstack [-l ] &lt;pid&gt; | tee -a jstack.log（获取ThreadDump） Thread Dump分析Thread Dump信息 头部信息：时间，JVM信息 122011-11-02 19:05:06 Full thread dump Java HotSpot(TM) Server VM (16.3-b01 mixed mode): 线程INFO信息块： 123456789101112131. &quot;Timer-0&quot; daemon prio=10 tid=0xac190c00 nid=0xaef in Object.wait() [0xae77d000] # 线程名称：Timer-0；线程类型：daemon；优先级: 10，默认是5；# JVM线程id：tid=0xac190c00，JVM内部线程的唯一标识（通过java.lang.Thread.getId()获取，通常用自增方式实现）。# 对应系统线程id（NativeThread ID）：nid=0xaef，和top命令查看的线程pid对应，不过一个是10进制，一个是16进制。（通过命令：top -H -p pid，可以查看该进程的所有线程信息）# 线程状态：in Object.wait()；# 起始栈地址：[0xae77d000]，对象的内存地址，通过JVM内存查看工具，能够看出线程是在哪儿个对象上等待；2. java.lang.Thread.State: TIMED_WAITING (on object monitor)3. at java.lang.Object.wait(Native Method)4. -waiting on &lt;0xb3885f60&gt; (a java.util.TaskQueue) # 继续wait 5. at java.util.TimerThread.mainLoop(Timer.java:509)6. -locked &lt;0xb3885f60&gt; (a java.util.TaskQueue) # 已经locked7. at java.util.TimerThread.run(Timer.java:462)Java thread statck trace：是上面2-7行的信息。到目前为止这是最重要的数据，Java stack trace提供了大部分信息来精确定位问题根源。 Java thread statck trace详解： 堆栈信息应该逆向解读：程序先执行的是第7行，然后是第6行，依次类推。 12- locked &lt;0xb3885f60&gt; (a java.util.ArrayList)- waiting on &lt;0xb3885f60&gt; (a java.util.ArrayList) 也就是说对象先上锁，锁住对象0xb3885f60，然后释放该对象锁，进入waiting状态。为啥会出现这样的情况呢？看看下面的java代码示例，就会明白： 12345synchronized(obj) &#123; ......... obj.wait(); ......... &#125; 如上，线程的执行过程，先用 synchronized 获得了这个对象的 Monitor（对应于 locked &lt;0xb3885f60&gt; ）。当执行到 obj.wait()，线程即放弃了 Monitor的所有权，进入 “wait set”队列（对应于 waiting on &lt;0xb3885f60&gt; ）。 在堆栈的第一行信息中，进一步标明了线程在代码级的状态，例如： 1java.lang.Thread.State: TIMED_WAITING (parking) 解释如下： 1234567891011121314151617181920212223|blocked|&gt; This thread tried to enter asynchronized block, but the lock was taken by another thread. This thread isblocked until the lock gets released.|blocked (on thin lock)|&gt; This is the same state asblocked, but the lock in question is a thin lock.|waiting|&gt; This thread calledObject.wait() on an object. The thread will remain there until some otherthread sends a notification to that object.|sleeping|&gt; This thread calledjava.lang.Thread.sleep().|parked|&gt; This thread calledjava.util.concurrent.locks.LockSupport.park().|suspended|&gt; The thread&#x27;s execution wassuspended by java.lang.Thread.suspend() or a JVMTI agent call. Thread状态分析线程的状态是一个很重要的东西，因此thread dump中会显示这些状态，通过对这些状态的分析，能够得出线程的运行状况，进而发现可能存在的问题。线程的状态在Thread.State这个枚举类型中定义： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public enum State &#123; /** * Thread state for a thread which has not yet started. */ NEW, /** * Thread state for a runnable thread. A thread in the runnable * state is executing in the Java virtual machine but it may * be waiting for other resources from the operating system * such as processor. */ RUNNABLE, /** * Thread state for a thread blocked waiting for a monitor lock. * A thread in the blocked state is waiting for a monitor lock * to enter a synchronized block/method or * reenter a synchronized block/method after calling * &#123;@link Object#wait() Object.wait&#125;. */ BLOCKED, /** * Thread state for a waiting thread. * A thread is in the waiting state due to calling one of the * following methods: * &lt;ul&gt; * &lt;li&gt;&#123;@link Object#wait() Object.wait&#125; with no timeout&lt;/li&gt; * &lt;li&gt;&#123;@link #join() Thread.join&#125; with no timeout&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#park() LockSupport.park&#125;&lt;/li&gt; * &lt;/ul&gt; * * &lt;p&gt;A thread in the waiting state is waiting for another thread to * perform a particular action. * * For example, a thread that has called &lt;tt&gt;Object.wait()&lt;/tt&gt; * on an object is waiting for another thread to call * &lt;tt&gt;Object.notify()&lt;/tt&gt; or &lt;tt&gt;Object.notifyAll()&lt;/tt&gt; on * that object. A thread that has called &lt;tt&gt;Thread.join()&lt;/tt&gt; * is waiting for a specified thread to terminate. */ WAITING, /** * Thread state for a waiting thread with a specified waiting time. * A thread is in the timed waiting state due to calling one of * the following methods with a specified positive waiting time: * &lt;ul&gt; * &lt;li&gt;&#123;@link #sleep Thread.sleep&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link Object#wait(long) Object.wait&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link #join(long) Thread.join&#125; with timeout&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkNanos LockSupport.parkNanos&#125;&lt;/li&gt; * &lt;li&gt;&#123;@link LockSupport#parkUntil LockSupport.parkUntil&#125;&lt;/li&gt; * &lt;/ul&gt; */ TIMED_WAITING, /** * Thread state for a terminated thread. * The thread has completed execution. */ TERMINATED; &#125; NEW： 每一个线程，在堆内存中都有一个对应的Thread对象。Thread t &#x3D; new Thread();当刚刚在堆内存中创建Thread对象，还没有调用t.start()方法之前，线程就处在NEW状态。在这个状态上，线程与普通的java对象没有什么区别，就仅仅是一个堆内存中的对象。 RUNNABLE： 该状态表示线程具备所有运行条件，在运行队列中准备操作系统的调度，或者正在运行。 这个状态的线程比较正常，但如果线程长时间停留在在这个状态就不正常了，这说明线程运行的时间很长（存在性能问题），或者是线程一直得不得执行的机会（存在线程饥饿的问题）。 BLOCKED： 线程正在等待获取java对象的监视器(也叫内置锁)，即线程正在等待进入由synchronized保护的方法或者代码块。synchronized用来保证原子性，任意时刻最多只能由一个线程进入该临界区域，其他线程只能排队等待。 WAITING： 处在该线程的状态，正在等待某个事件的发生，只有特定的条件满足，才能获得执行机会。而产生这个特定的事件，通常都是另一个线程。也就是说，如果不发生特定的事件，那么处在该状态的线程一直等待，不能获取执行的机会。比如： A线程调用了obj对象的obj.wait()方法，如果没有线程调用obj.notify或obj.notifyAll，那么A线程就没有办法恢复运行； 如果A线程调用了LockSupport.park()，没有别的线程调用LockSupport.unpark(A)，那么A没有办法恢复运行。 TIMED_WAITING： J.U.C中很多与线程相关类，都提供了限时版本和不限时版本的API。TIMED_WAITING意味着线程调用了限时版本的API，正在等待时间流逝。当等待时间过去后，线程一样可以恢复运行。如果线程进入了WAITING状态，一定要特定的事件发生才能恢复运行；而处在TIMED_WAITING的线程，如果特定的事件发生或者是时间流逝完毕，都会恢复运行。 TERMINATED： 线程执行完毕，执行完run方法正常返回，或者抛出了运行时异常而结束，线程都会停留在这个状态。这个时候线程只剩下Thread对象了，没有什么用了。 关键状态分析 Wait on condition：The thread is either sleeping or waiting to be notified by another thread. 该状态说明它在等待另一个条件的发生，来把自己唤醒，或者干脆它是调用了 sleep(n)。 此时线程状态大致为以下几种： 12java.lang.Thread.State: WAITING (parking)：一直等那个条件发生；java.lang.Thread.State: TIMED_WAITING (parking或sleeping)：定时的，那个条件不到来，也将定时唤醒自己。 **Waiting for Monitor Entry 和 in Object.wait()**：The thread is waiting to get the lock for an object (some other thread may be holding the lock). This happens if two or more threads try to execute synchronized code. Note that the lock is always for an object and not for individual methods. 在多线程的JAVA程序中，实现线程之间的同步，就要说说 Monitor。Monitor是Java中用以实现线程之间的互斥与协作的主要手段，它可以看成是对象或者Class的锁。每一个对象都有，也仅有一个 Monitor 。下面这个图，描述了线程和 Monitor之间关系，以及线程的状态转换图： 如上图，每个Monitor在某个时刻，只能被一个线程拥有，该线程就是 “ActiveThread”，而其它线程都是 “Waiting Thread”，分别在两个队列“Entry Set”和“Wait Set”里等候。在“Entry Set”中等待的线程状态是“Waiting for monitor entry”，而在“Wait Set”中等待的线程状态是“in Object.wait()”。 先看“Entry Set”里面的线程。我们称被 synchronized保护起来的代码段为临界区。当一个线程申请进入临界区时，它就进入了“Entry Set”队列。对应的 code就像： 123synchronized(obj) &#123; .........&#125; 这时有两种可能性： 该 monitor不被其它线程拥有， Entry Set里面也没有其它等待线程。本线程即成为相应类或者对象的 Monitor的 Owner，执行临界区的代码。 该 monitor被其它线程拥有，本线程在 Entry Set队列中等待。 在第一种情况下，线程将处于 “Runnable”的状态，而第二种情况下，线程 DUMP会显示处于 “waiting for monitor entry”。如下： 12345&quot;Thread-0&quot; prio=10 tid=0x08222eb0 nid=0x9 waiting for monitor entry [0xf927b000..0xf927bdb8] at testthread.WaitThread.run(WaitThread.java:39) - waiting to lock &lt;0xef63bf08&gt; (a java.lang.Object) - locked &lt;0xef63beb8&gt; (a java.util.ArrayList) at java.lang.Thread.run(Thread.java:595) 临界区的设置，是为了保证其内部的代码执行的原子性和完整性。但是因为临界区在任何时间只允许线程串行通过，这和我们多线程的程序的初衷是相反的。如果在多线程的程序中，大量使用 synchronized，或者不适当的使用了它，会造成大量线程在临界区的入口等待，造成系统的性能大幅下降。如果在线程 DUMP中发现了这个情况，应该审查源码，改进程序。 再看“Wait Set”里面的线程。当线程获得了 Monitor，进入了临界区之后，如果发现线程继续运行的条件没有满足，它则调用对象（一般就是被 synchronized 的对象）的 wait() 方法，放弃 Monitor，进入 “Wait Set”队列。只有当别的线程在该对象上调用了 notify() 或者 notifyAll()，“Wait Set”队列中线程才得到机会去竞争，但是只有一个线程获得对象的Monitor，恢复到运行态。在 “Wait Set”中的线程， DUMP中表现为： in Object.wait()。如下： 12345678&quot;Thread-1&quot; prio=10 tid=0x08223250 nid=0xa in Object.wait() [0xef47a000..0xef47aa38] at java.lang.Object.wait(Native Method) - waiting on &lt;0xef63beb8&gt; (a java.util.ArrayList) at java.lang.Object.wait(Object.java:474) at testthread.MyWaitThread.run(MyWaitThread.java:40) - locked &lt;0xef63beb8&gt; (a java.util.ArrayList) at java.lang.Thread.run(Thread.java:595) 综上，一般CPU很忙时，则关注runnable的线程，CPU很闲时，则关注waiting for monitor entry的线程。 JDK 5.0 的 Lock 上面提到如果 synchronized和 monitor机制运用不当，可能会造成多线程程序的性能问题。在 JDK 5.0中，引入了 Lock机制，从而使开发者能更灵活的开发高性能的并发多线程程序，可以替代以往 JDK中的 synchronized和 Monitor的 机制。但是，要注意的是，因为 Lock类只是一个普通类，JVM无从得知 Lock对象的占用情况，所以在线程 DUMP中，也不会包含关于 Lock的信息， 关于死锁等问题，就不如用 synchronized的编程方式容易识别。 关键状态示例 显示BLOCKED状态 1234567891011121314151617181920212223242526272829303132package jstack; public class BlockedState &#123; private static Object object = new Object(); public static void main(String[] args) &#123; Runnable task = new Runnable() &#123; @Override public void run() &#123; synchronized (object) &#123; long begin = System.currentTimeMillis(); long end = System.currentTimeMillis(); // 让线程运行5分钟,会一直持有object的监视器 while ((end - begin) &lt;= 5 * 60 * 1000) &#123; &#125; &#125; &#125; &#125;; new Thread(task, &quot;t1&quot;).start(); new Thread(task, &quot;t2&quot;).start(); &#125; &#125; 先获取object的线程会执行5分钟，这5分钟内会一直持有object的监视器，另一个线程无法执行处在BLOCKED状态： 12345678910111213141516Full thread dump Java HotSpot(TM) Server VM (20.12-b01 mixed mode): &quot;DestroyJavaVM&quot; prio=6 tid=0x00856c00 nid=0x1314 waiting on condition [0x00000000] java.lang.Thread.State: RUNNABLE &quot;t2&quot; prio=6 tid=0x27d7a800 nid=0x1350 waiting for monitor entry [0x2833f000] java.lang.Thread.State: BLOCKED (on object monitor) at jstack.BlockedState$1.run(BlockedState.java:17) - waiting to lock &lt;0x1cfcdc00&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:662) &quot;t1&quot; prio=6 tid=0x27d79400 nid=0x1338 runnable [0x282ef000] java.lang.Thread.State: RUNNABLE at jstack.BlockedState$1.run(BlockedState.java:22) - locked &lt;0x1cfcdc00&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:662) 通过thread dump可以看到：t2线程确实处在BLOCKED (on object monitor)。waiting for monitor entry 等待进入synchronized保护的区域。 显示WAITING状态 1234567891011121314151617181920212223242526272829303132333435363738package jstack; public class WaitingState &#123; private static Object object = new Object(); public static void main(String[] args) &#123; Runnable task = new Runnable() &#123; @Override public void run() &#123; synchronized (object) &#123; long begin = System.currentTimeMillis(); long end = System.currentTimeMillis(); // 让线程运行5分钟,会一直持有object的监视器 while ((end - begin) &lt;= 5 * 60 * 1000) &#123; try &#123; // 进入等待的同时,会进入释放监视器 object.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;; new Thread(task, &quot;t1&quot;).start(); new Thread(task, &quot;t2&quot;).start(); &#125; &#125; 12345678910111213141516171819202122Full thread dump Java HotSpot(TM) Server VM (20.12-b01 mixed mode): &quot;DestroyJavaVM&quot; prio=6 tid=0x00856c00 nid=0x1734 waiting on condition [0x00000000] java.lang.Thread.State: RUNNABLE &quot;t2&quot; prio=6 tid=0x27d7e000 nid=0x17f4 in Object.wait() [0x2833f000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x1cfcdc00&gt; (a java.lang.Object) at java.lang.Object.wait(Object.java:485) at jstack.WaitingState$1.run(WaitingState.java:26) - locked &lt;0x1cfcdc00&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:662) &quot;t1&quot; prio=6 tid=0x27d7d400 nid=0x17f0 in Object.wait() [0x282ef000] java.lang.Thread.State: WAITING (on object monitor) at java.lang.Object.wait(Native Method) - waiting on &lt;0x1cfcdc00&gt; (a java.lang.Object) at java.lang.Object.wait(Object.java:485) at jstack.WaitingState$1.run(WaitingState.java:26) - locked &lt;0x1cfcdc00&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:662) 可以发现t1和t2都处在WAITING (on object monitor)，进入等待状态的原因是调用了in Object.wait()。通过J.U.C包下的锁和条件队列，也是这个效果，大家可以自己实践下。 显示TIMED_WAITING状态 123456789101112131415161718192021222324252627282930313233343536373839404142package jstack; import java.util.concurrent.TimeUnit; import java.util.concurrent.locks.Condition; import java.util.concurrent.locks.Lock; import java.util.concurrent.locks.ReentrantLock; public class TimedWaitingState &#123; // java的显示锁,类似java对象内置的监视器 private static Lock lock = new ReentrantLock(); // 锁关联的条件队列(类似于object.wait) private static Condition condition = lock.newCondition(); public static void main(String[] args) &#123; Runnable task = new Runnable() &#123; @Override public void run() &#123; // 加锁,进入临界区 lock.lock(); try &#123; condition.await(5, TimeUnit.MINUTES); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 解锁,退出临界区 lock.unlock(); &#125; &#125;; new Thread(task, &quot;t1&quot;).start(); new Thread(task, &quot;t2&quot;).start(); &#125; &#125; 12345678910111213141516171819202122Full thread dump Java HotSpot(TM) Server VM (20.12-b01 mixed mode): &quot;DestroyJavaVM&quot; prio=6 tid=0x00856c00 nid=0x169c waiting on condition [0x00000000] java.lang.Thread.State: RUNNABLE &quot;t2&quot; prio=6 tid=0x27d7d800 nid=0xc30 waiting on condition [0x2833f000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x1cfce5b8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2116) at jstack.TimedWaitingState$1.run(TimedWaitingState.java:28) at java.lang.Thread.run(Thread.java:662) &quot;t1&quot; prio=6 tid=0x280d0c00 nid=0x16e0 waiting on condition [0x282ef000] java.lang.Thread.State: TIMED_WAITING (parking) at sun.misc.Unsafe.park(Native Method) - parking to wait for &lt;0x1cfce5b8&gt; (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject) at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196) at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2116) at jstack.TimedWaitingState$1.run(TimedWaitingState.java:28) at java.lang.Thread.run(Thread.java:662) 可以看到t1和t2线程都处在java.lang.Thread.State: TIMED_WAITING (parking)，这个parking代表是调用的JUC下的工具类，而不是java默认的监视器。 案例分析问题场景 CPU飙高，load高，响应很慢 一个请求过程中多次dump； 对比多次dump文件的runnable线程，如果执行的方法有比较大变化，说明比较正常。如果在执行同一个方法，就有一些问题了； 查找占用CPU最多的线程 使用命令：top -H -p pid（pid为被测系统的进程号），找到导致CPU高的线程ID，对应thread dump信息中线程的nid，只不过一个是十进制，一个是十六进制； 在thread dump中，根据top命令查找的线程id，查找对应的线程堆栈信息； CPU使用率不高但是响应很慢 进行dump，查看是否有很多thread struck在了i&#x2F;o、数据库等地方，定位瓶颈原因； 请求无法响应 多次dump，对比是否所有的runnable线程都一直在执行相同的方法，如果是的，恭喜你，锁住了！ 死锁死锁经常表现为程序的停顿，或者不再响应用户的请求。从操作系统上观察，对应进程的CPU占用率为零，很快会从top或prstat的输出中消失。 比如在下面这个示例中，是个较为典型的死锁情况： 1234567891011&quot;Thread-1&quot; prio=5 tid=0x00acc490 nid=0xe50 waiting for monitor entry [0x02d3f000 ..0x02d3fd68] at deadlockthreads.TestThread.run(TestThread.java:31) - waiting to lock &lt;0x22c19f18&gt; (a java.lang.Object) - locked &lt;0x22c19f20&gt; (a java.lang.Object) &quot;Thread-0&quot; prio=5 tid=0x00accdb0 nid=0xdec waiting for monitor entry [0x02cff000 ..0x02cff9e8] at deadlockthreads.TestThread.run(TestThread.java:31) - waiting to lock &lt;0x22c19f20&gt; (a java.lang.Object) - locked &lt;0x22c19f18&gt; (a java.lang.Object) 在 JAVA 5中加强了对死锁的检测。线程 Dump中可以直接报告出 Java级别的死锁，如下所示： 123456789Found one Java-level deadlock: ============================= &quot;Thread-1&quot;: waiting to lock monitor 0x0003f334 (object 0x22c19f18, a java.lang.Object), which is held by &quot;Thread-0&quot; &quot;Thread-0&quot;: waiting to lock monitor 0x0003f314 (object 0x22c19f20, a java.lang.Object), which is held by &quot;Thread-1&quot; 热锁热锁，也往往是导致系统性能瓶颈的主要因素。其表现特征为：由于多个线程对临界区，或者锁的竞争，可能出现： 频繁的线程的上下文切换：从操作系统对线程的调度来看，当线程在等待资源而阻塞的时候，操作系统会将之切换出来，放到等待的队列，当线程获得资源之后，调度算法会将这个线程切换进去，放到执行队列中。 大量的系统调用：因为线程的上下文切换，以及热锁的竞争，或者临界区的频繁的进出，都可能导致大量的系统调用。 大部分CPU开销用在“系统态”：线程上下文切换，和系统调用，都会导致 CPU在 “系统态 ”运行，换而言之，虽然系统很忙碌，但是CPU用在 “用户态 ”的比例较小，应用程序得不到充分的 CPU资源。 随着CPU数目的增多，系统的性能反而下降。因为CPU数目多，同时运行的线程就越多，可能就会造成更频繁的线程上下文切换和系统态的CPU开销，从而导致更糟糕的性能。 上面的描述，都是一个 scalability（可扩展性）很差的系统的表现。从整体的性能指标看，由于线程热锁的存在，程序的响应时间会变长，吞吐量会降低。 那么，怎么去了解 “热锁 ”出现在什么地方呢？ 一个重要的方法是 结合操作系统的各种工具观察系统资源使用状况，以及收集Java线程的DUMP信息，看线程都阻塞在什么方法上，了解原因，才能找到对应的解决方法。 JVM重要线程JVM运行过程中产生的一些比较重要的线程罗列如下： 线程名称 解释说明 Attach Listener Attach Listener 线程是负责接收到外部的命令，而对该命令进行执行的并把结果返回给发送者。通常我们会用一些命令去要求JVM给我们一些反馈信息，如：java -version、jmap、jstack等等。 如果该线程在JVM启动的时候没有初始化，那么，则会在用户第一次执行JVM命令时，得到启动。 Signal Dispatcher 前面提到Attach Listener线程的职责是接收外部JVM命令，当命令接收成功后，会交给signal dispather线程去进行分发到各个不同的模块处理命令，并且返回处理结果。signal dispather线程也是在第一次接收外部JVM命令时，进行初始化工作。 CompilerThread0 用来调用JITing，实时编译装卸class 。 通常，JVM会启动多个线程来处理这部分工作，线程名称后面的数字也会累加，例如：CompilerThread1。 Concurrent Mark-Sweep GC Thread 并发标记清除垃圾回收器（就是通常所说的CMS GC）线程， 该线程主要针对于老年代垃圾回收。ps：启用该垃圾回收器，需要在JVM启动参数中加上：-XX:+UseConcMarkSweepGC。 DestroyJavaVM 执行main()的线程，在main执行完后调用JNI中的 jni_DestroyJavaVM() 方法唤起DestroyJavaVM 线程，处于等待状态，等待其它线程（Java线程和Native线程）退出时通知它卸载JVM。每个线程退出时，都会判断自己当前是否是整个JVM中最后一个非deamon线程，如果是，则通知DestroyJavaVM 线程卸载JVM。 Finalizer Thread 这个线程也是在main线程之后创建的，其优先级为10，主要用于在垃圾收集前，调用对象的finalize()方法；关于Finalizer线程的几点：1) 只有当开始一轮垃圾收集时，才会开始调用finalize()方法；因此并不是所有对象的finalize()方法都会被执行；2) 该线程也是daemon线程，因此如果虚拟机中没有其他非daemon线程，不管该线程有没有执行完finalize()方法，JVM也会退出；3) JVM在垃圾收集时会将失去引用的对象包装成Finalizer对象（Reference的实现），并放入ReferenceQueue，由Finalizer线程来处理；最后将该Finalizer对象的引用置为null，由垃圾收集器来回收；4) JVM为什么要单独用一个线程来执行finalize()方法呢？如果JVM的垃圾收集线程自己来做，很有可能由于在finalize()方法中误操作导致GC线程停止或不可控，这对GC线程来说是一种灾难； Low Memory Detector 这个线程是负责对可使用内存进行检测，如果发现可用内存低，分配新的内存空间。 Reference Handler JVM在创建main线程后就创建Reference Handler线程，其优先级最高，为10，它主要用于处理引用对象本身（软引用、弱引用、虚引用）的垃圾回收问题 。 VM Thread 这个线程就比较牛b了，是JVM里面的线程母体，根据hotspot源码（vmThread.hpp）里面的注释，它是一个单个的对象（最原始的线程）会产生或触发所有其他的线程，这个单个的VM线程是会被其他线程所使用来做一些VM操作（如：清扫垃圾等）。 参考文章 作者：猿码架构 链接：https://www.jianshu.com/p/f1db856022de 来源：简书","tags":["Java","JVM","调试排错","线程分析"],"categories":["Java","JVM","调试排错","线程分析"]},{"title":"14.调试排错 - Java 内存分析之堆外内存","path":"/2023/12/27/14-调试排错-Java-内存分析之堆外内存/","content":"Java 堆外内存分析相对来说是复杂的，美团技术团队的Spring Boot引起的“堆外内存泄漏”排查及经验总结可以为很多Native Code内存泄漏&#x2F;占用提供方向性指引。 背景为了更好地实现对项目的管理，我们将组内一个项目迁移到MDP框架（基于Spring Boot），随后我们就发现系统会频繁报出Swap区域使用量过高的异常。笔者被叫去帮忙查看原因，发现配置了4G堆内内存，但是实际使用的物理内存竟然高达7G，确实不正常。JVM参数配置是-XX:MetaspaceSize=256M -XX:MaxMetaspaceSize=256M -XX:+AlwaysPreTouch -XX:ReservedCodeCacheSize=128m -XX:InitialCodeCacheSize=128m, -Xss512k -Xmx4g -Xms4g,-XX:+UseG1GC -XX:G1HeapRegionSize=4M，实际使用的物理内存如下图所示： 排查过程使用Java层面的工具定位内存区域 使用Java层面的工具可以定位出堆内内存、Code区域或者使用unsafe.allocateMemory和DirectByteBuffer申请的堆外内存 笔者在项目中添加-XX:NativeMemoryTracking=detailJVM参数重启项目，使用命令jcmd pid VM.native_memory detail查看到的内存分布如下： 发现命令显示的committed的内存小于物理内存，因为jcmd命令显示的内存包含堆内内存、Code区域、通过unsafe.allocateMemory和DirectByteBuffer申请的内存，但是不包含其他Native Code（C代码）申请的堆外内存。所以猜测是使用Native Code申请内存所导致的问题。 为了防止误判，笔者使用了pmap查看内存分布，发现大量的64M的地址；而这些地址空间不在jcmd命令所给出的地址空间里面，基本上就断定就是这些64M的内存所导致。 使用系统层面的工具定位堆外内存因为笔者已经基本上确定是Native Code所引起，而Java层面的工具不便于排查此类问题，只能使用系统层面的工具去定位问题。 首先，使用了gperftools去定位问题gperftools的使用方法可以参考gperftools，gperftools的监控如下： 从上图可以看出：使用malloc申请的的内存最高到3G之后就释放了，之后始终维持在700M-800M。笔者第一反应是：难道Native Code中没有使用malloc申请，直接使用mmap&#x2F;brk申请的？（gperftools原理就使用动态链接的方式替换了操作系统默认的内存分配器（glibc）。） 然后，使用strace去追踪系统调用因为使用gperftools没有追踪到这些内存，于是直接使用命令“strace -f -e”brk,mmap,munmap” -p pid”追踪向OS申请内存请求，但是并没有发现有可疑内存申请。strace监控如下图所示: 接着，使用GDB去dump可疑内存因为使用strace没有追踪到可疑内存申请；于是想着看看内存中的情况。就是直接使用命令gdp -pid pid进入GDB之后，然后使用命令dump memory mem.bin startAddress endAddressdump内存，其中startAddress和endAddress可以从&#x2F;proc&#x2F;pid&#x2F;smaps中查找。然后使用strings mem.bin查看dump的内容，如下： 从内容上来看，像是解压后的JAR包信息。读取JAR包信息应该是在项目启动的时候，那么在项目启动之后使用strace作用就不是很大了。所以应该在项目启动的时候使用strace，而不是启动完成之后。 再次，项目启动时使用strace去追踪系统调用项目启动使用strace追踪系统调用，发现确实申请了很多64M的内存空间，截图如下： 使用该mmap申请的地址空间在pmap对应如下： 最后，使用jstack去查看对应的线程因为strace命令中已经显示申请内存的线程ID。直接使用命令jstack pid去查看线程栈，找到对应的线程栈（注意10进制和16进制转换）如下： 这里基本上就可以看出问题来了：MCC（美团统一配置中心）使用了Reflections进行扫包，底层使用了Spring Boot去加载JAR。因为解压JAR使用Inflater类，需要用到堆外内存，然后使用Btrace去追踪这个类，栈如下： 然后查看使用MCC的地方，发现没有配置扫包路径，默认是扫描所有的包。于是修改代码，配置扫包路径，发布上线后内存问题解决。 为什么堆外内存没有释放掉呢？虽然问题已经解决了，但是有几个疑问： 为什么使用旧的框架没有问题？ 为什么堆外内存没有释放？ 为什么内存大小都是64M，JAR大小不可能这么大，而且都是一样大？ 为什么gperftools最终显示使用的的内存大小是700M左右，解压包真的没有使用malloc申请内存吗？ 带着疑问，笔者直接看了一下Spring Boot Loader那一块的源码。发现Spring Boot对Java JDK的InflaterInputStream进行了包装并且使用了Inflater，而Inflater本身用于解压JAR包的需要用到堆外内存。而包装之后的类ZipInflaterInputStream没有释放Inflater持有的堆外内存。于是笔者以为找到了原因，立马向Spring Boot社区反馈了这个bug。但是反馈之后，笔者就发现Inflater这个对象本身实现了finalize方法，在这个方法中有调用释放堆外内存的逻辑。也就是说Spring Boot依赖于GC释放堆外内存。 笔者使用jmap查看堆内对象时，发现已经基本上没有Inflater这个对象了。于是就怀疑GC的时候，没有调用finalize。带着这样的怀疑，笔者把Inflater进行包装在Spring Boot Loader里面替换成自己包装的Inflater，在finalize进行打点监控，结果finalize方法确实被调用了。于是笔者又去看了Inflater对应的C代码，发现初始化的使用了malloc申请内存，end的时候也调用了free去释放内存。 此刻，笔者只能怀疑free的时候没有真正释放内存，便把Spring Boot包装的InflaterInputStream替换成Java JDK自带的，发现替换之后，内存问题也得以解决了。 这时，再返过来看gperftools的内存分布情况，发现使用Spring Boot时，内存使用一直在增加，突然某个点内存使用下降了好多（使用量直接由3G降为700M左右）。这个点应该就是GC引起的，内存应该释放了，但是在操作系统层面并没有看到内存变化，那是不是没有释放到操作系统，被内存分配器持有了呢？ 继续探究，发现系统默认的内存分配器（glibc 2.12版本）和使用gperftools内存地址分布差别很明显，2.5G地址使用smaps发现它是属于Native Stack。内存地址分布如下： 到此，基本上可以确定是内存分配器在捣鬼；搜索了一下glibc 64M，发现glibc从2.11开始对每个线程引入内存池（64位机器大小就是64M内存），原文如下： 按照文中所说去修改MALLOC_ARENA_MAX环境变量，发现没什么效果。查看tcmalloc（gperftools使用的内存分配器）也使用了内存池方式。 为了验证是内存池搞的鬼，笔者就简单写个不带内存池的内存分配器。使用命令gcc zjbmalloc.c -fPIC -shared -o zjbmalloc.so生成动态库，然后使用export LD_PRELOAD=zjbmalloc.so替换掉glibc的内存分配器。其中代码Demo如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#include&lt;sys/mman.h&gt;#include&lt;stdlib.h&gt;#include&lt;string.h&gt;#include&lt;stdio.h&gt;//作者使用的64位机器，sizeof(size_t)也就是sizeof(long) void* malloc ( size_t size )&#123; long* ptr = mmap( 0, size + sizeof(long), PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANONYMOUS, 0, 0 ); if (ptr == MAP_FAILED) &#123; return NULL; &#125; *ptr = size; // First 8 bytes contain length. return (void*)(&amp;ptr[1]); // Memory that is after length variable&#125;void *calloc(size_t n, size_t size) &#123; void* ptr = malloc(n * size); if (ptr == NULL) &#123;\treturn NULL; &#125; memset(ptr, 0, n * size); return ptr;&#125;void *realloc(void *ptr, size_t size)&#123; if (size == 0) &#123;\tfree(ptr);\treturn NULL; &#125; if (ptr == NULL) &#123;\treturn malloc(size); &#125; long *plen = (long*)ptr; plen--; // Reach top of memory long len = *plen; if (size &lt;= len) &#123;\treturn ptr; &#125; void* rptr = malloc(size); if (rptr == NULL) &#123;\tfree(ptr);\treturn NULL; &#125; rptr = memcpy(rptr, ptr, len); free(ptr); return rptr;&#125;void free (void* ptr )&#123; if (ptr == NULL) &#123; return; &#125; long *plen = (long*)ptr; plen--; // Reach top of memory long len = *plen; // Read length munmap((void*)plen, len + sizeof(long));&#125; 通过在自定义分配器当中埋点可以发现其实程序启动之后应用实际申请的堆外内存始终在700M-800M之间，gperftools监控显示内存使用量也是在700M-800M左右。但是从操作系统角度来看进程占用的内存差别很大（这里只是监控堆外内存）。 笔者做了一下测试，使用不同分配器进行不同程度的扫包，占用的内存如下： 为什么自定义的malloc申请800M，最终占用的物理内存在1.7G呢？ 因为自定义内存分配器采用的是mmap分配内存，mmap分配内存按需向上取整到整数个页，所以存在着巨大的空间浪费。通过监控发现最终申请的页面数目在536k个左右，那实际上向系统申请的内存等于512k * 4k（pagesize） &#x3D; 2G。 为什么这个数据大于1.7G呢？ 因为操作系统采取的是延迟分配的方式，通过mmap向系统申请内存的时候，系统仅仅返回内存地址并没有分配真实的物理内存。只有在真正使用的时候，系统产生一个缺页中断，然后再分配实际的物理Page。 总结 整个内存分配的流程如上图所示。MCC扫包的默认配置是扫描所有的JAR包。在扫描包的时候，Spring Boot不会主动去释放堆外内存，导致在扫描阶段，堆外内存占用量一直持续飙升。当发生GC的时候，Spring Boot依赖于finalize机制去释放了堆外内存；但是glibc为了性能考虑，并没有真正把内存归返到操作系统，而是留下来放入内存池了，导致应用层以为发生了“内存泄漏”。所以修改MCC的配置路径为特定的JAR包，问题解决。笔者在发表这篇文章时，发现Spring Boot的最新版本（2.0.5.RELEASE）已经做了修改，在ZipInflaterInputStream主动释放了堆外内存不再依赖GC；所以Spring Boot升级到最新版本，这个问题也可以得到解决。 参考资料 GNU C Library (glibc) Native Memory Tracking gperftools Btrace 作者简介 纪兵，2015年加入美团，目前主要从事酒店C端相关的工作。","tags":["Java","JVM","调试排错","内存分析"],"categories":["Java","JVM","调试排错","内存分析"]},{"title":"13.调试排错 - Java 内存分析之堆内存和MetaSpace内存","path":"/2023/12/27/13-调试排错-Java-内存分析之堆内存和MetaSpace内存/","content":"本文以两个简单的例子(堆内存溢出和MetaSpace (元数据) 内存溢出）解释Java 内存溢出的分析过程。 常见的内存溢出问题(内存和MetaSpace内存) 常见的内存溢出问题(内存和MetaSpace内存)。 Java 堆内存溢出Java 堆内存（Heap Memory)主要有两种形式的错误： OutOfMemoryError: Java heap space OutOfMemoryError: GC overhead limit exceeded OutOfMemoryError: Java heap space在 Java 堆中只要不断的创建对象，并且 GC-Roots 到对象之间存在引用链，这样 JVM 就不会回收对象。 只要将-Xms(最小堆),-Xmx(最大堆) 设置为一样禁止自动扩展堆内存。 当使用一个 while(true) 循环来不断创建对象就会发生 OutOfMemory，还可以使用 -XX:+HeapDumpOutofMemoryErorr 当发生 OOM 时会自动 dump 堆栈到文件中。 伪代码: 123456public static void main(String[] args) &#123;\tList&lt;String&gt; list = new ArrayList&lt;&gt;(10) ;\twhile (true)&#123; list.add(&quot;1&quot;) ;\t&#125;&#125; 当出现 OOM 时可以通过工具来分析 GC-Roots 引用链在新窗口打开 ，查看对象和 GC-Roots 是如何进行关联的，是否存在对象的生命周期过长，或者是这些对象确实改存在的，那就要考虑将堆内存调大了。 123456789101112131415Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space\tat java.util.Arrays.copyOf(Arrays.java:3210)\tat java.util.Arrays.copyOf(Arrays.java:3181)\tat java.util.ArrayList.grow(ArrayList.java:261)\tat java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:235)\tat java.util.ArrayList.ensureCapacityInternal(ArrayList.java:227)\tat java.util.ArrayList.add(ArrayList.java:458)\tat com.crossoverjie.oom.HeapOOM.main(HeapOOM.java:18)\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\tat java.lang.reflect.Method.invoke(Method.java:498)\tat com.intellij.rt.execution.application.AppMain.main(AppMain.java:147)Process finished with exit code 1 java.lang.OutOfMemoryError: Java heap space表示堆内存溢出。 OutOfMemoryError: GC overhead limit exceededGC overhead limt exceed检查是Hotspot VM 1.6定义的一个策略，通过统计GC时间来预测是否要OOM了，提前抛出异常，防止OOM发生。Sun 官方对此的定义是：“并行&#x2F;并发回收器在GC回收时间过长时会抛出OutOfMemroyError。过长的定义是，超过98%的时间用来做GC并且回收了不到2%的堆内存。用来避免内存过小造成应用不能正常工作。“ PS：-Xmx最大内存配置2GB 12345678910public void testOom1() &#123;\tList&lt;Map&lt;String, Object&gt;&gt; mapList = new ArrayList&lt;&gt;();\tfor (int i = 0; i &lt; 1000000; i++) &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); for (int j = 0; j &lt; i; j++) &#123; map.put(String.valueOf(j), j); &#125; mapList.add(map);\t&#125;&#125; 上述的代码执行会：old区占用过多导致频繁Full GC，最终导致GC overhead limit exceed。 123456789101112131415161718192021222324252627282930313233java.lang.OutOfMemoryError: GC overhead limit exceeded\tat java.util.HashMap.newNode(HashMap.java:1747) ~[na:1.8.0_181]\tat java.util.HashMap.putVal(HashMap.java:642) ~[na:1.8.0_181]\tat java.util.HashMap.put(HashMap.java:612) ~[na:1.8.0_181]\tat tech.pdai.test.oom.controller.TestOomController.testOom1(TestOomController.java:33) ~[classes/:na]\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_181]\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_181]\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_181]\tat java.lang.reflect.Method.invoke(Method.java:498) ~[na:1.8.0_181]\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197) ~[spring-web-5.3.9.jar:5.3.9]\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141) ~[spring-web-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1064) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:655) ~[tomcat-embed-core-9.0.50.jar:4.0.FR]\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883) ~[spring-webmvc-5.3.9.jar:5.3.9]\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:764) ~[tomcat-embed-core-9.0.50.jar:4.0.FR]\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:228) ~[tomcat-embed-core-9.0.50.jar:9.0.50]\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) ~[tomcat-embed-core-9.0.50.jar:9.0.50]\tat org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53) ~[tomcat-embed-websocket-9.0.50.jar:9.0.50]\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) ~[tomcat-embed-core-9.0.50.jar:9.0.50]\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) ~[tomcat-embed-core-9.0.50.jar:9.0.50]\tat org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100) ~[spring-web-5.3.9.jar:5.3.9]\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.9.jar:5.3.9]\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190) ~[tomcat-embed-core-9.0.50.jar:9.0.50]\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163) ~[tomcat-embed-core-9.0.50.jar:9.0.50]\tat org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93) ~[spring-web-5.3.9.jar:5.3.9]\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119) ~[spring-web-5.3.9.jar:5.3.9] 还可以使用 -XX:+HeapDumpOutofMemoryErorr 当发生 OOM 时会自动 dump 堆栈到文件中。 JVM还有这样一个参数：-XX:-UseGCOverheadLimit 设置为false可以禁用这个检查。其实这个参数解决不了内存问题，只是把错误的信息延后，替换成 java.lang.OutOfMemoryError: Java heap space。 MetaSpace (元数据) 内存溢出 JDK8 中将永久代移除，使用 MetaSpace 来保存类加载之后的类信息，字符串常量池也被移动到 Java 堆。 PermSize 和 MaxPermSize 已经不能使用了，在 JDK8 中配置这两个参数将会发出警告。 JDK 8 中将类信息移到到了本地堆内存(Native Heap)中，将原有的永久代移动到了本地堆中成为 MetaSpace ,如果不指定该区域的大小，JVM 将会动态的调整。 可以使用 -XX:MaxMetaspaceSize=10M 来限制最大元数据。这样当不停的创建类时将会占满该区域并出现 OOM。 1234567891011121314public static void main(String[] args) &#123;\twhile (true)&#123; Enhancer enhancer = new Enhancer() ; enhancer.setSuperclass(HeapOOM.class); enhancer.setUseCache(false) ; enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; return methodProxy.invoke(o,objects) ; &#125; &#125;); enhancer.create() ;\t&#125;&#125; 使用 cglib 不停的创建新类，最终会抛出: 1234567891011Caused by: java.lang.reflect.InvocationTargetException\tat sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source)\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\tat java.lang.reflect.Method.invoke(Method.java:498)\tat net.sf.cglib.core.ReflectUtils.defineClass(ReflectUtils.java:459)\tat net.sf.cglib.core.AbstractClassGenerator.generate(AbstractClassGenerator.java:336)\t... 11 moreCaused by: java.lang.OutOfMemoryError: Metaspace\tat java.lang.ClassLoader.defineClass1(Native Method)\tat java.lang.ClassLoader.defineClass(ClassLoader.java:763)\t... 16 more 注意: 这里的 OOM 伴随的是 java.lang.OutOfMemoryError: Metaspace 也就是元数据溢出。 分析案例 在实际工作中，如何去定位内存泄漏问题呢？ 堆内存dump 通过OOM获取 即在OutOfMemoryError后获取一份HPROF二进制Heap Dump文件，在jvm中添加参数： 1-XX:+HeapDumpOnOutOfMemoryError 主动获取 在虚拟机添加参数如下，然后在Ctrl+Break组合键即可获取一份Heap Dump 1-XX:+HeapDumpOnCtrlBreak 使用HPROF agent 使用Agent可以在程序执行结束时或受到SIGOUT信号时生成Dump文件 配置在虚拟机的参数如下： 1-agentlib:hprof=heap=dump,format=b jmap获取 (常用) jmap可以在cmd里执行，命令如下： 1jmap -dump:format=b file=&lt;文件名XX.hprof&gt; &lt;pid&gt; 使用JConsole Acquire Heap Dump 使用JProfile Acquire Heap Dump 使用MAT分析内存MAT 等工具可以看：Java 问题排查之JVM可视化工具 - MAT","tags":["Java","JVM","调试排错","内存分析"],"categories":["Java","JVM","调试排错","内存分析"]},{"title":"12.调试排错 - JVM 调优参数","path":"/2023/12/27/12-调试排错-JVM-调优参数/","content":"本文对JVM涉及的常见的调优参数和垃圾回收参数进行阐述。 jvm参数 -Xms 堆最小值 -Xmx 堆最大堆值。-Xms与-Xmx 的单位默认字节都是以k、m做单位的。 通常这两个配置参数相等，避免每次空间不足，动态扩容带来的影响。 -Xmn 新生代大小 -Xss 每个线程池的堆栈大小。在jdk5以上的版本，每个线程堆栈大小为1m，jdk5以前的版本是每个线程池大小为256k。一般在相同物理内存下，如果减少－xss值会产生更大的线程数，但不同的操作系统对进程内线程数是有限制的，是不能无限生成。 -XX:NewRatio 设置新生代与老年代比值，-XX:NewRatio&#x3D;4 表示新生代与老年代所占比例为1:4 ，新生代占比整个堆的五分之一。如果设置了-Xmn的情况下，该参数是不需要在设置的。 -XX:PermSize 设置持久代初始值，默认是物理内存的六十四分之一 -XX:MaxPermSize 设置持久代最大值，默认是物理内存的四分之一 -XX:MaxTenuringThreshold 新生代中对象存活次数，默认15。(若对象在eden区，经历一次MinorGC后还活着，则被移动到Survior区，年龄加1。以后，对象每次经历MinorGC，年龄都加1。达到阀值，则移入老年代) -XX:SurvivorRatio Eden区与Subrvivor区大小的比值，如果设置为8，两个Subrvivor区与一个Eden区的比值为2:8，一个Survivor区占整个新生代的十分之一 -XX:+UseFastAccessorMethods 原始类型快速优化 -XX:+AggressiveOpts 编译速度加快 -XX:PretenureSizeThreshold 对象超过多大值时直接在老年代中分配 12345说明: 整个堆大小的计算公式: JVM 堆大小 ＝ 年轻代大小＋年老代大小＋持久代大小。增大新生代大小就会减少对应的年老代大小，设置-Xmn值对系统性能影响较大，所以如果设置新生代大小的调整，则需要严格的测试调整。而新生代是用来存放新创建的对象，大小是随着堆大小增大和减少而有相应的变化，默认值是保持堆大小的十五分之一，-Xmn参数就是设置新生代的大小，也可以通过-XX:NewRatio来设置新生代与年老代的比例，java 官方推荐配置为3:8。新生代的特点就是内存中的对象更新速度快，在短时间内容易产生大量的无用对象，如果在这个参数时就需要考虑垃圾回收器设置参数也需要调整。推荐使用: 复制清除算法和并行收集器进行垃圾回收，而新生代的垃圾回收叫做初级回收。 1StackOverflowError和OutOfMemoryException。当线程中的请求的栈的深度大于最大可用深度，就会抛出前者；若内存空间不够，无法创建新的线程，则会抛出后者。栈的大小直接决定了函数的调用最大深度，栈越大，函数嵌套可调用次数就越多。 经验 : Xmn用于设置新生代的大小。过小会增加Minor GC频率，过大会减小老年代的大小。一般设为整个堆空间的1&#x2F;4或1&#x2F;3. XX:SurvivorRatio用于设置新生代中survivor空间(from&#x2F;to)和eden空间的大小比例； XX:TargetSurvivorRatio表示，当经历Minor GC后，survivor空间占有量(百分比)超过它的时候，就会压缩进入老年代(当然，如果survivor空间不够，则直接进入老年代)。默认值为50%。 为了性能考虑，一开始尽量将新生代对象留在新生代，避免新生的大对象直接进入老年代。因为新生对象大部分都是短期的，这就造成了老年代的内存浪费，并且回收代价也高(Full GC发生在老年代和方法区Perm). 当Xms&#x3D;Xmx，可以使得堆相对稳定，避免不停震荡 一般来说，MaxPermSize设为64MB可以满足绝大多数的应用了。若依然出现方法区溢出，则可以设为128MB。若128MB还不能满足需求，那么就应该考虑程序优化了，减少动态类的产生。 垃圾回收垃圾回收算法 : 引用计数法: 会有循环引用的问题，古老的方法； Mark-Sweep: 标记清除。根可达判断，最大的问题是空间碎片(清除垃圾之后剩下不连续的内存空间)； Copying: 复制算法。对于短命对象来说有用，否则需要复制大量的对象，效率低。如Java的新生代堆空间中就是使用了它(survivor空间的from和to区)； Mark-Compact: 标记整理。对于老年对象来说有用，无需复制，不会产生内存碎片 GC考虑的指标 吞吐量: 应用耗时和实际耗时的比值； 停顿时间: 垃圾回收的时候，由于Stop the World，应用程序的所有线程会挂起，造成应用停顿。 123吞吐量和停顿时间是互斥的。对于后端服务(比如后台计算任务)，吞吐量优先考虑(并行垃圾回收)；对于前端应用，RT响应时间优先考虑，减少垃圾收集时的停顿时间，适用场景是Web系统(并发垃圾回收) 回收器的JVM参数 -XX:+UseSerialGC 串行垃圾回收，现在基本很少使用。 -XX:+UseParNewGC 新生代使用并行，老年代使用串行； -XX:+UseConcMarkSweepGC 新生代使用并行，老年代使用CMS(一般都是使用这种方式)，CMS是Concurrent Mark Sweep的缩写，并发标记清除，一看就是老年代的算法，所以，它可以作为老年代的垃圾回收器。CMS不是独占式的，它关注停顿时间 -XX:ParallelGCThreads 指定并行的垃圾回收线程的数量，最好等于CPU数量 -XX:+DisableExplicitGC 禁用System.gc()，因为它会触发Full GC，这是很浪费性能的，JVM会在需要GC的时候自己触发GC。 -XX:CMSFullGCsBeforeCompaction 在多少次GC后进行内存压缩，这个是因为并行收集器不对内存空间进行压缩的，所以运行一段时间后会产生很多碎片，使得运行效率降低。 -XX:+CMSParallelRemarkEnabled 降低标记停顿 -XX:+UseCMSCompactAtFullCollection 在每一次Full GC时对老年代区域碎片整理，因为CMS是不会移动内存的，因此会非常容易出现碎片导致内存不够用的 -XX:+UseCmsInitiatingOccupancyOnly 使用手动触发或者自定义触发cms 收集，同时也会禁止hostspot 自行触发CMS GC -XX:CMSInitiatingOccupancyFraction 使用CMS作为垃圾回收，使用70%后开始CMS收集 -XX:CMSInitiatingPermOccupancyFraction 设置perm gen使用达到多少％比时触发垃圾回收，默认是92% -XX:+CMSIncrementalMode 设置为增量模式 -XX:+CmsClassUnloadingEnabled CMS是不会默认对永久代进行垃圾回收的，设置此参数则是开启 -XX:+PrintGCDetails 开启详细GC日志模式，日志的格式是和所使用的算法有关 -XX:+PrintGCDateStamps 将时间和日期也加入到GC日志中","tags":["Java","JVM","调试排错","JVM调优"],"categories":["Java","JVM","调试排错","JVM调优"]},{"title":"11.GC - Java 垃圾回收器之CMS GC问题分析与解决","path":"/2023/12/27/11-GC-Java-垃圾回收器之CMS-GC问题分析与解决/","content":"本文整理自美团技术团队, 这篇文章将可以帮助你构建CMS GC相关问题解决的知识体系，分享给你。 1. 写在前面 本文主要针对 Hotspot VM 中“CMS + ParNew”组合的一些使用场景进行总结。重点通过部分源码对根因进行分析以及对排查方法进行总结，排查过程会省略较多，另外本文专业术语较多，有一定的阅读门槛，如未介绍清楚，还请自行查阅相关材料。 1.1 引言自 Sun 发布 Java 语言以来，开始使用 GC 技术来进行内存自动管理，避免了手动管理带来的悬挂指针（Dangling Pointer）问题，很大程度上提升了开发效率，从此 GC 技术也一举成名。GC 有着非常悠久的历史，1960 年有着“Lisp 之父”和“人工智能之父”之称的 John McCarthy 就在论文中发布了 GC 算法，60 年以来， GC 技术的发展也突飞猛进，但不管是多么前沿的收集器也都是基于三种基本算法的组合或应用，也就是说 GC 要解决的根本问题这么多年一直都没有变过。笔者认为，在不太远的将来， GC 技术依然不会过时，比起日新月异的新技术，GC 这门古典技术更值得我们学习。 目前，互联网上 Java 的 GC 资料要么是主要讲解理论，要么就是针对单一场景的 GC 问题进行了剖析，对整个体系总结的资料少之又少。前车之鉴，后事之师，美团的几位工程师搜集了内部各种 GC 问题的分析文章，并结合个人的理解做了一些总结，希望能起到“抛砖引玉”的作用，文中若有错误之处，还请大家不吝指正。 GC 问题处理能力能不能系统性掌握？一些影响因素都是互为因果的问题该怎么分析？比如一个服务 RT 突然上涨，有 GC 耗时增大、线程 Block 增多、慢查询增多、CPU 负载高四个表象，到底哪个是诱因？如何判断 GC 有没有问题？使用 CMS 有哪些常见问题？如何判断根因是什么？如何解决或避免这些问题？阅读完本文，相信你将会对 CMS GC 的问题处理有一个系统性的认知，更能游刃有余地解决这些问题，下面就让我们开始吧！ 1.2 概览想要系统性地掌握 GC 问题处理，笔者这里给出一个学习路径，整体文章的框架也是按照这个结构展开，主要分四大步。 建立知识体系： 从 JVM 的内存结构到垃圾收集的算法和收集器，学习 GC 的基础知识，掌握一些常用的 GC 问题分析工具。 确定评价指标： 了解基本 GC 的评价方法，摸清如何设定独立系统的指标，以及在业务场景中判断 GC 是否存在问题的手段。 场景调优实践： 运用掌握的知识和系统评价指标，分析与解决九种 CMS 中常见 GC 问题场景。 总结优化经验： 对整体过程做总结并提出笔者的几点建议，同时将总结到的经验完善到知识体系之中。 2. GC 基础在正式开始前，先做些简要铺垫，介绍下 JVM 内存划分、收集算法、收集器等常用概念介绍，基础比较好的同学可以直接跳过这部分。 2.1 基础概念 GC： GC 本身有三种语义，下文需要根据具体场景带入不同的语义： Garbage Collection：垃圾收集技术，名词。 Garbage Collector：垃圾收集器，名词。 Garbage Collecting：垃圾收集动作，动词。 Mutator： 生产垃圾的角色，也就是我们的应用程序，垃圾制造者，通过 Allocator 进行 allocate 和 free。 TLAB： Thread Local Allocation Buffer 的简写，基于 CAS 的独享线程（Mutator Threads）可以优先将对象分配在 Eden 中的一块内存，因为是 Java 线程独享的内存区没有锁竞争，所以分配速度更快，每个 TLAB 都是一个线程独享的。 Card Table： 中文翻译为卡表，主要是用来标记卡页的状态，每个卡表项对应一个卡页。当卡页中一个对象引用有写操作时，写屏障将会标记对象所在的卡表状态改为 dirty，卡表的本质是用来解决跨代引用的问题。具体怎么解决的可以参考 StackOverflow 上的这个问题 how-actually-card-table-and-writer-barrier-works，或者研读一下 cardTableRS.app 中的源码。 2.2 JVM 内存划分从 JCP（Java Community Process）的官网中可以看到，目前 Java 版本最新已经到了 Java 16，未来的 Java 17 以及现在的 Java 11 和 Java 8 是 LTS 版本，JVM 规范也在随着迭代在变更，由于本文主要讨论 CMS，此处还是放 Java 8 的内存结构。 GC 主要工作在 Heap 区和 MetaSpace 区（上图蓝色部分），在 Direct Memory 中，如果使用的是 DirectByteBuffer，那么在分配内存不够时则是 GC 通过 Cleaner#clean 间接管理。 任何自动内存管理系统都会面临的步骤：为新对象分配空间，然后收集垃圾对象空间，下面我们就展开介绍一下这些基础知识。 2.3 分配对象Java 中对象地址操作主要使用 Unsafe 调用了 C 的 allocate 和 free 两个方法，分配方法有两种： 空闲链表（free list）： 通过额外的存储记录空闲的地址，将随机 IO 变为顺序 IO，但带来了额外的空间消耗。 碰撞指针（bump pointer）： 通过一个指针作为分界点，需要分配内存时，仅需把指针往空闲的一端移动与对象大小相等的距离，分配效率较高，但使用场景有限。 2.4 收集对象2.4.1 识别垃圾引用计数法（Reference Counting）： 对每个对象的引用进行计数，每当有一个地方引用它时计数器 +1、引用失效则 -1，引用的计数放到对象头中，大于 0 的对象被认为是存活对象。虽然循环引用的问题可通过 Recycler 算法解决，但是在多线程环境下，引用计数变更也要进行昂贵的同步操作，性能较低，早期的编程语言会采用此算法。 可达性分析，又称引用链法（Tracing GC）： 从 GC Root 开始进行对象搜索，可以被搜索到的对象即为可达对象，此时还不足以判断对象是否存活&#x2F;死亡，需要经过多次标记才能更加准确地确定，整个连通图之外的对象便可以作为垃圾被回收掉。目前 Java 中主流的虚拟机均采用此算法。 备注：引用计数法是可以处理循环引用问题的，下次面试时不要再这么说啦~ ~ 2.4.2 收集算法自从有自动内存管理出现之时就有的一些收集算法，不同的收集器也是在不同场景下进行组合。 Mark-Sweep（标记-清除）： 回收过程主要分为两个阶段，第一阶段为追踪（Tracing）阶段，即从 GC Root 开始遍历对象图，并标记（Mark）所遇到的每个对象，第二阶段为清除（Sweep）阶段，即回收器检查堆中每一个对象，并将所有未被标记的对象进行回收，整个过程不会发生对象移动。整个算法在不同的实现中会使用三色抽象（Tricolour Abstraction）、位图标记（BitMap）等技术来提高算法的效率，存活对象较多时较高效。 Mark-Compact （标记-整理）： 这个算法的主要目的就是解决在非移动式回收器中都会存在的碎片化问题，也分为两个阶段，第一阶段与 Mark-Sweep 类似，第二阶段则会对存活对象按照整理顺序（Compaction Order）进行整理。主要实现有双指针（Two-Finger）回收算法、滑动回收（Lisp2）算法和引线整理（Threaded Compaction）算法等。 Copying（复制）： 将空间分为两个大小相同的 From 和 To 两个半区，同一时间只会使用其中一个，每次进行回收时将一个半区的存活对象通过复制的方式转移到另一个半区。有递归（Robert R. Fenichel 和 Jerome C. Yochelson提出）和迭代（Cheney 提出）算法，以及解决了前两者递归栈、缓存行等问题的近似优先搜索算法。复制算法可以通过碰撞指针的方式进行快速地分配内存，但是也存在着空间利用率不高的缺点，另外就是存活对象比较大时复制的成本比较高。 三种算法在是否移动对象、空间和时间方面的一些对比，假设存活对象数量为 L、堆空间大小为 H，则： 把 mark、sweep、compaction、copying 这几种动作的耗时放在一起看，大致有这样的关系： 虽然 compaction 与 copying 都涉及移动对象，但取决于具体算法，compaction 可能要先计算一次对象的目标地址，然后修正指针，最后再移动对象。copying 则可以把这几件事情合为一体来做，所以可以快一些。另外，还需要留意 GC 带来的开销不能只看 Collector 的耗时，还得看 Allocator 。如果能保证内存没碎片，分配就可以用 pointer bumping 方式，只需要挪一个指针就完成了分配，非常快。而如果内存有碎片就得用 freelist 之类的方式管理，分配速度通常会慢一些。 2.5 收集器目前在 Hotspot VM 中主要有分代收集和分区收集两大类，具体可以看下面的这个图，不过未来会逐渐向分区收集发展。在美团内部，有部分业务尝试用了 ZGC（感兴趣的同学可以学习下这篇文章 新一代垃圾回收器ZGC的探索与实践），其余基本都停留在 CMS 和 G1 上。另外在 JDK11 后提供了一个不执行任何垃圾回收动作的回收器 Epsilon（A No-Op Garbage Collector）用作性能分析。另外一个就是 Azul 的 Zing JVM，其 C4（Concurrent Continuously Compacting Collector）收集器也在业内有一定的影响力。 备注：值得一提的是，早些年国内 GC 技术的布道者 RednaxelaFX （江湖人称 R 大）也曾就职于 Azul，本文的一部分材料也参考了他的一些文章。 2.5.1 分代收集器 ParNew： 一款多线程的收集器，采用复制算法，主要工作在 Young 区，可以通过 -XX:ParallelGCThreads 参数来控制收集的线程数，整个过程都是 STW 的，常与 CMS 组合使用。 CMS： 以获取最短回收停顿时间为目标，采用“标记-清除”算法，分 4 大步进行垃圾收集，其中初始标记和重新标记会 STW ，多数应用于互联网站或者 B&#x2F;S 系统的服务器端上，JDK9 被标记弃用，JDK14 被删除，详情可见 JEP 363。 2.5.2 分区收集器 G1： 一种服务器端的垃圾收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能地满足垃圾收集暂停时间的要求。 ZGC： JDK11 中推出的一款低延迟垃圾回收器，适用于大内存低延迟服务的内存管理和回收，SPECjbb 2015 基准测试，在 128G 的大堆下，最大停顿时间才 1.68 ms，停顿时间远胜于 G1 和 CMS。 Shenandoah： 由 Red Hat 的一个团队负责开发，与 G1 类似，基于 Region 设计的垃圾收集器，但不需要 Remember Set 或者 Card Table 来记录跨 Region 引用，停顿时间和堆的大小没有任何关系。停顿时间与 ZGC 接近，下图为与 CMS 和 G1 等收集器的 benchmark。 2.5.3 常用收集器目前使用最多的是 CMS 和 G1 收集器，二者都有分代的概念，主要内存结构如下： 2.5.4 其他收集器以上仅列出常见收集器，除此之外还有很多，如 Metronome、Stopless、Staccato、Chicken、Clover 等实时回收器，Sapphire、Compressor、Pauseless 等并发复制&#x2F;整理回收器，Doligez-Leroy-Conthier 等标记整理回收器，由于篇幅原因，不在此一一介绍。 2.6 常用工具工欲善其事，必先利其器，此处列出一些笔者常用的工具，具体情况大家可以自由选择，本文的问题都是使用这些工具来定位和分析的。 2.6.1 命令行终端 标准终端类：jps、jinfo、jstat、jstack、jmap 功能整合类：jcmd、vjtools、arthas、greys 2.6.2 可视化界面 简易：JConsole、JVisualvm、HA、GCHisto、GCViewer 进阶：MAT、JProfiler 命令行推荐 arthas ，可视化界面推荐 JProfiler，此外还有一些在线的平台 gceasy、heaphero、fastthread ，美团内部的 Scalpel（一款自研的 JVM 问题诊断工具，暂时未开源）也比较好用。 3. GC 问题判断在做 GC 问题排查和优化之前，我们需要先来明确下到底是不是 GC 直接导致的问题，或者应用代码导致的 GC 异常，最终出现问题。 3.1 判断 GC 有没有问题？3.1.1 设定评价标准评判 GC 的两个核心指标： 延迟（Latency）： 也可以理解为最大停顿时间，即垃圾收集过程中一次 STW 的最长时间，越短越好，一定程度上可以接受频次的增大，GC 技术的主要发展方向。 吞吐量（Throughput）： 应用系统的生命周期内，由于 GC 线程会占用 Mutator 当前可用的 CPU 时钟周期，吞吐量即为 Mutator 有效花费的时间占系统总运行时间的百分比，例如系统运行了 100 min，GC 耗时 1 min，则系统吞吐量为 99%，吞吐量优先的收集器可以接受较长的停顿。 目前各大互联网公司的系统基本都更追求低延时，避免一次 GC 停顿的时间过长对用户体验造成损失，衡量指标需要结合一下应用服务的 SLA，主要如下两点来判断： 简而言之，即为一次停顿的时间不超过应用服务的 TP9999，GC 的吞吐量不小于 99.99%。举个例子，假设某个服务 A 的 TP9999 为 80 ms，平均 GC 停顿为 30 ms，那么该服务的最大停顿时间最好不要超过 80 ms，GC 频次控制在 5 min 以上一次。如果满足不了，那就需要调优或者通过更多资源来进行并联冗余。（大家可以先停下来，看看监控平台上面的 gc.meantime 分钟级别指标，如果超过了 6 ms 那单机 GC 吞吐量就达不到 4 个 9 了。） 备注：除了这两个指标之外还有 Footprint（资源量大小测量）、反应速度等指标，互联网这种实时系统追求低延迟，而很多嵌入式系统则追求 Footprint。 3.1.2 读懂 GC Cause拿到 GC 日志，我们就可以简单分析 GC 情况了，通过一些工具，我们可以比较直观地看到 Cause 的分布情况，如下图就是使用 gceasy 绘制的图表： 如上图所示，我们很清晰的就能知道是什么原因引起的 GC，以及每次的时间花费情况，但是要分析 GC 的问题，先要读懂 GC Cause，即 JVM 什么样的条件下选择进行 GC 操作，具体 Cause 的分类可以看一下 Hotspot 源码：src/share/vm/gc/shared/gcCause.hpp 和 src/share/vm/gc/shared/gcCause.cpp 中。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788const char* GCCause::to_string(GCCause::Cause cause) &#123; switch (cause) &#123; case _java_lang_system_gc: return &quot;System.gc()&quot;; case _full_gc_alot: return &quot;FullGCAlot&quot;; case _scavenge_alot: return &quot;ScavengeAlot&quot;; case _allocation_profiler: return &quot;Allocation Profiler&quot;; case _jvmti_force_gc: return &quot;JvmtiEnv ForceGarbageCollection&quot;; case _gc_locker: return &quot;GCLocker Initiated GC&quot;; case _heap_inspection: return &quot;Heap Inspection Initiated GC&quot;; case _heap_dump: return &quot;Heap Dump Initiated GC&quot;; case _wb_young_gc: return &quot;WhiteBox Initiated Young GC&quot;; case _wb_conc_mark: return &quot;WhiteBox Initiated Concurrent Mark&quot;; case _wb_full_gc: return &quot;WhiteBox Initiated Full GC&quot;; case _no_gc: return &quot;No GC&quot;; case _allocation_failure: return &quot;Allocation Failure&quot;; case _tenured_generation_full: return &quot;Tenured Generation Full&quot;; case _metadata_GC_threshold: return &quot;Metadata GC Threshold&quot;; case _metadata_GC_clear_soft_refs: return &quot;Metadata GC Clear Soft References&quot;; case _cms_generation_full: return &quot;CMS Generation Full&quot;; case _cms_initial_mark: return &quot;CMS Initial Mark&quot;; case _cms_final_remark: return &quot;CMS Final Remark&quot;; case _cms_concurrent_mark: return &quot;CMS Concurrent Mark&quot;; case _old_generation_expanded_on_last_scavenge: return &quot;Old Generation Expanded On Last Scavenge&quot;; case _old_generation_too_full_to_scavenge: return &quot;Old Generation Too Full To Scavenge&quot;; case _adaptive_size_policy: return &quot;Ergonomics&quot;; case _g1_inc_collection_pause: return &quot;G1 Evacuation Pause&quot;; case _g1_humongous_allocation: return &quot;G1 Humongous Allocation&quot;; case _dcmd_gc_run: return &quot;Diagnostic Command&quot;; case _last_gc_cause: return &quot;ILLEGAL VALUE - last gc cause - ILLEGAL VALUE&quot;; default: return &quot;unknown GCCause&quot;; &#125; ShouldNotReachHere();&#125; 重点需要关注的几个GC Cause： System.gc()： 手动触发GC操作。 CMS： CMS GC 在执行过程中的一些动作，重点关注 CMS Initial Mark 和 CMS Final Remark 两个 STW 阶段。 Promotion Failure： Old 区没有足够的空间分配给 Young 区晋升的对象（即使总可用内存足够大）。 Concurrent Mode Failure： CMS GC 运行期间，Old 区预留的空间不足以分配给新的对象，此时收集器会发生退化，严重影响 GC 性能，下面的一个案例即为这种场景。 GCLocker Initiated GC： 如果线程执行在 JNI 临界区时，刚好需要进行 GC，此时 GC Locker 将会阻止 GC 的发生，同时阻止其他线程进入 JNI 临界区，直到最后一个线程退出临界区时触发一次 GC。 什么时机使用这些 Cause 触发回收，大家可以看一下 CMS 的代码，这里就不讨论了，具体在 /src/hotspot/share/gc/cms/concurrentMarkSweepGeneration.cpp 中。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586bool CMSCollector::shouldConcurrentCollect() &#123; LogTarget(Trace, gc) log; if (_full_gc_requested) &#123; log.print(&quot;CMSCollector: collect because of explicit gc request (or GCLocker)&quot;); return true; &#125; FreelistLocker x(this); // ------------------------------------------------------------------ // Print out lots of information which affects the initiation of // a collection. if (log.is_enabled() &amp;&amp; stats().valid()) &#123; log.print(&quot;CMSCollector shouldConcurrentCollect: &quot;); LogStream out(log); stats().print_on(&amp;out); log.print(&quot;time_until_cms_gen_full %3.7f&quot;, stats().time_until_cms_gen_full()); log.print(&quot;free=&quot; SIZE_FORMAT, _cmsGen-&gt;free()); log.print(&quot;contiguous_available=&quot; SIZE_FORMAT, _cmsGen-&gt;contiguous_available()); log.print(&quot;promotion_rate=%g&quot;, stats().promotion_rate()); log.print(&quot;cms_allocation_rate=%g&quot;, stats().cms_allocation_rate()); log.print(&quot;occupancy=%3.7f&quot;, _cmsGen-&gt;occupancy()); log.print(&quot;initiatingOccupancy=%3.7f&quot;, _cmsGen-&gt;initiating_occupancy()); log.print(&quot;cms_time_since_begin=%3.7f&quot;, stats().cms_time_since_begin()); log.print(&quot;cms_time_since_end=%3.7f&quot;, stats().cms_time_since_end()); log.print(&quot;metadata initialized %d&quot;, MetaspaceGC::should_concurrent_collect()); &#125; // ------------------------------------------------------------------ // If the estimated time to complete a cms collection (cms_duration()) // is less than the estimated time remaining until the cms generation // is full, start a collection. if (!UseCMSInitiatingOccupancyOnly) &#123; if (stats().valid()) &#123; if (stats().time_until_cms_start() == 0.0) &#123; return true; &#125; &#125; else &#123; if (_cmsGen-&gt;occupancy() &gt;= _bootstrap_occupancy) &#123; log.print(&quot; CMSCollector: collect for bootstrapping statistics: occupancy = %f, boot occupancy = %f&quot;, _cmsGen-&gt;occupancy(), _bootstrap_occupancy); return true; &#125; &#125; &#125; if (_cmsGen-&gt;should_concurrent_collect()) &#123; log.print(&quot;CMS old gen initiated&quot;); return true; &#125; CMSHeap* heap = CMSHeap::heap(); if (heap-&gt;incremental_collection_will_fail(true /* consult_young */)) &#123; log.print(&quot;CMSCollector: collect because incremental collection will fail &quot;); return true; &#125; if (MetaspaceGC::should_concurrent_collect()) &#123; log.print(&quot;CMSCollector: collect for metadata allocation &quot;); return true; &#125; // CMSTriggerInterval starts a CMS cycle if enough time has passed. if (CMSTriggerInterval &gt;= 0) &#123; if (CMSTriggerInterval == 0) &#123; // Trigger always return true; &#125; // Check the CMS time since begin (we do not check the stats validity // as we want to be able to trigger the first CMS cycle as well) if (stats().cms_time_since_begin() &gt;= (CMSTriggerInterval / ((double) MILLIUNITS))) &#123; if (stats().valid()) &#123; log.print(&quot;CMSCollector: collect because of trigger interval (time since last begin %3.7f secs)&quot;, stats().cms_time_since_begin()); &#125; else &#123; log.print(&quot;CMSCollector: collect because of trigger interval (first collection)&quot;); &#125; return true; &#125; &#125; return false;&#125; 3.2 判断是不是 GC 引发的问题？到底是结果（现象）还是原因，在一次 GC 问题处理的过程中，如何判断是 GC 导致的故障，还是系统本身引发 GC 问题。这里继续拿在本文开头提到的一个 Case：“GC 耗时增大、线程 Block 增多、慢查询增多、CPU 负载高等四个表象，如何判断哪个是根因？”，笔者这里根据自己的经验大致整理了四种判断方法供参考： 时序分析： 先发生的事件是根因的概率更大，通过监控手段分析各个指标的异常时间点，还原事件时间线，如先观察到 CPU 负载高（要有足够的时间 Gap），那么整个问题影响链就可能是：CPU 负载高 -&gt; 慢查询增多 -&gt; GC 耗时增大 -&gt; 线程Block增多 -&gt; RT 上涨。 概率分析： 使用统计概率学，结合历史问题的经验进行推断，由近到远按类型分析，如过往慢查的问题比较多，那么整个问题影响链就可能是：慢查询增多 -&gt; GC 耗时增大 -&gt; CPU 负载高 -&gt; 线程 Block 增多 -&gt; RT上涨。 实验分析： 通过故障演练等方式对问题现场进行模拟，触发其中部分条件（一个或多个），观察是否会发生问题，如只触发线程 Block 就会发生问题，那么整个问题影响链就可能是：线程Block增多 -&gt; CPU 负载高 -&gt; 慢查询增多 -&gt; GC 耗时增大 -&gt; RT 上涨。 反证分析： 对其中某一表象进行反证分析，即判断表象的发不发生跟结果是否有相关性，例如我们从整个集群的角度观察到某些节点慢查和 CPU 都正常，但也出了问题，那么整个问题影响链就可能是：GC 耗时增大 -&gt; 线程 Block 增多 -&gt; RT 上涨。 不同的根因，后续的分析方法是完全不同的。如果是 CPU 负载高那可能需要用火焰图看下热点、如果是慢查询增多那可能需要看下 DB 情况、如果是线程 Block 引起那可能需要看下锁竞争的情况，最后如果各个表象证明都没有问题，那可能 GC 确实存在问题，可以继续分析 GC 问题了。 3.3 问题分类导读3.3.1 Mutator 类型Mutator 的类型根据对象存活时间比例图来看主要分为两种，在弱分代假说中也提到类似的说法，如下图所示 “Survival Time” 表示对象存活时间，“Rate” 表示对象分配比例： IO 交互型： 互联网上目前大部分的服务都属于该类型，例如分布式 RPC、MQ、HTTP 网关服务等，对内存要求并不大，大部分对象在 TP9999 的时间内都会死亡， Young 区越大越好。 MEM 计算型： 主要是分布式数据计算 Hadoop，分布式存储 HBase、Cassandra，自建的分布式缓存等，对内存要求高，对象存活时间长，Old 区越大越好。 当然，除了二者之外还有介于两者之间的场景，本篇文章主要讨论第一种情况。对象 Survival Time 分布图，对我们设置 GC 参数有着非常重要的指导意义，如下图就可以简单推算分代的边界。 3.3.2 GC 问题分类笔者选取了九种不同类型的 GC 问题，覆盖了大部分场景，如果有更好的场景，欢迎在评论区给出。 Unexpected GC： 意外发生的 GC，实际上不需要发生，我们可以通过一些手段去避免。 Space Shock： 空间震荡问题，参见“场景一：动态扩容引起的空间震荡”。 Explicit GC： 显示执行 GC 问题，参见“场景二：显式 GC 的去与留”。 Partial GC： 部分收集操作的 GC，只对某些分代&#x2F;分区进行回收。 Young GC 1234567 ： 分代收集里面的 Young 区收集动作，也可以叫做 Minor GC。 - `ParNew`： Young GC 频繁，参见“场景四：过早晋升”。- ``` Old GC ： 分代收集里面的 Old 区收集动作，也可以叫做 Major GC，有些也会叫做 Full GC，但其实这种叫法是不规范的，在 CMS 发生 Foreground GC 时才是 Full GC，CMSScavengeBeforeRemark 参数也只是在 Remark 前触发一次Young GC。 - CMS： Old GC 频繁，参见“场景五：CMS Old GC 频繁”。 - CMS： Old GC 不频繁但单次耗时大，参见“场景六：单次 CMS Old GC 耗时长”。 Full GC： 全量收集的 GC，对整个堆进行回收，STW 时间会比较长，一旦发生，影响较大，也可以叫做 Major GC，参见“场景七：内存碎片&amp;收集器退化”。 MetaSpace： 元空间回收引发问题，参见“场景三：MetaSpace 区 OOM”。 Direct Memory： 直接内存（也可以称作为堆外内存）回收引发问题，参见“场景八：堆外内存 OOM”。 JNI： 本地 Native 方法引发问题，参见“场景九：JNI 引发的 GC 问题”。 3.3.3 排查难度一个问题的解决难度跟它的常见程度成反比，大部分我们都可以通过各种搜索引擎找到类似的问题，然后用同样的手段尝试去解决。当一个问题在各种网站上都找不到相似的问题时，那么可能会有两种情况，一种这不是一个问题，另一种就是遇到一个隐藏比较深的问题，遇到这种问题可能就要深入到源码级别去调试了。以下 GC 问题场景，排查难度从上到下依次递增。 4. 常见场景分析与解决4.1 场景一：动态扩容引起的空间震荡4.1.1 现象服务刚刚启动时 GC 次数较多，最大空间剩余很多但是依然发生 GC，这种情况我们可以通过观察 GC 日志或者通过监控工具来观察堆的空间变化情况即可。GC Cause 一般为 Allocation Failure，且在 GC 日志中会观察到经历一次 GC ，堆内各个空间的大小会被调整，如下图所示： 4.1.2 原因在 JVM 的参数中 -Xms 和 -Xmx 设置的不一致，在初始化时只会初始 -Xms 大小的空间存储信息，每当空间不够用时再向操作系统申请，这样的话必然要进行一次 GC。具体是通过 ConcurrentMarkSweepGeneration::compute_new_size() 方法计算新的空间大小： 123456789101112131415161718192021void ConcurrentMarkSweepGeneration::compute_new_size() &#123; assert_locked_or_safepoint(Heap_lock); // If incremental collection failed, we just want to expand // to the limit. if (incremental_collection_failed()) &#123; clear_incremental_collection_failed(); grow_to_reserved(); return; &#125; // The heap has been compacted but not reset yet. // Any metric such as free() or used() will be incorrect. CardGeneration::compute_new_size(); // Reset again after a possible resizing if (did_compact()) &#123; cmsSpace()-&gt;reset_after_compaction(); &#125;&#125; 另外，如果空间剩余很多时也会进行缩容操作，JVM 通过 -XX:MinHeapFreeRatio 和 -XX:MaxHeapFreeRatio 来控制扩容和缩容的比例，调节这两个值也可以控制伸缩的时机，例如扩容便是使用 GenCollectedHeap::expand_heap_and_allocate() 来完成的，代码如下： 12345678910111213HeapWord* GenCollectedHeap::expand_heap_and_allocate(size_t size, bool is_tlab) &#123; HeapWord* result = NULL; if (_old_gen-&gt;should_allocate(size, is_tlab)) &#123; result = _old_gen-&gt;expand_and_allocate(size, is_tlab); &#125; if (result == NULL) &#123; if (_young_gen-&gt;should_allocate(size, is_tlab)) &#123; result = _young_gen-&gt;expand_and_allocate(size, is_tlab); &#125; &#125; assert(result == NULL || is_in_reserved(result), &quot;result not in heap&quot;); return result;&#125; 整个伸缩的模型理解可以看这个图，当 committed 的空间大小超过了低水位&#x2F;高水位的大小，capacity 也会随之调整： 4.1.3 策略定位：观察 CMS GC 触发时间点 Old/MetaSpace 区的 committed 占比是不是一个固定的值，或者像上文提到的观察总的内存使用率也可以。 解决：尽量将成对出现的空间大小配置参数设置成固定的，如 -Xms 和 -Xmx，-XX:MaxNewSize 和 -XX:NewSize，-XX:MetaSpaceSize 和 -XX:MaxMetaSpaceSize 等。 4.1.4 小结一般来说，我们需要保证 Java 虚拟机的堆是稳定的，确保 -Xms 和 -Xmx 设置的是一个值（即初始值和最大值一致），获得一个稳定的堆，同理在 MetaSpace 区也有类似的问题。不过在不追求停顿时间的情况下震荡的空间也是有利的，可以动态地伸缩以节省空间，例如作为富客户端的 Java 应用。 这个问题虽然初级，但是发生的概率还真不小，尤其是在一些规范不太健全的情况下。 4.2 场景二：显式 GC 的去与留4.2.1 现象除了扩容缩容会触发 CMS GC 之外，还有 Old 区达到回收阈值、MetaSpace 空间不足、Young 区晋升失败、大对象担保失败等几种触发条件，如果这些情况都没有发生却触发了 GC ？这种情况有可能是代码中手动调用了 System.gc 方法，此时可以找到 GC 日志中的 GC Cause 确认下。那么这种 GC 到底有没有问题，翻看网上的一些资料，有人说可以添加 -XX:+DisableExplicitGC 参数来避免这种 GC，也有人说不能加这个参数，加了就会影响 Native Memory 的回收。先说结论，笔者这里建议保留 System.gc，那为什么要保留？我们一起来分析下。 4.2.2 原因找到 System.gc 在 Hotspot 中的源码，可以发现增加 -XX:+DisableExplicitGC 参数后，这个方法变成了一个空方法，如果没有加的话便会调用 Universe::heap()::collect 方法，继续跟进到这个方法中，发现 System.gc 会引发一次 STW 的 Full GC，对整个堆做收集。 12345678910111213141516171819202122232425JVM_ENTRY_NO_ENV(void, JVM_GC(void)) JVMWrapper(&quot;JVM_GC&quot;); if (!DisableExplicitGC) &#123; Universe::heap()-&gt;collect(GCCause::_java_lang_system_gc); &#125;JVM_ENDvoid GenCollectedHeap::collect(GCCause::Cause cause) &#123; if (cause == GCCause::_wb_young_gc) &#123; // Young collection for the WhiteBox API. collect(cause, YoungGen); &#125; else &#123;#ifdef ASSERT if (cause == GCCause::_scavenge_alot) &#123; // Young collection only. collect(cause, YoungGen); &#125; else &#123; // Stop-the-world full collection. collect(cause, OldGen); &#125;#else // Stop-the-world full collection. collect(cause, OldGen);#endif &#125;&#125; 保留 System.gc 此处补充一个知识点，CMS GC 共分为 Background 和 Foreground 两种模式，前者就是我们常规理解中的并发收集，可以不影响正常的业务线程运行，但 Foreground Collector 却有很大的差异，他会进行一次压缩式 GC。此压缩式 GC 使用的是跟 Serial Old GC 一样的 Lisp2 算法，其使用 Mark-Compact 来做 Full GC，一般称之为 MSC（Mark-Sweep-Compact），它收集的范围是 Java 堆的 Young 区和 Old 区以及 MetaSpace。由上面的算法章节中我们知道 compact 的代价是巨大的，那么使用 Foreground Collector 时将会带来非常长的 STW。如果在应用程序中 System.gc 被频繁调用，那就非常危险了。 去掉 System.gc 如果禁用掉的话就会带来另外一个内存泄漏问题，此时就需要说一下 DirectByteBuffer，它有着零拷贝等特点，被 Netty 等各种 NIO 框架使用，会使用到堆外内存。堆内存由 JVM 自己管理，堆外内存必须要手动释放，DirectByteBuffer 没有 Finalizer，它的 Native Memory 的清理工作是通过 sun.misc.Cleaner 自动完成的，是一种基于 PhantomReference 的清理工具，比普通的 Finalizer 轻量些。 为 DirectByteBuffer 分配空间过程中会显式调用 System.gc ，希望通过 Full GC 来强迫已经无用的 DirectByteBuffer 对象释放掉它们关联的 Native Memory，下面为代码实现： 123456789101112131415161718192021222324252627282930// These methods should be called whenever direct memory is allocated or// freed. They allow the user to control the amount of direct memory// which a process may access. All sizes are specified in bytes.static void reserveMemory(long size) &#123; synchronized (Bits.class) &#123; if (!memoryLimitSet &amp;&amp; VM.isBooted()) &#123; maxMemory = VM.maxDirectMemory(); memoryLimitSet = true; &#125; if (size &lt;= maxMemory - reservedMemory) &#123; reservedMemory += size; return; &#125; &#125; System.gc(); try &#123; Thread.sleep(100); &#125; catch (InterruptedException x) &#123; // Restore interrupt status Thread.currentThread().interrupt(); &#125; synchronized (Bits.class) &#123; if (reservedMemory + size &gt; maxMemory) throw new OutOfMemoryError(&quot;Direct buffer memory&quot;); reservedMemory += size; &#125;&#125; HotSpot VM 只会在 Old GC 的时候才会对 Old 中的对象做 Reference Processing，而在 Young GC 时只会对 Young 里的对象做 Reference Processing。Young 中的 DirectByteBuffer 对象会在 Young GC 时被处理，也就是说，做 CMS GC 的话会对 Old 做 Reference Processing，进而能触发 Cleaner 对已死的 DirectByteBuffer 对象做清理工作。但如果很长一段时间里没做过 GC 或者只做了 Young GC 的话则不会在 Old 触发 Cleaner 的工作，那么就可能让本来已经死亡，但已经晋升到 Old 的 DirectByteBuffer 关联的 Native Memory 得不到及时释放。这几个实现特征使得依赖于 System.gc 触发 GC 来保证 DirectByteMemory 的清理工作能及时完成。如果打开了 -XX:+DisableExplicitGC，清理工作就可能得不到及时完成，于是就有发生 Direct Memory 的 OOM。 4.2.3 策略通过上面的分析看到，无论是保留还是去掉都会有一定的风险点，不过目前互联网中的 RPC 通信会大量使用 NIO，所以笔者在这里建议保留。此外 JVM 还提供了 -XX:+ExplicitGCInvokesConcurrent 和 -XX:+ExplicitGCInvokesConcurrentAndUnloadsClasses 参数来将 System.gc 的触发类型从 Foreground 改为 Background，同时 Background 也会做 Reference Processing，这样的话就能大幅降低了 STW 开销，同时也不会发生 NIO Direct Memory OOM。 4.2.4 小结不止 CMS，在 G1 或 ZGC中开启 ExplicitGCInvokesConcurrent 模式，都会采用高性能的并发收集方式进行收集，不过还是建议在代码规范方面也要做好约束，规范好 System.gc 的使用。 P.S. HotSpot 对 System.gc 有特别处理，最主要的地方体现在一次 System.gc 是否与普通 GC 一样会触发 GC 的统计&#x2F;阈值数据的更新，HotSpot 里的许多 GC 算法都带有自适应的功能，会根据先前收集的效率来决定接下来的 GC 中使用的参数，但 System.gc 默认不更新这些统计数据，避免用户强行 GC 对这些自适应功能的干扰（可以参考 -XX:+UseAdaptiveSizePolicyWithSystemGC 参数，默认是 false）。 4.3 场景三：MetaSpace 区 OOM4.3.1 现象JVM 在启动后或者某个时间点开始，MetaSpace 的已使用大小在持续增长，同时每次 GC 也无法释放，调大 MetaSpace 空间也无法彻底解决。 4.3.2 原因在讨论为什么会 OOM 之前，我们先来看一下这个区里面会存什么数据，Java7 之前字符串常量池被放到了 Perm 区，所有被 intern 的 String 都会被存在这里，由于 String.intern 是不受控的，所以 -XX:MaxPermSize 的值也不太好设置，经常会出现 java.lang.OutOfMemoryError: PermGen space 异常，所以在 Java7 之后常量池等字面量（Literal）、类静态变量（Class Static）、符号引用（Symbols Reference）等几项被移到 Heap 中。而 Java8 之后 PermGen 也被移除，取而代之的是 MetaSpace。 在最底层，JVM 通过 mmap 接口向操作系统申请内存映射，每次申请 2MB 空间，这里是虚拟内存映射，不是真的就消耗了主存的 2MB，只有之后在使用的时候才会真的消耗内存。申请的这些内存放到一个链表中 VirtualSpaceList，作为其中的一个 Node。 在上层，MetaSpace 主要由 Klass Metaspace 和 NoKlass Metaspace 两大部分组成。 Klass MetaSpace： 就是用来存 Klass 的，就是 Class 文件在 JVM 里的运行时数据结构，这部分默认放在 Compressed Class Pointer Space 中，是一块连续的内存区域，紧接着 Heap。Compressed Class Pointer Space 不是必须有的，如果设置了 -XX:-UseCompressedClassPointers，或者 -Xmx 设置大于 32 G，就不会有这块内存，这种情况下 Klass 都会存在 NoKlass Metaspace 里。 NoKlass MetaSpace： 专门来存 Klass 相关的其他的内容，比如 Method，ConstantPool 等，可以由多块不连续的内存组成。虽然叫做 NoKlass Metaspace，但是也其实可以存 Klass 的内容，上面已经提到了对应场景。 具体的定义都可以在源码 shared/vm/memory/metaspace.hpp 中找到： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051class Metaspace : public AllStatic &#123; friend class MetaspaceShared; public: enum MetadataType &#123; ClassType, NonClassType, MetadataTypeCount &#125;; enum MetaspaceType &#123; ZeroMetaspaceType = 0, StandardMetaspaceType = ZeroMetaspaceType, BootMetaspaceType = StandardMetaspaceType + 1, AnonymousMetaspaceType = BootMetaspaceType + 1, ReflectionMetaspaceType = AnonymousMetaspaceType + 1, MetaspaceTypeCount &#125;; private: // Align up the word size to the allocation word size static size_t align_word_size_up(size_t); // Aligned size of the metaspace. static size_t _compressed_class_space_size; static size_t compressed_class_space_size() &#123; return _compressed_class_space_size; &#125; static void set_compressed_class_space_size(size_t size) &#123; _compressed_class_space_size = size; &#125; static size_t _first_chunk_word_size; static size_t _first_class_chunk_word_size; static size_t _commit_alignment; static size_t _reserve_alignment; DEBUG_ONLY(static bool _frozen;) // Virtual Space lists for both classes and other metadata static metaspace::VirtualSpaceList* _space_list; static metaspace::VirtualSpaceList* _class_space_list; static metaspace::ChunkManager* _chunk_manager_metadata; static metaspace::ChunkManager* _chunk_manager_class; static const MetaspaceTracer* _tracer;&#125; MetaSpace 的对象为什么无法释放，我们看下面两点： MetaSpace 内存管理： 类和其元数据的生命周期与其对应的类加载器相同，只要类的类加载器是存活的，在 Metaspace 中的类元数据也是存活的，不能被回收。每个加载器有单独的存储空间，通过 ClassLoaderMetaspace 来进行管理 SpaceManager* 的指针，相互隔离的。 MetaSpace 弹性伸缩： 由于 MetaSpace 空间和 Heap 并不在一起，所以这块的空间可以不用设置或者单独设置，一般情况下避免 MetaSpace 耗尽 VM 内存都会设置一个 MaxMetaSpaceSize，在运行过程中，如果实际大小小于这个值，JVM 就会通过 -XX:MinMetaspaceFreeRatio 和 -XX:MaxMetaspaceFreeRatio 两个参数动态控制整个 MetaSpace 的大小，具体使用可以看 MetaSpaceGC::compute_new_size() 方法（下方代码），这个方法会在 CMSCollector 和 G1CollectorHeap 等几个收集器执行 GC 时调用。这个里面会根据 used_after_gc，MinMetaspaceFreeRatio 和 MaxMetaspaceFreeRatio 这三个值计算出来一个新的 _capacity_until_GC 值（水位线）。然后根据实际的 _capacity_until_GC 值使用 MetaspaceGC::inc_capacity_until_GC() 和 MetaspaceGC::dec_capacity_until_GC() 进行 expand 或 shrink，这个过程也可以参照场景一中的伸缩模型进行理解。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101void MetaspaceGC::compute_new_size() &#123; assert(_shrink_factor &lt;= 100, &quot;invalid shrink factor&quot;); uint current_shrink_factor = _shrink_factor; _shrink_factor = 0; const size_t used_after_gc = MetaspaceUtils::committed_bytes(); const size_t capacity_until_GC = MetaspaceGC::capacity_until_GC(); const double minimum_free_percentage = MinMetaspaceFreeRatio / 100.0; const double maximum_used_percentage = 1.0 - minimum_free_percentage; const double min_tmp = used_after_gc / maximum_used_percentage; size_t minimum_desired_capacity = (size_t)MIN2(min_tmp, double(max_uintx)); // Don&#x27;t shrink less than the initial generation size minimum_desired_capacity = MAX2(minimum_desired_capacity, MetaspaceSize); log_trace(gc, metaspace)(&quot;MetaspaceGC::compute_new_size: &quot;); log_trace(gc, metaspace)(&quot; minimum_free_percentage: %6.2f maximum_used_percentage: %6.2f&quot;, minimum_free_percentage, maximum_used_percentage); log_trace(gc, metaspace)(&quot; used_after_gc : %6.1fKB&quot;, used_after_gc / (double) K); size_t shrink_bytes = 0; if (capacity_until_GC &lt; minimum_desired_capacity) &#123; // If we have less capacity below the metaspace HWM, then // increment the HWM. size_t expand_bytes = minimum_desired_capacity - capacity_until_GC; expand_bytes = align_up(expand_bytes, Metaspace::commit_alignment()); // Don&#x27;t expand unless it&#x27;s significant if (expand_bytes &gt;= MinMetaspaceExpansion) &#123; size_t new_capacity_until_GC = 0; bool succeeded = MetaspaceGC::inc_capacity_until_GC(expand_bytes, &amp;new_capacity_until_GC); assert(succeeded, &quot;Should always succesfully increment HWM when at safepoint&quot;); Metaspace::tracer()-&gt;report_gc_threshold(capacity_until_GC, new_capacity_until_GC, MetaspaceGCThresholdUpdater::ComputeNewSize); log_trace(gc, metaspace)(&quot; expanding: minimum_desired_capacity: %6.1fKB expand_bytes: %6.1fKB MinMetaspaceExpansion: %6.1fKB new metaspace HWM: %6.1fKB&quot;, minimum_desired_capacity / (double) K, expand_bytes / (double) K, MinMetaspaceExpansion / (double) K, new_capacity_until_GC / (double) K); &#125; return; &#125; // No expansion, now see if we want to shrink // We would never want to shrink more than this assert(capacity_until_GC &gt;= minimum_desired_capacity, SIZE_FORMAT &quot; &gt;= &quot; SIZE_FORMAT, capacity_until_GC, minimum_desired_capacity); size_t max_shrink_bytes = capacity_until_GC - minimum_desired_capacity; // Should shrinking be considered? if (MaxMetaspaceFreeRatio &lt; 100) &#123; const double maximum_free_percentage = MaxMetaspaceFreeRatio / 100.0; const double minimum_used_percentage = 1.0 - maximum_free_percentage; const double max_tmp = used_after_gc / minimum_used_percentage; size_t maximum_desired_capacity = (size_t)MIN2(max_tmp, double(max_uintx)); maximum_desired_capacity = MAX2(maximum_desired_capacity, MetaspaceSize); log_trace(gc, metaspace)(&quot; maximum_free_percentage: %6.2f minimum_used_percentage: %6.2f&quot;, maximum_free_percentage, minimum_used_percentage); log_trace(gc, metaspace)(&quot; minimum_desired_capacity: %6.1fKB maximum_desired_capacity: %6.1fKB&quot;, minimum_desired_capacity / (double) K, maximum_desired_capacity / (double) K); assert(minimum_desired_capacity &lt;= maximum_desired_capacity, &quot;sanity check&quot;); if (capacity_until_GC &gt; maximum_desired_capacity) &#123; // Capacity too large, compute shrinking size shrink_bytes = capacity_until_GC - maximum_desired_capacity; shrink_bytes = shrink_bytes / 100 * current_shrink_factor; shrink_bytes = align_down(shrink_bytes, Metaspace::commit_alignment()); assert(shrink_bytes &lt;= max_shrink_bytes, &quot;invalid shrink size &quot; SIZE_FORMAT &quot; not &lt;= &quot; SIZE_FORMAT, shrink_bytes, max_shrink_bytes); if (current_shrink_factor == 0) &#123; _shrink_factor = 10; &#125; else &#123; _shrink_factor = MIN2(current_shrink_factor * 4, (uint) 100); &#125; log_trace(gc, metaspace)(&quot; shrinking: initThreshold: %.1fK maximum_desired_capacity: %.1fK&quot;, MetaspaceSize / (double) K, maximum_desired_capacity / (double) K); log_trace(gc, metaspace)(&quot; shrink_bytes: %.1fK current_shrink_factor: %d new shrink factor: %d MinMetaspaceExpansion: %.1fK&quot;, shrink_bytes / (double) K, current_shrink_factor, _shrink_factor, MinMetaspaceExpansion / (double) K); &#125; &#125; // Don&#x27;t shrink unless it&#x27;s significant if (shrink_bytes &gt;= MinMetaspaceExpansion &amp;&amp; ((capacity_until_GC - shrink_bytes) &gt;= MetaspaceSize)) &#123; size_t new_capacity_until_GC = MetaspaceGC::dec_capacity_until_GC(shrink_bytes); Metaspace::tracer()-&gt;report_gc_threshold(capacity_until_GC, new_capacity_until_GC, MetaspaceGCThresholdUpdater::ComputeNewSize); &#125;&#125; 由场景一可知，为了避免弹性伸缩带来的额外 GC 消耗，我们会将 -XX:MetaSpaceSize 和 -XX:MaxMetaSpaceSize 两个值设置为固定的，但是这样也会导致在空间不够的时候无法扩容，然后频繁地触发 GC，最终 OOM。所以关键原因就是 ClassLoader 不停地在内存中 load 了新的 Class ，一般这种问题都发生在动态类加载等情况上。 4.3.3 策略了解大概什么原因后，如何定位和解决就很简单了，可以 dump 快照之后通过 JProfiler 或 MAT 观察 Classes 的 Histogram（直方图） 即可，或者直接通过命令即可定位， jcmd 打几次 Histogram 的图，看一下具体是哪个包下的 Class 增加较多就可以定位了。不过有时候也要结合InstBytes、KlassBytes、Bytecodes、MethodAll 等几项指标综合来看下。如下图便是笔者使用 jcmd 排查到一个 Orika 的问题。 1jcmd &lt;PID&gt; GC.class_stats|awk &#x27;&#123;print$13&#125;&#x27;|sed &#x27;s/\\(.*\\)\\.\\(.*\\)/\\1/g&#x27;|sort |uniq -c|sort -nrk1 如果无法从整体的角度定位，可以添加 -XX:+TraceClassLoading 和 -XX:+TraceClassUnLoading 参数观察详细的类加载和卸载信息。 4.3.4 小结原理理解比较复杂，但定位和解决问题会比较简单，经常会出问题的几个点有 Orika 的 classMap、JSON 的 ASMSerializer、Groovy 动态加载类等，基本都集中在反射、Javasisit 字节码增强、CGLIB 动态代理、OSGi 自定义类加载器等的技术点上。另外就是及时给 MetaSpace 区的使用率加一个监控，如果指标有波动提前发现并解决问题。 4.4 场景四：过早晋升4.4.1 现象这种场景主要发生在分代的收集器上面，专业的术语称为“Premature Promotion”。90% 的对象朝生夕死，只有在 Young 区经历过几次 GC 的洗礼后才会晋升到 Old 区，每经历一次 GC 对象的 GC Age 就会增长 1，最大通过 -XX:MaxTenuringThreshold 来控制。 过早晋升一般不会直接影响 GC，总会伴随着浮动垃圾、大对象担保失败等问题，但这些问题不是立刻发生的，我们可以观察以下几种现象来判断是否发生了过早晋升。 分配速率接近于晋升速率，对象晋升年龄较小。 GC 日志中出现“Desired survivor size 107347968 bytes, new threshold 1(max 6)”等信息，说明此时经历过一次 GC 就会放到 Old 区。 Full GC 比较频繁，且经历过一次 GC 之后 Old 区的变化比例非常大。 比如说 Old 区触发的回收阈值是 80%，经历过一次 GC 之后下降到了 10%，这就说明 Old 区的 70% 的对象存活时间其实很短，如下图所示，Old 区大小每次 GC 后从 2.1G 回收到 300M，也就是说回收掉了 1.8G 的垃圾，只有 300M 的活跃对象。整个 Heap 目前是 4G，活跃对象只占了不到十分之一。 过早晋升的危害： Young GC 频繁，总的吞吐量下降。 Full GC 频繁，可能会有较大停顿。 4.4.2 原因主要的原因有以下两点： Young&#x2F;Eden 区过小： 过小的直接后果就是 Eden 被装满的时间变短，本应该回收的对象参与了 GC 并晋升，Young GC 采用的是复制算法，由基础篇我们知道 copying 耗时远大于 mark，也就是 Young GC 耗时本质上就是 copy 的时间（CMS 扫描 Card Table 或 G1 扫描 Remember Set 出问题的情况另说），没来及回收的对象增大了回收的代价，所以 Young GC 时间增加，同时又无法快速释放空间，Young GC 次数也跟着增加。 分配速率过大： 可以观察出问题前后 Mutator 的分配速率，如果有明显波动可以尝试观察网卡流量、存储类中间件慢查询日志等信息，看是否有大量数据被加载到内存中。 同时无法 GC 掉对象还会带来另外一个问题，引发动态年龄计算：JVM 通过 -XX:MaxTenuringThreshold 参数来控制晋升年龄，每经过一次 GC，年龄就会加一，达到最大年龄就可以进入 Old 区，最大值为 15（因为 JVM 中使用 4 个比特来表示对象的年龄）。设定固定的 MaxTenuringThreshold 值作为晋升条件： MaxTenuringThreshold 如果设置得过大，原本应该晋升的对象一直停留在 Survivor 区，直到 Survivor 区溢出，一旦溢出发生，Eden + Survivor 中对象将不再依据年龄全部提升到 Old 区，这样对象老化的机制就失效了。 MaxTenuringThreshold 如果设置得过小，过早晋升即对象不能在 Young 区充分被回收，大量短期对象被晋升到 Old 区，Old 区空间迅速增长，引起频繁的 Major GC，分代回收失去了意义，严重影响 GC 性能。 相同应用在不同时间的表现不同，特殊任务的执行或者流量成分的变化，都会导致对象的生命周期分布发生波动，那么固定的阈值设定，因为无法动态适应变化，会造成和上面问题，所以 Hotspot 会使用动态计算的方式来调整晋升的阈值。 具体动态计算可以看一下 Hotspot 源码，具体在 /src/hotspot/share/gc/shared/ageTable.cpp 的 compute_tenuring_threshold方法中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950uint ageTable::compute_tenuring_threshold(size_t survivor_capacity) &#123; //TargetSurvivorRatio默认50，意思是：在回收之后希望survivor区的占用率达到这个比例 size_t desired_survivor_size = (size_t)((((double) survivor_capacity)*TargetSurvivorRatio)/100); size_t total = 0; uint age = 1; assert(sizes[0] == 0, &quot;no objects with age zero should be recorded&quot;); while (age &lt; table_size) &#123;//table_size=16 total += sizes[age]; //如果加上这个年龄的所有对象的大小之后，占用量&gt;期望的大小，就设置age为新的晋升阈值 if (total &gt; desired_survivor_size) break; age++; &#125; uint result = age &lt; MaxTenuringThreshold ? age : MaxTenuringThreshold; if (PrintTenuringDistribution || UsePerfData) &#123; //打印期望的survivor的大小以及新计算出来的阈值，和设置的最大阈值 if (PrintTenuringDistribution) &#123; gclog_or_tty-&gt;cr(); gclog_or_tty-&gt;print_cr(&quot;Desired survivor size &quot; SIZE_FORMAT &quot; bytes, new threshold %u (max %u)&quot;, desired_survivor_size*oopSize, result, (int) MaxTenuringThreshold); &#125; total = 0; age = 1; while (age &lt; table_size) &#123; total += sizes[age]; if (sizes[age] &gt; 0) &#123; if (PrintTenuringDistribution) &#123; gclog_or_tty-&gt;print_cr(&quot;- age %3u: &quot; SIZE_FORMAT_W(10) &quot; bytes, &quot; SIZE_FORMAT_W(10) &quot; total&quot;, age, sizes[age]*oopSize, total*oopSize); &#125; &#125; if (UsePerfData) &#123; _perf_sizes[age]-&gt;set_value(sizes[age]*oopSize); &#125; age++; &#125; if (UsePerfData) &#123; SharedHeap* sh = SharedHeap::heap(); CollectorPolicy* policy = sh-&gt;collector_policy(); GCPolicyCounters* gc_counters = policy-&gt;counters(); gc_counters-&gt;tenuring_threshold()-&gt;set_value(result); gc_counters-&gt;desired_survivor_size()-&gt;set_value( desired_survivor_size*oopSize); &#125; &#125; return result;&#125; 可以看到 Hotspot 遍历所有对象时，从所有年龄为 0 的对象占用的空间开始累加，如果加上年龄等于 n 的所有对象的空间之后，使用 Survivor 区的条件值（TargetSurvivorRatio &#x2F; 100，TargetSurvivorRatio 默认值为 50）进行判断，若大于这个值则结束循环，将 n 和 MaxTenuringThreshold 比较，若 n 小，则阈值为 n，若 n 大，则只能去设置最大阈值为 MaxTenuringThreshold。动态年龄触发后导致更多的对象进入了 Old 区，造成资源浪费。 4.4.3 策略知道问题原因后我们就有解决的方向，如果是 Young&#x2F;Eden 区过小，我们可以在总的 Heap 内存不变的情况下适当增大 Young 区，具体怎么增加？一般情况下 Old 的大小应当为活跃对象的 2~3 倍左右，考虑到浮动垃圾问题最好在 3 倍左右，剩下的都可以分给 Young 区。 拿笔者的一次典型过早晋升优化来看，原配置为 Young 1.2G + Old 2.8G，通过观察 CMS GC 的情况找到存活对象大概为 300~400M，于是调整 Old 1.5G 左右，剩下 2.5G 分给 Young 区。仅仅调了一个 Young 区大小参数（-Xmn），整个 JVM 一分钟 Young GC 从 26 次降低到了 11 次，单次时间也没有增加，总的 GC 时间从 1100ms 降低到了 500ms，CMS GC 次数也从 40 分钟左右一次降低到了 7 小时 30 分钟一次。 如果是分配速率过大： 偶发较大：通过内存分析工具找到问题代码，从业务逻辑上做一些优化。 一直较大：当前的 Collector 已经不满足 Mutator 的期望了，这种情况要么扩容 Mutator 的 VM，要么调整 GC 收集器类型或加大空间。 4.4.4 小结过早晋升问题一般不会特别明显，但日积月累之后可能会爆发一波收集器退化之类的问题，所以我们还是要提前避免掉的，可以看看自己系统里面是否有这些现象，如果比较匹配的话，可以尝试优化一下。一行代码优化的 ROI 还是很高的。 如果在观察 Old 区前后比例变化的过程中，发现可以回收的比例非常小，如从 80% 只回收到了 60%，说明我们大部分对象都是存活的，Old 区的空间可以适当调大些。 4.4.5 加餐关于在调整 Young 与 Old 的比例时，如何选取具体的 NewRatio 值，这里将问题抽象成为一个蓄水池模型，找到以下关键衡量指标，大家可以根据自己场景进行推算。 NewRatio 的值 r 与 va、vp、vyc、voc、rs 等值存在一定函数相关性（rs 越小 r 越大、r 越小 vp 越小，…，之前尝试使用 NN 来辅助建模，但目前还没有完全算出具体的公式，有想法的同学可以在评论区给出你的答案）。 总停顿时间 T 为 Young GC 总时间 Tyc 和 Old GC 总时间 Toc 之和，其中 Tyc 与 vyc 和 vp 相关，Toc 与 voc相关。 忽略掉 GC 时间后，两次 Young GC 的时间间隔要大于 TP9999 时间，这样尽量让对象在 Eden 区就被回收，可以减少很多停顿。 4.5 场景五：CMS Old GC 频繁4.5.1 现象Old 区频繁的做 CMS GC，但是每次耗时不是特别长，整体最大 STW 也在可接受范围内，但由于 GC 太频繁导致吞吐下降比较多。 4.5.2 原因这种情况比较常见，基本都是一次 Young GC 完成后，负责处理 CMS GC 的一个后台线程 concurrentMarkSweepThread 会不断地轮询，使用 shouldConcurrentCollect() 方法做一次检测，判断是否达到了回收条件。如果达到条件，使用 collect_in_background() 启动一次 Background 模式 GC。轮询的判断是使用 sleepBeforeNextCycle() 方法，间隔周期为 -XX:CMSWaitDuration 决定，默认为2s。 具体代码在： src&#x2F;hotspot&#x2F;share&#x2F;gc&#x2F;cms&#x2F;concurrentMarkSweepThread.cpp。 1234567891011121314151617181920212223242526272829303132333435void ConcurrentMarkSweepThread::run_service() &#123; assert(this == cmst(), &quot;just checking&quot;); if (BindCMSThreadToCPU &amp;&amp; !os::bind_to_processor(CPUForCMSThread)) &#123; log_warning(gc)(&quot;Couldn&#x27;t bind CMS thread to processor &quot; UINTX_FORMAT, CPUForCMSThread); &#125; while (!should_terminate()) &#123; sleepBeforeNextCycle(); if (should_terminate()) break; GCIdMark gc_id_mark; GCCause::Cause cause = _collector-&gt;_full_gc_requested ? _collector-&gt;_full_gc_cause : GCCause::_cms_concurrent_mark; _collector-&gt;collect_in_background(cause); &#125; verify_ok_to_terminate();&#125;void ConcurrentMarkSweepThread::sleepBeforeNextCycle() &#123; while (!should_terminate()) &#123; if(CMSWaitDuration &gt;= 0) &#123; // Wait until the next synchronous GC, a concurrent full gc // request or a timeout, whichever is earlier. wait_on_cms_lock_for_scavenge(CMSWaitDuration); &#125; else &#123; // Wait until any cms_lock event or check interval not to call shouldConcurrentCollect permanently wait_on_cms_lock(CMSCheckInterval); &#125; // Check if we should start a CMS collection cycle if (_collector-&gt;shouldConcurrentCollect()) &#123; return; &#125; // .. collection criterion not yet met, let&#x27;s go back // and wait some more &#125;&#125; 判断是否进行回收的代码在：&#x2F;src&#x2F;hotspot&#x2F;share&#x2F;gc&#x2F;cms&#x2F;concurrentMarkSweepGeneration.cpp。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586bool CMSCollector::shouldConcurrentCollect() &#123; LogTarget(Trace, gc) log; if (_full_gc_requested) &#123; log.print(&quot;CMSCollector: collect because of explicit gc request (or GCLocker)&quot;); return true; &#125; FreelistLocker x(this); // ------------------------------------------------------------------ // Print out lots of information which affects the initiation of // a collection. if (log.is_enabled() &amp;&amp; stats().valid()) &#123; log.print(&quot;CMSCollector shouldConcurrentCollect: &quot;); LogStream out(log); stats().print_on(&amp;out); log.print(&quot;time_until_cms_gen_full %3.7f&quot;, stats().time_until_cms_gen_full()); log.print(&quot;free=&quot; SIZE_FORMAT, _cmsGen-&gt;free()); log.print(&quot;contiguous_available=&quot; SIZE_FORMAT, _cmsGen-&gt;contiguous_available()); log.print(&quot;promotion_rate=%g&quot;, stats().promotion_rate()); log.print(&quot;cms_allocation_rate=%g&quot;, stats().cms_allocation_rate()); log.print(&quot;occupancy=%3.7f&quot;, _cmsGen-&gt;occupancy()); log.print(&quot;initiatingOccupancy=%3.7f&quot;, _cmsGen-&gt;initiating_occupancy()); log.print(&quot;cms_time_since_begin=%3.7f&quot;, stats().cms_time_since_begin()); log.print(&quot;cms_time_since_end=%3.7f&quot;, stats().cms_time_since_end()); log.print(&quot;metadata initialized %d&quot;, MetaspaceGC::should_concurrent_collect()); &#125; // ------------------------------------------------------------------ if (!UseCMSInitiatingOccupancyOnly) &#123; if (stats().valid()) &#123; if (stats().time_until_cms_start() == 0.0) &#123; return true; &#125; &#125; else &#123; if (_cmsGen-&gt;occupancy() &gt;= _bootstrap_occupancy) &#123; log.print(&quot; CMSCollector: collect for bootstrapping statistics: occupancy = %f, boot occupancy = %f&quot;, _cmsGen-&gt;occupancy(), _bootstrap_occupancy); return true; &#125; &#125; &#125; if (_cmsGen-&gt;should_concurrent_collect()) &#123; log.print(&quot;CMS old gen initiated&quot;); return true; &#125; // We start a collection if we believe an incremental collection may fail; // this is not likely to be productive in practice because it&#x27;s probably too // late anyway. CMSHeap* heap = CMSHeap::heap(); if (heap-&gt;incremental_collection_will_fail(true /* consult_young */)) &#123; log.print(&quot;CMSCollector: collect because incremental collection will fail &quot;); return true; &#125; if (MetaspaceGC::should_concurrent_collect()) &#123; log.print(&quot;CMSCollector: collect for metadata allocation &quot;); return true; &#125; // CMSTriggerInterval starts a CMS cycle if enough time has passed. if (CMSTriggerInterval &gt;= 0) &#123; if (CMSTriggerInterval == 0) &#123; // Trigger always return true; &#125; // Check the CMS time since begin (we do not check the stats validity // as we want to be able to trigger the first CMS cycle as well) if (stats().cms_time_since_begin() &gt;= (CMSTriggerInterval / ((double) MILLIUNITS))) &#123; if (stats().valid()) &#123; log.print(&quot;CMSCollector: collect because of trigger interval (time since last begin %3.7f secs)&quot;, stats().cms_time_since_begin()); &#125; else &#123; log.print(&quot;CMSCollector: collect because of trigger interval (first collection)&quot;); &#125; return true; &#125; &#125; return false;&#125; 分析其中逻辑判断是否触发 GC，分为以下几种情况： 触发 CMS GC： 通过调用 _collector-&gt;collect_in_background() 进行触发 Background GC 。 CMS 默认采用 JVM 运行时的统计数据判断是否需要触发 CMS GC，如果需要根据 -XX:CMSInitiatingOccupancyFraction 的值进行判断，需要设置参数 -XX:+UseCMSInitiatingOccupancyOnly。 如果开启了 -XX:UseCMSInitiatingOccupancyOnly 参数，判断当前 Old 区使用率是否大于阈值，则触发 CMS GC，该阈值可以通过参数 -XX:CMSInitiatingOccupancyFraction 进行设置，如果没有设置，默认为 92%。 如果之前的 Young GC 失败过，或者下次 Young 区执行 Young GC 可能失败，这两种情况下都需要触发 CMS GC。 CMS 默认不会对 MetaSpace 或 Perm 进行垃圾收集，如果希望对这些区域进行垃圾收集，需要设置参数 -XX:+CMSClassUnloadingEnabled。 触发 Full GC： 直接进行 Full GC，这种情况到场景七中展开说明。 如果 _full_gc_requested 为真，说明有明确的需求要进行 GC，比如调用 System.gc。 在 Eden 区为对象或 TLAB 分配内存失败，导致一次 Young GC，在 GenCollectorPolicy 类的 satisfy_failed_allocation() 方法中进行判断。 大家可以看一下源码中的日志打印，通过日志我们就可以比较清楚地知道具体的原因，然后就可以着手分析了。 4.5.3 策略我们这里还是拿最常见的达到回收比例这个场景来说，与过早晋升不同的是这些对象确实存活了一段时间，Survival Time 超过了 TP9999 时间，但是又达不到长期存活，如各种数据库、网络链接，带有失效时间的缓存等。 处理这种常规内存泄漏问题基本是一个思路，主要步骤如下： Dump Diff 和 Leak Suspects 比较直观就不介绍了，这里说下其它几个关键点： 内存 Dump： 使用 jmap、arthas 等 dump 堆进行快照时记得摘掉流量，同时分别在 CMS GC 的发生前后分别 dump 一次。 分析 Top Component： 要记得按照对象、类、类加载器、包等多个维度观察 Histogram，同时使用 outgoing 和 incoming 分析关联的对象，另外就是 Soft Reference 和 Weak Reference、Finalizer 等也要看一下。 分析 Unreachable： 重点看一下这个，关注下 Shallow 和 Retained 的大小。如下图所示，笔者之前一次 GC 优化，就根据 Unreachable Objects 发现了 Hystrix 的滑动窗口问题。 4.5.4 小结经过整个流程下来基本就能定位问题了，不过在优化的过程中记得使用控制变量的方法来优化，防止一些会加剧问题的改动被掩盖。 4.6 场景六：单次 CMS Old GC 耗时长4.6.1 现象CMS GC 单次 STW 最大超过 1000ms，不会频繁发生，如下图所示最长达到了 8000ms。某些场景下会引起“雪崩效应”，这种场景非常危险，我们应该尽量避免出现。 4.6.2 原因CMS 在回收的过程中，STW 的阶段主要是 Init Mark 和 Final Remark 这两个阶段，也是导致 CMS Old GC 最多的原因，另外有些情况就是在 STW 前等待 Mutator 的线程到达 SafePoint 也会导致时间过长，但这种情况较少，我们在此处主要讨论前者。发生收集器退化或者碎片压缩的场景请看场景七。 想要知道这两个阶段为什么会耗时，我们需要先看一下这两个阶段都会干什么。 核心代码都在 &#x2F;src&#x2F;hotspot&#x2F;share&#x2F;gc&#x2F;cms&#x2F;concurrentMarkSweepGeneration.cpp 中，内部有个线程 ConcurrentMarkSweepThread 轮询来校验，Old 区的垃圾回收相关细节被完全封装在 CMSCollector 中，调用入口就是 ConcurrentMarkSweepThread 调用的 CMSCollector::collect_in_background 和 ConcurrentMarkSweepGeneration 调用的 CMSCollector::collect 方法，此处我们讨论大多数场景的 collect_in_background。整个过程中会 STW 的主要是 initial Mark 和 Final Remark，核心代码在 VM_CMS_Initial_Mark &#x2F; VM_CMS_Final_Remark 中，执行时需要将执行权交由 VMThread 来执行。 CMS Init Mark执行步骤，实现在 CMSCollector::checkpointRootsInitialWork() 和 CMSParInitialMarkTask::work 中，整体步骤和代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130void CMSCollector::checkpointRootsInitialWork() &#123; assert(SafepointSynchronize::is_at_safepoint(), &quot;world should be stopped&quot;); assert(_collectorState == InitialMarking, &quot;just checking&quot;); // Already have locks. assert_lock_strong(bitMapLock()); assert(_markBitMap.isAllClear(), &quot;was reset at end of previous cycle&quot;); // Setup the verification and class unloading state for this // CMS collection cycle. setup_cms_unloading_and_verification_state(); GCTraceTime(Trace, gc, phases) ts(&quot;checkpointRootsInitialWork&quot;, _gc_timer_cm); // Reset all the PLAB chunk arrays if necessary. if (_survivor_plab_array != NULL &amp;&amp; !CMSPLABRecordAlways) &#123; reset_survivor_plab_arrays(); &#125; ResourceMark rm; HandleMark hm; MarkRefsIntoClosure notOlder(_span, &amp;_markBitMap); CMSHeap* heap = CMSHeap::heap(); verify_work_stacks_empty(); verify_overflow_empty(); heap-&gt;ensure_parsability(false); // fill TLABs, but no need to retire them // Update the saved marks which may affect the root scans. heap-&gt;save_marks(); // weak reference processing has not started yet. ref_processor()-&gt;set_enqueuing_is_done(false); // Need to remember all newly created CLDs, // so that we can guarantee that the remark finds them. ClassLoaderDataGraph::remember_new_clds(true); // Whenever a CLD is found, it will be claimed before proceeding to mark // the klasses. The claimed marks need to be cleared before marking starts. ClassLoaderDataGraph::clear_claimed_marks(); print_eden_and_survivor_chunk_arrays(); &#123; if (CMSParallelInitialMarkEnabled) &#123; // The parallel version. WorkGang* workers = heap-&gt;workers(); assert(workers != NULL, &quot;Need parallel worker threads.&quot;); uint n_workers = workers-&gt;active_workers(); StrongRootsScope srs(n_workers); CMSParInitialMarkTask tsk(this, &amp;srs, n_workers); initialize_sequential_subtasks_for_young_gen_rescan(n_workers); // If the total workers is greater than 1, then multiple workers // may be used at some time and the initialization has been set // such that the single threaded path cannot be used. if (workers-&gt;total_workers() &gt; 1) &#123; workers-&gt;run_task(&amp;tsk); &#125; else &#123; tsk.work(0); &#125; &#125; else &#123; // The serial version. CLDToOopClosure cld_closure(&amp;notOlder, true); heap-&gt;rem_set()-&gt;prepare_for_younger_refs_iterate(false); // Not parallel. StrongRootsScope srs(1); heap-&gt;cms_process_roots(&amp;srs, true, // young gen as roots GenCollectedHeap::ScanningOption(roots_scanning_options()), should_unload_classes(), &amp;notOlder, &amp;cld_closure); &#125; &#125; // Clear mod-union table; it will be dirtied in the prologue of // CMS generation per each young generation collection. assert(_modUnionTable.isAllClear(), &quot;Was cleared in most recent final checkpoint phase&quot; &quot; or no bits are set in the gc_prologue before the start of the next &quot; &quot;subsequent marking phase.&quot;); assert(_ct-&gt;cld_rem_set()-&gt;mod_union_is_clear(), &quot;Must be&quot;); // Save the end of the used_region of the constituent generations // to be used to limit the extent of sweep in each generation. save_sweep_limits(); verify_overflow_empty();&#125;void CMSParInitialMarkTask::work(uint worker_id) &#123; elapsedTimer _timer; ResourceMark rm; HandleMark hm; // ---------- scan from roots -------------- _timer.start(); CMSHeap* heap = CMSHeap::heap(); ParMarkRefsIntoClosure par_mri_cl(_collector-&gt;_span, &amp;(_collector-&gt;_markBitMap)); // ---------- young gen roots -------------- &#123; work_on_young_gen_roots(&amp;par_mri_cl); _timer.stop(); log_trace(gc, task)(&quot;Finished young gen initial mark scan work in %dth thread: %3.3f sec&quot;, worker_id, _timer.seconds()); &#125; // ---------- remaining roots -------------- _timer.reset(); _timer.start(); CLDToOopClosure cld_closure(&amp;par_mri_cl, true); heap-&gt;cms_process_roots(_strong_roots_scope, false, // yg was scanned above GenCollectedHeap::ScanningOption(_collector-&gt;CMSCollector::roots_scanning_options()), _collector-&gt;should_unload_classes(), &amp;par_mri_cl, &amp;cld_closure, &amp;_par_state_string); assert(_collector-&gt;should_unload_classes() || (_collector-&gt;CMSCollector::roots_scanning_options() &amp; GenCollectedHeap::SO_AllCodeCache), &quot;if we didn&#x27;t scan the code cache, we have to be ready to drop nmethods with expired weak oops&quot;); _timer.stop(); log_trace(gc, task)(&quot;Finished remaining root initial mark scan work in %dth thread: %3.3f sec&quot;, worker_id, _timer.seconds());&#125; 整个过程比较简单，从 GC Root 出发标记 Old 中的对象，处理完成后借助 BitMap 处理下 Young 区对 Old 区的引用，整个过程基本都比较快，很少会有较大的停顿。 CMS Final Remark 执行步骤，实现在 CMSCollector::checkpointRootsFinalWork() 中，整体代码和步骤如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990void CMSCollector::checkpointRootsFinalWork() &#123; GCTraceTime(Trace, gc, phases) tm(&quot;checkpointRootsFinalWork&quot;, _gc_timer_cm); assert(haveFreelistLocks(), &quot;must have free list locks&quot;); assert_lock_strong(bitMapLock()); ResourceMark rm; HandleMark hm; CMSHeap* heap = CMSHeap::heap(); if (should_unload_classes()) &#123; CodeCache::gc_prologue(); &#125; assert(haveFreelistLocks(), &quot;must have free list locks&quot;); assert_lock_strong(bitMapLock()); heap-&gt;ensure_parsability(false); // fill TLAB&#x27;s, but no need to retire them // Update the saved marks which may affect the root scans. heap-&gt;save_marks(); print_eden_and_survivor_chunk_arrays(); &#123; if (CMSParallelRemarkEnabled) &#123; GCTraceTime(Debug, gc, phases) t(&quot;Rescan (parallel)&quot;, _gc_timer_cm); do_remark_parallel(); &#125; else &#123; GCTraceTime(Debug, gc, phases) t(&quot;Rescan (non-parallel)&quot;, _gc_timer_cm); do_remark_non_parallel(); &#125; &#125; verify_work_stacks_empty(); verify_overflow_empty(); &#123; GCTraceTime(Trace, gc, phases) ts(&quot;refProcessingWork&quot;, _gc_timer_cm); refProcessingWork(); &#125; verify_work_stacks_empty(); verify_overflow_empty(); if (should_unload_classes()) &#123; CodeCache::gc_epilogue(); &#125; JvmtiExport::gc_epilogue(); assert(_markStack.isEmpty(), &quot;No grey objects&quot;); size_t ser_ovflw = _ser_pmc_remark_ovflw + _ser_pmc_preclean_ovflw + _ser_kac_ovflw + _ser_kac_preclean_ovflw; if (ser_ovflw &gt; 0) &#123; log_trace(gc)(&quot;Marking stack overflow (benign) (pmc_pc=&quot; SIZE_FORMAT &quot;, pmc_rm=&quot; SIZE_FORMAT &quot;, kac=&quot; SIZE_FORMAT &quot;, kac_preclean=&quot; SIZE_FORMAT &quot;)&quot;, _ser_pmc_preclean_ovflw, _ser_pmc_remark_ovflw, _ser_kac_ovflw, _ser_kac_preclean_ovflw); _markStack.expand(); _ser_pmc_remark_ovflw = 0; _ser_pmc_preclean_ovflw = 0; _ser_kac_preclean_ovflw = 0; _ser_kac_ovflw = 0; &#125; if (_par_pmc_remark_ovflw &gt; 0 || _par_kac_ovflw &gt; 0) &#123; log_trace(gc)(&quot;Work queue overflow (benign) (pmc_rm=&quot; SIZE_FORMAT &quot;, kac=&quot; SIZE_FORMAT &quot;)&quot;, _par_pmc_remark_ovflw, _par_kac_ovflw); _par_pmc_remark_ovflw = 0; _par_kac_ovflw = 0; &#125; if (_markStack._hit_limit &gt; 0) &#123; log_trace(gc)(&quot; (benign) Hit max stack size limit (&quot; SIZE_FORMAT &quot;)&quot;, _markStack._hit_limit); &#125; if (_markStack._failed_double &gt; 0) &#123; log_trace(gc)(&quot; (benign) Failed stack doubling (&quot; SIZE_FORMAT &quot;), current capacity &quot; SIZE_FORMAT, _markStack._failed_double, _markStack.capacity()); &#125; _markStack._hit_limit = 0; _markStack._failed_double = 0; if ((VerifyAfterGC || VerifyDuringGC) &amp;&amp; CMSHeap::heap()-&gt;total_collections() &gt;= VerifyGCStartAt) &#123; verify_after_remark(); &#125; _gc_tracer_cm-&gt;report_object_count_after_gc(&amp;_is_alive_closure); // Change under the freelistLocks. _collectorState = Sweeping; // Call isAllClear() under bitMapLock assert(_modUnionTable.isAllClear(), &quot;Should be clear by end of the final marking&quot;); assert(_ct-&gt;cld_rem_set()-&gt;mod_union_is_clear(), &quot;Should be clear by end of the final marking&quot;);&#125; Final Remark 是最终的第二次标记，这种情况只有在 Background GC 执行了 InitialMarking 步骤的情形下才会执行，如果是 Foreground GC 执行的 InitialMarking 步骤则不需要再次执行 FinalRemark。Final Remark 的开始阶段与 Init Mark 处理的流程相同，但是后续多了 Card Table 遍历、Reference 实例的清理并将其加入到 Reference 维护的 pend_list 中，如果要收集元数据信息，还要清理 SystemDictionary、CodeCache、SymbolTable、StringTable 等组件中不再使用的资源。 4.6.3 策略知道了两个 STW 过程执行流程，我们分析解决就比较简单了，由于大部分问题都出在 Final Remark 过程，这里我们也拿这个场景来举例，主要步骤： +【方向】 观察详细 GC 日志，找到出问题时 Final Remark 日志，分析下 Reference 处理和元数据处理 real 耗时是否正常，详细信息需要通过 -XX:+PrintReferenceGC 参数开启。基本在日志里面就能定位到大概是哪个方向出了问题，耗时超过 10% 的就需要关注。 122019-02-27T19:55:37.920+0800: 516952.915: [GC (CMS Final Remark) 516952.915: [ParNew516952.939: [SoftReference, 0 refs, 0.0003857 secs]516952.939: [WeakReference, 1362 refs, 0.0002415 secs]516952.940: [FinalReference, 146 refs, 0.0001233 secs]516952.940: [PhantomReference, 0 refs, 57 refs, 0.0002369 secs]516952.940: [JNI Weak Reference, 0.0000662 secs][class unloading, 0.1770490 secs]516953.329: [scrub symbol table, 0.0442567 secs]516953.373: [scrub string table, 0.0036072 secs][1 CMS-remark: 1638504K(2048000K)] 1667558K(4352000K), 0.5269311 secs] [Times: user=1.20 sys=0.03, real=0.53 secs] +【根因】 有了具体的方向我们就可以进行深入的分析，一般来说最容易出问题的地方就是 Reference 中的 FinalReference 和元数据信息处理中的 scrub symbol table 两个阶段，想要找到具体问题代码就需要内存分析工具 MAT 或 JProfiler 了，注意要 dump 即将开始 CMS GC 的堆。在用 MAT 等工具前也可以先用命令行看下对象 Histogram，有可能直接就能定位问题。 对 FinalReference 的分析主要观察 java.lang.ref.Finalizer 对象的 dominator tree，找到泄漏的来源。经常会出现问题的几个点有 Socket 的 SocksSocketImpl 、Jersey 的 ClientRuntime、MySQL 的 ConnectionImpl 等等。 scrub symbol table 表示清理元数据符号引用耗时，符号引用是 Java 代码被编译成字节码时，方法在 JVM 中的表现形式，生命周期一般与 Class 一致，当 _should_unload_classes 被设置为 true 时在 CMSCollector::refProcessingWork() 中与 Class Unload、String Table 一起被处理。 1234567891011121314151617181920212223242526if (should_unload_classes()) &#123; &#123; GCTraceTime(Debug, gc, phases) t(&quot;Class Unloading&quot;, _gc_timer_cm); // Unload classes and purge the SystemDictionary. bool purged_class = SystemDictionary::do_unloading(_gc_timer_cm); // Unload nmethods. CodeCache::do_unloading(&amp;_is_alive_closure, purged_class); // Prune dead klasses from subklass/sibling/implementor lists. Klass::clean_weak_klass_links(purged_class); &#125; &#123; GCTraceTime(Debug, gc, phases) t(&quot;Scrub Symbol Table&quot;, _gc_timer_cm); // Clean up unreferenced symbols in symbol table. SymbolTable::unlink(); &#125; &#123; GCTraceTime(Debug, gc, phases) t(&quot;Scrub String Table&quot;, _gc_timer_cm); // Delete entries for dead interned strings. StringTable::unlink(&amp;_is_alive_closure); &#125; &#125; +【策略】 知道 GC 耗时的根因就比较好处理了，这种问题不会大面积同时爆发，不过有很多时候单台 STW 的时间会比较长，如果业务影响比较大，及时摘掉流量，具体后续优化策略如下： FinalReference：找到内存来源后通过优化代码的方式来解决，如果短时间无法定位可以增加 -XX:+ParallelRefProcEnabled 对 Reference 进行并行处理。 symbol table：观察 MetaSpace 区的历史使用峰值，以及每次 GC 前后的回收情况，一般没有使用动态类加载或者 DSL 处理等，MetaSpace 的使用率上不会有什么变化，这种情况可以通过 -XX:-CMSClassUnloadingEnabled 来避免 MetaSpace 的处理，JDK8 会默认开启 CMSClassUnloadingEnabled，这会使得 CMS 在 CMS-Remark 阶段尝试进行类的卸载。 4.6.4 小结正常情况进行的 Background CMS GC，出现问题基本都集中在 Reference 和 Class 等元数据处理上，在 Reference 类的问题处理方面，不管是 FinalReference，还是 SoftReference、WeakReference 核心的手段就是找准时机 dump 快照，然后用内存分析工具来分析。Class 处理方面目前除了关闭类卸载开关，没有太好的方法。 在 G1 中同样有 Reference 的问题，可以观察日志中的 Ref Proc，处理方法与 CMS 类似。 4.7 场景七：内存碎片&amp;收集器退化4.7.1 现象并发的 CMS GC 算法，退化为 Foreground 单线程串行 GC 模式，STW 时间超长，有时会长达十几秒。其中 CMS 收集器退化后单线程串行 GC 算法有两种： 带压缩动作的算法，称为 MSC，上面我们介绍过，使用标记-清理-压缩，单线程全暂停的方式，对整个堆进行垃圾收集，也就是真正意义上的 Full GC，暂停时间要长于普通 CMS。 不带压缩动作的算法，收集 Old 区，和普通的 CMS 算法比较相似，暂停时间相对 MSC 算法短一些。 4.7.2 原因CMS 发生收集器退化主要有以下几种情况： 晋升失败（Promotion Failed） 顾名思义，晋升失败就是指在进行 Young GC 时，Survivor 放不下，对象只能放入 Old，但此时 Old 也放不下。直觉上乍一看这种情况可能会经常发生，但其实因为有 concurrentMarkSweepThread 和担保机制的存在，发生的条件是很苛刻的，除非是短时间将 Old 区的剩余空间迅速填满，例如上文中说的动态年龄判断导致的过早晋升（见下文的增量收集担保失败）。另外还有一种情况就是内存碎片导致的 Promotion Failed，Young GC 以为 Old 有足够的空间，结果到分配时，晋级的大对象找不到连续的空间存放。 使用 CMS 作为 GC 收集器时，运行过一段时间的 Old 区如下图所示，清除算法导致内存出现多段的不连续，出现大量的内存碎片。 碎片带来了两个问题： 空间分配效率较低：上文已经提到过，如果是连续的空间 JVM 可以通过使用 pointer bumping 的方式来分配，而对于这种有大量碎片的空闲链表则需要逐个访问 freelist 中的项来访问，查找可以存放新建对象的地址。 空间利用效率变低：Young 区晋升的对象大小大于了连续空间的大小，那么将会触发 Promotion Failed ，即使整个 Old 区的容量是足够的，但由于其不连续，也无法存放新对象，也就是本文所说的问题。 增量收集担保失败 分配内存失败后，会判断统计得到的 Young GC 晋升到 Old 的平均大小，以及当前 Young 区已使用的大小也就是最大可能晋升的对象大小，是否大于 Old 区的剩余空间。只要 CMS 的剩余空间比前两者的任意一者大，CMS 就认为晋升还是安全的，反之，则代表不安全，不进行Young GC，直接触发Full GC。 显式 GC 这种情况参见场景二。 并发模式失败（Concurrent Mode Failure） 最后一种情况，也是发生概率较高的一种，在 GC 日志中经常能看到 Concurrent Mode Failure 关键字。这种是由于并发 Background CMS GC 正在执行，同时又有 Young GC 晋升的对象要放入到了 Old 区中，而此时 Old 区空间不足造成的。 为什么 CMS GC 正在执行还会导致收集器退化呢？主要是由于 CMS 无法处理浮动垃圾（Floating Garbage）引起的。CMS 的并发清理阶段，Mutator 还在运行，因此不断有新的垃圾产生，而这些垃圾不在这次清理标记的范畴里，无法在本次 GC 被清除掉，这些就是浮动垃圾，除此之外在 Remark 之前那些断开引用脱离了读写屏障控制的对象也算浮动垃圾。所以 Old 区回收的阈值不能太高，否则预留的内存空间很可能不够，从而导致 Concurrent Mode Failure 发生。 4.7.3 策略分析到具体原因后，我们就可以针对性解决了，具体思路还是从根因出发，具体解决策略： 内存碎片： 通过配置 -XX:UseCMSCompactAtFullCollection&#x3D;true 来控制 Full GC的过程中是否进行空间的整理（默认开启，注意是Full GC，不是普通CMS GC），以及 -XX: CMSFullGCsBeforeCompaction&#x3D;n 来控制多少次 Full GC 后进行一次压缩。 增量收集： 降低触发 CMS GC 的阈值，即参数 -XX:CMSInitiatingOccupancyFraction 的值，让 CMS GC 尽早执行，以保证有足够的连续空间，也减少 Old 区空间的使用大小，另外需要使用 -XX:+UseCMSInitiatingOccupancyOnly 来配合使用，不然 JVM 仅在第一次使用设定值，后续则自动调整。 浮动垃圾： 视情况控制每次晋升对象的大小，或者缩短每次 CMS GC 的时间，必要时可调节 NewRatio 的值。另外就是使用 -XX:+CMSScavengeBeforeRemark 在过程中提前触发一次 Young GC，防止后续晋升过多对象。 4.7.4 小结正常情况下触发并发模式的 CMS GC，停顿非常短，对业务影响很小，但 CMS GC 退化后，影响会非常大，建议发现一次后就彻底根治。只要能定位到内存碎片、浮动垃圾、增量收集相关等具体产生原因，还是比较好解决的，关于内存碎片这块，如果 -XX:CMSFullGCsBeforeCompaction 的值不好选取的话，可以使用 -XX:PrintFLSStatistics 来观察内存碎片率情况，然后再设置具体的值。 最后就是在编码的时候也要避免需要连续地址空间的大对象的产生，如过长的字符串，用于存放附件、序列化或反序列化的 byte 数组等，还有就是过早晋升问题尽量在爆发问题前就避免掉。 4.8 场景八：堆外内存 OOM4.8.1 现象内存使用率不断上升，甚至开始使用 SWAP 内存，同时可能出现 GC 时间飙升，线程被 Block 等现象，通过 top 命令发现 Java 进程的 RES 甚至超过了 -Xmx 的大小。出现这些现象时，基本可以确定是出现了堆外内存泄漏。 4.8.2 原因JVM 的堆外内存泄漏，主要有两种的原因： 通过 UnSafe#allocateMemory，ByteBuffer#allocateDirect 主动申请了堆外内存而没有释放，常见于 NIO、Netty 等相关组件。 代码中有通过 JNI 调用 Native Code 申请的内存没有释放。 4.8.3 策略哪种原因造成的堆外内存泄漏？ 首先，我们需要确定是哪种原因导致的堆外内存泄漏。这里可以使用 NMT（NativeMemoryTracking） 进行分析。在项目中添加 -XX:NativeMemoryTracking&#x3D;detail JVM参数后重启项目（需要注意的是，打开 NMT 会带来 5%~10% 的性能损耗）。使用命令 jcmd pid VM.native_memory detail 查看内存分布。重点观察 total 中的 committed，因为 jcmd 命令显示的内存包含堆内内存、Code 区域、通过 Unsafe.allocateMemory 和 DirectByteBuffer 申请的内存，但是不包含其他 Native Code（C 代码）申请的堆外内存。 如果 total 中的 committed 和 top 中的 RES 相差不大，则应为主动申请的堆外内存未释放造成的，如果相差较大，则基本可以确定是 JNI 调用造成的。 原因一：主动申请未释放 JVM 使用 -XX:MaxDirectMemorySize=size 参数来控制可申请的堆外内存的最大值。在 Java8 中，如果未配置该参数，默认和 -Xmx 相等。 NIO 和 Netty 都会取 -XX:MaxDirectMemorySize 配置的值，来限制申请的堆外内存的大小。NIO 和 Netty 中还有一个计数器字段，用来计算当前已申请的堆外内存大小，NIO 中是 java.nio.Bits#totalCapacity、Netty 中 io.netty.util.internal.PlatformDependent#DIRECT_MEMORY_COUNTER。 当申请堆外内存时，NIO 和 Netty 会比较计数器字段和最大值的大小，如果计数器的值超过了最大值的限制，会抛出 OOM 的异常。 NIO 中是：OutOfMemoryError: Direct buffer memory。 Netty 中是：OutOfDirectMemoryError: failed to allocate capacity byte(s) of direct memory (used: usedMemory , max: DIRECT_MEMORY_LIMIT )。 我们可以检查代码中是如何使用堆外内存的，NIO 或者是 Netty，通过反射，获取到对应组件中的计数器字段，并在项目中对该字段的数值进行打点，即可准确地监控到这部分堆外内存的使用情况。 此时，可以通过 Debug 的方式确定使用堆外内存的地方是否正确执行了释放内存的代码。另外，需要检查 JVM 的参数是否有 -XX:+DisableExplicitGC 选项，如果有就去掉，因为该参数会使 System.gc 失效。（场景二：显式 GC 的去与留） 原因二：通过 JNI 调用的 Native Code 申请的内存未释放 这种情况排查起来比较困难，我们可以通过 Google perftools + Btrace 等工具，帮助我们分析出问题的代码在哪里。 gperftools 是 Google 开发的一款非常实用的工具集，它的原理是在 Java 应用程序运行时，当调用 malloc 时换用它的 libtcmalloc.so，这样就能对内存分配情况做一些统计。我们使用 gperftools 来追踪分配内存的命令。如下图所示，通过 gperftools 发现 Java_java_util_zip_Inflater_init 比较可疑。 接下来可以使用 Btrace，尝试定位具体的调用栈。Btrace 是 Sun 推出的一款 Java 追踪、监控工具，可以在不停机的情况下对线上的 Java 程序进行监控。如下图所示，通过 Btrace 定位出项目中的 ZipHelper 在频繁调用 GZIPInputStream ，在堆外内存分配对象。 最终定位到是，项目中对 GIPInputStream 的使用错误，没有正确的 close()。 除了项目本身的原因，还可能有外部依赖导致的泄漏，如 Netty 和 Spring Boot，详细情况可以学习下这两篇文章，Spring Boot引起的“堆外内存泄漏”排查及经验总结、Netty堆外内存泄露排查盛宴。 4.8.4 小结首先可以使用 NMT + jcmd 分析泄漏的堆外内存是哪里申请，确定原因后，使用不同的手段，进行原因定位。 4.9 场景九：JNI 引发的 GC 问题4.9.1 现象在 GC 日志中，出现 GC Cause 为 GCLocker Initiated GC。 122020-09-23T16:49:09.727+0800: 504426.742: [GC (GCLocker Initiated GC) 504426.742: [ParNew (promotion failed): 209716K-&gt;6042K(1887488K), 0.0843330 secs] 1449487K-&gt;1347626K(3984640K), 0.0848963 secs] [Times: user=0.19 sys=0.00, real=0.09 secs]2020-09-23T16:49:09.812+0800: 504426.827: [Full GC (GCLocker Initiated GC) 504426.827: [CMS: 1341583K-&gt;419699K(2097152K), 1.8482275 secs] 1347626K-&gt;419699K(3984640K), [Metaspace: 297780K-&gt;297780K(1329152K)], 1.8490564 secs] [Times: user=1.62 sys=0.20, real=1.85 secs] 4.9.2 原因JNI（Java Native Interface）意为 Java 本地调用，它允许 Java 代码和其他语言写的 Native 代码进行交互。 JNI 如果需要获取 JVM 中的 String 或者数组，有两种方式： 拷贝传递。 共享引用（指针），性能更高。 由于 Native 代码直接使用了 JVM 堆区的指针，如果这时发生 GC，就会导致数据错误。因此，在发生此类 JNI 调用时，禁止 GC 的发生，同时阻止其他线程进入 JNI 临界区，直到最后一个线程退出临界区时触发一次 GC。 GC Locker 实验： 12345678910111213141516171819202122232425262728293031public class GCLockerTest &#123; static final int ITERS = 100; static final int ARR_SIZE = 10000; static final int WINDOW = 10000000; static native void acquire(int[] arr); static native void release(int[] arr); static final Object[] window = new Object[WINDOW]; public static void main(String... args) throws Throwable &#123; System.loadLibrary(&quot;GCLockerTest&quot;); int[] arr = new int[ARR_SIZE]; for (int i = 0; i &lt; ITERS; i++) &#123; acquire(arr); System.out.println(&quot;Acquired&quot;); try &#123; for (int c = 0; c &lt; WINDOW; c++) &#123; window[c] = new Object(); &#125; &#125; catch (Throwable t) &#123; // omit &#125; finally &#123; System.out.println(&quot;Releasing&quot;); release(arr); &#125; &#125; &#125;&#125; 123456789101112#include &lt;jni.h&gt;#include &quot;GCLockerTest.h&quot;static jbyte* sink;JNIEXPORT void JNICALL Java_GCLockerTest_acquire(JNIEnv* env, jclass klass, jintArray arr) &#123;sink = (*env)-&gt;GetPrimitiveArrayCritical(env, arr, 0);&#125;JNIEXPORT void JNICALL Java_GCLockerTest_release(JNIEnv* env, jclass klass, jintArray arr) &#123;(*env)-&gt;ReleasePrimitiveArrayCritical(env, arr, sink, 0);&#125; 运行该 JNI 程序，可以看到发生的 GC 都是 GCLocker Initiated GC，并且注意在 “Acquired” 和 “Released” 时不可能发生 GC。 GC Locker 可能导致的不良后果有： 如果此时是 Young 区不够 Allocation Failure 导致的 GC，由于无法进行 Young GC，会将对象直接分配至 Old 区。 如果 Old 区也没有空间了，则会等待锁释放，导致线程阻塞。 可能触发额外不必要的 Young GC，JDK 有一个 Bug，有一定的几率，本来只该触发一次 GCLocker Initiated GC 的 Young GC，实际发生了一次 Allocation Failure GC 又紧接着一次 GCLocker Initiated GC。是因为 GCLocker Initiated GC 的属性被设为 full，导致两次 GC 不能收敛。 4.9.3 策略 添加 -XX+PrintJNIGCStalls 参数，可以打印出发生 JNI 调用时的线程，进一步分析，找到引发问题的 JNI 调用。 JNI 调用需要谨慎，不一定可以提升性能，反而可能造成 GC 问题。 升级 JDK 版本到 14，避免 JDK-8048556 导致的重复 GC。 4.9.4 小结JNI 产生的 GC 问题较难排查，需要谨慎使用。 5. 总结在这里，我们把整个文章内容总结一下，方便大家整体地理解回顾。 5.1 处理流程（SOP）下图为整体 GC 问题普适的处理流程，重点的地方下面会单独标注，其他的基本都是标准处理流程，此处不再赘述，最后在整个问题都处理完之后有条件的话建议做一下复盘。 制定标准： 这块内容其实非常重要，但大部分系统都是缺失的，笔者过往面试的同学中只有不到一成的同学能给出自己的系统 GC 标准到底什么样，其他的都是用的统一指标模板，缺少预见性，具体指标制定可以参考 3.1 中的内容，需要结合应用系统的 TP9999 时间和延迟、吞吐量等设定具体的指标，而不是被问题驱动。 保留现场： 目前线上服务基本都是分布式服务，某个节点发生问题后，如果条件允许一定不要直接操作重启、回滚等动作恢复，优先通过摘掉流量的方式来恢复，这样我们可以将堆、栈、GC 日志等关键信息保留下来，不然错过了定位根因的时机，后续解决难度将大大增加。当然除了这些，应用日志、中间件日志、内核日志、各种 Metrics 指标等对问题分析也有很大帮助。 因果分析： 判断 GC 异常与其他系统指标异常的因果关系，可以参考笔者在 3.2 中介绍的时序分析、概率分析、实验分析、反证分析等 4 种因果分析法，避免在排查过程中走入误区。 根因分析： 确实是 GC 的问题后，可以借助上文提到的工具并通过 5 why 根因分析法以及跟第三节中的九种常见的场景进行逐一匹配，或者直接参考下文的根因鱼骨图，找出问题发生根因，最后再选择优化手段。 5.2 根因鱼骨图送上一张问题根因鱼骨图，一般情况下我们在处理一个 GC 问题时，只要能定位到问题的“病灶”，有的放矢，其实就相当于解决了 80%，如果在某些场景下不太好定位，大家可以借助这种根因分析图通过排除法去定位。 5.3 调优建议 Trade Off： 与 CAP 注定要缺一角一样，GC 优化要在延迟（Latency）、吞吐量（Throughput）、容量（Capacity）三者之间进行权衡。 最终手段： GC 发生问题不是一定要对 JVM 的 GC 参数进行调优，大部分情况下是通过 GC 的情况找出一些业务问题，切记上来就对 GC 参数进行调整，当然有明确配置错误的场景除外。 控制变量： 控制变量法是在蒙特卡洛（Monte Carlo）方法中用于减少方差的一种技术方法，我们调优的时候尽量也要使用，每次调优过程尽可能只调整一个变量。 善用搜索： 理论上 99.99% 的 GC 问题基本都被遇到了，我们要学会使用搜索引擎的高级技巧，重点关注 StackOverFlow、Github 上的 Issue、以及各种论坛博客，先看看其他人是怎么解决的，会让解决问题事半功倍。能看到这篇文章，你的搜索能力基本过关了~ 调优重点： 总体上来讲，我们开发的过程中遇到的问题类型也基本都符合正态分布，太简单或太复杂的基本遇到的概率很低，笔者这里将中间最重要的三个场景添加了“*”标识，希望阅读完本文之后可以观察下自己负责的系统，是否存在上述问题。 GC 参数： 如果堆、栈确实无法第一时间保留，一定要保留 GC 日志，这样我们最起码可以看到 GC Cause，有一个大概的排查方向。关于 GC 日志相关参数，最基本的 -XX:+HeapDumpOnOutOfMemoryError 等一些参数就不再提了，笔者建议添加以下参数，可以提高我们分析问题的效率。 其他建议： 上文场景中没有提到，但是对 GC 性能也有提升的一些建议。 主动式 GC： 也有另开生面的做法，通过监控手段监控观测 Old 区的使用情况，即将到达阈值时将应用服务摘掉流量，手动触发一次 Major GC，减少 CMS GC 带来的停顿，但随之系统的健壮性也会减少，如非必要不建议引入。 禁用偏向锁： 偏向锁在只有一个线程使用到该锁的时候效率很高，但是在竞争激烈情况会升级成轻量级锁，此时就需要先消除偏向锁，这个过程是 STW 的。如果每个同步资源都走这个升级过程，开销会非常大，所以在已知并发激烈的前提下，一般会禁用偏向锁 -XX:-UseBiasedLocking 来提高性能。 虚拟内存： 启动初期有些操作系统（例如 Linux）并没有真正分配物理内存给 JVM ，而是在虚拟内存中分配，使用的时候才会在物理内存中分配内存页，这样也会导致 GC 时间较长。这种情况可以添加 -XX:+AlwaysPreTouch 参数，让 VM 在 commit 内存时跑个循环来强制保证申请的内存真的 commit，避免运行时触发缺页异常。在一些大内存的场景下，有时候能将前几次的 GC 时间降一个数量级，但是添加这个参数后，启动的过程可能会变慢。 6. 写在最后最后，再说笔者个人的一些小建议，遇到一些 GC 问题，如果有精力，一定要探本穷源，找出最深层次的原因。另外，在这个信息泛滥的时代，有一些被“奉为圭臬”的经验可能都是错误的，尽量养成看源码的习惯，有一句话说到“源码面前，了无秘密”，也就意味着遇到搞不懂的问题，我们可以从源码中一窥究竟，某些场景下确有奇效。但也不是只靠读源码来学习，如果硬啃源码但不理会其背后可能蕴含的理论基础，那很容易“捡芝麻丢西瓜”，“只见树木，不见森林”，让“了无秘密”变成了一句空话，我们还是要结合一些实际的业务场景去针对性地学习。 你的时间在哪里，你的成就就会在哪里。笔者也是在前两年才开始逐步地在 GC 方向上不断深入，查问题、看源码、做总结，每个 Case 形成一个小的闭环，目前初步摸到了 GC 问题处理的一些门道，同时将经验总结应用于生产环境实践，慢慢地形成一个良性循环。 本篇文章主要是介绍了 CMS GC 的一些常见场景分析，另外一些，如 CodeCache 问题导致 JIT 失效、SafePoint 就绪时间长、Card Table 扫描耗时等问题不太常见就没有花太多篇幅去讲解。Java GC 是在“分代”的思想下内卷了很多年才突破到了“分区”，目前在美团也已经开始使用 G1 来替换使用了多年的 CMS，虽然在小的堆方面 G1 还略逊色于 CMS，但这是一个趋势，短时间无法升级到 ZGC，所以未来遇到的 G1 的问题可能会逐渐增多。目前已经收集到 Remember Set 粗化、Humongous 分配、Ergonomics 异常、Mixed GC 中 Evacuation Failure 等问题，除此之外也会给出 CMS 升级到 G1 的一些建议，接下来笔者将继续完成这部分文章整理，敬请期待。 “防火”永远要胜于“救火”，不放过任何一个异常的小指标（一般来说，任何不平滑的曲线都是值得怀疑的） ，就有可能避免一次故障的发生。作为 Java 程序员基本都会遇到一些 GC 的问题，独立解决 GC 问题是我们必须迈过的一道坎。开篇中也提到过 GC 作为经典的技术，非常值得我们学习，一些 GC 的学习材料，如《The Garbage Collection Handbook》《深入理解Java虚拟机》等也是常读常新，赶紧动起来，苦练 GC 基本功吧。 最后的最后，再多啰嗦一句，目前所有 GC 调优相关的文章，第一句讲的就是“不要过早优化”，使得很多同学对 GC 优化望而却步。在这里笔者提出不一样的观点，熵增定律（在一个孤立系统里，如果没有外力做功，其总混乱度（即熵）会不断增大）在计算机系统同样适用，如果不主动做功使熵减，系统终究会脱离你的掌控，在我们对业务系统和 GC 原理掌握得足够深的时候，可以放心大胆地做优化，因为我们基本可以预测到每一个操作的结果，放手一搏吧，少年！ 7. 参考资料 [1].《ガベージコレクションのアルゴリズムと実装》中村 成洋 &#x2F; 相川 光 [2].《The Garbage Collection Handbook》 Richard Jones&#x2F; Antony Hosking &#x2F; Eliot Moss [3].《深入理解Java虚拟机（第3版）》 周志明 [4].《Java Platform, Standard Edition HotSpot Virtual Machine Garbage Collection Tuning Guide》 [5].《Shipilev One Page Blog》 Shipilëv [6]. https://openjdk.java.net/projects/jdk/15/ [7]. https://jcp.org/en/home/index [8].《A Generational Mostly-concurrent Garbage Collector》 Tony Printezis &#x2F; David Detlefs [9].《Java Memory Management White Paper》 [10].《Stuff Happens：Understanding Causation in Policy and Strategy》AA Hill 8. 作者简介 新宇：2015 年加入美团，到店住宿门票业务开发工程师。 湘铭：2018 年加入美团，到店客户平台开发工程师。 祥璞：2018 年加入美团，到店客户平台开发工程师。","tags":["Java","JVM","GC","CMS"],"categories":["Java","JVM","GC"]},{"title":"10.GC - Java 垃圾回收器之ZGC详解","path":"/2023/12/27/10-GC-Java-垃圾回收器之ZGC详解/","content":"ZGC（The Z Garbage Collector）是JDK 11中推出的一款低延迟垃圾回收器, 是JDK 11+ 最为重要的更新之一，适用于大内存低延迟服务的内存管理和回收。在梳理相关知识点时，发现美团技术团队分享的文章新一代垃圾回收器ZGC的探索与实践比较完善（包含G1收集器停顿时间瓶颈，原理，优化等）, 这里分享给你，帮你构建ZGC相关的知识体系。 ZGC概述 ZGC（The Z Garbage Collector）是JDK 11中推出的一款低延迟垃圾回收器，它的设计目标包括： 停顿时间不超过10ms； 停顿时间不会随着堆的大小，或者活跃对象的大小而增加（对程序吞吐量影响小于15%）； 支持8MB~4TB级别的堆（未来支持16TB）。 从设计目标来看，我们知道ZGC适用于大内存低延迟服务的内存管理和回收。本文主要介绍ZGC在低延时场景中的应用和卓越表现，文章内容主要分为四部分： GC之痛：介绍实际业务中遇到的GC痛点，并分析CMS收集器和G1收集器停顿时间瓶颈； ZGC原理：分析ZGC停顿时间比G1或CMS更短的本质原因，以及背后的技术原理； ZGC调优实践：重点分享对ZGC调优的理解，并分析若干个实际调优案例； 升级ZGC效果：展示在生产环境应用ZGC取得的效果。 GC之痛 很多低延迟高可用Java服务的系统可用性经常受GC停顿的困扰。GC停顿指垃圾回收期间STW（Stop The World），当STW时，所有应用线程停止活动，等待GC停顿结束。 以美团风控服务为例，部分上游业务要求风控服务65ms内返回结果，并且可用性要达到99.99%。但因为GC停顿，我们未能达到上述可用性目标。当时使用的是CMS垃圾回收器，单次Young GC 40ms，一分钟10次，接口平均响应时间30ms。通过计算可知，有（40ms + 30ms) * 10次 &#x2F; 60000ms &#x3D; 1.12%的请求的响应时间会增加0 ~ 40ms不等，其中30ms * 10次 &#x2F; 60000ms &#x3D; 0.5%的请求响应时间会增加40ms。可见，GC停顿对响应时间的影响较大。为了降低GC停顿对系统可用性的影响，我们从降低单次GC时间和降低GC频率两个角度出发进行了调优，还测试过G1垃圾回收器，但这三项措施均未能降低GC对服务可用性的影响。 CMS与G1停顿时间瓶颈 在介绍ZGC之前，首先回顾一下CMS和G1的GC过程以及停顿时间的瓶颈。CMS新生代的Young GC、G1和ZGC都基于标记-复制算法，但算法具体实现的不同就导致了巨大的性能差异。 标记-复制算法应用在CMS新生代（ParNew是CMS默认的新生代垃圾回收器）和G1垃圾回收器中。标记-复制算法可以分为三个阶段： 标记阶段，即从GC Roots集合开始，标记活跃对象； 转移阶段，即把活跃对象复制到新的内存地址上； 重定位阶段，因为转移导致对象的地址发生了变化，在重定位阶段，所有指向对象旧地址的指针都要调整到对象新的地址上。 下面以G1为例，通过G1中标记-复制算法过程（G1的Young GC和Mixed GC均采用该算法），分析G1停顿耗时的主要瓶颈。G1垃圾回收周期如下图所示： G1的混合回收过程可以分为标记阶段、清理阶段和复制阶段。 标记阶段停顿分析 初始标记阶段：初始标记阶段是指从GC Roots出发标记全部直接子节点的过程，该阶段是STW的。由于GC Roots数量不多，通常该阶段耗时非常短。 并发标记阶段：并发标记阶段是指从GC Roots开始对堆中对象进行可达性分析，找出存活对象。该阶段是并发的，即应用线程和GC线程可以同时活动。并发标记耗时相对长很多，但因为不是STW，所以我们不太关心该阶段耗时的长短。 再标记阶段：重新标记那些在并发标记阶段发生变化的对象。该阶段是STW的。 清理阶段停顿分析 清理阶段清点出有存活对象的分区和没有存活对象的分区，该阶段不会清理垃圾对象，也不会执行存活对象的复制。该阶段是STW的。 复制阶段停顿分析 复制算法中的转移阶段需要分配新内存和复制对象的成员变量。转移阶段是STW的，其中内存分配通常耗时非常短，但对象成员变量的复制耗时有可能较长，这是因为复制耗时与存活对象数量与对象复杂度成正比。对象越复杂，复制耗时越长。 四个STW过程中，初始标记因为只标记GC Roots，耗时较短。再标记因为对象数少，耗时也较短。清理阶段因为内存分区数量少，耗时也较短。转移阶段要处理所有存活的对象，耗时会较长。因此，G1停顿时间的瓶颈主要是标记-复制中的转移阶段STW。为什么转移阶段不能和标记阶段一样并发执行呢？主要是G1未能解决转移过程中准确定位对象地址的问题。 G1的Young GC和CMS的Young GC，其标记-复制全过程STW，这里不再详细阐述。 ZGC原理全并发的ZGC 与CMS中的ParNew和G1类似，ZGC也采用标记-复制算法，不过ZGC对该算法做了重大改进：ZGC在标记、转移和重定位阶段几乎都是并发的，这是ZGC实现停顿时间小于10ms目标的最关键原因。 ZGC垃圾回收周期如下图所示： ZGC只有三个STW阶段：初始标记，再标记，初始转移。其中，初始标记和初始转移分别都只需要扫描所有GC Roots，其处理时间和GC Roots的数量成正比，一般情况耗时非常短；再标记阶段STW时间很短，最多1ms，超过1ms则再次进入并发标记阶段。即，ZGC几乎所有暂停都只依赖于GC Roots集合大小，停顿时间不会随着堆的大小或者活跃对象的大小而增加。与ZGC对比，G1的转移阶段完全STW的，且停顿时间随存活对象的大小增加而增加。 ZGC关键技术ZGC通过着色指针和读屏障技术，解决了转移过程中准确访问对象的问题，实现了并发转移。大致原理描述如下：并发转移中“并发”意味着GC线程在转移对象的过程中，应用线程也在不停地访问对象。假设对象发生转移，但对象地址未及时更新，那么应用线程可能访问到旧地址，从而造成错误。而在ZGC中，应用线程访问对象将触发“读屏障”，如果发现对象被移动了，那么“读屏障”会把读出来的指针更新到对象的新地址上，这样应用线程始终访问的都是对象的新地址。那么，JVM是如何判断对象被移动过呢？就是利用对象引用的地址，即着色指针。下面介绍着色指针和读屏障技术细节。 着色指针 着色指针是一种将信息存储在指针中的技术。 ZGC仅支持64位系统，它把64位虚拟地址空间划分为多个子空间，如下图所示： 其中，[0~4TB) 对应Java堆，[4TB ~ 8TB) 称为M0地址空间，[8TB ~ 12TB) 称为M1地址空间，[12TB ~ 16TB) 预留未使用，[16TB ~ 20TB) 称为Remapped空间。 当应用程序创建对象时，首先在堆空间申请一个虚拟地址，但该虚拟地址并不会映射到真正的物理地址。ZGC同时会为该对象在M0、M1和Remapped地址空间分别申请一个虚拟地址，且这三个虚拟地址对应同一个物理地址，但这三个空间在同一时间有且只有一个空间有效。ZGC之所以设置三个虚拟地址空间，是因为它使用“空间换时间”思想，去降低GC停顿时间。“空间换时间”中的空间是虚拟空间，而不是真正的物理空间。后续章节将详细介绍这三个空间的切换过程。 与上述地址空间划分相对应，ZGC实际仅使用64位地址空间的第041位，而第4245位存储元数据，第47~63位固定为0。 ZGC将对象存活信息存储在42~45位中，这与传统的垃圾回收并将对象存活信息放在对象头中完全不同。 读屏障 读屏障是JVM向应用代码插入一小段代码的技术。当应用线程从堆中读取对象引用时，就会执行这段代码。需要注意的是，仅“从堆中读取对象引用”才会触发这段代码。 读屏障示例： 12345Object o = obj.FieldA // 从堆中读取引用，需要加入屏障&lt;Load barrier&gt;Object p = o // 无需加入屏障，因为不是从堆中读取引用o.dosomething() // 无需加入屏障，因为不是从堆中读取引用int i = obj.FieldB //无需加入屏障，因为不是对象引用 ZGC中读屏障的代码作用：在对象标记和转移过程中，用于确定对象的引用地址是否满足条件，并作出相应动作。 ZGC并发处理演示接下来详细介绍ZGC一次垃圾回收周期中地址视图的切换过程： 初始化：ZGC初始化之后，整个内存空间的地址视图被设置为Remapped。程序正常运行，在内存中分配对象，满足一定条件后垃圾回收启动，此时进入标记阶段。 并发标记阶段：第一次进入标记阶段时视图为M0，如果对象被GC标记线程或者应用线程访问过，那么就将对象的地址视图从Remapped调整为M0。所以，在标记阶段结束之后，对象的地址要么是M0视图，要么是Remapped。如果对象的地址是M0视图，那么说明对象是活跃的；如果对象的地址是Remapped视图，说明对象是不活跃的。 并发转移阶段：标记结束后就进入转移阶段，此时地址视图再次被设置为Remapped。如果对象被GC转移线程或者应用线程访问过，那么就将对象的地址视图从M0调整为Remapped。 其实，在标记阶段存在两个地址视图M0和M1，上面的过程显示只用了一个地址视图。之所以设计成两个，是为了区别前一次标记和当前标记。也即，第二次进入并发标记阶段后，地址视图调整为M1，而非M0。 着色指针和读屏障技术不仅应用在并发转移阶段，还应用在并发标记阶段：将对象设置为已标记，传统的垃圾回收器需要进行一次内存访问，并将对象存活信息放在对象头中；而在ZGC中，只需要设置指针地址的第42~45位即可，并且因为是寄存器访问，所以速度比访问内存更快。 ZGC调优实践 ZGC不是“银弹”，需要根据服务的具体特点进行调优。网络上能搜索到实战经验较少，调优理论需自行摸索，我们在此阶段也耗费了不少时间，最终才达到理想的性能。本文的一个目的是列举一些使用ZGC时常见的问题，帮助大家使用ZGC提高服务可用性。 调优基础知识理解ZGC重要配置参数 以我们服务在生产环境中ZGC参数配置为例，说明各个参数的作用： 重要参数配置样例： 1234567-Xms10G -Xmx10G -XX:ReservedCodeCacheSize=256m -XX:InitialCodeCacheSize=256m -XX:+UnlockExperimentalVMOptions -XX:+UseZGC -XX:ConcGCThreads=2 -XX:ParallelGCThreads=6 -XX:ZCollectionInterval=120 -XX:ZAllocationSpikeTolerance=5 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive -Xlog:safepoint,classhisto*=trace,age*,gc*=info:file=/opt/logs/logs/gc-%t.log:time,tid,tags:filecount=5,filesize=50m -Xms -Xmx：堆的最大内存和最小内存，这里都设置为10G，程序的堆内存将保持10G不变。 -XX:ReservedCodeCacheSize -XX:InitialCodeCacheSize：设置CodeCache的大小， JIT编译的代码都放在CodeCache中，一般服务64m或128m就已经足够。我们的服务因为有一定特殊性，所以设置的较大，后面会详细介绍。 -XX:+UnlockExperimentalVMOptions -XX:+UseZGC：启用ZGC的配置。 -XX:ConcGCThreads：并发回收垃圾的线程。默认是总核数的12.5%，8核CPU默认是1。调大后GC变快，但会占用程序运行时的CPU资源，吞吐会受到影响。 -XX:ParallelGCThreads：STW阶段使用线程数，默认是总核数的60%。 -XX:ZCollectionInterval：ZGC发生的最小时间间隔，单位秒。 -XX:ZAllocationSpikeTolerance：ZGC触发自适应算法的修正系数，默认2，数值越大，越早的触发ZGC。 -XX:+UnlockDiagnosticVMOptions -XX:-ZProactive：是否启用主动回收，默认开启，这里的配置表示关闭。 -Xlog：设置GC日志中的内容、格式、位置以及每个日志的大小。 理解ZGC触发时机 相比于CMS和G1的GC触发机制，ZGC的GC触发机制有很大不同。ZGC的核心特点是并发，GC过程中一直有新的对象产生。如何保证在GC完成之前，新产生的对象不会将堆占满，是ZGC参数调优的第一大目标。因为在ZGC中，当垃圾来不及回收将堆占满时，会导致正在运行的线程停顿，持续时间可能长达秒级之久。 ZGC有多种GC触发机制，总结如下： 阻塞内存分配请求触发：当垃圾来不及回收，垃圾将堆占满时，会导致部分线程阻塞。我们应当避免出现这种触发方式。日志中关键字是“Allocation Stall”。 基于分配速率的自适应算法：最主要的GC触发方式，其算法原理可简单描述为”ZGC根据近期的对象分配速率以及GC时间，计算出当内存占用达到什么阈值时触发下一次GC”。自适应算法的详细理论可参考彭成寒《新一代垃圾回收器ZGC设计与实现》一书中的内容。通过ZAllocationSpikeTolerance参数控制阈值大小，该参数默认2，数值越大，越早的触发GC。我们通过调整此参数解决了一些问题。日志中关键字是“Allocation Rate”。 基于固定时间间隔：通过ZCollectionInterval控制，适合应对突增流量场景。流量平稳变化时，自适应算法可能在堆使用率达到95%以上才触发GC。流量突增时，自适应算法触发的时机可能会过晚，导致部分线程阻塞。我们通过调整此参数解决流量突增场景的问题，比如定时活动、秒杀等场景。日志中关键字是“Timer”。 主动触发规则：类似于固定间隔规则，但时间间隔不固定，是ZGC自行算出来的时机，我们的服务因为已经加了基于固定时间间隔的触发机制，所以通过-ZProactive参数将该功能关闭，以免GC频繁，影响服务可用性。 日志中关键字是“Proactive”。 预热规则：服务刚启动时出现，一般不需要关注。日志中关键字是“Warmup”。 外部触发：代码中显式调用System.gc()触发。 日志中关键字是“System.gc()”。 元数据分配触发：元数据区不足时导致，一般不需要关注。 日志中关键字是“Metadata GC Threshold”。 理解ZGC日志一次完整的GC过程，需要注意的点已在图中标出。 注意：该日志过滤了进入安全点的信息。正常情况，在一次GC过程中还穿插着进入安全点的操作。 GC日志中每一行都注明了GC过程中的信息，关键信息如下： Start：开始GC，并标明的GC触发的原因。上图中触发原因是自适应算法。 Phase-Pause Mark Start：初始标记，会STW。 Phase-Pause Mark End：再次标记，会STW。 Phase-Pause Relocate Start：初始转移，会STW。 Heap信息：记录了GC过程中Mark、Relocate前后的堆大小变化状况。High和Low记录了其中的最大值和最小值，我们一般关注High中Used的值，如果达到100%，在GC过程中一定存在内存分配不足的情况，需要调整GC的触发时机，更早或者更快地进行GC。 GC信息统计：可以定时的打印垃圾收集信息，观察10秒内、10分钟内、10个小时内，从启动到现在的所有统计信息。利用这些统计信息，可以排查定位一些异常点。 日志中内容较多，关键点已用红线标出，含义较好理解，更详细的解释大家可以自行在网上查阅资料。 理解ZGC停顿原因我们在实战过程中共发现了6种使程序停顿的场景，分别如下： GC时，初始标记：日志中Pause Mark Start。 GC时，再标记：日志中Pause Mark End。 GC时，初始转移：日志中Pause Relocate Start。 内存分配阻塞：当内存不足时线程会阻塞等待GC完成，关键字是”Allocation Stall”。 安全点：所有线程进入到安全点后才能进行GC，ZGC定期进入安全点判断是否需要GC。先进入安全点的线程需要等待后进入安全点的线程直到所有线程挂起。 dump线程、内存：比如jstack、jmap命令。 调优案例我们维护的服务名叫Zeus，它是美团的规则平台，常用于风控场景中的规则管理。规则运行是基于开源的表达式执行引擎Aviator。Aviator内部将每一条表达式转化成Java的一个类，通过调用该类的接口实现表达式逻辑。 Zeus服务内的规则数量超过万条，且每台机器每天的请求量几百万。这些客观条件导致Aviator生成的类和方法会产生很多的ClassLoader和CodeCache，这些在使用ZGC时都成为过GC的性能瓶颈。接下来介绍两类调优案例。 第一类：内存分配阻塞，系统停顿可达到秒级 案例一：秒杀活动中流量突增，出现性能毛刺日志信息：对比出现性能毛刺时间点的GC日志和业务日志，发现JVM停顿了较长时间，且停顿时GC日志中有大量的“Allocation Stall”日志。 分析：这种案例多出现在“自适应算法”为主要GC触发机制的场景中。ZGC是一款并发的垃圾回收器，GC线程和应用线程同时活动，在GC过程中，还会产生新的对象。GC完成之前，新产生的对象将堆占满，那么应用线程可能因为申请内存失败而导致线程阻塞。当秒杀活动开始，大量请求打入系统，但自适应算法计算的GC触发间隔较长，导致GC触发不及时，引起了内存分配阻塞，导致停顿。 解决方法： （1）开启”基于固定时间间隔“的GC触发机制：-XX:ZCollectionInterval。比如调整为5秒，甚至更短。 （2）增大修正系数-XX:ZAllocationSpikeTolerance，更早触发GC。ZGC采用正态分布模型预测内存分配速率，模型修正系数ZAllocationSpikeTolerance默认值为2，值越大，越早的触发GC，Zeus中所有集群设置的是5。 案例二：压测时，流量逐渐增大到一定程度后，出现性能毛刺日志信息：平均1秒GC一次，两次GC之间几乎没有间隔。 分析：GC触发及时，但内存标记和回收速度过慢，引起内存分配阻塞，导致停顿。 解决方法：增大-XX:ConcGCThreads， 加快并发标记和回收速度。ConcGCThreads默认值是核数的1&#x2F;8，8核机器，默认值是1。该参数影响系统吞吐，如果GC间隔时间大于GC周期，不建议调整该参数。 第二类：GC Roots 数量大，单次GC停顿时间长 案例三： 单次GC停顿时间30ms，与预期停顿10ms左右有较大差距日志信息：观察ZGC日志信息统计，“Pause Roots ClassLoaderDataGraph”一项耗时较长。 分析：dump内存文件，发现系统中有上万个ClassLoader实例。我们知道ClassLoader属于GC Roots一部分，且ZGC停顿时间与GC Roots成正比，GC Roots数量越大，停顿时间越久。再进一步分析，ClassLoader的类名表明，这些ClassLoader均由Aviator组件生成。分析Aviator源码，发现Aviator对每一个表达式新生成类时，会创建一个ClassLoader，这导致了ClassLoader数量巨大的问题。在更高Aviator版本中，该问题已经被修复，即仅创建一个ClassLoader为所有表达式生成类。 解决方法：升级Aviator组件版本，避免生成多余的ClassLoader。 案例四：服务启动后，运行时间越长，单次GC时间越长，重启后恢复日志信息：观察ZGC日志信息统计，“Pause Roots CodeCache”的耗时会随着服务运行时间逐渐增长。 分析：CodeCache空间用于存放Java热点代码的JIT编译结果，而CodeCache也属于GC Roots一部分。通过添加-XX:+PrintCodeCacheOnCompilation参数，打印CodeCache中的被优化的方法，发现大量的Aviator表达式代码。定位到根本原因，每个表达式都是一个类中一个方法。随着运行时间越长，执行次数增加，这些方法会被JIT优化编译进入到Code Cache中，导致CodeCache越来越大。 解决方法：JIT有一些参数配置可以调整JIT编译的条件，但对于我们的问题都不太适用。我们最终通过业务优化解决，删除不需要执行的Aviator表达式，从而避免了大量Aviator方法进入CodeCache中。 值得一提的是，我们并不是在所有这些问题都解决后才全量部署所有集群。即使开始有各种各样的毛刺，但计算后发现，有各种问题的ZGC也比之前的CMS对服务可用性影响小。所以从开始准备使用ZGC到全量部署，大概用了2周的时间。在之后的3个月时间里，我们边做业务需求，边跟进这些问题，最终逐个解决了上述问题，从而使ZGC在各个集群上达到了一个更好表现。 升级ZGC效果延迟降低TP(Top Percentile)是一项衡量系统延迟的指标：TP999表示99.9%请求都能被响应的最小耗时；TP99表示99%请求都能被响应的最小耗时。 在Zeus服务不同集群中，ZGC在低延迟（TP999 &lt; 200ms）场景中收益较大： TP999：下降12142ms，下降幅度18%74%。 TP99：下降528ms，下降幅度10%47%。 超低延迟（TP999 &lt; 20ms）和高延迟（TP999 &gt; 200ms）服务收益不大，原因是这些服务的响应时间瓶颈不是GC，而是外部依赖的性能。 吞吐下降对吞吐量优先的场景，ZGC可能并不适合。例如，Zeus某离线集群原先使用CMS，升级ZGC后，系统吞吐量明显降低。究其原因有二： 第一，ZGC是单代垃圾回收器，而CMS是分代垃圾回收器。单代垃圾回收器每次处理的对象更多，更耗费CPU资源； 第二，ZGC使用读屏障，读屏障操作需耗费额外的计算资源。 总结ZGC作为下一代垃圾回收器，性能非常优秀。ZGC垃圾回收过程几乎全部是并发，实际STW停顿时间极短，不到10ms。这得益于其采用的着色指针和读屏障技术。 Zeus在升级JDK 11+ZGC中，通过将风险和问题分类，然后各个击破，最终顺利实现了升级目标，GC停顿也几乎不再影响系统可用性。 最后推荐大家升级ZGC，Zeus系统因为业务特点，遇到了较多问题，而风控其他团队在升级时都非常顺利。 参考文献 ZGC官网 彭成寒.《新一代垃圾回收器ZGC设计与实现》. 机械工业出版社, 2019. 从实际案例聊聊Java应用的GC优化 Java Hotspot G1 GC的一些关键技术 作者简介 王东，美团信息安全资深工程师。 王伟，美团信息安全技术专家。 更多优秀文章推荐 https://www.jianshu.com/p/664e4da05b2c","tags":["Java","JVM","GC","ZGC"],"categories":["Java","JVM","GC"]},{"title":"9.GC - Java 垃圾回收器之G1详解","path":"/2023/12/27/9-GC-Java-垃圾回收器之G1详解/","content":"G1垃圾回收器是在Java7 update 4之后引入的一个新的垃圾回收器。同优秀的CMS垃圾回收器一样，G1也是关注最小时延的垃圾回收器，也同样适合大尺寸堆内存的垃圾收集，官方在ZGC还没有出现时也推荐使用G1来代替选择CMS。G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。 1. 概述G1垃圾回收器是在Java7 update 4之后引入的一个新的垃圾回收器。G1是一个分代的，增量的，并行与并发的标记-复制垃圾回收器。它的设计目标是为了适应现在不断扩大的内存和不断增加的处理器数量，进一步降低暂停时间（pause time），同时兼顾良好的吞吐量。G1回收器和CMS比起来，有以下不同： G1垃圾回收器是compacting的，因此其回收得到的空间是连续的。这避免了CMS回收器因为不连续空间所造成的问题。如需要更大的堆空间，更多的floating garbage。连续空间意味着G1垃圾回收器可以不必采用空闲链表的内存分配方式，而可以直接采用bump-the-pointer的方式； G1回收器的内存与CMS回收器要求的内存模型有极大的不同。G1将内存划分一个个固定大小的region，每个region可以是年轻代、老年代的一个。内存的回收是以region作为基本单位的； G1还有一个及其重要的特性：软实时（soft real-time）。所谓的实时垃圾回收，是指在要求的时间内完成垃圾回收。“软实时”则是指，用户可以指定垃圾回收时间的限时，G1会努力在这个时限内完成垃圾回收，但是G1并不担保每次都能在这个时限内完成垃圾回收。通过设定一个合理的目标，可以让达到90%以上的垃圾回收时间都在这个时限内。 2. G1的内存模型2.1 分区概念G1分区示意图 2.1.1 分区RegionG1采用了分区(Region)的思路，将整个堆空间分成若干个大小相等的内存区域，每次分配对象空间将逐段地使用内存。因此，在堆的使用上，G1并不要求对象的存储一定是物理上连续的，只要逻辑上连续即可；每个分区也不会确定地为某个代服务，可以按需在年轻代和老年代之间切换。启动时可以通过参数-XX:G1HeapRegionSize&#x3D;n可指定分区大小(1MB~32MB，且必须是2的幂)，默认将整堆划分为2048个分区。 2.1.2 卡片Card在每个分区内部又被分成了若干个大小为512 Byte卡片(Card)，标识堆内存最小可用粒度所有分区的卡片将会记录在全局卡片表(Global Card Table)中，分配的对象会占用物理上连续的若干个卡片，当查找对分区内对象的引用时便可通过记录卡片来查找该引用对象(见RSet)。每次对内存的回收，都是对指定分区的卡片进行处理。 2.1.3 堆HeapG1同样可以通过-Xms&#x2F;-Xmx来指定堆空间大小。当发生年轻代收集或混合收集时，通过计算GC与应用的耗费时间比，自动调整堆空间大小。如果GC频率太高，则通过增加堆尺寸，来减少GC频率，相应地GC占用的时间也随之降低；目标参数-XX:GCTimeRatio即为GC与应用的耗费时间比，G1默认为9，而CMS默认为99，因为CMS的设计原则是耗费在GC上的时间尽可能的少。另外，当空间不足，如对象空间分配或转移失败时，G1会首先尝试增加堆空间，如果扩容失败，则发起担保的Full GC。Full GC后，堆尺寸计算结果也会调整堆空间。 2.2 分代模型 2.2.1 分代垃圾收集分代垃圾收集可以将关注点集中在最近被分配的对象上，而无需整堆扫描，避免长命对象的拷贝，同时独立收集有助于降低响应时间。虽然分区使得内存分配不再要求紧凑的内存空间，但G1依然使用了分代的思想。与其他垃圾收集器类似，G1将内存在逻辑上划分为年轻代和老年代，其中年轻代又划分为Eden空间和Survivor空间。但年轻代空间并不是固定不变的，当现有年轻代分区占满时，JVM会分配新的空闲分区加入到年轻代空间。 整个年轻代内存会在初始空间-XX:G1NewSizePercent(默认整堆5%)与最大空间(默认60%)之间动态变化，且由参数目标暂停时间-XX:MaxGCPauseMillis(默认200ms)、需要扩缩容的大小以-XX:G1MaxNewSizePercent及分区的已记忆集合(RSet)计算得到。当然，G1依然可以设置固定的年轻代大小(参数-XX:NewRatio、-Xmn)，但同时暂停目标将失去意义。 2.2.2 本地分配缓冲 Local allocation buffer (Lab)值得注意的是，由于分区的思想，每个线程均可以”认领”某个分区用于线程本地的内存分配，而不需要顾及分区是否连续。因此，每个应用线程和GC线程都会独立的使用分区，进而减少同步时间，提升GC效率，这个分区称为本地分配缓冲区(Lab)。 其中，应用线程可以独占一个本地缓冲区(TLAB)来创建的对象，而大部分都会落入Eden区域(巨型对象或分配失败除外)，因此TLAB的分区属于Eden空间；而每次垃圾收集时，每个GC线程同样可以独占一个本地缓冲区(GCLAB)用来转移对象，每次回收会将对象复制到Suvivor空间或老年代空间；对于从Eden&#x2F;Survivor空间晋升(Promotion)到Survivor&#x2F;老年代空间的对象，同样有GC独占的本地缓冲区进行操作，该部分称为晋升本地缓冲区(PLAB)。 2.3 分区模型 G1对内存的使用以分区(Region)为单位，而对对象的分配则以卡片(Card)为单位。 2.3.1 巨形对象Humongous Region一个大小达到甚至超过分区大小一半的对象称为巨型对象(Humongous Object)。当线程为巨型分配空间时，不能简单在TLAB进行分配，因为巨型对象的移动成本很高，而且有可能一个分区不能容纳巨型对象。因此，巨型对象会直接在老年代分配，所占用的连续空间称为巨型分区(Humongous Region)。G1内部做了一个优化，一旦发现没有引用指向巨型对象，则可直接在年轻代收集周期中被回收。 巨型对象会独占一个、或多个连续分区，其中第一个分区被标记为开始巨型(StartsHumongous)，相邻连续分区被标记为连续巨型(ContinuesHumongous)。由于无法享受Lab带来的优化，并且确定一片连续的内存空间需要扫描整堆，因此确定巨型对象开始位置的成本非常高，如果可以，应用程序应避免生成巨型对象。 2.3.2 已记忆集合Remember Set (RSet)在串行和并行收集器中，GC通过整堆扫描，来确定对象是否处于可达路径中。然而G1为了避免STW式的整堆扫描，在每个分区记录了一个已记忆集合(RSet)，内部类似一个反向指针，记录引用分区内对象的卡片索引。当要回收该分区时，通过扫描分区的RSet，来确定引用本分区内的对象是否存活，进而确定本分区内的对象存活情况。 事实上，并非所有的引用都需要记录在RSet中，如果一个分区确定需要扫描，那么无需RSet也可以无遗漏的得到引用关系。那么引用源自本分区的对象，当然不用落入RSet中；同时，G1 GC每次都会对年轻代进行整体收集，因此引用源自年轻代的对象，也不需要在RSet中记录。最后只有老年代的分区可能会有RSet记录，这些分区称为拥有RSet分区(an RSet’s owning region)。 2.3.3 Per Region Table (PRT)RSet在内部使用Per Region Table(PRT)记录分区的引用情况。由于RSet的记录要占用分区的空间，如果一个分区非常”受欢迎”，那么RSet占用的空间会上升，从而降低分区的可用空间。G1应对这个问题采用了改变RSet的密度的方式，在PRT中将会以三种模式记录引用： 稀少：直接记录引用对象的卡片索引 细粒度：记录引用对象的分区索引 粗粒度：只记录引用情况，每个分区对应一个比特位 由上可知，粗粒度的PRT只是记录了引用数量，需要通过整堆扫描才能找出所有引用，因此扫描速度也是最慢的。 2.4 收集集合 (CSet)CSet收集示意图 收集集合(CSet)代表每次GC暂停时回收的一系列目标分区。在任意一次收集暂停中，CSet所有分区都会被释放，内部存活的对象都会被转移到分配的空闲分区中。因此无论是年轻代收集，还是混合收集，工作的机制都是一致的。年轻代收集CSet只容纳年轻代分区，而混合收集会通过启发式算法，在老年代候选回收分区中，筛选出回收收益最高的分区添加到CSet中。 候选老年代分区的CSet准入条件，可以通过活跃度阈值-XX:G1MixedGCLiveThresholdPercent(默认85%)进行设置，从而拦截那些回收开销巨大的对象；同时，每次混合收集可以包含候选老年代分区，可根据CSet对堆的总大小占比-XX:G1OldCSetRegionThresholdPercent(默认10%)设置数量上限。 由上述可知，G1的收集都是根据CSet进行操作的，年轻代收集与混合收集没有明显的不同，最大的区别在于两种收集的触发条件。 2.4.1 年轻代收集集合 CSet of Young Collection应用线程不断活动后，年轻代空间会被逐渐填满。当JVM分配对象到Eden区域失败(Eden区已满)时，便会触发一次STW式的年轻代收集。在年轻代收集中，Eden分区存活的对象将被拷贝到Survivor分区；原有Survivor分区存活的对象，将根据任期阈值(tenuring threshold)分别晋升到PLAB中，新的survivor分区和老年代分区。而原有的年轻代分区将被整体回收掉。 同时，年轻代收集还负责维护对象的年龄(存活次数)，辅助判断老化(tenuring)对象晋升的时候是到Survivor分区还是到老年代分区。年轻代收集首先先将晋升对象尺寸总和、对象年龄信息维护到年龄表中，再根据年龄表、Survivor尺寸、Survivor填充容量-XX:TargetSurvivorRatio(默认50%)、最大任期阈值-XX:MaxTenuringThreshold(默认15)，计算出一个恰当的任期阈值，凡是超过任期阈值的对象都会被晋升到老年代。 2.4.2 混合收集集合 CSet of Mixed Collection年轻代收集不断活动后，老年代的空间也会被逐渐填充。当老年代占用空间超过整堆比IHOP阈值-XX:InitiatingHeapOccupancyPercent(默认45%)时，G1就会启动一次混合垃圾收集周期。为了满足暂停目标，G1可能不能一口气将所有的候选分区收集掉，因此G1可能会产生连续多次的混合收集与应用线程交替执行，每次STW的混合收集与年轻代收集过程相类似。 为了确定包含到年轻代收集集合CSet的老年代分区，JVM通过参数混合周期的最大总次数-XX:G1MixedGCCountTarget(默认8)、堆废物百分比-XX:G1HeapWastePercent(默认5%)。通过候选老年代分区总数与混合周期最大总次数，确定每次包含到CSet的最小分区数量；根据堆废物百分比，当收集达到参数时，不再启动新的混合收集。而每次添加到CSet的分区，则通过计算得到的GC效率进行安排。 2.4.3 并发标记算法（三色标记法）CMS和G1在并发标记时使用的是同一个算法：三色标记法，使用白灰黑三种颜色标记对象。白色是未标记；灰色自身被标记，引用的对象未标记；黑色自身与引用对象都已标记。 GC 开始前所有对象都是白色，GC 一开始所有根能够直达的对象被压到栈中，待搜索，此时颜色是灰色。然后灰色对象依次从栈中取出搜索子对象，子对象也会被涂为灰色，入栈。当其所有的子对象都涂为灰色之后该对象被涂为黑色。当 GC 结束之后灰色对象将全部没了，剩下黑色的为存活对象，白色的为垃圾。 2.4.4 漏标问题在remark过程中，黑色指向了白色，如果不对黑色重新扫描，则会漏标。会把白色D对象当作没有新引用指向从而回收掉。 并发标记过程中，Mutator删除了所有从灰色到白色的引用，会产生漏标。此时白色对象应该被回收 产生漏标问题的条件有两个： 黑色对象指向了白色对象 灰色对象指向白色对象的引用消失 所以要解决漏标问题，打破两个条件之一即可： 跟踪黑指向白的增加 incremental update：增量更新，关注引用的增加，把黑色重新标记为灰色，下次重新扫描属性。CMS采用该方法。 记录灰指向白的消失 SATB snapshot at the beginning：关注引用的删除，当灰–&gt;白消失时，要把这个 引用 推到GC的堆栈，保证白还能被GC扫描到。G1采用该方法。 为什么G1采用SATB而不用incremental update？ 因为采用incremental update把黑色重新标记为灰色后，之前扫描过的还要再扫描一遍，效率太低。G1有RSet与SATB相配合。Card Table里记录了RSet，RSet里记录了其他对象指向自己的引用，这样就不需要再扫描其他区域，只要扫描RSet就可以了。 也就是说 灰色–&gt;白色 引用消失时，如果没有 黑色–&gt;白色，引用会被push到堆栈，下次扫描时拿到这个引用，由于有RSet的存在，不需要扫描整个堆去查找指向白色的引用，效率比较高。SATB配合RSet浑然天成。 3. G1的活动周期3.1 G1垃圾收集活动汇总G1垃圾收集活动周期图 3.2 RSet的维护由于不能整堆扫描，又需要计算分区确切的活跃度，因此，G1需要一个增量式的完全标记并发算法，通过维护RSet，得到准确的分区引用信息。在G1中，RSet的维护主要来源两个方面：写栅栏(Write Barrier)和并发优化线程(Concurrence Refinement Threads) 3.2.1 栅栏Barrier栅栏代码示意 我们首先介绍一下栅栏(Barrier)的概念。栅栏是指在原生代码片段中，当某些语句被执行时，栅栏代码也会被执行。而G1主要在赋值语句中，使用写前栅栏(Pre-Write Barrrier)和写后栅栏(Post-Write Barrrier)。事实上，写栅栏的指令序列开销非常昂贵，应用吞吐量也会根据栅栏复杂度而降低。 写前栅栏 Pre-Write Barrrier 即将执行一段赋值语句时，等式左侧对象将修改引用到另一个对象，那么等式左侧对象原先引用的对象所在分区将因此丧失一个引用，那么JVM就需要在赋值语句生效之前，记录丧失引用的对象。JVM并不会立即维护RSet，而是通过批量处理，在将来RSet更新(见SATB)。 写后栅栏 Post-Write Barrrier 当执行一段赋值语句后，等式右侧对象获取了左侧对象的引用，那么等式右侧对象所在分区的RSet也应该得到更新。同样为了降低开销，写后栅栏发生后，RSet也不会立即更新，同样只是记录此次更新日志，在将来批量处理(见Concurrence Refinement Threads)。 3.2.2 起始快照算法Snapshot at the beginning (SATB)Taiichi Tuasa贡献的增量式完全并发标记算法起始快照算法(SATB)，主要针对标记-清除垃圾收集器的并发标记阶段，非常适合G1的分区块的堆结构，同时解决了CMS的主要烦恼：重新标记暂停时间长带来的潜在风险。 SATB会创建一个对象图，相当于堆的逻辑快照，从而确保并发标记阶段所有的垃圾对象都能通过快照被鉴别出来。当赋值语句发生时，应用将会改变了它的对象图，那么JVM需要记录被覆盖的对象。因此写前栅栏会在引用变更前，将值记录在SATB日志或缓冲区中。每个线程都会独占一个SATB缓冲区，初始有256条记录空间。当空间用尽时，线程会分配新的SATB缓冲区继续使用，而原有的缓冲去则加入全局列表中。最终在并发标记阶段，并发标记线程(Concurrent Marking Threads)在标记的同时，还会定期检查和处理全局缓冲区列表的记录，然后根据标记位图分片的标记位，扫描引用字段来更新RSet。此过程又称为并发标记&#x2F;SATB写前栅栏。 3.2.3 并发优化线程Concurrence Refinement ThreadsG1中使用基于Urs Hölzle的快速写栅栏，将栅栏开销缩减到2个额外的指令。栅栏将会更新一个card table type的结构来跟踪代间引用。 当赋值语句发生后，写后栅栏会先通过G1的过滤技术判断是否是跨分区的引用更新，并将跨分区更新对象的卡片加入缓冲区序列，即更新日志缓冲区或脏卡片队列。与SATB类似，一旦日志缓冲区用尽，则分配一个新的日志缓冲区，并将原来的缓冲区加入全局列表中。 并发优化线程(Concurrence Refinement Threads)，只专注扫描日志缓冲区记录的卡片来维护更新RSet，线程最大数目可通过-XX:G1ConcRefinementThreads(默认等于-XX:ParellelGCThreads)设置。并发优化线程永远是活跃的，一旦发现全局列表有记录存在，就开始并发处理。如果记录增长很快或者来不及处理，那么通过阈值-X:G1ConcRefinementGreenZone/-XX:G1ConcRefinementYellowZone/-XX:G1ConcRefinementRedZone，G1会用分层的方式调度，使更多的线程处理全局列表。如果并发优化线程也不能跟上缓冲区数量，则Mutator线程(Java应用线程)会挂起应用并被加进来帮助处理，直到全部处理完。因此，必须避免此类场景出现。 3.3 并发标记周期 Concurrent Marking Cycle并发标记周期是G1中非常重要的阶段，这个阶段将会为混合收集周期识别垃圾最多的老年代分区。整个周期完成根标记、识别所有(可能)存活对象，并计算每个分区的活跃度，从而确定GC效率等级。 当达到IHOP阈值-XX:InitiatingHeapOccupancyPercent(老年代占整堆比，默认45%)时，便会触发并发标记周期。整个并发标记周期将由初始标记(Initial Mark)、根分区扫描(Root Region Scanning)、并发标记(Concurrent Marking)、重新标记(Remark)、清除(Cleanup)几个阶段组成。其中，初始标记(随年轻代收集一起活动)、重新标记、清除是STW的，而并发标记如果来不及标记存活对象，则可能在并发标记过程中，G1又触发了几次年轻代收集。 3.3.1 并发标记线程 Concurrent Marking Threads并发标记位图过程 要标记存活的对象，每个分区都需要创建位图(Bitmap)信息来存储标记数据，来确定标记周期内被分配的对象。G1采用了两个位图Previous Bitmap、Next Bitmap，来存储标记数据，Previous位图存储上次的标记数据，Next位图在标记周期内不断变化更新，同时Previous位图的标记数据也越来越过时，当标记周期结束后Next位图便替换Previous位图，成为上次标记的位图。同时，每个分区通过顶部开始标记(TAMS)，来记录已标记过的内存范围。同样的，G1使用了两个顶部开始标记Previous TAMS(PTAMS)、Next TAMS(NTAMS)，记录已标记的范围。 在并发标记阶段，G1会根据参数-XX:ConcGCThreads(默认GC线程数的1&#x2F;4，即-XX:ParallelGCThreads/4)，分配并发标记线程(Concurrent Marking Threads)，进行标记活动。每个并发线程一次只扫描一个分区，并通过”手指”指针的方式优化获取分区。并发标记线程是爆发式的，在给定的时间段拼命干活，然后休息一段时间，再拼命干活。 每个并发标记周期，在初始标记STW的最后，G1会分配一个空的Next位图和一个指向分区顶部(Top)的NTAMS标记。Previous位图记录的上次标记数据，上次的标记位置，即PTAMS，在PTAMS与分区底部(Bottom)的范围内，所有的存活对象都已被标记。那么，在PTAMS与Top之间的对象都将是隐式存活(Implicitly Live)对象。在并发标记阶段，Next位图吸收了Previous位图的标记数据，同时每个分区都会有新的对象分配，则Top与NTAMS分离，前往更高的地址空间。在并发标记的一次标记中，并发标记线程将找出NTAMS与PTAMS之间的所有存活对象，将标记数据存储在Next位图中。同时，在NTAMS与Top之间的对象即成为已标记对象。如此不断地更新Next位图信息，并在清除阶段与Previous位图交换角色。 3.3.2 初始标记 Initial Mark初始标记(Initial Mark)负责标记所有能被直接可达的根对象(原生栈对象、全局对象、JNI对象)，根是对象图的起点，因此初始标记需要将Mutator线程(Java应用线程)暂停掉，也就是需要一个STW的时间段。事实上，当达到IHOP阈值时，G1并不会立即发起并发标记周期，而是等待下一次年轻代收集，利用年轻代收集的STW时间段，完成初始标记，这种方式称为借道(Piggybacking)。在初始标记暂停中，分区的NTAMS都被设置到分区顶部Top，初始标记是并发执行，直到所有的分区处理完。 3.3.3 根分区扫描 Root Region Scanning在初始标记暂停结束后，年轻代收集也完成的对象复制到Survivor的工作，应用线程开始活跃起来。此时为了保证标记算法的正确性，所有新复制到Survivor分区的对象，都需要被扫描并标记成根，这个过程称为根分区扫描(Root Region Scanning)，同时扫描的Suvivor分区也被称为根分区(Root Region)。根分区扫描必须在下一次年轻代垃圾收集启动前完成(并发标记的过程中，可能会被若干次年轻代垃圾收集打断)，因为每次GC会产生新的存活对象集合。 3.3.4 并发标记 Concurrent Marking和应用线程并发执行，并发标记线程在并发标记阶段启动，由参数-XX:ConcGCThreads(默认GC线程数的1&#x2F;4，即-XX:ParallelGCThreads/4)控制启动数量，每个线程每次只扫描一个分区，从而标记出存活对象图。在这一阶段会处理Previous&#x2F;Next标记位图，扫描标记对象的引用字段。同时，并发标记线程还会定期检查和处理STAB全局缓冲区列表的记录，更新对象引用信息。参数-XX:+ClassUnloadingWithConcurrentMark会开启一个优化，如果一个类不可达(不是对象不可达)，则在重新标记阶段，这个类就会被直接卸载。所有的标记任务必须在堆满前就完成扫描，如果并发标记耗时很长，那么有可能在并发标记过程中，又经历了几次年轻代收集。如果堆满前没有完成标记任务，则会触发担保机制，经历一次长时间的串行Full GC。 3.3.5 存活数据计算 Live Data Accounting存活数据计算(Live Data Accounting)是标记操作的附加产物，只要一个对象被标记，同时会被计算字节数，并计入分区空间。只有NTAMS以下的对象会被标记和计算，在标记周期的最后，Next位图将被清空，等待下次标记周期。 3.3.6 重新标记 Remark重新标记(Remark)是最后一个标记阶段。在该阶段中，G1需要一个暂停的时间，去处理剩下的SATB日志缓冲区和所有更新，找出所有未被访问的存活对象，同时安全完成存活数据计算。这个阶段也是并行执行的，通过参数-XX:ParallelGCThread可设置GC暂停时可用的GC线程数。同时，引用处理也是重新标记阶段的一部分，所有重度使用引用对象(弱引用、软引用、虚引用、最终引用)的应用都会在引用处理上产生开销。 3.3.7 清除 Cleanup紧挨着重新标记阶段的清除(Clean)阶段也是STW的。Previous&#x2F;Next标记位图、以及PTAMS&#x2F;NTAMS，都会在清除阶段交换角色。清除阶段主要执行以下操作： RSet梳理，启发式算法会根据活跃度和RSet尺寸对分区定义不同等级，同时RSet数理也有助于发现无用的引用。参数-XX:+PrintAdaptiveSizePolicy可以开启打印启发式算法决策细节； 整理堆分区，为混合收集周期识别回收收益高(基于释放空间和暂停目标)的老年代分区集合； 识别所有空闲分区，即发现无存活对象的分区。该分区可在清除阶段直接回收，无需等待下次收集周期。 3.4 年轻代收集&#x2F;混合收集周期年轻代收集和混合收集周期，是G1回收空间的主要活动。当应用运行开始时，堆内存可用空间还比较大，只会在年轻代满时，触发年轻代收集；随着老年代内存增长，当到达IHOP阈值-XX:InitiatingHeapOccupancyPercent(老年代占整堆比，默认45%)时，G1开始着手准备收集老年代空间。首先经历并发标记周期，识别出高收益的老年代分区，前文已述。但随后G1并不会马上开始一次混合收集，而是让应用线程先运行一段时间，等待触发一次年轻代收集。在这次STW中，G1将保准整理混合收集周期。接着再次让应用线程运行，当接下来的几次年轻代收集时，将会有老年代分区加入到CSet中，即触发混合收集，这些连续多次的混合收集称为混合收集周期(Mixed Collection Cycle)。 3.4.1 GC工作线程数GC工作线程数 -XX:ParallelGCThreads JVM可以通过参数-XX:ParallelGCThreads进行指定GC工作的线程数量。参数-XX:ParallelGCThreads默认值并不是固定的，而是根据当前的CPU资源进行计算。如果用户没有指定，且CPU小于等于8，则默认与CPU核数相等；若CPU大于8，则默认JVM会经过计算得到一个小于CPU核数的线程数；当然也可以人工指定与CPU核数相等。 3.4.2 年轻代收集 Young Collection每次收集过程中，既有并行执行的活动，也有串行执行的活动，但都可以是多线程的。在并行执行的任务中，如果某个任务过重，会导致其他线程在等待某项任务的处理，需要对这些地方进行优化。 并行活动 外部根分区扫描 Ext Root Scanning：此活动对堆外的根(JVM系统目录、VM数据结构、JNI线程句柄、硬件寄存器、全局变量、线程对栈根)进行扫描，发现那些没有加入到暂停收集集合CSet中的对象。如果系统目录(单根)拥有大量加载的类，最终可能其他并行活动结束后，该活动依然没有结束而带来的等待时间。 更新已记忆集合 Update RS：并发优化线程会对脏卡片的分区进行扫描更新日志缓冲区来更新RSet，但只会处理全局缓冲列表。作为补充，所有被记录但是还没有被优化线程处理的剩余缓冲区，会在该阶段处理，变成已处理缓冲区(Processed Buffers)。为了限制花在更新RSet的时间，可以设置暂停占用百分比-XX:G1RSetUpdatingPauseTimePercent(默认10%，即-XX:MaxGCPauseMills&#x2F;10)。值得注意的是，如果更新日志缓冲区更新的任务不降低，单纯地减少RSet的更新时间，会导致暂停中被处理的缓冲区减少，将日志缓冲区更新工作推到并发优化线程上，从而增加对Java应用线程资源的争夺。 RSet扫描 Scan RS：在收集当前CSet之前，考虑到分区外的引用，必须扫描CSet分区的RSet。如果RSet发生粗化，则会增加RSet的扫描时间。开启诊断模式-XX:UnlockDiagnosticVMOptions后，通过参数-XX:+G1SummarizeRSetStats可以确定并发优化线程是否能够及时处理更新日志缓冲区，并提供更多的信息，来帮助为RSet粗化总数提供窗口。参数-XX：G1SummarizeRSetStatsPeriod&#x3D;n可设置RSet的统计周期，即经历多少此GC后进行一次统计 代码根扫描 Code Root Scanning：对代码根集合进行扫描，扫描JVM编译后代码Native Method的引用信息(nmethod扫描)，进行RSet扫描。事实上，只有CSet分区中的RSet有强代码根时，才会做nmethod扫描，查找对CSet的引用。 转移和回收 Object Copy：通过选定的CSet以及CSet分区完整的引用集，将执行暂停时间的主要部分：CSet分区存活对象的转移、CSet分区空间的回收。通过工作窃取机制来负载均衡地选定复制对象的线程，并且复制和扫描对象被转移的存活对象将拷贝到每个GC线程分配缓冲区GCLAB。G1会通过计算，预测分区复制所花费的时间，从而调整年轻代的尺寸。 终止 Termination：完成上述任务后，如果任务队列已空，则工作线程会发起终止要求。如果还有其他线程继续工作，空闲的线程会通过工作窃取机制尝试帮助其他线程处理。而单独执行根分区扫描的线程，如果任务过重，最终会晚于终止。 GC外部的并行活动 GC Worker Other：该部分并非GC的活动，而是JVM的活动导致占用了GC暂停时间(例如JNI编译)。 串行活动 代码根更新 Code Root Fixup：根据转移对象更新代码根。 代码根清理 Code Root Purge：清理代码根集合表。 清除全局卡片标记 Clear CT：在任意收集周期会扫描CSet与RSet记录的PRT，扫描时会在全局卡片表中进行标记，防止重复扫描。在收集周期的最后将会清除全局卡片表中的已扫描标志。 选择下次收集集合 Choose CSet：该部分主要用于并发标记周期后的年轻代收集、以及混合收集中，在这些收集过程中，由于有老年代候选分区的加入，往往需要对下次收集的范围做出界定；但单纯的年轻代收集中，所有收集的分区都会被收集，不存在选择。 引用处理 Ref Proc：主要针对软引用、弱引用、虚引用、final引用、JNI引用。当Ref Proc占用时间过多时，可选择使用参数-XX:ParallelRefProcEnabled激活多线程引用处理。G1希望应用能小心使用软引用，因为软引用会一直占据内存空间直到空间耗尽时被Full GC回收掉；即使未发生Full GC，软引用对内存的占用，也会导致GC次数的增加。 引用排队 Ref Enq：此项活动可能会导致RSet的更新，此时会通过记录日志，将关联的卡片标记为脏卡片。 卡片重新脏化 Redirty Cards：重新脏化卡片。 回收空闲巨型分区 Humongous Reclaim：G1做了一个优化：通过查看所有根对象以及年轻代分区的RSet，如果确定RSet中巨型对象没有任何引用，则说明G1发现了一个不可达的巨型对象，该对象分区会被回收。 释放分区 Free CSet：回收CSet分区的所有空间，并加入到空闲分区中。 其他活动 Other：GC中可能还会经历其他耗时很小的活动，如修复JNI句柄等。 3.5 并发标记周期后的年轻代收集 Young Collection Following Concurrent Marking Cycle当G1发起并发标记周期之后，并不会马上开始混合收集。G1会先等待下一次年轻代收集，然后在该收集阶段中，确定下次混合收集的CSet(Choose CSet)。 3.5.1 混合收集周期 Mixed Collection Cycle单次的混合收集与年轻代收集并无二致。根据暂停目标，老年代的分区可能不能一次暂停收集中被处理完，G1会发起连续多次的混合收集，称为混合收集周期(Mixed Collection Cycle)。G1会计算每次加入到CSet中的分区数量、混合收集进行次数，并且在上次的年轻代收集、以及接下来的混合收集中，G1会确定下次加入CSet的分区集(Choose CSet)，并且确定是否结束混合收集周期。 3.5.2 转移失败的担保机制 Full GC转移失败(Evacuation Failure)是指当G1无法在堆空间中申请新的分区时，G1便会触发担保机制，执行一次STW式的、单线程的Full GC。Full GC会对整堆做标记清除和压缩，最后将只包含纯粹的存活对象。参数-XX:G1ReservePercent(默认10%)可以保留空间，来应对晋升模式下的异常情况，最大占用整堆50%，更大也无意义。 G1在以下场景中会触发Full GC，同时会在日志中记录to-space-exhausted以及Evacuation Failure： 从年轻代分区拷贝存活对象时，无法找到可用的空闲分区 从老年代分区转移存活对象时，无法找到可用的空闲分区 分配巨型对象时在老年代无法找到足够的连续分区 由于G1的应用场合往往堆内存都比较大，所以Full GC的收集代价非常昂贵，应该避免Full GC的发生。 4. 总结G1是一款非常优秀的垃圾收集器，不仅适合堆内存大的应用，同时也简化了调优的工作。通过主要的参数初始和最大堆空间、以及最大容忍的GC暂停目标，就能得到不错的性能；同时，我们也看到G1对内存空间的浪费较高，但通过首先收集尽可能多的垃圾(Garbage First)的设计原则，可以及时发现过期对象，从而让内存占用处于合理的水平。 虽然G1也有类似CMS的收集动作：初始标记、并发标记、重新标记、清除、转移回收，并且也以一个串行收集器做担保机制，但单纯地以类似前三种的过程描述显得并不是很妥当。 G1的设计原则是”首先收集尽可能多的垃圾(Garbage First)”。因此，G1并不会等内存耗尽(串行、并行)或者快耗尽(CMS)的时候开始垃圾收集，而是在内部采用了启发式算法，在老年代找出具有高收集收益的分区进行收集。同时G1可以根据用户设置的暂停时间目标自动调整年轻代和总堆大小，暂停目标越短年轻代空间越小、总空间就越大； G1采用内存分区(Region)的思路，将内存划分为一个个相等大小的内存分区，回收时则以分区为单位进行回收，存活的对象复制到另一个空闲分区中。由于都是以相等大小的分区为单位进行操作，因此G1天然就是一种压缩方案(局部压缩)； G1虽然也是分代收集器，但整个内存分区不存在物理上的年轻代与老年代的区别，也不需要完全独立的survivor(to space)堆做复制准备。G1只有逻辑上的分代概念，或者说每个分区都可能随G1的运行在不同代之间前后切换； G1的收集都是STW的，但年轻代和老年代的收集界限比较模糊，采用了混合(mixed)收集的方式。即每次收集既可能只收集年轻代分区(年轻代收集)，也可能在收集年轻代的同时，包含部分老年代分区(混合收集)，这样即使堆内存很大时，也可以限制收集范围，从而降低停顿。 参考资料 Charlie H, Monica B, Poonam P, Bengt R. Java Performance Companion 周志明. 深入理解JVM虚拟机","tags":["Java","JVM","GC","G1"],"categories":["Java","JVM","GC"]},{"title":"8.GC - Java 垃圾回收基础知识","path":"/2023/12/27/8-GC-Java-垃圾回收基础知识/","content":"垃圾收集主要是针对堆和方法区进行；程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后也会消失，因此不需要对这三个区域进行垃圾回收。 判断一个对象是否可被回收1. 引用计数算法给对象添加一个引用计数器，当对象增加一个引用时计数器加 1，引用失效时计数器减 1。引用计数为 0 的对象可被回收。 两个对象出现循环引用的情况下，此时引用计数器永远不为 0，导致无法对它们进行回收。 正因为循环引用的存在，因此 Java 虚拟机不使用引用计数算法。 1234567891011public class ReferenceCountingGC &#123; public Object instance = null; public static void main(String[] args) &#123; ReferenceCountingGC objectA = new ReferenceCountingGC(); ReferenceCountingGC objectB = new ReferenceCountingGC(); objectA.instance = objectB; objectB.instance = objectA; &#125;&#125; 2. 可达性分析算法通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。 Java 虚拟机使用该算法来判断对象是否可被回收，在 Java 中 GC Roots 一般包含以下内容: 虚拟机栈中引用的对象 本地方法栈中引用的对象 方法区中类静态属性引用的对象 方法区中的常量引用的对象 3. 方法区的回收因为方法区主要存放永久代对象，而永久代对象的回收率比新生代低很多，因此在方法区上进行回收性价比不高。 主要是对常量池的回收和对类的卸载。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载功能，以保证不会出现内存溢出。 类的卸载条件很多，需要满足以下三个条件，并且满足了也不一定会被卸载: 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的 ClassLoader 已经被回收。 该类对应的 Class 对象没有在任何地方被引用，也就无法在任何地方通过反射访问该类方法。 可以通过 -Xnoclassgc 参数来控制是否对类进行卸载。 4. finalize()finalize() 类似 C++ 的析构函数，用来做关闭外部资源等工作。但是 try-finally 等方式可以做的更好，并且该方法运行代价高昂，不确定性大，无法保证各个对象的调用顺序，因此最好不要使用。 当一个对象可被回收时，如果需要执行该对象的 finalize() 方法，那么就有可能通过在该方法中让对象重新被引用，从而实现自救。自救只能进行一次，如果回收的对象之前调用了 finalize() 方法自救，后面回收时不会调用 finalize() 方法。 引用类型无论是通过引用计算算法判断对象的引用数量，还是通过可达性分析算法判断对象是否可达，判定对象是否可被回收都与引用有关。 Java 具有四种强度不同的引用类型。 1. 强引用被强引用关联的对象不会被回收。 使用 new 一个新对象的方式来创建强引用。 1Object obj = new Object(); 2. 软引用被软引用关联的对象只有在内存不够的情况下才会被回收。 使用 SoftReference 类来创建软引用。 123Object obj = new Object();SoftReference&lt;Object&gt; sf = new SoftReference&lt;Object&gt;(obj);obj = null; // 使对象只被软引用关联 3. 弱引用被弱引用关联的对象一定会被回收，也就是说它只能存活到下一次垃圾回收发生之前。 使用 WeakReference 类来实现弱引用。 123Object obj = new Object();WeakReference&lt;Object&gt; wf = new WeakReference&lt;Object&gt;(obj);obj = null; 4. 虚引用又称为幽灵引用或者幻影引用。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用取得一个对象。 为一个对象设置虚引用关联的唯一目的就是能在这个对象被回收时收到一个系统通知。 使用 PhantomReference 来实现虚引用。 123Object obj = new Object();PhantomReference&lt;Object&gt; pf = new PhantomReference&lt;Object&gt;(obj);obj = null; 垃圾回收算法1. 标记 - 清除 将存活的对象进行标记，然后清理掉未被标记的对象。 不足: 标记和清除过程效率都不高； 会产生大量不连续的内存碎片，导致无法给大对象分配内存。 2. 标记 - 整理 让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 3. 复制 将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理。 主要不足是只使用了内存的一半。 现在的商业虚拟机都采用这种收集算法来回收新生代，但是并不是将新生代划分为大小相等的两块，而是分为一块较大的 Eden 空间和两块较小的 Survivor 空间，每次使用 Eden 空间和其中一块 Survivor。在回收时，将 Eden 和 Survivor 中还存活着的对象一次性复制到另一块 Survivor 空间上，最后清理 Eden 和使用过的那一块 Survivor。 HotSpot 虚拟机的 Eden 和 Survivor 的大小比例默认为 8:1，保证了内存的利用率达到 90%。如果每次回收有多于 10% 的对象存活，那么一块 Survivor 空间就不够用了，此时需要依赖于老年代进行分配担保，也就是借用老年代的空间存储放不下的对象。 4. 分代收集现在的商业虚拟机采用分代收集算法，它根据对象存活周期将内存划分为几块，不同块采用适当的收集算法。 一般将堆分为新生代和老年代。 新生代使用: 复制算法 老年代使用: 标记 - 清除 或者 标记 - 整理 算法 垃圾收集器 以上是 HotSpot 虚拟机中的 7 个垃圾收集器，连线表示垃圾收集器可以配合使用。 单线程与多线程: 单线程指的是垃圾收集器只使用一个线程进行收集，而多线程使用多个线程； 串行与并行: 串行指的是垃圾收集器与用户程序交替执行，这意味着在执行垃圾收集的时候需要停顿用户程序；并形指的是垃圾收集器和用户程序同时执行。除了 CMS 和 G1 之外，其它垃圾收集器都是以串行的方式执行。 1. Serial 收集器 Serial 翻译为串行，也就是说它以串行的方式执行。 它是单线程的收集器，只会使用一个线程进行垃圾收集工作。 它的优点是简单高效，对于单个 CPU 环境来说，由于没有线程交互的开销，因此拥有最高的单线程收集效率。 它是 Client 模式下的默认新生代收集器，因为在用户的桌面应用场景下，分配给虚拟机管理的内存一般来说不会很大。Serial 收集器收集几十兆甚至一两百兆的新生代停顿时间可以控制在一百多毫秒以内，只要不是太频繁，这点停顿是可以接受的。 2. ParNew 收集器 它是 Serial 收集器的多线程版本。 是 Server 模式下的虚拟机首选新生代收集器，除了性能原因外，主要是因为除了 Serial 收集器，只有它能与 CMS 收集器配合工作。 默认开启的线程数量与 CPU 数量相同，可以使用 -XX:ParallelGCThreads 参数来设置线程数。 3. Parallel Scavenge 收集器与 ParNew 一样是多线程收集器。 其它收集器关注点是尽可能缩短垃圾收集时用户线程的停顿时间，而它的目标是达到一个可控制的吞吐量，它被称为“吞吐量优先”收集器。这里的吞吐量指 CPU 用于运行用户代码的时间占总时间的比值。 停顿时间越短就越适合需要与用户交互的程序，良好的响应速度能提升用户体验。而高吞吐量则可以高效率地利用 CPU 时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。 缩短停顿时间是以牺牲吞吐量和新生代空间来换取的: 新生代空间变小，垃圾回收变得频繁，导致吞吐量下降。 可以通过一个开关参数打开 GC 自适应的调节策略(GC Ergonomics)，就不需要手动指定新生代的大小(-Xmn)、Eden 和 Survivor 区的比例、晋升老年代对象年龄等细节参数了。虚拟机会根据当前系统的运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或者最大的吞吐量。 4. Serial Old 收集器 是 Serial 收集器的老年代版本，也是给 Client 模式下的虚拟机使用。如果用在 Server 模式下，它有两大用途: 在 JDK 1.5 以及之前版本(Parallel Old 诞生以前)中与 Parallel Scavenge 收集器搭配使用。 作为 CMS 收集器的后备预案，在并发收集发生 Concurrent Mode Failure 时使用。 5. Parallel Old 收集器 是 Parallel Scavenge 收集器的老年代版本。 在注重吞吐量以及 CPU 资源敏感的场合，都可以优先考虑 Parallel Scavenge 加 Parallel Old 收集器。 6. CMS 收集器 CMS(Concurrent Mark Sweep)，Mark Sweep 指的是标记 - 清除算法。 分为以下四个流程: 初始标记: 仅仅只是标记一下 GC Roots 能直接关联到的对象，速度很快，需要停顿。 并发标记: 进行 GC Roots Tracing 的过程，它在整个回收过程中耗时最长，不需要停顿。 重新标记: 为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，需要停顿。 并发清除: 不需要停顿。 在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。 具有以下缺点: 吞吐量低: 低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。 无法处理浮动垃圾，可能出现 Concurrent Mode Failure。浮动垃圾是指并发清除阶段由于用户线程继续运行而产生的垃圾，这部分垃圾只能到下一次 GC 时才能进行回收。由于浮动垃圾的存在，因此需要预留出一部分内存，意味着 CMS 收集不能像其它收集器那样等待老年代快满的时候再回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。 标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。 7. G1 收集器G1(Garbage-First)，它是一款面向服务端应用的垃圾收集器，在多 CPU 和大内存的场景下有很好的性能。HotSpot 开发团队赋予它的使命是未来可以替换掉 CMS 收集器。 堆被分为新生代和老年代，其它收集器进行收集的范围都是整个新生代或者老年代，而 G1 可以直接对新生代和老年代一起回收。 G1 把堆划分成多个大小相等的独立区域(Region)，新生代和老年代不再物理隔离。 通过引入 Region 的概念，从而将原来的一整块内存空间划分成多个的小空间，使得每个小空间可以单独进行垃圾回收。这种划分方法带来了很大的灵活性，使得可预测的停顿时间模型成为可能。通过记录每个 Region 垃圾回收时间以及回收所获得的空间(这两个值是通过过去回收的经验获得)，并维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region。 每个 Region 都有一个 Remembered Set，用来记录该 Region 对象的引用对象所在的 Region。通过使用 Remembered Set，在做可达性分析的时候就可以避免全堆扫描。 如果不计算维护 Remembered Set 的操作，G1 收集器的运作大致可划分为以下几个步骤: 初始标记 并发标记 最终标记: 为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程的 Remembered Set Logs 里面，最终标记阶段需要把 Remembered Set Logs 的数据合并到 Remembered Set 中。这阶段需要停顿线程，但是可并行执行。 筛选回收: 首先对各个 Region 中的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划。此阶段其实也可以做到与用户程序一起并发执行，但是因为只回收一部分 Region，时间是用户可控制的，而且停顿用户线程将大幅度提高收集效率。 具备如下特点: 空间整合: 整体来看是基于“标记 - 整理”算法实现的收集器，从局部(两个 Region 之间)上来看是基于“复制”算法实现的，这意味着运行期间不会产生内存空间碎片。 可预测的停顿: 能让使用者明确指定在一个长度为 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒。 更详细内容请参考: Getting Started with the G1 Garbage Collector 内存分配与回收策略Minor GC、Major GC、Full GCJVM 在进行 GC 时，并非每次都对堆内存（新生代、老年代；方法区）区域一起回收的，大部分时候回收的都是指新生代。 针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC） 部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： 新生代收集（Minor GC&#x2F;Young GC）：只是新生代的垃圾收集 老年代收集（Major GC&#x2F;Old GC）：只是老年代的垃圾收集 目前，只有 CMS GC 会有单独收集老年代的行为 很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 目前只有 G1 GC 会有这种行为 整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾 内存分配策略1. 对象优先在 Eden 分配大多数情况下，对象在新生代 Eden 区分配，当 Eden 区空间不够时，发起 Minor GC。 2. 大对象直接进入老年代大对象是指需要连续内存空间的对象，最典型的大对象是那种很长的字符串以及数组。 经常出现大对象会提前触发垃圾收集以获取足够的连续空间分配给大对象。 -XX:PretenureSizeThreshold，大于此值的对象直接在老年代分配，避免在 Eden 区和 Survivor 区之间的大量内存复制。 3. 长期存活的对象进入老年代为对象定义年龄计数器，对象在 Eden 出生并经过 Minor GC 依然存活，将移动到 Survivor 中，年龄就增加 1 岁，增加到一定年龄则移动到老年代中。 -XX:MaxTenuringThreshold 用来定义年龄的阈值。 4. 动态对象年龄判定虚拟机并不是永远地要求对象的年龄必须达到 MaxTenuringThreshold 才能晋升老年代，如果在 Survivor 中相同年龄所有对象大小的总和大于 Survivor 空间的一半，则年龄大于或等于该年龄的对象可以直接进入老年代，无需等到 MaxTenuringThreshold 中要求的年龄。 5. 空间分配担保在发生 Minor GC 之前，虚拟机先检查老年代最大可用的连续空间是否大于新生代所有对象总空间，如果条件成立的话，那么 Minor GC 可以确认是安全的。 如果不成立的话虚拟机会查看 HandlePromotionFailure 设置值是否允许担保失败，如果允许那么就会继续检查老年代最大可用的连续空间是否大于历次晋升到老年代对象的平均大小，如果大于，将尝试着进行一次 Minor GC；如果小于，或者 HandlePromotionFailure 设置不允许冒险，那么就要进行一次 Full GC。 Full GC 的触发条件对于 Minor GC，其触发条件非常简单，当 Eden 空间满时，就将触发一次 Minor GC。而 Full GC 则相对复杂，有以下条件: 1. 调用 System.gc()只是建议虚拟机执行 Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。 2. 老年代空间不足老年代空间不足的常见场景为前文所讲的大对象直接进入老年代、长期存活的对象进入老年代等。 为了避免以上原因引起的 Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过 -Xmn 虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold 调大对象进入老年代的年龄，让对象在新生代多存活一段时间。 3. 空间分配担保失败使用复制算法的 Minor GC 需要老年代的内存空间作担保，如果担保失败会执行一次 Full GC。具体内容请参考上面的第五小节。 4. JDK 1.7 及以前的永久代空间不足在 JDK 1.7 及以前，HotSpot 虚拟机中的方法区是用永久代实现的，永久代中存放的为一些 Class 的信息、常量、静态变量等数据。 当系统中要加载的类、反射的类和调用的方法较多时，永久代可能会被占满，在未配置为采用 CMS GC 的情况下也会执行 Full GC。如果经过 Full GC 仍然回收不了，那么虚拟机会抛出 java.lang.OutOfMemoryError。 为避免以上原因引起的 Full GC，可采用的方法为增大永久代空间或转为使用 CMS GC。 5. Concurrent Mode Failure执行 CMS GC 的过程中同时有对象要放入老年代，而此时老年代空间不足(可能是 GC 过程中浮动垃圾过多导致暂时性的空间不足)，便会报 Concurrent Mode Failure 错误，并触发 Full GC。 参考 GC算法 垃圾收集器 Java GC 分析 [Java应用频繁FullGC分析","tags":["Java","JVM","GC"],"categories":["Java","JVM","GC"]},{"title":"6.JVM 基础 - Java 内存模型引入","path":"/2023/12/27/6-JVM-基础-Java-内存模型引入/","content":"很多人都无法区分Java内存模型和JVM内存结构，以及Java内存模型与物理内存之间的关系。本文从堆栈角度引入JMM，然后介绍JMM和物理内存之间的关系, 为后面JMM详解, JVM 内存结构详解, Java 对象模型详解等铺垫。 JMM引入从堆栈说起JVM内部使用的Java内存模型在线程栈和堆之间划分内存。 此图从逻辑角度说明了Java内存模型： 堆栈里面放了什么?线程堆栈还包含正在执行的每个方法的所有局部变量(调用堆栈上的所有方法)。 线程只能访问它自己的线程堆栈。 由线程创建的局部变量对于创建它的线程以外的所有其他线程是不可见的。 即使两个线程正在执行完全相同的代码，两个线程仍将在每个自己的线程堆栈中创建该代码的局部变量。 因此，每个线程都有自己的每个局部变量的版本。 基本类型的所有局部变量(boolean，byte，short，char，int，long，float，double)完全存储在线程堆栈中，因此对其他线程不可见。 一个线程可以将一个基本类型变量的副本传递给另一个线程，但它不能共享原始局部变量本身。 堆包含了在Java应用程序中创建的所有对象，无论创建该对象的线程是什么。 这包括基本类型的包装类(例如Byte，Integer，Long等)。 无论是创建对象并将其分配给局部变量，还是创建为另一个对象的成员变量，该对象仍然存储在堆上。 局部变量可以是基本类型，在这种情况下，它完全保留在线程堆栈上。 局部变量也可以是对象的引用。 在这种情况下，引用(局部变量)存储在线程堆栈中，但是对象本身存储在堆(Heap)上。 对象的成员变量与对象本身一起存储在堆上。 当成员变量是基本类型时，以及它是对象的引用时都是如此。 静态类变量也与类定义一起存储在堆上。 线程栈如何访问堆上对象?所有具有对象引用的线程都可以访问堆上的对象。 当一个线程有权访问一个对象时，它也可以访问该对象的成员变量。 如果两个线程同时在同一个对象上调用一个方法，它们都可以访问该对象的成员变量，但每个线程都有自己的局部变量副本。 两个线程有一组局部变量。 其中一个局部变量(局部变量2)指向堆上的共享对象(对象3)。 两个线程各自对同一对象具有不同的引用。 它们的引用是局部变量，因此存储在每个线程的线程堆栈中(在每个线程堆栈上)。 但是，这两个不同的引用指向堆上的同一个对象。 注意共享对象(对象3)如何将对象2和对象4作为成员变量引用(由对象3到对象2和对象4的箭头所示)。 通过对象3中的这些成员变量引用，两个线程可以访问对象2和对象4. 该图还显示了一个局部变量，该变量指向堆上的两个不同对象。 在这种情况下，引用指向两个不同的对象(对象1和对象5)，而不是同一个对象。 理论上，如果两个线程都引用了两个对象，则两个线程都可以访问对象1和对象5。 但是在上图中，每个线程只引用了两个对象中的一个。 线程栈访问堆示例那么，什么样的Java代码可以导致上面的内存图? 好吧，代码就像下面的代码一样简单： 12345678910111213141516171819202122232425262728293031323334353637383940public class MyRunnable implements Runnable() &#123; public void run() &#123; methodOne(); &#125; public void methodOne() &#123; int localVariable1 = 45; MySharedObject localVariable2 = MySharedObject.sharedInstance; //... do more with local variables. methodTwo(); &#125; public void methodTwo() &#123; Integer localVariable1 = new Integer(99); //... do more with local variable. &#125;&#125;public class MySharedObject &#123; //static variable pointing to instance of MySharedObject public static final MySharedObject sharedInstance = new MySharedObject(); //member variables pointing to two objects on the heap public Integer object2 = new Integer(22); public Integer object4 = new Integer(44); public long member1 = 12345; public long member1 = 67890;&#125; 如果两个线程正在执行run()方法，则前面显示的图表将是结果。 run()方法调用methodOne()，methodOne()调用methodTwo()。 methodOne()声明一个局部基本类型变量(类型为int的localVariable1)和一个局部变量，它是一个对象引用(localVariable2)。 执行methodOne()的每个线程将在各自的线程堆栈上创建自己的localVariable1和localVariable2副本。 localVariable1变量将完全相互分离，只存在于每个线程的线程堆栈中。 一个线程无法看到另一个线程对其localVariable1副本所做的更改。 执行methodOne()的每个线程也将创建自己的localVariable2副本。 但是，localVariable2的两个不同副本最终都指向堆上的同一个对象。 代码将localVariable2设置为指向静态变量引用的对象。 静态变量只有一个副本，此副本存储在堆上。 因此，localVariable2的两个副本最终都指向静态变量指向的MySharedObject的同一个实例。 MySharedObject实例也存储在堆上。 它对应于上图中的对象3。 注意MySharedObject类还包含两个成员变量。 成员变量本身与对象一起存储在堆上。 两个成员变量指向另外两个Integer对象。 这些Integer对象对应于上图中的Object 2和Object 4。 另请注意methodTwo()如何创建名为localVariable1的局部变量。 此局部变量是对Integer对象的对象引用。 该方法将localVariable1引用设置为指向新的Integer实例。 localVariable1引用将存储在执行methodTwo()的每个线程的一个副本中。 实例化的两个Integer对象将存储在堆上，但由于该方法每次执行该方法时都会创建一个新的Integer对象，因此执行此方法的两个线程将创建单独的Integer实例。 在methodTwo()中创建的Integer对象对应于上图中的Object 1和Object 5。 另请注意类型为long的MySharedObject类中的两个成员变量，它们是基本类型。 由于这些变量是成员变量，因此它们仍与对象一起存储在堆上。 只有局部变量存储在线程堆栈中。 JMM与硬件内存结构关系硬件内存结构简介现代硬件内存架构与内部Java内存模型略有不同。 了解硬件内存架构也很重要，以了解Java内存模型如何与其一起工作。 本节介绍了常见的硬件内存架构，后面的部分将介绍Java内存模型如何与其配合使用。 这是现代计算机硬件架构的简化图： 现代计算机通常有2个或更多CPU。 其中一些CPU也可能有多个内核。 关键是，在具有2个或更多CPU的现代计算机上，可以同时运行多个线程。 每个CPU都能够在任何给定时间运行一个线程。 这意味着如果您的Java应用程序是多线程的，线程真的在可能同时运行. 每个CPU基本上都包含一组在CPU内存中的寄存器。 CPU可以在这些寄存器上执行的操作比在主存储器中对变量执行的操作快得多。 这是因为CPU可以比访问主存储器更快地访问这些寄存器。 每个CPU还可以具有CPU高速缓存存储器层。 事实上，大多数现代CPU都有一些大小的缓存存储层。 CPU可以比主存储器更快地访问其高速缓存存储器，但通常不会像访问其内部寄存器那样快。 因此，CPU高速缓存存储器介于内部寄存器和主存储器的速度之间。 某些CPU可能有多个缓存层(级别1和级别2)，但要了解Java内存模型如何与内存交互，这一点并不重要。 重要的是要知道CPU可以有某种缓存存储层。 计算机还包含主存储区(RAM)。 所有CPU都可以访问主内存。 主存储区通常比CPU的高速缓存存储器大得多。同时访问速度也就较慢. 通常，当CPU需要访问主存储器时，它会将部分主存储器读入其CPU缓存。 它甚至可以将部分缓存读入其内部寄存器，然后对其执行操作。 当CPU需要将结果写回主存储器时，它会将值从其内部寄存器刷新到高速缓冲存储器，并在某些时候将值刷新回主存储器。 JMM与硬件内存连接 - 引入如前所述，Java内存模型和硬件内存架构是不同的。 硬件内存架构不区分线程堆栈和堆。 在硬件上，线程堆栈和堆都位于主存储器中。 线程堆栈和堆的一部分有时可能存在于CPU高速缓存和内部CPU寄存器中。 这在图中说明： 当对象和变量可以存储在计算机的各种不同存储区域中时，可能会出现某些问题。 两个主要问题是： Visibility of thread updates (writes) to shared variables. Race conditions when reading, checking and writing shared variables. 以下各节将解释这两个问题。 JMM与硬件内存连接 - 对象共享后的可见性如果两个或多个线程共享一个对象，而没有正确使用volatile声明或同步，则一个线程对共享对象的更新可能对其他线程不可见。 想象一下，共享对象最初存储在主存储器中。 然后，在CPU上运行的线程将共享对象读入其CPU缓存中。 它在那里对共享对象进行了更改。 只要CPU缓存尚未刷新回主内存，共享对象的更改版本对于在其他CPU上运行的线程是不可见的。 这样，每个线程最终都可能拥有自己的共享对象副本，每个副本都位于不同的CPU缓存中。 下图描绘了该情况。 在左CPU上运行的一个线程将共享对象复制到其CPU缓存中，并将其count变量更改为2.对于在右边的CPU上运行的其他线程，此更改不可见，因为计数更新尚未刷新回主内存中. 要解决此问题，您可以使用Java的volatile关键字。 volatile关键字可以确保直接从主内存读取给定变量，并在更新时始终写回主内存。 JMM与硬件内存连接 - 竞态条件如果两个或多个线程共享一个对象，并且多个线程更新该共享对象中的变量，则可能会出现竞态。 想象一下，如果线程A将共享对象的变量计数读入其CPU缓存中。 想象一下，线程B也做同样的事情，但是进入不同的CPU缓存。 现在，线程A将一个添加到count，而线程B执行相同的操作。 现在var1已经增加了两次，每个CPU缓存一次。 如果这些增量是按先后顺序执行的，则变量计数将增加两次并将原始值+ 2写回主存储器。 但是，两个增量同时执行而没有适当的同步。 无论线程A和B中哪一个将其更新后的计数版本写回主存储器，更新的值将仅比原始值高1，尽管有两个增量。 该图说明了如上所述的竞争条件问题的发生： 要解决此问题，您可以使用Java synchronized块。 同步块保证在任何给定时间只有一个线程可以进入代码的给定关键部分。 同步块还保证在同步块内访问的所有变量都将从主存储器中读入，当线程退出同步块时，所有更新的变量将再次刷新回主存储器，无论变量是不是声明为volatile 参考文章 http://tutorials.jenkov.com/java-concurrency/java-memory-model.html https://blog.csdn.net/weixin_39596082/article/details/88093274","tags":["Java","JVM","内存模型"],"categories":["Java","JVM"]},{"title":"5.JVM 基础 - JVM 内存结构","path":"/2023/12/27/5-JVM-基础-JVM-内存结构/","content":"本文主要对JVM 内存结构进行讲解，注意不要和Java内存模型混淆了。原先这里放了一篇我自己整理的文章，最近看到海星的javakeeper公众号整理的文章，整理的很好。所以替换为他的文章，以方便你构筑JVM内存结构的知识体系。 运行时数据区内存是非常重要的系统资源，是硬盘和 CPU 的中间仓库及桥梁，承载着操作系统和应用程序的实时运行。JVM 内存布局规定了 Java 在运行过程中内存申请、分配、管理的策略，保证了 JVM 的高效稳定运行。不同的 JVM 对于内存的划分方式和管理机制存在着部分差异。 下图是 JVM 整体架构，中间部分就是 Java 虚拟机定义的各种运行时数据区域。 Java 虚拟机定义了若干种程序运行期间会使用到的运行时数据区，其中有一些会随着虚拟机启动而创建，随着虚拟机退出而销毁。另外一些则是与线程一一对应的，这些与线程一一对应的数据区域会随着线程开始和结束而创建和销毁。 线程私有：程序计数器、虚拟机栈、本地方法区 线程共享：堆、方法区, 堆外内存（Java7的永久代或JDK8的元空间、代码缓存） 下面我们就来一一解读下这些内存区域，先从最简单的入手 一、程序计数器程序计数寄存器（Program Counter Register），Register 的命名源于 CPU 的寄存器，寄存器存储指令相关的线程信息，CPU 只有把数据装载到寄存器才能够运行。 这里，并非是广义上所指的物理寄存器，叫程序计数器（或PC计数器或指令计数器）会更加贴切，并且也不容易引起一些不必要的误会。JVM 中的 PC 寄存器是对物理 PC 寄存器的一种抽象模拟。 程序计数器是一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。 1.1 作用PC 寄存器用来存储指向下一条指令的地址，即将要执行的指令代码。由执行引擎读取下一条指令。 （分析：进入class文件所在目录，执行 javap -v xx.class 反解析（或者通过 IDEA 插件 Jclasslib 直接查看，上图），可以看到当前类对应的Code区（汇编指令）、本地变量表、异常表和代码行偏移量映射表、常量池等信息。） 关于类的字节码相关可以看：JVM基础 - 类字节码详解 1.2 概述 通过下面两个问题，理解下PC计数器 使用PC寄存器存储字节码指令地址有什么用呢？为什么使用PC寄存器记录当前线程的执行地址呢？ 因为CPU需要不停的切换各个线程，这时候切换回来以后，就得知道接着从哪开始继续执行。JVM的字节码解释器就需要通过改变PC寄存器的值来明确下一条应该执行什么样的字节码指令。 PC寄存器为什么会被设定为线程私有的？ 多线程在一个特定的时间段内只会执行其中某一个线程方法，CPU会不停的做任务切换，这样必然会导致经常中断或恢复。为了能够准确的记录各个线程正在执行的当前字节码指令地址，所以为每个线程都分配了一个PC寄存器，每个线程都独立计算，不会互相影响。 相关总结如下： 它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域 在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致 任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined） 它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令 它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域 二、虚拟机栈2.1 概述 Java 虚拟机栈(Java Virtual Machine Stacks)，早期也叫 Java 栈。每个线程在创建的时候都会创建一个虚拟机栈，其内部保存一个个的栈帧(Stack Frame），对应着一次次 Java 方法调用，是线程私有的，生命周期和线程一致。 作用：主管 Java 程序的运行，它保存方法的局部变量、部分结果，并参与方法的调用和返回。 特点： 栈是一种快速有效的分配存储方式，访问速度仅次于程序计数器 JVM 直接对虚拟机栈的操作只有两个：每个方法执行，伴随着入栈（进栈&#x2F;压栈），方法执行结束出栈 栈不存在垃圾回收问题 栈中可能出现的异常： Java 虚拟机规范允许 Java虚拟机栈的大小是动态的或者是固定不变的 如果采用固定大小的 Java 虚拟机栈，那每个线程的 Java 虚拟机栈容量可以在线程创建的时候独立选定。如果线程请求分配的栈容量超过 Java 虚拟机栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常 如果 Java 虚拟机栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的虚拟机栈，那 Java 虚拟机将会抛出一个OutOfMemoryError异常 可以通过参数-Xss来设置线程的最大栈空间，栈的大小直接决定了函数调用的最大可达深度。 官方提供的参考工具，可查一些参数和操作：https://docs.oracle.com/javase/8/docs/technotes/tools/windows/java.html#BGBCIEFC 2.2 栈的存储单位栈中存储什么？ 每个线程都有自己的栈，栈中的数据都是以栈帧（Stack Frame）的格式存在 在这个线程上正在执行的每个方法都各自有对应的一个栈帧 栈帧是一个内存区块，是一个数据集，维系着方法执行过程中的各种数据信息 2.3 栈运行原理 JVM 直接对 Java 栈的操作只有两个，对栈帧的压栈和出栈，遵循“先进后出&#x2F;后进先出”原则 在一条活动线程中，一个时间点上，只会有一个活动的栈帧。即只有当前正在执行的方法的栈帧（栈顶栈帧）是有效的，这个栈帧被称为当前栈帧（Current Frame），与当前栈帧对应的方法就是当前方法（Current Method），定义这个方法的类就是当前类（Current Class） 执行引擎运行的所有字节码指令只针对当前栈帧进行操作 如果在该方法中调用了其他方法，对应的新的栈帧会被创建出来，放在栈的顶端，称为新的当前栈帧 不同线程中所包含的栈帧是不允许存在相互引用的，即不可能在一个栈帧中引用另外一个线程的栈帧 如果当前方法调用了其他方法，方法返回之际，当前栈帧会传回此方法的执行结果给前一个栈帧，接着，虚拟机会丢弃当前栈帧，使得前一个栈帧重新成为当前栈帧 Java 方法有两种返回函数的方式，一种是正常的函数返回，使用 return 指令，另一种是抛出异常，不管用哪种方式，都会导致栈帧被弹出 IDEA 在 debug 时候，可以在 debug 窗口看到 Frames 中各种方法的压栈和出栈情况 2.4 栈帧的内部结构每个栈帧（Stack Frame）中存储着： 局部变量表（Local Variables） 操作数栈（Operand Stack）(或称为表达式栈) 动态链接（Dynamic Linking）：指向运行时常量池的方法引用 方法返回地址（Return Address）：方法正常退出或异常退出的地址 一些附加信息 继续深抛栈帧中的五部分~~ 2.4.1. 局部变量表 局部变量表也被称为局部变量数组或者本地变量表 是一组变量值存储空间，主要用于存储方法参数和定义在方法体内的局部变量，包括编译器可知的各种 Java 虚拟机基本数据类型（boolean、byte、char、short、int、float、long、double）、对象引用（reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此相关的位置）和 returnAddress 类型（指向了一条字节码指令的地址，已被异常表取代） 由于局部变量表是建立在线程的栈上，是线程的私有数据，因此不存在数据安全问题 局部变量表所需要的容量大小是编译期确定下来的，并保存在方法的 Code 属性的 maximum local variables 数据项中。在方法运行期间是不会改变局部变量表的大小的 方法嵌套调用的次数由栈的大小决定。一般来说，栈越大，方法嵌套调用次数越多。对一个函数而言，它的参数和局部变量越多，使得局部变量表膨胀，它的栈帧就越大，以满足方法调用所需传递的信息增大的需求。进而函数调用就会占用更多的栈空间，导致其嵌套调用次数就会减少。 局部变量表中的变量只在当前方法调用中有效。在方法执行时，虚拟机通过使用局部变量表完成参数值到参数变量列表的传递过程。当方法调用结束后，随着方法栈帧的销毁，局部变量表也会随之销毁。 参数值的存放总是在局部变量数组的 index0 开始，到数组长度 -1 的索引结束 槽 Slot 局部变量表最基本的存储单元是 Slot（变量槽） 在局部变量表中，32 位以内的类型只占用一个 Slot(包括returnAddress类型)，64 位的类型（long和double）占用两个连续的 Slot byte、short、char 在存储前被转换为int，boolean也被转换为int，0 表示 false，非 0 表示 true long 和 double 则占据两个 Slot JVM 会为局部变量表中的每一个 Slot 都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量值，索引值的范围从 0 开始到局部变量表最大的 Slot 数量 当一个实例方法被调用的时候，它的方法参数和方法体内部定义的局部变量将会按照顺序被复制到局部变量表中的每一个 Slot 上 如果需要访问局部变量表中一个 64bit 的局部变量值时，只需要使用前一个索引即可。（比如：访问 long 或 double 类型变量，不允许采用任何方式单独访问其中的某一个 Slot） 如果当前帧是由构造方法或实例方法创建的，那么该对象引用 this 将会存放在 index 为 0 的 Slot 处，其余的参数按照参数表顺序继续排列（这里就引出一个问题：静态方法中为什么不可以引用 this，就是因为this 变量不存在于当前方法的局部变量表中） 栈帧中的局部变量表中的槽位是可以重用的，如果一个局部变量过了其作用域，那么在其作用域之后申明的新的局部变量就很有可能会复用过期局部变量的槽位，从而达到节省资源的目的。（下图中，this、a、b、c 理论上应该有 4 个变量，c 复用了 b 的槽） 在栈帧中，与性能调优关系最为密切的就是局部变量表。在方法执行时，虚拟机使用局部变量表完成方法的传递 局部变量表中的变量也是重要的垃圾回收根节点，只要被局部变量表中直接或间接引用的对象都不会被回收 2.4.2. 操作数栈 每个独立的栈帧中除了包含局部变量表之外，还包含一个后进先出（Last-In-First-Out）的操作数栈，也可以称为表达式栈（Expression Stack） 操作数栈，在方法执行过程中，根据字节码指令，往操作数栈中写入数据或提取数据，即入栈（push）、出栈（pop） 某些字节码指令将值压入操作数栈，其余的字节码指令将操作数取出栈。使用它们后再把结果压入栈。比如，执行复制、交换、求和等操作 概述 操作数栈，主要用于保存计算过程的中间结果，同时作为计算过程中变量临时的存储空间 操作数栈就是 JVM 执行引擎的一个工作区，当一个方法刚开始执行的时候，一个新的栈帧也会随之被创建出来，此时这个方法的操作数栈是空的 每一个操作数栈都会拥有一个明确的栈深度用于存储数值，其所需的最大深度在编译期就定义好了，保存在方法的 Code 属性的 max_stack 数据项中 栈中的任何一个元素都可以是任意的 Java 数据类型 32bit 的类型占用一个栈单位深度 64bit 的类型占用两个栈单位深度 操作数栈并非采用访问索引的方式来进行数据访问的，而是只能通过标准的入栈和出栈操作来完成一次数据访问 如果被调用的方法带有返回值的话，其返回值将会被压入当前栈帧的操作数栈中，并更新 PC 寄存器中下一条需要执行的字节码指令 操作数栈中元素的数据类型必须与字节码指令的序列严格匹配，这由编译器在编译期间进行验证，同时在类加载过程中的类检验阶段的数据流分析阶段要再次验证 另外，我们说Java虚拟机的解释引擎是基于栈的执行引擎，其中的栈指的就是操作数栈 栈顶缓存（Top-of-stack-Cashing）HotSpot 的执行引擎采用的并非是基于寄存器的架构，但这并不代表 HotSpot VM 的实现并没有间接利用到寄存器资源。寄存器是物理 CPU 中的组成部分之一，它同时也是 CPU 中非常重要的高速存储资源。一般来说，寄存器的读&#x2F;写速度非常迅速，甚至可以比内存的读&#x2F;写速度快上几十倍不止，不过寄存器资源却非常有限，不同平台下的CPU 寄存器数量是不同和不规律的。寄存器主要用于缓存本地机器指令、数值和下一条需要被执行的指令地址等数据。 基于栈式架构的虚拟机所使用的零地址指令更加紧凑，但完成一项操作的时候必然需要使用更多的入栈和出栈指令，这同时也就意味着将需要更多的指令分派（instruction dispatch）次数和内存读&#x2F;写次数。由于操作数是存储在内存中的，因此频繁的执行内存读&#x2F;写操作必然会影响执行速度。为了解决这个问题，HotSpot JVM 设计者们提出了栈顶缓存技术，将栈顶元素全部缓存在物理 CPU 的寄存器中，以此降低对内存的读&#x2F;写次数，提升执行引擎的执行效率 2.4.3. 动态链接（指向运行时常量池的方法引用） 每一个栈帧内部都包含一个指向运行时常量池中该栈帧所属方法的引用。包含这个引用的目的就是为了支持当前方法的代码能够实现动态链接(Dynamic Linking)。 在 Java 源文件被编译到字节码文件中时，所有的变量和方法引用都作为符号引用（Symbolic Reference）保存在 Class 文件的常量池中。比如：描述一个方法调用了另外的其他方法时，就是通过常量池中指向方法的符号引用来表示的，那么动态链接的作用就是为了将这些符号引用转换为调用方法的直接引用 JVM 是如何执行方法调用的方法调用不同于方法执行，方法调用阶段的唯一任务就是确定被调用方法的版本（即调用哪一个方法），暂时还不涉及方法内部的具体运行过程。Class 文件的编译过程中不包括传统编译器中的连接步骤，一切方法调用在 Class文件里面存储的都是符号引用，而不是方法在实际运行时内存布局中的入口地址（直接引用）。也就是需要在类加载阶段，甚至到运行期才能确定目标方法的直接引用。 【这一块内容，除了方法调用，还包括解析、分派（静态分派、动态分派、单分派与多分派），这里先不介绍，后续再挖】 在 JVM 中，将符号引用转换为调用方法的直接引用与方法的绑定机制有关 静态链接：当一个字节码文件被装载进 JVM 内部时，如果被调用的目标方法在编译期可知，且运行期保持不变时。这种情况下将调用方法的符号引用转换为直接引用的过程称之为静态链接 动态链接：如果被调用的方法在编译期无法被确定下来，也就是说，只能在程序运行期将调用方法的符号引用转换为直接引用，由于这种引用转换过程具备动态性，因此也就被称之为动态链接 对应的方法的绑定机制为：早期绑定（Early Binding）和晚期绑定（Late Binding）。绑定是一个字段、方法或者类在符号引用被替换为直接引用的过程，这仅仅发生一次。 早期绑定：早期绑定就是指被调用的目标方法如果在编译期可知，且运行期保持不变时，即可将这个方法与所属的类型进行绑定，这样一来，由于明确了被调用的目标方法究竟是哪一个，因此也就可以使用静态链接的方式将符号引用转换为直接引用。 晚期绑定：如果被调用的方法在编译器无法被确定下来，只能够在程序运行期根据实际的类型绑定相关的方法，这种绑定方式就被称为晚期绑定。 虚方法和非虚方法 如果方法在编译器就确定了具体的调用版本，这个版本在运行时是不可变的。这样的方法称为非虚方法，比如静态方法、私有方法、final 方法、实例构造器、父类方法都是非虚方法 其他方法称为虚方法 虚方法表在面向对象编程中，会频繁的使用到动态分派，如果每次动态分派都要重新在类的方法元数据中搜索合适的目标有可能会影响到执行效率。为了提高性能，JVM 采用在类的方法区建立一个虚方法表（virtual method table），使用索引表来代替查找。非虚方法不会出现在表中。 每个类中都有一个虚方法表，表中存放着各个方法的实际入口。 虚方法表会在类加载的连接阶段被创建并开始初始化，类的变量初始值准备完成之后，JVM 会把该类的方法表也初始化完毕。 2.4.4. 方法返回地址（return address）用来存放调用该方法的 PC 寄存器的值。 一个方法的结束，有两种方式 正常执行完成 出现未处理的异常，非正常退出 无论通过哪种方式退出，在方法退出后都返回到该方法被调用的位置。方法正常退出时，调用者的 PC 计数器的值作为返回地址，即调用该方法的指令的下一条指令的地址。而通过异常退出的，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。 当一个方法开始执行后，只有两种方式可以退出这个方法： 执行引擎遇到任意一个方法返回的字节码指令，会有返回值传递给上层的方法调用者，简称正常完成出口 一个方法的正常调用完成之后究竟需要使用哪一个返回指令还需要根据方法返回值的实际数据类型而定 在字节码指令中，返回指令包含 ireturn(当返回值是 boolean、byte、char、short 和 int 类型时使用)、lreturn、freturn、dreturn 以及 areturn，另外还有一个 return 指令供声明为 void 的方法、实例初始化方法、类和接口的初始化方法使用。 在方法执行的过程中遇到了异常，并且这个异常没有在方法内进行处理，也就是只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出。简称异常完成出口 方法执行过程中抛出异常时的异常处理，存储在一个异常处理表，方便在发生异常的时候找到处理异常的代码。 本质上，方法的退出就是当前栈帧出栈的过程。此时，需要恢复上层方法的局部变量表、操作数栈、将返回值压入调用者栈帧的操作数栈、设置PC寄存器值等，让调用者方法继续执行下去。 正常完成出口和异常完成出口的区别在于：通过异常完成出口退出的不会给他的上层调用者产生任何的返回值 2.4.5. 附加信息栈帧中还允许携带与 Java 虚拟机实现相关的一些附加信息。例如，对程序调试提供支持的信息，但这些信息取决于具体的虚拟机实现。 三、本地方法栈3.1 本地方法接口简单的讲，一个 Native Method 就是一个 Java 调用非 Java 代码的接口。我们知道的 Unsafe 类就有很多本地方法。 为什么要使用本地方法（Native Method）? Java 使用起来非常方便，然而有些层次的任务用 Java 实现起来也不容易，或者我们对程序的效率很在意时，问题就来了 与 Java 环境外交互：有时 Java 应用需要与 Java 外面的环境交互，这就是本地方法存在的原因。 与操作系统交互：JVM 支持 Java 语言本身和运行时库，但是有时仍需要依赖一些底层系统的支持。通过本地方法，我们可以实现用 Java 与实现了 jre 的底层系统交互， JVM 的一些部分就是 C 语言写的。 Sun’s Java：Sun的解释器就是C实现的，这使得它能像一些普通的C一样与外部交互。jre大部分都是用 Java 实现的，它也通过一些本地方法与外界交互。比如，类 java.lang.Thread 的 setPriority() 的方法是用Java 实现的，但它实现调用的是该类的本地方法 setPrioruty()，该方法是C实现的，并被植入 JVM 内部。 3.2 本地方法栈（Native Method Stack） Java 虚拟机栈用于管理 Java 方法的调用，而本地方法栈用于管理本地方法的调用 本地方法栈也是线程私有的 允许线程固定或者可动态扩展的内存大小 如果线程请求分配的栈容量超过本地方法栈允许的最大容量，Java 虚拟机将会抛出一个 StackOverflowError 异常 如果本地方法栈可以动态扩展，并且在尝试扩展的时候无法申请到足够的内存，或者在创建新的线程时没有足够的内存去创建对应的本地方法栈，那么 Java虚拟机将会抛出一个OutofMemoryError异常 本地方法是使用 C 语言实现的 它的具体做法是 Native Method Stack 中登记 native 方法，在 Execution Engine 执行时加载本地方法库当某个线程调用一个本地方法时，它就进入了一个全新的并且不再受虚拟机限制的世界。它和虚拟机拥有同样的权限。 本地方法可以通过本地方法接口来访问虚拟机内部的运行时数据区，它甚至可以直接使用本地处理器中的寄存器，直接从本地内存的堆中分配任意数量的内存 并不是所有 JVM 都支持本地方法。因为 Java 虚拟机规范并没有明确要求本地方法栈的使用语言、具体实现方式、数据结构等。如果 JVM 产品不打算支持 native 方法，也可以无需实现本地方法栈 在 Hotspot JVM 中，直接将本地方法栈和虚拟机栈合二为一 栈是运行时的单位，而堆是存储的单位。 栈解决程序的运行问题，即程序如何执行，或者说如何处理数据。堆解决的是数据存储的问题，即数据怎么放、放在哪。 四、堆内存4.1 内存划分对于大多数应用，Java 堆是 Java 虚拟机管理的内存中最大的一块，被所有线程共享。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数据都在这里分配内存。 为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）： 新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代 老年代（老年区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大 元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存 Java 虚拟机规范规定，Java 堆可以是处于物理上不连续的内存空间中，只要逻辑上是连续的即可，像磁盘空间一样。实现时，既可以是固定大小，也可以是可扩展的，主流虚拟机都是可扩展的（通过 -Xmx 和 -Xms 控制），如果堆中没有完成实例分配，并且堆无法再扩展时，就会抛出 OutOfMemoryError 异常。 年轻代 (Young Generation)年轻代是所有新对象创建的地方。当填充年轻代时，执行垃圾收集。这种垃圾收集称为 Minor GC。年轻一代被分为三个部分——Eden区（Eden Memory）和两个幸存区（Survivor Memory，被称为from&#x2F;to或s0&#x2F;s1），默认比例是8:1:1 大多数新创建的对象都位于 Eden 内存空间中 当 Eden 空间被对象填充时，执行Minor GC，并将所有幸存者对象移动到一个幸存者空间中 Minor GC 检查幸存者对象，并将它们移动到另一个幸存者空间。所以每次，一个幸存者空间总是空的 经过多次 GC 循环后存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代 老年代(Old Generation)旧的一代内存包含那些经过许多轮小型 GC 后仍然存活的对象。通常，垃圾收集是在老年代内存满时执行的。老年代垃圾收集称为 主GC（Major GC），通常需要更长的时间。 大对象直接进入老年代（大对象是指需要大量连续内存空间的对象）。这样做的目的是避免在 Eden 区和两个Survivor 区之间发生大量的内存拷贝 元空间不管是 JDK8 之前的永久代，还是 JDK8 及以后的元空间，都可以看作是 Java 虚拟机规范中方法区的实现。 虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。 所以元空间放在后边的方法区再说。 4.2 设置堆内存大小和 OOMJava 堆用于存储 Java 对象实例，那么堆的大小在 JVM 启动的时候就确定了，我们可以通过 -Xmx 和 -Xms 来设定 -Xms 用来表示堆的起始内存，等价于 -XX:InitialHeapSize -Xmx 用来表示堆的最大内存，等价于 -XX:MaxHeapSize 如果堆的内存大小超过 -Xmx 设定的最大内存， 就会抛出 OutOfMemoryError 异常。 我们通常会将 -Xmx 和 -Xms 两个参数配置为相同的值，其目的是为了能够在垃圾回收机制清理完堆区后不再需要重新分隔计算堆的大小，从而提高性能 默认情况下，初始堆内存大小为：电脑内存大小&#x2F;64 默认情况下，最大堆内存大小为：电脑内存大小&#x2F;4 可以通过代码获取到我们的设置值，当然也可以模拟 OOM： 12345678910111213public static void main(String[] args) &#123; //返回 JVM 堆大小 long initalMemory = Runtime.getRuntime().totalMemory() / 1024 /1024; //返回 JVM 堆的最大内存 long maxMemory = Runtime.getRuntime().maxMemory() / 1024 /1024; System.out.println(&quot;-Xms : &quot;+initalMemory + &quot;M&quot;); System.out.println(&quot;-Xmx : &quot;+maxMemory + &quot;M&quot;); System.out.println(&quot;系统内存大小：&quot; + initalMemory * 64 / 1024 + &quot;G&quot;); System.out.println(&quot;系统内存大小：&quot; + maxMemory * 4 / 1024 + &quot;G&quot;);&#125; 查看 JVM 堆内存分配 在默认不配置 JVM 堆内存大小的情况下，JVM 根据默认值来配置当前内存大小 默认情况下新生代和老年代的比例是 1:2，可以通过 –XX:NewRatio 来配置 新生代中的 Eden:From Survivor:To Survivor 的比例是 8:1:1，可以通过 -XX:SurvivorRatio 来配置 若在 JDK 7 中开启了 -XX:+UseAdaptiveSizePolicy，JVM 会动态调整 JVM 堆中各个区域的大小以及进入老年代的年龄 此时 –XX:NewRatio 和 -XX:SurvivorRatio 将会失效，而 JDK 8 是默认开启-XX:+UseAdaptiveSizePolicy 在 JDK 8中，不要随意关闭-XX:+UseAdaptiveSizePolicy，除非对堆内存的划分有明确的规划 每次 GC 后都会重新计算 Eden、From Survivor、To Survivor 的大小 计算依据是GC过程中统计的GC时间、吞吐量、内存占用量 12345678910java -XX:+PrintFlagsFinal -version | grep HeapSize uintx ErgoHeapSizeLimit = 0 &#123;product&#125; uintx HeapSizePerGCThread = 87241520 &#123;product&#125; uintx InitialHeapSize := 134217728 &#123;product&#125; uintx LargePageHeapSizeThreshold = 134217728 &#123;product&#125; uintx MaxHeapSize := 2147483648 &#123;product&#125;java version &quot;1.8.0_211&quot;Java(TM) SE Runtime Environment (build 1.8.0_211-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.211-b12, mixed mode)$ jmap -heap 进程号 4.3 对象在堆中的生命周期 在 JVM 内存模型的堆中，堆被划分为新生代和老年代 新生代又被进一步划分为 Eden区 和 Survivor区，Survivor 区由 From Survivor 和 To Survivor 组成 当创建一个对象时，对象会被优先分配到新生代的 Eden 区 此时 JVM 会给对象定义一个对象年轻计数器（-XX:MaxTenuringThreshold） 当 Eden 空间不足时，JVM 将执行新生代的垃圾回收（Minor GC） JVM 会把存活的对象转移到 Survivor 中，并且对象年龄 +1 对象在 Survivor 中同样也会经历 Minor GC，每经历一次 Minor GC，对象年龄都会+1 如果分配的对象超过了-XX:PetenureSizeThreshold，对象会直接被分配到老年代 4.4 对象的分配过程为对象分配内存是一件非常严谨和复杂的任务，JVM 的设计者们不仅需要考虑内存如何分配、在哪里分配等问题，并且由于内存分配算法和内存回收算法密切相关，所以还需要考虑 GC 执行完内存回收后是否会在内存空间中产生内存碎片。 new 的对象先放在Eden区，此区有大小限制 当Eden区的空间填满时，程序又需要创建对象，JVM 的垃圾回收器将对Eden区进行垃圾回收（Minor GC），将Eden区中的不再被其他对象所引用的对象进行销毁。再加载新的对象放到Eden区 然后将Eden区中的剩余对象移动到Survivor 0 区 如果再次触发垃圾回收，此时上次幸存下来的放到Survivor 0 区，如果没有回收，就会放到Survivor 1 区 如果再次经历垃圾回收，此时会重新放回Survivor 0 区，接着再去Survivor 1 区 什么时候才会去老年区呢？ 默认是 15 次回收标记 在老年区，相对悠闲。当老年区内存不足时，再次触发 Major GC，进行老年区的内存清理 若老年区执行了 Major GC 之后发现依然无法进行对象的保存，就会产生 OOM 异常 4.5 GC 垃圾回收简介Minor GC、Major GC、Full GCJVM 在进行 GC 时，并非每次都对堆内存（新生代、老年代；方法区）区域一起回收的，大部分时候回收的都是指新生代。 针对 HotSpot VM 的实现，它里面的 GC 按照回收区域又分为两大类：部分收集（Partial GC），整堆收集（Full GC） 部分收集：不是完整收集整个 Java 堆的垃圾收集。其中又分为： 新生代收集（Minor GC&#x2F;Young GC）：只是新生代的垃圾收集 老年代收集（Major GC&#x2F;Old GC）：只是老年代的垃圾收集 目前，只有 CMS GC 会有单独收集老年代的行为 很多时候 Major GC 会和 Full GC 混合使用，需要具体分辨是老年代回收还是整堆回收 混合收集（Mixed GC）：收集整个新生代以及部分老年代的垃圾收集 目前只有 G1 GC 会有这种行为 整堆收集（Full GC）：收集整个 Java 堆和方法区的垃圾 4.6 TLAB什么是 TLAB （Thread Local Allocation Buffer）? 从内存模型而不是垃圾回收的角度，对 Eden 区域继续进行划分，JVM 为每个线程分配了一个私有缓存区域，它包含在 Eden 空间内 多线程同时分配内存时，使用 TLAB 可以避免一系列的非线程安全问题，同时还能提升内存分配的吞吐量，因此我们可以将这种内存分配方式称为快速分配策略 OpenJDK 衍生出来的 JVM 大都提供了 TLAB 设计 为什么要有 TLAB ? 堆区是线程共享的，任何线程都可以访问到堆区中的共享数据 由于对象实例的创建在 JVM 中非常频繁，因此在并发环境下从堆区中划分内存空间是线程不安全的 为避免多个线程操作同一地址，需要使用加锁等机制，进而影响分配速度 尽管不是所有的对象实例都能够在 TLAB 中成功分配内存，但 JVM 确实是将 TLAB 作为内存分配的首选。 在程序中，可以通过 -XX:UseTLAB 设置是否开启 TLAB 空间。 默认情况下，TLAB 空间的内存非常小，仅占有整个 Eden 空间的 1%，我们可以通过 -XX:TLABWasteTargetPercent 设置 TLAB 空间所占用 Eden 空间的百分比大小。 一旦对象在 TLAB 空间分配内存失败时，JVM 就会尝试着通过使用加锁机制确保数据操作的原子性，从而直接在 Eden 空间中分配内存。 4.7 堆是分配对象存储的唯一选择吗 随着 JIT 编译期的发展和逃逸分析技术的逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，所有的对象都分配到堆上也渐渐变得不那么“绝对”了。 ——《深入理解 Java 虚拟机》 逃逸分析**逃逸分析(Escape Analysis)**是目前 Java 虚拟机中比较前沿的优化技术**。这是一种可以有效减少 Java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法**。通过逃逸分析，Java Hotspot 编译器能够分析出一个新的对象的引用的使用范围从而决定是否要将这个对象分配到堆上。 逃逸分析的基本行为就是分析对象动态作用域： 当一个对象在方法中被定义后，对象只在方法内部使用，则认为没有发生逃逸。 当一个对象在方法中被定义后，它被外部方法所引用，则认为发生逃逸。例如作为调用参数传递到其他地方中，称为方法逃逸。 例如： 123456public static StringBuffer craeteStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb;&#125; StringBuffer sb是一个方法内部变量，上述代码中直接将sb返回，这样这个 StringBuffer 有可能被其他方法所改变，这样它的作用域就不只是在方法内部，虽然它是一个局部变量，但是其逃逸到了方法外部。甚至还有可能被外部线程访问到，譬如赋值给类变量或可以在其他线程中访问的实例变量，称为线程逃逸。 上述代码如果想要 StringBuffer sb不逃出方法，可以这样写： 123456public static String createStringBuffer(String s1, String s2) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); return sb.toString();&#125; 不直接返回 StringBuffer，那么 StringBuffer 将不会逃逸出方法。 参数设置： 在 JDK 6u23 版本之后，HotSpot 中默认就已经开启了逃逸分析 如果使用较早版本，可以通过-XX&quot;+DoEscapeAnalysis显式开启 开发中使用局部变量，就不要在方法外定义。 使用逃逸分析，编译器可以对代码做优化： 栈上分配：将堆分配转化为栈分配。如果一个对象在子程序中被分配，要使指向该对象的指针永远不会逃逸，对象可能是栈分配的候选，而不是堆分配 同步省略：如果一个对象被发现只能从一个线程被访问到，那么对于这个对象的操作可以不考虑同步 分离对象或标量替换：有的对象可能不需要作为一个连续的内存结构存在也可以被访问到，那么对象的部分（或全部）可以不存储在内存，而存储在 CPU 寄存器 JIT 编译器在编译期间根据逃逸分析的结果，发现如果一个对象并没有逃逸出方法的话，就可能被优化成栈上分配。分配完成后，继续在调用栈内执行，最后线程结束，栈空间被回收，局部变量对象也被回收。这样就无需进行垃圾回收了。 常见栈上分配的场景：成员变量赋值、方法返回值、实例引用传递 代码优化之同步省略（消除） 线程同步的代价是相当高的，同步的后果是降低并发性和性能 在动态编译同步块的时候，JIT 编译器可以借助逃逸分析来判断同步块所使用的锁对象是否能够被一个线程访问而没有被发布到其他线程。如果没有，那么 JIT 编译器在编译这个同步块的时候就会取消对这个代码的同步。这样就能大大提高并发性和性能。这个取消同步的过程就叫做同步省略，也叫锁消除。 123456public void keep() &#123; Object keeper = new Object(); synchronized(keeper) &#123; System.out.println(keeper); &#125;&#125; 如上代码，代码中对 keeper 这个对象进行加锁，但是 keeper 对象的生命周期只在 keep()方法中，并不会被其他线程所访问到，所以在 JIT编译阶段就会被优化掉。优化成： 1234public void keep() &#123; Object keeper = new Object(); System.out.println(keeper);&#125; 代码优化之标量替换标量（Scalar）是指一个无法再分解成更小的数据的数据。Java 中的原始数据类型就是标量。 相对的，那些的还可以分解的数据叫做聚合量（Aggregate），Java 中的对象就是聚合量，因为其还可以分解成其他聚合量和标量。 在 JIT 阶段，通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM 不会创建该对象，而会将该对象成员变量分解若干个被这个方法使用的成员变量所代替。这些代替的成员变量在栈帧或寄存器上分配空间。这个过程就是标量替换。 通过 -XX:+EliminateAllocations 可以开启标量替换，-XX:+PrintEliminateAllocations 查看标量替换情况。 123456789101112public static void main(String[] args) &#123; alloc();&#125;private static void alloc() &#123; Point point = new Point（1,2）; System.out.println(&quot;point.x=&quot;+point.x+&quot;; point.y=&quot;+point.y);&#125;class Point&#123; private int x; private int y;&#125; 以上代码中，point 对象并没有逃逸出 alloc() 方法，并且 point 对象是可以拆解成标量的。那么，JIT 就不会直接创建 Point 对象，而是直接使用两个标量 int x ，int y 来替代 Point 对象。 12345private static void alloc() &#123; int x = 1; int y = 2; System.out.println(&quot;point.x=&quot;+x+&quot;; point.y=&quot;+y);&#125; 代码优化之栈上分配我们通过 JVM 内存分配可以知道 JAVA 中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠 GC 进行回收内存，如果对象数量较多的时候，会给 GC 带来较大压力，也间接影响了应用的性能。为了减少临时对象在堆内分配的数量，JVM 通过逃逸分析确定该对象不会被外部访问。那就通过标量替换将该对象分解在栈上分配内存，这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。 总结： 关于逃逸分析的论文在1999年就已经发表了，但直到JDK 1.6才有实现，而且这项技术到如今也并不是十分成熟的。 其根本原因就是无法保证逃逸分析的性能消耗一定能高于他的消耗。虽然经过逃逸分析可以做标量替换、栈上分配、和锁消除。但是逃逸分析自身也是需要进行一系列复杂的分析的，这其实也是一个相对耗时的过程。 一个极端的例子，就是经过逃逸分析之后，发现没有一个对象是不逃逸的。那这个逃逸分析的过程就白白浪费掉了。 虽然这项技术并不十分成熟，但是他也是即时编译器优化技术中一个十分重要的手段。 五、方法区 方法区（Method Area）与 Java 堆一样，是所有线程共享的内存区域。 虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。 运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本&#x2F;字段&#x2F;方法&#x2F;接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将类在加载后进入方法区的运行时常量池中存放。运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的是 String.intern()方法。受方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。 方法区的大小和堆空间一样，可以选择固定大小也可选择可扩展，方法区的大小决定了系统可以放多少个类，如果系统类太多，导致方法区溢出，虚拟机同样会抛出内存溢出错误 JVM 关闭后方法区即被释放 5.1 解惑你是否也有看不同的参考资料，有的内存结构图有方法区，有的又是永久代，元数据区，一脸懵逼的时候？ 方法区（method area）**只是 **JVM 规范**中定义的一个**概念**，用于存储类信息、常量池、静态变量、JIT编译后的代码等数据，并没有规定如何去实现它，不同的厂商有不同的实现。而永久代（PermGen）**是 **Hotspot** 虚拟机特有的概念， Java8 的时候又被**元空间**取代了，永久代和元空间都可以理解为方法区的落地实现。 永久代物理是堆的一部分，和新生代，老年代地址是连续的（受垃圾回收器管理），而元空间存在于本地内存（我们常说的堆外内存，不受垃圾回收器管理），这样就不受 JVM 限制了，也比较难发生OOM（都会有溢出异常） Java7 中我们通过-XX:PermSize 和 -xx:MaxPermSize 来设置永久代参数，Java8 之后，随着永久代的取消，这些参数也就随之失效了，改为通过-XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 用来设置元空间参数 存储内容不同，元空间存储类的元信息，静态变量和常量池等并入堆中。相当于永久代的数据被分到了堆和元空间中 如果方法区域中的内存不能用于满足分配请求，则 Java 虚拟机抛出 OutOfMemoryError JVM 规范说方法区在逻辑上是堆的一部分，但目前实际上是与 Java 堆分开的（Non-Heap） 所以对于方法区，Java8 之后的变化： 移除了永久代（PermGen），替换为元空间（Metaspace）； 永久代中的 class metadata 转移到了 native memory（本地内存，而不是虚拟机）； 永久代中的 interned Strings 和 class static variables 转移到了 Java heap； 永久代参数 （PermSize MaxPermSize） -&gt; 元空间参数（MetaspaceSize MaxMetaspaceSize） 5.2 设置方法区内存的大小JDK8 及以后： 元数据区大小可以使用参数 -XX:MetaspaceSize 和 -XX:MaxMetaspaceSize 指定，替代上述原有的两个参数 默认值依赖于平台。Windows 下，-XX:MetaspaceSize 是 21M，-XX:MaxMetaspacaSize 的值是 -1，即没有限制 与永久代不同，如果不指定大小，默认情况下，虚拟机会耗尽所有的可用系统内存。如果元数据发生溢出，虚拟机一样会抛出异常 OutOfMemoryError:Metaspace -XX:MetaspaceSize ：设置初始的元空间大小。对于一个 64 位的服务器端 JVM 来说，其默认的 -XX:MetaspaceSize 的值为20.75MB，这就是初始的高水位线，一旦触及这个水位线，Full GC 将会被触发并卸载没用的类（即这些类对应的类加载器不再存活），然后这个高水位线将会重置，新的高水位线的值取决于 GC 后释放了多少元空间。如果释放的空间不足，那么在不超过 MaxMetaspaceSize时，适当提高该值。如果释放空间过多，则适当降低该值 如果初始化的高水位线设置过低，上述高水位线调整情况会发生很多次，通过垃圾回收的日志可观察到 Full GC 多次调用。为了避免频繁 GC，建议将 -XX:MetaspaceSize 设置为一个相对较高的值。 5.3 方法区内部结构方法区用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等。 类型信息对每个加载的类型（类 class、接口 interface、枚举 enum、注解 annotation），JVM 必须在方法区中存储以下类型信息 这个类型的完整有效名称（全名&#x3D;包名.类名） 这个类型直接父类的完整有效名（对于 interface或是 java.lang.Object，都没有父类） 这个类型的修饰符（public，abstract，final 的某个子集） 这个类型直接接口的一个有序列表 域（Field）信息 JVM 必须在方法区中保存类型的所有域的相关信息以及域的声明顺序 域的相关信息包括：域名称、域类型、域修饰符（public、private、protected、static、final、volatile、transient 的某个子集） 方法（Method）信息JVM 必须保存所有方法的 方法名称 方法的返回类型 方法参数的数量和类型 方法的修饰符（public，private，protected，static，final，synchronized，native，abstract 的一个子集） 方法的字符码（bytecodes）、操作数栈、局部变量表及大小（abstract 和 native 方法除外） 异常表（abstract 和 native 方法除外） 每个异常处理的开始位置、结束位置、代码处理在程序计数器中的偏移地址、被捕获的异常类的常量池索引 栈、堆、方法区的交互关系 运行时数据区的完整结构，其中方法区是运行时数据区的相当重要的一块内存。 从线程共享与否的角度看 从代码层面看堆、栈、方法区的交互(配合)关系 12345public class Person &#123; public static void main(String[] args) &#123; Person person = new Person(); &#125;&#125; 看一下交互关系 5.4 运行时常量池运行时常量池（Runtime Constant Pool）是方法区的一部分，理解运行时常量池的话，我们先来说说字节码文件（Class 文件）中的常量池（常量池表） 常量池一个有效的字节码文件中除了包含类的版本信息、字段、方法以及接口等描述信息外，还包含一项信息那就是常量池表（Constant Pool Table），包含各种字面量和对类型、域和方法的符号引用。 为什么需要常量池？一个 Java 源文件中的类、接口，编译后产生一个字节码文件。而 Java 中的字节码需要数据支持，通常这种数据会很大以至于不能直接存到字节码里，换另一种方式，可以存到常量池，这个字节码包含了指向常量池的引用。在动态链接的时候用到的就是运行时常量池。 如下，我们通过 jclasslib 查看一个只有 Main 方法的简单类，字节码中的 #2 指向的就是 Constant Pool 常量池可以看作是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量等类型。 运行时常量池 在加载类和结构到虚拟机后，就会创建对应的运行时常量池 常量池表（Constant Pool Table）是 Class 文件的一部分，用于存储编译期生成的各种字面量和符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中 JVM 为每个已加载的类型（类或接口）都维护一个常量池。池中的数据项像数组项一样，是通过索引访问的 运行时常量池中包含各种不同的常量，包括编译器就已经明确的数值字面量，也包括到运行期解析后才能够获得的方法或字段引用。此时不再是常量池中的符号地址了，这里换为真实地址 运行时常量池，相对于 Class 文件常量池的另一个重要特征是：动态性，Java 语言并不要求常量一定只有编译期间才能产生，运行期间也可以将新的常量放入池中，String 类的 intern() 方法就是这样的 当创建类或接口的运行时常量池时，如果构造运行时常量池所需的内存空间超过了方法区所能提供的最大值，则 JVM 会抛出 OutOfMemoryError 异常。 5.5 方法区在 JDK6、7、8中的演进细节只有 HotSpot 才有永久代的概念 jdk1.6及之前 有永久代，静态变量存放在永久代上 jdk1.7 有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中 jdk1.8及之后 取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中 @pdai: HotSpot中字符串常量池保存哪里？永久代？方法区还是堆区？ 运行时常量池（Runtime Constant Pool）是虚拟机规范中是方法区的一部分，在加载类和结构到虚拟机后，就会创建对应的运行时常量池；而字符串常量池是这个过程中常量字符串的存放位置。所以从这个角度，字符串常量池属于虚拟机规范中的方法区，它是一个逻辑上的概念；而堆区，永久代以及元空间是实际的存放位置。 不同的虚拟机对虚拟机的规范（比如方法区）是不一样的，只有 HotSpot 才有永久代的概念。 HotSpot也是发展的，由于一些问题在新窗口打开的存在，HotSpot考虑逐渐去永久代，对于不同版本的JDK，实际的存储位置是有差异的，具体看如下表格： JDK版本 是否有永久代，字符串常量池放在哪里？ 方法区逻辑上规范，由哪些实际的部分实现的？ jdk1.6及之前 有永久代，运行时常量池（包括字符串常量池），静态变量存放在永久代上 这个时期方法区在HotSpot中是由永久代来实现的，以至于这个时期说方法区就是指永久代 jdk1.7 有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中； 这个时期方法区在HotSpot中由永久代（类型信息、字段、方法、常量）和堆（字符串常量池、静态变量）共同实现 jdk1.8及之后 取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中 这个时期方法区在HotSpot中由本地内存的元空间（类型信息、字段、方法、常量）和堆（字符串常量池、静态变量）共同实现 移除永久代原因http://openjdk.java.net/jeps/122 为永久代设置空间大小是很难确定的。 在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM。如果某个实际 Web 工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现 OOM。而元空间和永久代最大的区别在于，元空间不在虚拟机中，而是使用本地内存，所以默认情况下，元空间的大小仅受本地内存限制 对永久代进行调优较困难 5.6 方法区的垃圾回收方法区的垃圾收集主要回收两部分内容：常量池中废弃的常量和不再使用的类型。 先来说说方法区内常量池之中主要存放的两大类常量：字面量和符号引用。字面量比较接近 Java 语言层次的常量概念，如文本字符串、被声明为 final 的常量值等。而符号引用则属于编译原理方面的概念，包括下面三类常量： 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 HotSpot 虚拟机对常量池的回收策略是很明确的，只要常量池中的常量没有被任何地方引用，就可以被回收 判定一个类型是否属于“不再被使用的类”，需要同时满足三个条件： 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类及其任何派生子类的实例 加载该类的类加载器已经被回收，这个条件除非是经过精心设计的可替换类加载器的场景，如 OSGi、JSP 的重加载等，否则通常很难达成 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法 Java 虚拟机被允许堆满足上述三个条件的无用类进行回收，这里说的仅仅是“被允许”，而并不是和对象一样，不使用了就必然会回收。是否对类进行回收，HotSpot 虚拟机提供了 -Xnoclassgc 参数进行控制，还可以使用 -verbose:class 以及 -XX:+TraceClassLoading 、-XX:+TraceClassUnLoading 查看类加载和卸载信息。 在大量使用反射、动态代理、CGLib 等 ByteCode 框架、动态生成 JSP 以及 OSGi 这类频繁自定义 ClassLoader 的场景都需要虚拟机具备类卸载的功能，以保证永久代不会溢出。 参考与感谢 作者：海星 来源于：JavaKeeper 原作者参考内容如下 算是一篇学习笔记，共勉，主要来源： 《深入理解 Java 虚拟机 第三版》 宋红康老师的 JVM 教程 https://docs.oracle.com/javase/specs/index.html https://www.cnblogs.com/wicfhwffg/p/9382677.html https://www.cnblogs.com/hollischuang/p/12501950.html","tags":["Java","JVM","内存结构"],"categories":["Java","JVM"]},{"title":"3.JVM 基础 - 字节码的增强技术","path":"/2023/12/27/3-JVM-基础-字节码的增强技术/","content":"在上文中，着重介绍了字节码的结构，这为我们了解字节码增强技术的实现打下了基础。字节码增强技术就是一类对现有字节码进行修改或者动态生成全新字节码文件的技术。接下来，我们将从最直接操纵字节码的实现方式开始深入进行剖析。 字节码增强技术在上文中，着重介绍了字节码的结构，这为我们了解字节码增强技术的实现打下了基础。字节码增强技术就是一类对现有字节码进行修改或者动态生成全新字节码文件的技术。接下来，我们将从最直接操纵字节码的实现方式开始深入进行剖析 ASM对于需要手动操纵字节码的需求，可以使用ASM，它可以直接生产 .class字节码文件，也可以在类被加载入JVM之前动态修改类行为（如下图17所示）。ASM的应用场景有AOP（Cglib就是基于ASM）、热部署、修改其他jar包中的类等。当然，涉及到如此底层的步骤，实现起来也比较麻烦。接下来，本文将介绍ASM的两种API，并用ASM来实现一个比较粗糙的AOP。但在此之前，为了让大家更快地理解ASM的处理流程，强烈建议读者先对访问者模式进行了解。简单来说，访问者模式主要用于修改或操作一些数据结构比较稳定的数据，而通过第一章，我们知道字节码文件的结构是由JVM固定的，所以很适合利用访问者模式对字节码文件进行修改。 ASM API核心APIASM Core API可以类比解析XML文件中的SAX方式，不需要把这个类的整个结构读取进来，就可以用流式的方法来处理字节码文件。好处是非常节约内存，但是编程难度较大。然而出于性能考虑，一般情况下编程都使用Core API。在Core API中有以下几个关键类： ClassReader：用于读取已经编译好的.class文件。 ClassWriter：用于重新构建编译后的类，如修改类名、属性以及方法，也可以生成新的类的字节码文件。 各种Visitor类：如上所述，CoreAPI根据字节码从上到下依次处理，对于字节码文件中不同的区域有不同的Visitor，比如用于访问方法的MethodVisitor、用于访问类变量的FieldVisitor、用于访问注解的AnnotationVisitor等。为了实现AOP，重点要使用的是MethodVisitor。 树形APIASM Tree API可以类比解析XML文件中的DOM方式，把整个类的结构读取到内存中，缺点是消耗内存多，但是编程比较简单。TreeApi不同于CoreAPI，TreeAPI通过各种Node类来映射字节码的各个区域，类比DOM节点，就可以很好地理解这种编程方式。 直接利用ASM实现AOP利用ASM的CoreAPI来增强类。这里不纠结于AOP的专业名词如切片、通知，只实现在方法调用前、后增加逻辑，通俗易懂且方便理解。首先定义需要被增强的Base类：其中只包含一个process()方法，方法内输出一行“process”。增强后，我们期望的是，方法执行前输出“start”，之后输出”end”。 12345public class Base &#123; public void process()&#123; System.out.println(&quot;process&quot;); &#125;&#125; 为了利用ASM实现AOP，需要定义两个类：一个是MyClassVisitor类，用于对字节码的visit以及修改；另一个是Generator类，在这个类中定义ClassReader和ClassWriter，其中的逻辑是，classReader读取字节码，然后交给MyClassVisitor类处理，处理完成后由ClassWriter写字节码并将旧的字节码替换掉。Generator类较简单，我们先看一下它的实现，如下所示，然后重点解释MyClassVisitor类。 123456789101112131415161718192021import org.objectweb.asm.ClassReader;import org.objectweb.asm.ClassVisitor;import org.objectweb.asm.ClassWriter;public class Generator &#123; public static void main(String[] args) throws Exception &#123; //读取 ClassReader classReader = new ClassReader(&quot;meituan/bytecode/asm/Base&quot;); ClassWriter classWriter = new ClassWriter(ClassWriter.COMPUTE_MAXS); //处理 ClassVisitor classVisitor = new MyClassVisitor(classWriter); classReader.accept(classVisitor, ClassReader.SKIP_DEBUG); byte[] data = classWriter.toByteArray(); //输出 File f = new File(&quot;operation-server/target/classes/meituan/bytecode/asm/Base.class&quot;); FileOutputStream fout = new FileOutputStream(f); fout.write(data); fout.close(); System.out.println(&quot;now generator cc success!!!!!&quot;); &#125;&#125; MyClassVisitor继承自ClassVisitor，用于对字节码的观察。它还包含一个内部类MyMethodVisitor，继承自MethodVisitor用于对类内方法的观察，它的整体代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import org.objectweb.asm.ClassVisitor;import org.objectweb.asm.MethodVisitor;import org.objectweb.asm.Opcodes;public class MyClassVisitor extends ClassVisitor implements Opcodes &#123; public MyClassVisitor(ClassVisitor cv) &#123; super(ASM5, cv); &#125; @Override public void visit(int version, int access, String name, String signature, String superName, String[] interfaces) &#123; cv.visit(version, access, name, signature, superName, interfaces); &#125; @Override public MethodVisitor visitMethod(int access, String name, String desc, String signature, String[] exceptions) &#123; MethodVisitor mv = cv.visitMethod(access, name, desc, signature, exceptions); //Base类中有两个方法：无参构造以及process方法，这里不增强构造方法 if (!name.equals(&quot;&lt;init&gt;&quot;) &amp;&amp; mv != null) &#123; mv = new MyMethodVisitor(mv); &#125; return mv; &#125; class MyMethodVisitor extends MethodVisitor implements Opcodes &#123; public MyMethodVisitor(MethodVisitor mv) &#123; super(Opcodes.ASM5, mv); &#125; @Override public void visitCode() &#123; super.visitCode(); mv.visitFieldInsn(GETSTATIC, &quot;java/lang/System&quot;, &quot;out&quot;, &quot;Ljava/io/PrintStream;&quot;); mv.visitLdcInsn(&quot;start&quot;); mv.visitMethodInsn(INVOKEVIRTUAL, &quot;java/io/PrintStream&quot;, &quot;println&quot;, &quot;(Ljava/lang/String;)V&quot;, false); &#125; @Override public void visitInsn(int opcode) &#123; if ((opcode &gt;= Opcodes.IRETURN &amp;&amp; opcode &lt;= Opcodes.RETURN) || opcode == Opcodes.ATHROW) &#123; //方法在返回之前，打印&quot;end&quot; mv.visitFieldInsn(GETSTATIC, &quot;java/lang/System&quot;, &quot;out&quot;, &quot;Ljava/io/PrintStream;&quot;); mv.visitLdcInsn(&quot;end&quot;); mv.visitMethodInsn(INVOKEVIRTUAL, &quot;java/io/PrintStream&quot;, &quot;println&quot;, &quot;(Ljava/lang/String;)V&quot;, false); &#125; mv.visitInsn(opcode); &#125; &#125;&#125; 利用这个类就可以实现对字节码的修改。详细解读其中的代码，对字节码做修改的步骤是： 首先通过MyClassVisitor类中的visitMethod方法，判断当前字节码读到哪一个方法了。跳过构造方法 &lt;init&gt; 后，将需要被增强的方法交给内部类MyMethodVisitor来进行处理。 接下来，进入内部类MyMethodVisitor中的visitCode方法，它会在ASM开始访问某一个方法的Code区时被调用，重写visitCode方法，将AOP中的前置逻辑就放在这里。 MyMethodVisitor继续读取字节码指令，每当ASM访问到无参数指令时，都会调用MyMethodVisitor中的visitInsn方法。我们判断了当前指令是否为无参数的“return”指令，如果是就在它的前面添加一些指令，也就是将AOP的后置逻辑放在该方法中。 综上，重写MyMethodVisitor中的两个方法，就可以实现AOP了，而重写方法时就需要用ASM的写法，手动写入或者修改字节码。通过调用methodVisitor的visitXXXXInsn()方法就可以实现字节码的插入，XXXX对应相应的操作码助记符类型，比如mv.visitLdcInsn(“end”)对应的操作码就是ldc “end”，即将字符串“end”压入栈。 完成这两个visitor类后，运行Generator中的main方法完成对Base类的字节码增强，增强后的结果可以在编译后的target文件夹中找到Base.class文件进行查看，可以看到反编译后的代码已经改变了。然后写一个测试类MyTest，在其中new Base()，并调用base.process()方法，可以看到下图右侧所示的AOP实现效果： ASM工具利用ASM手写字节码时，需要利用一系列visitXXXXInsn()方法来写对应的助记符，所以需要先将每一行源代码转化为一个个的助记符，然后通过ASM的语法转换为visitXXXXInsn()这种写法。第一步将源码转化为助记符就已经够麻烦了，不熟悉字节码操作集合的话，需要我们将代码编译后再反编译，才能得到源代码对应的助记符。第二步利用ASM写字节码时，如何传参也很令人头疼。ASM社区也知道这两个问题，所以提供了工具ASM ByteCode Outline在新窗口打开。 安装后，右键选择“Show Bytecode Outline”，在新标签页中选择“ASMified”这个tab，如图19所示，就可以看到这个类中的代码对应的ASM写法了。图中上下两个红框分别对应AOP中的前置逻辑于后置逻辑，将这两块直接复制到visitor中的visitMethod()以及visitInsn()方法中，就可以了。 JavassistASM是在指令层次上操作字节码的，阅读上文后，我们的直观感受是在指令层次上操作字节码的框架实现起来比较晦涩。故除此之外，我们再简单介绍另外一类框架：强调源代码层次操作字节码的框架Javassist。 利用Javassist实现字节码增强时，可以无须关注字节码刻板的结构，其优点就在于编程简单。直接使用java编码的形式，而不需要了解虚拟机指令，就能动态改变类的结构或者动态生成类。其中最重要的是ClassPool、CtClass、CtMethod、CtField这四个类： CtClass（compile-time class）：编译时类信息，它是一个class文件在代码中的抽象表现形式，可以通过一个类的全限定名来获取一个CtClass对象，用来表示这个类文件。 ClassPool：从开发视角来看，ClassPool是一张保存CtClass信息的HashTable，key为类名，value为类名对应的CtClass对象。当我们需要对某个类进行修改时，就是通过pool.getCtClass(“className”)方法从pool中获取到相应的CtClass。 CtMethod、CtField：这两个比较好理解，对应的是类中的方法和属性。 了解这四个类后，我们可以写一个小Demo来展示Javassist简单、快速的特点。我们依然是对Base中的process()方法做增强，在方法调用前后分别输出”start”和”end”，实现代码如下。我们需要做的就是从pool中获取到相应的CtClass对象和其中的方法，然后执行method.insertBefore和insertAfter方法，参数为要插入的Java代码，再以字符串的形式传入即可，实现起来也极为简单。 123456789101112131415import com.meituan.mtrace.agent.javassist.*;public class JavassistTest &#123; public static void main(String[] args) throws NotFoundException, CannotCompileException, IllegalAccessException, InstantiationException, IOException &#123; ClassPool cp = ClassPool.getDefault(); CtClass cc = cp.get(&quot;meituan.bytecode.javassist.Base&quot;); CtMethod m = cc.getDeclaredMethod(&quot;process&quot;); m.insertBefore(&quot;&#123; System.out.println(\\&quot;start\\&quot;); &#125;&quot;); m.insertAfter(&quot;&#123; System.out.println(\\&quot;end\\&quot;); &#125;&quot;); Class c = cc.toClass(); cc.writeFile(&quot;/Users/zen/projects&quot;); Base h = (Base)c.newInstance(); h.process(); &#125;&#125; 运行时类的重载问题引出上一章重点介绍了两种不同类型的字节码操作框架，且都利用它们实现了较为粗糙的AOP。其实，为了方便大家理解字节码增强技术，在上文中我们避重就轻将ASM实现AOP的过程分为了两个main方法：第一个是利用MyClassVisitor对已编译好的class文件进行修改，第二个是new对象并调用。这期间并不涉及到JVM运行时对类的重加载，而是在第一个main方法中，通过ASM对已编译类的字节码进行替换，在第二个main方法中，直接使用已替换好的新类信息。另外在Javassist的实现中，我们也只加载了一次Base类，也不涉及到运行时重加载类。 如果我们在一个JVM中，先加载了一个类，然后又对其进行字节码增强并重新加载会发生什么呢？模拟这种情况，只需要我们在上文中Javassist的Demo中main()方法的第一行添加Base b&#x3D;new Base()，即在增强前就先让JVM加载Base类，然后在执行到c.toClass()方法时会抛出错误，如下图20所示。跟进c.toClass()方法中，我们会发现它是在最后调用了ClassLoader的native方法defineClass()时报错。也就是说，JVM是不允许在运行时动态重载一个类的。 显然，如果只能在类加载前对类进行强化，那字节码增强技术的使用场景就变得很窄了。我们期望的效果是：在一个持续运行并已经加载了所有类的JVM中，还能利用字节码增强技术对其中的类行为做替换并重新加载。为了模拟这种情况，我们将Base类做改写，在其中编写main方法，每五秒调用一次process()方法，在process()方法中输出一行“process”。 我们的目的就是，在JVM运行中的时候，将process()方法做替换，在其前后分别打印“start”和“end”。也就是在运行中时，每五秒打印的内容由”process”变为打印”start process end”。那如何解决JVM不允许运行时重加载类信息的问题呢？为了达到这个目的，我们接下来一一来介绍需要借助的Java类库。 12345678910111213141516171819202122import java.lang.management.ManagementFactory;public class Base &#123; public static void main(String[] args) &#123; String name = ManagementFactory.getRuntimeMXBean().getName(); String s = name.split(&quot;@&quot;)[0]; //打印当前Pid System.out.println(&quot;pid:&quot;+s); while (true) &#123; try &#123; Thread.sleep(5000L); &#125; catch (Exception e) &#123; break; &#125; process(); &#125; &#125; public static void process() &#123; System.out.println(&quot;process&quot;); &#125;&#125; Instrumentinstrument是JVM提供的一个可以修改已加载类的类库，专门为Java语言编写的插桩服务提供支持。它需要依赖JVMTI的Attach API机制实现，JVMTI这一部分，我们将在下一小节进行介绍。在JDK 1.6以前，instrument只能在JVM刚启动开始加载类时生效，而在JDK 1.6之后，instrument支持了在运行时对类定义的修改。要使用instrument的类修改功能，我们需要实现它提供的ClassFileTransformer接口，定义一个类文件转换器。接口中的transform()方法会在类文件被加载时调用，而在transform方法里，我们可以利用上文中的ASM或Javassist对传入的字节码进行改写或替换，生成新的字节码数组后返回。 我们定义一个实现了ClassFileTransformer接口的类TestTransformer，依然在其中利用Javassist对Base类中的process()方法进行增强，在前后分别打印“start”和“end”，代码如下： 12345678910111213141516171819import java.lang.instrument.ClassFileTransformer;public class TestTransformer implements ClassFileTransformer &#123; @Override public byte[] transform(ClassLoader loader, String className, Class&lt;?&gt; classBeingRedefined, ProtectionDomain protectionDomain, byte[] classfileBuffer) &#123; System.out.println(&quot;Transforming &quot; + className); try &#123; ClassPool cp = ClassPool.getDefault(); CtClass cc = cp.get(&quot;meituan.bytecode.jvmti.Base&quot;); CtMethod m = cc.getDeclaredMethod(&quot;process&quot;); m.insertBefore(&quot;&#123; System.out.println(\\&quot;start\\&quot;); &#125;&quot;); m.insertAfter(&quot;&#123; System.out.println(\\&quot;end\\&quot;); &#125;&quot;); return cc.toBytecode(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return null; &#125;&#125; 现在有了Transformer，那么它要如何注入到正在运行的JVM呢？还需要定义一个Agent，借助Agent的能力将Instrument注入到JVM中。我们将在下一小节介绍Agent，现在要介绍的是Agent中用到的另一个类Instrumentation。在JDK 1.6之后，Instrumentation可以做启动后的Instrument、本地代码（Native Code）的Instrument，以及动态改变Classpath等等。我们可以向Instrumentation中添加上文中定义的Transformer，并指定要被重加载的类，代码如下所示。这样，当Agent被Attach到一个JVM中时，就会执行类字节码替换并重载入JVM的操作。 123456789101112131415import java.lang.instrument.Instrumentation;public class TestAgent &#123; public static void agentmain(String args, Instrumentation inst) &#123; //指定我们自己定义的Transformer，在其中利用Javassist做字节码替换 inst.addTransformer(new TestTransformer(), true); try &#123; //重定义类并载入新的字节码 inst.retransformClasses(Base.class); System.out.println(&quot;Agent Load Done.&quot;); &#125; catch (Exception e) &#123; System.out.println(&quot;agent load failed!&quot;); &#125; &#125;&#125; JVMTI &amp; Agent &amp; Attach API上一小节中，我们给出了Agent类的代码，追根溯源需要先介绍JPDA（Java Platform Debugger Architecture）。如果JVM启动时开启了JPDA，那么类是允许被重新加载的。在这种情况下，已被加载的旧版本类信息可以被卸载，然后重新加载新版本的类。正如JDPA名称中的Debugger，JDPA其实是一套用于调试Java程序的标准，任何JDK都必须实现该标准。 JPDA定义了一整套完整的体系，它将调试体系分为三部分，并规定了三者之间的通信接口。三部分由低到高分别是Java 虚拟机工具接口（JVMTI），Java 调试协议（JDWP）以及 Java 调试接口（JDI），三者之间的关系如下图所示： 现在回到正题，我们可以借助JVMTI的一部分能力，帮助动态重载类信息。JVM TI（JVM TOOL INTERFACE，JVM工具接口）是JVM提供的一套对JVM进行操作的工具接口。通过JVMTI，可以实现对JVM的多种操作，它通过接口注册各种事件勾子，在JVM事件触发时，同时触发预定义的勾子，以实现对各个JVM事件的响应，事件包括类文件加载、异常产生与捕获、线程启动和结束、进入和退出临界区、成员变量修改、GC开始和结束、方法调用进入和退出、临界区竞争与等待、VM启动与退出等等。 而Agent就是JVMTI的一种实现，Agent有两种启动方式，一是随Java进程启动而启动，经常见到的java -agentlib就是这种方式；二是运行时载入，通过attach API，将模块（jar包）动态地Attach到指定进程id的Java进程内。 Attach API 的作用是提供JVM进程间通信的能力，比如说我们为了让另外一个JVM进程把线上服务的线程Dump出来，会运行jstack或jmap的进程，并传递pid的参数，告诉它要对哪个进程进行线程Dump，这就是Attach API做的事情。在下面，我们将通过Attach API的loadAgent()方法，将打包好的Agent jar包动态Attach到目标JVM上。具体实现起来的步骤如下： 定义Agent，并在其中实现AgentMain方法，如上一小节中定义的代码块7中的TestAgent类； 然后将TestAgent类打成一个包含MANIFEST.MF的jar包，其中MANIFEST.MF文件中将Agent-Class属性指定为TestAgent的全限定名，如下图所示； 最后利用Attach API，将我们打包好的jar包Attach到指定的JVM pid上，代码如下： 123456789import com.sun.tools.attach.VirtualMachine;public class Attacher &#123; public static void main(String[] args) throws AttachNotSupportedException, IOException, AgentLoadException, AgentInitializationException &#123; // 传入目标 JVM pid VirtualMachine vm = VirtualMachine.attach(&quot;39333&quot;); vm.loadAgent(&quot;/Users/zen/operation_server_jar/operation-server.jar&quot;); &#125;&#125; 由于在MANIFEST.MF中指定了Agent-Class，所以在Attach后，目标JVM在运行时会走到TestAgent类中定义的agentmain()方法，而在这个方法中，我们利用Instrumentation，将指定类的字节码通过定义的类转化器TestTransformer做了Base类的字节码替换（通过javassist），并完成了类的重新加载。由此，我们达成了“在JVM运行时，改变类的字节码并重新载入类信息”的目的。 以下为运行时重新载入类的效果：先运行Base中的main()方法，启动一个JVM，可以在控制台看到每隔五秒输出一次”process”。接着执行Attacher中的main()方法，并将上一个JVM的pid传入。此时回到上一个main()方法的控制台，可以看到现在每隔五秒输出”process”前后会分别输出”start”和”end”，也就是说完成了运行时的字节码增强，并重新载入了这个类。 使用场景至此，字节码增强技术的可使用范围就不再局限于JVM加载类前了。通过上述几个类库，我们可以在运行时对JVM中的类进行修改并重载了。通过这种手段，可以做的事情就变得很多了： 热部署：不部署服务而对线上服务做修改，可以做打点、增加日志等操作。 Mock：测试时候对某些服务做Mock。 性能诊断工具：比如bTrace就是利用Instrument，实现无侵入地跟踪一个正在运行的JVM，监控到类和方法级别的状态信息。 总结字节码增强技术相当于是一把打开运行时JVM的钥匙，利用它可以动态地对运行中的程序做修改，也可以跟踪JVM运行中程序的状态。此外，我们平时使用的动态代理、AOP也与字节码增强密切相关，它们实质上还是利用各种手段生成符合规范的字节码文件。综上所述，掌握字节码增强后可以高效地定位并快速修复一些棘手的问题（如线上性能问题、方法出现不可控的出入参需要紧急加日志等问题），也可以在开发中减少冗余代码，大大提高开发效率。 参考文献 《ASM4-Guide》 Oracle:The class File Format Oracle:The Java Virtual Machine Instruction Set javassist tutorial JVM Tool Interface - Version 1.2 作者简介泽恩，美团点评研发工程师。 文章来源： 美团技术团队 https://tech.meituan.com/2019/09/05/java-bytecode-enhancement.html","tags":["Java","JVM","字节码"],"categories":["Java","JVM"]},{"title":"1.JVM相关知识体系详解","path":"/2023/12/27/1-JVM相关知识体系详解/","content":"本系列将给大家构建JVM核心知识点全局知识体系。 知识体系 学习要点 不同的虚拟机实现方式上也有差别，如果没有特别指出，这里的JVM指的是sun的HotSpot；不同的JDK版本略有差别，这里主要以1.8为主，具体差异请看各个章节中详解。下图主要表示的逻辑关系，用来将所有知识点放到一张图里，帮助你理解。 A. Java进阶 - JVM相关 知识体系： 首先按照上述学习思路，理解总体知识点在全局上与知识体系之间的对应关系。 JVM 相关知识体系 B. Java进阶 - JVM相关 类加载： 然后理解类字节码和类的加载机制。 JVM基础 - 类字节码详解 源代码通过编译器编译为字节码，再通过类加载子系统进行加载到JVM中运行 JVM基础 - 字节码的增强技术 在上文中，着重介绍了字节码的结构，这为我们了解字节码增强技术的实现打下了基础。字节码增强技术就是一类对现有字节码进行修改或者动态生成全新字节码文件的技术。接下来，我们将从最直接操纵字节码的实现方式开始深入进行剖析。 JVM基础 - Java 类加载机制 这篇文章将带你深入理解Java 类加载机制 C. Java进阶 - JVM相关 内存结构： 因为类字节码是加载到JVM内存结构中的，所以紧接着理解JVM内存结构。 JVM基础 - JVM内存结构 本文主要对JVM 内存结构进行讲解，注意不要和Java内存模型混淆了 D. Java进阶 - JVM相关 JMM： 然后通过理解JVM与硬件之间的联系，理解Java 通过其内存模型保证数据线程安全等，这是JVM在并发上底层的支持。 JVM基础 - Java 内存模型引入 很多人都无法区分Java内存模型和JVM内存结构，以及Java内存模型与物理内存之间的关系。本文从堆栈角度引入JMM，然后介绍JMM和物理内存之间的关系, 为后面JMM详解, JVM 内存结构详解, Java 对象模型详解等铺垫。 JVM基础 - Java 内存模型详解 本文主要转载自 Info 上深入理解Java内存模型, 作者程晓明。这篇文章对JMM讲的很清楚了，大致分三部分：重排序与顺序一致性；三个同步原语（lock，volatile，final）的内存语义，重排序规则及在处理器中的实现；java 内存模型的设计，及其与处理器内存模型和顺序一致性内存模型的关系 E. Java进阶 - JVM相关 GC： 再者理解下Java GC机制，如何回收内存等。 GC - Java 垃圾回收基础知识 垃圾收集主要是针对堆和方法区进行；程序计数器、虚拟机栈和本地方法栈这三个区域属于线程私有的，只存在于线程的生命周期内，线程结束之后也会消失，因此不需要对这三个区域进行垃圾回收。 GC - Java 垃圾回收器之G1详解 G1垃圾回收器是在Java7 update 4之后引入的一个新的垃圾回收器。同优秀的CMS垃圾回收器一样，G1也是关注最小时延的垃圾回收器，也同样适合大尺寸堆内存的垃圾收集，官方在ZGC还没有出现时也推荐使用G1来代替选择CMS。G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。 GC - Java 垃圾回收器之ZGC详解 ZGC（The Z Garbage Collector）是JDK 11中推出的一款低延迟垃圾回收器, 是JDK 11+ 最为重要的更新之一，适用于大内存低延迟服务的内存管理和回收。在梳理相关知识点时，发现美团技术团队分享的文章新一代垃圾回收器ZGC的探索与实践比较完善（包含G1收集器停顿时间瓶颈，原理，优化等）, 这里分享给你，帮你构建ZGC相关的知识体系 GC - Java 垃圾回收器之CMS GC问题分析与解决 本文整理自美团技术团队, 这篇文章将可以帮助你构建CMS GC相关问题解决的知识体系，分享给你。 F. Java进阶 - JVM相关 排错调优： 最后围绕着调试和排错，分析理解JVM调优参数，动态字节码技术及动态在线调试的原理；学会使用常用的调工具和在线动态调试工具等。 调试排错 - JVM 调优参数 本文对JVM涉及的常见的调优参数和垃圾回收参数进行阐述 调试排错 - Java 内存分析之堆内存和MetaSpace内存 本文以两个简单的例子(堆内存溢出和MetaSpace (元数据) 内存溢出）解释Java 内存溢出的分析过程 调试排错 - Java 内存分析之堆外内存 Java 堆外内存分析相对来说是复杂的，美团技术团队的Spring Boot引起的“堆外内存泄漏”排查及经验总结可以为很多Native Code内存泄漏&#x2F;占用提供方向性指引。 调试排错 - Java 线程分析之线程Dump分析 Thread Dump是非常有用的诊断Java应用问题的工具。 调试排错 - Java 问题排查之Linux命令 Java 在线问题排查之通过linux常用命令排查。 调试排错 - Java 问题排查之工具单 Java 在线问题排查之通过java调试&#x2F;排查工具进行问题定位。 调试排错 - Java 问题排查之JVM可视化工具 本文主要梳理常见的JVM可视化的分析工具，主要包括JConsole, Visual VM, Vusial GC, JProfile 和 MAT等。 调试排错 - Java 问题排查之应用在线调试Arthas 本文主要介绍Alibaba开源的Java诊断工具，开源到现在已经1.7万个点赞了，深受开发者喜爱。具体解决在线问题，比如： 这个类从哪个 jar 包加载的? 为什么会报各种类相关的 Exception? 我改的代码为什么没有执行到? 难道是我没 commit? 分支搞错了? 遇到问题无法在线上 debug，难道只能通过加日志再重新发布吗? 线上遇到某个用户的数据处理有问题，但线上同样无法 debug，线下无法重现！ 是否有一个全局视角来查看系统的运行状况? 有什么办法可以监控到JVM的实时运行状态? 调试排错 - Java 问题排查之使用IDEA本地调试和远程调试 Debug用来追踪代码的运行流程，通常在程序运行过程中出现异常，启用Debug模式可以分析定位异常发生的位置，以及在运行过程中参数的变化；并且在实际的排错过程中，还会用到Remote Debug。IDEA 相比 Eclipse&#x2F;STS效率更高，本文主要介绍基于IDEA的Debug和Remote Debug的技巧。 调试排错 - Java动态调试技术原理 本文转载自 美团技术团队胡健的Java 动态调试技术原理及实践, 通过学习java agent方式进行动态调试了解目前很多大厂开源的一些基于此的调试工具。 学习文献 Java虚拟机规范（Java SE 8） [JSR-133: JavaTM Memory Model and Thread Specification","tags":["Java","JVM"],"categories":["Java","JVM"]},{"title":"16.Java 21 新特性概述","path":"/2023/12/27/16-Java-21-新特性概述/","content":"本文章转载自 京东云开发社社区 原文 一、导语几天前 Oracle 刚刚发布了 Java21，由于这是最新的 LTS 版本，引起了大家的关注。我也第一时间在个人项目中进行了升级体验。 一探究竟，和大家分享。 二、Java21 更新内容介绍官方 release 公告：https://jdk.java.net/21/release-notes 开源中国介绍：https://my.oschina.net/waylau/blog/10112170 新特性一览： JEP 431：序列集合 JEP 439：分代 ZGC JEP 440：记录模式 JEP 441：switch 模式匹配 JEP 444：虚拟线程 JEP 449：弃用 Windows 32 位 x86 移植 JEP 451：准备禁止动态加载代理 JEP 452：密钥封装机制 API JEP 430：字符串模板（预览） JEP 442：外部函数和内存 API（第三次预览） JEP 443：未命名模式和变量（预览） JEP 445：未命名类和实例主方法（预览） JEP 446：作用域值（预览） JEP 453：结构化并发（预览） JEP 448：Vector API（孵化器第六阶段） 其中大家比较关注的是分代 ZGC 和虚拟线程。 三、开箱下载地址： OpenJDK 版本：https://jdk.java.net/21/Oracle 版本：https://www.oracle.com/java/technologies/downloads/ 对比 17边框由不锈钢升级为钛金属目录结构一致： 模块数量比 17 少一个： 整体大小从 289MB 增加到了 320MB 四、升级体验下载 更新 pom 尝试运行运行报错：java.lang.NoSuchFieldError: Class com.sun.tools.javac.tree.JCTree$JCImport does not have member field &#39;com.sun.tools.javac.tree.JCTree qualid&#39;解决办法：升级 lombok 至 1.18.30 原因：https://github.com/projectlombok/lombok/issues/3393 兼容性检查：由于我的项目以前用的 JDK17，本次升级兼容性良好，只发现了一处：系统托盘中 使用了 PopupMenu，出现了字符集问题： 五、分代 ZGC 体验ZGC 在之前的 JDK 版本中也有，这次的分代 ZGC 更是被大家看好，官方的介绍如下： Applications running with Generational ZGC should enjoy:Lower risks of allocations stalls,Lower required heap memory overhead, andLower garbage collection CPU overhead.Enable Generational ZGC with command line options -XX:+UseZGC -XX:+ZGenerational 性能测试参考： https://inside.java/2023/09/03/roadto21-performance/ JVM 参数：-XX:+UseZGC -XX:+ZGenerational使用 Java21，未使用 ZGCMooInfo 内存占用查看 使用 Java21，使用分代 ZGCMooInfo 内存占用查看 以上只是初步体验，关于 ZGC 的更多内容，如详细的分代回收情况后续进一步探索。 以上内存占用查看使用我之前做的一个工具，MooInfo：https://github.com/rememberber/MooInfo 六、虚拟线程探索Virtual threads are lightweight threads that reduce the effort of writing, maintaining, and debugging high-throughput concurrent applications. 虚拟线程是轻量级线程，可以减少编写、维护和调试高吞吐量并发应用程序的工作量。 Oracle 介绍原文： https://docs.oracle.com/en/java/javase/20/core/virtual-threads.html#GUID-DC4306FC-D6C1-4BCC-AECE-48C32C1A8DAA 平台线程Oracle 官方文档的机器翻译： 平台线程是作为操作系统 (OS) 线程的瘦包装器实现的。平台线程在其底层操作系统线程上运行 Java 代码，平台线程在平台线程的整个生命周期内捕获其操作系统线程。因此，可用平台线程的数量受限于操作系统线程的数量。平台线程通常有一个大的线程堆栈和其他由操作系统维护的资源。平台线程支持线程局部变量。平台线程适合运行所有类型的任务，但可能是有限的资源。 虚拟线程Oracle 官方文档的机器翻译： 与平台线程一样，虚拟线程也是 java.lang.Thread 的一个实例。但是，虚拟线程并不依赖于特定的操作系统线程。虚拟线程仍然在操作系统线程上运行代码。但是，当虚拟线程中运行的代码调用阻塞 I&#x2F;O 操作时，Java 运行时会挂起虚拟线程，直到可以恢复为止。与挂起的虚拟线程关联的操作系统线程现在可以自由地为其他虚拟线程执行操作。 实现原理 虚拟线程的实现方式与虚拟内存类似。为了模拟大量内存，操作系统将较大的虚拟地址空间映射到有限的 RAM。同样，为了模拟大量线程，Java 运行时将大量虚拟线程映射到少量操作系统线程。与平台线程不同，虚拟线程通常具有浅调用堆栈，只执行单个 HTTP 客户端调用或单个 JDBC 查询。尽管虚拟线程支持线程局部变量，但您应该仔细考虑使用它们，因为单个 JVM 可能支持数百万个虚拟线程。 虚拟线程适合运行大部分时间处于阻塞状态、通常等待 I&#x2F;O 操作完成的任务。但是，它们不适用于长时间运行的 CPU 密集型操作。 虚拟线程用法12Thread thread = Thread.ofVirtual().start(() -&gt; System.out.println(&quot;Hello&quot;));thread.join(); 或者 1234567891011try &#123; Thread.Builder builder = Thread.ofVirtual().name(&quot;MyThread&quot;); Runnable task = () -&gt; &#123; System.out.println(&quot;Running thread&quot;); &#125;; Thread t = builder.start(task); System.out.println(&quot;Thread t name: &quot; + t.getName()); t.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; 或者 12345678910111213141516171819202122232425262728public class CreateNamedThreadsWithBuilders &#123; public static void main(String[] args) &#123; try &#123; Thread.Builder builder = Thread.ofVirtual().name(&quot;worker-&quot;, 0); Runnable task = () -&gt; &#123; System.out.println(&quot;Thread ID: &quot; + Thread.currentThread().threadId()); &#125;; // name &quot;worker-0&quot; Thread t1 = builder.start(task); t1.join(); System.out.println(t1.getName() + &quot; terminated&quot;); // name &quot;worker-1&quot; Thread t2 = builder.start(task); t2.join(); System.out.println(t2.getName() + &quot; terminated&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 或者 123456789try (ExecutorService myExecutor = Executors.newVirtualThreadPerTaskExecutor()) &#123; Future&lt;?&gt; future = myExecutor.submit(() -&gt; System.out.println(&quot;Running thread&quot;)); future.get(); System.out.println(&quot;Task completed&quot;); &#125; catch (InterruptedException | ExecutionException e) &#123; e.printStackTrace(); &#125; 以上是 Java20 文档的用法，实际使用时我发现还可以这样： 1234Thread.startVirtualThread(() -&gt; &#123; // do something &#125;); 平台线程和虚拟线程对比测试为了测试对比，我建了一个项目 初步对比，和官网描述一致，计算密集型场景差别不大，IO 密集型场景有明显改善：虚拟线程 100 个，IO 读文件 平台线程 100 个，IO 读文件 虚拟线程 100 个，Get 请求百度首页 平台线程 100 个，Get 请求百度首页 但是由于是本地测试，且用例比较简陋，无法完全得出准确结论。日后大家有实际 IO 密集性多线程场景可以实际感受下。 线程池？忘了它吧开发人员通常会将应用程序代码从基于线程池的传统 ExecutorService 迁移到虚拟线程每任务 ExecutorService。线程池和所有资源池一样，旨在共享昂贵的资源，但虚拟线程并不昂贵，而且永远不需要将它们池化。 七、一颗语法糖？Java21 新特性：Record Patterns一个例子感受一下新特性：Record Patternsbefore： 1234567static void printSum(Object obj) &#123; if (obj instanceof Point p) &#123; int x = p.x(); int y = p.y(); System.out.println(x+y); &#125;&#125; after: 12345static void printSum(Object obj) &#123; if (obj instanceof Point(int x, int y)) &#123; System.out.println(x+y); &#125;&#125;","tags":["Java","新特性","Java21"],"categories":["Java","新特性","Java21"]},{"title":"15.Java 20 新特性概览","path":"/2023/12/27/15-Java-20-新特性概览/","content":"JDK 20 于 2023 年 3 月 21 日发布，非长期支持版本。 根据开发计划，下一个 LTS 版本就是将于 2023 年 9 月发布的 JDK 21。 JDK 20 只有 7 个新特性： JEP 429：Scoped Values（作用域值）（第一次孵化） JEP 432：Record Patterns（记录模式）（第二次预览） JEP 433：switch 模式匹配（第四次预览） JEP 434: Foreign Function &amp; Memory API（外部函数和内存 API）（第二次预览） JEP 436: Virtual Threads（虚拟线程）（第二次预览） JEP 437:Structured Concurrency（结构化并发）(第二次孵化) JEP 432:向量 API（第五次孵化） JEP 429：作用域值（第一次孵化）作用域值（Scoped Values）它可以在线程内和线程间共享不可变的数据，优于线程局部变量，尤其是在使用大量虚拟线程时。 12345678final static ScopedValue&lt;...&gt; V = new ScopedValue&lt;&gt;();// In some methodScopedValue.where(V, &lt;value&gt;) .run(() -&gt; &#123; ... V.get() ... call methods ... &#125;);// In a method called directly or indirectly from the lambda expression... V.get() ... 作用域值允许在大型程序中的组件之间安全有效地共享数据，而无需求助于方法参数。 关于作用域值的详细介绍，推荐阅读作用域值常见问题解答这篇文章。 JEP 432：记录模式（第二次预览）记录模式（Record Patterns） 可对 record 的值进行解构，也就是更方便地从记录类（Record Class）中提取数据。并且，还可以嵌套记录模式和类型模式结合使用，以实现强大的、声明性的和可组合的数据导航和处理形式。 记录模式不能单独使用，而是要与 instanceof 或 switch 模式匹配一同使用。 先以 instanceof 为例简单演示一下。 简单定义一个记录类： 1record Shape(String type, long unit)&#123;&#125; 没有记录模式之前： 12345Shape circle = new Shape(&quot;Circle&quot;, 10);if (circle instanceof Shape shape) &#123; System.out.println(&quot;Area of &quot; + shape.type() + &quot; is : &quot; + Math.PI * Math.pow(shape.unit(), 2));&#125; 有了记录模式之后： 1234Shape circle = new Shape(&quot;Circle&quot;, 10);if (circle instanceof Shape(String type, long unit)) &#123; System.out.println(&quot;Area of &quot; + type + &quot; is : &quot; + Math.PI * Math.pow(unit, 2));&#125; 再看看记录模式与 switch 的配合使用。 定义一些类： 1234interface Shape &#123;&#125;record Circle(double radius) implements Shape &#123; &#125;record Square(double side) implements Shape &#123; &#125;record Rectangle(double length, double width) implements Shape &#123; &#125; 没有记录模式之前： 123456789101112131415161718Shape shape = new Circle(10);switch (shape) &#123; case Circle c: System.out.println(&quot;The shape is Circle with area: &quot; + Math.PI * c.radius() * c.radius()); break; case Square s: System.out.println(&quot;The shape is Square with area: &quot; + s.side() * s.side()); break; case Rectangle r: System.out.println(&quot;The shape is Rectangle with area: + &quot; + r.length() * r.width()); break; default: System.out.println(&quot;Unknown Shape&quot;); break;&#125; 有了记录模式之后： 12345678910111213141516171819Shape shape = new Circle(10);switch(shape) &#123; case Circle(double radius): System.out.println(&quot;The shape is Circle with area: &quot; + Math.PI * radius * radius); break; case Square(double side): System.out.println(&quot;The shape is Square with area: &quot; + side * side); break; case Rectangle(double length, double width): System.out.println(&quot;The shape is Rectangle with area: + &quot; + length * width); break; default: System.out.println(&quot;Unknown Shape&quot;); break;&#125; 记录模式可以避免不必要的转换，使得代码更建简洁易读。而且，用了记录模式后不必再担心 null 或者 NullPointerException，代码更安全可靠。 记录模式在 Java 19 进行了第一次预览， 由 JEP 405 提出。JDK 20 中是第二次预览，由 JEP 432 提出。这次的改进包括： 添加对通用记录模式类型参数推断的支持， 添加对记录模式的支持以出现在增强语句的标题中for 删除对命名记录模式的支持。 注意：不要把记录模式和 JDK16 正式引入的记录类搞混了。 JEP 433：switch 模式匹配（第四次预览）正如 instanceof 一样， switch 也紧跟着增加了类型匹配自动转换功能。 instanceof 代码示例： 12345678910// Old codeif (o instanceof String) &#123; String s = (String)o; ... use s ...&#125;// New codeif (o instanceof String s) &#123; ... use s ...&#125; switch 代码示例： 12345678910111213141516171819202122232425// Old codestatic String formatter(Object o) &#123; String formatted = &quot;unknown&quot;; if (o instanceof Integer i) &#123; formatted = String.format(&quot;int %d&quot;, i); &#125; else if (o instanceof Long l) &#123; formatted = String.format(&quot;long %d&quot;, l); &#125; else if (o instanceof Double d) &#123; formatted = String.format(&quot;double %f&quot;, d); &#125; else if (o instanceof String s) &#123; formatted = String.format(&quot;String %s&quot;, s); &#125; return formatted;&#125;// New codestatic String formatterPatternSwitch(Object o) &#123; return switch (o) &#123; case Integer i -&gt; String.format(&quot;int %d&quot;, i); case Long l -&gt; String.format(&quot;long %d&quot;, l); case Double d -&gt; String.format(&quot;double %f&quot;, d); case String s -&gt; String.format(&quot;String %s&quot;, s); default -&gt; o.toString(); &#125;;&#125; switch 模式匹配分别在 Java17、Java18、Java19 中进行了预览，Java20 是第四次预览了。每一次的预览基本都会有一些小改进，这里就不细提了。 JEP 434: 外部函数和内存 API（第二次预览）Java 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。 外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。Java 18 中进行了第二次孵化，由JEP 419 提出。Java 19 中是第一次预览，由 JEP 424 提出。 JDK 20 中是第二次预览，由 JEP 434 提出，这次的改进包括： MemorySegment 和 MemoryAddress 抽象的统一 增强的 MemoryLayout 层次结构 MemorySession拆分为Arena和SegmentScope，以促进跨维护边界的段共享。 在 Java 19 新特性概览 中，我有详细介绍到外部函数和内存 API，这里就不再做额外的介绍了。 JEP 436: 虚拟线程（第二次预览）虚拟线程（Virtual Thread）是 JDK 而不是 OS 实现的轻量级线程(Lightweight Process，LWP），由 JVM 调度。许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。 在引入虚拟线程之前，java.lang.Thread 包已经支持所谓的平台线程，也就是没有虚拟线程之前，我们一直使用的线程。JVM 调度程序通过平台线程（载体线程）来管理虚拟线程，一个平台线程可以在不同的时间执行不同的虚拟线程（多个虚拟线程挂载在一个平台线程上），当虚拟线程被阻塞或等待时，平台线程可以切换到执行另一个虚拟线程。 虚拟线程、平台线程和系统内核线程的关系图如下所示（图源：How to Use Java 19 Virtual Threads）： 关于平台线程和系统内核线程的对应关系多提一点：在 Windows 和 Linux 等主流操作系统中，Java 线程采用的是一对一的线程模型，也就是一个平台线程对应一个系统内核线程。Solaris 系统是一个特例，HotSpot VM 在 Solaris 上支持多对多和一对一。具体可以参考 R 大的回答: JVM 中的线程模型是用户级的么？。 相比较于平台线程来说，虚拟线程是廉价且轻量级的，使用完后立即被销毁，因此它们不需要被重用或池化，每个任务可以有自己专属的虚拟线程来运行。虚拟线程暂停和恢复来实现线程之间的切换，避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂，可以有效减少编写、维护和观察高吞吐量并发应用程序的工作量。 虚拟线程在其他多线程语言中已经被证实是十分有用的，比如 Go 中的 Goroutine、Erlang 中的进程。 知乎有一个关于 Java 19 虚拟线程的讨论，感兴趣的可以去看看：https://www.zhihu.com/question/536743167 。 Java 虚拟线程的详细解读和原理可以看下面这两篇文章： Java19 正式 GA！看虚拟线程如何大幅提高系统吞吐量 虚拟线程 - VirtualThread 源码透视 虚拟线程在 Java 19 中进行了第一次预览，由JEP 425提出。JDK 20 中是第二次预览，做了一些细微变化，这里就不细提了。 最后，我们来看一下四种创建虚拟线程的方法： 1234567891011121314151617181920212223242526272829303132333435// 1、通过 Thread.ofVirtual() 创建Runnable fn = () -&gt; &#123; // your code here&#125;;Thread thread = Thread.ofVirtual(fn) .start();// 2、通过 Thread.startVirtualThread() 、创建Thread thread = Thread.startVirtualThread(() -&gt; &#123; // your code here&#125;);// 3、通过 Executors.newVirtualThreadPerTaskExecutor() 创建var executorService = Executors.newVirtualThreadPerTaskExecutor();executorService.submit(() -&gt; &#123; // your code here&#125;);class CustomThread implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;CustomThread run&quot;); &#125;&#125;//4、通过 ThreadFactory 创建CustomThread customThread = new CustomThread();// 获取线程工厂类ThreadFactory factory = Thread.ofVirtual().factory();// 创建虚拟线程Thread thread = factory.newThread(customThread);// 启动线程thread.start(); 通过上述列举的 4 种创建虚拟线程的方式可以看出，官方为了降低虚拟线程的门槛，尽力复用原有的 Thread 线程类，这样可以平滑的过渡到虚拟线程的使用。 JEP 437: 结构化并发(第二次孵化)Java 19 引入了结构化并发，一种多线程编程方法，目的是为了通过结构化并发 API 来简化多线程编程，并不是为了取代java.util.concurrent，目前处于孵化器阶段。 结构化并发将不同线程中运行的多个任务视为单个工作单元，从而简化错误处理、提高可靠性并增强可观察性。也就是说，结构化并发保留了单线程代码的可读性、可维护性和可观察性。 结构化并发的基本 API 是StructuredTaskScope。StructuredTaskScope 支持将任务拆分为多个并发子任务，在它们自己的线程中执行，并且子任务必须在主任务继续之前完成。 StructuredTaskScope 的基本用法如下： 123456789try (var scope = new StructuredTaskScope&lt;Object&gt;()) &#123; // 使用fork方法派生线程来执行子任务 Future&lt;Integer&gt; future1 = scope.fork(task1); Future&lt;String&gt; future2 = scope.fork(task2); // 等待线程完成 scope.join(); // 结果的处理可能包括处理或重新抛出异常 ... process results/exceptions ... &#125; // close 结构化并发非常适合虚拟线程，虚拟线程是 JDK 实现的轻量级线程。许多虚拟线程共享同一个操作系统线程，从而允许非常多的虚拟线程。 JDK 20 中对结构化并发唯一变化是更新为支持在任务范围内创建的线程StructuredTaskScope继承范围值 这简化了跨线程共享不可变数据，详见JEP 429。 JEP 432：向量 API（第五次孵化）向量计算由对向量的一系列操作组成。向量 API 用来表达向量计算，该计算可以在运行时可靠地编译为支持的 CPU 架构上的最佳向量指令，从而实现优于等效标量计算的性能。 向量 API 的目标是为用户提供简洁易用且与平台无关的表达范围广泛的向量计算。 向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。 Java20 的这次孵化基本没有改变向量 API ，只是进行了一些错误修复和性能增强，详见 JEP 438。","tags":["Java","新特性","Java20"],"categories":["Java","新特性","Java20"]},{"title":"14.Java 19 新特性概览","path":"/2023/12/27/14-Java-19-新特性概览/","content":"JDK 19 定于 2022 年 9 月 20 日正式发布以供生产使用，非长期支持版本。不过，JDK 19 中有一些比较重要的新特性值得关注。 JDK 19 只有 7 个新特性： JEP 405: Record Patterns（记录模式）（预览） JEP 422: Linux&#x2F;RISC-V Port JEP 424: Foreign Function &amp; Memory API（外部函数和内存 API）（预览） JEP 425: Virtual Threads（虚拟线程）（预览） JEP 426: Vector（向量）API（第四次孵化） JEP 427: Pattern Matching for switch（switch 模式匹配） JEP 428: Structured Concurrency（结构化并发）（孵化） 这里只对 424、425、426、428 这 4 个我觉得比较重要的新特性进行详细介绍。 相关阅读：OpenJDK Java 19 文档 JEP 424: 外部函数和内存 API（预览）Java 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。 外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。第二轮孵化由JEP 419 提出并集成到了 Java 18 中，预览由 JEP 424 提出并集成到了 Java 19 中。 在没有外部函数和内存 API 之前： Java 通过 sun.misc.Unsafe 提供一些执行低级别、不安全操作的方法（如直接访问系统内存资源、自主管理内存资源等），Unsafe 类让 Java 语言拥有了类似 C 语言指针一样操作内存空间的能力的同时，也增加了 Java 语言的不安全性，不正确使用 Unsafe 类会使得程序出错的概率变大。 Java 1.1 就已通过 Java 原生接口（JNI）支持了原生方法调用，但并不好用。JNI 实现起来过于复杂，步骤繁琐（具体的步骤可以参考这篇文章：Guide to JNI (Java Native Interface) ），不受 JVM 的语言安全机制控制，影响 Java 语言的跨平台特性。并且，JNI 的性能也不行，因为 JNI 方法调用不能从许多常见的 JIT 优化(如内联)中受益。虽然JNA、JNR和JavaCPP等框架对 JNI 进行了改进，但效果还是不太理想。 引入外部函数和内存 API 就是为了解决 Java 访问外部函数和外部内存存在的一些痛点。 Foreign Function &amp; Memory API (FFM API) 定义了类和接口： 分配外部内存：MemorySegment、、MemoryAddress和SegmentAllocator）； 操作和访问结构化的外部内存：MemoryLayout, VarHandle； 控制外部内存的分配和释放：MemorySession； 调用外部函数：Linker、FunctionDescriptor和SymbolLookup。 下面是 FFM API 使用示例，这段代码获取了 C 库函数的 radixsort 方法句柄，然后使用它对 Java 数组中的四个字符串进行排序。 123456789101112131415161718192021222324// 1. 在C库路径上查找外部函数Linker linker = Linker.nativeLinker();SymbolLookup stdlib = linker.defaultLookup();MethodHandle radixSort = linker.downcallHandle( stdlib.lookup(&quot;radixsort&quot;), ...);// 2. 分配堆上内存以存储四个字符串String[] javaStrings = &#123; &quot;mouse&quot;, &quot;cat&quot;, &quot;dog&quot;, &quot;car&quot; &#125;;// 3. 分配堆外内存以存储四个指针SegmentAllocator allocator = implicitAllocator();MemorySegment offHeap = allocator.allocateArray(ValueLayout.ADDRESS, javaStrings.length);// 4. 将字符串从堆上复制到堆外for (int i = 0; i &lt; javaStrings.length; i++) &#123; // 在堆外分配一个字符串，然后存储指向它的指针 MemorySegment cString = allocator.allocateUtf8String(javaStrings[i]); offHeap.setAtIndex(ValueLayout.ADDRESS, i, cString);&#125;// 5. 通过调用外部函数对堆外数据进行排序radixSort.invoke(offHeap, javaStrings.length, MemoryAddress.NULL, &#x27;\\0&#x27;);// 6. 将(重新排序的)字符串从堆外复制到堆上for (int i = 0; i &lt; javaStrings.length; i++) &#123; MemoryAddress cStringPtr = offHeap.getAtIndex(ValueLayout.ADDRESS, i); javaStrings[i] = cStringPtr.getUtf8String(0);&#125;assert Arrays.equals(javaStrings, new String[] &#123;&quot;car&quot;, &quot;cat&quot;, &quot;dog&quot;, &quot;mouse&quot;&#125;); // true JEP 425: 虚拟线程（预览）虚拟线程（Virtual Thread-）是 JDK 而不是 OS 实现的轻量级线程(Lightweight Process，LWP），许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。 虚拟线程在其他多线程语言中已经被证实是十分有用的，比如 Go 中的 Goroutine、Erlang 中的进程。 虚拟线程避免了上下文切换的额外耗费，兼顾了多线程的优点，简化了高并发程序的复杂，可以有效减少编写、维护和观察高吞吐量并发应用程序的工作量。 知乎有一个关于 Java 19 虚拟线程的讨论，感兴趣的可以去看看：https://www.zhihu.com/question/536743167 。 Java 虚拟线程的详细解读和原理可以看下面这两篇文章： Java19 正式 GA！看虚拟线程如何大幅提高系统吞吐量 虚拟线程 - VirtualThread 源码透视 JEP 426: 向量 API（第四次孵化）向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。 在 Java 18 新特性概览 中，我有详细介绍到向量 API，这里就不再做额外的介绍了。 JEP 428: 结构化并发(孵化)JDK 19 引入了结构化并发，一种多线程编程方法，目的是为了通过结构化并发 API 来简化多线程编程，并不是为了取代java.util.concurrent，目前处于孵化器阶段。 结构化并发将不同线程中运行的多个任务视为单个工作单元，从而简化错误处理、提高可靠性并增强可观察性。也就是说，结构化并发保留了单线程代码的可读性、可维护性和可观察性。 结构化并发的基本 API 是StructuredTaskScope。StructuredTaskScope 支持将任务拆分为多个并发子任务，在它们自己的线程中执行，并且子任务必须在主任务继续之前完成。 StructuredTaskScope 的基本用法如下： 123456789try (var scope = new StructuredTaskScope&lt;Object&gt;()) &#123; // 使用fork方法派生线程来执行子任务 Future&lt;Integer&gt; future1 = scope.fork(task1); Future&lt;String&gt; future2 = scope.fork(task2); // 等待线程完成 scope.join(); // 结果的处理可能包括处理或重新抛出异常 ... process results/exceptions ... &#125; // close 结构化并发非常适合虚拟线程，虚拟线程是 JDK 实现的轻量级线程。许多虚拟线程共享同一个操作系统线程，从而允许非常多的虚拟线程。","tags":["Java","新特性","Java19"],"categories":["Java","新特性","Java19"]},{"title":"13.Java 18 新特性概览","path":"/2023/12/27/13-Java-18-新特性概览/","content":"Java 18 在 2022 年 3 月 22 日正式发布，非长期支持版本。 Java 18 带来了 9 个新特性： JEP 400:UTF-8 by Default（默认字符集为 UTF-8） JEP 408:Simple Web Server（简易的 Web 服务器） JEP 413:Code Snippets in Java API Documentation（Java API 文档中的代码片段） JEP 416:Reimplement Core Reflection with Method Handles（使用方法句柄重新实现反射核心） JEP 417:Vector（向量） API（第三次孵化） JEP 418:Internet-Address Resolution（互联网地址解析）SPI JEP 419:Foreign Function &amp; Memory API（外部函数和内存 API）（第二次孵化） JEP 420:Pattern Matching for switch（switch 模式匹配）（第二次预览） JEP 421:Deprecate Finalization for Removal Java 17 中包含 14 个特性，Java 16 中包含 17 个特性，Java 15 中包含 14 个特性，Java 14 中包含 16 个特性。相比于前面发布的版本来说，Java 18 的新特性少了很多。 这里只对 400、408、413、416、417、418、419 这几个我觉得比较重要的新特性进行详细介绍。 相关阅读： OpenJDK Java 18 文档 IntelliJ IDEA | Java 18 功能支持 JEP 400:默认字符集为 UTF-8JDK 终于将 UTF-8 设置为默认字符集。 在 Java 17 及更早版本中，默认字符集是在 Java 虚拟机运行时才确定的，取决于不同的操作系统、区域设置等因素，因此存在潜在的风险。就比如说你在 Mac 上运行正常的一段打印文字到控制台的 Java 程序到了 Windows 上就会出现乱码，如果你不手动更改字符集的话。 JEP 408:简易的 Web 服务器Java 18 之后，你可以使用 jwebserver 命令启动一个简易的静态 Web 服务器。 1234$ jwebserverBinding to loopback by default. For all interfaces use &quot;-b 0.0.0.0&quot; or &quot;-b ::&quot;.Serving /cwd and subdirectories on 127.0.0.1 port 8000URL: http://127.0.0.1:8000/ 这个服务器不支持 CGI 和 Servlet，只限于静态文件。 JEP 413:优化 Java API 文档中的代码片段在 Java 18 之前，如果我们想要在 Javadoc 中引入代码片段可以使用 &lt;pre&gt;&#123;@code ...&#125;&lt;/pre&gt; 。 123&lt;pre&gt;&#123;@code lines of source code&#125;&lt;/pre&gt; {@code ...} 这种方式生成的效果比较一般。 在 Java 18 之后，可以通过 @snippet 标签来做这件事情。 12345678/** * The following code shows how to use &#123;@code Optional.isPresent&#125;: * &#123;@snippet : * if (v.isPresent()) &#123; * System.out.println(&quot;v: &quot; + v.get()); * &#125; * &#125; */ @snippet 这种方式生成的效果更好且使用起来更方便一些。 JEP 416:使用方法句柄重新实现反射核心Java 18 改进了 java.lang.reflect.Method、Constructor 的实现逻辑，使之性能更好，速度更快。这项改动不会改动相关 API ，这意味着开发中不需要改动反射相关代码，就可以体验到性能更好反射。 OpenJDK 官方给出了新老实现的反射性能基准测试结果。 JEP 417: 向量 API（第三次孵化）向量（Vector） API 最初由 JEP 338 提出，并作为孵化 API集成到 Java 16 中。第二轮孵化由 JEP 414 提出并集成到 Java 17 中，第三轮孵化由 JEP 417 提出并集成到 Java 18 中，第四轮由 JEP 426 提出并集成到了 Java 19 中。 向量计算由对向量的一系列操作组成。向量 API 用来表达向量计算，该计算可以在运行时可靠地编译为支持的 CPU 架构上的最佳向量指令，从而实现优于等效标量计算的性能。 向量 API 的目标是为用户提供简洁易用且与平台无关的表达范围广泛的向量计算。 这是对数组元素的简单标量计算： 12345void scalarComputation(float[] a, float[] b, float[] c) &#123; for (int i = 0; i &lt; a.length; i++) &#123; c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f; &#125;&#125; 这是使用 Vector API 进行的等效向量计算： 123456789101112131415161718static final VectorSpecies&lt;Float&gt; SPECIES = FloatVector.SPECIES_PREFERRED;void vectorComputation(float[] a, float[] b, float[] c) &#123; int i = 0; int upperBound = SPECIES.loopBound(a.length); for (; i &lt; upperBound; i += SPECIES.length()) &#123; // FloatVector va, vb, vc; var va = FloatVector.fromArray(SPECIES, a, i); var vb = FloatVector.fromArray(SPECIES, b, i); var vc = va.mul(va) .add(vb.mul(vb)) .neg(); vc.intoArray(c, i); &#125; for (; i &lt; a.length; i++) &#123; c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f; &#125;&#125; 在 JDK 18 中，向量 API 的性能得到了进一步的优化。 JEP 418:互联网地址解析 SPIJava 18 定义了一个全新的 SPI（service-provider interface），用于主要名称和地址的解析，以便 java.net.InetAddress 可以使用平台之外的第三方解析器。 JEP 419:Foreign Function &amp; Memory API（第二次孵化）Java 程序可以通过该 API 与 Java 运行时之外的代码和数据进行互操作。通过高效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存（即不受 JVM 管理的内存），该 API 使 Java 程序能够调用本机库并处理本机数据，而不会像 JNI 那样危险和脆弱。 外部函数和内存 API 在 Java 17 中进行了第一轮孵化，由 JEP 412 提出。第二轮孵化由JEP 419 提出并集成到了 Java 18 中，预览由 JEP 424 提出并集成到了 Java 19 中。 在Java 19 新特性中，我有详细介绍到外部函数和内存 API，这里就不再做额外的介绍了。","tags":["Java","新特性","Java18"],"categories":["Java","新特性","Java18"]},{"title":"12.Java 17 新特性概述","path":"/2023/12/27/12-Java-17-新特性概述/","content":"JDK 17 在 2021 年 9 月 14 号正式发布了！根据发布的规划，这次发布的 JDK 17 是一个长期维护的版本（LTS)。Java 17 提供了数千个性能、稳定性和安全性更新，以及 14 个 JEP（JDK 增强提案），进一步改进了 Java 语言和平台，以帮助开发人员提高工作效率。JDK 17 包括新的语言增强、库更新、对新 Apple (Mx CPU)计算机的支持、旧功能的删除和弃用，并努力确保今天编写的 Java 代码在未来的 JDK 版本中继续工作而不会发生变化。它还提供语言功能预览和孵化 API，以收集 Java 社区的反馈。 知识体系 语言特性增强密封的类和接口（正式版） 封闭类可以是封闭类和或者封闭接口，用来增强 Java 编程语言，防止其他类或接口扩展或实现它们。这个特性由Java 15的预览版本晋升为正式版本。 密封的类和接口解释和应用 因为我们引入了sealed class或interfaces，这些class或者interfaces只允许被指定的类或者interface进行扩展和实现。 使用修饰符sealed，您可以将一个类声明为密封类。密封的类使用reserved关键字permits列出可以直接扩展它的类。子类可以是最终的，非密封的或密封的。 之前我们的代码是这样的。 1234567public class Person &#123; &#125; //人 class Teacher extends Person &#123; &#125;//教师 class Worker extends Person &#123; &#125; //工人 class Student extends Person&#123; &#125; //学生 但是我们现在要限制 Person类 只能被这三个类继承，不能被其他类继承，需要这么做。 123456789101112131415161718// 添加sealed修饰符，permits后面跟上只能被继承的子类名称public sealed class Person permits Teacher, Worker, Student&#123; &#125; //人 // 子类可以被修饰为 finalfinal class Teacher extends Person &#123; &#125;//教师 // 子类可以被修饰为 non-sealed，此时 Worker类就成了普通类，谁都可以继承它non-sealed class Worker extends Person &#123; &#125; //工人// 任何类都可以继承Workerclass AnyClass extends Worker&#123;&#125; //子类可以被修饰为 sealed,同上sealed class Student extends Person permits MiddleSchoolStudent,GraduateStudent&#123; &#125; //学生 final class MiddleSchoolStudent extends Student &#123; &#125; //中学生 final class GraduateStudent extends Student &#123; &#125; //研究生 很强很实用的一个特性，可以限制类的层次结构。 补充：它是由Amber项目孵化而来（会经历两轮以上预览版本） 什么是Amber项目? Amber 项目的目标是探索和孵化更小的、以生产力为导向的 Java 语言功能，这些功能已被 OpenJDK JEP 流程接受为候选 JEP。本项目由 Compiler Group 赞助。 大多数 Amber 功能在成为 Java 平台的正式部分之前至少要经过两轮预览。对于给定的功能，每轮预览和最终标准化都有单独的 JEP。此页面仅链接到某个功能的最新 JEP。此类 JEP 可能会酌情链接到该功能的早期 JEP。 工具库的更新JEP 306：恢复始终严格的浮点语义Java 编程语言和 Java 虚拟机最初只有严格的浮点语义。从 Java 1.2 开始，默认情况下允许在这些严格语义中进行微小的变化，以适应当时硬件架构的限制。这些差异不再有帮助或必要，因此已被 JEP 306 删除。 JEP 356：增强的伪随机数生成器 为伪随机数生成器 (PRNG) 提供新的接口类型和实现。这一变化提高了不同 PRNG 的互操作性，并使得根据需求请求算法变得容易，而不是硬编码特定的实现。简单而言只需要理解如下三个问题： @pdai JDK 17之前如何生成随机数？ Random 类 典型的使用如下，随机一个int值 12345678910111213141516171819// random intnew Random().nextInt();/** * description 获取指定位数的随机数 * * @param length 1 * @return java.lang.String */public static String getRandomString(int length) &#123; String base = &quot;abcdefghijklmnopqrstuvwxyz0123456789&quot;; Random random = new Random(); StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; length; i++) &#123; int number = random.nextInt(base.length()); sb.append(base.charAt(number)); &#125; return sb.toString();&#125; ThreadLocalRandom 类 提供线程间独立的随机序列。它只有一个实例，多个线程用到这个实例，也会在线程内部各自更新状态。它同时也是 Random 的子类，不过它几乎把所有 Random 的方法又实现了一遍。 12345678910111213141516171819/** * nextInt(bound) returns 0 &lt;= value &lt; bound; repeated calls produce at * least two distinct results */public void testNextIntBounded() &#123; // sample bound space across prime number increments for (int bound = 2; bound &lt; MAX_INT_BOUND; bound += 524959) &#123; int f = ThreadLocalRandom.current().nextInt(bound); assertTrue(0 &lt;= f &amp;&amp; f &lt; bound); int i = 0; int j; while (i &lt; NCALLS &amp;&amp; (j = ThreadLocalRandom.current().nextInt(bound)) == f) &#123; assertTrue(0 &lt;= j &amp;&amp; j &lt; bound); ++i; &#125; assertTrue(i &lt; NCALLS); &#125;&#125; SplittableRandom 类 非线程安全，但可以 fork 的随机序列实现，适用于拆分子任务的场景。 1234567891011/** * Repeated calls to nextLong produce at least two distinct results */public void testNextLong() &#123; SplittableRandom sr = new SplittableRandom(); long f = sr.nextLong(); int i = 0; while (i &lt; NCALLS &amp;&amp; sr.nextLong() == f) ++i; assertTrue(i &lt; NCALLS);&#125; 为什么需要增强？ 上述几个类实现代码质量和接口抽象不佳 缺少常见的伪随机算法 自定义扩展随机数的算法只能自己去实现，缺少统一的接口 增强后是什么样的？代码的优化自不必说，我们就看下新增了哪些常见的伪随机算法 如何使用这个呢？可以使用RandomGenerator 1RandomGenerator g = RandomGenerator.of(&quot;L64X128MixRandom&quot;); JEP 382：新的macOS渲染管道 使用 Apple Metal API 为 macOS 实现 Java 2D 管道。新管道将减少 JDK 对已弃用的 Apple OpenGL API 的依赖。 目前默认情况下，这是禁用的，因此渲染仍然使用OpenGL API；要启用metal，应用程序应通过设置系统属性指定其使用： 1-Dsun.java2d.metal=true Metal或OpenGL的使用对应用程序是透明的，因为这是内部实现的区别，对Java API没有影响。Metal管道需要macOS 10.14.x或更高版本。在早期版本上设置它的尝试将被忽略。 新的平台支持JEP 391：支持macOS AArch64将 JDK 移植到 macOS&#x2F;AArch64 平台。该端口将允许 Java 应用程序在新的基于 Arm 64 的 Apple Silicon 计算机上本地运行。 旧功能的删除和弃用JEP 398：弃用 Applet API所有网络浏览器供应商要么已取消对 Java 浏览器插件的支持，要么已宣布计划这样做。 Applet API 已于 2017 年 9 月在 Java 9 中弃用，但并未移除。 JEP 407：删除 RMI 激活删除远程方法调用 (RMI) 激活机制，同时保留 RMI 的其余部分。 JEP 410：删除实验性 AOT 和 JIT 编译器实验性的基于 Java 的提前 (AOT) 和即时 (JIT) 编译器是实验性功能，并未得到广泛采用。作为可选，它们已经从 JDK 16 中删除。这个 JEP 从 JDK 源代码中删除了这些组件。 JEP 411：弃用安全管理器以进行删除安全管理器可以追溯到 Java 1.0。多年来，它一直不是保护客户端 Java 代码的主要方法，也很少用于保护服务器端代码。在未来的版本中将其删除将消除重大的维护负担，并使 Java 平台能够向前发展。 新功能的预览和孵化APIJEP 406：新增switch模式匹配（预览版）允许针对多个模式测试表达式，每个模式都有特定的操作，以便可以简洁安全地表达复杂的面向数据的查询。 JEP 412：外部函数和内存api （第一轮孵化）改进了 JDK 14 和 JDK 15 中引入的孵化 API，使 Java 程序能够与 Java 运行时之外的代码和数据进行互操作。通过有效地调用外部函数（即 JVM 之外的代码）和安全地访问外部内存，这些 API 使 Java 程序能够调用本地库和处理本地数据，而不会像 Java 本地接口 (JNI) 那样脆弱和复杂。这些 API 正在巴拿马项目中开发，旨在改善 Java 和非 Java 代码之间的交互。 JEP 414：Vector API（第二轮孵化） 如下内容来源于https://xie.infoq.cn/article/8304c894c4e38318d38ceb116，作者是九叔 AVX（Advanced Vector Extensions，高级向量扩展）实际上是 x86-64 处理器上的一套 SIMD（Single Instruction Multiple Data，单指令多数据流）指令集，相对于 SISD（Single instruction, Single dat，单指令流但数据流）而言，SIMD 非常适用于 CPU 密集型场景，因为向量计算允许在同一个 CPU 时钟周期内对多组数据批量进行数据运算，执行性能非常高效，甚至从某种程度上来看，向量运算似乎更像是一种并行任务，而非像标量计算那样，在同一个 CPU 时钟周期内仅允许执行一组数据运算，存在严重的执行效率低下问题。 随着 Java16 的正式来临，开发人员可以在程序中使用 Vector API 来实现各种复杂的向量计算，由 JIT 编译器 Server Compiler(C2)在运行期将其编译为对应的底层 AVX 指令执行。当然，在讲解如何使用 Vector API 之前，我们首先来看一个简单的标量计算程序。示例： 123456789void scalarComputation() &#123; var a = new float[10000000]; var b = new float[10000000]; // 省略数组a和b的赋值操作 var c = new float[10000000]; for (int i = 0; i &lt; a.length; i++) &#123; c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f; &#125;&#125; 在上述程序示例中，循环体内每次只能执行一组浮点运算，总共需要执行约 1000 万次才能够获得最终的运算结果，可想而知，这样的执行效率必然低效。值得庆幸的是，从 Java6 的时代开始，Java 的设计者们就在 HotSpot 虚拟机中引入了一种被称之为 SuperWord 的自动向量优化算法，该算法缺省会将循环体内的标量计算自动优化为向量计算，以此来提升数据运算时的执行效率。当然，我们可以通过虚拟机参数-XX:-UseSuperWord来显式关闭这项优化（从实际测试结果来看，如果不开启自动向量优化，存在约 20%~22%之间的性能下降）。 在此大家需要注意，尽管 HotSpot 缺省支持自动向量优化，但局限性仍然非常明显，首先，JIT 编译器 Server Compiler(C2)仅仅只会对循环体内的代码块做向量优化，并且这样的优化也是极不可靠的；其次，对于一些复杂的向量运算，SuperWord 则显得无能为力。因此，在一些特定场景下（比如：机器学习，线性代数，密码学等），建议大家还是尽可能使用 Java16 为大家提供的 Vector API 来实现复杂的向量计算。示例： 1234567891011121314151617// 定义256bit的向量浮点运算static final VectorSpecies&lt;Float&gt; SPECIES = FloatVector.SPECIES_256;void vectorComputation(float[] a, float[] b, float[] c) &#123; var i = 0; var upperBound = SPECIES.loopBound(a.length); for (; i &lt; upperBound; i += SPECIES.length()) &#123; var va = FloatVector.fromArray(SPECIES, a, i); var vb = FloatVector.fromArray(SPECIES, b, i); var vc = va.mul(va). add(vb.mul(vb)). neg(); vc.intoArray(c, i); &#125; for (; i &lt; a.length; i++) &#123; c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f; &#125;&#125; 值得注意的是，Vector API 包含在 jdk.incubator.vector 模块中，程序中如果需要使用 Vector API 则需要在 module-info.java 文件中引入该模块。： 123module java16.test&#123; requires jdk.incubator.vector;&#125; JEP 389：外部链接器 API（孵化器）该孵化器 API 提供了静态类型、纯 Java 访问原生代码的特性，该 API 将大大简化绑定原生库的原本复杂且容易出错的过程。Java 1.1 就已通过 Java 原生接口（JNI）支持了原生方法调用，但并不好用。Java 开发人员应该能够为特定任务绑定特定的原生库。它还提供了外来函数支持，而无需任何中间的 JNI 粘合代码。 JEP 393：外部存储器访问 API（第三次孵化） 在 Java 14 和 Java 15 中作为孵化器 API 引入的这个 API 使 Java 程序能够安全有效地对各种外部存储器（例如本机存储器、持久性存储器、托管堆存储器等）进行操作。它提供了外部链接器 API 的基础。 如下内容来源于https://xie.infoq.cn/article/8304c894c4e38318d38ceb116，作者是九叔 在实际的开发过程中，绝大多数的开发人员基本都不会直接与堆外内存打交道，但这并不代表你从未接触过堆外内存，像大家经常使用的诸如：RocketMQ、MapDB 等中间件产品底层实现都是基于堆外存储的，换句话说，我们几乎每天都在间接与堆外内存打交道。那么究竟为什么需要使用到堆外内存呢？简单来说，主要是出于以下 3 个方面的考虑： 减少 GC 次数和降低 Stop-the-world 时间； 可以扩展和使用更大的内存空间； 可以省去物理内存和堆内存之间的数据复制步骤。 在 Java14 之前，如果开发人员想要操作堆外内存，通常的做法就是使用 ByteBuffer 或者 Unsafe，甚至是 JNI 等方式，但无论使用哪一种方式，均无法同时有效解决安全性和高效性等 2 个问题，并且，堆外内存的释放也是一个令人头痛的问题。以 DirectByteBuffer 为例，该对象仅仅只是一个引用，其背后还关联着一大段堆外内存，由于 DirectByteBuffer 对象实例仍然是存储在堆空间内，只有当 DirectByteBuffer 对象被 GC 回收时，其背后的堆外内存才会被进一步释放。 在此大家需要注意，程序中通过 ByteBuffer.allocateDirect()方法来申请物理内存资源所耗费的成本远远高于直接在 on-heap 中的操作，而且实际开发过程中还需要考虑数据结构如何设计、序列化&#x2F;反序列化如何支撑等诸多难题，所以与其使用语法层面的 API 倒不如直接使用 MapDB 等开源产品来得更实惠。 如今，在堆外内存领域，我们似乎又多了一个选择，从 Java14 开始，Java 的设计者们在语法层面为大家带来了崭新的 Memory Access API，极大程度上简化了开发难度，并得以有效的解决了安全性和高效性等 2 个核心问题。示例： 12345678910// 获取内存访问var句柄var handle = MemoryHandles.varHandle(char.class, ByteOrder.nativeOrder());// 申请200字节的堆外内存try (MemorySegment segment = MemorySegment.allocateNative(200)) &#123; for (int i = 0; i &lt; 25; i++) &#123; handle.set(segment, i &lt;&lt; 2, (char) (i + 1 + 64)); System.out.println(handle.get(segment, i &lt;&lt; 2)); &#125;&#125; 关于堆外内存段的释放，Memory Access API 提供有显式和隐式 2 种方式，开发人员除了可以在程序中通过 MemorySegment 的 close()方法来显式释放所申请的内存资源外，还可以注册 Cleaner 清理器来实现资源的隐式释放，后者会在 GC 确定目标内存段不再可访问时，释放与之关联的堆外内存资源。 参考文章 https://www.oracle.com/news/announcement/oracle-releases-java-17-2021-09-14/ https://openjdk.java.net/projects/amber/ https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/random/package-summary.html","tags":["Java","新特性","Java17"],"categories":["Java","新特性","Java17"]},{"title":"11.Java 16 新特性概述","path":"/2023/12/27/11-Java-16-新特性概述/","content":"JDK 16 在 2021 年 3 月 16 号发布！根据发布的规划，这次发布的 JDK 17 是一个长期维护的版本（LTS)。Java 16 提供了数千个性能、稳定性和安全性更新，以及 17 个 JEP（JDK 增强提案），进一步改进了 Java 语言和平台，以帮助开发人员提高工作效率。 知识体系 语言特性增强JEP 394: instanceof 模式匹配（正式版） 模式匹配（Pattern Matching）最早在 Java 14 中作为预览特性引入，在 Java 15 中还是预览特性，在Java 16中成为正式版。模式匹配通过对 instacneof 运算符进行模式匹配来增强 Java 编程语言。 如下内容来自Java14 对 instanceof 的改进，主要目的是为了让创建对象更简单、简洁和高效，并且可读性更强、提高安全性。 在以往实际使用中，instanceof 主要用来检查对象的类型，然后根据类型对目标对象进行类型转换，之后进行不同的处理、实现不同的逻辑，具体可以参考如下： 123456789if (person instanceof Student) &#123; Student student = (Student) person; student.say(); // other student operations&#125; else if (person instanceof Teacher) &#123; Teacher teacher = (Teacher) person; teacher.say(); // other teacher operations&#125; 上述代码中，我们首先需要对 person 对象进行类型判断，判断 person 具体是 Student 还是 Teacher，因为这两种角色对应不同操作，亦即对应到的实际逻辑实现，判断完 person 类型之后，然后强制对 person 进行类型转换为局部变量，以方便后续执行属于该角色的特定操作。 上面这种写法，有下面两个问题： 每次在检查类型之后，都需要强制进行类型转换。 类型转换后，需要提前创建一个局部变量来接收转换后的结果，代码显得多余且繁琐。 对 instanceof 进行模式匹配改进之后，上面示例代码可以改写成： 1234567if (person instanceof Student student) &#123; student.say(); // other student operations&#125; else if (person instanceof Teacher teacher) &#123; teacher.say(); // other teacher operations&#125; 首先在 if 代码块中，对 person 对象进行类型匹配，校验 person 对象是否为 Student 类型，如果类型匹配成功，则会转换为 Student 类型，并赋值给模式局部变量 student，并且只有当模式匹配表达式匹配成功是才会生效和复制，同时这里的 student 变量只能在 if 块中使用，而不能在 else if&#x2F;else 中使用，否则会报编译错误。 注意，如果 if 条件中有 &amp;&amp; 运算符时，当 instanceof 类型匹配成功，模式局部变量的作用范围也可以相应延长，如下面代码： 1if (obj instanceof String s &amp;&amp; s.length() &gt; 5) &#123;.. s.contains(..) ..&#125; 另外，需要注意，这种作用范围延长，并不适用于或 || 运算符，因为即便 || 运算符左边的 instanceof 类型匹配没有成功也不会造成短路，依旧会执行到||运算符右边的表达式，但是此时，因为 instanceof 类型匹配没有成功，局部变量并未定义赋值，此时使用会产生问题。 与传统写法对比，可以发现模式匹配不但提高了程序的安全性、健壮性，另一方面，不需要显式的去进行二次类型转换，减少了大量不必要的强制类型转换。模式匹配变量在模式匹配成功之后，可以直接使用，同时它还被限制了作用范围，大大提高了程序的简洁性、可读性和安全性。instanceof 的模式匹配，为 Java 带来的有一次便捷的提升，能够剔除一些冗余的代码，写出更加简洁安全的代码，提高码代码效率。 JEP 395: Records (正式版) Records 最早在 Java 14 中作为预览特性引入，在 Java 15 中还是预览特性，在Java 16中成为正式版。 如下内容来自Java14 Record 类型允许在代码中使用紧凑的语法形式来声明类，而这些类能够作为不可变数据类型的封装持有者。Record 这一特性主要用在特定领域的类上；与枚举类型一样，Record 类型是一种受限形式的类型，主要用于存储、保存数据，并且没有其它额外自定义行为的场景下。 在以往开发过程中，被当作数据载体的类对象，在正确声明定义过程中，通常需要编写大量的无实际业务、重复性质的代码，其中包括：构造函数、属性调用、访问以及 equals() 、hashCode()、toString() 等方法，因此在 Java 14 中引入了 Record 类型，其效果有些类似 Lombok 的 @Data 注解、Kotlin 中的 data class，但是又不尽完全相同，它们的共同点都是类的部分或者全部可以直接在类头中定义、描述，并且这个类只用于存储数据而已。对于 Record 类型，具体可以用下面代码来说明： 1234567public record Person(String name, int age) &#123; public static String address; public String getName() &#123; return name; &#125;&#125; 对上述代码进行编译，然后反编译之后可以看到如下结果： 123456789101112131415161718public final class Person extends java.lang.Record &#123; private final java.lang.String name; private final java.lang.String age; public Person(java.lang.String name, java.lang.String age) &#123; /* compiled code */ &#125; public java.lang.String getName() &#123; /* compiled code */ &#125; public java.lang.String toString() &#123; /* compiled code */ &#125; public final int hashCode() &#123; /* compiled code */ &#125; public final boolean equals(java.lang.Object o) &#123; /* compiled code */ &#125; public java.lang.String name() &#123; /* compiled code */ &#125; public java.lang.String age() &#123; /* compiled code */ &#125;&#125; 根据反编译结果，可以得出，当用 Record 来声明一个类时，该类将自动拥有下面特征： 拥有一个构造方法 获取成员属性值的方法：name()、age() hashCode() 方法和 euqals() 方法 toString() 方法 类对象和属性被 final 关键字修饰，不能被继承，类的示例属性也都被 final 修饰，不能再被赋值使用。 还可以在 Record 声明的类中定义静态属性、方法和示例方法。注意，不能在 Record 声明的类中定义示例字段，类也不能声明为抽象类等。 可以看到，该预览特性提供了一种更为紧凑的语法来声明类，并且可以大幅减少定义类似数据类型时所需的重复性代码。 另外 Java 14 中为了引入 Record 这种新的类型，在 java.lang.Class 中引入了下面两个新方法： 12RecordComponent[] getRecordComponents()boolean isRecord() 其中 getRecordComponents() 方法返回一组 java.lang.reflect.RecordComponent 对象组成的数组，java.lang.reflect.RecordComponent也是一个新引入类，该数组的元素与 Record 类中的组件相对应，其顺序与在记录声明中出现的顺序相同，可以从该数组中的每个 RecordComponent 中提取到组件信息，包括其名称、类型、泛型类型、注释及其访问方法。 而 isRecord() 方法，则返回所在类是否是 Record 类型，如果是，则返回 true。 新工具和库JEP 380：Unix-Domain 套接字通道Unix-domain 套接字一直是大多数 Unix 平台的一个特性，现在在 Windows 10 和 Windows Server 2019 也提供了支持。此特性为 java.nio.channels 包的套接字通道和服务器套接字通道 API 添加了 Unix-domain（AF_UNIX）套接字支持。它扩展了继承的通道机制以支持 Unix-domain 套接字通道和服务器套接字通道。Unix-domain 套接字用于同一主机上的进程间通信（IPC）。它们在很大程度上类似于 TCP&#x2F;IP，区别在于套接字是通过文件系统路径名而不是 Internet 协议（IP）地址和端口号寻址的。对于本地进程间通信，Unix-domain 套接字比 TCP&#x2F;IP 环回连接更安全、更有效。 JEP 390: 对基于值的类发出警告 JDK9注解@Deprecated得到了增强，增加了 since 和 forRemoval 两个属性，可以分别指定一个程序元素被废弃的版本，以及是否会在今后的版本中被删除。JDK16中对@jdk.internal.ValueBased注解加入了基于值的类的告警，所以继续在 Synchronized 同步块中使用值类型，将会在编译期和运行期产生警告，甚至是异常。 JDK9中@Deprecated增强了增加了 since 和 forRemoval 两 个属性 JDK9注解@Deprecated得到了增强，增加了 since 和 forRemoval 两个属性，可以分别指定一个程序元素被废弃的版本，以及是否会在今后的版本中被删除。 在如下的代码中，表示PdaiDeprecatedTest这个类在JDK9版本中被弃用并且在将来的某个版本中一定会被删除。 1234@Deprecated(since=&quot;9&quot;, forRemoval = true)public class PdaiDeprecatedTest &#123;&#125; JDK16中对基于值的类（@jdk.internal.ValueBased）给出告警 在JDK9中我们可以看到Integer.java类构造函数中加入了@Deprecated(since=&quot;9&quot;)，表示在JDK9版本中被弃用并且在将来的某个版本中一定会被删除 12345678910111213141516171819202122public final class Integer extends Number implements Comparable&lt;Integer&gt; &#123;// ... /** * Constructs a newly allocated &#123;@code Integer&#125; object that * represents the specified &#123;@code int&#125; value. * * @param value the value to be represented by the * &#123;@code Integer&#125; object. * * @deprecated * It is rarely appropriate to use this constructor. The static factory * &#123;@link #valueOf(int)&#125; is generally a better choice, as it is * likely to yield significantly better space and time performance. */ @Deprecated(since=&quot;9&quot;) public Integer(int value) &#123; this.value = value; &#125;// ... &#125; 如下是JDK16中Integer.java的代码 1234567891011121314151617181920212223242526272829303132333435363738394041/** &lt;p&gt;This is a &lt;a href=&quot;&#123;@docRoot&#125;/java.base/java/lang/doc-files/ValueBased.html&quot;&gt;value-based&lt;/a&gt; * class; programmers should treat instances that are * &#123;@linkplain #equals(Object) equal&#125; as interchangeable and should not * use instances for synchronization, or unpredictable behavior may * occur. For example, in a future release, synchronization may fail. * * &lt;p&gt;Implementation note: The implementations of the &quot;bit twiddling&quot; * methods (such as &#123;@link #highestOneBit(int) highestOneBit&#125; and * &#123;@link #numberOfTrailingZeros(int) numberOfTrailingZeros&#125;) are * based on material from Henry S. Warren, Jr.&#x27;s &lt;i&gt;Hacker&#x27;s * Delight&lt;/i&gt;, (Addison Wesley, 2002). * * @author Lee Boynton * @author Arthur van Hoff * @author Josh Bloch * @author Joseph D. Darcy * @since 1.0 */@jdk.internal.ValueBasedpublic final class Integer extends Number implements Comparable&lt;Integer&gt;, Constable, ConstantDesc &#123;// ... /** * Constructs a newly allocated &#123;@code Integer&#125; object that * represents the specified &#123;@code int&#125; value. * * @param value the value to be represented by the * &#123;@code Integer&#125; object. * * @deprecated * It is rarely appropriate to use this constructor. The static factory * &#123;@link #valueOf(int)&#125; is generally a better choice, as it is * likely to yield significantly better space and time performance. */ @Deprecated(since=&quot;9&quot;, forRemoval = true) public Integer(int value) &#123; this.value = value; &#125;// ... 添加@jdk.internal.ValueBased和@Deprecated(since=&quot;9&quot;, forRemoval = true)的作用是什么呢？ JDK设计者建议使用Integer a &#x3D; 10或者Integer.valueOf()函数，而不是new Integer()，让其抛出告警？ 在构造函数上都已经标记有@Deprecated(since&#x3D;”9”, forRemoval &#x3D; true)注解，这就意味着其构造函数在将来会被删除，不应该在程序中继续使用诸如new Integer(); 如果继续使用，编译期将会产生’Integer(int)’ is deprecated and marked for removal 告警。 在并发环境下，Integer 对象根本无法通过 Synchronized 来保证线程安全，让其抛出告警？ 由于JDK中对@jdk.internal.ValueBased注解加入了基于值的类的告警，所以继续在 Synchronized 同步块中使用值类型，将会在编译期和运行期产生警告，甚至是异常。 123456789public void inc(Integer count) &#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; synchronized (count) &#123; // 这里会产生编译告警 count++; &#125; &#125;).start(); &#125;&#125; JEP 392：打包工具（正式版）此特性最初是作为 Java 14 中的一个孵化器模块引入的，该工具允许打包自包含的 Java 应用程序。它支持原生打包格式，为最终用户提供自然的安装体验，这些格式包括 Windows 上的 msi 和 exe、macOS 上的 pkg 和 dmg，还有 Linux 上的 deb 和 rpm。它还允许在打包时指定启动时参数，并且可以从命令行直接调用，也可以通过 ToolProvider API 以编程方式调用。注意 jpackage 模块名称从 jdk.incubator.jpackage 更改为 jdk.jpackage。这将改善最终用户在安装应用程序时的体验，并简化了“应用商店”模型的部署。 JEP 396：默认强封装 JDK 内部元素此特性会默认强封装 JDK 的所有内部元素，但关键内部 API（例如 sun.misc.Unsafe）除外。默认情况下，使用早期版本成功编译的访问 JDK 内部 API 的代码可能不再起作用。鼓励开发人员从使用内部元素迁移到使用标准 API 的方法上，以便他们及其用户都可以无缝升级到将来的 Java 版本。强封装由 JDK 9 的启动器选项–illegal-access 控制，到 JDK 15 默认改为 warning，从 JDK 16 开始默认为 deny。（目前）仍然可以使用单个命令行选项放宽对所有软件包的封装，将来只有使用–add-opens 打开特定的软件包才行。 JVM 优化JEP 376：ZGC 并发线程处理JEP 376 将 ZGC 线程栈处理从安全点转移到一个并发阶段，甚至在大堆上也允许在毫秒内暂停 GC 安全点。消除 ZGC 垃圾收集器中最后一个延迟源可以极大地提高应用程序的性能和效率。 JEP 387：弹性元空间此特性可将未使用的 HotSpot 类元数据（即元空间，metaspace）内存更快速地返回到操作系统，从而减少元空间的占用空间。具有大量类加载和卸载活动的应用程序可能会占用大量未使用的空间。新方案将元空间内存按较小的块分配，它将未使用的元空间内存返回给操作系统来提高弹性，从而提高应用程序性能并降低内存占用。 新功能的预览和孵化JEP 338：向量 API（孵化器） 如下内容来源于https://xie.infoq.cn/article/8304c894c4e38318d38ceb116，作者是九叔 AVX（Advanced Vector Extensions，高级向量扩展）实际上是 x86-64 处理器上的一套 SIMD（Single Instruction Multiple Data，单指令多数据流）指令集，相对于 SISD（Single instruction, Single dat，单指令流但数据流）而言，SIMD 非常适用于 CPU 密集型场景，因为向量计算允许在同一个 CPU 时钟周期内对多组数据批量进行数据运算，执行性能非常高效，甚至从某种程度上来看，向量运算似乎更像是一种并行任务，而非像标量计算那样，在同一个 CPU 时钟周期内仅允许执行一组数据运算，存在严重的执行效率低下问题。 随着 Java16 的正式来临，开发人员可以在程序中使用 Vector API 来实现各种复杂的向量计算，由 JIT 编译器 Server Compiler(C2)在运行期将其编译为对应的底层 AVX 指令执行。当然，在讲解如何使用 Vector API 之前，我们首先来看一个简单的标量计算程序。示例： 123456789void scalarComputation() &#123; var a = new float[10000000]; var b = new float[10000000]; // 省略数组a和b的赋值操作 var c = new float[10000000]; for (int i = 0; i &lt; a.length; i++) &#123; c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f; &#125;&#125; 在上述程序示例中，循环体内每次只能执行一组浮点运算，总共需要执行约 1000 万次才能够获得最终的运算结果，可想而知，这样的执行效率必然低效。值得庆幸的是，从 Java6 的时代开始，Java 的设计者们就在 HotSpot 虚拟机中引入了一种被称之为 SuperWord 的自动向量优化算法，该算法缺省会将循环体内的标量计算自动优化为向量计算，以此来提升数据运算时的执行效率。当然，我们可以通过虚拟机参数-XX:-UseSuperWord来显式关闭这项优化（从实际测试结果来看，如果不开启自动向量优化，存在约 20%~22%之间的性能下降）。 在此大家需要注意，尽管 HotSpot 缺省支持自动向量优化，但局限性仍然非常明显，首先，JIT 编译器 Server Compiler(C2)仅仅只会对循环体内的代码块做向量优化，并且这样的优化也是极不可靠的；其次，对于一些复杂的向量运算，SuperWord 则显得无能为力。因此，在一些特定场景下（比如：机器学习，线性代数，密码学等），建议大家还是尽可能使用 Java16 为大家提供的 Vector API 来实现复杂的向量计算。示例： 1234567891011121314151617// 定义256bit的向量浮点运算static final VectorSpecies&lt;Float&gt; SPECIES = FloatVector.SPECIES_256;void vectorComputation(float[] a, float[] b, float[] c) &#123; var i = 0; var upperBound = SPECIES.loopBound(a.length); for (; i &lt; upperBound; i += SPECIES.length()) &#123; var va = FloatVector.fromArray(SPECIES, a, i); var vb = FloatVector.fromArray(SPECIES, b, i); var vc = va.mul(va). add(vb.mul(vb)). neg(); vc.intoArray(c, i); &#125; for (; i &lt; a.length; i++) &#123; c[i] = (a[i] * a[i] + b[i] * b[i]) * -1.0f; &#125;&#125; 值得注意的是，Vector API 包含在 jdk.incubator.vector 模块中，程序中如果需要使用 Vector API 则需要在 module-info.java 文件中引入该模块。： 123module java16.test&#123; requires jdk.incubator.vector;&#125; JEP 389：外部链接器 API（孵化器）该孵化器 API 提供了静态类型、纯 Java 访问原生代码的特性，该 API 将大大简化绑定原生库的原本复杂且容易出错的过程。Java 1.1 就已通过 Java 原生接口（JNI）支持了原生方法调用，但并不好用。Java 开发人员应该能够为特定任务绑定特定的原生库。它还提供了外来函数支持，而无需任何中间的 JNI 粘合代码。 JEP 393：外部存储器访问 API（第三次孵化） 在 Java 14 和 Java 15 中作为孵化器 API 引入的这个 API 使 Java 程序能够安全有效地对各种外部存储器（例如本机存储器、持久性存储器、托管堆存储器等）进行操作。它提供了外部链接器 API 的基础。 如下内容来源于https://xie.infoq.cn/article/8304c894c4e38318d38ceb116，作者是九叔 在实际的开发过程中，绝大多数的开发人员基本都不会直接与堆外内存打交道，但这并不代表你从未接触过堆外内存，像大家经常使用的诸如：RocketMQ、MapDB 等中间件产品底层实现都是基于堆外存储的，换句话说，我们几乎每天都在间接与堆外内存打交道。那么究竟为什么需要使用到堆外内存呢？简单来说，主要是出于以下 3 个方面的考虑： 减少 GC 次数和降低 Stop-the-world 时间； 可以扩展和使用更大的内存空间； 可以省去物理内存和堆内存之间的数据复制步骤。 在 Java14 之前，如果开发人员想要操作堆外内存，通常的做法就是使用 ByteBuffer 或者 Unsafe，甚至是 JNI 等方式，但无论使用哪一种方式，均无法同时有效解决安全性和高效性等 2 个问题，并且，堆外内存的释放也是一个令人头痛的问题。以 DirectByteBuffer 为例，该对象仅仅只是一个引用，其背后还关联着一大段堆外内存，由于 DirectByteBuffer 对象实例仍然是存储在堆空间内，只有当 DirectByteBuffer 对象被 GC 回收时，其背后的堆外内存才会被进一步释放。 在此大家需要注意，程序中通过 ByteBuffer.allocateDirect()方法来申请物理内存资源所耗费的成本远远高于直接在 on-heap 中的操作，而且实际开发过程中还需要考虑数据结构如何设计、序列化&#x2F;反序列化如何支撑等诸多难题，所以与其使用语法层面的 API 倒不如直接使用 MapDB 等开源产品来得更实惠。 如今，在堆外内存领域，我们似乎又多了一个选择，从 Java14 开始，Java 的设计者们在语法层面为大家带来了崭新的 Memory Access API，极大程度上简化了开发难度，并得以有效的解决了安全性和高效性等 2 个核心问题。示例： 12345678910// 获取内存访问var句柄var handle = MemoryHandles.varHandle(char.class, ByteOrder.nativeOrder());// 申请200字节的堆外内存try (MemorySegment segment = MemorySegment.allocateNative(200)) &#123; for (int i = 0; i &lt; 25; i++) &#123; handle.set(segment, i &lt;&lt; 2, (char) (i + 1 + 64)); System.out.println(handle.get(segment, i &lt;&lt; 2)); &#125;&#125; 关于堆外内存段的释放，Memory Access API 提供有显式和隐式 2 种方式，开发人员除了可以在程序中通过 MemorySegment 的 close()方法来显式释放所申请的内存资源外，还可以注册 Cleaner 清理器来实现资源的隐式释放，后者会在 GC 确定目标内存段不再可访问时，释放与之关联的堆外内存资源。 JEP 397：密封类（第二预览） 封闭类可以是封闭类和或者封闭接口，用来增强 Java 编程语言，防止其他类或接口扩展或实现它们。这个特性由Java 15的预览版本晋升为正式版本。 密封的类和接口解释和应用 因为我们引入了sealed class或interfaces，这些class或者interfaces只允许被指定的类或者interface进行扩展和实现。 使用修饰符sealed，您可以将一个类声明为密封类。密封的类使用reserved关键字permits列出可以直接扩展它的类。子类可以是最终的，非密封的或密封的。 之前我们的代码是这样的。 1234567public class Person &#123; &#125; //人 class Teacher extends Person &#123; &#125;//教师 class Worker extends Person &#123; &#125; //工人 class Student extends Person&#123; &#125; //学生 但是我们现在要限制 Person类 只能被这三个类继承，不能被其他类继承，需要这么做。 123456789101112131415161718// 添加sealed修饰符，permits后面跟上只能被继承的子类名称public sealed class Person permits Teacher, Worker, Student&#123; &#125; //人 // 子类可以被修饰为 finalfinal class Teacher extends Person &#123; &#125;//教师 // 子类可以被修饰为 non-sealed，此时 Worker类就成了普通类，谁都可以继承它non-sealed class Worker extends Person &#123; &#125; //工人// 任何类都可以继承Workerclass AnyClass extends Worker&#123;&#125; //子类可以被修饰为 sealed,同上sealed class Student extends Person permits MiddleSchoolStudent,GraduateStudent&#123; &#125; //学生 final class MiddleSchoolStudent extends Student &#123; &#125; //中学生 final class GraduateStudent extends Student &#123; &#125; //研究生 很强很实用的一个特性，可以限制类的层次结构。 提升 OpenJDK 开发人员的生产力 其余更改对使用 Java 开发人员（使用 Java 编写代码和运行应用程序的人员）不会直接可见，而只对 Java 开发人员（参与 OpenJDK 开发的人员）可见。 JEP 347：启用 C++14 语言特性（在 JDK 源代码中）它允许在 JDK C++ 源代码中使用 C++14 语言特性，并提供在 HotSpot 代码中可以使用哪些特性的具体指导。在 JDK 15 中，JDK 中 C++ 代码使用的语言特性仅限于 C++98&#x2F;03 语言标准。它要求更新各种平台编译器的最低可接受版本 JEP 357：从 Mercurial 迁移到 Git &amp; JEP 369，迁移到 GitHub这些 JEP 将 OpenJDK 社区的源代码存储库从 Mercurial（hg）迁移到 Git，并将它们托管在 GitHub 上以供 JDK 11 及更高版本使用，其中包括将 jcheck、webrev 和 defpath 工具等工具更新到 Git。Git 减小了元数据的大小（约 1&#x2F;4），可节省本地磁盘空间并减少克隆时间。与 Mercurial 相比，现代工具链可以更好地与 Git 集成。 Open JDK Git 存储库现在位于 https://github.com/openjdk。 JEP 386：AlpineLinux 移植 &amp; JEP 388：Windows&#x2F;AArch64 移植这些 JEP 的重点不是移植工作本身，而是将它们集成到 JDK 主线存储库中；JEP 386 将 JDK 移植到 Alpine Linux 和其他使用 musl 作为 x64 上主要 C 库的发行版上。此外，JEP 388 将 JDK 移植到 Windows AArch64（ARM64）。 参考文章 https://docs.oracle.com/en/java/javase/16/ https://xie.infoq.cn/article/8304c894c4e38318d38ceb116","tags":["Java","新特性","Java16"],"categories":["Java","新特性","Java16"]},{"title":"10.Java 15 新特性概述","path":"/2023/12/27/10-Java-15-新特性概述/","content":"JDK 15 在 2020 年 9 月 15 号正式发布了！根据发布的规划，这次发布的 JDK 15 将是一个短期的过度版，只会被 Oracle 支持（维护）6 个月，直到明年 3 月的 JDK 16 发布此版本将停止维护。而 Oracle 下一个长期支持版（LTS 版）会在明年的 9 月份候发布（Java 17），LTS 版每 3 年发布一个，上一次长期支持版是 18 年 9 月发布的 JDK 11。 知识体系 语言特性增强JEP 378: 文本块(Text Blocks) 文本块，是一个多行字符串，它可以避免使用大多数转义符号，自动以可预测的方式格式化字符串，并让开发人员在需要时可以控制格式。 Text Blocks首次是在JDK 13中以预览功能出现的，然后在JDK 14中又预览了一次，终于在JDK 15中被确定下来，可放心使用了。 12345678public static void main(String[] args) &#123; String query = &quot;&quot;&quot; SELECT * from USER \\ WHERE `id` = 1 \\ ORDER BY `id`, `name`;\\ &quot;&quot;&quot;; System.out.println(query);&#125; 运行程序，输出（可以看到展示为一行了）： 1SELECT * from USER WHERE `id` = 1 ORDER BY `id`, `name`; Java14中文本块相关介绍 新功能和库的更新JEP 339: Edwards-Curve 数字签名算法 (EdDSA) Edwards-Curve 数字签名算法（EdDSA），一种根据 RFC 8032 规范所描述的 Edwards-Curve 数字签名算法（EdDSA）实现加密签名，实现了一种 RFC 8032 标准化方案，但它不能代替 ECDSA。 与 JDK 中的现有签名方案相比，EdDSA 具有更高的安全性和性能，因此备受关注。它已经在OpenSSL和BoringSSL等加密库中得到支持，在区块链领域用的比较多。 EdDSA是一种现代的椭圆曲线方案，具有JDK中现有签名方案的优点。EdDSA将只在SunEC提供商中实现。 12345678910111213141516// example: generate a key pair and signKeyPairGenerator kpg = KeyPairGenerator.getInstance(&quot;Ed25519&quot;);KeyPair kp = kpg.generateKeyPair();// algorithm is pure Ed25519Signature sig = Signature.getInstance(&quot;Ed25519&quot;);sig.initSign(kp.getPrivate());sig.update(msg);byte[] s = sig.sign();// example: use KeyFactory to contruct a public keyKeyFactory kf = KeyFactory.getInstance(&quot;EdDSA&quot;);boolean xOdd = ...BigInteger y = ...NamedParameterSpec paramSpec = new NamedParameterSpec(&quot;Ed25519&quot;);EdECPublicKeySpec pubSpec = new EdECPublicKeySpec(paramSpec, new EdPoint(xOdd, y));PublicKey pubKey = kf.generatePublic(pubSpec); JEP 371: 隐藏类 Hidden Classes 隐藏类是为框架（frameworks）所设计的，隐藏类不能直接被其他类的字节码使用，只能在运行时生成类并通过反射间接使用它们。 该提案通过启用标准 API 来定义 无法发现 且 具有有限生命周期 的隐藏类，从而提高 JVM 上所有语言的效率。JDK内部和外部的框架将能够动态生成类，而这些类可以定义隐藏类。通常来说基于JVM的很多语言都有动态生成类的机制，这样可以提高语言的灵活性和效率。 隐藏类天生为框架设计的，在运行时生成内部的class。 隐藏类只能通过反射访问，不能直接被其他类的字节码访问。 隐藏类可以独立于其他类加载、卸载，这可以减少框架的内存占用。 Hidden Classes是什么呢？ Hidden Classes就是不能直接被其他class的二进制代码使用的class。Hidden Classes主要被一些框架用来生成运行时类，但是这些类不是被用来直接使用的，而是通过反射机制来调用。 比如在JDK8中引入的lambda表达式，JVM并不会在编译的时候将lambda表达式转换成为专门的类，而是在运行时将相应的字节码动态生成相应的类对象。 另外使用动态代理也可以为某些类生成新的动态类。 那么我们希望这些动态生成的类需要具有什么特性呢？ 不可发现性。 因为我们是为某些静态的类动态生成的动态类，所以我们希望把这个动态生成的类看做是静态类的一部分。所以我们不希望除了该静态类之外的其他机制发现。 访问控制。 我们希望在访问控制静态类的同时，也能控制到动态生成的类。 生命周期。 动态生成类的生命周期一般都比较短，我们并不需要将其保存和静态类的生命周期一致。 API的支持 所以我们需要一些API来定义无法发现的且具有有限生命周期的隐藏类。这将提高所有基于JVM的语言实现的效率。 比如： 123java.lang.reflect.Proxy // 可以定义隐藏类作为实现代理接口的代理类。 java.lang.invoke.StringConcatFactory // 可以生成隐藏类来保存常量连接方法； java.lang.invoke.LambdaMetaFactory //可以生成隐藏的nestmate类，以容纳访问封闭变量的lambda主体； 普通类是通过调用ClassLoader::defineClass创建的，而隐藏类是通过调用Lookup::defineHiddenClass创建的。这使JVM从提供的字节中派生一个隐藏类，链接该隐藏类，并返回提供对隐藏类的反射访问的查找对象。调用程序可以通过返回的查找对象来获取隐藏类的Class对象。 JEP 373: 重新实现 DatagramSocket API 重新实现了老的 DatagramSocket API 接口，更改了 java.net.DatagramSocket 和 java.net.MulticastSocket 为更加简单、现代化的底层实现，更易于维护和调试。 java.net.datagram.Socket和java.net.MulticastSocket的当前实现可以追溯到JDK 1.0，那时IPv6还在开发中。因此，当前的多播套接字实现尝试调和IPv4和IPv6难以维护的方式。 通过替换 java.net.datagram 的基础实现，重新实现旧版 DatagramSocket API。 更改java.net.DatagramSocket 和 java.net.MulticastSocket 为更加简单、现代化的底层实现。提高了 JDK 的可维护性和稳定性。 通过将java.net.datagram.Socket和java.net.MulticastSocket API的底层实现替换为更简单、更现代的实现来重新实现遗留的DatagramSocket API。 新的实现： 易于调试和维护; 与Project Loom中正在探索的虚拟线程协同。 JVM 优化JEP 373: ZGC: 可伸缩低延迟垃圾收集器 ZGC是Java 11引入的新的垃圾收集器（JDK9以后默认的垃圾回收器是G1），经过了多个实验阶段，自此终于成为正式特性。ZGC是一个重新设计的并发的垃圾回收器，可以极大的提升GC的性能。支持任意堆大小而保持稳定的低延迟（10ms以内），性能非常可观。目前默认垃圾回收器仍然是 G1，后续很有可以能将ZGC设为默认垃圾回收器。之前需要通过-XX:+UnlockExperimentalVMOptions -XX:+UseZGC来启用ZGC，现在只需要-XX:+UseZGC就可以。 以下是相关介绍： ZGC 是一个可伸缩的、低延迟的垃圾收集器，主要为了满足如下目标进行设计： GC 停顿时间不超过 10ms 即能处理几百 MB 的小堆，也能处理几个 TB 的大堆 应用吞吐能力不会下降超过 15%（与 G1 回收算法相比） 方便在此基础上引入新的 GC 特性和利用 colord 针以及 Load barriers 优化奠定基础 当前只支持 Linux&#x2F;x64 位平台 停顿时间在 10ms 以下，10ms 其实是一个很保守的数据，即便是 10ms 这个数据，也是 GC 调优几乎达不到的极值。根据 SPECjbb 2015 的基准测试，128G 的大堆下最大停顿时间才 1.68ms，远低于 10ms，和 G1 算法相比，改进非常明显。 本图片引用自： The Z Garbage Collector – An Introduction 不过目前 ZGC 还处于实验阶段，目前只在 Linux&#x2F;x64 上可用，如果有足够的需求，将来可能会增加对其他平台的支持。同时作为实验性功能的 ZGC 将不会出现在 JDK 构建中，除非在编译时使用 configure 参数： --with-jvm-features=zgc 显式启用。 在实验阶段，编译完成之后，已经迫不及待的想试试 ZGC，需要配置以下 JVM 参数，才能使用 ZGC，具体启动 ZGC 参数如下： 1-XX：+ UnlockExperimentalVMOptions -XX：+ UseZGC -Xmx10g 其中参数： -Xmx 是 ZGC 收集器中最重要的调优选项，大大解决了程序员在 JVM 参数调优上的困扰。ZGC 是一个并发收集器，必须要设置一个最大堆的大小，应用需要多大的堆，主要有下面几个考量： 对象的分配速率，要保证在 GC 的时候，堆中有足够的内存分配新对象。 一般来说，给 ZGC 的内存越多越好，但是也不能浪费内存，所以要找到一个平衡。 JEP 374: 禁用偏向锁定 准备禁用和废除偏向锁，在 JDK 15 中，默认情况下禁用偏向锁，并弃用所有相关的命令行选项。 在默认情况下禁用偏向锁定，并弃用所有相关命令行选项。目标是确定是否需要继续支持偏置锁定的 高维护成本 的遗留同步优化， HotSpot虚拟机使用该优化来减少非竞争锁定的开销。 尽管某些Java应用程序在禁用偏向锁后可能会出现性能下降，但偏向锁的性能提高通常不像以前那么明显。 该特性默认禁用了biased locking(-XX:+UseBiasedLocking)，并且废弃了所有相关的命令行选型(BiasedLockingStartupDelay, BiasedLockingBulkRebiasThreshold, BiasedLockingBulkRevokeThreshold, BiasedLockingDecayTime, UseOptoBiasInlining, PrintBiasedLockingStatistics and PrintPreciseBiasedLockingStatistics) JEP 379: Shenandoah：低暂停时间垃圾收集器(转正) Shenandoah垃圾回收算法终于从实验特性转变为产品特性，这是一个从 JDK 12 引入的回收算法，该算法通过与正在运行的 Java 线程同时进行疏散工作来减少 GC 暂停时间。Shenandoah 的暂停时间与堆大小无关，无论堆栈是 200 MB 还是 200 GB，都具有相同的一致暂停时间。 Shenandoah适用于高吞吐和大内存场景，不适合高实时性场景。Shenandoah算法设计目标主要是响应性和一致可控的短暂停顿，对于垃圾回收生命周期中安全点停顿（TTSP)和内存增长监控的时间开销并无帮助。 Shenandoah算法为每个Java对象添加了一个间接指针，使得GC线程能够在Java线程运行时压缩堆。标记和压缩是同时执行的，因此我们只需要暂停Java线程在一致可控的时间内扫描线程堆栈以查找和更新对象图的根。 怎么形容Shenandoah和ZGC的关系呢？异同点大概如下： 相同点：性能几乎可认为是相同的 不同点：ZGC是Oracle JDK的。而Shenandoah只存在于OpenJDK中，因此使用时需注意你的JDK版本 打开方式：使用-XX:+UseShenandoahGC命令行参数打开。 Shenandoah在JDK12被作为experimental引入，在JDK15变为Production；之前需要通过-XX:+UnlockExperimentalVMOptions -XX:+UseShenandoahGC来启用，现在只需要-XX:+UseShenandoahGC即可启用 旧功能的删除和弃用JEP 372: 移除Nashorn JavaScript引擎 移除了 Nashorn JavaScript 脚本引擎、APIs，以及 jjs 工具。这些早在 JDK 11 中就已经被标记为 deprecated 了，JDK 15 被移除就很正常了。 Nashorn引擎是什么？ Nashorn 是 JDK 1.8 引入的一个 JavaScript 脚本引擎，用来取代 Rhino 脚本引擎。Nashorn 是 ECMAScript-262 5.1 的完整实现，增强了 Java 和 JavaScript 的兼容性，并且大大提升了性能。 为什么要移除？ 官方的描述是，随着 ECMAScript 脚本语言的结构、API 的改编速度越来越快，维护 Nashorn 太有挑战性了，所以……。 JEP 381: 移除了 Solaris 和 SPARC 端口。 移除了 Solaris&#x2F;SPARC、Solaris&#x2F;x64 和 Linux&#x2F;SPARC 端口的源代码及构建支持。这些端口在 JDK 14 中就已经被标记为 deprecated 了，JDK 15 被移除也不奇怪。 删除对Solaris&#x2F;SPARC、Solaris&#x2F;x64和Linux&#x2F;SPARC端口的源代码和构建支持，在JDK 14中被标记为废弃，在JDK15版本正式移除。 许多正在开发的项目和功能（如Valhalla、Loom和Panama）需要进行重大更改以适应CPU架构和操作系统特定代码。 近年来，Solaris 和 SPARC 都已被 Linux 操作系统和英特尔处理器取代。放弃对 Solaris 和 SPARC 端口的支持将使 OpenJDK 社区的贡献者能够加速开发新功能，从而推动平台向前发展。 JEP 385: 废除 RMI 激活 RMI Activation被标记为Deprecate,将会在未来的版本中删除。RMI激活机制是RMI中一个过时的部分，自Java 8以来一直是可选的而非必选项。RMI激活机制增加了持续的维护负担。RMI的其他部分暂时不会被弃用。 RMI jdk1.2引入，EJB在RMI系统中，我们使用延迟激活。延迟激活将激活对象推迟到客户第一次使用（即第一次方法调用）之前。 既然RMI Activation这么好用，为什么要废弃呢？ 因为对于现代应用程序来说，分布式系统大部分都是基于Web的，web服务器已经解决了穿越防火墙，过滤请求，身份验证和安全性的问题，并且也提供了很多延迟加载的技术。 所以在现代应用程序中，RMI Activation已经很少被使用到了。并且在各种开源的代码库中，也基本上找不到RMI Activation的使用代码了。 为了减少RMI Activation的维护成本，在JDK8中，RMI Activation被置为可选的。现在在JDK15中，终于可以废弃了。 新功能的预览和孵化JEP 375: instanceof 自动匹配模式（第二次预览） 模式匹配（第二次预览），第一次预览是 JDK 14 中提出来的。 Java 14 之前： 1234567if (object instanceof Kid) &#123; Kid kid = (Kid) object; // ...&#125; else if (object instanceof Kiddle) &#123; Kid kid = (Kid) object; // ...&#125; Java 14+： 12345if (object instanceof Kid kid) &#123; // ...&#125; else if (object instanceof Kiddle kiddle) &#123; // ...&#125; Java 15 并没有对此特性进行调整，继续预览特性，只是为了收集更多的用户反馈，可能还不成熟吧。 JEP 360: 密封的类和接口（预览） 封闭类（预览特性），可以是封闭类和或者封闭接口，用来增强 Java 编程语言，防止其他类或接口扩展或实现它们。 因为我们引入了sealed class或interfaces，这些class或者interfaces只允许被指定的类或者interface进行扩展和实现。 使用修饰符sealed，您可以将一个类声明为密封类。密封的类使用reserved关键字permits列出可以直接扩展它的类。子类可以是最终的，非密封的或密封的。 之前我们的代码是这样的。 1234567public class Person &#123; &#125; //人 class Teacher extends Person &#123; &#125;//教师 class Worker extends Person &#123; &#125; //工人 class Student extends Person&#123; &#125; //学生 但是我们现在要限制 Person类 只能被这三个类继承，不能被其他类继承，需要这么做。 123456789101112131415161718// 添加sealed修饰符，permits后面跟上只能被继承的子类名称public sealed class Person permits Teacher, Worker, Student&#123; &#125; //人 // 子类可以被修饰为 finalfinal class Teacher extends Person &#123; &#125;//教师 // 子类可以被修饰为 non-sealed，此时 Worker类就成了普通类，谁都可以继承它non-sealed class Worker extends Person &#123; &#125; //工人// 任何类都可以继承Workerclass AnyClass extends Worker&#123;&#125; //子类可以被修饰为 sealed,同上sealed class Student extends Person permits MiddleSchoolStudent,GraduateStudent&#123; &#125; //学生 final class MiddleSchoolStudent extends Student &#123; &#125; //中学生 final class GraduateStudent extends Student &#123; &#125; //研究生 很强很实用的一个特性，可以限制类的层次结构。 JEP 383: 外部存储器访问 API（二次孵化器版） 外存访问 API（二次孵化），可以允许 Java 应用程序安全有效地访问 Java 堆之外的外部内存。目的是引入一个 API，以允许 Java 程序安全、有效地访问 Java 堆之外的外部存储器。如本机、持久和托管堆。如下内容来源于https://xie.infoq.cn/article/8304c894c4e38318d38ceb116，作者是九叔 在实际的开发过程中，绝大多数的开发人员基本都不会直接与堆外内存打交道，但这并不代表你从未接触过堆外内存，像大家经常使用的诸如：RocketMQ、MapDB 等中间件产品底层实现都是基于堆外存储的，换句话说，我们几乎每天都在间接与堆外内存打交道。那么究竟为什么需要使用到堆外内存呢？简单来说，主要是出于以下 3 个方面的考虑： 减少 GC 次数和降低 Stop-the-world 时间； 可以扩展和使用更大的内存空间； 可以省去物理内存和堆内存之间的数据复制步骤。 在 Java14 之前，如果开发人员想要操作堆外内存，通常的做法就是使用 ByteBuffer 或者 Unsafe，甚至是 JNI 等方式，但无论使用哪一种方式，均无法同时有效解决安全性和高效性等 2 个问题，并且，堆外内存的释放也是一个令人头痛的问题。以 DirectByteBuffer 为例，该对象仅仅只是一个引用，其背后还关联着一大段堆外内存，由于 DirectByteBuffer 对象实例仍然是存储在堆空间内，只有当 DirectByteBuffer 对象被 GC 回收时，其背后的堆外内存才会被进一步释放。 在此大家需要注意，程序中通过 ByteBuffer.allocateDirect()方法来申请物理内存资源所耗费的成本远远高于直接在 on-heap 中的操作，而且实际开发过程中还需要考虑数据结构如何设计、序列化&#x2F;反序列化如何支撑等诸多难题，所以与其使用语法层面的 API 倒不如直接使用 MapDB 等开源产品来得更实惠。 如今，在堆外内存领域，我们似乎又多了一个选择，从 Java14 开始，Java 的设计者们在语法层面为大家带来了崭新的 Memory Access API，极大程度上简化了开发难度，并得以有效的解决了安全性和高效性等 2 个核心问题。示例： 12345678910// 获取内存访问var句柄var handle = MemoryHandles.varHandle(char.class, ByteOrder.nativeOrder());// 申请200字节的堆外内存try (MemorySegment segment = MemorySegment.allocateNative(200)) &#123; for (int i = 0; i &lt; 25; i++) &#123; handle.set(segment, i &lt;&lt; 2, (char) (i + 1 + 64)); System.out.println(handle.get(segment, i &lt;&lt; 2)); &#125;&#125; 关于堆外内存段的释放，Memory Access API 提供有显式和隐式 2 种方式，开发人员除了可以在程序中通过 MemorySegment 的 close()方法来显式释放所申请的内存资源外，还可以注册 Cleaner 清理器来实现资源的隐式释放，后者会在 GC 确定目标内存段不再可访问时，释放与之关联的堆外内存资源。 JEP 384: Records (二次预览) Records 最早在 JDK 14 中成为预览特性，JDK 15 继续二次预览。 如下内容来自Java14 Record 类型允许在代码中使用紧凑的语法形式来声明类，而这些类能够作为不可变数据类型的封装持有者。Record 这一特性主要用在特定领域的类上；与枚举类型一样，Record 类型是一种受限形式的类型，主要用于存储、保存数据，并且没有其它额外自定义行为的场景下。 在以往开发过程中，被当作数据载体的类对象，在正确声明定义过程中，通常需要编写大量的无实际业务、重复性质的代码，其中包括：构造函数、属性调用、访问以及 equals() 、hashCode()、toString() 等方法，因此在 Java 14 中引入了 Record 类型，其效果有些类似 Lombok 的 @Data 注解、Kotlin 中的 data class，但是又不尽完全相同，它们的共同点都是类的部分或者全部可以直接在类头中定义、描述，并且这个类只用于存储数据而已。对于 Record 类型，具体可以用下面代码来说明： 1234567public record Person(String name, int age) &#123; public static String address; public String getName() &#123; return name; &#125;&#125; 对上述代码进行编译，然后反编译之后可以看到如下结果： 123456789101112131415161718public final class Person extends java.lang.Record &#123; private final java.lang.String name; private final java.lang.String age; public Person(java.lang.String name, java.lang.String age) &#123; /* compiled code */ &#125; public java.lang.String getName() &#123; /* compiled code */ &#125; public java.lang.String toString() &#123; /* compiled code */ &#125; public final int hashCode() &#123; /* compiled code */ &#125; public final boolean equals(java.lang.Object o) &#123; /* compiled code */ &#125; public java.lang.String name() &#123; /* compiled code */ &#125; public java.lang.String age() &#123; /* compiled code */ &#125;&#125; 根据反编译结果，可以得出，当用 Record 来声明一个类时，该类将自动拥有下面特征： 拥有一个构造方法 获取成员属性值的方法：name()、age() hashCode() 方法和 euqals() 方法 toString() 方法 类对象和属性被 final 关键字修饰，不能被继承，类的示例属性也都被 final 修饰，不能再被赋值使用。 还可以在 Record 声明的类中定义静态属性、方法和示例方法。注意，不能在 Record 声明的类中定义示例字段，类也不能声明为抽象类等。 可以看到，该预览特性提供了一种更为紧凑的语法来声明类，并且可以大幅减少定义类似数据类型时所需的重复性代码。 另外 Java 14 中为了引入 Record 这种新的类型，在 java.lang.Class 中引入了下面两个新方法： 12RecordComponent[] getRecordComponents()boolean isRecord() 其中 getRecordComponents() 方法返回一组 java.lang.reflect.RecordComponent 对象组成的数组，java.lang.reflect.RecordComponent也是一个新引入类，该数组的元素与 Record 类中的组件相对应，其顺序与在记录声明中出现的顺序相同，可以从该数组中的每个 RecordComponent 中提取到组件信息，包括其名称、类型、泛型类型、注释及其访问方法。 而 isRecord() 方法，则返回所在类是否是 Record 类型，如果是，则返回 true。 总结 OracleJDK 15 下载地址： https://www.oracle.com/java/technologies/javase-downloads.html OpenJDK 15 地址： https://openjdk.java.net/projects/jdk/15/ 参考文章 https://openjdk.java.net/projects/jdk/15/ https://www.cnblogs.com/javastack/p/13683220.html https://blog.csdn.net/cyberherman/article/details/109253931 https://my.oschina.net/u/4262150/blog/4656149","tags":["Java","新特性","Java15"],"categories":["Java","新特性","Java15"]},{"title":"9.Java 14 新特性概述","path":"/2023/12/27/9-Java-14-新特性概述/","content":"Java 14 已如期于 2020 年 3 月 17 日正式发布，此次更新是继半年前 Java 13 这大版本发布之后的又一次常规版本更新，即便在全球疫情如此严峻形势下，依然保持每六个月的版本更新频率，为大家及时带来改进和增强，这一点值得点赞。在这一版中，主要带来了 ZGC 增强、instanceof 增强、Switch 表达式更新为标准版等方面的改动、增强和新功能。本文主要介绍 Java 14 中的主要新特性，带您快速了解 Java 14 带来了哪些不一样的体验和便利。 知识体系 语言特性增强JEP 359: Switch 表达式（正式版）switch 表达式在之前的 Java 12 和 Java 13 中都是处于预览阶段，而在这次更新的 Java 14 中，终于成为稳定版本，能够正式可用。 switch 表达式带来的不仅仅是编码上的简洁、流畅，也精简了 switch 语句的使用方式，同时也兼容之前的 switch 语句的使用；之前使用 switch 语句时，在每个分支结束之前，往往都需要加上 break 关键字进行分支跳出，以防 switch 语句一直往后执行到整个 switch 语句结束，由此造成一些意想不到的问题。switch 语句一般使用冒号 ：来作为语句分支代码的开始，而 switch 表达式则提供了新的分支切换方式，即 -&gt; 符号右则表达式方法体在执行完分支方法之后，自动结束 switch 分支，同时 -&gt; 右则方法块中可以是表达式、代码块或者是手动抛出的异常。以往的 switch 语句写法如下： 清单 9. Switch 语句 123456789101112131415161718192021int dayOfWeek;switch (day) &#123; case MONDAY: case FRIDAY: case SUNDAY: dayOfWeek = 6; break; case TUESDAY: dayOfWeek = 7; break; case THURSDAY: case SATURDAY: dayOfWeek = 8; break; case WEDNESDAY: dayOfWeek = 9; break; default: dayOfWeek = 0; break;&#125; 而现在 Java 14 可以使用 switch 表达式正式版之后，上面语句可以转换为下列写法： 清单 10. Switch 表达式 12345678int dayOfWeek = switch (day) &#123; case MONDAY, FRIDAY, SUNDAY -&gt; 6; case TUESDAY -&gt; 7; case THURSDAY, SATURDAY -&gt; 8;case WEDNESDAY -&gt; 9; default -&gt; 0;&#125;; 很明显，switch 表达式将之前 switch 语句从编码方式上简化了不少，但是还是需要注意下面几点： 需要保持与之前 switch 语句同样的 case 分支情况。 之前需要用变量来接收返回值，而现在直接使用 yield 关键字来返回 case 分支需要返回的结果。 现在的 switch 表达式中不再需要显式地使用 return、break 或者 continue 来跳出当前分支。 现在不需要像之前一样，在每个分支结束之前加上 break 关键字来结束当前分支，如果不加，则会默认往后执行，直到遇到 break 关键字或者整个 switch 语句结束，在 Java 14 表达式中，表达式默认执行完之后自动跳出，不会继续往后执行。 对于多个相同的 case 方法块，可以将 case 条件并列，而不需要像之前一样，通过每个 case 后面故意不加 break 关键字来使用相同方法块。 使用 switch 表达式来替换之前的 switch 语句，确实精简了不少代码，提高了编码效率，同时也可以规避一些可能由于不太经意而出现的意想不到的情况，可见 Java 在提高使用者编码效率、编码体验和简化使用方面一直在不停的努力中，同时也期待未来有更多的类似 lambda、switch 表达式这样的新特性出来。 新功能和库的更新JEP 358: 改进 NullPointerExceptions 提示信息Java 14 改进 NullPointerException 的可查性、可读性，能更准确地定位 null 变量的信息。该特性能够帮助开发者和技术支持人员提高生产力，以及改进各种开发工具和调试工具的质量，能够更加准确、清楚地根据动态异常与程序代码相结合来理解程序。 相信每位开发者在实际编码过程中都遇到过 NullPointerException，每当遇到这种异常的时候，都需要根据打印出来的详细信息来分析、定位出现问题的原因，以在程序代码中规避或解决。例如，假设下面代码出现了一个 NullPointerException： 1book.id = 99; 打印出来的 NullPointerException 信息如下： 清单 4. NullPointerException 信息 12Exception in thread &quot;main&quot; java.lang.NullPointerException at Book.main(Book.java:5) 像上面这种异常，因为代码比较简单，并且异常信息中也打印出来了行号信息，开发者可以很快速定位到出现异常位置：book 为空而导致的 NullPointerException，而对于一些复杂或者嵌套的情况下出现 NullPointerException 时，仅根据打印出来的信息，很难判断实际出现问题的位置，具体见下面示例： 1shoopingcart.buy.book.id = 99; 对于这种比较复杂的情况下，仅仅单根据异常信息中打印的行号，则比较难判断出现 NullPointerException 的原因。 而 Java 14 中，则做了对 NullPointerException 打印异常信息的改进增强，通过分析程序的字节码信息，能够做到准确的定位到出现 NullPointerException 的变量，并且根据实际源代码打印出详细异常信息，对于上述示例，打印信息如下： 清单 5. NullPointerException 详细信息 123Exception in thread &quot;main&quot; java.lang.NullPointerException: Cannot assign field &quot;book&quot; because &quot;shoopingcart.buy&quot; is null at Book.main(Book.java:5) 对比可以看出，改进之后的 NullPointerException 信息，能够准确打印出具体哪个变量导致的 NullPointerException，减少了由于仅带行号的异常提示信息带来的困惑。该改进功能可以通过如下参数开启： 1-XX:+ShowCodeDetailsInExceptionMessages 该增强改进特性，不仅适用于属性访问，还适用于方法调用、数组访问和赋值等有可能会导致 NullPointerException 的地方。 旧功能的删除和弃用JEP 367: 删除 pack200 和 unpack200 工具删除 pack200 和 unpack200 工具，以及 java.util.jar 包中的 Pack200 API。这些工具和 API 在 Java SE 11 中已被弃用，以便在未来的版本中删除它们。 JVM 相关JEP 345: G1 的 NUMA 可识别内存分配Java 14 改进非一致性内存访问（NUMA）系统上的 G1 垃圾收集器的整体性能，主要是对年轻代的内存分配进行优化，从而提高 CPU 计算过程中内存访问速度。 NUMA 是 non-unified memory access 的缩写，主要是指在当前的多插槽物理计算机体系中，比较普遍是多核的处理器，并且越来越多的具有 NUMA 内存访问体系结构，即内存与每个插槽或内核之间的距离并不相等。同时套接字之间的内存访问具有不同的性能特征，对更远的套接字的访问通常具有更多的时间消耗。这样每个核对于每一块或者某一区域的内存访问速度会随着核和物理内存所在的位置的远近而有不同的时延差异。 Java 中，堆内存分配一般发生在线程运行的时候，当创建了一个新对象时，该线程会触发 G1 去分配一块内存出来，用来存放新创建的对象，在 G1 内存体系中，其实就是一块 region（大对象除外，大对象需要多个 region），在这个分配新内存的过程中，如果支持了 NUMA 感知内存分配，将会优先在与当前线程所绑定的 NUMA 节点空闲内存区域来执行 allocate 操作，同一线程创建的对象，尽可能的保留在年轻代的同一 NUMA 内存节点上，因为是基于同一个线程创建的对象大部分是短存活并且高概率互相调用的。 具体启用方式可以在 JVM 参数后面加上如下参数: 1-XX:+UseNUMA 通过这种方式来启用可识别的内存分配方式，能够提高一些大型计算机的 G1 内存分配回收性能。 JEP 363: 删除 CMS 垃圾回收器CMS 是老年代垃圾回收算法，通过标记-清除的方式进行内存回收，在内存回收过程中能够与用户线程并行执行。CMS 回收器可以与 Serial 回收器和 Parallel New 回收器搭配使用，CMS 主要通过并发的方式，适当减少系统的吞吐量以达到追求响应速度的目的，比较适合在追求 GC 速度的服务器上使用。 因为 CMS 回收算法在进行 GC 回收内存过程中是使用并行方式进行的，如果服务器 CPU 核数不多的情况下，进行 CMS 垃圾回收有可能造成比较高的负载。同时在 CMS 并行标记和并行清理时，应用线程还在继续运行，程序在运行过程中自然会创建新对象、释放不用对象，所以在这个过程中，会有新的不可达内存地址产生，而这部分的不可达内存是出现在标记过程结束之后，本轮 CMS 回收无法在周期内将它们回收掉，只能留在下次垃圾回收周期再清理掉。这样的垃圾就叫做浮动垃圾。由于垃圾收集和用户线程是并发执行的，因此 CMS 回收器不能像其他回收器那样进行内存回收，需要预留一些空间用来保存用户新创建的对象。由于 CMS 回收器在老年代中使用标记-清除的内存回收策略，势必会产生内存碎片，内存当碎片过多时，将会给大对象分配带来麻烦，往往会出现老年代还有空间但不能再保存对象的情况。 所以，早在几年前的 Java 9 中，就已经决定放弃使用 CMS 回收器了，而这次在 Java 14 中，是继之前 Java 9 中放弃使用 CMS 之后，彻底将其禁用，并删除与 CMS 有关的选项，同时清除与 CMS 有关的文档内容，至此曾经辉煌一度的 CMS 回收器，也将成为历史。 当在 Java 14 版本中，通过使用参数： -XX:+UseConcMarkSweepGC，尝试使用 CMS 时，将会收到下面信息： 12Java HotSpot(TM) 64-Bit Server VM warning: Ignoring option UseConcMarkSweepGC; \\support was removed in &lt;version&gt; JEP 364&amp;365: ZGC 支持 MacOS 和 Windows 系统（实验阶段）ZGC 是最初在 Java 11 中引入，同时在后续几个版本中，不断进行改进的一款基于内存 Region，同时使用了内存读屏障、染色指针和内存多重映射等技，并且以可伸缩、低延迟为目标的内存垃圾回收器器，不过在 Java 14 之前版本中，仅仅只支持在 Linux&#x2F;x64 位平台。 此次 Java 14，同时支持 MacOS 和 Windows 系统，解决了开发人员需要在桌面操作系统中使用 ZGC 的问题。 在 MacOS 和 Windows 下面开启 ZGC 的方式，需要添加如下 JVM 参数： 1-XX:+UnlockExperimentalVMOptions -XX:+UseZGC JEP 366: 弃用 ParallelScavenge 和 SerialOld GC 的组合使用由于 Parallel Scavenge 和 Serial Old 垃圾收集算法组合起来使用的情况比较少，并且在年轻代中使用并行算法，而在老年代中使用串行算法，这种并行、串行混搭使用的情况，本身已属罕见同时也很冒险。由于这两 GC 算法组合很少使用，却要花费巨大工作量来进行维护，所以在 Java 14 版本中，考虑将这两 GC 的组合弃用。 具体弃用情况如下，通过弃用组合参数：-XX:+UseParallelGC -XX:-UseParallelOldGC，来弃用年轻代、老年期中并行、串行混搭使用的情况；同时，对于单独使用参数：-XX:-UseParallelOldGC 的地方，也将显示该参数已被弃用的警告信息。 新功能的预览和实验JEP 305: instanceof 模式匹配（预览阶段）Java 14 中对 instanceof 的改进，主要目的是为了让创建对象更简单、简洁和高效，并且可读性更强、提高安全性。 在以往实际使用中，instanceof 主要用来检查对象的类型，然后根据类型对目标对象进行类型转换，之后进行不同的处理、实现不同的逻辑，具体可以参考清单 1： 清单 1. instanceof 传统使用方式 123456789if (person instanceof Student) &#123; Student student = (Student) person; student.say(); // other student operations&#125; else if (person instanceof Teacher) &#123; Teacher teacher = (Teacher) person; teacher.say(); // other teacher operations&#125; 上述代码中，我们首先需要对 person 对象进行类型判断，判断 person 具体是 Student 还是 Teacher，因为这两种角色对应不同操作，亦即对应到的实际逻辑实现，判断完 person 类型之后，然后强制对 person 进行类型转换为局部变量，以方便后续执行属于该角色的特定操作。 上面这种写法，有下面两个问题： 每次在检查类型之后，都需要强制进行类型转换。 类型转换后，需要提前创建一个局部变量来接收转换后的结果，代码显得多余且繁琐。 Java 14 中，对 instanceof 进行模式匹配改进之后，上面示例代码可以改写成： 清单 2. instanceof 模式匹配使用方式 1234567if (person instanceof Student student) &#123; student.say(); // other student operations&#125; else if (person instanceof Teacher teacher) &#123; teacher.say(); // other teacher operations&#125; 清单 2 中，首先在 if 代码块中，对 person 对象进行类型匹配，校验 person 对象是否为 Student 类型，如果类型匹配成功，则会转换为 Student 类型，并赋值给模式局部变量 student，并且只有当模式匹配表达式匹配成功是才会生效和复制，同时这里的 student 变量只能在 if 块中使用，而不能在 else if&#x2F;else 中使用，否则会报编译错误。 注意，如果 if 条件中有 &amp;&amp; 运算符时，当 instanceof 类型匹配成功，模式局部变量的作用范围也可以相应延长，如下面代码： 清单 3. Instanceof 模式匹配 &amp;&amp; 方式 1if (obj instanceof String s &amp;&amp; s.length() &gt; 5) &#123;.. s.contains(..) ..&#125; 另外，需要注意，这种作用范围延长，并不适用于或 || 运算符，因为即便 || 运算符左边的 instanceof 类型匹配没有成功也不会造成短路，依旧会执行到||运算符右边的表达式，但是此时，因为 instanceof 类型匹配没有成功，局部变量并未定义赋值，此时使用会产生问题。 与传统写法对比，可以发现模式匹配不但提高了程序的安全性、健壮性，另一方面，不需要显式的去进行二次类型转换，减少了大量不必要的强制类型转换。模式匹配变量在模式匹配成功之后，可以直接使用，同时它还被限制了作用范围，大大提高了程序的简洁性、可读性和安全性。instanceof 的模式匹配，为 Java 带来的有一次便捷的提升，能够剔除一些冗余的代码，写出更加简洁安全的代码，提高码代码效率。 JEP 359: Record 类型（预览功能）Java 14 富有建设性地将 Record 类型作为预览特性而引入。Record 类型允许在代码中使用紧凑的语法形式来声明类，而这些类能够作为不可变数据类型的封装持有者。Record 这一特性主要用在特定领域的类上；与枚举类型一样，Record 类型是一种受限形式的类型，主要用于存储、保存数据，并且没有其它额外自定义行为的场景下。 在以往开发过程中，被当作数据载体的类对象，在正确声明定义过程中，通常需要编写大量的无实际业务、重复性质的代码，其中包括：构造函数、属性调用、访问以及 equals() 、hashCode()、toString() 等方法，因此在 Java 14 中引入了 Record 类型，其效果有些类似 Lombok 的 @Data 注解、Kotlin 中的 data class，但是又不尽完全相同，它们的共同点都是类的部分或者全部可以直接在类头中定义、描述，并且这个类只用于存储数据而已。对于 Record 类型，具体可以用下面代码来说明： 清单 6. Record 类型定义 1234567public record Person(String name, int age) &#123; public static String address; public String getName() &#123; return name; &#125;&#125; 对上述代码进行编译，然后反编译之后可以看到如下结果： 清单 7. Record 类型反编译结果 123456789101112131415161718public final class Person extends java.lang.Record &#123; private final java.lang.String name; private final java.lang.String age; public Person(java.lang.String name, java.lang.String age) &#123; /* compiled code */ &#125; public java.lang.String getName() &#123; /* compiled code */ &#125; public java.lang.String toString() &#123; /* compiled code */ &#125; public final int hashCode() &#123; /* compiled code */ &#125; public final boolean equals(java.lang.Object o) &#123; /* compiled code */ &#125; public java.lang.String name() &#123; /* compiled code */ &#125; public java.lang.String age() &#123; /* compiled code */ &#125;&#125; 根据反编译结果，可以得出，当用 Record 来声明一个类时，该类将自动拥有下面特征： 拥有一个构造方法 获取成员属性值的方法：name()、age() hashCode() 方法和 euqals() 方法 toString() 方法 类对象和属性被 final 关键字修饰，不能被继承，类的示例属性也都被 final 修饰，不能再被赋值使用。 还可以在 Record 声明的类中定义静态属性、方法和示例方法。注意，不能在 Record 声明的类中定义示例字段，类也不能声明为抽象类等。 可以看到，该预览特性提供了一种更为紧凑的语法来声明类，并且可以大幅减少定义类似数据类型时所需的重复性代码。 另外 Java 14 中为了引入 Record 这种新的类型，在 java.lang.Class 中引入了下面两个新方法： 清单 8. Record 新引入至 Class 中的方法 12RecordComponent[] getRecordComponents()boolean isRecord() 其中 getRecordComponents() 方法返回一组 java.lang.reflect.RecordComponent 对象组成的数组，java.lang.reflect.RecordComponent也是一个新引入类，该数组的元素与 Record 类中的组件相对应，其顺序与在记录声明中出现的顺序相同，可以从该数组中的每个 RecordComponent 中提取到组件信息，包括其名称、类型、泛型类型、注释及其访问方法。 而 isRecord() 方法，则返回所在类是否是 Record 类型，如果是，则返回 true。 JEP 368: 文本块（第二预览版本）Java 13 引入了文本块来解决多行文本的问题，文本块主要以三重双引号开头，并以同样的以三重双引号结尾终止，它们之间的任何内容都被解释为文本块字符串的一部分，包括换行符，避免了对大多数转义序列的需要，并且它仍然是普通的 java.lang.String 对象，文本块可以在 Java 中能够使用字符串的任何地方进行使用，而与编译后的代码没有区别，还增强了 Java 程序中的字符串可读性。并且通过这种方式，可以更直观地表示字符串，可以支持跨越多行，而且不会出现转义的视觉混乱，将可以广泛提高 Java 类程序的可读性和可写性。 Java 14 在 Java 13 引入的文本块的基础之上，新加入了两个转义符，分别是：\\ 和 \\s，这两个转义符分别表达涵义如下： \\：行终止符，主要用于阻止插入换行符； \\s：表示一个空格。可以用来避免末尾的白字符被去掉。 在 Java 13 之前，多行字符串写法为： 清单 11. 多行字符串写法 123String literal = &quot;Lorem ipsum dolor sit amet, consectetur adipiscing &quot; + &quot;elit, sed do eiusmod tempor incididunt ut labore &quot; + &quot;et dolore magna aliqua.&quot;; 在 Java 14 新引入两个转义符之后，上述内容可以写为： 清单 12. 多行文本块加上转义符的写法 12345String text = &quot;&quot;&quot; Lorem ipsum dolor sit amet, consectetur adipiscing \\ elit, sed do eiusmod tempor incididunt ut labore \\ et dolore magna aliqua.\\ &quot;&quot;&quot;; 上述两种写法，text 实际还是只有一行内容。 对于转义符：\\s，用法如下，能够保证下列文本每行正好都是六个字符长度： 清单 13. 多行文本块加上转义符的写法 12345String colors = &quot;&quot;&quot; red \\s green\\s blue \\s &quot;&quot;&quot;; Java 14 带来的这两个转义符，能够简化跨多行字符串编码问题，通过转义符，能够避免对换行等特殊字符串进行转移，从而简化代码编写，同时也增强了使用 String 来表达 HTML、XML、SQL 或 JSON 等格式字符串的编码可读性，且易于维护。 同时 Java 14 还对 String 进行了方法扩展： stripIndent() ：用于从文本块中去除空白字符 translateEscapes()：用于翻译转义字符 formatted(Object... args)：用于格式化 JEP 343: 打包工具（孵化器版本）创建用于打包自包含 Java 应用程序的工具。 它基于 JavaFX javapackager 工具创建一个简单的打包工具，主要目标是： 支持原生打包格式，为最终用户提供自然的安装体验。这些格式包括 Windows 上的 msi 和 exe，macOS 上的 pkg 和 dmg，以及 Linux 上的 deb 和 rpm。 允许在打包时指定启动时间参数。 可以从命令行直接调用，也可以通过 ToolProvider API 以编程方式调用。 JEP 370: 外部存储器访问 API（孵化器版） 外存访问 API（二次孵化），可以允许 Java 应用程序安全有效地访问 Java 堆之外的外部内存。目的是引入一个 API，以允许 Java 程序安全、有效地访问 Java 堆之外的外部存储器。如本机、持久和托管堆。如下内容来源于https://xie.infoq.cn/article/8304c894c4e38318d38ceb116，作者是九叔 在实际的开发过程中，绝大多数的开发人员基本都不会直接与堆外内存打交道，但这并不代表你从未接触过堆外内存，像大家经常使用的诸如：RocketMQ、MapDB 等中间件产品底层实现都是基于堆外存储的，换句话说，我们几乎每天都在间接与堆外内存打交道。那么究竟为什么需要使用到堆外内存呢？简单来说，主要是出于以下 3 个方面的考虑： 减少 GC 次数和降低 Stop-the-world 时间； 可以扩展和使用更大的内存空间； 可以省去物理内存和堆内存之间的数据复制步骤。 在 Java14 之前，如果开发人员想要操作堆外内存，通常的做法就是使用 ByteBuffer 或者 Unsafe，甚至是 JNI 等方式，但无论使用哪一种方式，均无法同时有效解决安全性和高效性等 2 个问题，并且，堆外内存的释放也是一个令人头痛的问题。以 DirectByteBuffer 为例，该对象仅仅只是一个引用，其背后还关联着一大段堆外内存，由于 DirectByteBuffer 对象实例仍然是存储在堆空间内，只有当 DirectByteBuffer 对象被 GC 回收时，其背后的堆外内存才会被进一步释放。 在此大家需要注意，程序中通过 ByteBuffer.allocateDirect()方法来申请物理内存资源所耗费的成本远远高于直接在 on-heap 中的操作，而且实际开发过程中还需要考虑数据结构如何设计、序列化&#x2F;反序列化如何支撑等诸多难题，所以与其使用语法层面的 API 倒不如直接使用 MapDB 等开源产品来得更实惠。 如今，在堆外内存领域，我们似乎又多了一个选择，从 Java14 开始，Java 的设计者们在语法层面为大家带来了崭新的 Memory Access API，极大程度上简化了开发难度，并得以有效的解决了安全性和高效性等 2 个核心问题。示例： 12345678910// 获取内存访问var句柄var handle = MemoryHandles.varHandle(char.class, ByteOrder.nativeOrder());// 申请200字节的堆外内存try (MemorySegment segment = MemorySegment.allocateNative(200)) &#123; for (int i = 0; i &lt; 25; i++) &#123; handle.set(segment, i &lt;&lt; 2, (char) (i + 1 + 64)); System.out.println(handle.get(segment, i &lt;&lt; 2)); &#125;&#125; 关于堆外内存段的释放，Memory Access API 提供有显式和隐式 2 种方式，开发人员除了可以在程序中通过 MemorySegment 的 close()方法来显式释放所申请的内存资源外，还可以注册 Cleaner 清理器来实现资源的隐式释放，后者会在 GC 确定目标内存段不再可访问时，释放与之关联的堆外内存资源。 结束语Java 在更新版本周期为每半年发布一次之后，目前来看，确实是严格保持每半年更新的节奏。Java 14 版本的发布带来了不少新特性、功能实用性的增强、性能提升和 GC 方面的改进尝试。本文仅针对其中对使用人员影响较大的以及其中主要的特性做了介绍，如有兴趣，您还可以自行下载相关代码，继续深入研究。 参考文章 本文转载自 https://developer.ibm.com/zh/technologies/java/articles/the-new-features-of-java-14/","tags":["Java","新特性","Java14"],"categories":["Java","新特性","Java14"]},{"title":"8.Java 13 新特性概述","path":"/2023/12/27/8-Java-13-新特性概述/","content":"ava 13 已如期于 9 月 17 日正式发布，此次更新是继半年前 Java 12 这大版本发布之后的一次常规版本更新，在这一版中，主要带来了 ZGC 增强、更新 Socket 实现、Switch 表达式更新等方面的改动、增强。本文主要针对 Java 13 中主要的新特性展开介绍，带你快速了解 Java 13 带来的不同体验。 知识体系 新功能和库的更新JEP350: 动态应用程序类-数据共享在 Java 10 中，为了改善应用启动时间和内存空间占用，通过使用 APP CDS，加大了 CDS 的使用范围，允许自定义的类加载器也可以加载自定义类给多个 JVM 共享使用，具体介绍可以参考 Java 10 新特性介绍一文详细介绍，在此就不再继续展开。 Java 13 中对 Java 10 中引入的 应用程序类数据共享进行了进一步的简化、改进和扩展，即：允许在 Java 应用程序执行结束时动态进行类归档，具体能够被归档的类包括：所有已被加载，但不属于默认基层 CDS 的应用程序类和引用类库中的类。通过这种改进，可以提高应用程序类-数据使用上的简易性，减少在使用类-数据存档中需要为应用程序创建类加载列表的必要，简化使用类-数据共享的步骤，以便更简单、便捷地使用 CDS 存档。 在 Java 中，如果要执行一个类，首先需要将类编译成对应的字节码文件，以下是 JVM 装载、执行等需要的一系列准备步骤：假设给定一个类名，JVM 将在磁盘上查找到该类对应的字节码文件，并将其进行加载，验证字节码文件，准备，解析，初始化，根据其内部数据结构加载到内存中。当然，这一连串的操作都需要一些时间，这在 JVM 启动并且需要加载至少几百个甚至是数千个类时，加载时间就尤其明显。 Java 10 中的 App CDS 主要是为了将不变的类数据，进行一次创建，然后存储到归档中，以便在应用重启之后可以对其进行内存映射而直接使用，同时也可以在运行的 JVM 实例之间共享使用。但是在 Java 10 中使用 App CDS 需要进行如下操作： 创建需要进行类归档的类列表 创建归档 使用归档方式启动 在使用归档文件启动时，JVM 将归档文件映射到其对应的内存中，其中包含所需的大多数类，而 需要使用多么复杂的类加载机制。甚至可以在并发运行的 JVM 实例之间共享内存区域，通过这种方式可以释放需要在每个 JVM 实例中创建相同信息时浪费的内存，从而节省了内存空间。 在 Java 12 中，默认开启了对 JDK 自带 JAR 包类的存档，如果想关闭对自带类库的存档，可以在启动参数中加上： 1-Xshare:off 而在 Java 13 中，可以不用提供归档类列表，而是通过更简洁的方式来创建包含应用程序类的归档。具体可以使用参数 -XX:ArchiveClassesAtExit 来控制应用程序在退出时生成存档，也可以使用 -XX:SharedArchiveFile 来使用动态存档功能，详细使用见如下示例。 清单 1. 创建存档文件示例 1$ java -XX:ArchiveClassesAtExit=helloworld.jsa -cp helloworld.jar Hello 清单 2. 使用存档文件示例 1$ java -XX:SharedArchiveFile=hello.jsa -cp helloworld.jar Hello 上述就是在 Java 应用程序执行结束时动态进行类归档，并且在 Java 10 的基础上，将多条命令进行了简化，可以更加方便地使用类归档功能。 JEP353: Socket API 重构Java 中的 Socket API 已经存在了二十多年了，尽管这么多年来，一直在维护和更新中，但是在实际使用中遇到一些局限性，并且不容易维护和调试，所以要对其进行大修大改，才能跟得上现代技术的发展，毕竟二十多年来，技术都发生了深刻的变化。Java 13 为 Socket API 带来了新的底层实现方法，并且在 Java 13 中是默认使用新的 Socket 实现，使其易于发现并在排除问题同时增加可维护性。 Java Socket API（java.net.ServerSocket 和 java.net.Socket）包含允许监听控制服务器和发送数据的套接字对象。可以使用 ServerSocket 来监听连接请求的端口，一旦连接成功就返回一个 Socket 对象，可以使用该对象读取发送的数据和进行数据写回操作，而这些类的繁重工作都是依赖于 SocketImpl 的内部实现，服务器的发送和接收两端都基于 SOCKS 进行实现的。 在 Java 13 之前，通过使用 PlainSocketImpl 作为 SocketImpl 的具体实现。 Java 13 中的新底层实现，引入 NioSocketImpl 的实现用以替换 SocketImpl 的 PlainSocketImpl 实现，此实现与 NIO（新 I&#x2F;O）实现共享相同的内部基础结构，并且与现有的缓冲区高速缓存机制集成在一起，因此不需要使用线程堆栈。除了这些更改之外，还有其他一些更便利的更改，如使用 java.lang.ref.Cleaner 机制来关闭套接字（如果 SocketImpl 实现在尚未关闭的套接字上被进行了垃圾收集），以及在轮询时套接字处于非阻塞模式时处理超时操作等方面。 为了最小化在重新实现已使用二十多年的方法时出现问题的风险，在引入新实现方法的同时，之前版本的实现还未被移除，可以通过使用下列系统属性以重新使用原实现方法： 1-Djdk.net.usePlainSocketImpl = true 另外需要注意的是，SocketImpl 是一种传统的 SPI 机制，同时也是一个抽象类，并未指定具体的实现，所以，新的实现方式尝试模拟未指定的行为，以达到与原有实现兼容的目的。但是，在使用新实现时，有些基本情况可能会失败，使用上述系统属性可以纠正遇到的问题，下面两个除外。 老版本中，PlainSocketImpl 中的 getInputStream() 和 getOutputStream() 方法返回的 InputStream 和 OutputStream 分别来自于其对应的扩展类型 FileInputStream 和 FileOutputStream，而这个在新版实现中则没有。 使用自定义或其它平台的 SocketImpl 的服务器套接字无法接受使用其他（自定义或其它平台）类型 SocketImpl 返回 Sockets 的连接。 通过这些更改，Java Socket API 将更易于维护，更好地维护将使套接字代码的可靠性得到改善。同时 NIO 实现也可以在基础层面完成，从而保持 Socket 和 ServerSocket 类层面上的不变。 JVM 优化JEP351: 增强 ZGC 释放未使用内存ZGC 是 Java 11 中引入的最为瞩目的垃圾回收特性，是一种可伸缩、低延迟的垃圾收集器，不过在 Java 11 中是实验性的引入，主要用来改善 GC 停顿时间，并支持几百 MB 至几个 TB 级别大小的堆，并且应用吞吐能力下降不会超过 15%，目前只支持 Linux&#x2F;x64 位平台的这样一种新型垃圾收集器。 通过在实际中的使用，发现 ZGC 收集器中并没有像 Hotspot 中的 G1 和 Shenandoah 垃圾收集器一样，能够主动将未使用的内存释放给操作系统的功能。对于大多数应用程序来说，CPU 和内存都属于有限的紧缺资源，特别是现在使用的云上或者虚拟化环境中。如果应用程序中的内存长期处于空闲状态，并且还不能释放给操作系统，这样会导致其他需要内存的应用无法分配到需要的内存，而这边应用分配的内存还处于空闲状态，处于”忙的太忙，闲的太闲”的非公平状态，并且也容易导致基于虚拟化的环境中，因为这些实际并未使用的资源而多付费的情况。由此可见，将未使用内存释放给系统主内存是一项非常有用且亟需的功能。 ZGC 堆由一组称为 ZPages 的堆区域组成。在 GC 周期中清空 ZPages 区域时，它们将被释放并返回到页面缓存 ZPageCache 中，此缓存中的 ZPages 按最近最少使用（LRU）的顺序，并按照大小进行组织。在 Java 13 中，ZGC 将向操作系统返回被标识为长时间未使用的页面，这样它们将可以被其他进程重用。同时释放这些未使用的内存给操作系统不会导致堆大小缩小到参数设置的最小大小以下，如果将最小和最大堆大小设置为相同的值，则不会释放任何内存给操作系统。 Java 13 中对 ZGC 的改进，主要体现在下面几点： 释放未使用内存给操作系统 支持最大堆大小为 16TB 添加参数：-XX:SoftMaxHeapSize 来软限制堆大小 这里提到的是软限制堆大小，是指 GC 应努力是堆大小不要超过指定大小，但是如果实际需要，也还是允许 GC 将堆大小增加到超过 SoftMaxHeapSize 指定值。主要用在下面几种情况：当希望降低堆占用，同时保持应对堆空间临时增加的能力，亦或想保留充足内存空间，以能够应对内存分配，而不会因为内存分配意外增加而陷入分配停滞状态。不应将 SoftMaxHeapSize 设置为大于最大堆大小（-Xmx 的值，如果未在命令行上设置，则此标志应默认为最大堆大小。 Java 13 中，ZGC 内存释放功能，默认情况下是开启的，不过可以使用参数：-XX：-ZUncommit 显式关闭，同时如果将最小堆大小 (-Xms) 配置为等于最大堆大小 (-Xmx)，则将隐式禁用此功能。 还可以使用参数：-XX：ZUncommitDelay = &lt;seconds&gt;（默认值为 300 秒）来配置延迟释放，此延迟时间可以指定释放多长时间之前未使用的内存。 新功能预览JEP354: Switch 表达式扩展（预览功能）在 Java 12 中引入了 Switch 表达式作为预览特性，而在 Java 13 中对 Switch 表达式做了增强改进，在块中引入了 yield 语句来返回值，而不是使用 break。这意味着，Switch 表达式（返回值）应该使用 yield，而 Switch 语句（不返回值）应该使用 break，而在此之前，想要在 Switch 中返回内容，还是比较麻烦的，只不过目前还处于预览状态。 在 Java 13 之后，Switch 表达式中就多了一个关键字用于跳出 Switch 块的关键字 yield，主要用于返回一个值，它和 return 的区别在于：return 会直接跳出当前循环或者方法，而 yield 只会跳出当前 Switch块，同时在使用 yield 时，需要有 default 条件。 在 Java 12 之前，传统 Switch 语句写法为： 清单 3. 传统形式 123456789101112131415161718private static String getText(int number) &#123; String result = &quot;&quot;; switch (number) &#123; case 1, 2: result = &quot;one or two&quot;; break; case 3: result = &quot;three&quot;; break; case 4, 5, 6: result = &quot;four or five or six&quot;; break; default: result = &quot;unknown&quot;; break; &#125;; return result;&#125; 在 Java 12 之后，关于 Switch 表达式的写法改进为如下： 清单 4. 标签简化形式 123456789private static String getText(int number) &#123; String result = switch (number) &#123; case 1, 2 -&gt; &quot;one or two&quot;; case 3 -&gt; &quot;three&quot;; case 4, 5, 6 -&gt; &quot;four or five or six&quot;; default -&gt; &quot;unknown&quot;; &#125;; return result;&#125; 而在 Java 13 中，value break 语句不再被编译，而是用 yield 来进行值返回，上述写法被改为如下写法： 清单 5. yield 返回值形式 123456789101112private static String getText(int number) &#123; return switch (number) &#123; case 1, 2: yield &quot;one or two&quot;; case 3: yield &quot;three&quot;; case 4, 5, 6: yield &quot;four or five or six&quot;; default: yield &quot;unknown&quot;; &#125;;&#125; JEP355: 文本块（预览功能）一直以来，Java 语言在定义字符串的方式是有限的，字符串需要以双引号开头，以双引号结尾，这导致字符串不能够多行使用，而是需要通过换行转义或者换行连接符等方式来变通支持多行，但这样会增加编辑工作量，同时也会导致所在代码段难以阅读、难以维护。 Java 13 引入了文本块来解决多行文本的问题，文本块以三重双引号开头，并以同样的以三重双引号结尾终止，它们之间的任何内容都被解释为字符串的一部分，包括换行符，避免了对大多数转义序列的需要，并且它仍然是普通的 java.lang.String 对象，文本块可以在 Java 中可以使用字符串文字的任何地方使用，而与编译后的代码没有区别，还增强了 Java 程序中的字符串可读性。并且通过这种方式，可以更直观地表示字符串，可以支持跨越多行，而且不会出现转义的视觉混乱，将可以广泛提高 Java 类程序的可读性和可写性。 在 Java 13 之前，多行字符串写法为： 清单 6. 多行字符串写法 1234567891011String html =&quot;&lt;html&gt; &quot; + &quot; &lt;body&gt; &quot; + &quot; &lt;p&gt;Hello, World&lt;/p&gt; &quot; + &quot; &lt;/body&gt; &quot; + &quot;&lt;/html&gt; &quot;; String json =&quot;&#123; &quot; + &quot; \\&quot;name\\&quot;:\\&quot;mkyong\\&quot;, &quot; + &quot; \\&quot;age\\&quot;:38 &quot; + &quot;&#125; &quot;; 在 Java 13 引入文本块之后，写法为： 清单 7. 多行文本块写法 1234567891011121314String html = &quot;&quot;&quot; &lt;html&gt; &lt;body&gt; &lt;p&gt;Hello, World&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &quot;&quot;&quot;; String json = &quot;&quot;&quot; &#123; &quot;name&quot;:&quot;mkyong&quot;, &quot;age&quot;:38 &#125; &quot;&quot;&quot;; 文本块是作为预览功能引入到 Java 13 中的，这意味着它们不包含在相关的 Java 语言规范中，这样做的好处是方便用户测试功能并提供反馈，后续更新可以根据反馈来改进功能，或者必要时甚至删除该功能，如果该功能立即成为 Java SE 标准的一部分，则进行更改将变得更加困难。重要的是要意识到预览功能不是 beta 形式。 由于预览功能不是规范的一部分，因此有必要为编译和运行时明确启用它们。需要使用下面两个命令行参数来启用预览功能： 清单 8. 启用预览功能 12$ javac --enable-preview --release 13 Example.java$ java --enable-preview Example 结束语Java 在更新发布周期为每半年发布一次之后，在合并关键特性、快速得到开发者反馈等方面，做得越来越好。从 Java 11 到 Java 13，目前确实是严格保持半年更新的节奏。Java 13 版本的发布带来了些新特性和功能增强、性能提升和改进尝试，不过 Java 13 不是 LTS 版本，本文针对其中对使用人员影响重大的以及主要的特性做了介绍，如有兴趣，您可以自行下载相关代码，继续深入研究。 参考文章 本文 参考了http://openjdk.java.net/projects/jdk/12/发布特性 并重新整合来自https://developer.ibm.com/zh/technologies/java/articles/the-new-features-of-java-13/ 的内容","tags":["Java","新特性","Java13"],"categories":["Java","新特性","Java13"]},{"title":"7.Java 12 新特性概述","path":"/2023/12/27/7-Java-12-新特性概述/","content":"JDK12 在 2019 年 3 月 19 号正式发布，不同于JDK11，JDK12并不是一个LTS版本。作为一个中间版本，JDK12版本特性增加较少。 2017年宣布的加速发布节奏要求每六个月发布一次功能，每季度更新一次，每三年发布一次长期支持（LTS）更新版本（或每六个版本一次）。 知识体系 新功能和库的更新JEP334: JVM常量API每个Java类文件都有一个常量池，该池存储该类中字节码指令的操作。广义上讲，常量池中的条目要么描述运行时artifacts（例如类和方法），要么描述简单值（例如字符串和整数）。 所有这些条目都称为可加载常量，因为它们可以用作ldc指令的参数（“加载常量”）。它们也可能出现在invokedynamic指令的引导方法的静态参数列表中。执行ldc或invokedynamic指令会导致将可加载常量解析为标准Java类型（如Class，String或int）的“实时”值。 处理类文件的程序需要对字节码指令进行建模，然后对可加载常量进行建模。但是，使用标准Java类型对可加载常量进行建模是不够的。 描述一个字符串（一个CONSTANT_String_info条目）的可加载常量可能是可以接受的，因为生成一个“live” String对象是很简单的，但是对于描述一个类（一个CONSTANT_Class_info条目）的一个可加载常量来说，这是有问题的，因为生成一个“live”类对象依赖于类加载的正确性和一致性。 在实际应用中，类加载具有许多环境依赖性和失败的情况，例如：所需的类不存在或请求者可能无法访问；类加载的结果随上下文而变化；加载类具有副作用；有时根本不可能加载类。 因此，处理可加载常量的程序如果能够操纵类和方法，并且以纯名义上的符号形式操纵诸如方法句柄和动态计算的常量之类的artifacts，则它们将变得更加简单。 JDK12在新包java.lang.invoke.constant中定义了一系列基于值的符号引用（JVMS 5.1）类型，它们能够描述每种可加载常量。符号引用以纯字面的形式描述了可加载常量，与类加载或可访问性上下文分开。某些类可以充当自己的符号引用（例如String）；对于可链接常量，JDK12定义了一系列符号引用类型（ClassDesc，MethodTypeDesc，MethodHandleDesc和DynamicConstantDesc），来包含描述这些常量的信息。 JEP341: 默认CDS归档通过在64位平台上的默认类列表的帮助下生成CDS归档来改进JDK构建过程，从而有效地消除了运行java -Xshare：dump。 此功能的目标包括： 改进开箱即用的启动时间 摆脱使用-Xshare：dump。 JEP230: Microbenchmark测试套件此功能为JDK源代码添加了一套Microbenchmark测试（大约100个），简化了现有Microbenchmark测试的运行和新基准测试的创建过程。 它基于Java Microbenchmark Harness（JMH）并支持JMH更新。 此功能使开发人员可以轻松运行当前的Microbenchmark测试并为JDK源代码添加新的Microbenchmark测试。 可以基于Java Microbenchmark Harness（JMH）轻松测试JDK性能。 它将支持JMH更新，并在套件中包含一组（约100个）基准测试。 新的平台支持JEP340: 移除多余ARM64实现Java 12将只有一个ARM 64位实现（aarch64）。 目标是删除所有与arm64实现相关的代码，同时保留32位ARM端口和64位aarch64实现。 这将把重点转移到单个64位ARM实现，并消除维护两个实现所需的重复工作。 当前的JDK 11实现中有两个64位ARM实现。 JVM 优化JPE 344: G1的可中断 mixed GC此功能通过将Mixed GC集拆分为强制部分和可选部分，使G1垃圾收集器更有效地中止垃圾收集过程。通过允许垃圾收集过程优先处理强制集，g1可以更多满足满足暂停时间目标。 G1是一个垃圾收集器，设计用于具有大量内存的多处理器机器。由于它提高了性能效率，g1垃圾收集器最终将取代cms垃圾收集器。 G1垃圾收集器的主要目标之一是满足用户设置的暂停时间。G1采用一个分析引擎来选择在收集期间要处理的工作量。此选择过程的结果是一组称为GC集的区域。一旦GC集建立并且GC已经开始，那么G1就无法停止。 如果G1发现GC集选择选择了错误的区域，它会将GC区域的拆分为两部分（强制部分和可选部分）来切换到处理Mix GC的增量模式。如果未达到暂停时间目标，则停止对可选部分的垃圾收集。 JEP 346: G1归还不使用的内存此功能的主要目标是改进G1垃圾收集器，以便在不活动时将Java堆内存归还给操作系统。 为实现此目标，G1将在低应用程序活动期间定期生成或持续循环检查完整的Java堆使用情况。 这将立即归还未使用的部分Java堆内存给操作系统。 用户可以选择执行FULL GC以最大化返回的内存量。 新功能的预览和实验JEP 189: Shenandoah：低暂停时间垃圾收集器（实验） JDK 12 引入的回收算法（实验阶段），该算法通过与正在运行的 Java 线程同时进行疏散工作来减少 GC 暂停时间。Shenandoah 的暂停时间与堆大小无关，无论堆栈是 200 MB 还是 200 GB，都具有相同的一致暂停时间。 Shenandoah适用于高吞吐和大内存场景，不适合高实时性场景。Shenandoah算法设计目标主要是响应性和一致可控的短暂停顿，对于垃圾回收生命周期中安全点停顿（TTSP)和内存增长监控的时间开销并无帮助。 Shenandoah算法为每个Java对象添加了一个间接指针，使得GC线程能够在Java线程运行时压缩堆。标记和压缩是同时执行的，因此我们只需要暂停Java线程在一致可控的时间内扫描线程堆栈以查找和更新对象图的根。 怎么形容Shenandoah和ZGC的关系呢？异同点大概如下： 相同点：性能几乎可认为是相同的 不同点：ZGC是Oracle JDK的。而Shenandoah只存在于OpenJDK中，因此使用时需注意你的JDK版本 打开方式：使用-XX:+UseShenandoahGC命令行参数打开。 JEP 325: Switch 表达式 (预览版本) 在 Java 12 中引入了 Switch 表达式作为预览特性 在 Java 12 之前，传统 Switch 语句写法为： 123456789101112131415161718private static String getText(int number) &#123; String result = &quot;&quot;; switch (number) &#123; case 1, 2: result = &quot;one or two&quot;; break; case 3: result = &quot;three&quot;; break; case 4, 5, 6: result = &quot;four or five or six&quot;; break; default: result = &quot;unknown&quot;; break; &#125;; return result;&#125; 在 Java 12 之后，关于 Switch 表达式的写法改进为如下： 123456789private static String getText(int number) &#123; String result = switch (number) &#123; case 1, 2 -&gt; &quot;one or two&quot;; case 3 -&gt; &quot;three&quot;; case 4, 5, 6 -&gt; &quot;four or five or six&quot;; default -&gt; &quot;unknown&quot;; &#125;; return result;&#125; 参考文章http://openjdk.java.net/projects/jdk/12/","tags":["Java","新特性","Java12"],"categories":["Java","新特性","Java12"]},{"title":"6.Java 11 新特性概述","path":"/2023/12/27/6-Java-11-新特性概述/","content":"Java 11 在 2018 年 9 月 25 日正式发布，之前在 Java 10 新特性介绍 中介绍过，为了加快的版本迭代、跟进社区反馈，Java 的版本发布周期调整为每六个月一次——即每半年发布一个大版本，每个季度发布一个中间特性版本，并且做出不会跳票的承诺。通过这样的方式，Java 开发团队能够将一些重要特性尽早的合并到 Java Release 版本中，以便快速得到开发者的反馈，避免出现类似 Java 9 发布时的两次延期的情况。 按照官方介绍，新的版本发布周期将会严格按照时间节点，于每年的 3 月和 9 月发布，Java 11 发布的时间节点也正好处于 Java 8 免费更新到期的前夕。与 Java 9 和 Java 10 这两个被称为”功能性的版本”不同，Java 11 仅将提供长期支持服务（LTS, Long-Term-Support），还将作为 Java 平台的默认支持版本，并且会提供技术支持直至 2023 年 9 月，对应的补丁和安全警告等支持将持续至 2026 年。 本文主要针对 Java 11 中的新特性展开介绍，让您快速了解 Java 11 带来的变化。 知识体系 基于嵌套的访问控制与 Java 语言中现有的嵌套类型概念一致, 嵌套访问控制是一种控制上下文访问的策略，允许逻辑上属于同一代码实体，但被编译之后分为多个分散的 class 文件的类，无需编译器额外的创建可扩展的桥接访问方法，即可访问彼此的私有成员，并且这种改进是在 Java 字节码级别的。 在 Java 11 之前的版本中，编译之后的 class 文件中通过 InnerClasses 和 Enclosing Method 两种属性来帮助编译器确认源码的嵌套关系，每一个嵌套的类会编译到自己所在的 class 文件中，不同类的文件通过上面介绍的两种属性的来相互连接。这两种属性对于编译器确定相互之间的嵌套关系已经足够了，但是并不适用于访问控制。这里大家可以写一段包含内部类的代码，并将其编译成 class 文件，然后通过 javap 命令行来分析，碍于篇幅，这里就不展开讨论了。 Java 11 中引入了两个新的属性：一个叫做 NestMembers 的属性，用于标识其它已知的静态 nest 成员；另外一个是每个 nest 成员都包含的 NestHost 属性，用于标识出它的 nest 宿主类。 标准 HTTP Client 升级Java 11 对 Java 9 中引入并在 Java 10 中进行了更新的 Http Client API 进行了标准化，在前两个版本中进行孵化的同时，Http Client 几乎被完全重写，并且现在完全支持异步非阻塞。 新版 Java 中，Http Client 的包名由 jdk.incubator.http 改为 java.net.http，该 API 通过 CompleteableFutures 提供非阻塞请求和响应语义，可以联合使用以触发相应的动作，并且 RX Flo w 的概念也在 Java 11 中得到了实现。现在，在用户层请求发布者和响应发布者与底层套接字之间追踪数据流更容易了。这降低了复杂性，并最大程度上提高了 HTTP&#x2F;1 和 HTTP&#x2F;2 之间的重用的可能性。 Java 11 中的新 Http Client API，提供了对 HTTP&#x2F;2 等业界前沿标准的支持，同时也向下兼容 HTTP&#x2F;1.1，精简而又友好的 API 接口，与主流开源 API（如：Apache HttpClient、Jetty、OkHttp 等）类似甚至拥有更高的性能。与此同时它是 Java 在 Reactive-Stream 方面的第一个生产实践，其中广泛使用了 Java Flow API，终于让 Java 标准 HTTP 类库在扩展能力等方面，满足了现代互联网的需求，是一个难得的现代 Http&#x2F;2 Client API 标准的实现，Java 工程师终于可以摆脱老旧的 HttpURLConnection 了。下面模拟 Http GET 请求并打印返回内容： 清单 1. GET 请求示例 12345678HttpClient client = HttpClient.newHttpClient();HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(&quot;http://openjdk.java.net/&quot;)) .build();client.sendAsync(request, BodyHandlers.ofString()) .thenApply(HttpResponse::body) .thenAccept(System.out::println) .join(); Epsilon：低开销垃圾回收器Epsilon 垃圾回收器的目标是开发一个控制内存分配，但是不执行任何实际的垃圾回收工作。它提供一个完全消极的 GC 实现，分配有限的内存资源，最大限度的降低内存占用和内存吞吐延迟时间。 Java 版本中已经包含了一系列的高度可配置化的 GC 实现。各种不同的垃圾回收器可以面对各种情况。但是有些时候使用一种独特的实现，而不是将其堆积在其他 GC 实现上将会是事情变得更加简单。 下面是 no-op GC 的几个使用场景： 性能测试：什么都不执行的 GC 非常适合用于 GC 的差异性分析。no-op （无操作）GC 可以用于过滤掉 GC 诱发的性能损耗，比如 GC 线程的调度，GC 屏障的消耗，GC 周期的不合适触发，内存位置变化等。此外有些延迟者不是由于 GC 引起的，比如 scheduling hiccups, compiler transition hiccups，所以去除 GC 引发的延迟有助于统计这些延迟。 内存压力测试：在测试 Java 代码时，确定分配内存的阈值有助于设置内存压力常量值。这时 no-op 就很有用，它可以简单地接受一个分配的内存分配上限，当内存超限时就失败。例如：测试需要分配小于 1G 的内存，就使用-Xmx1g 参数来配置 no-op GC，然后当内存耗尽的时候就直接 crash。 VM 接口测试：以 VM 开发视角，有一个简单的 GC 实现，有助于理解 VM-GC 的最小接口实现。它也用于证明 VM-GC 接口的健全性。 极度短暂 job 任务：一个短声明周期的 job 任务可能会依赖快速退出来释放资源，这个时候接收 GC 周期来清理 heap 其实是在浪费时间，因为 heap 会在退出时清理。并且 GC 周期可能会占用一会时间，因为它依赖 heap 上的数据量。 延迟改进：对那些极端延迟敏感的应用，开发者十分清楚内存占用，或者是几乎没有垃圾回收的应用，此时耗时较长的 GC 周期将会是一件坏事。 吞吐改进：即便对那些无需内存分配的工作，选择一个 GC 意味着选择了一系列的 GC 屏障，所有的 OpenJDK GC 都是分代的，所以他们至少会有一个写屏障。避免这些屏障可以带来一点点的吞吐量提升。 Epsilon 垃圾回收器和其他 OpenJDK 的垃圾回收器一样，可以通过参数 -XX:+UseEpsilonGC 开启。 Epsilon 线性分配单个连续内存块。可复用现存 VM 代码中的 TLAB 部分的分配功能。非 TLAB 分配也是同一段代码，因为在此方案中，分配 TLAB 和分配大对象只有一点点的不同。Epsilon 用到的 barrier 是空的(或者说是无操作的)。因为该 GC 执行任何的 GC 周期，不用关系对象图，对象标记，对象复制等。引进一种新的 barrier-set 实现可能是该 GC 对 JVM 最大的变化。 简化启动单个源代码文件的方法Java 11 版本中最令人兴奋的功能之一是增强 Java 启动器，使之能够运行单一文件的 Java 源代码。此功能允许使用 Java 解释器直接执行 Java 源代码。源代码在内存中编译，然后由解释器执行。唯一的约束在于所有相关的类必须定义在同一个 Java 文件中。 此功能对于开始学习 Java 并希望尝试简单程序的人特别有用，并且能与 jshell 一起使用，将成为任何初学者学习语言的一个很好的工具集。不仅初学者会受益，专业人员还可以利用这些工具来探索新的语言更改或尝试未知的 API。 如今单文件程序在编写小实用程序时很常见，特别是脚本语言领域。从中开发者可以省去用 Java 编译程序等不必要工作，以及减少新手的入门障碍。在基于 Java 10 的程序实现中可以通过三种方式启动： 作为 * .class 文件 作为 * .jar 文件中的主类 作为模块中的主类 而在最新的 Java 11 中新增了一个启动方式，即可以在源代码中声明类，例如：如果名为 HelloWorld.java 的文件包含一个名为 hello.World 的类，那么该命令： 1$ java HelloWorld.java 也等同于： 12$ javac HelloWorld.java$ java -cp . hello.World 用于 Lambda 参数的局部变量语法在 Lambda 表达式中使用局部变量类型推断是 Java 11 引入的唯一与语言相关的特性，这一节，我们将探索这一新特性。 从 Java 10 开始，便引入了局部变量类型推断这一关键特性。类型推断允许使用关键字 var 作为局部变量的类型而不是实际类型，编译器根据分配给变量的值推断出类型。这一改进简化了代码编写、节省了开发者的工作时间，因为不再需要显式声明局部变量的类型，而是可以使用关键字 var，且不会使源代码过于复杂。 可以使用关键字 var 声明局部变量，如下所示： 12var s = &quot;Hello Java 11&quot;;System.out.println(s); 但是在 Java 10 中，还有下面几个限制： 只能用于局部变量上 声明时必须初始化 不能用作方法参数 不能在 Lambda 表达式中使用 Java 11 与 Java 10 的不同之处在于允许开发者在 Lambda 表达式中使用 var 进行参数声明。乍一看，这一举措似乎有点多余，因为在写代码过程中可以省略 Lambda 参数的类型，并通过类型推断确定它们。但是，添加上类型定义同时使用 @Nonnull 和 @Nullable 等类型注释还是很有用的，既能保持与局部变量的一致写法，也不丢失代码简洁。 Lambda 表达式使用隐式类型定义，它形参的所有类型全部靠推断出来的。隐式类型 Lambda 表达式如下： 1(x, y) -&gt; x.process(y) Java 10 为局部变量提供隐式定义写法如下： 123var x = new Foo();for (var x : xs) &#123; ... &#125;try (var x = ...) &#123; ... &#125; catch ... 为了 Lambda 类型表达式中正式参数定义的语法与局部变量定义语法的不一致，且为了保持与其他局部变量用法上的一致性，希望能够使用关键字 var 隐式定义 Lambda 表达式的形参： 1(var x, var y) -&gt; x.process(y) 于是在 Java 11 中将局部变量和 Lambda 表达式的用法进行了统一，并且可以将注释应用于局部变量和 Lambda 表达式： 12@Nonnull var x = new Foo();(@Nonnull var x, @Nullable var y) -&gt; x.process(y) 低开销的 Heap ProfilingJava 11 中提供一种低开销的 Java 堆分配采样方法，能够得到堆分配的 Java 对象信息，并且能够通过 JVMTI 访问堆信息。 引入这个低开销内存分析工具是为了达到如下目的： 足够低的开销，可以默认且一直开启 能通过定义好的程序接口访问 能够对所有堆分配区域进行采样 能给出正在和未被使用的 Java 对象信息 对用户来说，了解它们堆里的内存分布是非常重要的，特别是遇到生产环境中出现的高 CPU、高内存占用率的情况。目前有一些已经开源的工具，允许用户分析应用程序中的堆使用情况，比如：Java Flight Recorder、jmap、YourKit 以及 VisualVM tools.。但是这些工具都有一个明显的不足之处：无法得到对象的分配位置，headp dump 以及 heap histogram 中都没有包含对象分配的具体信息，但是这些信息对于调试内存问题至关重要，因为它能够告诉开发人员他们的代码中发生的高内存分配的确切位置，并根据实际源码来分析具体问题，这也是 Java 11 中引入这种低开销堆分配采样方法的原因。 支持 TLS 1.3 协议Java 11 中包含了传输层安全性（TLS）1.3 规范（RFC 8446）的实现，替换了之前版本中包含的 TLS，包括 TLS 1.2，同时还改进了其他 TLS 功能，例如 OCSP 装订扩展（RFC 6066，RFC 6961），以及会话散列和扩展主密钥扩展（RFC 7627），在安全性和性能方面也做了很多提升。 新版本中包含了 Java 安全套接字扩展（JSSE）提供 SSL，TLS 和 DTLS 协议的框架和 Java 实现。目前，JSSE API 和 JDK 实现支持 SSL 3.0，TLS 1.0，TLS 1.1，TLS 1.2，DTLS 1.0 和 DTLS 1.2。 同时 Java 11 版本中实现的 TLS 1.3，重新定义了以下新标准算法名称： TLS 协议版本名称：TLSv1.3 SSLContext 算法名称：TLSv1.3 TLS 1.3 的 TLS 密码套件名称：TLS_AES_128_GCM_SHA256，TLS_AES_256_GCM_SHA384 用于 X509KeyManager 的 keyType：RSASSA-PSS 用于 X509TrustManager 的 authType：RSASSA-PSS 还为 TLS 1.3 添加了一个新的安全属性 jdk.tls.keyLimits。当处理了特定算法的指定数据量时，触发握手后，密钥和 IV 更新以导出新密钥。还添加了一个新的系统属性 jdk.tls.server.protocols，用于在 SunJSSE 提供程序的服务器端配置默认启用的协议套件。 之前版本中使用的 KRB5 密码套件实现已从 Java 11 中删除，因为该算法已不再安全。同时注意，TLS 1.3 与以前的版本不直接兼容。 升级到 TLS 1.3 之前，需要考虑如下几个兼容性问题： TLS 1.3 使用半关闭策略，而 TLS 1.2 以及之前版本使用双工关闭策略，对于依赖于双工关闭策略的应用程序，升级到 TLS 1.3 时可能存在兼容性问题。 TLS 1.3 使用预定义的签名算法进行证书身份验证，但实际场景中应用程序可能会使用不被支持的签名算法。 TLS 1.3 再支持 DSA 签名算法，如果在服务器端配置为仅使用 DSA 证书，则无法升级到 TLS 1.3。 TLS 1.3 支持的加密套件与 TLS 1.2 和早期版本不同，若应用程序硬编码了加密算法单元，则在升级的过程中需要修改相应代码才能升级使用 TLS 1.3。 TLS 1.3 版本的 session 用行为及秘钥更新行为与 1.2 及之前的版本不同，若应用依赖于 TLS 协议的握手过程细节，则需要注意。 ZGC：可伸缩低延迟垃圾收集器ZGC 即 Z Garbage Collector（垃圾收集器或垃圾回收器），这应该是 Java 11 中最为瞩目的特性，没有之一。ZGC 是一个可伸缩的、低延迟的垃圾收集器，主要为了满足如下目标进行设计： GC 停顿时间不超过 10ms 即能处理几百 MB 的小堆，也能处理几个 TB 的大堆 应用吞吐能力不会下降超过 15%（与 G1 回收算法相比） 方便在此基础上引入新的 GC 特性和利用 colord 针以及 Load barriers 优化奠定基础 当前只支持 Linux&#x2F;x64 位平台 停顿时间在 10ms 以下，10ms 其实是一个很保守的数据，即便是 10ms 这个数据，也是 GC 调优几乎达不到的极值。根据 SPECjbb 2015 的基准测试，128G 的大堆下最大停顿时间才 1.68ms，远低于 10ms，和 G1 算法相比，改进非常明显。 本图片引用自： The Z Garbage Collector – An Introduction 不过目前 ZGC 还处于实验阶段，目前只在 Linux&#x2F;x64 上可用，如果有足够的需求，将来可能会增加对其他平台的支持。同时作为实验性功能的 ZGC 将不会出现在 JDK 构建中，除非在编译时使用 configure 参数： --with-jvm-features=zgc 显式启用。 在实验阶段，编译完成之后，已经迫不及待的想试试 ZGC，需要配置以下 JVM 参数，才能使用 ZGC，具体启动 ZGC 参数如下： 1-XX：+ UnlockExperimentalVMOptions -XX：+ UseZGC -Xmx10g 其中参数： -Xmx 是 ZGC 收集器中最重要的调优选项，大大解决了程序员在 JVM 参数调优上的困扰。ZGC 是一个并发收集器，必须要设置一个最大堆的大小，应用需要多大的堆，主要有下面几个考量： 对象的分配速率，要保证在 GC 的时候，堆中有足够的内存分配新对象。 一般来说，给 ZGC 的内存越多越好，但是也不能浪费内存，所以要找到一个平衡。 飞行记录器飞行记录器之前是商业版 JDK 的一项分析工具，但在 Java 11 中，其代码被包含到公开代码库中，这样所有人都能使用该功能了。 Java 语言中的飞行记录器类似飞机上的黑盒子，是一种低开销的事件信息收集框架，主要用于对应用程序和 JVM 进行故障检查、分析。飞行记录器记录的主要数据源于应用程序、JVM 和 OS，这些事件信息保存在单独的事件记录文件中，故障发生后，能够从事件记录文件中提取出有用信息对故障进行分析。 启用飞行记录器参数如下： 1-XX:StartFlightRecording 也可以使用 bin&#x2F;jcmd 工具启动和配置飞行记录器： 清单 2. 飞行记录器启动、配置参数示例 123$ jcmd &lt;pid&gt; JFR.start$ jcmd &lt;pid&gt; JFR.dump filename=recording.jfr$ jcmd &lt;pid&gt; JFR.stop JFR 使用测试： 清单 3. JFR 使用示例 1234567891011121314public class FlightRecorderTest extends Event &#123; @Label(&quot;Hello World&quot;) @Description(&quot;Helps the programmer getting started&quot;) static class HelloWorld extends Event &#123; @Label(&quot;Message&quot;) String message; &#125; public static void main(String[] args) &#123; HelloWorld event = new HelloWorld(); event.message = &quot;hello, world!&quot;; event.commit(); &#125;&#125; 在运行时加上如下参数： 1java -XX:StartFlightRecording=duration=1s, filename=recording.jfr 下面读取上一步中生成的 JFR 文件：recording.jfr 清单 4. 飞行记录器分析示例 1234567public void readRecordFile() throws IOException &#123; final Path path = Paths.get(&quot;D:\\\\ java \\\\recording.jfr&quot;); final List&lt;RecordedEvent&gt; recordedEvents = RecordingFile.readAllEvents(path); for (RecordedEvent event : recordedEvents) &#123; System.out.println(event.getStartTime() + &quot;,&quot; + event.getValue(&quot;message&quot;)); &#125;&#125; 动态类文件常量为了使 JVM 对动态语言更具吸引力，Java 的第七个版本已将 invokedynamic 引入其指令集。 不过 Java 开发人员通常不会注意到此功能，因为它隐藏在 Java 字节代码中。通过使用 invokedynamic，可以延迟方法调用的绑定，直到第一次调用。例如，Java 语言使用该技术来实现 Lambda 表达式，这些表达式仅在首次使用时才显示出来。这样做，invokedynamic 已经演变成一种必不可少的语言功能。 Java 11 引入了类似的机制，扩展了 Java 文件格式，以支持新的常量池：CONSTANT_Dynamic，它在初始化的时候，像 invokedynamic 指令生成代理方法一样，委托给 bootstrap 方法进行初始化创建，对上层软件没有很大的影响，降低开发新形式的可实现类文件约束带来的成本和干扰。 结束语Java 在更新发布周期为每半年发布一次之后，在合并关键特性、快速得到开发者反馈等方面，做得越来越好。Java 11 版本的发布也带来了不少新特性和功能增强、性能提升、基础能力的全面进步和突破，本文针对其中对使用人员影响重大的以及主要的特性做了介绍。Java 12 即将到来，您准备好了吗？ 本文仅代表作者个人观点，不代表其所在单位的意见，如有不足之处，还望您能够海涵。希望您能够反馈意见，交流心得，一同进步。 参考文章 文章转载自 https://developer.ibm.com/zh/technologies/java/articles/the-new-features-of-java-11/","tags":["Java","新特性","Java11"],"categories":["Java","新特性","Java11"]},{"title":"5.Java 10 新特性概述","path":"/2023/12/27/5-Java-10-新特性概述/","content":"作为当今使用最广泛的编程语言之一的 Java 在 2018 年 3 月 21 日发布了第十个大版本。为了更快地迭代、更好地跟进社区反馈，Java 语言版本发布周期调整为每隔 6 个月发布一次。Java 10 是这一新规则之后，采用新发布周期的第一个大版本。Java 10 版本带来了很多新特性，其中最备受广大开发者关注的莫过于局部变量类型推断。除此之外，还有其他包括垃圾收集器改善、GC 改进、性能提升、线程管控等一批新特性。本文主要针对 Java 10 中的新特性展开介绍，希望读者能从本文的介绍中快速了解 Java 10 带来的变化。 知识体系 局部变量类型推断局部变量类型推断是 Java 10 中最值得开发人员注意的新特性，这是 Java 语言开发人员为了简化 Java 应用程序的编写而进行的又一重要改进。 这一新功能将为 Java 增加一些新语法，允许开发人员省略通常不必要的局部变量类型初始化声明。新的语法将减少 Java 代码的冗长度，同时保持对静态类型安全性的承诺。局部变量类型推断主要是向 Java 语法中引入在其他语言（比如 C#、JavaScript）中很常见的保留类型名称 var 。但需要特别注意的是： var 不是一个关键字，而是一个保留字。只要编译器可以推断此种类型，开发人员不再需要专门声明一个局部变量的类型，也就是可以随意定义变量而不必指定变量的类型。这种改进对于链式表达式来说，也会很方便。以下是一个简单的例子： 清单 1. 局部变量类型推断示例 12var list = new ArrayList&lt;String&gt;(); // ArrayList&lt;String&gt;var stream = list.stream(); // Stream&lt;String&gt; 看着是不是有点 JS 的感觉？有没有感觉越来越像 JS 了？虽然变量类型的推断在 Java 中不是一个崭新的概念，但在局部变量中确是很大的一个改进。说到变量类型推断，从 Java 5 中引进泛型，到 Java 7 的 &lt;&gt; 操作符允许不绑定类型而初始化 List，再到 Java 8 中的 Lambda 表达式，再到现在 Java 10 中引入的局部变量类型推断，Java 类型推断正大刀阔斧地向前进步、发展。 而上面这段例子，在以前版本的 Java 语法中初始化列表的写法为： 清单 2. Java 类型初始化示例 12List&lt;String&gt; list = new ArrayList&lt;String&gt;();Stream&lt;String&gt; stream = getStream(); 在运算符允许在没有绑定 ArrayList &lt;&gt; 的类型的情况下初始化列表的写法为： 清单 3. Java 7 之后版本类型初始化示例 12List&lt;String&gt; list = new LinkedList&lt;&gt;();Stream&lt;String&gt; stream = getStream(); 但这种 var 变量类型推断的使用也有局限性，仅局限于具有初始化器的局部变量、增强型 for 循环中的索引变量以及在传统 for 循环中声明的局部变量，而不能用于推断方法的参数类型，不能用于构造函数参数类型推断，不能用于推断方法返回类型，也不能用于字段类型推断，同时还不能用于捕获表达式（或任何其他类型的变量声明）。 不过对于开发者而言，变量类型显式声明会提供更加全面的程序语言信息，对于理解和维护代码有很大的帮助。Java 10 中新引入的局部变量类型推断能够帮助我们快速编写更加简洁的代码，但是局部变量类型推断的保留字 var 的使用势必会引起变量类型可视化缺失，并不是任何时候使用 var 都能容易、清晰的分辨出变量的类型。一旦 var 被广泛运用，开发者在没有 IDE 的支持下阅读代码，势必会对理解程序的执行流程带来一定的困难。所以还是建议尽量显式定义变量类型，在保持代码简洁的同时，也需要兼顾程序的易读性、可维护性。 整合 JDK 代码仓库为了简化开发流程，Java 10 中会将多个代码库合并到一个代码仓库中。 在已发布的 Java 版本中，JDK 的整套代码根据不同功能已被分别存储在多个 Mercurial 存储库，这八个 Mercurial 存储库分别是：root、corba、hotspot、jaxp、jaxws、jdk、langtools、nashorn。 虽然以上八个存储库之间相互独立以保持各组件代码清晰分离，但同时管理这些存储库存在许多缺点，并且无法进行相关联源代码的管理操作。其中最重要的一点是，涉及多个存储库的变更集无法进行原子提交 （atomic commit）。例如，如果一个 bug 修复时需要对独立存储两个不同代码库的代码进行更改，那么必须创建两个提交：每个存储库中各一个。这种不连续性很容易降低项目和源代码管理工具的可跟踪性和加大复杂性。特别是，不可能跨越相互依赖的变更集的存储库执行原子提交这种多次跨仓库的变化是常见现象。 为了解决这个问题，JDK 10 中将所有现有存储库合并到一个 Mercurial 存储库中。这种合并的一个次生效应是，单一的 Mercurial 存储库比现有的八个存储库要更容易地被镜像(作为一个 Git 存储库)，并且使得跨越相互依赖的变更集的存储库运行原子提交成为可能，从而简化开发和管理过程。虽然在整合过程中，外部开发人员有一些阻力，但是 JDK 开发团队已经使这一更改成为 JDK 10 的一部分。 统一的垃圾回收接口在当前的 Java 结构中，组成垃圾回收器（GC）实现的组件分散在代码库的各个部分。尽管这些惯例对于使用 GC 计划的 JDK 开发者来说比较熟悉，但对新的开发人员来说，对于在哪里查找特定 GC 的源代码，或者实现一个新的垃圾收集器常常会感到困惑。更重要的是，随着 Java modules 的出现，我们希望在构建过程中排除不需要的 GC，但是当前 GC 接口的横向结构会给排除、定位问题带来困难。 为解决此问题，需要整合并清理 GC 接口，以便更容易地实现新的 GC，并更好地维护现有的 GC。Java 10 中，hotspot&#x2F;gc 代码实现方面，引入一个干净的 GC 接口，改进不同 GC 源代码的隔离性，多个 GC 之间共享的实现细节代码应该存在于辅助类中。这种方式提供了足够的灵活性来实现全新 GC 接口，同时允许以混合搭配方式重复使用现有代码，并且能够保持代码更加干净、整洁，便于排查收集器问题。 并行全垃圾回收器 G1大家如果接触过 Java 性能调优工作，应该会知道，调优的最终目标是通过参数设置来达到快速、低延时的内存垃圾回收以提高应用吞吐量，尽可能的避免因内存回收不及时而触发的完整 GC（Full GC 会带来应用出现卡顿）。 G1 垃圾回收器是 Java 9 中 Hotspot 的默认垃圾回收器，是以一种低延时的垃圾回收器来设计的，旨在避免进行 Full GC，但是当并发收集无法快速回收内存时，会触发垃圾回收器回退进行 Full GC。之前 Java 版本中的 G1 垃圾回收器执行 GC 时采用的是基于单线程标记扫描压缩算法（mark-sweep-compact）。为了最大限度地减少 Full GC 造成的应用停顿的影响，Java 10 中将为 G1 引入多线程并行 GC，同时会使用与年轻代回收和混合回收相同的并行工作线程数量，从而减少了 Full GC 的发生，以带来更好的性能提升、更大的吞吐量。 Java 10 中将采用并行化 mark-sweep-compact 算法，并使用与年轻代回收和混合回收相同数量的线程。具体并行 GC 线程数量可以通过： -XX：ParallelGCThreads 参数来调节，但这也会影响用于年轻代和混合收集的工作线程数。 应用程序类数据共享在 Java 5 中就已经引入了类数据共享机制 (Class Data Sharing，简称 CDS)，允许将一组类预处理为共享归档文件，以便在运行时能够进行内存映射以减少 Java 程序的启动时间，当多个 Java 虚拟机（JVM）共享相同的归档文件时，还可以减少动态内存的占用量，同时减少多个虚拟机在同一个物理或虚拟的机器上运行时的资源占用。简单来说，Java 安装程序会把 rt.jar 中的核心类提前转化成内部表示，转储到一个共享存档（shared archive）中。多个 Java 进程（或者说 JVM 实例）可以共享这部分数据。为改善启动和占用空间，Java 10 在现有的 CDS 功能基础上再次拓展，以允许应用类放置在共享存档中。 CDS 特性在原来的 bootstrap 类基础之上，扩展加入了应用类的 CDS (Application Class-Data Sharing) 支持。 其原理为：在启动时记录加载类的过程，写入到文本文件中，再次启动时直接读取此启动文本并加载。设想如果应用环境没有大的变化，启动速度就会得到提升。 可以想像为类似于操作系统的休眠过程，合上电脑时把当前应用环境写入磁盘，再次使用时就可以快速恢复环境。 对大型企业应用程序的内存使用情况的分析表明，此类应用程序通常会将数以万计的类加载到应用程序类加载器中，如果能够将 AppCDS 应用于这些应用，将为每个 JVM 进程节省数十乃至数百兆字节的内存。另外对于云平台上的微服务分析表明，许多服务器在启动时会加载数千个应用程序类，AppCDS 可以让这些服务快速启动并改善整个系统响应时间。 线程-局部管控在已有的 Java 版本中，JVM 线程只能全部启用或者停止，没法做到对单独某个线程的操作。为了能够对单独的某个线程进行操作，Java 10 中线程管控引入 JVM 安全点的概念，将允许在不运行全局 JVM 安全点的情况下实现线程回调，由线程本身或者 JVM 线程来执行，同时保持线程处于阻塞状态，这种方式使得停止单个线程变成可能，而不是只能启用或停止所有线程。通过这种方式显著地提高了现有 JVM 功能的性能开销，并且改变了到达 JVM 全局安全点的现有时间语义。 增加的参数为：-XX:ThreadLocalHandshakes (默认为开启)，将允许用户在支持的平台上选择安全点。 移除 Native-Header 自动生成工具自 Java 9 以来便开始了一些对 JDK 的调整，用户每次调用 javah 工具时会被警告该工具在未来的版本中将会执行的删除操作。当编译 JNI 代码时，已不再需要单独的 Native-Header 工具来生成头文件，因为这可以通过 Java 8（JDK-7150368）中添加的 javac 来完成。在未来的某一时刻，JNI 将会被 Panama 项目的结果取代，但是何时发生还没有具体时间表。 额外的 Unicode 语言标签扩展自 Java 7 开始支持 BCP 47 语言标记以来， JDK 中便增加了与日历和数字相关的 Unicode 区域设置扩展，在 Java 9 中，新增支持 ca 和 nu 两种语言标签扩展。而在 Java 10 中将继续增加 Unicode 语言标签扩展，具体为：增强 java.util.Locale 类及其相关的 API，以更方便的获得所需要的语言地域环境信息。同时在这次升级中还带来了如下扩展支持： 表 1.Unicode 扩展表 编码 注释 cu 货币类型 fw 一周的第一天 rg 区域覆盖 tz 时区 如 Java 10 加入的一个方法： 清单 4. Unicode 语言标签扩展示例 1java.time.format.DateTimeFormatter::localizedBy 通过这个方法，可以采用某种数字样式，区域定义或者时区来获得时间信息所需的语言地域本地环境信息。 备用存储装置上的堆分配硬件技术在持续进化，现在可以使用与传统 DRAM 具有相同接口和类似性能特点的非易失性 RAM。Java 10 中将使得 JVM 能够使用适用于不同类型的存储机制的堆，在可选内存设备上进行堆内存分配。 一些操作系统中已经通过文件系统提供了使用非 DRAM 内存的方法。例如：NTFS DAX 模式和 ext4 DAX。这些文件系统中的内存映射文件可绕过页面缓存并提供虚拟内存与设备物理内存的相互映射。与 DRAM 相比，NV-DIMM 可能具有更高的访问延迟，低优先级进程可以为堆使用 NV-DIMM 内存，允许高优先级进程使用更多 DRAM。 要在这样的备用设备上进行堆分配，可以使用堆分配参数 -XX：AllocateHeapAt = &lt;path&gt; ，这个参数将指向文件系统的文件并使用内存映射来达到在备用存储设备上进行堆分配的预期结果。 基于 Java 的 实验性 JIT 编译器Java 10 中开启了基于 Java 的 JIT 编译器 Graal，并将其用作 Linux&#x2F;x64 平台上的实验性 JIT 编译器开始进行测试和调试工作，另外 Graal 将使用 Java 9 中引入的 JVM 编译器接口（JVMCI）。 Graal 是一个以 Java 为主要编程语言、面向 Java bytecode 的编译器。与用 C++实现的 C1 及 C2 相比，它的模块化更加明显，也更加容易维护。Graal 既可以作为动态编译器，在运行时编译热点方法；亦可以作为静态编译器，实现 AOT 编译。在 Java 10 中，Graal 作为试验性 JIT 编译器一同发布（JEP 317）。将 Graal 编译器研究项目引入到 Java 中，或许能够为 JVM 性能与当前 C++ 所写版本匹敌（或有幸超越）提供基础。 Java 10 中默认情况下 HotSpot 仍使用的是 C2 编译器，要启用 Graal 作为 JIT 编译器，请在 Java 命令行上使用以下参数： 清单 5. 启用 Graal 为 JIT 编译器示例 1-XX：+ UnlockExperimentalVMOptions -XX：+ UseJVMCICompiler 根证书认证自 Java 9 起在 keytool 中加入参数 -cacerts ，可以查看当前 JDK 管理的根证书。而 Java 9 中 cacerts 目录为空，这样就会给开发者带来很多不便。从 Java 10 开始，将会在 JDK 中提供一套默认的 CA 根证书。 作为 JDK 一部分的 cacerts 密钥库旨在包含一组能够用于在各种安全协议的证书链中建立信任的根证书。但是，JDK 源代码中的 cacerts 密钥库至目前为止一直是空的。因此，在 JDK 构建中，默认情况下，关键安全组件（如 TLS）是不起作用的。要解决此问题，用户必须使用一组根证书配置和 cacerts 密钥库下的 CA 根证书。 基于时间的版本发布模式虽然 JEP 223 中引入的版本字符串方案较以往有了显著的改进。但是，该方案并不适合以后严格按照六个月的节奏来发布 Java 新版本的这种情况。 按照 JEP 223 的语义中，每个基于 JDK 构建或使用组件的开发者（包括 JDK 的发布者）都必须提前敲定版本号，然后切换过去。开发人员则必须在代码中修改检查版本号的相关代码，这对所有参与者来说都很尴尬和混乱。 Java 10 中将重新编写之前 JDK 版本中引入的版本号方案，将使用基于时间模型定义的版本号格式来定义新版本。保留与 JEP 223 版本字符串方案的兼容性，同时也允许除当前模型以外的基于时间的发布模型。使开发人员或终端用户能够轻松找出版本的发布时间，以便开发人员能够判断是否将其升级到具有最新安全修补程序或可能的附加功能的新版本。 Oracle Java 平台组的首席架构师 Mark Reinhold 在博客上介绍了有关 Java 未来版本的一些想法（你能接受 Java 9 的下一个版本是 Java 18.3 吗？）。他提到，Java 计划按照时间来发布，每半年一个版本，而不是像之前那样按照重要特性来确定大版本，如果某个大的特性因故延期，这个版本可能一拖再拖。 当时，Mark 也提出来一种基于时间命名版本号的机制，比如下一个将于 2018 年 3 月发布的版本，就是 18.3，再下一个版本是 18.9，以后版本依此类推。 不过经过讨论，考虑和之前版本号的兼容等问题，最终选择的命名机制是： 1$FEATURE.$INTERIM.$UPDATE.$PATCH $FEATURE：每次版本发布加 1，不考虑具体的版本内容。2018 年 3 月的版本是 JDK 10，9 月的版本是 JDK 11，依此类推。 $INTERIM：中间版本号，在大版本中间发布的，包含问题修复和增强的版本，不会引入非兼容性修改。 结束语尽管距离 Java 9 发布仅有六个月的时间，Java 10 的发布也带来了不少新特性和功能增强，以上只是针对其中对开发人员影响重大的主要的一些特性做了介绍，同时也希望下一个 Java 版本能够带来更多、更大的变化。以上只是个人在实际项目中的一点思考，如有不足之处，还望各位读者能够海涵，如可以，希望读者们能够反馈意见，交流心得，一同进步。 参考文章 本文章转载自 https://developer.ibm.com/zh/technologies/java/articles/the-new-features-of-java-10/","tags":["Java","新特性","Java10"],"categories":["Java","新特性","Java10"]},{"title":"4.Java 9 新特性概述","path":"/2023/12/27/4-Java-9-新特性概述/","content":"Java 9 正式发布于 2017 年 9 月 21 日。作为 Java8 之后 3 年半才发布的新版本，Java 9 带来了很多重大的变化。其中最重要的改动是 Java 平台模块系统的引入。除此之外，还有一些新的特性。本文对 Java9 中包含的新特性做了概括性的介绍，可以帮助你快速了解 Java 9。 知识体系 Java 平台 模块系统Java 平台模块系统，也就是 Project Jigsaw，把模块化开发实践引入到了 Java 平台中。在引入了模块系统之后，JDK 被重新组织成 94 个模块。Java 应用可以通过新增的 jlink 工具，创建出只包含所依赖的 JDK 模块的自定义运行时镜像。这样可以极大的减少 Java 运行时环境的大小。这对于目前流行的不可变基础设施的实践来说，镜像的大小的减少可以节省很多存储空间和带宽资源 。 模块化开发的实践在软件开发领域并不是一个新的概念。Java 开发社区已经使用这样的模块化实践有相当长的一段时间。主流的构建工具，包括 Apache Maven 和 Gradle 都支持把一个大的项目划分成若干个子项目。子项目之间通过不同的依赖关系组织在一起。每个子项目在构建之后都会产生对应的 JAR 文件。 在 Java9 中 ，已有的这些项目可以很容易的升级转换为 Java 9 模块 ，并保持原有的组织结构不变。 Java 9 模块的重要特征是在其工件（artifact）的根目录中包含了一个描述模块的 module-info.class 文 件。 工件的格式可以是传统的 JAR 文件或是 Java 9 新增的 JMOD 文件。这个文件由根目录中的源代码文件 module-info.java 编译而来。该模块声明文件可以描述模块的不同特征。模块声明文件中可以包含的内容如下： 模块导出的包：使用 exports 可以声明模块对其他模块所导出的包。包中的 public 和 protected 类型，以及这些类型的 public 和 protected 成员可以被其他模块所访问。没有声明为导出的包相当于模块中的私有成员，不能被其他模块使用。 模块的依赖关系：使用 requires 可以声明模块对其他模块的依赖关系。使用 requires transitive 可 以把一个模块依赖声明为传递的。传递的模块依赖可以被依赖当前模块的其他模块所读取。 如果一个模块所导出的类型的型构中包含了来自它所依赖的模块的类型，那么对该模块的依赖应该声明为传递的。 服务的提供和使用：如果一个模块中包含了可以被 ServiceLocator 发现的服务接口的实现 ，需要使用 provides with 语句来声明具体的实现类 ；如果一个模块需要使用服务接口，可以使用 uses 语句来声明。 如下代码中给出了一个模块声明文件的示例。在该声明文件中，模块 com.mycompany.sample 导出了 Java 包 com.mycompany.sample。该模块依赖于模块 com.mycompany.common 。该模块也提供了服务接口 com.mycompany.common.DemoService 的实现类 com.mycompany.sample.DemoServiceImpl 。 123456module com.mycompany.sample &#123; exports com.mycompany.sample; requires com.mycompany.common; provides com.mycompany.common.DemoService with com.mycompany.sample.DemoServiceImpl;&#125; 模块系统中增加了模块路径的概念。模块系统在解析模块时，会从模块路径中进行查找。为了保持与之前 Java 版本的兼容性，CLASSPATH 依然被保留。所有的类型在运行时都属于某个特定的模块。对于从 CLASSPATH 中加载的类型，它们属于加载它们的类加载器对应的未命名模块。可以通过 Class 的 getModule()方法来获取到表示其所在模块的 Module 对象。 在 JVM 启动时，会从应用的根模块开始，根据依赖关系递归的进行解析，直到得到一个表示依赖关系的图。如果解析过程中出现找不到模块的情况，或是在模块路径的同一个地方找到了名称相同的模块，模块解析过程会终止，JVM 也会退出。Java 也提供了相应的 API 与模块系统进行交互。 Jshelljshell 是 Java 9 新增的一个实用工具。jshell 为 Java 增加了类似 NodeJS 和 Python 中的读取-求值-打印循环（ Read-Evaluation-Print Loop ） 。 在 jshell 中 可以直接 输入表达式并查看其执行结果。当需要测试一个方法的运行效果，或是快速的对表达式进行求值时，jshell 都非常实用。只需要通过 jshell 命令启动 jshell，然后直接输入表达式即可。每个表达式的结果会被自动保存下来 ，以数字编号作为引用，类似 $1 和$2 这样的名称 。可以在后续的表达式中引用之前语句的运行结果。 在 jshell 中 ，除了表达式之外，还可以创建 Java 类和方法。jshell 也有基本的代码完成功能。 在 如下代码 中，我们直接创建了一个方法 add。 1234jshell&gt; int add(int x, int y) &#123; ...&gt; return x + y; ...&gt; &#125; | created method add(int,int) 接着就可以在 jshell 中直接使用这个方法，如下代码 所示。 12jshell&gt; add(1, 2)$19 ==&gt; 3 集合、Stream 和 Optional在集合上，Java 9 增加 了 List.of()、Set.of()、Map.of() 和 Map.ofEntries()等工厂方法来创建不可变集合 ，如 如下 所示。 12345678List.of();List.of(&quot;Hello&quot;, &quot;World&quot;);List.of(1, 2, 3);Set.of();Set.of(&quot;Hello&quot;, &quot;World&quot;);Set.of(1, 2, 3);Map.of();Map.of(&quot;Hello&quot;, 1, &quot;World&quot;, 2); Stream 中增加了新的方法 ofNullable、dropWhile、takeWhile 和 iterate。在 如下代码 中，流中包含了从 1 到 5 的 元素。断言检查元素是否为奇数。第一个元素 1 被删除，结果流中包含 4 个元素。 1234567@Testpublic void testDropWhile() throws Exception &#123; final long count = Stream.of(1, 2, 3, 4, 5) .dropWhile(i -&gt; i % 2 != 0) .count(); assertEquals(4, count);&#125; Collectors 中增加了新的方法 filtering 和 flatMapping。在 如下代码 中，对于输入的 String 流 ，先通过 flatMapping 把 String 映射成 Integer 流 ，再把所有的 Integer 收集到一个集合中。 1234567@Testpublic void testFlatMapping() throws Exception &#123; final Set&lt;Integer&gt; result = Stream.of(&quot;a&quot;, &quot;ab&quot;, &quot;abc&quot;) .collect(Collectors.flatMapping(v -&gt; v.chars().boxed(), Collectors.toSet())); assertEquals(3, result.size());&#125; Optional 类中新增了 ifPresentOrElse、or 和 stream 等方法。在 如下代码 中，Optiona l 流中包含 3 个 元素，其中只有 2 个有值。在使用 flatMap 之后，结果流中包含了 2 个值。 12345678910@Testpublic void testStream() throws Exception &#123; final long count = Stream.of( Optional.of(1), Optional.empty(), Optional.of(2) ).flatMap(Optional::stream) .count(); assertEquals(2, count);&#125; 进程 APIJava 9 增加了 ProcessHandle 接口，可以对原生进程进行管理，尤其适合于管理长时间运行的进程。在使用 ProcessBuilder 来启动一个进程之后，可以通过 Process.toHandle()方法来得到一个 ProcessHandl e 对象的实例。通过 ProcessHandle 可以获取到由 ProcessHandle.Info 表 示的进程的基本信息，如命令行参数、可执行文件路径和启动时间等。ProcessHandle 的 onExit()方法返回一个 CompletableFuture对象，可以在进程结束时执行自定义的动作。 如下代码中给出了进程 API 的使用示例。 12345678910final ProcessBuilder processBuilder = new ProcessBuilder(&quot;top&quot;) .inheritIO();final ProcessHandle processHandle = processBuilder.start().toHandle();processHandle.onExit().whenCompleteAsync((handle, throwable) -&gt; &#123; if (throwable == null) &#123; System.out.println(handle.pid()); &#125; else &#123; throwable.printStackTrace(); &#125;&#125;); 平台日志 API 和 服务Java 9 允许为 JDK 和应用配置同样的日志实现。新增的 System.LoggerFinder 用来管理 JDK 使 用的日志记录器实现。JVM 在运行时只有一个系统范围的 LoggerFinder 实例。LoggerFinder 通 过服务查找机制来加载日志记录器实现。默认情况下，JDK 使用 java.logging 模块中的 java.util.logging 实现。通过 LoggerFinder 的 getLogger()方法就可以获取到表示日志记录器的 System.Logger 实现。应用同样可以使用 System.Logger 来记录日志。这样就保证了 JDK 和应用使用同样的日志实现。我们也可以通过添加自己的 System.LoggerFinder 实现来让 JDK 和应用使用 SLF4J 等其他日志记录框架。 代码清单 9 中给出了平台日志 API 的使用示例。 123456public class Main &#123; private static final System.Logger LOGGER = System.getLogger(&quot;Main&quot;); public static void main(final String[] args) &#123; LOGGER.log(Level.INFO, &quot;Run!&quot;); &#125;&#125; 反应式流 （ Reactive Streams ）反应式编程的思想最近得到了广泛的流行。 在 Java 平台上有流行的反应式 库 RxJava 和 R eactor。反应式流规范的出发点是提供一个带非阻塞负压（ non-blocking backpressure ） 的异步流处理规范。反应式流规范的核心接口已经添加到了 Java9 中的 java.util.concurrent.Flow 类中。 Flow 中包含了 Flow.Publisher、Flow.Subscriber、Flow.Subscription 和 F low.Processor 等 4 个核心接口。Java 9 还提供了 SubmissionPublisher 作为 Flow.Publisher 的一个实现。RxJava 2 和 Reactor 都可以很方便的 与 Flow 类的核心接口进行互操作。 变量句柄变量句柄是一个变量或一组变量的引用，包括静态域，非静态域，数组元素和堆外数据结构中的组成部分等。变量句柄的含义类似于已有的方法句柄。变量句柄由 Java 类 java.lang.invoke.VarHandle 来表示。可以使用类 java.lang.invoke.MethodHandles.Lookup 中的静态工厂方法来创建 VarHandle 对象。通过变量句柄，可以在变量上进行各种操作。这些操作称为访问模式。不同的访问模式尤其在内存排序上的不同语义。目前一共有 31 种 访问模式，而每种访问模式都 在 VarHandle 中 有对应的方法。这些方法可以对变量进行读取、写入、原子更新、数值原子更新和比特位原子操作等。VarHandle 还可以用来访问数组中的单个元素，以及把 byte[]数组 和 ByteBuffer 当成是不同原始类型的数组来访问。 在 如下代码 中，我们创建了访问 HandleTarget 类中的域 count 的变量句柄，并在其上进行读取操作。 123456789101112131415161718192021public class HandleTarget &#123; public int count = 1;&#125;public class VarHandleTest &#123; private HandleTarget handleTarget = new HandleTarget(); private VarHandle varHandle; @Before public void setUp() throws Exception &#123; this.handleTarget = new HandleTarget(); this.varHandle = MethodHandles .lookup() .findVarHandle(HandleTarget.class, &quot;count&quot;, int.class); &#125; @Test public void testGet() throws Exception &#123; assertEquals(1, this.varHandle.get(this.handleTarget)); assertEquals(1, this.varHandle.getVolatile(this.handleTarget)); assertEquals(1, this.varHandle.getOpaque(this.handleTarget)); assertEquals(1, this.varHandle.getAcquire(this.handleTarget)); &#125;&#125; 改进方法句柄（Method Handle）类 java.lang.invoke.MethodHandles 增加了更多的静态方法来创建不同类型的方法句柄。 arrayConstructor：创建指定类型的数组。 arrayLength：获取指定类型的数组的大小。 varHandleInvoker 和 varHandleExactInvoker：调用 VarHandle 中的访问模式方法。 zero：返回一个类型的默认值。 empty：返 回 MethodType 的返回值类型的默认值。 loop、countedLoop、iteratedLoop、whileLoop 和 doWhileLoop：创建不同类型的循环，包括 for 循环、while 循环 和 do-while 循环。 tryFinally：把对方法句柄的调用封装在 try-finally 语句中。 在 如下代码 中，我们使用 iteratedLoop 来创建一个遍历 S tring 类型迭代器的方法句柄，并计算所有字符串的长度的总和。 123456789101112131415161718192021222324public class IteratedLoopTest &#123; static int body(final int sum, final String value) &#123; return sum + value.length(); &#125; @Test public void testIteratedLoop() throws Throwable &#123; final MethodHandle iterator = MethodHandles.constant( Iterator.class, List.of(&quot;a&quot;, &quot;bc&quot;, &quot;def&quot;).iterator()); final MethodHandle init = MethodHandles.zero(int.class); final MethodHandle body = MethodHandles .lookup() .findStatic( IteratedLoopTest.class, &quot;body&quot;, MethodType.methodType( int.class, int.class, String.class)); final MethodHandle iteratedLoop = MethodHandles .iteratedLoop(iterator, init, body); assertEquals(6, iteratedLoop.invoke()); &#125;&#125; 并发在并发方面，类 CompletableFuture 中增加了几个新的方法。completeAsync 使用一个异步任务来获取结果并完成该 CompletableFuture。orTimeout 在 CompletableFuture 没有在给定的超时时间之前完成，使用 TimeoutException 异常来完成 CompletableFuture。completeOnTimeout 与 orTimeout 类似，只不过它在超时时使用给定的值来完成 CompletableFuture。新的 Thread.onSpinWait 方法在当前线程需要使用忙循环来等待时，可以提高等待的效率。 NashornNashorn 是 Java 8 中引入的新的 JavaScript 引擎。Java 9 中的 Nashorn 已经实现了一些 ECMAScript 6 规范中的新特性，包括模板字符串、二进制和八进制字面量、迭代器 和 for..of 循环和箭头函数等。Nashorn 还提供了 API 把 ECMAScript 源代码解析成抽象语法树（ Abstract Syntax Tree，AST ） ，可以用来对 ECMAScript 源代码进行分析。 I&#x2F;O 流新特性类 java.io.InputStream 中增加了新的方法来读取和复制 InputStream 中包含的数据。 readAllBytes：读取 InputStream 中的所有剩余字节。 readNBytes： 从 InputStream 中读取指定数量的字节到数组中。 transferTo：读取 InputStream 中的全部字节并写入到指定的 OutputStream 中 。 1234567891011121314151617181920212223242526public class TestInputStream &#123; private InputStream inputStream; private static final String CONTENT = &quot;Hello World&quot;; @Before public void setUp() throws Exception &#123; this.inputStream = TestInputStream.class.getResourceAsStream(&quot;/input.txt&quot;); &#125; @Test public void testReadAllBytes() throws Exception &#123; final String content = new String(this.inputStream.readAllBytes()); assertEquals(CONTENT, content); &#125; @Test public void testReadNBytes() throws Exception &#123; final byte[] data = new byte[5]; this.inputStream.readNBytes(data, 0, 5); assertEquals(&quot;Hello&quot;, new String(data)); &#125; @Test public void testTransferTo() throws Exception &#123; final ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); this.inputStream.transferTo(outputStream); assertEquals(CONTENT, outputStream.toString()); &#125;&#125; ObjectInputFilter 可以对 ObjectInputStream 中 包含的内容进行检查，来确保其中包含的数据是合法的。可以使用 ObjectInputStream 的方法 setObjectInputFilter 来设置。ObjectInputFilter 在 进行检查时，可以检查如对象图的最大深度、对象引用的最大数量、输入流中的最大字节数和数组的最大长度等限制，也可以对包含的类的名称进行限制。 改进应用安全性能Java 9 新增了 4 个 SHA-3 哈希算法，SHA3-224、SHA3-256、SHA3-384 和 SHA3-512。另外也增加了通过 java.security.SecureRandom 生成使用 DRBG 算法的强随机数。如下代码中给出了 SHA-3 哈希算法的使用示例。 12345678import org.apache.commons.codec.binary.Hex;public class SHA3 &#123; public static void main(final String[] args) throws NoSuchAlgorithmException &#123; final MessageDigest instance = MessageDigest.getInstance(&quot;SHA3-224&quot;); final byte[] digest = instance.digest(&quot;&quot;.getBytes()); System.out.println(Hex.encodeHexString(digest)); &#125;&#125; 用户界面类 java.awt.Desktop 增加了新的与桌面进行互动的能力。可以使用 addAppEventListener 方法来添加不同应用事件的监听器，包括应用变为前台应用、应用隐藏或显示、屏幕和系统进入休眠与唤醒、以及 用户会话的开始和终止等。还可以在显示关于窗口和配置窗口时，添加自定义的逻辑。在用户要求退出应用时，可以通过自定义处理器来接受或拒绝退出请求。在 A WT 图像支持方面，可以在应用中使用多分辨率图像。 统一 JVM 日志Java 9 中 ，JVM 有了统一的日志记录系统，可以使用新的命令行选项-Xlog 来控制 JVM 上 所有组件的日志记录。该日志记录系统可以设置输出的日志消息的标签、级别、修饰符和输出目标等。Java 9 移除了在 Java 8 中 被废弃的垃圾回收器配置组合，同时 把 G1 设为默认的垃圾回收器实现。另外，CMS 垃圾回收器已经被声明为废弃。Java 9 也增加了很多可以通过 jcmd 调用的诊断命令。 其他改动方面 在 Java 语言本身，Java 9 允许在接口中使用私有方法。 在如下代码中，buildMessage 是接口 SayHi 中的私有方法，在默认方法 sayHi 中被使用。 123456789public interface SayHi &#123; private String buildMessage() &#123; return &quot;Hello&quot;; &#125; void sayHi(final String message); default void sayHi() &#123; sayHi(buildMessage()); &#125;&#125; 在 try-with-resources 语句中可以使用 effectively-final 变量。 类 java.lang.StackWalker 可以对线程的堆栈进行遍历，并且支持过滤和延迟访问。Java 9 把对 Unicode 的支持升级到了 8.0。 ResourceBundle 加载属性文件的默认编码从 ISO-8859-1 改成了 UTF-8，不再需要使用 native2ascii 命 令来对属性文件进行额外处理。 注解@Deprecated 也得到了增强，增加了 since 和 forRemoval 两 个属性，可以分别指定一个程序元素被废弃的版本，以及是否会在今后的版本中被删除。 在如下的代码中，表示PdaiDeprecatedTest这个类在JDK9版本中被弃用并且在将来的某个版本中一定会被删除。 1234@Deprecated(since=&quot;9&quot;, forRemoval = true)public class PdaiDeprecatedTest &#123;&#125; 结束语作为 Java 平台最新的一个重大更新，Java 9 中的很多新特性，尤其模块系统，对于 Java 应用的开发会产生深远的影响。本文对 Java 9 中的新特性做了概括的介绍，可以作为了解 Java 9 的基础。这些新特性的相信内容，可以通过官方文档来进一步的了解。 参考文章 本文主要转载自 https://developer.ibm.com/zh/articles/the-new-features-of-Java-9/ 并在此文章的基础上进行了补充和调整。","tags":["Java","新特性","Java9"],"categories":["Java","新特性","Java9"]},{"title":"3.Java 11 升Java 17 重要特性必读","path":"/2023/12/27/3-Java-11-升Java-17-重要特性必读/","content":"JDK 17 在 2021 年 9 月 14 号正式发布了！根据发布的规划，这次发布的 JDK 17 是一个长期维护的版本（LTS)。SpingFramework 6 和SpringBoot 3中默认将使用JDK 17，所以JDK 17必将是使用较广泛的版本; 而从上个LTS版本JDK11到JDK17有哪些重要特性需要掌握呢？本文帮助你梳理Java 11 升Java 17 重要特性。 升级JDK17概述 这里帮你梳理为何JDK 17将会是一个极为重要的版本以及如何去理解它。 JDK 17升级的必要性？ JDK 11 作为一个 LTS版本，它的商业支持时间框架比 JDK 8 短，JDK 11 的 LTS 会提供技术支持直至 2023 年 9 月, 对应的补丁和安全警告等支持将持续至 2026 年。JDK 17 作为下一代 LTS 将提供至少到 2026 年的支持时间框架； Java系最为重要的开发框架Spring Framework 6 和 Spring Boot 3对JDK版本的最低要求是JDK 17；所以可以预见, 为了使用Spring最新框架，很多团队和开发者将被迫从Java 11（甚至Java 8)直接升级到Java 17版本。 JDK 11 升级到JDK 17 性能提升多少？从规划调度引擎 OptaPlanner 项目（原文在这里）对 JDK 17和 JDK 11 的性能基准测试进行了对比来看： 对于 G1GC（默认），Java 17 比 Java 11 快 8.66%； 对于 ParallelGC，Java 17 比 Java 11 快 6.54%； Parallel GC 整体比 G1 GC 快 16.39% 简而言之，JDK17 更快，高吞吐量垃圾回收器比低延迟垃圾回收器更快。 如何更好的理解从JDK 11 到 JDK 17 升级中带来的重要特性？主要从如下三个方面理解，后续的章节主要围绕这三个方面进行： 语言新特性 新工具和库更新 JVM优化 语言新特性JDK14 - Switch 表达式（JDK 12,13预览，14正式） switch 表达式在之前的 Java 12 和 Java 13 中都是处于预览阶段，而在这次更新的 Java 14 中，终于成为稳定版本，能够正式可用。 switch 表达式带来的不仅仅是编码上的简洁、流畅，也精简了 switch 语句的使用方式，同时也兼容之前的 switch 语句的使用；之前使用 switch 语句时，在每个分支结束之前，往往都需要加上 break 关键字进行分支跳出，以防 switch 语句一直往后执行到整个 switch 语句结束，由此造成一些意想不到的问题。switch 语句一般使用冒号 ：来作为语句分支代码的开始，而 switch 表达式则提供了新的分支切换方式，即 -&gt; 符号右则表达式方法体在执行完分支方法之后，自动结束 switch 分支，同时 -&gt; 右则方法块中可以是表达式、代码块或者是手动抛出的异常。以往的 switch 语句写法如下： 123456789101112131415161718192021int dayOfWeek;switch (day) &#123; case MONDAY: case FRIDAY: case SUNDAY: dayOfWeek = 6; break; case TUESDAY: dayOfWeek = 7; break; case THURSDAY: case SATURDAY: dayOfWeek = 8; break; case WEDNESDAY: dayOfWeek = 9; break; default: dayOfWeek = 0; break;&#125; 而现在 Java 14 可以使用 switch 表达式正式版之后，上面语句可以转换为下列写法： 12345678int dayOfWeek = switch (day) &#123; case MONDAY, FRIDAY, SUNDAY -&gt; 6; case TUESDAY -&gt; 7; case THURSDAY, SATURDAY -&gt; 8;case WEDNESDAY -&gt; 9; default -&gt; 0;&#125;; 很明显，switch 表达式将之前 switch 语句从编码方式上简化了不少，但是还是需要注意下面几点： 需要保持与之前 switch 语句同样的 case 分支情况。 之前需要用变量来接收返回值，而现在直接使用 yield 关键字来返回 case 分支需要返回的结果。 现在的 switch 表达式中不再需要显式地使用 return、break 或者 continue 来跳出当前分支。 现在不需要像之前一样，在每个分支结束之前加上 break 关键字来结束当前分支，如果不加，则会默认往后执行，直到遇到 break 关键字或者整个 switch 语句结束，在 Java 14 表达式中，表达式默认执行完之后自动跳出，不会继续往后执行。 对于多个相同的 case 方法块，可以将 case 条件并列，而不需要像之前一样，通过每个 case 后面故意不加 break 关键字来使用相同方法块。 使用 switch 表达式来替换之前的 switch 语句，确实精简了不少代码，提高了编码效率，同时也可以规避一些可能由于不太经意而出现的意想不到的情况，可见 Java 在提高使用者编码效率、编码体验和简化使用方面一直在不停的努力中，同时也期待未来有更多的类似 lambda、switch 表达式这样的新特性出来。 JDK15 - 文本块（JDK 13,14预览，15正式） 文本块，是一个多行字符串，它可以避免使用大多数转义符号，自动以可预测的方式格式化字符串，并让开发人员在需要时可以控制格式。 Text Blocks首次是在JDK 13中以预览功能出现的，然后在JDK 14中又预览了一次，终于在JDK 15中被确定下来，可放心使用了。 12345678public static void main(String[] args) &#123; String query = &quot;&quot;&quot; SELECT * from USER \\ WHERE `id` = 1 \\ ORDER BY `id`, `name`;\\ &quot;&quot;&quot;; System.out.println(query);&#125; 运行程序，输出（可以看到展示为一行了）： 1SELECT * from USER WHERE `id` = 1 ORDER BY `id`, `name`; JDK16 - instanceof 模式匹配（JDK 14,15预览，16正式） 模式匹配（Pattern Matching）最早在 Java 14 中作为预览特性引入，在 Java 15 中还是预览特性，在Java 16中成为正式版。模式匹配通过对 instacneof 运算符进行模式匹配来增强 Java 编程语言。 对 instanceof 的改进，主要目的是为了让创建对象更简单、简洁和高效，并且可读性更强、提高安全性。 在以往实际使用中，instanceof 主要用来检查对象的类型，然后根据类型对目标对象进行类型转换，之后进行不同的处理、实现不同的逻辑，具体可以参考如下： 123456789if (person instanceof Student) &#123; Student student = (Student) person; student.say(); // other student operations&#125; else if (person instanceof Teacher) &#123; Teacher teacher = (Teacher) person; teacher.say(); // other teacher operations&#125; 上述代码中，我们首先需要对 person 对象进行类型判断，判断 person 具体是 Student 还是 Teacher，因为这两种角色对应不同操作，亦即对应到的实际逻辑实现，判断完 person 类型之后，然后强制对 person 进行类型转换为局部变量，以方便后续执行属于该角色的特定操作。 上面这种写法，有下面两个问题： 每次在检查类型之后，都需要强制进行类型转换。 类型转换后，需要提前创建一个局部变量来接收转换后的结果，代码显得多余且繁琐。 对 instanceof 进行模式匹配改进之后，上面示例代码可以改写成： 1234567if (person instanceof Student student) &#123; student.say(); // other student operations&#125; else if (person instanceof Teacher teacher) &#123; teacher.say(); // other teacher operations&#125; 首先在 if 代码块中，对 person 对象进行类型匹配，校验 person 对象是否为 Student 类型，如果类型匹配成功，则会转换为 Student 类型，并赋值给模式局部变量 student，并且只有当模式匹配表达式匹配成功是才会生效和复制，同时这里的 student 变量只能在 if 块中使用，而不能在 else if&#x2F;else 中使用，否则会报编译错误。 注意，如果 if 条件中有 &amp;&amp; 运算符时，当 instanceof 类型匹配成功，模式局部变量的作用范围也可以相应延长，如下面代码： 1if (obj instanceof String s &amp;&amp; s.length() &gt; 5) &#123;.. s.contains(..) ..&#125; 另外，需要注意，这种作用范围延长，并不适用于或 || 运算符，因为即便 || 运算符左边的 instanceof 类型匹配没有成功也不会造成短路，依旧会执行到||运算符右边的表达式，但是此时，因为 instanceof 类型匹配没有成功，局部变量并未定义赋值，此时使用会产生问题。 与传统写法对比，可以发现模式匹配不但提高了程序的安全性、健壮性，另一方面，不需要显式的去进行二次类型转换，减少了大量不必要的强制类型转换。模式匹配变量在模式匹配成功之后，可以直接使用，同时它还被限制了作用范围，大大提高了程序的简洁性、可读性和安全性。instanceof 的模式匹配，为 Java 带来的有一次便捷的提升，能够剔除一些冗余的代码，写出更加简洁安全的代码，提高码代码效率。 JDK16 - Records类型（JDK 14,15预览，16正式） Records 最早在 Java 14 中作为预览特性引入，在 Java 15 中还是预览特性，在Java 16中成为正式版。 Record 类型允许在代码中使用紧凑的语法形式来声明类，而这些类能够作为不可变数据类型的封装持有者。Record 这一特性主要用在特定领域的类上；与枚举类型一样，Record 类型是一种受限形式的类型，主要用于存储、保存数据，并且没有其它额外自定义行为的场景下。 在以往开发过程中，被当作数据载体的类对象，在正确声明定义过程中，通常需要编写大量的无实际业务、重复性质的代码，其中包括：构造函数、属性调用、访问以及 equals() 、hashCode()、toString() 等方法，因此在 Java 14 中引入了 Record 类型，其效果有些类似 Lombok 的 @Data 注解、Kotlin 中的 data class，但是又不尽完全相同，它们的共同点都是类的部分或者全部可以直接在类头中定义、描述，并且这个类只用于存储数据而已。对于 Record 类型，具体可以用下面代码来说明： 1234567public record Person(String name, int age) &#123; public static String address; public String getName() &#123; return name; &#125;&#125; 对上述代码进行编译，然后反编译之后可以看到如下结果： 123456789101112131415161718public final class Person extends java.lang.Record &#123; private final java.lang.String name; private final java.lang.String age; public Person(java.lang.String name, java.lang.String age) &#123; /* compiled code */ &#125; public java.lang.String getName() &#123; /* compiled code */ &#125; public java.lang.String toString() &#123; /* compiled code */ &#125; public final int hashCode() &#123; /* compiled code */ &#125; public final boolean equals(java.lang.Object o) &#123; /* compiled code */ &#125; public java.lang.String name() &#123; /* compiled code */ &#125; public java.lang.String age() &#123; /* compiled code */ &#125;&#125; 根据反编译结果，可以得出，当用 Record 来声明一个类时，该类将自动拥有下面特征： 拥有一个构造方法 获取成员属性值的方法：name()、age() hashCode() 方法和 euqals() 方法 toString() 方法 类对象和属性被 final 关键字修饰，不能被继承，类的示例属性也都被 final 修饰，不能再被赋值使用。 还可以在 Record 声明的类中定义静态属性、方法和示例方法。注意，不能在 Record 声明的类中定义示例字段，类也不能声明为抽象类等。 可以看到，该预览特性提供了一种更为紧凑的语法来声明类，并且可以大幅减少定义类似数据类型时所需的重复性代码。 另外 Java 14 中为了引入 Record 这种新的类型，在 java.lang.Class 中引入了下面两个新方法： 12RecordComponent[] getRecordComponents()boolean isRecord() 其中 getRecordComponents() 方法返回一组 java.lang.reflect.RecordComponent 对象组成的数组，java.lang.reflect.RecordComponent也是一个新引入类，该数组的元素与 Record 类中的组件相对应，其顺序与在记录声明中出现的顺序相同，可以从该数组中的每个 RecordComponent 中提取到组件信息，包括其名称、类型、泛型类型、注释及其访问方法。 而 isRecord() 方法，则返回所在类是否是 Record 类型，如果是，则返回 true。 JDK17 - 密封的类和接口（JDK 15,16预览，17正式） 封闭类可以是封闭类和或者封闭接口，用来增强 Java 编程语言，防止其他类或接口扩展或实现它们。这个特性由Java 15的预览版本晋升为正式版本。 密封的类和接口解释和应用 因为我们引入了sealed class或interfaces，这些class或者interfaces只允许被指定的类或者interface进行扩展和实现。 使用修饰符sealed，您可以将一个类声明为密封类。密封的类使用reserved关键字permits列出可以直接扩展它的类。子类可以是最终的，非密封的或密封的。 之前我们的代码是这样的。 1234567public class Person &#123; &#125; //人 class Teacher extends Person &#123; &#125;//教师 class Worker extends Person &#123; &#125; //工人 class Student extends Person&#123; &#125; //学生 但是我们现在要限制 Person类 只能被这三个类继承，不能被其他类继承，需要这么做。 123456789101112131415161718// 添加sealed修饰符，permits后面跟上只能被继承的子类名称public sealed class Person permits Teacher, Worker, Student&#123; &#125; //人 // 子类可以被修饰为 finalfinal class Teacher extends Person &#123; &#125;//教师 // 子类可以被修饰为 non-sealed，此时 Worker类就成了普通类，谁都可以继承它non-sealed class Worker extends Person &#123; &#125; //工人// 任何类都可以继承Workerclass AnyClass extends Worker&#123;&#125; //子类可以被修饰为 sealed,同上sealed class Student extends Person permits MiddleSchoolStudent,GraduateStudent&#123; &#125; //学生 final class MiddleSchoolStudent extends Student &#123; &#125; //中学生 final class GraduateStudent extends Student &#123; &#125; //研究生 很强很实用的一个特性，可以限制类的层次结构。 新工具和库更新JDK13 - Socket API 重构Java 中的 Socket API 已经存在了二十多年了，尽管这么多年来，一直在维护和更新中，但是在实际使用中遇到一些局限性，并且不容易维护和调试，所以要对其进行大修大改，才能跟得上现代技术的发展，毕竟二十多年来，技术都发生了深刻的变化。Java 13 为 Socket API 带来了新的底层实现方法，并且在 Java 13 中是默认使用新的 Socket 实现，使其易于发现并在排除问题同时增加可维护性。 Java Socket API（java.net.ServerSocket 和 java.net.Socket）包含允许监听控制服务器和发送数据的套接字对象。可以使用 ServerSocket 来监听连接请求的端口，一旦连接成功就返回一个 Socket 对象，可以使用该对象读取发送的数据和进行数据写回操作，而这些类的繁重工作都是依赖于 SocketImpl 的内部实现，服务器的发送和接收两端都基于 SOCKS 进行实现的。 在 Java 13 之前，通过使用 PlainSocketImpl 作为 SocketImpl 的具体实现。 Java 13 中的新底层实现，引入 NioSocketImpl 的实现用以替换 SocketImpl 的 PlainSocketImpl 实现，此实现与 NIO（新 I&#x2F;O）实现共享相同的内部基础结构，并且与现有的缓冲区高速缓存机制集成在一起，因此不需要使用线程堆栈。除了这些更改之外，还有其他一些更便利的更改，如使用 java.lang.ref.Cleaner 机制来关闭套接字（如果 SocketImpl 实现在尚未关闭的套接字上被进行了垃圾收集），以及在轮询时套接字处于非阻塞模式时处理超时操作等方面。 为了最小化在重新实现已使用二十多年的方法时出现问题的风险，在引入新实现方法的同时，之前版本的实现还未被移除，可以通过使用下列系统属性以重新使用原实现方法： 1-Djdk.net.usePlainSocketImpl = true 另外需要注意的是，SocketImpl 是一种传统的 SPI 机制，同时也是一个抽象类，并未指定具体的实现，所以，新的实现方式尝试模拟未指定的行为，以达到与原有实现兼容的目的。但是，在使用新实现时，有些基本情况可能会失败，使用上述系统属性可以纠正遇到的问题，下面两个除外。 老版本中，PlainSocketImpl 中的 getInputStream() 和 getOutputStream() 方法返回的 InputStream 和 OutputStream 分别来自于其对应的扩展类型 FileInputStream 和 FileOutputStream，而这个在新版实现中则没有。 使用自定义或其它平台的 SocketImpl 的服务器套接字无法接受使用其他（自定义或其它平台）类型 SocketImpl 返回 Sockets 的连接。 通过这些更改，Java Socket API 将更易于维护，更好地维护将使套接字代码的可靠性得到改善。同时 NIO 实现也可以在基础层面完成，从而保持 Socket 和 ServerSocket 类层面上的不变。 JDK14 - 改进 NullPointerExceptions 提示信息Java 14 改进 NullPointerException 的可查性、可读性，能更准确地定位 null 变量的信息。该特性能够帮助开发者和技术支持人员提高生产力，以及改进各种开发工具和调试工具的质量，能够更加准确、清楚地根据动态异常与程序代码相结合来理解程序。 相信每位开发者在实际编码过程中都遇到过 NullPointerException，每当遇到这种异常的时候，都需要根据打印出来的详细信息来分析、定位出现问题的原因，以在程序代码中规避或解决。例如，假设下面代码出现了一个 NullPointerException： 1book.id = 99; 打印出来的 NullPointerException 信息如下： 12Exception in thread &quot;main&quot; java.lang.NullPointerException at Book.main(Book.java:5) 像上面这种异常，因为代码比较简单，并且异常信息中也打印出来了行号信息，开发者可以很快速定位到出现异常位置：book 为空而导致的 NullPointerException，而对于一些复杂或者嵌套的情况下出现 NullPointerException 时，仅根据打印出来的信息，很难判断实际出现问题的位置，具体见下面示例： 1shoopingcart.buy.book.id = 99; 对于这种比较复杂的情况下，仅仅单根据异常信息中打印的行号，则比较难判断出现 NullPointerException 的原因。 而 Java 14 中，则做了对 NullPointerException 打印异常信息的改进增强，通过分析程序的字节码信息，能够做到准确的定位到出现 NullPointerException 的变量，并且根据实际源代码打印出详细异常信息，对于上述示例，打印信息如下： 123Exception in thread &quot;main&quot; java.lang.NullPointerException: Cannot assign field &quot;book&quot; because &quot;shoopingcart.buy&quot; is null at Book.main(Book.java:5) 对比可以看出，改进之后的 NullPointerException 信息，能够准确打印出具体哪个变量导致的 NullPointerException，减少了由于仅带行号的异常提示信息带来的困惑。该改进功能可以通过如下参数开启： 1-XX:+ShowCodeDetailsInExceptionMessages 该增强改进特性，不仅适用于属性访问，还适用于方法调用、数组访问和赋值等有可能会导致 NullPointerException 的地方。 JDK15 - 隐藏类 Hidden Classes 隐藏类是为框架（frameworks）所设计的，隐藏类不能直接被其他类的字节码使用，只能在运行时生成类并通过反射间接使用它们。 该提案通过启用标准 API 来定义 无法发现 且 具有有限生命周期 的隐藏类，从而提高 JVM 上所有语言的效率。JDK内部和外部的框架将能够动态生成类，而这些类可以定义隐藏类。通常来说基于JVM的很多语言都有动态生成类的机制，这样可以提高语言的灵活性和效率。 隐藏类天生为框架设计的，在运行时生成内部的class。 隐藏类只能通过反射访问，不能直接被其他类的字节码访问。 隐藏类可以独立于其他类加载、卸载，这可以减少框架的内存占用。 Hidden Classes是什么呢？ Hidden Classes就是不能直接被其他class的二进制代码使用的class。Hidden Classes主要被一些框架用来生成运行时类，但是这些类不是被用来直接使用的，而是通过反射机制来调用。 比如在JDK8中引入的lambda表达式，JVM并不会在编译的时候将lambda表达式转换成为专门的类，而是在运行时将相应的字节码动态生成相应的类对象。 另外使用动态代理也可以为某些类生成新的动态类。 那么我们希望这些动态生成的类需要具有什么特性呢？ 不可发现性。 因为我们是为某些静态的类动态生成的动态类，所以我们希望把这个动态生成的类看做是静态类的一部分。所以我们不希望除了该静态类之外的其他机制发现。 访问控制。 我们希望在访问控制静态类的同时，也能控制到动态生成的类。 生命周期。 动态生成类的生命周期一般都比较短，我们并不需要将其保存和静态类的生命周期一致。 API的支持 所以我们需要一些API来定义无法发现的且具有有限生命周期的隐藏类。这将提高所有基于JVM的语言实现的效率。 比如： 123java.lang.reflect.Proxy // 可以定义隐藏类作为实现代理接口的代理类。 java.lang.invoke.StringConcatFactory // 可以生成隐藏类来保存常量连接方法； java.lang.invoke.LambdaMetaFactory //可以生成隐藏的nestmate类，以容纳访问封闭变量的lambda主体； 普通类是通过调用ClassLoader::defineClass创建的，而隐藏类是通过调用Lookup::defineHiddenClass创建的。这使JVM从提供的字节中派生一个隐藏类，链接该隐藏类，并返回提供对隐藏类的反射访问的查找对象。调用程序可以通过返回的查找对象来获取隐藏类的Class对象。 JDK15 - DatagramSocket API重构 重新实现了老的 DatagramSocket API 接口，更改了 java.net.DatagramSocket 和 java.net.MulticastSocket 为更加简单、现代化的底层实现，更易于维护和调试。 java.net.datagram.Socket和java.net.MulticastSocket的当前实现可以追溯到JDK 1.0，那时IPv6还在开发中。因此，当前的多播套接字实现尝试调和IPv4和IPv6难以维护的方式。 通过替换 java.net.datagram 的基础实现，重新实现旧版 DatagramSocket API。 更改java.net.DatagramSocket 和 java.net.MulticastSocket 为更加简单、现代化的底层实现。提高了 JDK 的可维护性和稳定性。 通过将java.net.datagram.Socket和java.net.MulticastSocket API的底层实现替换为更简单、更现代的实现来重新实现遗留的DatagramSocket API。 新的实现： 易于调试和维护; 与Project Loom中正在探索的虚拟线程协同。 JDK16 - 对基于值的类发出警告 JDK9注解@Deprecated得到了增强，增加了 since 和 forRemoval 两个属性，可以分别指定一个程序元素被废弃的版本，以及是否会在今后的版本中被删除。JDK16中对@jdk.internal.ValueBased注解加入了基于值的类的告警，所以继续在 Synchronized 同步块中使用值类型，将会在编译期和运行期产生警告，甚至是异常。 JDK9中@Deprecated增强了增加了 since 和 forRemoval 两 个属性 JDK9注解@Deprecated得到了增强，增加了 since 和 forRemoval 两个属性，可以分别指定一个程序元素被废弃的版本，以及是否会在今后的版本中被删除。 在如下的代码中，表示PdaiDeprecatedTest这个类在JDK9版本中被弃用并且在将来的某个版本中一定会被删除。 1234@Deprecated(since=&quot;9&quot;, forRemoval = true)public class PdaiDeprecatedTest &#123;&#125; JDK16中对基于值的类（@jdk.internal.ValueBased）给出告警 在JDK9中我们可以看到Integer.java类构造函数中加入了@Deprecated(since=&quot;9&quot;)，表示在JDK9版本中被弃用并且在将来的某个版本中一定会被删除 12345678910111213141516171819202122public final class Integer extends Number implements Comparable&lt;Integer&gt; &#123;// ... /** * Constructs a newly allocated &#123;@code Integer&#125; object that * represents the specified &#123;@code int&#125; value. * * @param value the value to be represented by the * &#123;@code Integer&#125; object. * * @deprecated * It is rarely appropriate to use this constructor. The static factory * &#123;@link #valueOf(int)&#125; is generally a better choice, as it is * likely to yield significantly better space and time performance. */ @Deprecated(since=&quot;9&quot;) public Integer(int value) &#123; this.value = value; &#125;// ... &#125; 如下是JDK16中Integer.java的代码 1234567891011121314151617181920212223242526272829303132333435363738394041/** &lt;p&gt;This is a &lt;a href=&quot;&#123;@docRoot&#125;/java.base/java/lang/doc-files/ValueBased.html&quot;&gt;value-based&lt;/a&gt; * class; programmers should treat instances that are * &#123;@linkplain #equals(Object) equal&#125; as interchangeable and should not * use instances for synchronization, or unpredictable behavior may * occur. For example, in a future release, synchronization may fail. * * &lt;p&gt;Implementation note: The implementations of the &quot;bit twiddling&quot; * methods (such as &#123;@link #highestOneBit(int) highestOneBit&#125; and * &#123;@link #numberOfTrailingZeros(int) numberOfTrailingZeros&#125;) are * based on material from Henry S. Warren, Jr.&#x27;s &lt;i&gt;Hacker&#x27;s * Delight&lt;/i&gt;, (Addison Wesley, 2002). * * @author Lee Boynton * @author Arthur van Hoff * @author Josh Bloch * @author Joseph D. Darcy * @since 1.0 */@jdk.internal.ValueBasedpublic final class Integer extends Number implements Comparable&lt;Integer&gt;, Constable, ConstantDesc &#123;// ... /** * Constructs a newly allocated &#123;@code Integer&#125; object that * represents the specified &#123;@code int&#125; value. * * @param value the value to be represented by the * &#123;@code Integer&#125; object. * * @deprecated * It is rarely appropriate to use this constructor. The static factory * &#123;@link #valueOf(int)&#125; is generally a better choice, as it is * likely to yield significantly better space and time performance. */ @Deprecated(since=&quot;9&quot;, forRemoval = true) public Integer(int value) &#123; this.value = value; &#125;// ... 添加@jdk.internal.ValueBased和@Deprecated(since=&quot;9&quot;, forRemoval = true)的作用是什么呢？ JDK设计者建议使用Integer a &#x3D; 10或者Integer.valueOf()函数，而不是new Integer()，让其抛出告警？ 在构造函数上都已经标记有@Deprecated(since&#x3D;”9”, forRemoval &#x3D; true)注解，这就意味着其构造函数在将来会被删除，不应该在程序中继续使用诸如new Integer(); 如果继续使用，编译期将会产生’Integer(int)’ is deprecated and marked for removal 告警。 在并发环境下，Integer 对象根本无法通过 Synchronized 来保证线程安全，让其抛出告警？ 由于JDK中对@jdk.internal.ValueBased注解加入了基于值的类的告警，所以继续在 Synchronized 同步块中使用值类型，将会在编译期和运行期产生警告，甚至是异常。 123456789public void inc(Integer count) &#123; for (int i = 0; i &lt; 10; i++) &#123; new Thread(() -&gt; &#123; synchronized (count) &#123; // 这里会产生编译告警 count++; &#125; &#125;).start(); &#125;&#125; JDK17 - 增强的伪随机数生成器 为伪随机数生成器 (PRNG) 提供新的接口类型和实现。这一变化提高了不同 PRNG 的互操作性，并使得根据需求请求算法变得容易，而不是硬编码特定的实现。简单而言只需要理解如下三个问题： JDK 17之前如何生成随机数？ Random 类 典型的使用如下，随机一个int值 12345678910111213141516171819// random intnew Random().nextInt();/** * description 获取指定位数的随机数 * * @param length 1 * @return java.lang.String */public static String getRandomString(int length) &#123; String base = &quot;abcdefghijklmnopqrstuvwxyz0123456789&quot;; Random random = new Random(); StringBuilder sb = new StringBuilder(); for (int i = 0; i &lt; length; i++) &#123; int number = random.nextInt(base.length()); sb.append(base.charAt(number)); &#125; return sb.toString();&#125; ThreadLocalRandom 类 提供线程间独立的随机序列。它只有一个实例，多个线程用到这个实例，也会在线程内部各自更新状态。它同时也是 Random 的子类，不过它几乎把所有 Random 的方法又实现了一遍。 12345678910111213141516171819/** * nextInt(bound) returns 0 &lt;= value &lt; bound; repeated calls produce at * least two distinct results */public void testNextIntBounded() &#123; // sample bound space across prime number increments for (int bound = 2; bound &lt; MAX_INT_BOUND; bound += 524959) &#123; int f = ThreadLocalRandom.current().nextInt(bound); assertTrue(0 &lt;= f &amp;&amp; f &lt; bound); int i = 0; int j; while (i &lt; NCALLS &amp;&amp; (j = ThreadLocalRandom.current().nextInt(bound)) == f) &#123; assertTrue(0 &lt;= j &amp;&amp; j &lt; bound); ++i; &#125; assertTrue(i &lt; NCALLS); &#125;&#125; SplittableRandom 类 非线程安全，但可以 fork 的随机序列实现，适用于拆分子任务的场景。 1234567891011/** * Repeated calls to nextLong produce at least two distinct results */public void testNextLong() &#123; SplittableRandom sr = new SplittableRandom(); long f = sr.nextLong(); int i = 0; while (i &lt; NCALLS &amp;&amp; sr.nextLong() == f) ++i; assertTrue(i &lt; NCALLS);&#125; 为什么需要增强？ 上述几个类实现代码质量和接口抽象不佳 缺少常见的伪随机算法 自定义扩展随机数的算法只能自己去实现，缺少统一的接口 增强后是什么样的？代码的优化自不必说，我们就看下新增了哪些常见的伪随机算法 如何使用这个呢？可以使用RandomGenerator 1RandomGenerator g = RandomGenerator.of(&quot;L64X128MixRandom&quot;); JVM优化JDK13 - 增强 ZGC 释放未使用内存ZGC 是 Java 11 中引入的最为瞩目的垃圾回收特性，是一种可伸缩、低延迟的垃圾收集器，不过在 Java 11 中是实验性的引入，主要用来改善 GC 停顿时间，并支持几百 MB 至几个 TB 级别大小的堆，并且应用吞吐能力下降不会超过 15%，目前只支持 Linux&#x2F;x64 位平台的这样一种新型垃圾收集器。 通过在实际中的使用，发现 ZGC 收集器中并没有像 Hotspot 中的 G1 和 Shenandoah 垃圾收集器一样，能够主动将未使用的内存释放给操作系统的功能。对于大多数应用程序来说，CPU 和内存都属于有限的紧缺资源，特别是现在使用的云上或者虚拟化环境中。如果应用程序中的内存长期处于空闲状态，并且还不能释放给操作系统，这样会导致其他需要内存的应用无法分配到需要的内存，而这边应用分配的内存还处于空闲状态，处于”忙的太忙，闲的太闲”的非公平状态，并且也容易导致基于虚拟化的环境中，因为这些实际并未使用的资源而多付费的情况。由此可见，将未使用内存释放给系统主内存是一项非常有用且亟需的功能。 ZGC 堆由一组称为 ZPages 的堆区域组成。在 GC 周期中清空 ZPages 区域时，它们将被释放并返回到页面缓存 ZPageCache 中，此缓存中的 ZPages 按最近最少使用（LRU）的顺序，并按照大小进行组织。在 Java 13 中，ZGC 将向操作系统返回被标识为长时间未使用的页面，这样它们将可以被其他进程重用。同时释放这些未使用的内存给操作系统不会导致堆大小缩小到参数设置的最小大小以下，如果将最小和最大堆大小设置为相同的值，则不会释放任何内存给操作系统。 Java 13 中对 ZGC 的改进，主要体现在下面几点： 释放未使用内存给操作系统 支持最大堆大小为 16TB 添加参数：-XX:SoftMaxHeapSize 来软限制堆大小 这里提到的是软限制堆大小，是指 GC 应努力是堆大小不要超过指定大小，但是如果实际需要，也还是允许 GC 将堆大小增加到超过 SoftMaxHeapSize 指定值。主要用在下面几种情况：当希望降低堆占用，同时保持应对堆空间临时增加的能力，亦或想保留充足内存空间，以能够应对内存分配，而不会因为内存分配意外增加而陷入分配停滞状态。不应将 SoftMaxHeapSize 设置为大于最大堆大小（-Xmx 的值，如果未在命令行上设置，则此标志应默认为最大堆大小。 Java 13 中，ZGC 内存释放功能，默认情况下是开启的，不过可以使用参数：-XX：-ZUncommit 显式关闭，同时如果将最小堆大小 (-Xms) 配置为等于最大堆大小 (-Xmx)，则将隐式禁用此功能。 还可以使用参数：-XX：ZUncommitDelay = &lt;seconds&gt;（默认值为 300 秒）来配置延迟释放，此延迟时间可以指定释放多长时间之前未使用的内存。 JDK14 - G1 的 NUMA 可识别内存分配Java 14 改进非一致性内存访问（NUMA）系统上的 G1 垃圾收集器的整体性能，主要是对年轻代的内存分配进行优化，从而提高 CPU 计算过程中内存访问速度。 NUMA 是 non-unified memory access 的缩写，主要是指在当前的多插槽物理计算机体系中，比较普遍是多核的处理器，并且越来越多的具有 NUMA 内存访问体系结构，即内存与每个插槽或内核之间的距离并不相等。同时套接字之间的内存访问具有不同的性能特征，对更远的套接字的访问通常具有更多的时间消耗。这样每个核对于每一块或者某一区域的内存访问速度会随着核和物理内存所在的位置的远近而有不同的时延差异。 Java 中，堆内存分配一般发生在线程运行的时候，当创建了一个新对象时，该线程会触发 G1 去分配一块内存出来，用来存放新创建的对象，在 G1 内存体系中，其实就是一块 region（大对象除外，大对象需要多个 region），在这个分配新内存的过程中，如果支持了 NUMA 感知内存分配，将会优先在与当前线程所绑定的 NUMA 节点空闲内存区域来执行 allocate 操作，同一线程创建的对象，尽可能的保留在年轻代的同一 NUMA 内存节点上，因为是基于同一个线程创建的对象大部分是短存活并且高概率互相调用的。 具体启用方式可以在 JVM 参数后面加上如下参数: 1-XX:+UseNUMA 通过这种方式来启用可识别的内存分配方式，能够提高一些大型计算机的 G1 内存分配回收性能。 JDK14 - 删除 CMS 垃圾回收器CMS 是老年代垃圾回收算法，通过标记-清除的方式进行内存回收，在内存回收过程中能够与用户线程并行执行。CMS 回收器可以与 Serial 回收器和 Parallel New 回收器搭配使用，CMS 主要通过并发的方式，适当减少系统的吞吐量以达到追求响应速度的目的，比较适合在追求 GC 速度的服务器上使用。 因为 CMS 回收算法在进行 GC 回收内存过程中是使用并行方式进行的，如果服务器 CPU 核数不多的情况下，进行 CMS 垃圾回收有可能造成比较高的负载。同时在 CMS 并行标记和并行清理时，应用线程还在继续运行，程序在运行过程中自然会创建新对象、释放不用对象，所以在这个过程中，会有新的不可达内存地址产生，而这部分的不可达内存是出现在标记过程结束之后，本轮 CMS 回收无法在周期内将它们回收掉，只能留在下次垃圾回收周期再清理掉。这样的垃圾就叫做浮动垃圾。由于垃圾收集和用户线程是并发执行的，因此 CMS 回收器不能像其他回收器那样进行内存回收，需要预留一些空间用来保存用户新创建的对象。由于 CMS 回收器在老年代中使用标记-清除的内存回收策略，势必会产生内存碎片，内存当碎片过多时，将会给大对象分配带来麻烦，往往会出现老年代还有空间但不能再保存对象的情况。 所以，早在几年前的 Java 9 中，就已经决定放弃使用 CMS 回收器了，而这次在 Java 14 中，是继之前 Java 9 中放弃使用 CMS 之后，彻底将其禁用，并删除与 CMS 有关的选项，同时清除与 CMS 有关的文档内容，至此曾经辉煌一度的 CMS 回收器，也将成为历史。 当在 Java 14 版本中，通过使用参数： -XX:+UseConcMarkSweepGC，尝试使用 CMS 时，将会收到下面信息： 12Java HotSpot(TM) 64-Bit Server VM warning: Ignoring option UseConcMarkSweepGC; \\support was removed in &lt;version&gt; JDK14 - 弃用 ParallelScavenge 和 SerialOld GC 的组合使用由于 Parallel Scavenge 和 Serial Old 垃圾收集算法组合起来使用的情况比较少，并且在年轻代中使用并行算法，而在老年代中使用串行算法，这种并行、串行混搭使用的情况，本身已属罕见同时也很冒险。由于这两 GC 算法组合很少使用，却要花费巨大工作量来进行维护，所以在 Java 14 版本中，考虑将这两 GC 的组合弃用。 具体弃用情况如下，通过弃用组合参数：-XX:+UseParallelGC -XX:-UseParallelOldGC，来弃用年轻代、老年期中并行、串行混搭使用的情况；同时，对于单独使用参数：-XX:-UseParallelOldGC 的地方，也将显示该参数已被弃用的警告信息。 JDK15 - 禁用偏向锁定 准备禁用和废除偏向锁，在 JDK 15 中，默认情况下禁用偏向锁，并弃用所有相关的命令行选项。 在默认情况下禁用偏向锁定，并弃用所有相关命令行选项。目标是确定是否需要继续支持偏置锁定的 高维护成本 的遗留同步优化， HotSpot虚拟机使用该优化来减少非竞争锁定的开销。 尽管某些Java应用程序在禁用偏向锁后可能会出现性能下降，但偏向锁的性能提高通常不像以前那么明显。 该特性默认禁用了biased locking(-XX:+UseBiasedLocking)，并且废弃了所有相关的命令行选型(BiasedLockingStartupDelay, BiasedLockingBulkRebiasThreshold, BiasedLockingBulkRevokeThreshold, BiasedLockingDecayTime, UseOptoBiasInlining, PrintBiasedLockingStatistics and PrintPreciseBiasedLockingStatistics) JDK15 - 低暂停时间垃圾收集器 Shenandoah垃圾回收算法终于从实验特性转变为产品特性，这是一个从 JDK 12 引入的回收算法，该算法通过与正在运行的 Java 线程同时进行疏散工作来减少 GC 暂停时间。Shenandoah 的暂停时间与堆大小无关，无论堆栈是 200 MB 还是 200 GB，都具有相同的一致暂停时间。 怎么形容Shenandoah和ZGC的关系呢？异同点大概如下： 相同点：性能几乎可认为是相同的 不同点：ZGC是Oracle JDK的。而Shenandoah只存在于OpenJDK中，因此使用时需注意你的JDK版本 打开方式：使用-XX:+UseShenandoahGC命令行参数打开。 Shenandoah在JDK12被作为experimental引入，在JDK15变为Production；之前需要通过-XX:+UnlockExperimentalVMOptions -XX:+UseShenandoahGC来启用，现在只需要-XX:+UseShenandoahGC即可启用 JDK16 - ZGC 并发线程处理JEP 376 将 ZGC 线程栈处理从安全点转移到一个并发阶段，甚至在大堆上也允许在毫秒内暂停 GC 安全点。消除 ZGC 垃圾收集器中最后一个延迟源可以极大地提高应用程序的性能和效率。 JDK16 - 弹性元空间此特性可将未使用的 HotSpot 类元数据（即元空间，metaspace）内存更快速地返回到操作系统，从而减少元空间的占用空间。具有大量类加载和卸载活动的应用程序可能会占用大量未使用的空间。新方案将元空间内存按较小的块分配，它将未使用的元空间内存返回给操作系统来提高弹性，从而提高应用程序性能并降低内存占用。 参考资料《Java 全栈知识体系》Java 12 - 17 特性概述等文章 https://openjdk.java.net/projects/jdk/17/jeps-since-jdk-11 https://docs.oracle.com/en/java/javase/17/language/local-variable-type-inference.html","tags":["Java","新特性","Java11"],"categories":["Java","新特性","Java11"]},{"title":"2.Java 8 升Java 11 重要特性必读","path":"/2023/12/27/2-Java-8-升Java-11-重要特性必读/","content":"Java 11 在 2018 年 9 月 25 日正式发布！根据发布的规划，JDK 11 是一个长期维护的版本（LTS); 本文帮助你梳理Java 8 升Java 11 重要特性。 升级JDK11概述 这里帮你梳理为何JDK 11会是一个极为重要的版本以及如何去理解它。 JDK 10后版本发布规则？Java 11 已于 2018 年 9 月 25 日正式发布，之前在 Java 10 新特性介绍 中介绍过，为了加快的版本迭代、跟进社区反馈，Java 的版本发布周期调整为每六个月一次——即每半年发布一个大版本，每个季度发布一个中间特性版本，并且做出不会跳票的承诺。通过这样的方式，Java 开发团队能够将一些重要特性尽早的合并到 Java Release 版本中，以便快速得到开发者的反馈，避免出现类似 Java 9 发布时的两次延期的情况。 按照官方介绍，新的版本发布周期将会严格按照时间节点，于每年的 3 月和 9 月发布，Java 11 发布的时间节点也正好处于 Java 8 免费更新到期的前夕。与 Java 9 和 Java 10 这两个被称为”功能性的版本”不同，Java 11 仅将提供长期支持服务（LTS, Long-Term-Support），还将作为 Java 平台的默认支持版本，并且会提供技术支持直至 2023 年 9 月，对应的补丁和安全警告等支持将持续至 2026 年。 JDK 8 升级到JDK 11 性能提升多少？从规划调度引擎 OptaPlanner 项目对 JDK 8和 JDK 11 的性能基准测试进行了对比来看： 如何更好的理解从JDK 8 到 JDK 11 升级中带来的重要特性？ 主要从如下三个方面理解，后续的章节主要围绕这三个方面进行： 语言新特性 新工具和库更新 JVM优化 语言新特性JDK9 - 允许在接口中使用私有方法在如下代码中，buildMessage 是接口 SayHi 中的私有方法，在默认方法 sayHi 中被使用。 123456789public interface SayHi &#123; private String buildMessage() &#123; return &quot;Hello&quot;; &#125; void sayHi(final String message); default void sayHi() &#123; sayHi(buildMessage()); &#125;&#125; JDK10 - 局部变量类型推断局部变量类型推断是 Java 10 中最值得开发人员注意的新特性，这是 Java 语言开发人员为了简化 Java 应用程序的编写而进行的又一重要改进。 这一新功能将为 Java 增加一些新语法，允许开发人员省略通常不必要的局部变量类型初始化声明。新的语法将减少 Java 代码的冗长度，同时保持对静态类型安全性的承诺。局部变量类型推断主要是向 Java 语法中引入在其他语言（比如 C#、JavaScript）中很常见的保留类型名称 var 。但需要特别注意的是： var 不是一个关键字，而是一个保留字。只要编译器可以推断此种类型，开发人员不再需要专门声明一个局部变量的类型，也就是可以随意定义变量而不必指定变量的类型。这种改进对于链式表达式来说，也会很方便。以下是一个简单的例子： 12var list = new ArrayList&lt;String&gt;(); // ArrayList&lt;String&gt;var stream = list.stream(); // Stream&lt;String&gt; 看着是不是有点 JS 的感觉？有没有感觉越来越像 JS 了？虽然变量类型的推断在 Java 中不是一个崭新的概念，但在局部变量中确是很大的一个改进。说到变量类型推断，从 Java 5 中引进泛型，到 Java 7 的 &lt;&gt; 操作符允许不绑定类型而初始化 List，再到 Java 8 中的 Lambda 表达式，再到现在 Java 10 中引入的局部变量类型推断，Java 类型推断正大刀阔斧地向前进步、发展。 而上面这段例子，在以前版本的 Java 语法中初始化列表的写法为： 12List&lt;String&gt; list = new ArrayList&lt;String&gt;();Stream&lt;String&gt; stream = getStream(); 在运算符允许在没有绑定 ArrayList &lt;&gt; 的类型的情况下初始化列表的写法为： 12List&lt;String&gt; list = new LinkedList&lt;&gt;();Stream&lt;String&gt; stream = getStream(); 但这种 var 变量类型推断的使用也有局限性，仅局限于具有初始化器的局部变量、增强型 for 循环中的索引变量以及在传统 for 循环中声明的局部变量，而不能用于推断方法的参数类型，不能用于构造函数参数类型推断，不能用于推断方法返回类型，也不能用于字段类型推断，同时还不能用于捕获表达式（或任何其他类型的变量声明）。 不过对于开发者而言，变量类型显式声明会提供更加全面的程序语言信息，对于理解和维护代码有很大的帮助。Java 10 中新引入的局部变量类型推断能够帮助我们快速编写更加简洁的代码，但是局部变量类型推断的保留字 var 的使用势必会引起变量类型可视化缺失，并不是任何时候使用 var 都能容易、清晰的分辨出变量的类型。一旦 var 被广泛运用，开发者在没有 IDE 的支持下阅读代码，势必会对理解程序的执行流程带来一定的困难。所以还是建议尽量显式定义变量类型，在保持代码简洁的同时，也需要兼顾程序的易读性、可维护性。 JDK11 - 用于 Lambda 参数的局部变量语法在 Lambda 表达式中使用局部变量类型推断是 Java 11 引入的唯一与语言相关的特性，这一节，我们将探索这一新特性。 从 Java 10 开始，便引入了局部变量类型推断这一关键特性。类型推断允许使用关键字 var 作为局部变量的类型而不是实际类型，编译器根据分配给变量的值推断出类型。这一改进简化了代码编写、节省了开发者的工作时间，因为不再需要显式声明局部变量的类型，而是可以使用关键字 var，且不会使源代码过于复杂。 可以使用关键字 var 声明局部变量，如下所示： 12var s = &quot;Hello Java 11&quot;;System.out.println(s); 但是在 Java 10 中，还有下面几个限制： 只能用于局部变量上 声明时必须初始化 不能用作方法参数 不能在 Lambda 表达式中使用 Java 11 与 Java 10 的不同之处在于允许开发者在 Lambda 表达式中使用 var 进行参数声明。乍一看，这一举措似乎有点多余，因为在写代码过程中可以省略 Lambda 参数的类型，并通过类型推断确定它们。但是，添加上类型定义同时使用 @Nonnull 和 @Nullable 等类型注释还是很有用的，既能保持与局部变量的一致写法，也不丢失代码简洁。 Lambda 表达式使用隐式类型定义，它形参的所有类型全部靠推断出来的。隐式类型 Lambda 表达式如下： 1(x, y) -&gt; x.process(y) Java 10 为局部变量提供隐式定义写法如下： 123var x = new Foo();for (var x : xs) &#123; ... &#125;try (var x = ...) &#123; ... &#125; catch ... 为了 Lambda 类型表达式中正式参数定义的语法与局部变量定义语法的不一致，且为了保持与其他局部变量用法上的一致性，希望能够使用关键字 var 隐式定义 Lambda 表达式的形参： 1(var x, var y) -&gt; x.process(y) 于是在 Java 11 中将局部变量和 Lambda 表达式的用法进行了统一，并且可以将注释应用于局部变量和 Lambda 表达式： 12@Nonnull var x = new Foo();(@Nonnull var x, @Nullable var y) -&gt; x.process(y) 新工具和库更新JDK9 - 集合、Stream 和 Optional更新方法在集合上，Java 9 增加 了 List.of()、Set.of()、Map.of() 和 Map.ofEntries()等工厂方法来创建不可变集合 ，如 如下 所示。 12345678List.of();List.of(&quot;Hello&quot;, &quot;World&quot;);List.of(1, 2, 3);Set.of();Set.of(&quot;Hello&quot;, &quot;World&quot;);Set.of(1, 2, 3);Map.of();Map.of(&quot;Hello&quot;, 1, &quot;World&quot;, 2); Stream 中增加了新的方法 ofNullable、dropWhile、takeWhile 和 iterate。在 如下代码 中，流中包含了从 1 到 5 的 元素。断言检查元素是否为奇数。第一个元素 1 被删除，结果流中包含 4 个元素。 1234567@Testpublic void testDropWhile() throws Exception &#123; final long count = Stream.of(1, 2, 3, 4, 5) .dropWhile(i -&gt; i % 2 != 0) .count(); assertEquals(4, count);&#125; Collectors 中增加了新的方法 filtering 和 flatMapping。在 如下代码 中，对于输入的 String 流 ，先通过 flatMapping 把 String 映射成 Integer 流 ，再把所有的 Integer 收集到一个集合中。 1234567@Testpublic void testFlatMapping() throws Exception &#123; final Set&lt;Integer&gt; result = Stream.of(&quot;a&quot;, &quot;ab&quot;, &quot;abc&quot;) .collect(Collectors.flatMapping(v -&gt; v.chars().boxed(), Collectors.toSet())); assertEquals(3, result.size());&#125; Optional 类中新增了 ifPresentOrElse、or 和 stream 等方法。在 如下代码 中，Optiona l 流中包含 3 个 元素，其中只有 2 个有值。在使用 flatMap 之后，结果流中包含了 2 个值。 12345678910@Testpublic void testStream() throws Exception &#123; final long count = Stream.of( Optional.of(1), Optional.empty(), Optional.of(2) ).flatMap(Optional::stream) .count(); assertEquals(2, count);&#125; JDK9 - 进程 API (Process Handle)Java 9 增加了 ProcessHandle 接口，可以对原生进程进行管理，尤其适合于管理长时间运行的进程。在使用 ProcessBuilder 来启动一个进程之后，可以通过 Process.toHandle()方法来得到一个 ProcessHandl e 对象的实例。通过 ProcessHandle 可以获取到由 ProcessHandle.Info 表 示的进程的基本信息，如命令行参数、可执行文件路径和启动时间等。ProcessHandle 的 onExit()方法返回一个 CompletableFuture对象，可以在进程结束时执行自定义的动作。 如下代码中给出了进程 API 的使用示例。 12345678910final ProcessBuilder processBuilder = new ProcessBuilder(&quot;top&quot;) .inheritIO();final ProcessHandle processHandle = processBuilder.start().toHandle();processHandle.onExit().whenCompleteAsync((handle, throwable) -&gt; &#123; if (throwable == null) &#123; System.out.println(handle.pid()); &#125; else &#123; throwable.printStackTrace(); &#125;&#125;); JDK9 - 变量句柄 (Var Handle)变量句柄是一个变量或一组变量的引用，包括静态域，非静态域，数组元素和堆外数据结构中的组成部分等。变量句柄的含义类似于已有的方法句柄。变量句柄由 Java 类 java.lang.invoke.VarHandle 来表示。可以使用类 java.lang.invoke.MethodHandles.Lookup 中的静态工厂方法来创建 VarHandle 对象。通过变量句柄，可以在变量上进行各种操作。这些操作称为访问模式。不同的访问模式尤其在内存排序上的不同语义。目前一共有 31 种 访问模式，而每种访问模式都 在 VarHandle 中 有对应的方法。这些方法可以对变量进行读取、写入、原子更新、数值原子更新和比特位原子操作等。VarHandle 还可以用来访问数组中的单个元素，以及把 byte[]数组 和 ByteBuffer 当成是不同原始类型的数组来访问。 在 如下代码 中，我们创建了访问 HandleTarget 类中的域 count 的变量句柄，并在其上进行读取操作。 123456789101112131415161718192021public class HandleTarget &#123; public int count = 1;&#125;public class VarHandleTest &#123; private HandleTarget handleTarget = new HandleTarget(); private VarHandle varHandle; @Before public void setUp() throws Exception &#123; this.handleTarget = new HandleTarget(); this.varHandle = MethodHandles .lookup() .findVarHandle(HandleTarget.class, &quot;count&quot;, int.class); &#125; @Test public void testGet() throws Exception &#123; assertEquals(1, this.varHandle.get(this.handleTarget)); assertEquals(1, this.varHandle.getVolatile(this.handleTarget)); assertEquals(1, this.varHandle.getOpaque(this.handleTarget)); assertEquals(1, this.varHandle.getAcquire(this.handleTarget)); &#125;&#125; JDK9 - I&#x2F;O 流新特性类 java.io.InputStream 中增加了新的方法来读取和复制 InputStream 中包含的数据。 readAllBytes：读取 InputStream 中的所有剩余字节。 readNBytes： 从 InputStream 中读取指定数量的字节到数组中。 transferTo：读取 InputStream 中的全部字节并写入到指定的 OutputStream 中 。 1234567891011121314151617181920212223242526public class TestInputStream &#123; private InputStream inputStream; private static final String CONTENT = &quot;Hello World&quot;; @Before public void setUp() throws Exception &#123; this.inputStream = TestInputStream.class.getResourceAsStream(&quot;/input.txt&quot;); &#125; @Test public void testReadAllBytes() throws Exception &#123; final String content = new String(this.inputStream.readAllBytes()); assertEquals(CONTENT, content); &#125; @Test public void testReadNBytes() throws Exception &#123; final byte[] data = new byte[5]; this.inputStream.readNBytes(data, 0, 5); assertEquals(&quot;Hello&quot;, new String(data)); &#125; @Test public void testTransferTo() throws Exception &#123; final ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); this.inputStream.transferTo(outputStream); assertEquals(CONTENT, outputStream.toString()); &#125;&#125; ObjectInputFilter 可以对 ObjectInputStream 中 包含的内容进行检查，来确保其中包含的数据是合法的。可以使用 ObjectInputStream 的方法 setObjectInputFilter 来设置。ObjectInputFilter 在 进行检查时，可以检查如对象图的最大深度、对象引用的最大数量、输入流中的最大字节数和数组的最大长度等限制，也可以对包含的类的名称进行限制。 JDK9 - 改进应用安全性能Java 9 新增了 4 个 SHA-3 哈希算法，SHA3-224、SHA3-256、SHA3-384 和 SHA3-512。另外也增加了通过 java.security.SecureRandom 生成使用 DRBG 算法的强随机数。如下代码中给出了 SHA-3 哈希算法的使用示例。 12345678import org.apache.commons.codec.binary.Hex;public class SHA3 &#123; public static void main(final String[] args) throws NoSuchAlgorithmException &#123; final MessageDigest instance = MessageDigest.getInstance(&quot;SHA3-224&quot;); final byte[] digest = instance.digest(&quot;&quot;.getBytes()); System.out.println(Hex.encodeHexString(digest)); &#125;&#125; JDK10 - 根证书认证自 Java 9 起在 keytool 中加入参数 -cacerts ，可以查看当前 JDK 管理的根证书。而 Java 9 中 cacerts 目录为空，这样就会给开发者带来很多不便。从 Java 10 开始，将会在 JDK 中提供一套默认的 CA 根证书。 作为 JDK 一部分的 cacerts 密钥库旨在包含一组能够用于在各种安全协议的证书链中建立信任的根证书。但是，JDK 源代码中的 cacerts 密钥库至目前为止一直是空的。因此，在 JDK 构建中，默认情况下，关键安全组件（如 TLS）是不起作用的。要解决此问题，用户必须使用一组根证书配置和 cacerts 密钥库下的 CA 根证书。 JDK11 - 标准 HTTP Client 升级Java 11 对 Java 9 中引入并在 Java 10 中进行了更新的 Http Client API 进行了标准化，在前两个版本中进行孵化的同时，Http Client 几乎被完全重写，并且现在完全支持异步非阻塞。 新版 Java 中，Http Client 的包名由 jdk.incubator.http 改为 java.net.http，该 API 通过 CompleteableFutures 提供非阻塞请求和响应语义，可以联合使用以触发相应的动作，并且 RX Flo w 的概念也在 Java 11 中得到了实现。现在，在用户层请求发布者和响应发布者与底层套接字之间追踪数据流更容易了。这降低了复杂性，并最大程度上提高了 HTTP&#x2F;1 和 HTTP&#x2F;2 之间的重用的可能性。 Java 11 中的新 Http Client API，提供了对 HTTP&#x2F;2 等业界前沿标准的支持，同时也向下兼容 HTTP&#x2F;1.1，精简而又友好的 API 接口，与主流开源 API（如：Apache HttpClient、Jetty、OkHttp 等）类似甚至拥有更高的性能。与此同时它是 Java 在 Reactive-Stream 方面的第一个生产实践，其中广泛使用了 Java Flow API，终于让 Java 标准 HTTP 类库在扩展能力等方面，满足了现代互联网的需求，是一个难得的现代 Http&#x2F;2 Client API 标准的实现，Java 工程师终于可以摆脱老旧的 HttpURLConnection 了。下面模拟 Http GET 请求并打印返回内容： 12345678HttpClient client = HttpClient.newHttpClient();HttpRequest request = HttpRequest.newBuilder() .uri(URI.create(&quot;http://openjdk.java.net/&quot;)) .build();client.sendAsync(request, BodyHandlers.ofString()) .thenApply(HttpResponse::body) .thenAccept(System.out::println) .join(); JDK11 - 简化启动单个源代码文件的方法Java 11 版本中最令人兴奋的功能之一是增强 Java 启动器，使之能够运行单一文件的 Java 源代码。此功能允许使用 Java 解释器直接执行 Java 源代码。源代码在内存中编译，然后由解释器执行。唯一的约束在于所有相关的类必须定义在同一个 Java 文件中。 此功能对于开始学习 Java 并希望尝试简单程序的人特别有用，并且能与 jshell 一起使用，将成为任何初学者学习语言的一个很好的工具集。不仅初学者会受益，专业人员还可以利用这些工具来探索新的语言更改或尝试未知的 API。 如今单文件程序在编写小实用程序时很常见，特别是脚本语言领域。从中开发者可以省去用 Java 编译程序等不必要工作，以及减少新手的入门障碍。在基于 Java 10 的程序实现中可以通过三种方式启动： 作为 * .class 文件 作为 * .jar 文件中的主类 作为模块中的主类 而在最新的 Java 11 中新增了一个启动方式，即可以在源代码中声明类，例如：如果名为 HelloWorld.java 的文件包含一个名为 hello.World 的类，那么该命令： 1$ java HelloWorld.java 也等同于： 12$ javac HelloWorld.java$ java -cp . hello.World JDK11 - 支持 TLS 1.3 协议Java 11 中包含了传输层安全性（TLS）1.3 规范（RFC 8446）的实现，替换了之前版本中包含的 TLS，包括 TLS 1.2，同时还改进了其他 TLS 功能，例如 OCSP 装订扩展（RFC 6066，RFC 6961），以及会话散列和扩展主密钥扩展（RFC 7627），在安全性和性能方面也做了很多提升。 新版本中包含了 Java 安全套接字扩展（JSSE）提供 SSL，TLS 和 DTLS 协议的框架和 Java 实现。目前，JSSE API 和 JDK 实现支持 SSL 3.0，TLS 1.0，TLS 1.1，TLS 1.2，DTLS 1.0 和 DTLS 1.2。 同时 Java 11 版本中实现的 TLS 1.3，重新定义了以下新标准算法名称： TLS 协议版本名称：TLSv1.3 SSLContext 算法名称：TLSv1.3 TLS 1.3 的 TLS 密码套件名称：TLS_AES_128_GCM_SHA256，TLS_AES_256_GCM_SHA384 用于 X509KeyManager 的 keyType：RSASSA-PSS 用于 X509TrustManager 的 authType：RSASSA-PSS 还为 TLS 1.3 添加了一个新的安全属性 jdk.tls.keyLimits。当处理了特定算法的指定数据量时，触发握手后，密钥和 IV 更新以导出新密钥。还添加了一个新的系统属性 jdk.tls.server.protocols，用于在 SunJSSE 提供程序的服务器端配置默认启用的协议套件。 之前版本中使用的 KRB5 密码套件实现已从 Java 11 中删除，因为该算法已不再安全。同时注意，TLS 1.3 与以前的版本不直接兼容。 升级到 TLS 1.3 之前，需要考虑如下几个兼容性问题： TLS 1.3 使用半关闭策略，而 TLS 1.2 以及之前版本使用双工关闭策略，对于依赖于双工关闭策略的应用程序，升级到 TLS 1.3 时可能存在兼容性问题。 TLS 1.3 使用预定义的签名算法进行证书身份验证，但实际场景中应用程序可能会使用不被支持的签名算法。 TLS 1.3 再支持 DSA 签名算法，如果在服务器端配置为仅使用 DSA 证书，则无法升级到 TLS 1.3。 TLS 1.3 支持的加密套件与 TLS 1.2 和早期版本不同，若应用程序硬编码了加密算法单元，则在升级的过程中需要修改相应代码才能升级使用 TLS 1.3。 TLS 1.3 版本的 session 用行为及秘钥更新行为与 1.2 及之前的版本不同，若应用依赖于 TLS 协议的握手过程细节，则需要注意。 JVM优化JDK9 - 统一 JVM 日志Java 9 中 ，JVM 有了统一的日志记录系统，可以使用新的命令行选项-Xlog 来控制 JVM 上 所有组件的日志记录。该日志记录系统可以设置输出的日志消息的标签、级别、修饰符和输出目标等。Java 9 移除了在 Java 8 中 被废弃的垃圾回收器配置组合，同时 把 G1 设为默认的垃圾回收器实现。另外，CMS 垃圾回收器已经被声明为废弃。Java 9 也增加了很多可以通过 jcmd 调用的诊断命令。 JDK10 - 统一 GC 接口在当前的 Java 结构中，组成垃圾回收器（GC）实现的组件分散在代码库的各个部分。尽管这些惯例对于使用 GC 计划的 JDK 开发者来说比较熟悉，但对新的开发人员来说，对于在哪里查找特定 GC 的源代码，或者实现一个新的垃圾收集器常常会感到困惑。更重要的是，随着 Java modules 的出现，我们希望在构建过程中排除不需要的 GC，但是当前 GC 接口的横向结构会给排除、定位问题带来困难。 为解决此问题，需要整合并清理 GC 接口，以便更容易地实现新的 GC，并更好地维护现有的 GC。Java 10 中，hotspot&#x2F;gc 代码实现方面，引入一个干净的 GC 接口，改进不同 GC 源代码的隔离性，多个 GC 之间共享的实现细节代码应该存在于辅助类中。这种方式提供了足够的灵活性来实现全新 GC 接口，同时允许以混合搭配方式重复使用现有代码，并且能够保持代码更加干净、整洁，便于排查收集器问题。 JDK10 - 并行全垃圾回收器 G1大家如果接触过 Java 性能调优工作，应该会知道，调优的最终目标是通过参数设置来达到快速、低延时的内存垃圾回收以提高应用吞吐量，尽可能的避免因内存回收不及时而触发的完整 GC（Full GC 会带来应用出现卡顿）。 G1 垃圾回收器是 Java 9 中 Hotspot 的默认垃圾回收器，是以一种低延时的垃圾回收器来设计的，旨在避免进行 Full GC，但是当并发收集无法快速回收内存时，会触发垃圾回收器回退进行 Full GC。之前 Java 版本中的 G1 垃圾回收器执行 GC 时采用的是基于单线程标记扫描压缩算法（mark-sweep-compact）。为了最大限度地减少 Full GC 造成的应用停顿的影响，Java 10 中将为 G1 引入多线程并行 GC，同时会使用与年轻代回收和混合回收相同的并行工作线程数量，从而减少了 Full GC 的发生，以带来更好的性能提升、更大的吞吐量。 Java 10 中将采用并行化 mark-sweep-compact 算法，并使用与年轻代回收和混合回收相同数量的线程。具体并行 GC 线程数量可以通过： -XX：ParallelGCThreads 参数来调节，但这也会影响用于年轻代和混合收集的工作线程数。 JDK11 - Epsilon：低开销垃圾回收器Epsilon 垃圾回收器的目标是开发一个控制内存分配，但是不执行任何实际的垃圾回收工作。它提供一个完全消极的 GC 实现，分配有限的内存资源，最大限度的降低内存占用和内存吞吐延迟时间。 Java 版本中已经包含了一系列的高度可配置化的 GC 实现。各种不同的垃圾回收器可以面对各种情况。但是有些时候使用一种独特的实现，而不是将其堆积在其他 GC 实现上将会是事情变得更加简单。 下面是 no-op GC 的几个使用场景： 性能测试：什么都不执行的 GC 非常适合用于 GC 的差异性分析。no-op （无操作）GC 可以用于过滤掉 GC 诱发的性能损耗，比如 GC 线程的调度，GC 屏障的消耗，GC 周期的不合适触发，内存位置变化等。此外有些延迟者不是由于 GC 引起的，比如 scheduling hiccups, compiler transition hiccups，所以去除 GC 引发的延迟有助于统计这些延迟。 内存压力测试：在测试 Java 代码时，确定分配内存的阈值有助于设置内存压力常量值。这时 no-op 就很有用，它可以简单地接受一个分配的内存分配上限，当内存超限时就失败。例如：测试需要分配小于 1G 的内存，就使用-Xmx1g 参数来配置 no-op GC，然后当内存耗尽的时候就直接 crash。 VM 接口测试：以 VM 开发视角，有一个简单的 GC 实现，有助于理解 VM-GC 的最小接口实现。它也用于证明 VM-GC 接口的健全性。 极度短暂 job 任务：一个短声明周期的 job 任务可能会依赖快速退出来释放资源，这个时候接收 GC 周期来清理 heap 其实是在浪费时间，因为 heap 会在退出时清理。并且 GC 周期可能会占用一会时间，因为它依赖 heap 上的数据量。 延迟改进：对那些极端延迟敏感的应用，开发者十分清楚内存占用，或者是几乎没有垃圾回收的应用，此时耗时较长的 GC 周期将会是一件坏事。 吞吐改进：即便对那些无需内存分配的工作，选择一个 GC 意味着选择了一系列的 GC 屏障，所有的 OpenJDK GC 都是分代的，所以他们至少会有一个写屏障。避免这些屏障可以带来一点点的吞吐量提升。 Epsilon 垃圾回收器和其他 OpenJDK 的垃圾回收器一样，可以通过参数 -XX:+UseEpsilonGC 开启。 Epsilon 线性分配单个连续内存块。可复用现存 VM 代码中的 TLAB 部分的分配功能。非 TLAB 分配也是同一段代码，因为在此方案中，分配 TLAB 和分配大对象只有一点点的不同。Epsilon 用到的 barrier 是空的(或者说是无操作的)。因为该 GC 执行任何的 GC 周期，不用关系对象图，对象标记，对象复制等。引进一种新的 barrier-set 实现可能是该 GC 对 JVM 最大的变化。 JDK11 - 低开销的 Heap ProfilingJava 11 中提供一种低开销的 Java 堆分配采样方法，能够得到堆分配的 Java 对象信息，并且能够通过 JVMTI 访问堆信息。 引入这个低开销内存分析工具是为了达到如下目的： 足够低的开销，可以默认且一直开启 能通过定义好的程序接口访问 能够对所有堆分配区域进行采样 能给出正在和未被使用的 Java 对象信息 对用户来说，了解它们堆里的内存分布是非常重要的，特别是遇到生产环境中出现的高 CPU、高内存占用率的情况。目前有一些已经开源的工具，允许用户分析应用程序中的堆使用情况，比如：Java Flight Recorder、jmap、YourKit 以及 VisualVM tools.。但是这些工具都有一个明显的不足之处：无法得到对象的分配位置，headp dump 以及 heap histogram 中都没有包含对象分配的具体信息，但是这些信息对于调试内存问题至关重要，因为它能够告诉开发人员他们的代码中发生的高内存分配的确切位置，并根据实际源码来分析具体问题，这也是 Java 11 中引入这种低开销堆分配采样方法的原因。 JDK11 - 可伸缩低延迟垃圾收集器(ZGC)ZGC 即 Z Garbage Collector（垃圾收集器或垃圾回收器），这应该是 Java 11 中最为瞩目的特性，没有之一。ZGC 是一个可伸缩的、低延迟的垃圾收集器，主要为了满足如下目标进行设计： GC 停顿时间不超过 10ms 即能处理几百 MB 的小堆，也能处理几个 TB 的大堆 应用吞吐能力不会下降超过 15%（与 G1 回收算法相比） 方便在此基础上引入新的 GC 特性和利用 colord 针以及 Load barriers 优化奠定基础 当前只支持 Linux&#x2F;x64 位平台 停顿时间在 10ms 以下，10ms 其实是一个很保守的数据，即便是 10ms 这个数据，也是 GC 调优几乎达不到的极值。根据 SPECjbb 2015 的基准测试，128G 的大堆下最大停顿时间才 1.68ms，远低于 10ms，和 G1 算法相比，改进非常明显。 本图片引用自： The Z Garbage Collector – An Introduction 不过目前 ZGC 还处于实验阶段，目前只在 Linux&#x2F;x64 上可用，如果有足够的需求，将来可能会增加对其他平台的支持。同时作为实验性功能的 ZGC 将不会出现在 JDK 构建中，除非在编译时使用 configure 参数： --with-jvm-features=zgc 显式启用。 在实验阶段，编译完成之后，已经迫不及待的想试试 ZGC，需要配置以下 JVM 参数，才能使用 ZGC，具体启动 ZGC 参数如下： 1-XX：+ UnlockExperimentalVMOptions -XX：+ UseZGC -Xmx10g 其中参数： -Xmx 是 ZGC 收集器中最重要的调优选项，大大解决了程序员在 JVM 参数调优上的困扰。ZGC 是一个并发收集器，必须要设置一个最大堆的大小，应用需要多大的堆，主要有下面几个考量： 对象的分配速率，要保证在 GC 的时候，堆中有足够的内存分配新对象。 一般来说，给 ZGC 的内存越多越好，但是也不能浪费内存，所以要找到一个平衡。 参考资料https://www.optaplanner.org/blog/2019/01/17/HowMuchFasterIsJava11.html https://docs.oracle.com/en/java/javase/17/language/local-variable-type-inference.html","tags":["Java","新特性","Java11"],"categories":["Java","新特性","Java11"]},{"title":"1.Java8+特性知识体系详解","path":"/2023/12/27/1-Java8-特性知识体系详解/","content":"本系列主要介绍Java8以上所有版本特性知识体系详解。 重点知识 Java现在发布的版本很快，每年两个，但是真正会被大规模使用的是三年一个的TLS版本。@pdai 每3年发布一个TLS，长期维护版本。意味着Java 8 ，Java 11， Java 17 才可能被大规模使用。 每年发布两个正式版本，分别是3月份和9月份。 版本详解Java 8 升Java 11 Java 11 在 2018 年 9 月 25 日正式发布！根据发布的规划，JDK 11 是一个长期维护的版本（LTS); 本文帮助你梳理Java 8 升Java 11 重要特性。 Java 8 升Java 11 重要特性必读 Java 11 升Java 17 JDK 17 在 2021 年 9 月 14 号正式发布了！根据发布的规划，这次发布的 JDK 17 是一个长期维护的版本（LTS)。SpingFramework 6 和SpringBoot 3中默认将使用JDK 17，所以JDK 17必将是使用较广泛的版本; 而从上个LTS版本JDK11到JDK17有哪些重要特性需要掌握呢？本文帮助你梳理Java 11 升Java 17 重要特性。 Java 11 升Java 17 重要特性必读 Java 9 新特性详解 Java 9 正式发布于 2017 年 9 月 21 日。作为 Java8 之后 3 年半才发布的新版本，Java 9 带来了很多重大的变化。其中最重要的改动是 Java 平台模块系统的引入。除此之外，还有一些新的特性。本文对 Java9 中包含的新特性做了概括性的介绍，可以帮助你快速了解 Java 9。 知识体系系统性梳理 相关文章 Java 9 新特性概述 Java 平台 模块系统 Jshell 集合、Stream 和 Optional 进程 API 平台日志 API 和 服务 反应式流 （ Reactive Streams ） 变量句柄 并发 Nashorn I&#x2F;O 流新特性 改进应用安全性能 用户界面 统一 JVM 日志 其他改动方面 结束语 参考文章 Java 10 新特性概述 作为当今使用最广泛的编程语言之一的 Java 在 2018 年 3 月 21 日发布了第十个大版本。为了更快地迭代、更好地跟进社区反馈，Java 语言版本发布周期调整为每隔 6 个月发布一次。Java 10 是这一新规则之后，采用新发布周期的第一个大版本。Java 10 版本带来了很多新特性，其中最备受广大开发者关注的莫过于局部变量类型推断。除此之外，还有其他包括垃圾收集器改善、GC 改进、性能提升、线程管控等一批新特性。本文主要针对 Java 10 中的新特性展开介绍，希望读者能从本文的介绍中快速了解 Java 10 带来的变化。 知识体系系统性梳理 相关文章 Java 10 新特性概述 局部变量类型推断 整合 JDK 代码仓库 统一的垃圾回收接口 并行全垃圾回收器 G1 应用程序类数据共享 线程-局部管控 移除 Native-Header 自动生成工具 额外的 Unicode 语言标签扩展 备用存储装置上的堆分配 基于 Java 的 实验性 JIT 编译器 根证书认证 基于时间的版本发布模式 结束语 参考文章 Java 11 新特性概述 Java 11 已于 2018 年 9 月 25 日正式发布，之前在 Java 10 新特性介绍 中介绍过，为了加快的版本迭代、跟进社区反馈，Java 的版本发布周期调整为每六个月一次——即每半年发布一个大版本，每个季度发布一个中间特性版本，并且做出不会跳票的承诺。通过这样的方式，Java 开发团队能够将一些重要特性尽早的合并到 Java Release 版本中，以便快速得到开发者的反馈，避免出现类似 Java 9 发布时的两次延期的情况。 知识体系系统性梳理 相关文章 Java 11 新特性概述 基于嵌套的访问控制 标准 HTTP Client 升级 Epsilon：低开销垃圾回收器 简化启动单个源代码文件的方法 用于 Lambda 参数的局部变量语法 低开销的 Heap Profiling 支持 TLS 1.3 协议 ZGC：可伸缩低延迟垃圾收集器 飞行记录器 动态类文件常量 结束语 参考文章 Java 12 新特性概述 JDK12 在 2019 年 3 月 19 号正式发布，不同于JDK11，JDK12并不是一个LTS版本。作为一个中间版本，JDK12版本特性增加较少。 2017年宣布的加速发布节奏要求每六个月发布一次功能，每季度更新一次，每三年发布一次长期支持（LTS）更新版本（或每六个版本一次） 知识体系系统性梳理 相关文章 Java 12 新特性概述 新功能和库的更新 JEP334: JVM常量API JEP341: 默认CDS归档 JEP230: Microbenchmark测试套件 新的平台支持 JEP340: 移除多余ARM64实现 JVM 优化 JPE 344: G1的可中断 mixed GC JEP 346: G1归还不使用的内存 新功能的预览和实验 JEP 189: Shenandoah：低暂停时间垃圾收集器（实验） JEP 325: Switch 表达式 (预览版本) Java 13 新特性概述 Java 13 已如期于 9 月 17 日正式发布，此次更新是继半年前 Java 12 这大版本发布之后的一次常规版本更新，在这一版中，主要带来了 ZGC 增强、更新 Socket 实现、Switch 表达式更新等方面的改动、增强。本文主要针对 Java 13 中主要的新特性展开介绍，带你快速了解 Java 13 带来的不同体验。 知识体系系统性梳理 相关文章 Java 13 新特性概述 新功能和库的更新 JEP350: 动态应用程序类-数据共享 JEP353: Socket API 重构 JVM 优化 JEP351: 增强 ZGC 释放未使用内存 新功能预览 JEP354: Switch 表达式扩展（预览功能） JEP355: 文本块（预览功能） Java 14 新特性概述 Java 14 已如期于 2020 年 3 月 17 日正式发布，此次更新是继半年前 Java 13 这大版本发布之后的又一次常规版本更新，即便在全球疫情如此严峻形势下，依然保持每六个月的版本更新频率，为大家及时带来改进和增强，这一点值得点赞。在这一版中，主要带来了 ZGC 增强、instanceof 增强、Switch 表达式更新为标准版等方面的改动、增强和新功能。本文主要介绍 Java 14 中的主要新特性，带您快速了解 Java 14 带来了哪些不一样的体验和便利。 知识体系系统性梳理 相关文章 Java 14 新特性概述 语言特性增强 JEP 359: Switch 表达式（正式版） 新功能和库的更新 JEP 358: 改进 NullPointerExceptions 提示信息 旧功能的删除和弃用 JEP 367: 删除 pack200 和 unpack200 工具 JVM 相关 JEP 345: G1 的 NUMA 可识别内存分配 JEP 363: 删除 CMS 垃圾回收器 JEP 364&amp;365: ZGC 支持 MacOS 和 Windows 系统（实验阶段） JEP 366: 弃用 ParallelScavenge 和 SerialOld GC 的组合使用 新功能的预览和实验 JEP 305: instanceof 模式匹配（预览阶段） JEP 359: Record 类型（预览功能） JEP 368: 文本块（第二预览版本） JEP 343: 打包工具（孵化器版本） JEP 370: 外部存储器访问 API（孵化器版） Java 15 新特性概述 JDK 15 在 2020 年 9 月 15 号正式发布了！根据发布的规划，这次发布的 JDK 15 将是一个短期的过度版，只会被 Oracle 支持（维护）6 个月，直到明年 3 月的 JDK 16 发布此版本将停止维护。而 Oracle 下一个长期支持版（LTS 版）会在明年的 9 月份候发布（Java 17），LTS 版每 3 年发布一个，上一次长期支持版是 18 年 9 月发布的 JDK 11。 知识体系系统性梳理 相关文章 Java 15 新特性概述 语言特性增强 JEP 378: 文本块(Text Blocks) 新功能和库的更新 JEP 339: Edwards-Curve 数字签名算法 (EdDSA) JEP 371: 隐藏类 Hidden Classes JEP 373: 重新实现 DatagramSocket API JVM 优化 JEP 373: ZGC: 可伸缩低延迟垃圾收集器 JEP 374: 禁用偏向锁定 JEP 379: Shenandoah：低暂停时间垃圾收集器(转正) 旧功能的删除和弃用 JEP 372: 移除Nashorn JavaScript引擎 JEP 381: 移除了 Solaris 和 SPARC 端口。 JEP 385: 废除 RMI 激活 新功能的预览和孵化 JEP 375: instanceof 自动匹配模式（第二次预览） JEP 360: 密封的类和接口（预览） JEP 383: 外部存储器访问 API（二次孵化器版） JEP 384: Records (二次预览) Java 16 新特性概述 JDK 16 在 2021 年 3 月 16 号发布！根据发布的规划，这次发布的 JDK 17 是一个长期维护的版本（LTS)。Java 16 提供了数千个性能、稳定性和安全性更新，以及 17 个 JEP（JDK 增强提案），进一步改进了 Java 语言和平台，以帮助开发人员提高工作效率。 知识体系系统性梳理 相关文章 Java 16 新特性概述 语言特性增强 JEP 394: instanceof 模式匹配（正式版） JEP 395: Records (正式版) 新工具和库 JEP 380：Unix-Domain 套接字通道 JEP 390: 对基于值的类发出警告 JEP 392：打包工具（正式版） JEP 396：默认强封装 JDK 内部元素 JVM 优化 JEP 376：ZGC 并发线程处理 JEP 387：弹性元空间 新功能的预览和孵化 JEP 338：向量 API（孵化器） JEP 389：外部链接器 API（孵化器） JEP 393：外部存储器访问 API（第三次孵化） JEP 397：密封类（第二预览） 提升 OpenJDK 开发人员的生产力 JEP 347：启用 C++14 语言特性（在 JDK 源代码中） JEP 357：从 Mercurial 迁移到 Git &amp; JEP 369，迁移到 GitHub JEP 386：AlpineLinux 移植 &amp; JEP 388：Windows&#x2F;AArch64 移植 Java 17 新特性概述 JDK 17 在 2021 年 9 月 14 号正式发布了！根据发布的规划，这次发布的 JDK 17 是一个长期维护的版本（LTS)。Java 17 提供了数千个性能、稳定性和安全性更新，以及 14 个 JEP（JDK 增强提案），进一步改进了 Java 语言和平台，以帮助开发人员提高工作效率。JDK 17 包括新的语言增强、库更新、对新 Apple (Mx CPU)计算机的支持、旧功能的删除和弃用，并努力确保今天编写的 Java 代码在未来的 JDK 版本中继续工作而不会发生变化。它还提供语言功能预览和孵化 API，以收集 Java 社区的反馈。@pdai 知识体系系统性梳理 相关文章 Java 17 新特性概述 语言特性增强 密封的类和接口（正式版） 工具库的更新 JEP 306：恢复始终严格的浮点语义 JEP 356：增强的伪随机数生成器 JDK 17之前如何生成随机数？ 为什么需要增强？ 增强后是什么样的？ JEP 382：新的macOS渲染管道 新的平台支持 JEP 391：支持macOS AArch64 旧功能的删除和弃用 JEP 398：弃用 Applet API JEP 407：删除 RMI 激活 JEP 410：删除实验性 AOT 和 JIT 编译器 JEP 411：弃用安全管理器以进行删除 新功能的预览和孵化API JEP 406：新增switch模式匹配（预览版） JEP 412：外部函数和内存api （第一轮孵化） JEP 414：Vector API（第二轮孵化） JEP 393：外部存储器访问 API（第三次孵化） Java 18 新特性概述Java 18 新特性概述 Java 19 新特性概述Java 19 新特性概述 Java 20 新特性概述Java 20 新特性概述 Java 21 新特性概述Java 21 新特性概述","tags":["Java","新特性","Java8 plus"],"categories":["Java","新特性","Java8 plus"]},{"title":"13.Java 8 - 其它更新: 字符串，base64,...","path":"/2023/12/26/13-Java-8-其它更新-字符串，base64/","content":"本文对Java 8 其它更新介绍和解读。 处理数值Java8添加了对无符号数的额外支持。Java中的数值总是有符号的，例如，让我们来观察Integer: int可表示最多2 ** 32个数。Java中的数值默认为有符号的，所以最后一个二进制数字表示符号(0为正数，1为负数)。所以从十进制的0开始，最大的有符号正整数为2 ** 31 - 1。 你可以通过Integer.MAX_VALUE来访问它: 12System.out.println(Integer.MAX_VALUE); // 2147483647System.out.println(Integer.MAX_VALUE + 1); // -2147483648 Java8添加了解析无符号整数的支持，让我们看看它如何工作: 1234long maxUnsignedInt = (1l &lt;&lt; 32) - 1;String string = String.valueOf(maxUnsignedInt);int unsignedInt = Integer.parseUnsignedInt(string, 10);String string2 = Integer.toUnsignedString(unsignedInt, 10); 就像你看到的那样，现在可以将最大的无符号数2 ** 32 - 1解析为整数。而且你也可以将这个数值转换回无符号数的字符串表示。 这在之前不可能使用parseInt完成，就像这个例子展示的那样: 123456try &#123; Integer.parseInt(string, 10);&#125;catch (NumberFormatException e) &#123; System.err.println(&quot;could not parse signed int of &quot; + maxUnsignedInt);&#125; 这个数值不可解析为有符号整数，因为它超出了最大范围2 ** 31 - 1。 算术运算 Math工具类新增了一些方法来处理数值溢出。这是什么意思呢? 我们已经看到了所有数值类型都有最大值。所以当算术运算的结果不能被它的大小装下时，会发生什么呢? 12System.out.println(Integer.MAX_VALUE); // 2147483647System.out.println(Integer.MAX_VALUE + 1); // -2147483648 就像你看到的那样，发生了整数溢出，这通常是我们不愿意看到的。 Java8添加了严格数学运算的支持来解决这个问题。Math扩展了一些方法，它们全部以exact结尾，例如addExact。当运算结果不能被数值类型装下时，这些方法通过抛出ArithmeticException异常来合理地处理溢出。 1234567try &#123; Math.addExact(Integer.MAX_VALUE, 1);&#125;catch (ArithmeticException e) &#123; System.err.println(e.getMessage()); // =&gt; integer overflow&#125; 当尝试通过toIntExact将长整数转换为整数时，可能会抛出同样的异常: 1234567try &#123; Math.toIntExact(Long.MAX_VALUE);&#125;catch (ArithmeticException e) &#123; System.err.println(e.getMessage()); // =&gt; integer overflow&#125; 处理文件Files工具类首次在Java7中引入，作为NIO的一部分。JDK8 API添加了一些额外的方法，它们可以将文件用于函数式数据流。让我们深入探索一些代码示例。 列出文件 Files.list方法将指定目录的所有路径转换为数据流，便于我们在文件系统的内容上使用类似filter和sorted的流操作。 12345678try (Stream&lt;Path&gt; stream = Files.list(Paths.get(&quot;&quot;))) &#123; String joined = stream .map(String::valueOf) .filter(path -&gt; !path.startsWith(&quot;.&quot;)) .sorted() .collect(Collectors.joining(&quot;; &quot;)); System.out.println(&quot;List: &quot; + joined);&#125; 上面的例子列出了当前工作目录的所有文件，之后将每个路径都映射为它的字符串表示。之后结果被过滤、排序，最后连接为一个字符串。如果你还不熟悉函数式数据流，你应该阅读我的Java8数据流教程。 你可能已经注意到，数据流的创建包装在try-with语句中。数据流实现了AutoCloseable，并且这里我们需要显式关闭数据流，因为它基于IO操作。 返回的数据流是DirectoryStream的封装。如果需要及时处理文件资源，就应该使用try-with结构来确保在流式操作完成后，数据流的close方法被调用。 查找文件下面的例子演示了如何查找在目录及其子目录下的文件: 12345678910Path start = Paths.get(&quot;&quot;);int maxDepth = 5;try (Stream&lt;Path&gt; stream = Files.find(start, maxDepth, (path, attr) -&gt; String.valueOf(path).endsWith(&quot;.js&quot;))) &#123; String joined = stream .sorted() .map(String::valueOf) .collect(Collectors.joining(&quot;; &quot;)); System.out.println(&quot;Found: &quot; + joined);&#125; find方法接受三个参数: 目录路径start是起始点，maxDepth定义了最大搜索深度。第三个参数是一个匹配谓词，定义了搜索的逻辑。上面的例子中，我们搜索了所有JavaScirpt文件(以.js结尾的文件名)。 我们可以使用Files.walk方法来完成相同的行为。这个方法会遍历每个文件，而不需要传递搜索谓词。 12345678910Path start = Paths.get(&quot;&quot;);int maxDepth = 5;try (Stream&lt;Path&gt; stream = Files.walk(start, maxDepth)) &#123; String joined = stream .map(String::valueOf) .filter(path -&gt; path.endsWith(&quot;.js&quot;)) .sorted() .collect(Collectors.joining(&quot;; &quot;)); System.out.println(&quot;walk(): &quot; + joined);&#125; 这个例子中，我们使用了流式操作filter来完成和上个例子相同的行为。 读写文件将文本文件读到内存，以及向文本文件写入字符串在Java 8 中是简单的任务。不需要再去摆弄读写器了。Files.readAllLines从指定的文件把所有行读进字符串列表中。你可以简单地修改这个列表，并且将它通过Files.write写到另一个文件中: 123List&lt;String&gt; lines = Files.readAllLines(Paths.get(&quot;res/nashorn1.js&quot;));lines.add(&quot;print(&#x27;foobar&#x27;);&quot;);Files.write(Paths.get(&quot;res/nashorn1-modified.js&quot;), lines); 要注意这些方法对内存并不十分高效，因为整个文件都会读进内存。文件越大，所用的堆区也就越大。 你可以使用Files.lines方法来作为内存高效的替代。这个方法读取每一行，并使用函数式数据流来对其流式处理，而不是一次性把所有行都读进内存。 123456try (Stream&lt;String&gt; stream = Files.lines(Paths.get(&quot;res/nashorn1.js&quot;))) &#123; stream .filter(line -&gt; line.contains(&quot;print&quot;)) .map(String::trim) .forEach(System.out::println);&#125; 如果你需要更多的精细控制，你需要构造一个新的BufferedReader来代替: 1234Path path = Paths.get(&quot;res/nashorn1.js&quot;);try (BufferedReader reader = Files.newBufferedReader(path)) &#123; System.out.println(reader.readLine());&#125; 或者，你需要写入文件时，简单地构造一个BufferedWriter来代替: 1234Path path = Paths.get(&quot;res/output.js&quot;);try (BufferedWriter writer = Files.newBufferedWriter(path)) &#123; writer.write(&quot;print(&#x27;Hello World&#x27;);&quot;);&#125; BufferedReader也可以访问函数式数据流。lines方法在它所有行上面构建数据流: 12345678Path path = Paths.get(&quot;res/nashorn1.js&quot;);try (BufferedReader reader = Files.newBufferedReader(path)) &#123; long countPrints = reader .lines() .filter(line -&gt; line.contains(&quot;print&quot;)) .count(); System.out.println(countPrints);&#125; 目前为止你可以看到Java8提供了三个简单的方法来读取文本文件的每一行，使文件处理更加便捷。 不幸的是你需要显式使用try-with语句来关闭文件流，这会使示例代码有些凌乱。我期待函数式数据流可以在调用类似count和collect时可以自动关闭，因为你不能在相同数据流上调用终止操作两次。 java.util.Random在Java8中java.util.Random类的一个非常明显的变化就是新增了返回随机数流(random Stream of numbers)的一些方法。 下面的代码是创建一个无穷尽的double类型的数字流，这些数字在0(包括0)和1(不包含1)之间。 12Random random = new Random();DoubleStream doubleStream = random.doubles(); 下面的代码是创建一个无穷尽的int类型的数字流，这些数字在0(包括0)和100(不包括100)之间。 12Random random = new Random();IntStream intStream = random.ints(0, 100); 那么这些无穷尽的数字流用来做什么呢? 接下来，我通过一些案例来分析。记住，这些无穷大的数字流只能通过某种方式被截断(limited)。 示例1: 创建10个随机的整数流并打印出来: 1intStream.limit(10).forEach(System.out::println); 示例2: 创建100个随机整数: 1234List&lt;Integer&gt; randomBetween0And99 = intStream .limit(100) .boxed() .collect(Collectors.toList()); 对于高斯伪随机数(gaussian pseudo-random values)来说，random.doubles()方法所创建的流不能等价于高斯伪随机数，然而，如果用java8所提供的功能是非常容易实现的。 12Random random = new Random();DoubleStream gaussianStream = Stream.generate(random::nextGaussian).mapToDouble(e -&gt; e); 这里，我使用了Stream.generate api，并传入Supplier 类的对象作为参数，这个对象是通过调用Random类中的方法 nextGaussian()创建另一个高斯伪随机数。 接下来，我们来对double类型的伪随机数流和double类型的高斯伪随机数流做一个更加有意思的事情，那就是获得两个流的随机数的分配情况。预期的结果是: double类型的伪随机数是均匀的分配的，而double类型的高斯伪随机数应该是正态分布的。 通过下面的代码，我生成了一百万个伪随机数，这是通过java8提供的api实现的: 12345678Random random = new Random();DoubleStream doubleStream = random.doubles(-1.0, 1.0);LinkedHashMap&lt;Range, Integer&gt; rangeCountMap = doubleStream.limit(1000000) .boxed() .map(Ranges::of) .collect(Ranges::emptyRangeCountMap, (m, e) -&gt; m.put(e, m.get(e) + 1), Ranges::mergeRangeCountMaps);rangeCountMap.forEach((k, v) -&gt; System.out.println(k.from() + &quot;\\t&quot; + v)); 代码的运行结果如下: 1234567891011121314151617181920-1 49730-0.9 49931-0.8 50057-0.7 50060-0.6 49963-0.5 50159-0.4 49921-0.3 49962-0.2 50231-0.1 496580 501770.1 498610.2 499470.3 501570.4 504140.5 500060.6 500380.7 499620.8 500710.9 49695 为了类比，我们再生成一百万个高斯伪随机数: 1234567891011Random random = new Random();DoubleStream gaussianStream = Stream.generate(random::nextGaussian).mapToDouble(e -&gt; e);LinkedHashMap&lt;Range, Integer&gt; gaussianRangeCountMap = gaussianStream .filter(e -&gt; (e &gt;= -1.0 &amp;&amp; e &lt; 1.0)) .limit(1000000) .boxed() .map(Ranges::of) .collect(Ranges::emptyRangeCountMap, (m, e) -&gt; m.put(e, m.get(e) + 1), Ranges::mergeRangeCountMaps);gaussianRangeCountMap.forEach((k, v) -&gt; System.out.println(k.from() + &quot;\\t&quot; + v)); 上面代码输出的结果恰恰与我们预期结果相吻合，即: double类型的伪随机数是均匀的分配的，而double类型的高斯伪随机数应该是正态分布的。 附: 完整代码可点击这里获取 https://gist.github.com/bijukunjummen/8129250 译文链接: http://www.importnew.com/9672.html java.util.Base64 Java8中java.util.Base64性能比较高，推荐使用。请参考: 性能对比: https://wizardforcel.gitbooks.io/java8-new-features/content/11.html 源代码: http://git.oschina.net/benhail/javase8-sample 该类提供了一套静态方法获取下面三种BASE64编解码器: 1)Basic编码: 是标准的BASE64编码，用于处理常规的需求 123456// 编码String asB64 = Base64.getEncoder().encodeToString(&quot;some string&quot;.getBytes(&quot;utf-8&quot;));System.out.println(asB64); // 输出为: c29tZSBzdHJpbmc=// 解码byte[] asBytes = Base64.getDecoder().decode(&quot;c29tZSBzdHJpbmc=&quot;);System.out.println(new String(asBytes, &quot;utf-8&quot;)); // 输出为: some string 2)URL编码: 使用下划线替换URL里面的反斜线“&#x2F;” 1234String urlEncoded = Base64.getUrlEncoder().encodeToString(&quot;subjects?abcd&quot;.getBytes(&quot;utf-8&quot;));System.out.println(&quot;Using URL Alphabet: &quot; + urlEncoded);// 输出为:Using URL Alphabet: c3ViamVjdHM_YWJjZA== 3)MIME编码: 使用基本的字母数字产生BASE64输出，而且对MIME格式友好: 每一行输出不超过76个字符，而且每行以“\\r ”符结束。 1234567StringBuilder sb = new StringBuilder();for (int t = 0; t &lt; 10; ++t) &#123; sb.append(UUID.randomUUID().toString());&#125;byte[] toEncode = sb.toString().getBytes(&quot;utf-8&quot;);String mimeEncoded = Base64.getMimeEncoder().encodeToString(toEncode);System.out.println(mimeEncoded); 参考 https://wizardforcel.gitbooks.io/modern-java/ch7.html http://www.importnew.com/9672.html","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"12.Java 8 - JavaFx 2.0","path":"/2023/12/26/12-Java-8-JavaFx-2-0/","content":"JavaFX主要致力于富客户端开发，以弥补swing的缺陷，主要提供图形库与media库，支持audio,video,graphics,animation,3D等，同时采用现代化的css方式支持界面设计。同时又采用XUI方式以XML方式设计UI界面，达到显示与逻辑的分离。与android这方面确实有点相似性。 JavaFX历史跟java在服务器端和web端成绩相比，桌面一直是java的软肋，于是Sun公司在2008年推出JavaFX，弥补桌面软件的缺陷，请看下图JavaFX一路走过来的改进 从上图看出，一开始推出时候，开发者需使用一种名为JavaFX Script的静态的、声明式的编程语言来开发JavaFX应用程序。因为JavaFX Script将会被编译为Java bytecode，程序员可以使用Java代码代替。 JavaFX 2.0之后的版本摒弃了JavaFX Script语言，而作为一个Java API来使用。因此使用JavaFX平台实现的应用程序将直接通过标准Java代码来实现。 JavaFX 2.0 包含非常丰富的 UI 控件、图形和多媒体特性用于简化可视化应用的开发，WebView可直接在应用中嵌入网页；另外 2.0 版本允许使用 FXML 进行 UI 定义，这是一个脚本化基于 XML 的标识语言。 从JDK 7u6开始，JavaFx就与JDK捆绑在一起了，JavaFX团队称，下一个版本将是8.0，目前所有的工作都已经围绕8.0库进行。这是因为JavaFX将捆绑在Java 8中，因此该团队决定跳过几个版本号，迎头赶上Java 8。 JavaFx8的新特性全新现代主题: Modena新的Modena主题来替换原来的Caspian主题。不过在Application的start()方法中，可以通过setUserAgentStylesheet(STYLESHEET_CASPIAN)来继续使用Caspian主题。 参考http://fxexperience.com/2013/03/modena-theme-update/ JavaFX 3D在JavaFX8中提供了3D图像处理API，包括Shape3D (Box, Cylinder, MeshView, Sphere子类),SubScene, Material, PickResult, LightBase (AmbientLight 和PointLight子类),SceneAntialiasing等。Camera类也得到了更新。从JavaDoc中可以找到更多信息。 富文本强化了富文本的支持 TreeTableView日期控件DatePicker增加日期控件 用于 CSS 结构的公共 API1234CSS 样式设置是 JavaFX 的一项主要特性CSS 已专门在私有 API 中实现(com.sun.javafx.css 软件包)多种工具(例如 Scene Builder)需要 CSS 公共 API开发人员将能够定义自定义 CSS 样式 WebView 增强功能 Nashorn JavaScript 引擎 https://blogs.oracle.com/nashorn/entry/open_for_business WebSocket http://javafx-jira.kenai.com/browse/RT-14947 Web Workers http://javafx-jira.kenai.com/browse/RT-9782 JavaFX Scene Builder 2.0可视化工具，加速JavaFX图形界面的开发，下载地址 JavaFX Scene Builder如同NetBeans一般，通过拖拽的方式配置界面，待完成界面之後，保存为FXML格式文件，此文件以XML描述物件配置，再交由JavaFX程式处理，因此可減少直接以JavaFX编写界面的困難度。 JavaFX Scene Builder 2.0新增JavaFX Theme预览功能，菜单「Preview」→「JavaFX Theme」选择不同的主題，包括: 12345678Modena (FX8).Modena Touch (FX8).Modena High Contrast – Black on White (FX8).Modena High Contrast – White on Black (FX8).Modena High Contrast – Yellow on Black (FX8).Caspian (FX2).Caspian Embedded (FX2).Caspian Embedded QVGA (FX2). JavaFX 8开发2048游戏2048虽然不像前段时间那么火了，但个人还是非常喜欢玩2048，空闲时间都忍不住来一发，感谢 Gabriele Cirulli 发明了这了不起 (并且会上瘾)的2048游戏，因为是用MIT协议开源出来，各种语言版本的2048游戏横空出世，下图是用JavaFX 8来开发的一款2048。 所用到的技术 123456789101112Lambda expressionsStream APIJavaFX 8JavaFX CSS basicsJavaFX animationsfx2048相关类的说明Game2048,游戏主类GameManager,包含游戏界面布局(Board)以及Grid的操作(GridOperator)Board,包含labels ，分数，grid ，TileTile,游戏中的数字块GridOperator,Grid操作类Location,Direction 位置帮助类RecordManager，SessionManager，纪录游戏分数，会话类 这里是源码地址，大家感兴趣的可以去学习下git.oschina.net&#x2F;benhail&#x2F;javase8-sample&#x2F;tree&#x2F;master&#x2F;src&#x2F;main&#x2F;java&#x2F;javase8sample&#x2F;chapter13&#x2F;javafx8&#x2F;fx2048 总结比起AWT和SWING，JavaFX的优势很明显，各大主流IDE已经支持JavaFX的开发了，最佳的工具莫过于NetBeans，且随着lambda带来的好处，JavaFX的事件处理简洁了不少，以前需要写匿名函数类。另外JavaFX开源以来，JavaFX的生态环境也越来越活跃了，包括各种教程，嵌入式尝试，还有一些开源项目，比如: ControlsFX，JRebirth，DataFX Flow，mvvmFX，TestFX 等等。还有JavaFX是可以运行在Android和ios上面，这个很赞！ 好了，总结到这里也差不多了，在RIA平台上面，有HTML5、Flex和微软的Sliverlight，JavaFX能否表现优秀，在于大家的各位，只要我们多用JavaFX，那么JavaFX也会越来越优秀，任何语言都是这样, THE END . 参考 https://github.com/oimchat/oim-fx https://github.com/goxr3plus/FX-BorderlessScene https://github.com/topics/material-ui https://github.com/in-sideFX/Undecorator https://github.com/brunoborges/webfx https://blog.csdn.net/loongshawn/article/details/52805751 https://docs.oracle.com/javafx/2/ui_controls/overview.htm#BABJACHC https://www.oracle.com/technetwork/cn/articles/java/layoutfx-1536156-zhs.html","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"11.Java 8 - LocalDate/LocalDateTime","path":"/2023/12/26/11-Java-8-LocalDate-LocalDateTime/","content":"理解时间和日期库需要理解如下问题: Java8之前的Date有哪些槽点? Java8之前使用哪些常用的第三方时间库? Java8关于时间和日期有哪些类和方法，变比Java8之前它的特点是什么? 其它语言时间库? Java8之前的Date有哪些槽点 Tiago Fernandez做过一次投票，选举最烂的JAVA API，排第一的EJB2.X，第二的就是日期API。 槽点一最开始的时候，Date既要承载日期信息，又要做日期之间的转换，还要做不同日期格式的显示，职责较繁杂(不懂单一职责，你妈妈知道吗? 纯属恶搞~哈哈) 后来从JDK 1.1 开始，这三项职责分开了: 123使用Calendar类实现日期和时间字段之间转换；使用DateFormat类来格式化和分析日期字符串；而Date只用来承载日期和时间信息。 原有Date中的相应方法已废弃。不过，无论是Date，还是Calendar，都用着太不方便了，这是API没有设计好的地方。 槽点二坑爹的year和month 123Date date = new Date(2012,1,1);System.out.println(date);输出Thu Feb 01 00:00:00 CST 3912 观察输出结果，year是2012+1900，而month，月份参数我不是给了1吗? 怎么输出二月(Feb)了? 应该曾有人告诉你，如果你要设置日期，应该使用 java.util.Calendar，像这样… 12Calendar calendar = Calendar.getInstance();calendar.set(2013, 8, 2); 这样写又不对了，calendar的month也是从0开始的，表达8月份应该用7这个数字，要么就干脆用枚举 1calendar.set(2013, Calendar.AUGUST, 2); 注意上面的代码，Calendar年份的传值不需要减去1900(当然月份的定义和Date还是一样)，这种不一致真是让人抓狂！ 有些人可能知道，Calendar相关的API是IBM捐出去的，所以才导致不一致。 槽点三java.util.Date与java.util.Calendar中的所有属性都是可变的 下面的代码，计算两个日期之间的天数…. 12345678910111213141516public static void main(String[] args) &#123; Calendar birth = Calendar.getInstance(); birth.set(1975, Calendar.MAY, 26); Calendar now = Calendar.getInstance(); System.out.println(daysBetween(birth, now)); System.out.println(daysBetween(birth, now)); // 显示 0? &#125; public static long daysBetween(Calendar begin, Calendar end) &#123; long daysBetween = 0; while(begin.before(end)) &#123; begin.add(Calendar.DAY_OF_MONTH, 1); daysBetween++; &#125; return daysBetween;&#125; daysBetween有点问题，如果连续计算两个Date实例的话，第二次会取得0，因为Calendar状态是可变的，考虑到重复计算的场合，最好复制一个新的Calendar 123456789public static long daysBetween(Calendar begin, Calendar end) &#123; Calendar calendar = (Calendar) begin.clone(); // 复制 long daysBetween = 0; while(calendar.before(end)) &#123; calendar.add(Calendar.DAY_OF_MONTH, 1); daysBetween++; &#125; return daysBetween;&#125; 槽点四SimpleDateTimeFormat是非线程安全的。 Java8时间和日期类概览Java 8仍然延用了ISO的日历体系，并且与它的前辈们不同，java.time包中的类是不可变且线程安全的。新的时间及日期API位于java.time包中，下面是里面的一些关键的类: Instant——它代表的是时间戳 LocalDate——不包含具体时间的日期，比如2014-01-14。它可以用来存储生日，周年纪念日，入职日期等。 LocalTime——它代表的是不含日期的时间 LocalDateTime——它包含了日期及时间，不过还是没有偏移信息或者说时区。 ZonedDateTime——这是一个包含时区的完整的日期时间，偏移量是以UTC&#x2F;格林威治时间为基准的。 新的库还增加了ZoneOffset及Zoned，可以为时区提供更好的支持。有了新的DateTimeFormatter之后日期的解析及格式化也变得焕然一新了。 方法概览该包的API提供了大量相关的方法，这些方法一般有一致的方法前缀: of: 静态工厂方法。 parse: 静态工厂方法，关注于解析。 get: 获取某些东西的值。 is: 检查某些东西的是否是true。 with: 不可变的setter等价物。 plus: 加一些量到某个对象。 minus: 从某个对象减去一些量。 to: 转换到另一个类型。 at: 把这个对象与另一个对象组合起来，例如: date.atTime(time)。 一些例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147public class TimeIntroduction &#123; public static void testClock() throws InterruptedException &#123; //时钟提供给我们用于访问某个特定 时区的 瞬时时间、日期 和 时间的。 Clock c1 = Clock.systemUTC(); //系统默认UTC时钟(当前瞬时时间 System.currentTimeMillis()) System.out.println(c1.millis()); //每次调用将返回当前瞬时时间(UTC) Clock c2 = Clock.systemDefaultZone(); //系统默认时区时钟(当前瞬时时间) Clock c31 = Clock.system(ZoneId.of(&quot;Europe/Paris&quot;)); //巴黎时区 System.out.println(c31.millis()); //每次调用将返回当前瞬时时间(UTC) Clock c32 = Clock.system(ZoneId.of(&quot;Asia/Shanghai&quot;));//上海时区 System.out.println(c32.millis());//每次调用将返回当前瞬时时间(UTC) Clock c4 = Clock.fixed(Instant.now(), ZoneId.of(&quot;Asia/Shanghai&quot;));//固定上海时区时钟 System.out.println(c4.millis()); Thread.sleep(1000); System.out.println(c4.millis()); //不变 即时钟时钟在那一个点不动 Clock c5 = Clock.offset(c1, Duration.ofSeconds(2)); //相对于系统默认时钟两秒的时钟 System.out.println(c1.millis()); System.out.println(c5.millis()); &#125; public static void testInstant() &#123; //瞬时时间 相当于以前的System.currentTimeMillis() Instant instant1 = Instant.now(); System.out.println(instant1.getEpochSecond());//精确到秒 得到相对于1970-01-01 00:00:00 UTC的一个时间 System.out.println(instant1.toEpochMilli()); //精确到毫秒 Clock clock1 = Clock.systemUTC(); //获取系统UTC默认时钟 Instant instant2 = Instant.now(clock1);//得到时钟的瞬时时间 System.out.println(instant2.toEpochMilli()); Clock clock2 = Clock.fixed(instant1, ZoneId.systemDefault()); //固定瞬时时间时钟 Instant instant3 = Instant.now(clock2);//得到时钟的瞬时时间 System.out.println(instant3.toEpochMilli());//equals instant1 &#125; public static void testLocalDateTime() &#123; //使用默认时区时钟瞬时时间创建 Clock.systemDefaultZone() --&gt;即相对于 ZoneId.systemDefault()默认时区 LocalDateTime now = LocalDateTime.now(); System.out.println(now); //自定义时区 LocalDateTime now2 = LocalDateTime.now(ZoneId.of(&quot;Europe/Paris&quot;)); System.out.println(now2);//会以相应的时区显示日期 //自定义时钟 Clock clock = Clock.system(ZoneId.of(&quot;Asia/Dhaka&quot;)); LocalDateTime now3 = LocalDateTime.now(clock); System.out.println(now3);//会以相应的时区显示日期 //不需要写什么相对时间 如java.util.Date 年是相对于1900 月是从0开始 //2013-12-31 23:59 LocalDateTime d1 = LocalDateTime.of(2013, 12, 31, 23, 59); //年月日 时分秒 纳秒 LocalDateTime d2 = LocalDateTime.of(2013, 12, 31, 23, 59, 59, 11); //使用瞬时时间 + 时区 Instant instant = Instant.now(); LocalDateTime d3 = LocalDateTime.ofInstant(Instant.now(), ZoneId.systemDefault()); System.out.println(d3); //解析String---&gt;LocalDateTime LocalDateTime d4 = LocalDateTime.parse(&quot;2013-12-31T23:59&quot;); System.out.println(d4); LocalDateTime d5 = LocalDateTime.parse(&quot;2013-12-31T23:59:59.999&quot;);//999毫秒 等价于999000000纳秒 System.out.println(d5); //使用DateTimeFormatter API 解析 和 格式化 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy/MM/dd HH:mm:ss&quot;); LocalDateTime d6 = LocalDateTime.parse(&quot;2013/12/31 23:59:59&quot;, formatter); System.out.println(formatter.format(d6)); //时间获取 System.out.println(d6.getYear()); System.out.println(d6.getMonth()); System.out.println(d6.getDayOfYear()); System.out.println(d6.getDayOfMonth()); System.out.println(d6.getDayOfWeek()); System.out.println(d6.getHour()); System.out.println(d6.getMinute()); System.out.println(d6.getSecond()); System.out.println(d6.getNano()); //时间增减 LocalDateTime d7 = d6.minusDays(1); LocalDateTime d8 = d7.plus(1, IsoFields.QUARTER_YEARS); //LocalDate 即年月日 无时分秒 //LocalTime即时分秒 无年月日 //API和LocalDateTime类似就不演示了 // 两个日期是否相等 System.out.println(d1.equals(d2)); // MonthDay - 用来检查生日 LocalDate dateOfBirth = LocalDate.of(2010, 01, 14); MonthDay birthday = MonthDay.of(dateOfBirth.getMonth(), dateOfBirth.getDayOfMonth()); MonthDay currentMonthDay = MonthDay.from(today); System.out.println(currentMonthDay.equals(birthday)); // YearMonth - 用来检查信用卡过期 YearMonth currentYearMonth = YearMonth.now(); System.out.printf(&quot;Days in month year %s: %d%n&quot;, currentYearMonth, currentYearMonth.lengthOfMonth()); YearMonth creditCardExpiry = YearMonth.of(2018, Month.FEBRUARY); System.out.printf(&quot;Your credit card expires on %s %n&quot;, creditCardExpiry); // 判断闰年 - LocalDate类有一个isLeapYear()的方法 System.out.println(dateOfBirth.isLeapYear()); &#125; public static void testZonedDateTime() &#123; //即带有时区的date-time 存储纳秒、时区和时差(避免与本地date-time歧义)。 //API和LocalDateTime类似，只是多了时差(如2013-12-20T10:35:50.711+08:00[Asia/Shanghai]) ZonedDateTime now = ZonedDateTime.now(); System.out.println(now); ZonedDateTime now2 = ZonedDateTime.now(ZoneId.of(&quot;Europe/Paris&quot;)); System.out.println(now2); //其他的用法也是类似的 就不介绍了 ZonedDateTime z1 = ZonedDateTime.parse(&quot;2013-12-31T23:59:59Z[Europe/Paris]&quot;); System.out.println(z1); &#125; public static void testDuration() &#123; //表示两个瞬时时间的时间段 Duration d1 = Duration.between(Instant.ofEpochMilli(System.currentTimeMillis() - 12323123), Instant.now()); //得到相应的时差 System.out.println(d1.toDays()); System.out.println(d1.toHours()); System.out.println(d1.toMinutes()); System.out.println(d1.toMillis()); System.out.println(d1.toNanos()); //1天时差 类似的还有如ofHours() Duration d2 = Duration.ofDays(1); System.out.println(d2.toDays()); &#125; public static void testChronology() &#123; //提供对java.util.Calendar的替换，提供对年历系统的支持 Chronology c = HijrahChronology.INSTANCE; ChronoLocalDateTime d = c.localDateTime(LocalDateTime.now()); System.out.println(d); &#125; /** * 新旧日期转换 */ public static void testNewOldDateConversion()&#123; Instant instant=new Date().toInstant(); Date date=Date.from(instant); System.out.println(instant); System.out.println(date); &#125; public static void main(String[] args) throws InterruptedException &#123; testClock(); testInstant(); testLocalDateTime(); testZonedDateTime(); testDuration(); testChronology(); testNewOldDateConversion(); &#125;&#125; 其它语言时间日期与时间处理API，在各种语言中，可能都只是个不起眼的API，如果你没有较复杂的时间处理需求，可能只是利用日期与时间处理API取得系统时间，简单做些显示罢了，然而如果认真看待日期与时间，其复杂程度可能会远超过你的想象，天文、地理、历史、政治、文化等因素，都会影响到你对时间的处理。所以在处理时间上，最好选用JSR310(如果你用java8的话就实现310了)，或者Joda-Time。 不止是java面临时间处理的尴尬，其他语言同样也遇到过类似的问题，比如 Arrow: Python 中更好的日期与时间处理库 Moment.js: JavaScript 中的日期库 Noda-Time: .NET 阵营的 Joda-Time 的复制 总结看完了这些例子后，我相信你已经对Java 8这套新的时间日期API有了一定的了解了。现在我们来回顾下关于这个新的API的一些关键的要素。 它提供了javax.time.ZoneId用来处理时区。 它提供了LocalDate与LocalTime类 Java 8中新的时间与日期API中的所有类都是不可变且线程安全的，这与之前的Date与Calendar API中的恰好相反，那里面像java.util.Date以及SimpleDateFormat这些关键的类都不是线程安全的。 新的时间与日期API中很重要的一点是它定义清楚了基本的时间与日期的概念，比方说，瞬时时间，持续时间，日期，时间，时区以及时间段。它们都是基于ISO日历体系的。 每个Java开发人员都应该至少了解这套新的API中的这五个类: Instant 它代表的是时间戳，比如2014-01-14T02:20:13.592Z，这可以从java.time.Clock类中获取，像这样: Instant current &#x3D; Clock.system(ZoneId.of(“Asia&#x2F;Tokyo”)).instant(); LocalDate 它表示的是不带时间的日期，比如2014-01-14。它可以用来存储生日，周年纪念日，入职日期等。 LocalTime – 它表示的是不带日期的时间 LocalDateTime – 它包含了时间与日期，不过没有带时区的偏移量 ZonedDateTime – 这是一个带时区的完整时间，它根据UTC&#x2F;格林威治时间来进行时区调整 这个库的主包是java.time，里面包含了代表日期，时间，瞬时以及持续时间的类。它有两个子package，一个是java.time.foramt，这个是什么用途就很明显了，还有一个是java.time.temporal，它能从更低层面对各个字段进行访问。 时区指的是地球上共享同一标准时间的地区。每个时区都有一个唯一标识符，同时还有一个地区&#x2F;城市(Asia&#x2F;Tokyo)的格式以及从格林威治时间开始的一个偏移时间。比如说，东京的偏移时间就是+09:00。 OffsetDateTime类实际上包含了LocalDateTime与ZoneOffset。它用来表示一个包含格林威治时间偏移量(+&#x2F;-小时: 分，比如+06:00或者 -08: 00)的完整的日期(年月日)及时间(时分秒，纳秒)。 DateTimeFormatter类用于在Java中进行日期的格式化与解析。与SimpleDateFormat不同，它是不可变且线程安全的，如果需要的话，可以赋值给一个静态变量。DateTimeFormatter类提供了许多预定义的格式器，你也可以自定义自己想要的格式。当然了，根据约定，它还有一个parse()方法是用于将字符串转换成日期的，如果转换期间出现任何错误，它会抛出DateTimeParseException异常。类似的，DateFormatter类也有一个用于格式化日期的format()方法，它出错的话则会抛出DateTimeException异常。 再说一句，“MMM d yyyy”与“MMm dd yyyy”这两个日期格式也略有不同，前者能识别出”Jan 2 2014″与”Jan 14 2014″这两个串，而后者如果传进来的是”Jan 2 2014″则会报错，因为它期望月份处传进来的是两个字符。为了解决这个问题，在天为个位数的情况下，你得在前面补0，比如”Jan 2 2014″应该改为”Jan 02 2014″。","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"9.Java 8 - 移除Permgen","path":"/2023/12/26/9-Java-8-移除Permgen/","content":"本文主要介绍PermGen space，及Java 8 - 移除Permgen。 很多开发者都在其系统中见过“java.lang.OutOfMemoryError: PermGen space”这一问题。这往往是由类加载器相关的内存泄漏以及新类加载器的创建导致的，通常出现于代码热部署时。相对于正式产品，该问题在开发机上出现的频率更高，在产品中最常见的“问题”是默认值太低了。常用的解决方法是将其设置为256MB或更高。 PermGen space简单介绍PermGen space的全称是Permanent Generation space,是指内存的永久保存区域，说说为什么会内存益出: 这一部分用于存放Class和Meta的信息,Class在被 Load的时候被放入PermGen space区域，它和和存放Instance的Heap区域不同,所以如果你的APP会LOAD很多CLASS的话,就很可能出现PermGen space错误。这种错误常见在web服务器对JSP进行pre compile的时候。 JVM 种类有很多，比如 Oralce-Sun Hotspot, Oralce JRockit, IBM J9, Taobao JVM(淘宝好样的！)等等。当然武林盟主是Hotspot了，这个毫无争议。需要注意的是，PermGen space是Oracle-Sun Hotspot才有，JRockit以及J9是没有这个区域。 元空间(MetaSpace)一种新的内存空间诞生JDK8 HotSpot JVM 将移除永久区，使用本地内存来存储类元数据信息并称之为: 元空间(Metaspace)；这与Oracle JRockit 和IBM JVM’s很相似，如下图所示 这意味着不会再有java.lang.OutOfMemoryError: PermGen问题，也不再需要你进行调优及监控内存空间的使用……但请等等，这么说还为时过早。在默认情况下，这些改变是透明的，接下来我们的展示将使你知道仍然要关注类元数据内存的占用。请一定要牢记，这个新特性也不能神奇地消除类和类加载器导致的内存泄漏。 java8中metaspace总结如下: PermGen 空间的状况 这部分内存空间将全部移除。 JVM的参数: PermSize 和 MaxPermSize 会被忽略并给出警告(如果在启用时设置了这两个参数)。 Metaspace 内存分配模型 大部分类元数据都在本地内存中分配。 用于描述类元数据的“klasses”已经被移除。 Metaspace 容量 默认情况下，类元数据只受可用的本地内存限制(容量取决于是32位或是64位操作系统的可用虚拟内存大小)。 新参数(MaxMetaspaceSize)用于限制本地内存分配给类元数据的大小。如果没有指定这个参数，元空间会在运行时根据需要动态调整。 Metaspace 垃圾回收 对于僵死的类及类加载器的垃圾回收将在元数据使用达到“MaxMetaspaceSize”参数的设定值时进行。 适时地监控和调整元空间对于减小垃圾回收频率和减少延时是很有必要的。持续的元空间垃圾回收说明，可能存在类、类加载器导致的内存泄漏或是大小设置不合适。 Java 堆内存的影响 一些杂项数据已经移到Java堆空间中。升级到JDK8之后，会发现Java堆 空间有所增长。 Metaspace 监控 元空间的使用情况可以从HotSpot1.8的详细GC日志输出中得到。 Jstat 和 JVisualVM两个工具，在使用b75版本进行测试时，已经更新了，但是还是能看到老的PermGen空间的出现。 前面已经从理论上充分说明，下面让我们通过“泄漏”程序进行新内存空间的观察…… PermGen vs. Metaspace 运行时比较为了更好地理解Metaspace内存空间的运行时行为， 将进行以下几种场景的测试: 使用JDK1.7运行Java程序，监控并耗尽默认设定的85MB大小的PermGen内存空间。 使用JDK1.8运行Java程序，监控新Metaspace内存空间的动态增长和垃圾回收过程。 使用JDK1.8运行Java程序，模拟耗尽通过“MaxMetaspaceSize”参数设定的128MB大小的Metaspace内存空间。 首先建立了一个模拟PermGen OOM的代码 12345public class ClassA &#123; public void method(String name) &#123; // do nothing &#125;&#125; 上面是一个简单的ClassA，把他编译成class字节码放到D: &#x2F;classes下面，测试代码中用URLClassLoader来加载此类型上面类编译成class 1234567891011121314151617181920212223242526272829/** * 模拟PermGen OOM * @author benhail */public class OOMTest &#123; public static void main(String[] args) &#123; try &#123; //准备url URL url = new File(&quot;D:/classes&quot;).toURI().toURL(); URL[] urls = &#123;url&#125;; //获取有关类型加载的JMX接口 ClassLoadingMXBean loadingBean = ManagementFactory.getClassLoadingMXBean(); //用于缓存类加载器 List&lt;ClassLoader&gt; classLoaders = new ArrayList&lt;ClassLoader&gt;(); while (true) &#123; //加载类型并缓存类加载器实例 ClassLoader classLoader = new URLClassLoader(urls); classLoaders.add(classLoader); classLoader.loadClass(&quot;ClassA&quot;); //显示数量信息(共加载过的类型数目，当前还有效的类型数目，已经被卸载的类型数目) System.out.println(&quot;total: &quot; + loadingBean.getTotalLoadedClassCount()); System.out.println(&quot;active: &quot; + loadingBean.getLoadedClassCount()); System.out.println(&quot;unloaded: &quot; + loadingBean.getUnloadedClassCount()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 虚拟机器参数设置如下: -verbose -verbose:gc 设置-verbose参数是为了获取类型加载和卸载的信息 设置-verbose:gc是为了获取垃圾收集的相关信息 JDK 1.7 @64-bit – PermGen 耗尽测试Java1.7的PermGen默认空间为85 MB(或者可以通过-XX:MaxPermSize&#x3D;XXXm指定) 可以从上面的JVisualVM的截图看出: 当加载超过6万个类之后，PermGen被耗尽。我们也能通过程序和GC的输出观察耗尽的过程。 程序输出(摘取了部分) 123456789101112......[Loaded ClassA from file:/D:/classes/]total: 64887active: 64887unloaded: 0[GC 245041K-&gt;213978K(536768K), 0.0597188 secs][Full GC 213978K-&gt;211425K(644992K), 0.6456638 secs][GC 211425K-&gt;211425K(656448K), 0.0086696 secs][Full GC 211425K-&gt;211411K(731008K), 0.6924754 secs][GC 211411K-&gt;211411K(726528K), 0.0088992 secs]...............java.lang.OutOfMemoryError: PermGen space JDK 1.8 @64-bit – Metaspace大小动态调整测试Java的Metaspace空间: 不受限制 (默认) 从上面的截图可以看到，JVM Metaspace进行了动态扩展，本地内存的使用由20MB增长到646MB，以满足程序中不断增长的类数据内存占用需求。我们也能观察到JVM的垃圾回收事件—试图销毁僵死的类或类加载器对象。但是，由于我们程序的泄漏，JVM别无选择只能动态扩展Metaspace内存空间。程序加载超过10万个类，而没有出现OOM事件。 JDK 1.8 @64-bit – Metaspace 受限测试Java的Metaspace空间: 128MB(-XX:MaxMetaspaceSize&#x3D;128m) 可以从上面的JVisualVM的截图看出: 当加载超过2万个类之后，Metaspace被耗尽；与JDK1.7运行时非常相似。我们也能通过程序和GC的输出观察耗尽的过程。另一个有趣的现象是，保留的原生内存占用量是设定的最大大小两倍之多。这可能表明，如果可能的话，可微调元空间容量大小策略，来避免本地内存的浪费。 从Java程序的输出中看到如下异常。 1234567[Loaded ClassA from file:/D:/classes/]total: 21393active: 21393unloaded: 0[GC (Metadata GC Threshold) 64306K-&gt;57010K(111616K), 0.0145502 secs][Full GC (Metadata GC Threshold) 57010K-&gt;56810K(122368K), 0.1068084 secs]java.lang.OutOfMemoryError: Metaspace 在设置了MaxMetaspaceSize的情况下，该空间的内存仍然会耗尽，进而引发“java.lang.OutOfMemoryError: Metadata space”错误。因为类加载器的泄漏仍然存在，而通常Java又不希望无限制地消耗本机内存，因此设置一个类似于MaxPermSize的限制看起来也是合理的。 总结 之前不管是不是需要，JVM都会吃掉那块空间……如果设置得太小，JVM会死掉；如果设置得太大，这块内存就被JVM浪费了。理论上说，现在你完全可以不关注这个，因为JVM会在运行时自动调校为“合适的大小”； 提高Full GC的性能，在Full GC期间，Metadata到Metadata pointers之间不需要扫描了，别小看这几纳秒时间； 隐患就是如果程序存在内存泄露，像OOMTest那样，不停的扩展metaspace的空间，会导致机器的内存不足，所以还是要有必要的调试和监控。 参考文章https://wizardforcel.gitbooks.io/java8-new-features/content/9.html","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"8.Java 8 - JRE精简","path":"/2023/12/26/8-Java-8-JRE精简/","content":"理解Java8 JRE精简需理解几个问题: 为什么精简Java8 JRE，及好处是啥? 在不同平台上如何编译等? Oracle公司如期发布了Java 8正式版！没有让广大javaer失望。对于一个人来说，18岁是人生的转折点，从稚嫩走向成熟，法律意味着你是完全民事行为能力人，不再收益于未成年人保护法，到今年为止，java也走过了18年，java8是一个新的里程碑，带来了前所未有的诸多特性，lambda表达式，Stream API，新的Date time api，多核并发支持，重大安全问题改进等，相信java会越来越好，丰富的类库以及庞大的开源生态环境是其他语言所不具备的，说起丰富的类库，很多同学就吐槽了，java该减肥了，确实是该减肥，java8有个很好的特性，即JEP161(http://openjdk.java.net/jeps/161 ),该特性定义了Java SE平台规范的一些子集，使java应用程序不需要整个JRE平台即可部署和运行在小型设备上。开发人员可以基于目标硬件的可用资源选择一个合适的JRE运行环境。 JRE精简好处 更小的Java环境需要更少的计算资源。 一个较小的运行时环境可以更好的优化性能和启动时间。 消除未使用的代码从安全的角度总是好的。 这些打包的应用程序可以下载速度更快。 概念紧凑的JRE分3种，分别是compact1、compact2、compact3，他们的关系是compact1&lt;compact2&lt;compact3,他们包含的API如下图所示 使用javac根据profile编译应用程序 1javac –bootclasspath, or javac –profile 如果不符合compact的api，则报错。 12345678$ javac -profile compact2 Test.javaTest.java:7: error: ThreadMXBean is not available in profile &#x27;compact2&#x27; ThreadMXBean bean = ManagementFactory.getThreadMXBean(); ^Test.java:7: error: ManagementFactory is not available in profile &#x27;compact2&#x27; ThreadMXBean bean = ManagementFactory.getThreadMXBean(); ^2 errors 使用工具开发的效果 JDEPS工具使用java8新增一个工具，用来分析应用程序所依赖的profile，有三个参数比较常用 -p，-v，-r 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import java.util.Set;import java.util.HashSet;public class Deps &#123; public static void main(String[] args) &#123; System.out.println(Math.random()); Set&lt;String&gt; set = new HashSet&lt;&gt;(); &#125;&#125;************** PROFILE ********************jdeps -P Deps.class Deps.class -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar &lt;unnamed&gt; (Deps.class) -&gt; java.io compact1 -&gt; java.lang compact1 -&gt; java.util compact1************** VERBOSE ********************jdeps -v Deps.class Deps.class -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar Deps (Deps.class) -&gt; java.io.PrintStream -&gt; java.lang.Math -&gt; java.lang.Object -&gt; java.lang.String -&gt; java.lang.System -&gt; java.util.HashSet ************** RECURSIVE ********************jdeps -R Deps.class Deps.class -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar &lt;unnamed&gt; (Deps.class) -&gt; java.io -&gt; java.lang -&gt; java.util /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/jce.jar -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar javax.crypto (jce.jar) -&gt; java.io -&gt; java.lang -&gt; java.lang.reflect -&gt; java.net -&gt; java.nio -&gt; java.security -&gt; java.security.cert -&gt; java.security.spec -&gt; java.util -&gt; java.util.concurrent -&gt; java.util.jar -&gt; java.util.regex -&gt; java.util.zip -&gt; javax.security.auth -&gt; sun.security.jca JDK internal API (rt.jar) -&gt; sun.security.util JDK internal API (rt.jar) -&gt; sun.security.validator JDK internal API (rt.jar) javax.crypto.interfaces (jce.jar) -&gt; java.lang -&gt; java.math -&gt; java.security javax.crypto.spec (jce.jar) -&gt; java.lang -&gt; java.math -&gt; java.security.spec -&gt; java.util /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/rt.jar -&gt; /Library/Java/JavaVirtualMachines/jdk1.8.0.jdk/Contents/Home/jre/lib/jce.jar java.security (rt.jar) -&gt; javax.crypto JDK internal API (jce.jar) sun.security.util (rt.jar) -&gt; javax.crypto JDK internal API (jce.jar) -&gt; javax.crypto.interfaces JDK internal API (jce.jar) -&gt; javax.crypto.spec JDK internal API (jce.jar) 在linux上构建profile1234567891011121314151617181920212223$ hg clone http://hg.openjdk.java.net/jdk8/jdk8/$ cd jdk8$ make images profiles : # Finished profiles (build time 00:00:27)----- Build times -------Start 2013-03-17 14:47:35End 2013-03-17 14:58:2600:00:25 corba00:00:15 demos00:01:50 hotspot00:00:24 images00:00:21 jaxp00:00:31 jaxws00:05:37 jdk00:00:43 langtools00:00:18 nashorn00:00:27 profiles00:10:51 TOTAL-------------------------Finished building Java(TM) for target &#x27;images profiles&#x27;$ cd images$ ls -d *imagej2re-compact1-image j2re-compact2-image j2re-compact3-image j2re-image j2sdk-image 编译后compact大致的占用空间 总结如今，物联网正风行一时。我们看到大量不同的设备在市场上出现，每一种的更新速度都越来越快。java需要一个占用资源少的JRE运行环境，紧凑的JRE特性的出现，希望能带来以后的物联网的发展，甚至还是会有大量的java应用程序出现在物联网上面。目前oracle也发布了针对raspberry pi的JRE了。 另外该特性也是为java9的模块化项目做准备，模块化特性是javaer所期待的特性。他是解决业务系统复杂度的一个利器，当然OSGI也是相当的出色。但osgi对于新学者来说未免太复杂了。","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"7.Java 8 - 类型推断优化","path":"/2023/12/26/7-Java-8-类型推断优化/","content":"理解Java 8 类型推断需理解几个问题: 什么是泛型 Java7对泛型推断做了哪些优化 Java8对此有做了哪些优化 简单理解泛型泛型是Java SE 1.5的新特性，泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。通俗点将就是“类型的变量”。这种类型变量可以用在类、接口和方法的创建中。 理解Java泛型最简单的方法是把它看成一种便捷语法，能节省你某些Java类型转换(casting)上的操作: 123List&lt;Apple&gt; box = new ArrayList&lt;Apple&gt;();box.add(new Apple());Apple apple =box.get(0); 上面的代码自身已表达的很清楚: box是一个装有Apple对象的List。get方法返回一个Apple对象实例，这个过程不需要进行类型转换。没有泛型，上面的代码需要写成这样: 1Apple apple = (Apple)box.get(0); 泛型的尴尬泛型的最大优点是提供了程序的类型安全同时可以向后兼容，但也有尴尬的地方，就是每次定义时都要写明泛型的类型，这样显示指定不仅感觉有些冗长，最主要是很多程序员不熟悉泛型，因此很多时候不能够给出正确的类型参数，现在通过编译器自动推断泛型的参数类型，能够减少这样的情况，并提高代码可读性。 java7的泛型类型推断改进在以前的版本中使用泛型类型，需要在声明并赋值的时候，两侧都加上泛型类型。例如: 1Map&lt;String, String&gt; myMap = new HashMap&lt;String, String&gt;(); 你可能觉得:老子在声明变量的的时候已经指明了参数类型，为毛还要在初始化对象时再指定? 幸好，在Java SE 7中，这种方式得以改进，现在你可以使用如下语句进行声明并赋值: 1Map&lt;String, String&gt; myMap = new HashMap&lt;&gt;(); //注意后面的&quot;&lt;&gt;&quot; 在这条语句中，编译器会根据变量声明时的泛型类型自动推断出实例化HashMap时的泛型类型。再次提醒一定要注意new HashMap后面的“&lt;&gt;”，只有加上这个“&lt;&gt;”才表示是自动类型推断，否则就是非泛型类型的HashMap，并且在使用编译器编译源代码时会给出一个警告提示。 但是: Java SE 7在创建泛型实例时的类型推断是有限制的: 只有构造器的参数化类型在上下文中被显著的声明了，才可以使用类型推断，否则不行。例如: 下面的例子在java 7无法正确编译(但现在在java8里面可以编译，因为根据方法参数来自动推断泛型的类型): 123List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(&quot;A&quot;);// 由于addAll期望获得Collection&lt;? extends String&gt;类型的参数，因此下面的语句无法通过list.addAll(new ArrayList&lt;&gt;()); Java8的泛型类型推断改进java8里面泛型的目标类型推断主要2个: 1.支持通过方法上下文推断泛型目标类型 2.支持在方法调用链路当中，泛型类型推断传递到最后一个方法 让我们看看官网的例子 12345class List&lt;E&gt; &#123; static &lt;Z&gt; List&lt;Z&gt; nil() &#123; ... &#125;; static &lt;Z&gt; List&lt;Z&gt; cons(Z head, List&lt;Z&gt; tail) &#123; ... &#125;; E head() &#123; ... &#125;&#125; 根据JEP101的特性，我们在调用上面方法的时候可以这样写 12345678//通过方法赋值的目标参数来自动推断泛型的类型List&lt;String&gt; l = List.nil();//而不是显示的指定类型//List&lt;String&gt; l = List.&lt;String&gt;nil();//通过前面方法参数类型推断泛型的类型List.cons(42, List.nil());//而不是显示的指定类型//List.cons(42, List.&lt;Integer&gt;nil()); 总结以上是JEP101的特性内容了，Java作为静态语言的代表者，可以说类型系统相当丰富。导致类型间互相转换的问题困扰着每个java程序员，通过编译器自动推断类型的东西可以稍微缓解一下类型转换太复杂的问题。 虽然说是小进步，但对于我们天天写代码的程序员，肯定能带来巨大的作用，至少心情更愉悦了","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"4.Java 8 - 默认方法","path":"/2023/12/26/4-Java-8-默认方法/","content":"理解Java 8 默认方法需理解几个问题: 为什么会出现默认方法? 接口中出现默认方法，且类可以实现多接口的，那和抽象类有啥区别? 多重实现的默认方法冲突怎么办? 什么是默认方法，为什么要有默认方法先上例子一个接口A，Clazz类实现了接口A。 123456789101112public interface A &#123; default void foo()&#123; System.out.println(&quot;Calling A.foo()&quot;); &#125;&#125;public class Clazz implements A &#123; public static void main(String[] args)&#123; Clazz clazz = new Clazz(); clazz.foo();//调用A.foo() &#125;&#125; 代码是可以编译的，即使Clazz类并没有实现foo()方法。在接口A中提供了foo()方法的默认实现。 什么是默认方法简单说，就是接口可以有实现方法，而且不需要实现类去实现其方法。只需在方法名前面加个default关键字即可。 为什么出现默认方法为什么要有这个特性? 首先，之前的接口是个双刃剑，好处是面向抽象而不是面向具体编程，缺陷是，当需要修改接口时候，需要修改全部实现该接口的类，目前的java 8之前的集合框架没有foreach方法，通常能想到的解决办法是在JDK里给相关的接口添加新的方法及实现。然而，对于已经发布的版本，是没法在给接口添加新方法的同时不影响已有的实现。所以引进的默认方法。他们的目的是为了解决接口的修改与现有的实现不兼容的问题。 java 8抽象类与接口对比这一个功能特性出来后，很多同学都反应了，java 8的接口都有实现方法了，跟抽象类还有什么区别? 其实还是有的，请看下表对比。。 相同点 不同点 都是抽象类型 抽象类不可以多重继承，接口可以(无论是多重类型继承还是多重行为继承) 都可以有实现方法(以前接口不行) 抽象类和接口所反映出的设计理念不同。其实抽象类表示的是”is-a”关系，接口表示的是”like-a”关系 都可以不需要实现类或者继承者去实现所有方法，(以前不行，现在接口中默认方法不需要实现者实现) 接口中定义的变量默认是public static final 型，且必须给其初值，所以实现类中不能改变其值；抽象类中的变量默认是 friendly 型，其值可以在子类中重新定义，也可以重新赋值。 多重继承的冲突由于同一个方法可以从不同接口引入，自然而然的会有冲突的现象，默认方法判断冲突的规则如下: 1.一个声明在类里面的方法优先于任何默认方法(classes always win) 2.否则，则会优先选取路径最短的。 举例子 Case 1 12345678910111213public interface A&#123;\tdefault void aa() &#123; System.out.println(&quot;A&#x27;s aa&quot;);\t&#125;&#125;public interface B&#123;\tdefault void aa() &#123; System.out.println(&quot;B&#x27;s aa&quot;);\t&#125;&#125;public static class D implements A,B&#123;\t&#125; 报错 Duplicate default methods named aa with the parameters () and () are inherited from the types DocApplication.B and DocApplication.A 如果一定要这么写呢，同时实现A,B并且使用A中aa? 可以这么写: 123456public static class D implements A,B&#123; @Override public void aa()&#123; A.super.aa(); &#125;&#125; Case 2 123456789101112131415161718public interface A&#123;\tdefault void aa() &#123; System.out.println(&quot;A&#x27;s aa&quot;);\t&#125;&#125;public interface B&#123;\tdefault void aa() &#123; System.out.println(&quot;B&#x27;s aa&quot;);\t&#125;&#125;public interface C extends A, B&#123;\tdefault void aa() &#123; System.out.println(&quot;C&#x27;s aa&quot;);\t&#125;&#125;public static class D implements A,B,C&#123;\t&#125; 输出 C’s aa Case 3 12345678910111213public interface A&#123;\tdefault void aa() &#123; System.out.println(&quot;A&#x27;s aa&quot;);\t&#125;&#125;public interface C extends A&#123;\tdefault void aa() &#123; System.out.println(&quot;C&#x27;s aa&quot;);\t&#125;&#125;public static class D implements C&#123;\t&#125; 输出 C’s aa 通过Case1-3可以知道它是找唯一的最短路径的default，如果是多个那么报错。 Case 4 如果想调用A的默认函数，则用到新语法X.super.m(…),下面修改C类，实现A接口，重写一个hello方法，如下所示: 1234567891011public interface A&#123;\tdefault void aa() &#123; System.out.println(&quot;A&#x27;s aa&quot;);\t&#125;&#125;public class X implements A&#123; @Override public void aa()&#123; A.super.aa(); &#125;&#125; 输出: A’s aa Case 5 123456789101112131415161718192021public interface A&#123;\tdefault void aa() &#123; System.out.println(&quot;A&#x27;s aa&quot;);\t&#125;&#125;public interface B&#123;\tdefault void aa() &#123; System.out.println(&quot;B&#x27;s aa&quot;);\t&#125;&#125;public interface C extends A,B&#123;\tdefault void aa() &#123; System.out.println(&quot;C&#x27;s aa&quot;);\t&#125;&#125;public static class D implements C&#123;\t@Override public void aa()&#123; C.super.aa(); &#125;&#125; 输出 C’s aa 可见C.super表示的是C接口，同时D无法访问A,B的aa 通过Case 5也可以看出，C虽然有同一个两个最短路径的aa, 但是它自己有一个更高优先级的aa，所以不会报错; case 6 会报错 Case 6 123456789101112public interface A&#123;\tdefault void aa() &#123; System.out.println(&quot;A&#x27;s aa&quot;);\t&#125;&#125;public interface B&#123;\tdefault void aa() &#123; System.out.println(&quot;B&#x27;s aa&quot;);\t&#125;&#125;public interface C extends A,B&#123;&#125; 报错 总结默认方法给予我们修改接口而不破坏原来的实现类的结构提供了便利，目前java 8的集合框架已经大量使用了默认方法来改进了，当我们最终开始使用Java 8的lambdas表达式时，提供给我们一个平滑的过渡体验。也许将来我们会在API设计中看到更多的默认方法的应用。","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"3.Java 8 - Optional类深度解析","path":"/2023/12/26/3-Java-8-Optional类深度解析/","content":"对Java 8 Optional类进行深度解析。 身为一名Java程序员，大家可能都有这样的经历: 调用一个方法得到了返回值却不能直接将返回值作为参数去调用别的方法。我们首先要判断这个返回值是否为null，只有在非空的前提下才能将其作为其他方法的参数。这正是一些类似Guava的外部API试图解决的问题。一些JVM编程语言比如Scala、Ceylon等已经将对在核心API中解决了这个问题。在我的前一篇文章中，介绍了Scala是如何解决了这个问题。 新版本的Java，比如Java 8引入了一个新的Optional类。Optional类的Javadoc描述如下: 这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。 Optional类包含的方法of 为非null的值创建一个Optional。 of方法通过工厂方法创建Optional类。需要注意的是，创建对象时传入的参数不能为null。如果传入参数为null，则抛出NullPointerException 。 1234//调用工厂方法创建Optional实例Optional&lt;String&gt; name = Optional.of(&quot;Sanaulla&quot;);//传入参数为null，抛出NullPointerException.Optional&lt;String&gt; someNull = Optional.of(null); ofNullable 为指定的值创建一个Optional，如果指定的值为null，则返回一个空的Optional。 ofNullable与of方法相似，唯一的区别是可以接受参数为null的情况。示例如下: 123//下面创建了一个不包含任何值的Optional实例//例如，值为&#x27;null&#x27;Optional empty = Optional.ofNullable(null); isPresent非常容易理解 如果值存在返回true，否则返回false。 类似下面的代码: 12345//isPresent方法用来检查Optional实例中是否包含值if (name.isPresent()) &#123; //在Optional实例内调用get()返回已存在的值 System.out.println(name.get());//输出Sanaulla&#125; get 如果Optional有值则将其返回，否则抛出NoSuchElementException。 上面的示例中，get方法用来得到Optional实例中的值。下面我们看一个抛出NoSuchElementException的例子: 1234567//执行下面的代码会输出: No value present try &#123; //在空的Optional实例上调用get()，抛出NoSuchElementException System.out.println(empty.get());&#125; catch (NoSuchElementException ex) &#123; System.out.println(ex.getMessage());&#125; ifPresent 如果Optional实例有值则为其调用consumer，否则不做处理 要理解ifPresent方法，首先需要了解Consumer类。简答地说，Consumer类包含一个抽象方法。该抽象方法对传入的值进行处理，但没有返回值。Java8支持不用接口直接通过lambda表达式传入参数。 如果Optional实例有值，调用ifPresent()可以接受接口段或lambda表达式。类似下面的代码: 12345//ifPresent方法接受lambda表达式作为参数。//lambda表达式对Optional的值调用consumer进行处理。name.ifPresent((value) -&gt; &#123; System.out.println(&quot;The length of the value is: &quot; + value.length());&#125;); orElse 如果有值则将其返回，否则返回指定的其它值。 如果Optional实例有值则将其返回，否则返回orElse方法传入的参数。示例如下: 123456//如果值不为null，orElse方法返回Optional实例的值。//如果为null，返回传入的消息。//输出: There is no value present!System.out.println(empty.orElse(&quot;There is no value present!&quot;));//输出: SanaullaSystem.out.println(name.orElse(&quot;There is some value!&quot;)); orElseGet orElseGet与orElse方法类似，区别在于得到的默认值。orElse方法将传入的字符串作为默认值，orElseGet方法可以接受Supplier接口的实现用来生成默认值。示例如下: 123456//orElseGet与orElse方法类似，区别在于orElse传入的是默认值，//orElseGet可以接受一个lambda表达式生成默认值。//输出: Default ValueSystem.out.println(empty.orElseGet(() -&gt; &quot;Default Value&quot;));//输出: SanaullaSystem.out.println(name.orElseGet(() -&gt; &quot;Default Value&quot;)); orElseThrow 如果有值则将其返回，否则抛出supplier接口创建的异常。 在orElseGet方法中，我们传入一个Supplier接口。然而，在orElseThrow中我们可以传入一个lambda表达式或方法，如果值不存在来抛出异常。示例如下: 123456789try &#123; //orElseThrow与orElse方法类似。与返回默认值不同， //orElseThrow会抛出lambda表达式或方法生成的异常 empty.orElseThrow(ValueAbsentException::new);&#125; catch (Throwable ex) &#123; //输出: No value present in the Optional instance System.out.println(ex.getMessage());&#125; ValueAbsentException定义如下: 123456789101112131415class ValueAbsentException extends Throwable &#123; public ValueAbsentException() &#123; super(); &#125; public ValueAbsentException(String msg) &#123; super(msg); &#125; @Override public String getMessage() &#123; return &quot;No value present in the Optional instance&quot;; &#125;&#125; mapmap方法文档说明如下: 如果有值，则对其执行调用mapping函数得到返回值。如果返回值不为null，则创建包含mapping返回值的Optional作为map方法返回值，否则返回空Optional。 map方法用来对Optional实例的值执行一系列操作。通过一组实现了Function接口的lambda表达式传入操作。如果你不熟悉Function接口，可以参考我的这篇博客。map方法示例如下: 1234//map方法执行传入的lambda表达式参数对Optional实例的值进行修改。//为lambda表达式的返回值创建新的Optional实例作为map方法的返回值。Optional&lt;String&gt; upperName = name.map((value) -&gt; value.toUpperCase());System.out.println(upperName.orElse(&quot;No value found&quot;)); flatMap 如果有值，为其执行mapping函数返回Optional类型返回值，否则返回空Optional。flatMap与map(Funtion)方法类似，区别在于flatMap中的mapper返回值必须是Optional。调用结束时，flatMap不会对结果用Optional封装。 flatMap方法与map方法类似，区别在于mapping函数的返回值不同。map方法的mapping函数返回值可以是任何类型T，而flatMap方法的mapping函数必须是Optional。 参照map函数，使用flatMap重写的示例如下: 12345//flatMap与map(Function)非常类似，区别在于传入方法的lambda表达式的返回类型。//map方法中的lambda表达式返回值可以是任意类型，在map函数返回之前会包装为Optional。 //但flatMap方法中的lambda表达式返回值必须是Optionl实例。 upperName = name.flatMap((value) -&gt; Optional.of(value.toUpperCase()));System.out.println(upperName.orElse(&quot;No value found&quot;));//输出SANAULLA filterfilter个方法通过传入限定条件对Optional实例的值进行过滤。文档描述如下: 如果有值并且满足断言条件返回包含该值的Optional，否则返回空Optional。 读到这里，可能你已经知道如何为filter方法传入一段代码。是的，这里可以传入一个lambda表达式。对于filter函数我们应该传入实现了Predicate接口的lambda表达式。如果你不熟悉Predicate接口，可以参考这篇文章。 现在我来看看filter的各种用法，下面的示例介绍了满足限定条件和不满足两种情况: 12345678910//filter方法检查给定的Option值是否满足某些条件。//如果满足则返回同一个Option实例，否则返回空Optional。Optional&lt;String&gt; longName = name.filter((value) -&gt; value.length() &gt; 6);System.out.println(longName.orElse(&quot;The name is less than 6 characters&quot;));//输出Sanaulla//另一个例子是Optional值不满足filter指定的条件。Optional&lt;String&gt; anotherName = Optional.of(&quot;Sana&quot;);Optional&lt;String&gt; shortName = anotherName.filter((value) -&gt; value.length() &gt; 6);//输出: name长度不足6字符System.out.println(shortName.orElse(&quot;The name is less than 6 characters&quot;)); 一些例子 一个综合例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class OptionalDemo &#123; public static void main(String[] args) &#123; //创建Optional实例，也可以通过方法返回值得到。 Optional&lt;String&gt; name = Optional.of(&quot;Sanaulla&quot;); //创建没有值的Optional实例，例如值为&#x27;null&#x27; Optional empty = Optional.ofNullable(null); //isPresent方法用来检查Optional实例是否有值。 if (name.isPresent()) &#123; //调用get()返回Optional值。 System.out.println(name.get()); &#125; try &#123; //在Optional实例上调用get()抛出NoSuchElementException。 System.out.println(empty.get()); &#125; catch (NoSuchElementException ex) &#123; System.out.println(ex.getMessage()); &#125; //ifPresent方法接受lambda表达式参数。 //如果Optional值不为空，lambda表达式会处理并在其上执行操作。 name.ifPresent((value) -&gt; &#123; System.out.println(&quot;The length of the value is: &quot; + value.length()); &#125;); //如果有值orElse方法会返回Optional实例，否则返回传入的错误信息。 System.out.println(empty.orElse(&quot;There is no value present!&quot;)); System.out.println(name.orElse(&quot;There is some value!&quot;)); //orElseGet与orElse类似，区别在于传入的默认值。 //orElseGet接受lambda表达式生成默认值。 System.out.println(empty.orElseGet(() -&gt; &quot;Default Value&quot;)); System.out.println(name.orElseGet(() -&gt; &quot;Default Value&quot;)); try &#123; //orElseThrow与orElse方法类似，区别在于返回值。 //orElseThrow抛出由传入的lambda表达式/方法生成异常。 empty.orElseThrow(ValueAbsentException::new); &#125; catch (Throwable ex) &#123; System.out.println(ex.getMessage()); &#125; //map方法通过传入的lambda表达式修改Optonal实例默认值。 //lambda表达式返回值会包装为Optional实例。 Optional&lt;String&gt; upperName = name.map((value) -&gt; value.toUpperCase()); System.out.println(upperName.orElse(&quot;No value found&quot;)); //flatMap与map(Funtion)非常相似，区别在于lambda表达式的返回值。 //map方法的lambda表达式返回值可以是任何类型，但是返回值会包装成Optional实例。 //但是flatMap方法的lambda返回值总是Optional类型。 upperName = name.flatMap((value) -&gt; Optional.of(value.toUpperCase())); System.out.println(upperName.orElse(&quot;No value found&quot;)); //filter方法检查Optiona值是否满足给定条件。 //如果满足返回Optional实例值，否则返回空Optional。 Optional&lt;String&gt; longName = name.filter((value) -&gt; value.length() &gt; 6); System.out.println(longName.orElse(&quot;The name is less than 6 characters&quot;)); //另一个示例，Optional值不满足给定条件。 Optional&lt;String&gt; anotherName = Optional.of(&quot;Sana&quot;); Optional&lt;String&gt; shortName = anotherName.filter((value) -&gt; value.length() &gt; 6); System.out.println(shortName.orElse(&quot;The name is less than 6 characters&quot;)); &#125;&#125; 上述代码输出如下: 123456789101112SanaullaNo value presentThe length of the value is: 8There is no value present!SanaullaDefault ValueSanaullaNo value present in the Optional instanceSANAULLASANAULLASanaullaThe name is less than 6 characters 在 Java 8 中提高 Null 的安全性 假设我们有一个像这样的类层次结构: 123456789101112131415161718class Outer &#123; Nested nested; Nested getNested() &#123; return nested; &#125;&#125;class Nested &#123; Inner inner; Inner getInner() &#123; return inner; &#125;&#125;class Inner &#123; String foo; String getFoo() &#123; return foo; &#125;&#125; 解决这种结构的深层嵌套路径是有点麻烦的。我们必须编写一堆 null 检查来确保不会导致一个 NullPointerException: 1234Outer outer = new Outer();if (outer != null &amp;&amp; outer.nested != null &amp;&amp; outer.nested.inner != null) &#123; System.out.println(outer.nested.inner.foo);&#125; 我们可以通过利用 Java 8 的 Optional 类型来摆脱所有这些 null 检查。map 方法接收一个 Function 类型的 lambda 表达式，并自动将每个 function 的结果包装成一个 Optional 对象。这使我们能够在一行中进行多个 map 操作。Null 检查是在底层自动处理的。 12345Optional.of(new Outer()) .map(Outer::getNested) .map(Nested::getInner) .map(Inner::getFoo) .ifPresent(System.out::println); 还有一种实现相同作用的方式就是通过利用一个 supplier 函数来解决嵌套路径的问题: 123Outer obj = new Outer();resolve(() -&gt; obj.getNested().getInner().getFoo()) .ifPresent(System.out::println); 调用 obj.getNested().getInner().getFoo()) 可能会抛出一个 NullPointerException 异常。在这种情况下，该异常将会被捕获，而该方法会返回 Optional.empty()。 123456789public static &lt;T&gt; Optional&lt;T&gt; resolve(Supplier&lt;T&gt; resolver) &#123; try &#123; T result = resolver.get(); return Optional.ofNullable(result); &#125; catch (NullPointerException e) &#123; return Optional.empty(); &#125;&#125; 请记住，这两个解决方案可能没有传统 null 检查那么高的性能。不过在大多数情况下不会有太大问题。 参考原文链接: javacodegeeks 翻译: ImportNew.com - 高俊阳 译文链接: http://www.importnew.com/6675.html","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"2.Java 8 - 函数编程(lambda表达式)","path":"/2023/12/26/2-Java-8-函数编程-lambda表达式/","content":"我们关心的是如何写出好代码，而不是符合函数编程风格的代码。 简介 在Java世界里面，面向对象还是主流思想，对于习惯了面向对象编程的开发者来说，抽象的概念并不陌生。面向对象编程是对数据进行抽象，而函数式编程是对行为进行抽象。现实世界中，数据和行为并存，程序也是如此，因此这两种编程方式我们都得学。 这种新的抽象方式还有其他好处。很多人不总是在编写性能优先的代码，对于这些人来说，函数式编程带来的好处尤为明显。程序员能编写出更容易阅读的代码——这种代码更多地表达了业务逻辑，而不是从机制上如何实现。易读的代码也易于维护、更可靠、更不容易出错。 在写回调函数和事件处理器时，程序员不必再纠缠于匿名内部类的冗繁和可读性，函数式编程让事件处理系统变得更加简单。能将函数方便地传递也让编写惰性代码变得容易，只有在真正需要的时候，才初始化变量的值。 面向对象编程是对数据进行抽象；函数式编程是对行为进行抽象。 核心思想: 使用不可变值和函数，函数对一个值进行处理，映射成另一个值。 对核心类库的改进主要包括集合类的API和新引入的流Stream。流使程序员可以站在更高的抽象层次上对集合进行操作。 lambda表达式 lambda表达式仅能放入如下代码: 预定义使用了 @Functional 注释的函数式接口，自带一个抽象函数的方法，或者SAM(Single Abstract Method 单个抽象方法)类型。这些称为lambda表达式的目标类型，可以用作返回类型，或lambda目标代码的参数。例如，若一个方法接收Runnable、Comparable或者 Callable 接口，都有单个抽象方法，可以传入lambda表达式。类似的，如果一个方法接受声明于 java.util.function 包内的接口，例如 Predicate、Function、Consumer 或 Supplier，那么可以向其传lambda表达式。 lambda表达式内可以使用方法引用，仅当该方法不修改lambda表达式提供的参数。本例中的lambda表达式可以换为方法引用，因为这仅是一个参数相同的简单方法调用。 12list.forEach(n -&gt; System.out.println(n)); list.forEach(System.out::println); // 使用方法引用 然而，若对参数有任何修改，则不能使用方法引用，而需键入完整地lambda表达式，如下所示: 1list.forEach((String s) -&gt; System.out.println(&quot;*&quot; + s + &quot;*&quot;)); 事实上，可以省略这里的lambda参数的类型声明，编译器可以从列表的类属性推测出来。 lambda内部可以使用静态、非静态和局部变量，这称为lambda内的变量捕获。 Lambda表达式在Java中又称为闭包或匿名函数，所以如果有同事把它叫闭包的时候，不用惊讶。 Lambda方法在编译器内部被翻译成私有方法，并派发 invokedynamic 字节码指令来进行调用。可以使用JDK中的 javap 工具来反编译class文件。使用 javap -p 或 javap -c -v 命令来看一看lambda表达式生成的字节码。大致应该长这样: 1private static java.lang.Object lambda$0(java.lang.String); lambda表达式有个限制，那就是只能引用 final 或 final 局部变量，这就是说不能在lambda内部修改定义在域外的变量。 123List&lt;Integer&gt; primes = Arrays.asList(new Integer[]&#123;2, 3,5,7&#125;);int factor = 2;primes.forEach(element -&gt; &#123; factor++; &#125;); Compile time error : “local variables referenced from a lambda expression must be final or effectively final” 另外，只是访问它而不作修改是可以的，如下所示: 123List&lt;Integer&gt; primes = Arrays.asList(new Integer[]&#123;2, 3,5,7&#125;);int factor = 2;primes.forEach(element -&gt; &#123; System.out.println(factor*element); &#125;); 分类惰性求值方法1lists.stream().filter(f -&gt; f.getName().equals(&quot;p1&quot;)) 如上示例，这行代码并未做什么实际性的工作，filter只是描述了Stream，没有产生新的集合。 如果是多个条件组合，可以通过代码块{} 及早求值方法1List&lt;Person&gt; list2 = lists.stream().filter(f -&gt; f.getName().equals(&quot;p1&quot;)).collect(Collectors.toList()); 如上示例，collect最终会从Stream产生新值，拥有终止操作。 理想方式是形成一个惰性求值的链，最后用一个及早求值的操作返回想要的结果。与建造者模式相似，建造者模式先是使用一系列操作设置属性和配置，最后调用build方法，创建对象。 stream &amp; parallelStreamstream &amp; parallelStream每个Stream都有两种模式: 顺序执行和并行执行。 顺序流: 1List &lt;Person&gt; people = list.getStream.collect(Collectors.toList()); 并行流: 1List &lt;Person&gt; people = list.getStream.parallel().collect(Collectors.toList()); 顾名思义，当使用顺序方式去遍历时，每个item读完后再读下一个item。而使用并行去遍历时，数组会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。 parallelStream原理:123456List originalList = someData;split1 = originalList(0, mid);//将数据分小部分split2 = originalList(mid,end);new Runnable(split1.process());//小部分执行操作new Runnable(split2.process());List revisedList = split1 + split2;//将结果合并 大家对hadoop有稍微了解就知道，里面的 MapReduce 本身就是用于并行处理大数据集的软件框架，其 处理大数据的核心思想就是大而化小，分配到不同机器去运行map，最终通过reduce将所有机器的结果结合起来得到一个最终结果，与MapReduce不同，Stream则是利用多核技术可将大数据通过多核并行处理，而MapReduce则可以分布式的。 stream与parallelStream性能测试对比如果是多核机器，理论上并行流则会比顺序流快上一倍，下面是测试代码 1234567891011121314151617long t0 = System.nanoTime();//初始化一个范围100万整数流,求能被2整除的数字，toArray()是终点方法int a[]=IntStream.range(0, 1_000_000).filter(p -&gt; p % 2==0).toArray();long t1 = System.nanoTime();//和上面功能一样，这里是用并行流来计算int b[]=IntStream.range(0, 1_000_000).parallel().filter(p -&gt; p % 2==0).toArray();long t2 = System.nanoTime();//我本机的结果是serial: 0.06s, parallel 0.02s，证明并行流确实比顺序流快System.out.printf(&quot;serial: %.2fs, parallel %.2fs%n&quot;, (t1 - t0) * 1e-9, (t2 - t1) * 1e-9); Stream中常用方法如下: stream(), parallelStream() filter() findAny() findFirst() sort forEach void map(), reduce() flatMap() - 将多个Stream连接成一个Stream collect(Collectors.toList()) distinct, limit count min, max, summaryStatistics 看下所有API: 常用例子匿名类简写123456new Thread( () -&gt; System.out.println(&quot;In Java8, Lambda expression rocks !!&quot;) ).start();// 用法(params) -&gt; expression(params) -&gt; statement(params) -&gt; &#123; statements &#125; forEach123456// forEachList features = Arrays.asList(&quot;Lambdas&quot;, &quot;Default Method&quot;, &quot;Stream API&quot;, &quot;Date and Time API&quot;);features.forEach(n -&gt; System.out.println(n)); // 使用Java 8的方法引用更方便，方法引用由::双冒号操作符标示，features.forEach(System.out::println); 方法引用构造引用 12// Supplier&lt;Student&gt; s = () -&gt; new Student();Supplier&lt;Student&gt; s = Student::new; 对象::实例方法 Lambda表达式的(形参列表)与实例方法的(实参列表)类型，个数是对应 12// set.forEach(t -&gt; System.out.println(t));set.forEach(System.out::println); 类名::静态方法 12// Stream&lt;Double&gt; stream = Stream.generate(() -&gt; Math.random());Stream&lt;Double&gt; stream = Stream.generate(Math::random); 类名::实例方法 123456// TreeSet&lt;String&gt; set = new TreeSet&lt;&gt;((s1,s2) -&gt; s1.compareTo(s2));/* 这里如果使用第一句话，编译器会有提示: Can be replaced with Comparator.naturalOrder，这句话告诉我们 String已经重写了compareTo()方法，在这里写是多此一举，这里为什么这么写，是因为为了体现下面 这句编译器的提示: Lambda can be replaced with method reference。好了，下面的这句就是改写成方法引用之后: */TreeSet&lt;String&gt; set = new TreeSet&lt;&gt;(String::compareTo); Filter &amp; Predicate常规用法 123456789101112131415161718192021222324public static void main(args[])&#123; List languages = Arrays.asList(&quot;Java&quot;, &quot;Scala&quot;, &quot;C++&quot;, &quot;Haskell&quot;, &quot;Lisp&quot;); System.out.println(&quot;Languages which starts with J :&quot;); filter(languages, (str)-&gt;str.startsWith(&quot;J&quot;)); System.out.println(&quot;Languages which ends with a &quot;); filter(languages, (str)-&gt;str.endsWith(&quot;a&quot;)); System.out.println(&quot;Print all languages :&quot;); filter(languages, (str)-&gt;true); System.out.println(&quot;Print no language : &quot;); filter(languages, (str)-&gt;false); System.out.println(&quot;Print language whose length greater than 4:&quot;); filter(languages, (str)-&gt;str.length() &gt; 4);&#125; public static void filter(List names, Predicate condition) &#123; names.stream().filter((name) -&gt; (condition.test(name))).forEach((name) -&gt; &#123; System.out.println(name + &quot; &quot;); &#125;);&#125; 多个Predicate组合filter 1234567// 可以用and()、or()和xor()逻辑函数来合并Predicate，// 例如要找到所有以J开始，长度为四个字母的名字，你可以合并两个Predicate并传入Predicate&lt;String&gt; startsWithJ = (n) -&gt; n.startsWith(&quot;J&quot;);Predicate&lt;String&gt; fourLetterLong = (n) -&gt; n.length() == 4;names.stream() .filter(startsWithJ.and(fourLetterLong)) .forEach((n) -&gt; System.out.print(&quot;nName, which starts with &#x27;J&#x27; and four letter long is : &quot; + n)); Map&amp;Reducemap将集合类(例如列表)元素进行转换的。还有一个 reduce() 函数可以将所有值合并成一个 123List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);double bill = costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).reduce((sum, cost) -&gt; sum + cost).get();System.out.println(&quot;Total : &quot; + bill); Collectors1234// 将字符串换成大写并用逗号链接起来List&lt;String&gt; G7 = Arrays.asList(&quot;USA&quot;, &quot;Japan&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Italy&quot;, &quot;U.K.&quot;,&quot;Canada&quot;);String G7Countries = G7.stream().map(x -&gt; x.toUpperCase()).collect(Collectors.joining(&quot;, &quot;));System.out.println(G7Countries); Collectors.joining(“, “) Collectors.toList() Collectors.toSet() ，生成set集合 Collectors.toMap(MemberModel::getUid, Function.identity()) Collectors.toMap(ImageModel::getAid, o -&gt; IMAGE_ADDRESS_PREFIX + o.getUrl()) flatMap将多个Stream连接成一个Stream 1List&lt;Integer&gt; result= Stream.of(Arrays.asList(1,3),Arrays.asList(5,6)).flatMap(a-&gt;a.stream()).collect(Collectors.toList()); 结果: [1, 3, 5, 6] distinct去重 123List&lt;LikeDO&gt; likeDOs=new ArrayList&lt;LikeDO&gt;();List&lt;Long&gt; likeTidList = likeDOs.stream().map(LikeDO::getTid) .distinct().collect(Collectors.toList()); count计总数 1234int countOfAdult=persons.stream() .filter(p -&gt; p.getAge() &gt; 18) .map(person -&gt; new Adult(person)) .count(); Match1234567891011121314151617181920boolean anyStartsWithA = stringCollection .stream() .anyMatch((s) -&gt; s.startsWith(&quot;a&quot;));System.out.println(anyStartsWithA); // trueboolean allStartsWithA = stringCollection .stream() .allMatch((s) -&gt; s.startsWith(&quot;a&quot;));System.out.println(allStartsWithA); // falseboolean noneStartsWithZ = stringCollection .stream() .noneMatch((s) -&gt; s.startsWith(&quot;z&quot;));System.out.println(noneStartsWithZ); // true min,max,summaryStatistics最小值，最大值 1234567List&lt;Person&gt; lists = new ArrayList&lt;Person&gt;();lists.add(new Person(1L, &quot;p1&quot;));lists.add(new Person(2L, &quot;p2&quot;));lists.add(new Person(3L, &quot;p3&quot;));lists.add(new Person(4L, &quot;p4&quot;));Person a = lists.stream().max(Comparator.comparing(t -&gt; t.getId())).get();System.out.println(a.getId()); 如果比较器涉及多个条件，比较复杂，可以定制 123456789Person a = lists.stream().min(new Comparator&lt;Person&gt;() &#123; @Override public int compare(Person o1, Person o2) &#123; if (o1.getId() &gt; o2.getId()) return -1; if (o1.getId() &lt; o2.getId()) return 1; return 0; &#125;&#125;).get(); summaryStatistics 1234567//获取数字的个数、最小值、最大值、总和以及平均值List&lt;Integer&gt; primes = Arrays.asList(2, 3, 5, 7, 11, 13, 17, 19, 23, 29);IntSummaryStatistics stats = primes.stream().mapToInt((x) -&gt; x).summaryStatistics();System.out.println(&quot;Highest prime number in List : &quot; + stats.getMax());System.out.println(&quot;Lowest prime number in List : &quot; + stats.getMin());System.out.println(&quot;Sum of all prime numbers : &quot; + stats.getSum());System.out.println(&quot;Average of all prime numbers : &quot; + stats.getAverage()); peek可以使用peek方法，peek方法可只包含一个空的方法体，只要能设置断点即可，但有些IDE不允许空，可以如下文示例，简单写一个打印逻辑。 注意，调试完后要删掉。 1234567891011121314List&lt;Person&gt; lists = new ArrayList&lt;Person&gt;();lists.add(new Person(1L, &quot;p1&quot;));lists.add(new Person(2L, &quot;p2&quot;));lists.add(new Person(3L, &quot;p3&quot;));lists.add(new Person(4L, &quot;p4&quot;));System.out.println(lists);List&lt;Person&gt; list2 = lists.stream() .filter(f -&gt; f.getName().startsWith(&quot;p&quot;)) .peek(t -&gt; &#123; System.out.println(t.getName()); &#125;) .collect(Collectors.toList());System.out.println(list2); FunctionalInterface理解注解 @FunctionInterface123456789101112131415161718192021222324252627282930313233343536373839/** * An informative annotation type used to indicate that an interface * type declaration is intended to be a &lt;i&gt;functional interface&lt;/i&gt; as * defined by the Java Language Specification. * * Conceptually, a functional interface has exactly one abstract * method. Since &#123;@linkplain java.lang.reflect.Method#isDefault() * default methods&#125; have an implementation, they are not abstract. If * an interface declares an abstract method overriding one of the * public methods of &#123;@code java.lang.Object&#125;, that also does * &lt;em&gt;not&lt;/em&gt; count toward the interface&#x27;s abstract method count * since any implementation of the interface will have an * implementation from &#123;@code java.lang.Object&#125; or elsewhere. * * &lt;p&gt;Note that instances of functional interfaces can be created with * lambda expressions, method references, or constructor references. * * &lt;p&gt;If a type is annotated with this annotation type, compilers are * required to generate an error message unless: * * &lt;ul&gt; * &lt;li&gt; The type is an interface type and not an annotation type, enum, or class. * &lt;li&gt; The annotated type satisfies the requirements of a functional interface. * &lt;/ul&gt; * * &lt;p&gt;However, the compiler will treat any interface meeting the * definition of a functional interface as a functional interface * regardless of whether or not a &#123;@code FunctionalInterface&#125; * annotation is present on the interface declaration. * * @jls 4.3.2. The Class Object * @jls 9.8 Functional Interfaces * @jls 9.4.3 Interface Method Body * @since 1.8 */@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface FunctionalInterface&#123;&#125; interface做注解的注解类型，被定义成java语言规范 一个被它注解的接口只能有一个抽象方法，有两种例外 第一是接口允许有实现的方法，这种实现的方法是用default关键字来标记的(java反射中java.lang.reflect.Method#isDefault()方法用来判断是否是default方法) 第二如果声明的方法和java.lang.Object中的某个方法一样，它可以不当做未实现的方法，不违背这个原则: 一个被它注解的接口只能有一个抽象方法, 比如: java public interface Comparator&lt;T&gt; &#123; int compare(T o1, T o2); boolean equals(Object obj); &#125; 如果一个类型被这个注解修饰，那么编译器会要求这个类型必须满足如下条件: 这个类型必须是一个interface，而不是其他的注解类型、枚举enum或者类class 这个类型必须满足function interface的所有要求，如你个包含两个抽象方法的接口增加这个注解，会有编译错误。 编译器会自动把满足function interface要求的接口自动识别为function interface，所以你才不需要对上面示例中的 ITest接口增加@FunctionInterface注解。 自定义函数接口123456789101112@FunctionalInterfacepublic interface IMyInterface &#123; void study();&#125;package com.isea.java;public class TestIMyInterface &#123; public static void main(String[] args) &#123; IMyInterface iMyInterface = () -&gt; System.out.println(&quot;I like study&quot;); iMyInterface.study(); &#125;&#125; 内置四大函数接口 消费型接口: Consumer&lt; T&gt; void accept(T t)有参数，无返回值的抽象方法； 比如: map.forEach(BiConsumer&lt;A, T&gt;) 12Consumer&lt;Person&gt; greeter = (p) -&gt; System.out.println(&quot;Hello, &quot; + p.firstName);greeter.accept(new Person(&quot;Luke&quot;, &quot;Skywalker&quot;)); 供给型接口: Supplier &lt; T&gt; T get() 无参有返回值的抽象方法； 以stream().collect(Collector&lt;? super T, A, R&gt; collector)为例: 比如: 12Supplier&lt;Person&gt; personSupplier = Person::new;personSupplier.get(); // new Person 再如: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 调用方法&lt;R, A&gt; R collect(Collector&lt;? super T, A, R&gt; collector)// Collectors.toSetpublic static &lt;T&gt;\tCollector&lt;T, ?, Set&lt;T&gt;&gt; toSet() &#123; return new CollectorImpl&lt;&gt;((Supplier&lt;Set&lt;T&gt;&gt;) HashSet::new, Set::add, (left, right) -&gt; &#123; left.addAll(right); return left; &#125;, CH_UNORDERED_ID);&#125;// CollectorImplprivate final Supplier&lt;A&gt; supplier;private final BiConsumer&lt;A, T&gt; accumulator;private final BinaryOperator&lt;A&gt; combiner;private final Function&lt;A, R&gt; finisher;private final Set&lt;Characteristics&gt; characteristics;CollectorImpl(Supplier&lt;A&gt; supplier, BiConsumer&lt;A, T&gt; accumulator, BinaryOperator&lt;A&gt; combiner, Function&lt;A,R&gt; finisher, Set&lt;Characteristics&gt; characteristics) &#123; this.supplier = supplier; this.accumulator = accumulator; this.combiner = combiner; this.finisher = finisher; this.characteristics = characteristics;&#125;CollectorImpl(Supplier&lt;A&gt; supplier, BiConsumer&lt;A, T&gt; accumulator, BinaryOperator&lt;A&gt; combiner, Set&lt;Characteristics&gt; characteristics) &#123; this(supplier, accumulator, combiner, castingIdentity(), characteristics);&#125;// collect()方法实现public final &lt;R, A&gt; R collect(Collector&lt;? super P_OUT, A, R&gt; collector) &#123; A container; if (isParallel() &amp;&amp; (collector.characteristics().contains(Collector.Characteristics.CONCURRENT)) &amp;&amp; (!isOrdered() || collector.characteristics().contains(Collector.Characteristics.UNORDERED))) &#123; container = collector.supplier().get(); BiConsumer&lt;A, ? super P_OUT&gt; accumulator = collector.accumulator(); forEach(u -&gt; accumulator.accept(container, u)); &#125; else &#123; container = evaluate(ReduceOps.makeRef(collector)); &#125; return collector.characteristics().contains(Collector.Characteristics.IDENTITY_FINISH) ? (R) container : collector.finisher().apply(container);&#125; 断定型接口: Predicate boolean test(T t):有参，但是返回值类型是固定的boolean 比如: steam().filter()中参数就是Predicate 12345678910Predicate&lt;String&gt; predicate = (s) -&gt; s.length() &gt; 0;predicate.test(&quot;foo&quot;); // truepredicate.negate().test(&quot;foo&quot;); // falsePredicate&lt;Boolean&gt; nonNull = Objects::nonNull;Predicate&lt;Boolean&gt; isNull = Objects::isNull;Predicate&lt;String&gt; isEmpty = String::isEmpty;Predicate&lt;String&gt; isNotEmpty = isEmpty.negate(); 函数型接口: Function&lt;T,R&gt; R apply(T t)有参有返回值的抽象方法； 比如: steam().map() 中参数就是Function&lt;? super T, ? extends R&gt;；reduce()中参数BinaryOperator (ps: BinaryOperator extends BiFunction&lt;T,T,T&gt;) 1234Function&lt;String, Integer&gt; toInteger = Integer::valueOf;Function&lt;String, String&gt; backToString = toInteger.andThen(String::valueOf);backToString.apply(&quot;123&quot;); // &quot;123&quot; 一些例子 输出 年龄&gt;25的女程序员中名字排名前3位的姓名 1234567javaProgrammers.stream() .filter((p) -&gt; (p.getAge() &gt; 25)) .filter((p) -&gt; (&quot;female&quot;.equals(p.getGender()))) .sorted((p, p2) -&gt; (p.getFirstName().compareTo(p2.getFirstName()))) .limit(3) //.forEach(e -&gt; e.setSalary(e.getSalary() / 100 * 5 + e.getSalary()))//涨工资 .forEach((p) -&gt; System.out.printf(&quot;%s %s; &quot;, p.getFirstName(), p.getLastName())); 工资最高的 Java programmer 1234Person person = javaProgrammers .stream() .max((p, p2) -&gt; (p.getSalary() - p2.getSalary())) .get() 将 Java programmers 的 first name 存放到 TreeSet 1234TreeSet&lt;String&gt; javaDevLastName = javaProgrammers .stream() .map(Person::getLastName) .collect(toCollection(TreeSet::new)) 计算付给 Java programmers 的所有money 1234int totalSalary = javaProgrammers .parallelStream() .mapToInt(p -&gt; p.getSalary()) .sum(); Comparator多属性排序: 先按名字不分大小写排，再按GID倒序排，最后按年龄正序排 12345678910111213141516171819202122232425public static void main(String[] args) &#123;\tList&lt;Person&gt; personList = getTestList();\tpersonList.sort(Comparator.comparing(Person::getName, String.CASE_INSENSITIVE_ORDER) .thenComparing(Person::getGid, (a, b) -&gt; b.compareTo(a)) .thenComparingInt(Person::getAge));\tpersonList.stream().forEach(System.out::println);&#125;public static List&lt;Person&gt; getTestList() &#123;\treturn Lists.newArrayList(new Person(&quot;dai&quot;, &quot;301&quot;, 10), new Person(&quot;dai&quot;, &quot;303&quot;, 10), new Person(&quot;dai&quot;, &quot;303&quot;, 8), new Person(&quot;dai&quot;, &quot;303&quot;, 6), new Person(&quot;dai&quot;, &quot;303&quot;, 11), new Person(&quot;dai&quot;, &quot;302&quot;, 9), new Person(&quot;zhang&quot;, &quot;302&quot;, 9), new Person(&quot;zhang&quot;, &quot;301&quot;, 9), new Person(&quot;Li&quot;, &quot;301&quot;, 8));&#125;// 输出结果// Person [name=dai, gid=303, age=6]// Person [name=dai, gid=303, age=8]// Person [name=dai, gid=303, age=10]// Person [name=dai, gid=303, age=11]// Person [name=dai, gid=302, age=9]// Person [name=dai, gid=301, age=10]// Person [name=Li, gid=301, age=8]// Person [name=zhang, gid=302, age=9]// Person [name=zhang, gid=301, age=9] 处理字符串 两个新的方法可在字符串类上使用: join和chars。第一个方法使用指定的分隔符，将任何数量的字符串连接为一个字符串。 12String.join(&quot;:&quot;, &quot;foobar&quot;, &quot;foo&quot;, &quot;bar&quot;);// =&gt; foobar:foo:bar 第二个方法chars从字符串所有字符创建数据流，所以你可以在这些字符上使用流式操作。 1234567&quot;foobar:foo:bar&quot; .chars() .distinct() .mapToObj(c -&gt; String.valueOf((char)c)) .sorted() .collect(Collectors.joining());// =&gt; :abfor 不仅仅是字符串，正则表达式模式串也能受益于数据流。我们可以分割任何模式串，并创建数据流来处理它们，而不是将字符串分割为单个字符的数据流，像下面这样: 123456Pattern.compile(&quot;:&quot;) .splitAsStream(&quot;foobar:foo:bar&quot;) .filter(s -&gt; s.contains(&quot;bar&quot;)) .sorted() .collect(Collectors.joining(&quot;:&quot;));// =&gt; bar:foobar 此外，正则模式串可以转换为谓词。这些谓词可以像下面那样用于过滤字符串流: 12345Pattern pattern = Pattern.compile(&quot;.*@gmail\\\\.com&quot;);Stream.of(&quot;bob@gmail.com&quot;, &quot;alice@hotmail.com&quot;) .filter(pattern.asPredicate()) .count();// =&gt; 1 上面的模式串接受任何以@gmail.com结尾的字符串，并且之后用作Java8的Predicate来过滤电子邮件地址流。 Local Cache实现 123456789101112131415161718192021222324252627282930public class TestLocalCache &#123;\tprivate static ConcurrentHashMap&lt;Integer, Long&gt; cache = new ConcurrentHashMap&lt;&gt;();\tstatic long fibonacci(int i) &#123; if (i == 0) return i; if (i == 1) return 1; return cache.computeIfAbsent(i, (key) -&gt; &#123; System.out.println(&quot;Slow calculation of &quot; + key); return fibonacci(i - 2) + fibonacci(i - 1); &#125;);\t&#125; public static void main(String[] args) &#123; // warm up for (int i = 0; i &lt; 101; i++) System.out.println( &quot;f(&quot; + i + &quot;) = &quot; + fibonacci(i)); // read -&gt; cal long current = System.currentTimeMillis(); System.out.println(fibonacci(100)); System.out.println(System.currentTimeMillis()-current);\t&#125;&#125; 集合–》取元素的一个属性–》去重—》组装成List–》返回 123List&lt;LikeDO&gt; likeDOs=new ArrayList&lt;LikeDO&gt;();List&lt;Long&gt; likeTidList = likeDOs.stream().map(LikeDO::getTid) .distinct().collect(Collectors.toList()); 集合–》按表达式过滤–》遍历、每个元系处理–》放入预先定义的集合中 1234567891011121314 Map&lt;String, StkProduct&gt; newStockName2Product = Maps.newConcurrentMap(); stockProducts.stream().filter(stkProduct -&gt; stkProduct.enabled).forEach(stkProduct -&gt; &#123; String newName = BCConvert.bj2qj(StringUtils.replace(stkProduct.name, &quot; &quot;, &quot;&quot;)); newStockName2Product.put(newName, stkProduct); &#125;);Set&lt;String&gt; qjStockNames;qjStockNames.stream().filter(name -&gt; !acAutomaton.getKey2link().containsKey(name)).forEach(name -&gt; &#123; String value = &quot;&quot;; StkProduct stkProduct = stockNameQj2Product.get(name); if (stkProduct != null) &#123; value = stkProduct.name; &#125; acAutomaton.getKey2link().put(name, value); &#125;); 集合–》map 123456789101112List&lt;ImageModel&gt; imageModelList = null;Map&lt;Long, String&gt; imagesMap = null;imagesMap = imageModelList.stream().collect(Collectors.toMap(ImageModel::getAid, o -&gt; IMAGE_ADDRESS_PREFIX + o.getUrl())); Map&lt;String, String&gt; kvMap = postDetailCacheList.stream().collect(Collectors.toMap((detailCache) -&gt; getBbsSimplePostKey(detailCache.getTid()), JSON::toJSONString));Map&lt;Long, Long&gt; pidToTid；List&lt;String&gt; pidKeyList = pidToTid.entrySet().stream().map((o) -&gt; getKeyBbsReplyPid(o.getValue(), o.getKey())).collect(Collectors.toList()); DO模型—》Model模型 123List&lt;AdDO&gt; adDOList;adDOList.stream().map(adDo -&gt; convertAdModel(adDo)) .collect(Collectors.toList()); phones 是一个List，将相同的元素分组、归类 1234567891011List&lt;String&gt; phones=new ArrayList&lt;String&gt;(); phones.add(&quot;a&quot;); phones.add(&quot;b&quot;); phones.add(&quot;a&quot;); phones.add(&quot;a&quot;); phones.add(&quot;c&quot;); phones.add(&quot;b&quot;); Map&lt;String, List&lt;String&gt;&gt; phoneClassify = phones.stream().collect(Collectors.groupingBy(item -&gt; item)); System.out.println(phoneClassify);返回结果: &#123;a=[a, a, a], b=[b, b], c=[c]&#125; 参考资料 Lambda 表达式的 10 个示例在新窗口打开 learn-java8在新窗口打开 java8-tutorial在新窗口打开 一文让你明白lambda用法与源码分析在新窗口打开 http://blog.csdn.net/renfufei/article/details/24600507在新窗口打开 http://www.oracle.com/webfolder/technetwork/tutorials/obe/java/Lambda-QuickStart/index.html在新窗口打开 Java8 Lambda表达式教程 https://blog.csdn.net/ioriogami/article/details/12782141 Java8 6个问题 https://wizardforcel.gitbooks.io/java8-tutorials/content/Java%208%20%E7%9A%846%E4%B8%AA%E9%97%AE%E9%A2%98.html","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"1.Java8特性知识体系详解","path":"/2023/12/26/1-Java8特性知识体系详解/","content":"Java 8 新特性详解汇总。 Java 新特性的增加都是来源于 JSR或者JEP JSR论坛: https://jcp.org/en/jsr/detail?id=335 知识体系 相关文章函数编程 面向对象编程是对数据进行抽象；函数式编程是对行为进行抽象。 Lambda 表达式的特点 Lambda 表达式使用和Stream下的接口 函数接口定义和使用，四大内置函数接口Consumer，Function，Supplier, Predicate. Comparator排序为例贯穿所有知识点。 详细分析请参看:Java 8 - 函数编程 Optional类 这是一个可以为null的容器对象。如果值存在则isPresent()方法会返回true，调用get()方法会返回该对象。 Optional类的意义 Optional类有哪些常用的方法 Optional举例贯穿所有知识点 多重类嵌套Null值判断 详细分析请参看: Java 8 - Optional类 default方法 默认方法给予我们修改接口而不破坏原来的实现类的结构提供了便利，目前java 8的集合框架已经大量使用了默认方法来改进了，当我们最终开始使用Java 8的lambdas表达式时，提供给我们一个平滑的过渡体验。 为什么会出现默认方法? 接口中出现默认方法，且类可以实现多接口的，那和抽象类有啥区别? 多重实现的默认方法冲突怎么办? 详细分析请参看: Java 8 - default方法 类型注解 那充满争议的类型注解究竟是什么? 复杂还是便捷? 注解在JDK哪个版本中出现的，可以在哪些地方用注解? 什么是类型注解? 类型注解的作用是什么? 为什么会出现类型注解(JSR308)? 详细分析请参看: Java 8 - 类型注解 重复注解 Java8之前对重复注解是怎么做的? Java8对重复注解添加了什么支持? 详细分析请参看: Java 8 - 重复注解 类型推断 导致类型间互相转换的问题困扰着每个java程序员，通过编译器自动推断类型的东西可以稍微缓解一下类型转换太复杂的问题。 什么是泛型? Java7对泛型推断做了哪些优化? Java8对此有做了哪些优化? 详细分析请参看: Java 8 - 类型推断优化 JRE 精简 模块化特性是javaer所期待的特性, 一个占用资源少的JRE运行环境，紧凑的JRE特性的出现，能带来以后的物联网的发展，甚至还是会有大量的java应用程序出现在物联网上面。 为什么精简Java8 JRE，及好处是啥? 紧凑的JRE分3种，分别是compact1、compact2、compact3，他们的关系是? 在不同平台上如何编译等? 详细分析请参看: Java 8 - JRE精简 LocalDate&#x2F;LocalDateTime Date&#x2F;Calendar槽点, java8对其进行了重写。 Java8之前的Date有哪些槽点? (Calendar的所有属性都是可变的，SimpleDateFormat的线程不安全性等) Java8之前使用哪些常用的第三方时间库? Java8关于时间和日期有哪些类和方法，变比Java8之前它的特点是什么? 其它语言时间库? 详细分析请参看: Java 8 - LocalDate&#x2F;LocalDateTime JavaFX JavaFX主要致力于富客户端开发，以弥补swing的缺陷，主要提供图形库与media库，支持audio,video,graphics,animation,3D等，同时采用现代化的css方式支持界面设计。同时又采用XUI方式以XML方式设计UI界面，达到显示与逻辑的分离。 javaFX发展历程? Java8对其增加了哪些特性? 详细分析请参看: Java 8 - JavaFX PermGen移除 PermGen space的全称是Permanent Generation space,是指内存的永久保存区域。PermGen space是Oracle-Sun Hotspot才有，JRockit以及J9是没有这个区域。 Java8之前 “java.lang.OutOfMemoryError: PermGen space”是怎么引起的，怎么解决的? 新增加的元空间(Metaspace)包含哪些东西，画出图 元空间(Metaspace)和PermGen对比 详细分析请参看: Java 8 - 移除Permgen StampedLock 为什么会引入StampedLock 用Lock写悲观锁和乐观锁举例 用StampedLock写悲观锁和乐观锁举例 性能对比 详细分析请参看: Java 8 - StampedLock 其它更新 Java8 还有哪些其它更新 字符串 Base64 Random Nashorn … 详细分析请参看: Java 8 - 其它更新 参考文档 主要参考自以下文档: Java 8 教程汇总 https://wizardforcel.gitbooks.io/java8-tutorials/content/index.html Java8简明教程gitbook https://wizardforcel.gitbooks.io/modern-java Java8简明教程 https://github.com/wizardforcel/modern-java-zh Java8新特性探究 https://wizardforcel.gitbooks.io/java8-new-features/content/","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"13.Java NIO - 零拷贝实现","path":"/2023/12/26/13-Java-NIO-零拷贝实现/","content":"这里转一篇Java NIO 零拷贝的实现文章，在此之前建议先理解什么是Linux中零拷贝，可以先看这篇文章。本文从源码着手分析了 Java NIO 对零拷贝的实现，主要包括基于内存映射（mmap）方式的 MappedByteBuffer 以及基于 sendfile 方式的 FileChannel。最后在篇末简单的阐述了一下 Netty 中的零拷贝机制，以及 RocketMQ 和 Kafka 两种消息队列在零拷贝实现方式上的区别。 Java NIO零拷贝在 Java NIO 中的通道（Channel）**就相当于操作系统的**内核空间**（kernel space）的缓冲区，而缓冲区（Buffer）对应的相当于操作系统的用户空间（user space）中的用户缓冲区**（user buffer）。 通道（Channel）是全双工的（双向传输），它既可能是读缓冲区（read buffer），也可能是网络缓冲区（socket buffer）。 缓冲区（Buffer）分为堆内存（HeapBuffer）和堆外内存（DirectBuffer），这是通过 malloc() 分配出来的用户态内存。 堆外内存（DirectBuffer）在使用后需要应用程序手动回收，而堆内存（HeapBuffer）的数据在 GC 时可能会被自动回收。因此，在使用 HeapBuffer 读写数据时，为了避免缓冲区数据因为 GC 而丢失，NIO 会先把 HeapBuffer 内部的数据拷贝到一个临时的 DirectBuffer 中的本地内存（native memory），这个拷贝涉及到 sun.misc.Unsafe.copyMemory() 的调用，背后的实现原理与 memcpy() 类似。 最后，将临时生成的 DirectBuffer 内部的数据的内存地址传给 I&#x2F;O 调用函数，这样就避免了再去访问 Java 对象处理 I&#x2F;O 读写。 MappedByteBufferMappedByteBuffer 是 NIO 基于内存映射（mmap）这种零拷贝方式的提供的一种实现，它继承自 ByteBuffer。FileChannel 定义了一个 map() 方法，它可以把一个文件从 position 位置开始的 size 大小的区域映射为内存映像文件。抽象方法 map() 方法在 FileChannel 中的定义如下： 12public abstract MappedByteBuffer map(MapMode mode, long position, long size) throws IOException; mode：限定内存映射区域（MappedByteBuffer）对内存映像文件的访问模式，包括只可读（READ_ONLY）、可读可写（READ_WRITE）和写时拷贝（PRIVATE）三种模式。 position：文件映射的起始地址，对应内存映射区域（MappedByteBuffer）的首地址。 size：文件映射的字节长度，从 position 往后的字节数，对应内存映射区域（MappedByteBuffer）的大小。 MappedByteBuffer 相比 ByteBuffer 新增了 fore()、load() 和 isLoad() 三个重要的方法： **fore()**：对于处于 READ_WRITE 模式下的缓冲区，把对缓冲区内容的修改强制刷新到本地文件。 **load()**：将缓冲区的内容载入物理内存中，并返回这个缓冲区的引用。 **isLoaded()**：如果缓冲区的内容在物理内存中，则返回 true，否则返回 false。 下面给出一个利用 MappedByteBuffer 对文件进行读写的使用示例： 123private final static String CONTENT = &quot;Zero copy implemented by MappedByteBuffer&quot;;private final static String FILE_NAME = &quot;/mmap.txt&quot;;private final static String CHARSET = &quot;UTF-8&quot;; 写文件数据：打开文件通道 fileChannel 并提供读权限、写权限和数据清空权限，通过 fileChannel 映射到一个可写的内存缓冲区 mappedByteBuffer，将目标数据写入 mappedByteBuffer，通过 force() 方法把缓冲区更改的内容强制写入本地文件。 123456789101112131415@Testpublic void writeToFileByMappedByteBuffer() &#123; Path path = Paths.get(getClass().getResource(FILE_NAME).getPath()); byte[] bytes = CONTENT.getBytes(Charset.forName(CHARSET)); try (FileChannel fileChannel = FileChannel.open(path, StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.TRUNCATE_EXISTING)) &#123; MappedByteBuffer mappedByteBuffer = fileChannel.map(READ_WRITE, 0, bytes.length); if (mappedByteBuffer != null) &#123; mappedByteBuffer.put(bytes); mappedByteBuffer.force(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 读文件数据：打开文件通道 fileChannel 并提供只读权限，通过 fileChannel 映射到一个只可读的内存缓冲区 mappedByteBuffer，读取 mappedByteBuffer 中的字节数组即可得到文件数据。 12345678910111213141516@Testpublic void readFromFileByMappedByteBuffer() &#123; Path path = Paths.get(getClass().getResource(FILE_NAME).getPath()); int length = CONTENT.getBytes(Charset.forName(CHARSET)).length; try (FileChannel fileChannel = FileChannel.open(path, StandardOpenOption.READ)) &#123; MappedByteBuffer mappedByteBuffer = fileChannel.map(READ_ONLY, 0, length); if (mappedByteBuffer != null) &#123; byte[] bytes = new byte[length]; mappedByteBuffer.get(bytes); String content = new String(bytes, StandardCharsets.UTF_8); assertEquals(content, &quot;Zero copy implemented by MappedByteBuffer&quot;); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 下面介绍 map() 方法的底层实现原理。map() 方法是 java.nio.channels.FileChannel 的抽象方法，由子类 sun.nio.ch.FileChannelImpl.java 实现，下面是和内存映射相关的核心代码： 12345678910111213141516171819202122232425262728public MappedByteBuffer map(MapMode mode, long position, long size) throws IOException &#123; int pagePosition = (int)(position % allocationGranularity); long mapPosition = position - pagePosition; long mapSize = size + pagePosition; try &#123; addr = map0(imode, mapPosition, mapSize); &#125; catch (OutOfMemoryError x) &#123; System.gc(); try &#123; Thread.sleep(100); &#125; catch (InterruptedException y) &#123; Thread.currentThread().interrupt(); &#125; try &#123; addr = map0(imode, mapPosition, mapSize); &#125; catch (OutOfMemoryError y) &#123; throw new IOException(&quot;Map failed&quot;, y); &#125; &#125; int isize = (int)size; Unmapper um = new Unmapper(addr, mapSize, isize, mfd); if ((!writable) || (imode == MAP_RO)) &#123; return Util.newMappedByteBufferR(isize, addr + pagePosition, mfd, um); &#125; else &#123; return Util.newMappedByteBuffer(isize, addr + pagePosition, mfd, um); &#125;&#125; map() 方法通过本地方法 map0() 为文件分配一块虚拟内存，作为它的内存映射区域，然后返回这块内存映射区域的起始地址。 文件映射需要在 Java 堆中创建一个 MappedByteBuffer 的实例。如果第一次文件映射导致 OOM，则手动触发垃圾回收，休眠 100ms 后再尝试映射，如果失败则抛出异常。 通过 Util 的 newMappedByteBuffer （可读可写）方法或者 newMappedByteBufferR（仅读） 方法方法反射创建一个 DirectByteBuffer 实例，其中 DirectByteBuffer 是 MappedByteBuffer 的子类。 map() 方法返回的是内存映射区域的起始地址，通过（起始地址 + 偏移量）就可以获取指定内存的数据。这样一定程度上替代了 read() 或 write() 方法，底层直接采用 sun.misc.Unsafe类的 getByte() 和 putByte() 方法对数据进行读写。 1private native long map0(int prot, long position, long mapSize) throws IOException; 上面是本地方法（native method）map0 的定义，它通过 JNI（Java Native Interface）调用底层 C 的实现，这个 native 函数（Java_sun_nio_ch_FileChannelImpl_map0）的实现位于 JDK 源码包下的 native/sun/nio/ch/FileChannelImpl.c这个源文件里面。 123456789101112131415161718192021222324252627282930313233343536373839JNIEXPORT jlong JNICALLJava_sun_nio_ch_FileChannelImpl_map0(JNIEnv *env, jobject this, jint prot, jlong off, jlong len)&#123; void *mapAddress = 0; jobject fdo = (*env)-&gt;GetObjectField(env, this, chan_fd); jint fd = fdval(env, fdo); int protections = 0; int flags = 0; if (prot == sun_nio_ch_FileChannelImpl_MAP_RO) &#123; protections = PROT_READ; flags = MAP_SHARED; &#125; else if (prot == sun_nio_ch_FileChannelImpl_MAP_RW) &#123; protections = PROT_WRITE | PROT_READ; flags = MAP_SHARED; &#125; else if (prot == sun_nio_ch_FileChannelImpl_MAP_PV) &#123; protections = PROT_WRITE | PROT_READ; flags = MAP_PRIVATE; &#125; mapAddress = mmap64( 0, /* Let OS decide location */ len, /* Number of bytes to map */ protections, /* File permissions */ flags, /* Changes are shared */ fd, /* File descriptor of mapped file */ off); /* Offset into file */ if (mapAddress == MAP_FAILED) &#123; if (errno == ENOMEM) &#123; JNU_ThrowOutOfMemoryError(env, &quot;Map failed&quot;); return IOS_THROWN; &#125; return handle(env, -1, &quot;Map failed&quot;); &#125; return ((jlong) (unsigned long) mapAddress);&#125; 可以看出 map0() 函数最终是通过 mmap64() 这个函数对 Linux 底层内核发出内存映射的调用， mmap64() 函数的原型如下： 123#include &lt;sys/mman.h&gt;void *mmap64(void *addr, size_t len, int prot, int flags, int fd, off64_t offset); 下面详细介绍一下 mmap64() 函数各个参数的含义以及参数可选值： addr：文件在用户进程空间的内存映射区中的起始地址，是一个建议的参数，通常可设置为 0 或 NULL，此时由内核去决定真实的起始地址。当 + flags 为 MAP_FIXED 时，addr 就是一个必选的参数，即需要提供一个存在的地址。 len：文件需要进行内存映射的字节长度 prot 12345678910 ：控制用户进程对内存映射区的访问权限 - `PROT_READ`：读权限 - `PROT_WRITE`：写权限 - `PROT_EXEC`：执行权限 - `PROT_NONE`：无权限- ``` flags ：控制内存映射区的修改是否被多个进程共享 - `MAP_PRIVATE`：对内存映射区数据的修改不会反映到真正的文件，数据修改发生时采用写时复制机制 - `MAP_SHARED`：对内存映射区的修改会同步到真正的文件，修改对共享此内存映射区的进程是可见的 - `MAP_FIXED`：不建议使用，这种模式下 addr 参数指定的必须的提供一个存在的 addr 参数 fd：文件描述符。每次 map 操作会导致文件的引用计数加 1，每次 unmap 操作或者结束进程会导致引用计数减 1 offset：文件偏移量。进行映射的文件位置，从文件起始地址向后的位移量 下面总结一下 MappedByteBuffer 的特点和不足之处： MappedByteBuffer 使用是堆外的虚拟内存，因此分配（map）的内存大小不受 JVM 的 -Xmx 参数限制，但是也是有大小限制的。 如果当文件超出 Integer.MAX_VALUE 字节限制时，可以通过 position 参数重新 map 文件后面的内容。 MappedByteBuffer 在处理大文件时性能的确很高，但也存内存占用、文件关闭不确定等问题，被其打开的文件只有在垃圾回收的才会被关闭，而且这个时间点是不确定的。 MappedByteBuffer 提供了文件映射内存的 mmap() 方法，也提供了释放映射内存的 unmap() 方法。然而 unmap() 是 FileChannelImpl 中的私有方法，无法直接显示调用。因此，用户程序需要通过 Java 反射的调用 sun.misc.Cleaner 类的 clean() 方法手动释放映射占用的内存区域。 123456789101112public static void clean(final Object buffer) throws Exception &#123; AccessController.doPrivileged((PrivilegedAction&lt;Void&gt;) () -&gt; &#123; try &#123; Method getCleanerMethod = buffer.getClass().getMethod(&quot;cleaner&quot;, new Class[0]); getCleanerMethod.setAccessible(true); Cleaner cleaner = (Cleaner) getCleanerMethod.invoke(buffer, new Object[0]); cleaner.clean(); &#125; catch(Exception e) &#123; e.printStackTrace(); &#125; &#125;);&#125; DirectByteBufferDirectByteBuffer 的对象引用位于 Java 内存模型的堆里面，JVM 可以对 DirectByteBuffer 的对象进行内存分配和回收管理，一般使用 DirectByteBuffer 的静态方法 allocateDirect() 创建 DirectByteBuffer 实例并分配内存。 123public static ByteBuffer allocateDirect(int capacity) &#123; return new DirectByteBuffer(capacity);&#125; DirectByteBuffer 内部的字节缓冲区位在于堆外的（用户态）直接内存，它是通过 Unsafe 的本地方法 allocateMemory() 进行内存分配，底层调用的是操作系统的 malloc() 函数。 1234567891011121314151617181920212223DirectByteBuffer(int cap) &#123; super(-1, 0, cap, cap); boolean pa = VM.isDirectMemoryPageAligned(); int ps = Bits.pageSize(); long size = Math.max(1L, (long)cap + (pa ? ps : 0)); Bits.reserveMemory(size, cap); long base = 0; try &#123; base = unsafe.allocateMemory(size); &#125; catch (OutOfMemoryError x) &#123; Bits.unreserveMemory(size, cap); throw x; &#125; unsafe.setMemory(base, size, (byte) 0); if (pa &amp;&amp; (base % ps != 0)) &#123; address = base + ps - (base &amp; (ps - 1)); &#125; else &#123; address = base; &#125; cleaner = Cleaner.create(this, new Deallocator(base, size, cap)); att = null;&#125; 除此之外，初始化 DirectByteBuffer 时还会创建一个 Deallocator 线程，并通过 Cleaner 的 freeMemory() 方法来对直接内存进行回收操作，freeMemory() 底层调用的是操作系统的 free() 函数。 1234567891011121314151617181920212223private static class Deallocator implements Runnable &#123; private static Unsafe unsafe = Unsafe.getUnsafe(); private long address; private long size; private int capacity; private Deallocator(long address, long size, int capacity) &#123; assert (address != 0); this.address = address; this.size = size; this.capacity = capacity; &#125; public void run() &#123; if (address == 0) &#123; return; &#125; unsafe.freeMemory(address); address = 0; Bits.unreserveMemory(size, capacity); &#125;&#125; 由于使用 DirectByteBuffer 分配的是系统本地的内存，不在 JVM 的管控范围之内，因此直接内存的回收和堆内存的回收不同，直接内存如果使用不当，很容易造成 OutOfMemoryError。 说了这么多，那么 DirectByteBuffer 和零拷贝有什么关系？前面有提到在 MappedByteBuffer 进行内存映射时，它的 map() 方法会通过 Util.newMappedByteBuffer() 来创建一个缓冲区实例，初始化的代码如下： 12345678910111213141516171819202122232425262728293031static MappedByteBuffer newMappedByteBuffer(int size, long addr, FileDescriptor fd, Runnable unmapper) &#123; MappedByteBuffer dbb; if (directByteBufferConstructor == null) initDBBConstructor(); try &#123; dbb = (MappedByteBuffer)directByteBufferConstructor.newInstance( new Object[] &#123; new Integer(size), new Long(addr), fd, unmapper &#125;); &#125; catch (InstantiationException | IllegalAccessException | InvocationTargetException e) &#123; throw new InternalError(e); &#125; return dbb;&#125;private static void initDBBRConstructor() &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; try &#123; Class&lt;?&gt; cl = Class.forName(&quot;java.nio.DirectByteBufferR&quot;); Constructor&lt;?&gt; ctor = cl.getDeclaredConstructor( new Class&lt;?&gt;[] &#123; int.class, long.class, FileDescriptor.class, Runnable.class &#125;); ctor.setAccessible(true); directByteBufferRConstructor = ctor; &#125; catch (ClassNotFoundException | NoSuchMethodException | IllegalArgumentException | ClassCastException x) &#123; throw new InternalError(x); &#125; return null; &#125;&#125;);&#125; DirectByteBuffer 是 MappedByteBuffer 的具体实现类。实际上，Util.newMappedByteBuffer() 方法通过反射机制获取 DirectByteBuffer 的构造器，然后创建一个 DirectByteBuffer 的实例，对应的是一个单独用于内存映射的构造方法： 123456protected DirectByteBuffer(int cap, long addr, FileDescriptor fd, Runnable unmapper) &#123; super(-1, 0, cap, cap, fd); address = addr; cleaner = Cleaner.create(this, unmapper); att = null;&#125; 因此，除了允许分配操作系统的直接内存以外，DirectByteBuffer 本身也具有文件内存映射的功能，这里不做过多说明。我们需要关注的是，DirectByteBuffer 在 MappedByteBuffer 的基础上提供了内存映像文件的随机读取 get() 和写入 write() 的操作。 内存映像文件的随机读操作 1234567public byte get() &#123; return ((unsafe.getByte(ix(nextGetIndex()))));&#125;public byte get(int i) &#123; return ((unsafe.getByte(ix(checkIndex(i)))));&#125; 内存映像文件的随机写操作 123456789public ByteBuffer put(byte x) &#123; unsafe.putByte(ix(nextPutIndex()), ((x))); return this;&#125;public ByteBuffer put(int i, byte x) &#123; unsafe.putByte(ix(checkIndex(i)), ((x))); return this;&#125; 内存映像文件的随机读写都是借助 ix() 方法实现定位的， ix() 方法通过内存映射空间的内存首地址（address）和给定偏移量 i 计算出指针地址，然后由 unsafe 类的 get() 和 put() 方法和对指针指向的数据进行读取或写入。 123private long ix(int i) &#123; return address + ((long)i &lt;&lt; 0);&#125; FileChannelFileChannel 是一个用于文件读写、映射和操作的通道，同时它在并发环境下是线程安全的，基于 FileInputStream、FileOutputStream 或者 RandomAccessFile 的 getChannel() 方法可以创建并打开一个文件通道。FileChannel 定义了 transferFrom() 和 transferTo() 两个抽象方法，它通过在通道和通道之间建立连接实现数据传输的。 transferTo()：通过 FileChannel 把文件里面的源数据写入一个 WritableByteChannel 的目的通道。 12public abstract long transferTo(long position, long count, WritableByteChannel target) throws IOException; transferFrom()：把一个源通道 ReadableByteChannel 中的数据读取到当前 FileChannel 的文件里面。 12public abstract long transferFrom(ReadableByteChannel src, long position, long count) throws IOException; 下面给出 FileChannel 利用 transferTo() 和 transferFrom() 方法进行数据传输的使用示例： 1234private static final String CONTENT = &quot;Zero copy implemented by FileChannel&quot;;private static final String SOURCE_FILE = &quot;/source.txt&quot;;private static final String TARGET_FILE = &quot;/target.txt&quot;;private static final String CHARSET = &quot;UTF-8&quot;; 首先在类加载根路径下创建 source.txt 和 target.txt 两个文件，对源文件 source.txt 文件写入初始化数据。 1234567891011@Beforepublic void setup() &#123; Path source = Paths.get(getClassPath(SOURCE_FILE)); byte[] bytes = CONTENT.getBytes(Charset.forName(CHARSET)); try (FileChannel fromChannel = FileChannel.open(source, StandardOpenOption.READ, StandardOpenOption.WRITE, StandardOpenOption.TRUNCATE_EXISTING)) &#123; fromChannel.write(ByteBuffer.wrap(bytes)); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 对于 transferTo() 方法而言，目的通道 toChannel 可以是任意的单向字节写通道 WritableByteChannel；而对于 transferFrom() 方法而言，源通道 fromChannel 可以是任意的单向字节读通道 ReadableByteChannel。其中，FileChannel、SocketChannel 和 DatagramChannel 等通道实现了 WritableByteChannel 和 ReadableByteChannel 接口，都是同时支持读写的双向通道。为了方便测试，下面给出基于 FileChannel 完成 channel-to-channel 的数据传输示例。 通过 transferTo() 将 fromChannel 中的数据拷贝到 toChannel 1234567891011@Testpublic void transferTo() throws Exception &#123; try (FileChannel fromChannel = new RandomAccessFile( getClassPath(SOURCE_FILE), &quot;rw&quot;).getChannel(); FileChannel toChannel = new RandomAccessFile( getClassPath(TARGET_FILE), &quot;rw&quot;).getChannel()) &#123; long position = 0L; long offset = fromChannel.size(); fromChannel.transferTo(position, offset, toChannel); &#125;&#125; 通过 transferFrom() 将 fromChannel 中的数据拷贝到 toChannel 1234567891011@Testpublic void transferFrom() throws Exception &#123; try (FileChannel fromChannel = new RandomAccessFile( getClassPath(SOURCE_FILE), &quot;rw&quot;).getChannel(); FileChannel toChannel = new RandomAccessFile( getClassPath(TARGET_FILE), &quot;rw&quot;).getChannel()) &#123; long position = 0L; long offset = fromChannel.size(); toChannel.transferFrom(fromChannel, position, offset); &#125;&#125; 下面介绍 transferTo() 和 transferFrom() 方法的底层实现原理，这两个方法也是 java.nio.channels.FileChannel 的抽象方法，由子类 sun.nio.ch.FileChannelImpl.java 实现。transferTo() 和 transferFrom() 底层都是基于 sendfile 实现数据传输的，其中 FileChannelImpl.java 定义了 3 个常量，用于标示当前操作系统的内核是否支持 sendfile 以及 sendfile 的相关特性。 123private static volatile boolean transferSupported = true;private static volatile boolean pipeSupported = true;private static volatile boolean fileSupported = true; transferSupported：用于标记当前的系统内核是否支持 sendfile() 调用，默认为 true。 pipeSupported：用于标记当前的系统内核是否支持文件描述符（fd）基于管道（pipe）的 sendfile() 调用，默认为 true。 fileSupported：用于标记当前的系统内核是否支持文件描述符（fd）基于文件（file）的 sendfile() 调用，默认为 true。 下面以 transferTo() 的源码实现为例。FileChannelImpl 首先执行 transferToDirectly() 方法，以 sendfile 的零拷贝方式尝试数据拷贝。如果系统内核不支持 sendfile，进一步执行 transferToTrustedChannel() 方法，以 mmap 的零拷贝方式进行内存映射，这种情况下目的通道必须是 FileChannelImpl 或者 SelChImpl 类型。如果以上两步都失败了，则执行 transferToArbitraryChannel() 方法，基于传统的 I&#x2F;O 方式完成读写，具体步骤是初始化一个临时的 DirectBuffer，将源通道 FileChannel 的数据读取到 DirectBuffer，再写入目的通道 WritableByteChannel 里面。 12345678910111213141516171819202122public long transferTo(long position, long count, WritableByteChannel target) throws IOException &#123; // 计算文件的大小 long sz = size(); // 校验起始位置 if (position &gt; sz) return 0; int icount = (int)Math.min(count, Integer.MAX_VALUE); // 校验偏移量 if ((sz - position) &lt; icount) icount = (int)(sz - position); long n; if ((n = transferToDirectly(position, icount, target)) &gt;= 0) return n; if ((n = transferToTrustedChannel(position, icount, target)) &gt;= 0) return n; return transferToArbitraryChannel(position, icount, target);&#125; 接下来重点分析一下 transferToDirectly() 方法的实现，也就是 transferTo() 通过 sendfile 实现零拷贝的精髓所在。可以看到，transferToDirectlyInternal() 方法先获取到目的通道 WritableByteChannel 的文件描述符 targetFD，获取同步锁然后执行 transferToDirectlyInternal() 方法。 1234567891011121314151617private long transferToDirectly(long position, int icount, WritableByteChannel target) throws IOException &#123; // 省略从target获取targetFD的过程 if (nd.transferToDirectlyNeedsPositionLock()) &#123; synchronized (positionLock) &#123; long pos = position(); try &#123; return transferToDirectlyInternal(position, icount, target, targetFD); &#125; finally &#123; position(pos); &#125; &#125; &#125; else &#123; return transferToDirectlyInternal(position, icount, target, targetFD); &#125;&#125; 最终由 transferToDirectlyInternal() 调用本地方法 transferTo0() ，尝试以 sendfile 的方式进行数据传输。如果系统内核完全不支持 sendfile，比如 Windows 操作系统，则返回 UNSUPPORTED 并把 transferSupported 标识为 false。如果系统内核不支持 sendfile 的一些特性，比如说低版本的 Linux 内核不支持 DMA gather copy 操作，则返回 UNSUPPORTED_CASE 并把 pipeSupported 或者 fileSupported 标识为 false。 123456789101112131415161718192021222324252627282930313233private long transferToDirectlyInternal(long position, int icount, WritableByteChannel target, FileDescriptor targetFD) throws IOException &#123; assert !nd.transferToDirectlyNeedsPositionLock() || Thread.holdsLock(positionLock); long n = -1; int ti = -1; try &#123; begin(); ti = threads.add(); if (!isOpen()) return -1; do &#123; n = transferTo0(fd, position, icount, targetFD); &#125; while ((n == IOStatus.INTERRUPTED) &amp;&amp; isOpen()); if (n == IOStatus.UNSUPPORTED_CASE) &#123; if (target instanceof SinkChannelImpl) pipeSupported = false; if (target instanceof FileChannelImpl) fileSupported = false; return IOStatus.UNSUPPORTED_CASE; &#125; if (n == IOStatus.UNSUPPORTED) &#123; transferSupported = false; return IOStatus.UNSUPPORTED; &#125; return IOStatus.normalize(n); &#125; finally &#123; threads.remove(ti); end (n &gt; -1); &#125;&#125; 本地方法（native method）transferTo0() 通过 JNI（Java Native Interface）调用底层 C 的函数，这个 native 函数（Java_sun_nio_ch_FileChannelImpl_transferTo0）同样位于 JDK 源码包下的 native&#x2F;sun&#x2F;nio&#x2F;ch&#x2F;FileChannelImpl.c 源文件里面。JNI 函数 Java_sun_nio_ch_FileChannelImpl_transferTo0() 基于条件编译对不同的系统进行预编译，下面是 JDK 基于 Linux 系统内核对 transferTo() 提供的调用封装。 12345678910111213141516171819202122232425262728293031323334#if defined(__linux__) || defined(__solaris__)#include &lt;sys/sendfile.h&gt;#elif defined(_AIX)#include &lt;sys/socket.h&gt;#elif defined(_ALLBSD_SOURCE)#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;sys/uio.h&gt;#define lseek64 lseek#define mmap64 mmap#endifJNIEXPORT jlong JNICALLJava_sun_nio_ch_FileChannelImpl_transferTo0(JNIEnv *env, jobject this, jobject srcFDO, jlong position, jlong count, jobject dstFDO)&#123; jint srcFD = fdval(env, srcFDO); jint dstFD = fdval(env, dstFDO);#if defined(__linux__) off64_t offset = (off64_t)position; jlong n = sendfile64(dstFD, srcFD, &amp;offset, (size_t)count); return n;#elif defined(__solaris__) result = sendfilev64(dstFD, &amp;sfv, 1, &amp;numBytes); return result;#elif defined(__APPLE__) result = sendfile(srcFD, dstFD, position, &amp;numBytes, NULL, 0); return result;#endif&#125; 对 Linux、Solaris 以及 Apple 系统而言，transferTo0() 函数底层会执行 sendfile64 这个系统调用完成零拷贝操作，sendfile64() 函数的原型如下： 123#include &lt;sys/sendfile.h&gt;ssize_t sendfile64(int out_fd, int in_fd, off_t *offset, size_t count); 下面简单介绍一下 sendfile64() 函数各个参数的含义： out_fd：待写入的文件描述符 in_fd：待读取的文件描述符 offset：指定 in_fd 对应文件流的读取位置，如果为空，则默认从起始位置开始 count：指定在文件描述符 in_fd 和 out_fd 之间传输的字节数 在 Linux 2.6.3 之前，out_fd 必须是一个 socket，而从 Linux 2.6.3 以后，out_fd 可以是任何文件。也就是说，sendfile64() 函数不仅可以进行网络文件传输，还可以对本地文件实现零拷贝操作。 其它的零拷贝实现Netty零拷贝Netty 中的零拷贝和上面提到的操作系统层面上的零拷贝不太一样, 我们所说的 Netty 零拷贝完全是基于（Java 层面）用户态的，它的更多的是偏向于数据操作优化这样的概念，具体表现在以下几个方面： Netty 通过 DefaultFileRegion 类对 java.nio.channels.FileChannel 的 tranferTo() 方法进行包装，在文件传输时可以将文件缓冲区的数据直接发送到目的通道（Channel） ByteBuf 可以通过 wrap 操作把字节数组、ByteBuf、ByteBuffer 包装成一个 ByteBuf 对象, 进而避免了拷贝操作 ByteBuf 支持 slice 操作, 因此可以将 ByteBuf 分解为多个共享同一个存储区域的 ByteBuf，避免了内存的拷贝 Netty 提供了 CompositeByteBuf 类，它可以将多个 ByteBuf 合并为一个逻辑上的 ByteBuf，避免了各个 ByteBuf 之间的拷贝 其中第 1 条属于操作系统层面的零拷贝操作，后面 3 条只能算用户层面的数据操作优化。 RocketMQ和Kafka对比RocketMQ 选择了 mmap + write 这种零拷贝方式，适用于业务级消息这种小块文件的数据持久化和传输；而 Kafka 采用的是 sendfile 这种零拷贝方式，适用于系统日志消息这种高吞吐量的大块文件的数据持久化和传输。但是值得注意的一点是，Kafka 的索引文件使用的是 mmap + write 方式，数据文件使用的是 sendfile 方式。 参考文章 本文主要整理自 https://zhuanlan.zhihu.com/p/83398714 作者：零壹技术栈","tags":["Java","IO","NIO","零拷贝"],"categories":["Java","IO","NIO"]},{"title":"12.Java N(A)IO - 框架: Netty","path":"/2023/12/26/12-Java-N-A-IO-框架-Netty/","content":"Netty是一个高性能、异步事件驱动的NIO框架，提供了对TCP、UDP和文件传输的支持。作为当前最流行的NIO框架，Netty在互联网领域、大数据分布式计算领域、游戏行业、通信行业等获得了广泛的应用，一些业界著名的开源组件也基于Netty构建，比如RPC框架、zookeeper等。@pdai NIO框架目前流行的NIO框架非常的多。在论坛上、互联网上大家讨论和使用最多的有以下几种: 原生JAVA NIO框架: JAVA NIO通信框架基于多路复用IO原理，我们将详细讲解它的工作原理。 APACHE MINA 2: 是一个网络应用程序框架，用来帮助用户简单地开发高性能和高可扩展性的网络应用程序。它提供了一个通过Java NIO在不同的传输例如TCP&#x2F;IP和UDP&#x2F;IP上抽象的事件驱动的异步API。 NETTY 4&#x2F;5: Netty是由JBOSS提供的一个java开源框架。Netty提供异步的、事件驱动的网络应用程序框架和工具，用以快速开发高性能、高可靠性的网络服务器和客户端程序。我们将讲解NETTY 4 的工作原理。另外说一句: MINA和NETTY的主要作者是同一人Trustin Lee。 Grizzly: Grizzly是一种应用程序框架，专门解决编写成千上万用户访问服务器时候产生的各种问题。使用JAVA NIO作为基础，并隐藏其编程的复杂性。 比较好的基于NIO的开源框架(Netty)优点 api简单，开发门槛低 功能强大，内置了多种编码、解码功能 与其它业界主流的NIO框架对比，netty的综合性能最优 社区活跃，使用广泛，经历过很多商业应用项目的考验 定制能力强，可以对框架进行灵活的扩展 例子12345&lt;dependency&gt; &lt;groupId&gt;org.jboss.netty&lt;/groupId&gt; &lt;artifactId&gt;netty&lt;/artifactId&gt; &lt;version&gt;3.2.5.Final&lt;/version&gt;&lt;/dependency&gt; 服务端。接收客户端请求并将内容打印出来，同时发送一个消息收到回执。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class NettyServer &#123; private static int HEADER_LENGTH = 4; public void bind(int port) throws Exception &#123; ServerBootstrap b = new ServerBootstrap(new NioServerSocketChannelFactory(Executors.newCachedThreadPool(), Executors.newCachedThreadPool())); // 构造对应的pipeline b.setPipelineFactory(new ChannelPipelineFactory() &#123; public ChannelPipeline getPipeline() throws Exception &#123; ChannelPipeline pipelines = Channels.pipeline(); pipelines.addLast(MessageHandler.class.getName(), new MessageHandler()); return pipelines; &#125; &#125;); // 监听端口号 b.bind(new InetSocketAddress(port)); &#125; // 处理消息 static class MessageHandler extends SimpleChannelHandler &#123; public void messageReceived(ChannelHandlerContext ctx, MessageEvent e) throws Exception &#123; // 接收客户端请求 ChannelBuffer buffer = (ChannelBuffer) e.getMessage(); String message = new String(buffer.readBytes(buffer.readableBytes()).array(), &quot;UTF-8&quot;); System.out.println(&quot;&lt;服务端&gt;收到内容=&quot; + message); // 给客户端发送回执 byte[] body = &quot;服务端已收到&quot;.getBytes(); byte[] header = ByteBuffer.allocate(HEADER_LENGTH).order(ByteOrder.BIG_ENDIAN).putInt(body.length).array(); Channels.write(ctx.getChannel(), ChannelBuffers.wrappedBuffer(header, body)); System.out.println(&quot;&lt;服务端&gt;发送回执,time=&quot; + System.currentTimeMillis()); &#125; &#125; public static void main(String[] args) &#123; try &#123; new NettyServer().bind(1088); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; ; &#125;&#125; 客户端。向服务端发送一个请求，然后打印服务端响应的内容。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class NettyClient &#123; private final ByteBuffer readHeader = ByteBuffer.allocate(4).order(ByteOrder.BIG_ENDIAN); private final ByteBuffer writeHeader = ByteBuffer.allocate(4).order(ByteOrder.BIG_ENDIAN); private SocketChannel channel; public void sendMessage(byte[] body) throws Exception &#123; // 创建客户端通道 channel = SocketChannel.open(); channel.socket().setSoTimeout(60000); channel.connect(new InetSocketAddress(AddressUtils.getHostIp(), 1088)); // 客户端发请求 writeWithHeader(channel, body); // 接收服务端响应的信息 readHeader.clear(); read(channel, readHeader); int bodyLen = readHeader.getInt(0); ByteBuffer bodyBuf = ByteBuffer.allocate(bodyLen).order(ByteOrder.BIG_ENDIAN); read(channel, bodyBuf); System.out.println(&quot;&lt;客户端&gt;收到响应内容: &quot; + new String(bodyBuf.array(), &quot;UTF-8&quot;) + &quot;,长度:&quot; + bodyLen); &#125; private void writeWithHeader(SocketChannel channel, byte[] body) throws IOException &#123; writeHeader.clear(); writeHeader.putInt(body.length); writeHeader.flip(); // channel.write(writeHeader); channel.write(ByteBuffer.wrap(body)); &#125; private void read(SocketChannel channel, ByteBuffer buffer) throws IOException &#123; while (buffer.hasRemaining()) &#123; int r = channel.read(buffer); if (r == -1) &#123; throw new IOException(&quot;end of stream when reading header&quot;); &#125; &#125; &#125; public static void main(String[] args) &#123; String body = &quot;客户发的测试请求！&quot;; try &#123; new NettyClient().sendMessage(body.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 参考文章 https://blog.csdn.net/yinwenjie/article/details/48829419 https://blog.csdn.net/yinwenjie/article/details/48969853 Netty入门简介","tags":["Java","IO","NIO","Netty"],"categories":["Java","IO","NIO","Netty"]},{"title":"11.Java AIO - 异步IO详解","path":"/2023/12/26/11-Java-AIO-异步IO详解/","content":"本文主要对异步IO和Java中对AIO的支持详解。 异步IO上面两篇文章中，我们分别讲解了阻塞式同步IO、非阻塞式同步IO、多路复用IO 这三种IO模型，以及JAVA对于这三种IO模型的支持。重点说明了IO模型是由操作系统提供支持，且这三种IO模型都是同步IO，都是采用的“应用程序不询问我，我绝不会主动通知”的方式。 异步IO则是采用“订阅-通知”模式: 即应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，在主动通知应用程序，触发相应的函数: 和同步IO一样，异步IO也是由操作系统进行支持的。微软的windows系统提供了一种异步IO技术: IOCP(I&#x2F;O Completion Port，I&#x2F;O完成端口)； Linux下由于没有这种异步IO技术，所以使用的是epoll(上文介绍过的一种多路复用IO技术的实现)对异步IO进行模拟。 JAVA对AIO的支持JAVA AIO框架简析 这里通过这个结构分析要告诉各位读者JAVA AIO中类设计和操作系统的相关性 在文中我们一再说明JAVA AIO框架在windows下使用windows IOCP技术，在Linux下使用epoll多路复用IO技术模拟异步IO，这个从JAVA AIO框架的部分类设计上就可以看出来。例如框架中，在Windows下负责实现套接字通道的具体类是“sun.nio.ch.WindowsAsynchronousSocketChannelImpl”，其引用的IOCP类型文档注释如是: 1234/** * Windows implementation of AsynchronousChannelGroup encapsulating an I/O * completion port. */ 如果您感兴趣，当然可以去看看全部完整代码(建议从“java.nio.channels.spi.AsynchronousChannelProvider”这个类看起)。 特别说明一下，请注意图中的“java.nio.channels.NetworkChannel”接口，这个接口同样被JAVA NIO框架实现了，如下图所示: 代码实例下面，我们通过一个代码示例，来讲解JAVA AIO框架的具体使用，先上代码，在针对代码编写和运行中的要点进行讲解: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197package testASocket;import java.io.IOException;import java.io.UnsupportedEncodingException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.AsynchronousChannelGroup;import java.nio.channels.AsynchronousServerSocketChannel;import java.nio.channels.AsynchronousSocketChannel;import java.nio.channels.CompletionHandler;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.apache.log4j.BasicConfigurator;/** * @author yinwenjie */public class SocketServer &#123; static &#123; BasicConfigurator.configure(); &#125; private static final Object waitObject = new Object(); /** * @param args * @throws Exception */ public static void main(String[] args) throws Exception &#123; /* * 对于使用的线程池技术，我一定要多说几句 * 1、Executors是线程池生成工具，通过这个工具我们可以很轻松的生成“固定大小的线程池”、“调度池”、“可伸缩线程数量的池”。具体请看API Doc * 2、当然您也可以通过ThreadPoolExecutor直接生成池。 * 3、这个线程池是用来得到操作系统的“IO事件通知”的，不是用来进行“得到IO数据后的业务处理的”。要进行后者的操作，您可以再使用一个池(最好不要混用) * 4、您也可以不使用线程池(不推荐)，如果决定不使用线程池，直接AsynchronousServerSocketChannel.open()就行了。 * */ ExecutorService threadPool = Executors.newFixedThreadPool(20); AsynchronousChannelGroup group = AsynchronousChannelGroup.withThreadPool(threadPool); final AsynchronousServerSocketChannel serverSocket = AsynchronousServerSocketChannel.open(group); //设置要监听的端口“0.0.0.0”代表本机所有IP设备 serverSocket.bind(new InetSocketAddress(&quot;0.0.0.0&quot;, 83)); //为AsynchronousServerSocketChannel注册监听，注意只是为AsynchronousServerSocketChannel通道注册监听 //并不包括为 随后客户端和服务器 socketchannel通道注册的监听 serverSocket.accept(null, new ServerSocketChannelHandle(serverSocket)); //等待，以便观察现象(这个和要讲解的原理本身没有任何关系，只是为了保证守护线程不会退出) synchronized(waitObject) &#123; waitObject.wait(); &#125; &#125;&#125;/** * 这个处理器类，专门用来响应 ServerSocketChannel 的事件。 * @author yinwenjie */class ServerSocketChannelHandle implements CompletionHandler&lt;AsynchronousSocketChannel, Void&gt; &#123; /** * 日志 */ private static final Log LOGGER = LogFactory.getLog(ServerSocketChannelHandle.class); private AsynchronousServerSocketChannel serverSocketChannel; /** * @param serverSocketChannel */ public ServerSocketChannelHandle(AsynchronousServerSocketChannel serverSocketChannel) &#123; this.serverSocketChannel = serverSocketChannel; &#125; /** * 注意，我们分别观察 this、socketChannel、attachment三个对象的id。 * 来观察不同客户端连接到达时，这三个对象的变化，以说明ServerSocketChannelHandle的监听模式 */ @Override public void completed(AsynchronousSocketChannel socketChannel, Void attachment) &#123; ServerSocketChannelHandle.LOGGER.info(&quot;completed(AsynchronousSocketChannel result, ByteBuffer attachment)&quot;); //每次都要重新注册监听(一次注册，一次响应)，但是由于“文件状态标示符”是独享的，所以不需要担心有“漏掉的”事件 this.serverSocketChannel.accept(attachment, this); //为这个新的socketChannel注册“read”事件，以便操作系统在收到数据并准备好后，主动通知应用程序 //在这里，由于我们要将这个客户端多次传输的数据累加起来一起处理，所以我们将一个stringbuffer对象作为一个“附件”依附在这个channel上 // ByteBuffer readBuffer = ByteBuffer.allocate(50); socketChannel.read(readBuffer, new StringBuffer(), new SocketChannelReadHandle(socketChannel , readBuffer)); &#125; /* (non-Javadoc) * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object) */ @Override public void failed(Throwable exc, Void attachment) &#123; ServerSocketChannelHandle.LOGGER.info(&quot;failed(Throwable exc, ByteBuffer attachment)&quot;); &#125;&#125;/** * 负责对每一个socketChannel的数据获取事件进行监听。&lt;p&gt; * * 重要的说明: 一个socketchannel都会有一个独立工作的SocketChannelReadHandle对象(CompletionHandler接口的实现)， * 其中又都将独享一个“文件状态标示”对象FileDescriptor、 * 一个独立的由程序员定义的Buffer缓存(这里我们使用的是ByteBuffer)、 * 所以不用担心在服务器端会出现“窜对象”这种情况，因为JAVA AIO框架已经帮您组织好了。&lt;p&gt; * * 但是最重要的，用于生成channel的对象: AsynchronousChannelProvider是单例模式，无论在哪组socketchannel， * 对是一个对象引用(但这没关系，因为您不会直接操作这个AsynchronousChannelProvider对象)。 * @author yinwenjie */class SocketChannelReadHandle implements CompletionHandler&lt;Integer, StringBuffer&gt; &#123; /** * 日志 */ private static final Log LOGGER = LogFactory.getLog(SocketChannelReadHandle.class); private AsynchronousSocketChannel socketChannel; /** * 专门用于进行这个通道数据缓存操作的ByteBuffer&lt;br&gt; * 当然，您也可以作为CompletionHandler的attachment形式传入。&lt;br&gt; * 这是，在这段示例代码中，attachment被我们用来记录所有传送过来的Stringbuffer了。 */ private ByteBuffer byteBuffer; public SocketChannelReadHandle(AsynchronousSocketChannel socketChannel , ByteBuffer byteBuffer) &#123; this.socketChannel = socketChannel; this.byteBuffer = byteBuffer; &#125; /* (non-Javadoc) * @see java.nio.channels.CompletionHandler#completed(java.lang.Object, java.lang.Object) */ @Override public void completed(Integer result, StringBuffer historyContext) &#123; //如果条件成立，说明客户端主动终止了TCP套接字，这时服务端终止就可以了 if(result == -1) &#123; try &#123; this.socketChannel.close(); &#125; catch (IOException e) &#123; SocketChannelReadHandle.LOGGER.error(e); &#125; return; &#125; SocketChannelReadHandle.LOGGER.info(&quot;completed(Integer result, Void attachment) : 然后我们来取出通道中准备好的值&quot;); /* * 实际上，由于我们从Integer result知道了本次channel从操作系统获取数据总长度 * 所以实际上，我们不需要切换成“读模式”的，但是为了保证编码的规范性，还是建议进行切换。 * * 另外，无论是JAVA AIO框架还是JAVA NIO框架，都会出现“buffer的总容量”小于“当前从操作系统获取到的总数据量”， * 但区别是，JAVA AIO框架中，我们不需要专门考虑处理这样的情况，因为JAVA AIO框架已经帮我们做了处理(做成了多次通知) * */ this.byteBuffer.flip(); byte[] contexts = new byte[1024]; this.byteBuffer.get(contexts, 0, result); this.byteBuffer.clear(); try &#123; String nowContent = new String(contexts , 0 , result , &quot;UTF-8&quot;); historyContext.append(nowContent); SocketChannelReadHandle.LOGGER.info(&quot;================目前的传输结果: &quot; + historyContext); &#125; catch (UnsupportedEncodingException e) &#123; SocketChannelReadHandle.LOGGER.error(e); &#125; //如果条件成立，说明还没有接收到“结束标记” if(historyContext.indexOf(&quot;over&quot;) == -1) &#123; return; &#125; //========================================================================= // 和上篇文章的代码相同，我们以“over”符号作为客户端完整信息的标记 //========================================================================= SocketChannelReadHandle.LOGGER.info(&quot;=======收到完整信息，开始处理业务=========&quot;); historyContext = new StringBuffer(); //还要继续监听(一次监听一次通知) this.socketChannel.read(this.byteBuffer, historyContext, this); &#125; /* (non-Javadoc) * @see java.nio.channels.CompletionHandler#failed(java.lang.Throwable, java.lang.Object) */ @Override public void failed(Throwable exc, StringBuffer historyContext) &#123; SocketChannelReadHandle.LOGGER.info(&quot;=====发现客户端异常关闭，服务器将关闭TCP通道&quot;); try &#123; this.socketChannel.close(); &#125; catch (IOException e) &#123; SocketChannelReadHandle.LOGGER.error(e); &#125; &#125;&#125; 要点讲解注意在JAVA NIO框架中，我们说到了一个重要概念“selector”(选择器)。它负责代替应用查询中所有已注册的通道到操作系统中进行IO事件轮询、管理当前注册的通道集合，定位发生事件的通道等操操作；但是在JAVA AIO框架中，由于应用程序不是“轮询”方式，而是订阅-通知方式，所以不再需要“selector”(选择器)了，改由channel通道直接到操作系统注册监听。 JAVA AIO框架中，只实现了两种网络IO通道“AsynchronousServerSocketChannel”(服务器监听通道)、“AsynchronousSocketChannel”(socket套接字通道)。但是无论哪种通道他们都有独立的fileDescriptor(文件标识符)、attachment(附件，附件可以使任意对象，类似“通道上下文”)，并被独立的SocketChannelReadHandle类实例引用。我们通过debug操作来看看它们的引用结构: 在测试过程中，我们启动了两个客户端(客户端用什么语言来写都行，用阻塞或者非阻塞方式也都行，只要是支持 TCP Socket套接字的就行，然后我们观察服务器端对这两个客户端通道的处理情况: 可以看到，在服务器端分别为客户端1和客户端2创建的两个WindowsAsynchronousSocketChannelImpl对象为: 客户端1: WindowsAsynchronousSocketChannelImpl: 760 | FileDescriptor: 762 客户端2: WindowsAsynchronousSocketChannelImpl: 792 | FileDescriptor: 797 接下来，我们让两个客户端发送信息到服务器端，并观察服务器端的处理情况。客户端1发来的消息和客户端2发来的消息，在服务器端的处理情况如下图所示: 客户端1: WindowsAsynchronousSocketChannelImpl: 760 | FileDescriptor: 762 | SocketChannelReadHandle: 803 | HeapByteBuffer: 808 客户端2: WindowsAsynchronousSocketChannelImpl: 792 | FileDescriptor: 797 | SocketChannelReadHandle: 828 | HeapByteBuffer: 833 可以明显看到，服务器端处理每一个客户端通道所使用的SocketChannelReadHandle(处理器)对象都是独立的，并且所引用的SocketChannel对象都是独立的。 JAVA NIO和JAVA AIO框架，除了因为操作系统的实现不一样而去掉了Selector外，其他的重要概念都是存在的，例如上文中提到的Channel的概念，还有演示代码中使用的Buffer缓存方式。实际上JAVA NIO和JAVA AIO框架您可以看成是一套完整的“高并发IO处理”的实现。 还有改进可能当然，以上代码是示例代码，目标是为了让您了解JAVA AIO框架的基本使用。所以它还有很多改造的空间，例如: 在生产环境下，我们需要记录这个通道上“用户的登录信息”。那么这个需求可以使用JAVA AIO中的“附件”功能进行实现。 记住JAVA AIO 和 JAVA NIO 框架都是要使用线程池的(当然您也可以不用)，线程池的使用原则，一定是只有业务处理部分才使用，使用后马上结束线程的执行(还回线程池或者消灭它)。JAVA AIO框架中还有一个线程池，是拿给“通知处理器”使用的，这是因为JAVA AIO框架是基于“订阅-通知”模型的，“订阅”操作可以由主线程完成，但是您总不能要求在应用程序中并发的“通知”操作也在主线程上完成吧_。 最好的改进方式，当然就是使用Netty或者Mina咯。 为什么还有Netty 那么有的读者可能就会问，既然JAVA NIO &#x2F; JAVA AIO已经实现了各主流操作系统的底层支持，那么为什么现在主流的JAVA NIO技术会是Netty和MINA呢? 答案很简单: 因为更好用，这里举几个方面的例子: 虽然JAVA NIO 和 JAVA AIO框架提供了 多路复用IO&#x2F;异步IO的支持，但是并没有提供上层“信息格式”的良好封装。例如前两者并没有提供针对 Protocol Buffer、JSON这些信息格式的封装，但是Netty框架提供了这些数据格式封装(基于责任链模式的编码和解码功能) 要编写一个可靠的、易维护的、高性能的(注意它们的排序)NIO&#x2F;AIO 服务器应用。除了框架本身要兼容实现各类操作系统的实现外。更重要的是它应该还要处理很多上层特有服务，例如: 客户端的权限、还有上面提到的信息格式封装、简单的数据读取。这些Netty框架都提供了响应的支持。 JAVA NIO框架存在一个poll&#x2F;epoll bug: Selector doesn’t block on Selector.select(timeout)，不能block意味着CPU的使用率会变成100%(这是底层JNI的问题，上层要处理这个异常实际上也好办)。当然这个bug只有在Linux内核上才能重现。 这个问题在JDK 1.7版本中还没有被完全解决: http://bugs.java.com/bugdatabase/view_bug.do?bug_id=2147719。虽然Netty 4.0中也是基于JAVA NIO框架进行封装的(上文中已经给出了Netty中NioServerSocketChannel类的介绍)，但是Netty已经将这个bug进行了处理。 其他原因，用过Netty后，您就可以自己进行比较了。 参考文章 文章主要来源于: 银文杰，笔名“说好不能打脸”，博客地址。他的书《高性能服务系统构建与实战》。 https://blog.csdn.net/yinwenjie/article/details/48784375","tags":["Java","IO","AIO"],"categories":["Java","IO","AIO"]},{"title":"9.Java NIO - 基础详解","path":"/2023/12/26/9-Java-NIO-基础详解/","content":"新的输入&#x2F;输出 (NIO) 库是在 JDK 1.4 中引入的，弥补了原来的 I&#x2F;O 的不足，提供了高速的、面向块的 I&#x2F;O。 NIO 不单单是 New IO，个人认为解释为 No-Blocking IO 更为贴切 Standard IO是对字节流的读写，在进行IO之前，首先创建一个流对象，流对象进行读写操作都是按字节 ，一个字节一个字节的来读或写。而NIO把IO抽象成块，类似磁盘的读写，每次IO操作的单位都是一个块，块被读入内存之后就是一个byte[]，NIO一次可以读或写多个字节。 流与块I&#x2F;O 与 NIO 最重要的区别是数据打包和传输的方式，I&#x2F;O 以流的方式处理数据，而 NIO 以块的方式处理数据。 面向流的 I&#x2F;O 一次处理一个字节数据: 一个输入流产生一个字节数据，一个输出流消费一个字节数据。为流式数据创建过滤器非常容易，链接几个过滤器，以便每个过滤器只负责复杂处理机制的一部分。不利的一面是，面向流的 I&#x2F;O 通常相当慢。 面向块的 I&#x2F;O 一次处理一个数据块，按块处理数据比按流处理数据要快得多。但是面向块的 I&#x2F;O 缺少一些面向流的 I&#x2F;O 所具有的优雅性和简单性。 I&#x2F;O 包和 NIO 已经很好地集成了，java.io.* 已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。例如，java.io.* 包中的一些类包含以块的形式读写数据的方法，这使得即使在面向流的系统中，处理速度也会更快。 通道与缓冲区1. 通道通道 Channel 是对原 I&#x2F;O 包中的流的模拟，可以通过它读取和写入数据。 通道与流的不同之处在于，流只能在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)，而通道是双向的，可以用于读、写或者同时用于读写。 通道包括以下类型: FileChannel: 从文件中读写数据； DatagramChannel: 通过 UDP 读写网络中数据； SocketChannel: 通过 TCP 读写网络中数据； ServerSocketChannel: 可以监听新进来的 TCP 连接，对每一个新进来的连接都会创建一个 SocketChannel。 2. 缓冲区发送给一个通道的所有数据都必须首先放到缓冲区中，同样地，从通道中读取的任何数据都要先读到缓冲区中。也就是说，不会直接对通道进行读写数据，而是要先经过缓冲区。 缓冲区实质上是一个数组，但它不仅仅是一个数组。缓冲区提供了对数据的结构化访问，而且还可以跟踪系统的读&#x2F;写进程。 缓冲区包括以下类型: ByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer FloatBuffer DoubleBuffer 缓冲区状态变量 capacity: 最大容量； position: 当前已经读写的字节数； limit: 还可以读写的字节数。 状态变量的改变过程举例: ① 新建一个大小为 8 个字节的缓冲区，此时 position 为 0，而 limit &#x3D; capacity &#x3D; 8。capacity 变量不会改变，下面的讨论会忽略它。 ② 从输入通道中读取 5 个字节数据写入缓冲区中，此时 position 移动设置为 5，limit 保持不变。 ③ 在将缓冲区的数据写到输出通道之前，需要先调用 flip() 方法，这个方法将 limit 设置为当前 position，并将 position 设置为 0。 ④ 从缓冲区中取 4 个字节到输出缓冲中，此时 position 设为 4。 ⑤ 最后需要调用 clear() 方法来清空缓冲区，此时 position 和 limit 都被设置为最初位置。 文件 NIO 实例以下展示了使用 NIO 快速复制文件的实例: 12345678910111213141516171819202122232425262728293031323334353637public static void fastCopy(String src, String dist) throws IOException &#123; /* 获得源文件的输入字节流 */ FileInputStream fin = new FileInputStream(src); /* 获取输入字节流的文件通道 */ FileChannel fcin = fin.getChannel(); /* 获取目标文件的输出字节流 */ FileOutputStream fout = new FileOutputStream(dist); /* 获取输出字节流的通道 */ FileChannel fcout = fout.getChannel(); /* 为缓冲区分配 1024 个字节 */ ByteBuffer buffer = ByteBuffer.allocateDirect(1024); while (true) &#123; /* 从输入通道中读取数据到缓冲区中 */ int r = fcin.read(buffer); /* read() 返回 -1 表示 EOF */ if (r == -1) &#123; break; &#125; /* 切换读写 */ buffer.flip(); /* 把缓冲区的内容写入输出文件中 */ fcout.write(buffer); /* 清空缓冲区 */ buffer.clear(); &#125;&#125; 选择器NIO 常常被叫做非阻塞 IO，主要是因为 NIO 在网络通信中的非阻塞特性被广泛使用。 NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。 通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。 因为创建和切换线程的开销很大，因此使用一个线程来处理多个事件而不是一个线程处理一个事件具有更好的性能。 应该注意的是，只有套接字 Channel 才能配置为非阻塞，而 FileChannel 不能，为 FileChannel 配置非阻塞也没有意义。 1. 创建选择器1Selector selector = Selector.open(); 2. 将通道注册到选择器上123ServerSocketChannel ssChannel = ServerSocketChannel.open();ssChannel.configureBlocking(false);ssChannel.register(selector, SelectionKey.OP_ACCEPT); 通道必须配置为非阻塞模式，否则使用选择器就没有任何意义了，因为如果通道在某个事件上被阻塞，那么服务器就不能响应其它事件，必须等待这个事件处理完毕才能去处理其它事件，显然这和选择器的作用背道而驰。 在将通道注册到选择器上时，还需要指定要注册的具体事件，主要有以下几类: SelectionKey.OP_CONNECT SelectionKey.OP_ACCEPT SelectionKey.OP_READ SelectionKey.OP_WRITE 它们在 SelectionKey 的定义如下: 1234public static final int OP_READ = 1 &lt;&lt; 0;public static final int OP_WRITE = 1 &lt;&lt; 2;public static final int OP_CONNECT = 1 &lt;&lt; 3;public static final int OP_ACCEPT = 1 &lt;&lt; 4; 可以看出每个事件可以被当成一个位域，从而组成事件集整数。例如: 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; 3. 监听事件1int num = selector.select(); 使用 select() 来监听到达的事件，它会一直阻塞直到有至少一个事件到达。 4. 获取到达的事件1234567891011Set&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove();&#125; 5. 事件循环因为一次 select() 调用不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理事件的代码一般会放在一个死循环内。 1234567891011121314while (true) &#123; int num = selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; // ... &#125; else if (key.isReadable()) &#123; // ... &#125; keyIterator.remove(); &#125;&#125; 套接字 NIO 实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081public class NIOServer &#123; public static void main(String[] args) throws IOException &#123; Selector selector = Selector.open(); ServerSocketChannel ssChannel = ServerSocketChannel.open(); ssChannel.configureBlocking(false); ssChannel.register(selector, SelectionKey.OP_ACCEPT); ServerSocket serverSocket = ssChannel.socket(); InetSocketAddress address = new InetSocketAddress(&quot;127.0.0.1&quot;, 8888); serverSocket.bind(address); while (true) &#123; selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator(); while (keyIterator.hasNext()) &#123; SelectionKey key = keyIterator.next(); if (key.isAcceptable()) &#123; ServerSocketChannel ssChannel1 = (ServerSocketChannel) key.channel(); // 服务器会为每个新连接创建一个 SocketChannel SocketChannel sChannel = ssChannel1.accept(); sChannel.configureBlocking(false); // 这个新连接主要用于从客户端读取数据 sChannel.register(selector, SelectionKey.OP_READ); &#125; else if (key.isReadable()) &#123; SocketChannel sChannel = (SocketChannel) key.channel(); System.out.println(readDataFromSocketChannel(sChannel)); sChannel.close(); &#125; keyIterator.remove(); &#125; &#125; &#125; private static String readDataFromSocketChannel(SocketChannel sChannel) throws IOException &#123; ByteBuffer buffer = ByteBuffer.allocate(1024); StringBuilder data = new StringBuilder(); while (true) &#123; buffer.clear(); int n = sChannel.read(buffer); if (n == -1) &#123; break; &#125; buffer.flip(); int limit = buffer.limit(); char[] dst = new char[limit]; for (int i = 0; i &lt; limit; i++) &#123; dst[i] = (char) buffer.get(i); &#125; data.append(dst); buffer.clear(); &#125; return data.toString(); &#125;&#125;public class NIOClient &#123; public static void main(String[] args) throws IOException &#123; Socket socket = new Socket(&quot;127.0.0.1&quot;, 8888); OutputStream out = socket.getOutputStream(); String s = &quot;hello world&quot;; out.write(s.getBytes()); out.close(); &#125;&#125; 内存映射文件内存映射文件 I&#x2F;O 是一种读和写文件数据的方法，它可以比常规的基于流或者基于通道的 I&#x2F;O 快得多。 向内存映射文件写入可能是危险的，只是改变数组的单个元素这样的简单操作，就可能会直接修改磁盘上的文件。修改数据与将数据保存到磁盘是没有分开的。 下面代码行将文件的前 1024 个字节映射到内存中，map() 方法返回一个 MappedByteBuffer，它是 ByteBuffer 的子类。因此，可以像使用其他任何 ByteBuffer 一样使用新映射的缓冲区，操作系统会在需要时负责执行映射。 1MappedByteBuffer mbb = fc.map(FileChannel.MapMode.READ_WRITE, 0, 1024); 对比NIO 与普通 I&#x2F;O 的区别主要有以下两点: NIO 是非阻塞的 NIO 面向块，I&#x2F;O 面向流 参考文章 Java NIO Tutorial在新窗口打开 Java NIO 浅析在新窗口打开 IBM: NIO 入门在新窗口打开 Eckel B, 埃克尔, 昊鹏, 等. Java 编程思想 [M]. 机械工业出版社, 2002. IBM: NIO 入门在新窗口打开 IBM: 深入分析 Java I&#x2F;O 的工作机制在新窗口打开 IBM: 深入分析 Java 中的中文编码问题在新窗口打开 IBM: Java 序列化的高级认识在新窗口打开 NIO 与传统 IO 的区别在新窗口打开 Decorator Design Pattern在新窗口打开 Socket Multicast在新窗口打开","tags":["Java","IO","NIO"],"categories":["Java","IO","NIO"]},{"title":"8.Java IO - BIO 详解","path":"/2023/12/26/8-Java-IO-BIO-详解/","content":"BIO就是: blocking IO。最容易理解、最容易实现的IO工作方式，应用程序向操作系统请求网络IO操作，这时应用程序会一直等待；另一方面，操作系统收到请求后，也会等待，直到网络上有数据传到监听端口；操作系统在收集数据后，会把数据发送给应用程序；最后应用程序受到数据，并解除等待状态。 几个重要概念 阻塞IO 和 非阻塞IO 这两个概念是程序级别的。主要描述的是程序请求操作系统IO操作后，如果IO资源没有准备好，那么程序该如何处理的问题: 前者等待；后者继续执行(并且使用线程一直轮询，直到有IO资源准备好了) 同步IO 和 非同步IO 这两个概念是操作系统级别的。主要描述的是操作系统在收到程序请求IO操作后，如果IO资源没有准备好，该如何响应程序的问题: 前者不响应，直到IO资源准备好以后；后者返回一个标记(好让程序和自己知道以后的数据往哪里通知)，当IO资源准备好以后，再用事件机制返回给程序。 传统的BIO通信方式简介以前大多数网络通信方式都是阻塞模式的，即: 客户端向服务器端发出请求后，客户端会一直等待(不会再做其他事情)，直到服务器端返回结果或者网络出现问题。 服务器端同样的，当在处理某个客户端A发来的请求时，另一个客户端B发来的请求会等待，直到服务器端的这个处理线程完成上一个处理。 传统的BIO的问题 同一时间，服务器只能接受来自于客户端A的请求信息；虽然客户端A和客户端B的请求是同时进行的，但客户端B发送的请求信息只能等到服务器接受完A的请求数据后，才能被接受。 由于服务器一次只能处理一个客户端请求，当处理完成并返回后(或者异常时)，才能进行第二次请求的处理。很显然，这样的处理方式在高并发的情况下，是不能采用的。 多线程方式 - 伪异步方式上面说的情况是服务器只有一个线程的情况，那么读者会直接提出我们可以使用多线程技术来解决这个问题: 当服务器收到客户端X的请求后，(读取到所有请求数据后)将这个请求送入一个独立线程进行处理，然后主线程继续接受客户端Y的请求。 客户端一侧，也可以使用一个子线程和服务器端进行通信。这样客户端主线程的其他工作就不受影响了，当服务器端有响应信息的时候再由这个子线程通过 监听模式&#x2F;观察模式(等其他设计模式)通知主线程。 如下图所示: 但是使用线程来解决这个问题实际上是有局限性的: 虽然在服务器端，请求的处理交给了一个独立线程进行，但是操作系统通知accept()的方式还是单个的。也就是，实际上是服务器接收到数据报文后的“业务处理过程”可以多线程，但是数据报文的接受还是需要一个一个的来(下文的示例代码和debug过程我们可以明确看到这一点) 在linux系统中，可以创建的线程是有限的。我们可以通过cat &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;threads-max 命令查看可以创建的最大线程数。当然这个值是可以更改的，但是线程越多，CPU切换所需的时间也就越长，用来处理真正业务的需求也就越少。 创建一个线程是有较大的资源消耗的。JVM创建一个线程的时候，即使这个线程不做任何的工作，JVM都会分配一个堆栈空间。这个空间的大小默认为128K，您可以通过-Xss参数进行调整。当然您还可以使用ThreadPoolExecutor线程池来缓解线程的创建问题，但是又会造成BlockingQueue积压任务的持续增加，同样消耗了大量资源。 另外，如果您的应用程序大量使用长连接的话，线程是不会关闭的。这样系统资源的消耗更容易失控。 那么，如果你真想单纯使用线程解决阻塞的问题，那么您自己都可以算出来您一个服务器节点可以一次接受多大的并发了。看来，单纯使用线程解决这个问题不是最好的办法。 BIO通信方式深入分析BIO的问题关键不在于是否使用了多线程(包括线程池)处理这次请求，而在于accept()、read()的操作点都是被阻塞。要测试这个问题，也很简单。我们模拟了20个客户端(用20根线程模拟)，利用JAVA的同步计数器CountDownLatch，保证这20个客户都初始化完成后然后同时向服务器发送请求，然后我们来观察一下Server这边接受信息的情况。 模拟20个客户端并发请求，服务器端使用单线程:客户端代码(SocketClientDaemon) 123456789101112131415161718192021package testBSocket;import java.util.concurrent.CountDownLatch;public class SocketClientDaemon &#123; public static void main(String[] args) throws Exception &#123; Integer clientNumber = 20; CountDownLatch countDownLatch = new CountDownLatch(clientNumber); //分别开始启动这20个客户端 for(int index = 0 ; index &lt; clientNumber ; index++ , countDownLatch.countDown()) &#123; SocketClientRequestThread client = new SocketClientRequestThread(countDownLatch, index); new Thread(client).start(); &#125; //这个wait不涉及到具体的实验逻辑，只是为了保证守护线程在启动所有线程后，进入等待状态 synchronized (SocketClientDaemon.class) &#123; SocketClientDaemon.class.wait(); &#125; &#125;&#125; 客户端代码(SocketClientRequestThread模拟请求) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package testBSocket;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.Socket;import java.util.concurrent.CountDownLatch;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.apache.log4j.BasicConfigurator;/** * 一个SocketClientRequestThread线程模拟一个客户端请求。 * @author yinwenjie */public class SocketClientRequestThread implements Runnable &#123; static &#123; BasicConfigurator.configure(); &#125; /** * 日志 */ private static final Log LOGGER = LogFactory.getLog(SocketClientRequestThread.class); private CountDownLatch countDownLatch; /** * 这个线层的编号 * @param countDownLatch */ private Integer clientIndex; /** * countDownLatch是java提供的同步计数器。 * 当计数器数值减为0时，所有受其影响而等待的线程将会被激活。这样保证模拟并发请求的真实性 * @param countDownLatch */ public SocketClientRequestThread(CountDownLatch countDownLatch , Integer clientIndex) &#123; this.countDownLatch = countDownLatch; this.clientIndex = clientIndex; &#125; @Override public void run() &#123; Socket socket = null; OutputStream clientRequest = null; InputStream clientResponse = null; try &#123; socket = new Socket(&quot;localhost&quot;,83); clientRequest = socket.getOutputStream(); clientResponse = socket.getInputStream(); //等待，直到SocketClientDaemon完成所有线程的启动，然后所有线程一起发送请求 this.countDownLatch.await(); //发送请求信息 clientRequest.write((&quot;这是第&quot; + this.clientIndex + &quot; 个客户端的请求。&quot;).getBytes()); clientRequest.flush(); //在这里等待，直到服务器返回信息 SocketClientRequestThread.LOGGER.info(&quot;第&quot; + this.clientIndex + &quot;个客户端的请求发送完成，等待服务器返回信息&quot;); int maxLen = 1024; byte[] contextBytes = new byte[maxLen]; int realLen; String message = &quot;&quot;; //程序执行到这里，会一直等待服务器返回信息(注意，前提是in和out都不能close，如果close了就收不到服务器的反馈了) while((realLen = clientResponse.read(contextBytes, 0, maxLen)) != -1) &#123; message += new String(contextBytes , 0 , realLen); &#125; SocketClientRequestThread.LOGGER.info(&quot;接收到来自服务器的信息:&quot; + message); &#125; catch (Exception e) &#123; SocketClientRequestThread.LOGGER.error(e.getMessage(), e); &#125; finally &#123; try &#123; if(clientRequest != null) &#123; clientRequest.close(); &#125; if(clientResponse != null) &#123; clientResponse.close(); &#125; &#125; catch (IOException e) &#123; SocketClientRequestThread.LOGGER.error(e.getMessage(), e); &#125; &#125; &#125;&#125; 服务器端(SocketServer1)单个线程 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package testBSocket;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.apache.log4j.BasicConfigurator;public class SocketServer1 &#123; static &#123; BasicConfigurator.configure(); &#125; /** * 日志 */ private static final Log LOGGER = LogFactory.getLog(SocketServer1.class); public static void main(String[] args) throws Exception&#123; ServerSocket serverSocket = new ServerSocket(83); try &#123; while(true) &#123; Socket socket = serverSocket.accept(); //下面我们收取信息 InputStream in = socket.getInputStream(); OutputStream out = socket.getOutputStream(); Integer sourcePort = socket.getPort(); int maxLen = 2048; byte[] contextBytes = new byte[maxLen]; //这里也会被阻塞，直到有数据准备好 int realLen = in.read(contextBytes, 0, maxLen); //读取信息 String message = new String(contextBytes , 0 , realLen); //下面打印信息 SocketServer1.LOGGER.info(&quot;服务器收到来自于端口: &quot; + sourcePort + &quot;的信息: &quot; + message); //下面开始发送信息 out.write(&quot;回发响应信息！&quot;.getBytes()); //关闭 out.close(); in.close(); socket.close(); &#125; &#125; catch(Exception e) &#123; SocketServer1.LOGGER.error(e.getMessage(), e); &#125; finally &#123; if(serverSocket != null) &#123; serverSocket.close(); &#125; &#125; &#125;&#125; 多线程来优化服务器端客户端代码和上文一样，最主要是更改服务器端的代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package testBSocket;import java.io.IOException;import java.io.InputStream;import java.io.OutputStream;import java.net.ServerSocket;import java.net.Socket;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.apache.log4j.BasicConfigurator;public class SocketServer2 &#123; static &#123; BasicConfigurator.configure(); &#125; private static final Log LOGGER = LogFactory.getLog(SocketServer2.class); public static void main(String[] args) throws Exception&#123; ServerSocket serverSocket = new ServerSocket(83); try &#123; while(true) &#123; Socket socket = serverSocket.accept(); //当然业务处理过程可以交给一个线程(这里可以使用线程池),并且线程的创建是很耗资源的。 //最终改变不了.accept()只能一个一个接受socket的情况,并且被阻塞的情况 SocketServerThread socketServerThread = new SocketServerThread(socket); new Thread(socketServerThread).start(); &#125; &#125; catch(Exception e) &#123; SocketServer2.LOGGER.error(e.getMessage(), e); &#125; finally &#123; if(serverSocket != null) &#123; serverSocket.close(); &#125; &#125; &#125;&#125;/** * 当然，接收到客户端的socket后，业务的处理过程可以交给一个线程来做。 * 但还是改变不了socket被一个一个的做accept()的情况。 * @author yinwenjie */class SocketServerThread implements Runnable &#123; /** * 日志 */ private static final Log LOGGER = LogFactory.getLog(SocketServerThread.class); private Socket socket; public SocketServerThread (Socket socket) &#123; this.socket = socket; &#125; @Override public void run() &#123; InputStream in = null; OutputStream out = null; try &#123; //下面我们收取信息 in = socket.getInputStream(); out = socket.getOutputStream(); Integer sourcePort = socket.getPort(); int maxLen = 1024; byte[] contextBytes = new byte[maxLen]; //使用线程，同样无法解决read方法的阻塞问题， //也就是说read方法处同样会被阻塞，直到操作系统有数据准备好 int realLen = in.read(contextBytes, 0, maxLen); //读取信息 String message = new String(contextBytes , 0 , realLen); //下面打印信息 SocketServerThread.LOGGER.info(&quot;服务器收到来自于端口: &quot; + sourcePort + &quot;的信息: &quot; + message); //下面开始发送信息 out.write(&quot;回发响应信息！&quot;.getBytes()); &#125; catch(Exception e) &#123; SocketServerThread.LOGGER.error(e.getMessage(), e); &#125; finally &#123; //试图关闭 try &#123; if(in != null) &#123; in.close(); &#125; if(out != null) &#123; out.close(); &#125; if(this.socket != null) &#123; this.socket.close(); &#125; &#125; catch (IOException e) &#123; SocketServerThread.LOGGER.error(e.getMessage(), e); &#125; &#125; &#125;&#125; 看看服务器端的执行效果我们主要看一看服务器使用多线程处理时的情况: 问题根源那么重点的问题并不是“是否使用了多线程”，而是为什么accept()、read()方法会被阻塞。即: 异步IO模式 就是为了解决这样的并发性存在的。但是为了说清楚异步IO模式，在介绍IO模式的时候，我们就要首先了解清楚，什么是 阻塞式同步、非阻塞式同步、多路复用同步模式。 API文档中对于 serverSocket.accept() 方法的使用描述: Listens for a connection to be made to this socket and accepts it. The method blocks until a connection is made. serverSocket.accept()会被阻塞? 这里涉及到阻塞式同步IO的工作原理: 服务器线程发起一个accept动作，询问操作系统 是否有新的socket套接字信息从端口X发送过来。 注意，是询问操作系统。也就是说socket套接字的IO模式支持是基于操作系统的，那么自然同步IO&#x2F;异步IO的支持就是需要操作系统级别的了。如下图: 如果操作系统没有发现有套接字从指定的端口X来，那么操作系统就会等待。这样serverSocket.accept()方法就会一直等待。这就是为什么accept()方法为什么会阻塞: 它内部的实现是使用的操作系统级别的同步IO。 参考文章 文章主要来源于: 银文杰，笔名“说好不能打脸”，博客地址。他的书《高性能服务系统构建与实战》。 https://blog.csdn.net/yinwenjie/article/details/48274255","tags":["Java","IO","BIO"],"categories":["Java","IO","BIO"]},{"title":"10.Java NIO - IO多路复用详解","path":"/2023/12/26/10-Java-NIO-IO多路复用详解/","content":"本文主要对IO多路复用，Ractor模型以及Java NIO对其的支持。 现实场景我们试想一下这样的现实场景: 一个餐厅同时有100位客人到店，当然到店后第一件要做的事情就是点菜。但是问题来了，餐厅老板为了节约人力成本目前只有一位大堂服务员拿着唯一的一本菜单等待客人进行服务。 那么最笨(但是最简单)的方法是(方法A)，无论有多少客人等待点餐，服务员都把仅有的一份菜单递给其中一位客人，然后站在客人身旁等待这个客人完成点菜过程。在记录客人点菜内容后，把点菜记录交给后堂厨师。然后是第二位客人。。。。然后是第三位客人。很明显，只有脑袋被门夹过的老板，才会这样设置服务流程。因为随后的80位客人，再等待超时后就会离店(还会给差评)。 于是还有一种办法(方法B)，老板马上新雇佣99名服务员，同时印制99本新的菜单。每一名服务员手持一本菜单负责一位客人(关键不只在于服务员，还在于菜单。因为没有菜单客人也无法点菜)。在客人点完菜后，记录点菜内容交给后堂厨师(当然为了更高效，后堂厨师最好也有100名)。这样每一位客人享受的就是VIP服务咯，当然客人不会走，但是人力成本可是一个大头哦(亏死你)。 另外一种办法(方法C)，就是改进点菜的方式，当客人到店后，自己申请一本菜单。想好自己要点的才后，就呼叫服务员。服务员站在自己身边后记录客人的菜单内容。将菜单递给厨师的过程也要进行改进，并不是每一份菜单记录好以后，都要交给后堂厨师。服务员可以记录号多份菜单后，同时交给厨师就行了。那么这种方式，对于老板来说人力成本是最低的；对于客人来说，虽然不再享受VIP服务并且要进行一定的等待，但是这些都是可接受的；对于服务员来说，基本上她的时间都没有浪费，基本上被老板压杆了最后一滴油水。 如果您是老板，您会采用哪种方式呢? 到店情况: 并发量。到店情况不理想时，一个服务员一本菜单，当然是足够了。所以不同的老板在不同的场合下，将会灵活选择服务员和菜单的配置。 客人: 客户端请求 点餐内容: 客户端发送的实际数据 老板: 操作系统 人力成本: 系统资源 菜单: 文件状态描述符。操作系统对于一个进程能够同时持有的文件状态描述符的个数是有限制的，在linux系统中$ulimit -n查看这个限制值，当然也是可以(并且应该)进行内核参数调整的。 服务员: 操作系统内核用于IO操作的线程(内核线程) 厨师: 应用程序线程(当然厨房就是应用程序进程咯) 餐单传递方式: 包括了阻塞式和非阻塞式两种。 方法A: 阻塞式&#x2F;非阻塞式 同步IO 方法B: 使用线程进行处理的 阻塞式&#x2F;非阻塞式 同步IO 方法C: 阻塞式&#x2F;非阻塞式 多路复用IO 典型的多路复用IO实现目前流程的多路复用IO实现主要包括四种: select、poll、epoll、kqueue。下表是他们的一些重要特性的比较: IO模型 相对性能 关键思路 操作系统 JAVA支持情况 select 较高 Reactor windows&#x2F;Linux 支持,Reactor模式(反应器设计模式)。Linux操作系统的 kernels 2.4内核版本之前，默认使用select；而目前windows下对同步IO的支持，都是select模型 poll 较高 Reactor Linux Linux下的JAVA NIO框架，Linux kernels 2.6内核版本之前使用poll进行支持。也是使用的Reactor模式 epoll 高 Reactor&#x2F;Proactor Linux Linux kernels 2.6内核版本及以后使用epoll进行支持；Linux kernels 2.6内核版本之前使用poll进行支持；另外一定注意，由于Linux下没有Windows下的IOCP技术提供真正的 异步IO 支持，所以Linux下使用epoll模拟异步IO kqueue 高 Proactor Linux 目前JAVA的版本不支持 多路复用IO技术最适用的是“高并发”场景，所谓高并发是指1毫秒内至少同时有上千个连接请求准备好。其他情况下多路复用IO技术发挥不出来它的优势。另一方面，使用JAVA NIO进行功能实现，相对于传统的Socket套接字实现要复杂一些，所以实际应用中，需要根据自己的业务需求进行技术选择。 Reactor模型和Proactor模型传统IO模型对于传统IO模型，其主要是一个Server对接N个客户端，在客户端连接之后，为每个客户端都分配一个执行线程。如下图是该模型的一个演示： 从图中可以看出，传统IO的特点在于： 每个客户端连接到达之后，服务端会分配一个线程给该客户端，该线程会处理包括读取数据，解码，业务计算，编码，以及发送数据整个过程； 同一时刻，服务端的吞吐量与服务器所提供的线程数量是呈线性关系的。 这种设计模式在客户端连接不多，并发量不大的情况下是可以运行得很好的，但是在海量并发的情况下，这种模式就显得力不从心了。这种模式主要存在的问题有如下几点： 服务器的并发量对服务端能够创建的线程数有很大的依赖关系，但是服务器线程却是不能无限增长的； 服务端每个线程不仅要进行IO读写操作，而且还需要进行业务计算； 服务端在获取客户端连接，读取数据，以及写入数据的过程都是阻塞类型的，在网络状况不好的情况下，这将极大的降低服务器每个线程的利用率，从而降低服务器吞吐量。 Reactor事件驱动模型在传统IO模型中，由于线程在等待连接以及进行IO操作时都会阻塞当前线程，这部分损耗是非常大的。因而jdk 1.4中就提供了一套非阻塞IO的API。该API本质上是以事件驱动来处理网络事件的，而Reactor是基于该API提出的一套IO模型。如下是Reactor事件驱动模型的示意图： 从图中可以看出，在Reactor模型中，主要有四个角色：客户端连接，Reactor，Acceptor和Handler。这里Acceptor会不断地接收客户端的连接，然后将接收到的连接交由Reactor进行分发，最后有具体的Handler进行处理。改进后的Reactor模型相对于传统的IO模型主要有如下优点： 从模型上来讲，如果仅仅还是只使用一个线程池来处理客户端连接的网络读写，以及业务计算，那么Reactor模型与传统IO模型在效率上并没有什么提升。但是Reactor模型是以事件进行驱动的，其能够将接收客户端连接，+ 网络读和网络写，以及业务计算进行拆分，从而极大的提升处理效率； Reactor模型是异步非阻塞模型，工作线程在没有网络事件时可以处理其他的任务，而不用像传统IO那样必须阻塞等待。 Reactor模型—-业务处理与IO分离在上面的Reactor模型中，由于网络读写和业务操作都在同一个线程中，在高并发情况下，这里的系统瓶颈主要在两方面： 高频率的网络读写事件处理； 大量的业务操作处理； 基于上述两个问题，这里在单线程Reactor模型的基础上提出了使用线程池的方式处理业务操作的模型。如下是该模型的示意图： 从图中可以看出，在多线程进行业务操作的模型下，该模式主要具有如下特点： 使用一个线程进行客户端连接的接收以及网络读写事件的处理； 在接收到客户端连接之后，将该连接交由线程池进行数据的编解码以及业务计算。 这种模式相较于前面的模式性能有了很大的提升，主要在于在进行网络读写的同时，也进行了业务计算，从而大大提升了系统的吞吐量。但是这种模式也有其不足，主要在于： 网络读写是一个比较消耗CPU的操作，在高并发的情况下，将会有大量的客户端数据需要进行网络读写，此时一个线程将不足以处理这么多请求。 Reactor模型—-并发读写对于使用线程池处理业务操作的模型，由于网络读写在高并发情况下会成为系统的一个瓶颈，因而针对该模型这里提出了一种改进后的模型，即使用线程池进行网络读写，而仅仅只使用一个线程专门接收客户端连接。如下是该模型的示意图： 可以看到，改进后的Reactor模型将Reactor拆分为了mainReactor和subReactor。这里mainReactor主要进行客户端连接的处理，处理完成之后将该连接交由subReactor以处理客户端的网络读写。这里的subReactor则是使用一个线程池来支撑的，其读写能力将会随着线程数的增多而大大增加。对于业务操作，这里也是使用一个线程池，而每个业务请求都只需要进行编解码和业务计算。通过这种方式，服务器的性能将会大大提升，在可见情况下，其基本上可以支持百万连接。 Reactor模型示例对于上述Reactor模型，服务端主要有三个角色：Reactor，Acceptor和Handler。这里基于Doug Lea的文档对其进行了实现，如下是Reactor的实现代码： 123456789101112131415161718192021222324252627282930313233343536373839public class Reactor implements Runnable &#123; private final Selector selector; private final ServerSocketChannel serverSocket; public Reactor(int port) throws IOException &#123; serverSocket = ServerSocketChannel.open(); // 创建服务端的ServerSocketChannel serverSocket.configureBlocking(false); // 设置为非阻塞模式 selector = Selector.open(); // 创建一个Selector多路复用器 SelectionKey key = serverSocket.register(selector, SelectionKey.OP_ACCEPT); serverSocket.bind(new InetSocketAddress(port)); // 绑定服务端端口 key.attach(new Acceptor(serverSocket)); // 为服务端Channel绑定一个Acceptor &#125; @Override public void run() &#123; try &#123; while (!Thread.interrupted()) &#123; selector.select(); // 服务端使用一个线程不断等待客户端的连接到达 Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; iterator = keys.iterator(); while (iterator.hasNext()) &#123; dispatch(iterator.next()); // 监听到客户端连接事件后将其分发给Acceptor iterator.remove(); &#125; selector.selectNow(); &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void dispatch(SelectionKey key) throws IOException &#123; // 这里的attachement也即前面为服务端Channel绑定的Acceptor，调用其run()方法进行 // 客户端连接的获取，并且进行分发 Runnable attachment = (Runnable) key.attachment(); attachment.run(); &#125;&#125; 这里Reactor首先开启了一个ServerSocketChannel，然后将其绑定到指定的端口，并且注册到了一个多路复用器上。接着在一个线程中，其会在多路复用器上等待客户端连接。当有客户端连接到达后，Reactor就会将其派发给一个Acceptor，由该Acceptor专门进行客户端连接的获取。下面我们继续看一下Acceptor的代码： 123456789101112131415161718192021public class Acceptor implements Runnable &#123; private final ExecutorService executor = Executors.newFixedThreadPool(20); private final ServerSocketChannel serverSocket; public Acceptor(ServerSocketChannel serverSocket) &#123; this.serverSocket = serverSocket; &#125; @Override public void run() &#123; try &#123; SocketChannel channel = serverSocket.accept(); // 获取客户端连接 if (null != channel) &#123; executor.execute(new Handler(channel)); // 将客户端连接交由线程池处理 &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 这里可以看到，在Acceptor获取到客户端连接之后，其就将其交由线程池进行网络读写了，而这里的主线程只是不断监听客户端连接事件。下面我们看看Handler的具体逻辑： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class Handler implements Runnable &#123; private volatile static Selector selector; private final SocketChannel channel; private SelectionKey key; private volatile ByteBuffer input = ByteBuffer.allocate(1024); private volatile ByteBuffer output = ByteBuffer.allocate(1024); public Handler(SocketChannel channel) throws IOException &#123; this.channel = channel; channel.configureBlocking(false); // 设置客户端连接为非阻塞模式 selector = Selector.open(); // 为客户端创建一个新的多路复用器 key = channel.register(selector, SelectionKey.OP_READ); // 注册客户端Channel的读事件 &#125; @Override public void run() &#123; try &#123; while (selector.isOpen() &amp;&amp; channel.isOpen()) &#123; Set&lt;SelectionKey&gt; keys = select(); // 等待客户端事件发生 Iterator&lt;SelectionKey&gt; iterator = keys.iterator(); while (iterator.hasNext()) &#123; SelectionKey key = iterator.next(); iterator.remove(); // 如果当前是读事件，则读取数据 if (key.isReadable()) &#123; read(key); &#125; else if (key.isWritable()) &#123; // 如果当前是写事件，则写入数据 write(key); &#125; &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; // 这里处理的主要目的是处理Jdk的一个bug，该bug会导致Selector被意外触发，但是实际上没有任何事件到达， // 此时的处理方式是新建一个Selector，然后重新将当前Channel注册到该Selector上 private Set&lt;SelectionKey&gt; select() throws IOException &#123; selector.select(); Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); if (keys.isEmpty()) &#123; int interestOps = key.interestOps(); selector = Selector.open(); key = channel.register(selector, interestOps); return select(); &#125; return keys; &#125; // 读取客户端发送的数据 private void read(SelectionKey key) throws IOException &#123; channel.read(input); if (input.position() == 0) &#123; return; &#125; input.flip(); process(); // 对读取的数据进行业务处理 input.clear(); key.interestOps(SelectionKey.OP_WRITE); // 读取完成后监听写入事件 &#125; private void write(SelectionKey key) throws IOException &#123; output.flip(); if (channel.isOpen()) &#123; channel.write(output); // 当有写入事件时，将业务处理的结果写入到客户端Channel中 key.channel(); channel.close(); output.clear(); &#125; &#125; // 进行业务处理，并且获取处理结果。本质上，基于Reactor模型，如果这里成为处理瓶颈， // 则直接将其处理过程放入线程池即可，并且使用一个Future获取处理结果，最后写入客户端Channel private void process() &#123; byte[] bytes = new byte[input.remaining()]; input.get(bytes); String message = new String(bytes, CharsetUtil.UTF_8); System.out.println(&quot;receive message from client: &quot; + message); output.put(&quot;hello client&quot;.getBytes()); &#125;&#125; 在Handler中，主要进行的就是为每一个客户端Channel创建一个Selector，并且监听该Channel的网络读写事件。当有事件到达时，进行数据的读写，而业务操作这交由具体的业务线程池处理。 JAVA对多路复用IO的支持 重要概念: Channel通道，被建立的一个应用程序和操作系统交互事件、传递内容的渠道(注意是连接到操作系统)。一个通道会有一个专属的文件状态描述符。那么既然是和操作系统进行内容的传递，那么说明应用程序可以通过通道读取数据，也可以通过通道向操作系统写数据。 JDK API中的Channel的描述是: A channel represents an open connection to an entity such as a hardware device, a file, a network socket, or a program component that is capable of performing one or more distinct I&#x2F;O operations, for example reading or writing. A channel is either open or closed. A channel is open upon creation, and once closed it remains closed. Once a channel is closed, any attempt to invoke an I&#x2F;O operation upon it will cause a ClosedChannelException to be thrown. Whether or not a channel is open may be tested by invoking its isOpen method. JAVA NIO 框架中，自有的Channel通道包括: 所有被Selector(选择器)注册的通道，只能是继承了SelectableChannel类的子类。如上图所示 ServerSocketChannel: 应用服务器程序的监听通道。只有通过这个通道，应用程序才能向操作系统注册支持“多路复用IO”的端口监听。同时支持UDP协议和TCP协议。 ScoketChannel: TCP Socket套接字的监听通道，一个Socket套接字对应了一个客户端IP: 端口 到 服务器IP: 端口的通信连接。 DatagramChannel: UDP 数据报文的监听通道。 重要概念: Buffer数据缓存区: 在JAVA NIO 框架中，为了保证每个通道的数据读写速度JAVA NIO 框架为每一种需要支持数据读写的通道集成了Buffer的支持。 这句话怎么理解呢? 例如ServerSocketChannel通道它只支持对OP_ACCEPT事件的监听，所以它是不能直接进行网络数据内容的读写的。所以ServerSocketChannel是没有集成Buffer的。 Buffer有两种工作模式: 写模式和读模式。在读模式下，应用程序只能从Buffer中读取数据，不能进行写操作。但是在写模式下，应用程序是可以进行读操作的，这就表示可能会出现脏读的情况。所以一旦您决定要从Buffer中读取数据，一定要将Buffer的状态改为读模式。 如下图: position: 缓存区目前这在操作的数据块位置 limit: 缓存区最大可以进行操作的位置。缓存区的读写状态正式由这个属性控制的。 capacity: 缓存区的最大容量。这个容量是在缓存区创建时进行指定的。由于高并发时通道数量往往会很庞大，所以每一个缓存区的容量最好不要过大。 在下文JAVA NIO框架的代码实例中，我们将进行Buffer缓存区操作的演示。 重要概念: SelectorSelector的英文含义是“选择器”，不过根据我们详细介绍的Selector的岗位职责，您可以把它称之为“轮询代理器”、“事件订阅器”、“channel容器管理机”都行。 事件订阅和Channel管理 应用程序将向Selector对象注册需要它关注的Channel，以及具体的某一个Channel会对哪些IO事件感兴趣。Selector中也会维护一个“已经注册的Channel”的容器。以下代码来自WindowsSelectorImpl实现类中，对已经注册的Channel的管理容器: 12345678910// Initial capacity of the poll arrayprivate final int INIT_CAP = 8;// Maximum number of sockets for select().// Should be INIT_CAP times a power of 2private final static int MAX_SELECTABLE_FDS = 1024;// The list of SelectableChannels serviced by this Selector. Every mod// MAX_SELECTABLE_FDS entry is bogus, to align this array with the poll// array, where the corresponding entry is occupied by the wakeupSocketprivate SelectionKeyImpl[] channelArray = new SelectionKeyImpl[INIT_CAP]; 轮询代理 应用层不再通过阻塞模式或者非阻塞模式直接询问操作系统“事件有没有发生”，而是由Selector代其询问。 实现不同操作系统的支持 之前已经提到过，多路复用IO技术 是需要操作系统进行支持的，其特点就是操作系统可以同时扫描同一个端口上不同网络连接的事件。所以作为上层的JVM，必须要为 不同操作系统的多路复用IO实现 编写不同的代码。同样我使用的测试环境是Windows，它对应的实现类是sun.nio.ch.WindowsSelectorImpl: JAVA NIO 框架简要设计分析通过上文的描述，我们知道了多路复用IO技术是操作系统的内核实现。在不同的操作系统，甚至同一系列操作系统的版本中所实现的多路复用IO技术都是不一样的。那么作为跨平台的JAVA JVM来说如何适应多种多样的多路复用IO技术实现呢? 面向对象的威力就显现出来了: 无论使用哪种实现方式，他们都会有“选择器”、“通道”、“缓存”这几个操作要素，那么可以为不同的多路复用IO技术创建一个统一的抽象组，并且为不同的操作系统进行具体的实现。JAVA NIO中对各种多路复用IO的支持，主要的基础是java.nio.channels.spi.SelectorProvider抽象类，其中的几个主要抽象方法包括: public abstract DatagramChannel openDatagramChannel(): 创建和这个操作系统匹配的UDP 通道实现。 public abstract AbstractSelector openSelector(): 创建和这个操作系统匹配的NIO选择器，就像上文所述，不同的操作系统，不同的版本所默认支持的NIO模型是不一样的。 public abstract ServerSocketChannel openServerSocketChannel(): 创建和这个NIO模型匹配的服务器端通道。 public abstract SocketChannel openSocketChannel(): 创建和这个NIO模型匹配的TCP Socket套接字通道(用来反映客户端的TCP连接) 由于JAVA NIO框架的整个设计是很大的，所以我们只能还原一部分我们关心的问题。这里我们以JAVA NIO框架中对于不同多路复用IO技术的选择器 进行实例化创建的方式作为例子，以点窥豹观全局: 很明显，不同的SelectorProvider实现对应了不同的 选择器。由具体的SelectorProvider实现进行创建。另外说明一下，实际上netty底层也是通过这个设计获得具体使用的NIO模型，我们后文讲解Netty时，会讲到这个问题。以下代码是Netty 4.0中NioServerSocketChannel进行实例化时的核心代码片段: 1234567891011121314private static ServerSocketChannel newSocket(SelectorProvider provider) &#123; try &#123; /** * Use the &#123;@link SelectorProvider&#125; to open &#123;@link SocketChannel&#125; and so remove condition in * &#123;@link SelectorProvider#provider()&#125; which is called by each ServerSocketChannel.open() otherwise. * * See &lt;a href=&quot;See https://github.com/netty/netty/issues/2308&quot;&gt;#2308&lt;/a&gt;. */ return provider.openServerSocketChannel(); &#125; catch (IOException e) &#123; throw new ChannelException( &quot;Failed to open a server socket.&quot;, e); &#125;&#125; # JAVA实例下面，我们使用JAVA NIO框架，实现一个支持多路复用IO的服务器端(实际上客户端是否使用多路复用IO技术，对整个系统架构的性能提升相关性不大): 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170package testNSocket;import java.net.InetSocketAddress;import java.net.ServerSocket;import java.net.URLDecoder;import java.net.URLEncoder;import java.nio.ByteBuffer;import java.nio.channels.SelectableChannel;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.apache.log4j.BasicConfigurator;public class SocketServer1 &#123; static &#123; BasicConfigurator.configure(); &#125; /** * 日志 */ private static final Log LOGGER = LogFactory.getLog(SocketServer1.class); public static void main(String[] args) throws Exception &#123; ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); ServerSocket serverSocket = serverChannel.socket(); serverSocket.setReuseAddress(true); serverSocket.bind(new InetSocketAddress(83)); Selector selector = Selector.open(); //注意、服务器通道只能注册SelectionKey.OP_ACCEPT事件 serverChannel.register(selector, SelectionKey.OP_ACCEPT); try &#123; while(true) &#123; //如果条件成立，说明本次询问selector，并没有获取到任何准备好的、感兴趣的事件 //java程序对多路复用IO的支持也包括了阻塞模式 和非阻塞模式两种。 if(selector.select(100) == 0) &#123; //================================================ // 这里视业务情况，可以做一些然并卵的事情 //================================================ continue; &#125; //这里就是本次询问操作系统，所获取到的“所关心的事件”的事件类型(每一个通道都是独立的) Iterator&lt;SelectionKey&gt; selecionKeys = selector.selectedKeys().iterator(); while(selecionKeys.hasNext()) &#123; SelectionKey readyKey = selecionKeys.next(); //这个已经处理的readyKey一定要移除。如果不移除，就会一直存在在selector.selectedKeys集合中 //待到下一次selector.select() &gt; 0时，这个readyKey又会被处理一次 selecionKeys.remove(); SelectableChannel selectableChannel = readyKey.channel(); if(readyKey.isValid() &amp;&amp; readyKey.isAcceptable()) &#123; SocketServer1.LOGGER.info(&quot;======channel通道已经准备好=======&quot;); /* * 当server socket channel通道已经准备好，就可以从server socket channel中获取socketchannel了 * 拿到socket channel后，要做的事情就是马上到selector注册这个socket channel感兴趣的事情。 * 否则无法监听到这个socket channel到达的数据 * */ ServerSocketChannel serverSocketChannel = (ServerSocketChannel)selectableChannel; SocketChannel socketChannel = serverSocketChannel.accept(); registerSocketChannel(socketChannel , selector); &#125; else if(readyKey.isValid() &amp;&amp; readyKey.isConnectable()) &#123; SocketServer1.LOGGER.info(&quot;======socket channel 建立连接=======&quot;); &#125; else if(readyKey.isValid() &amp;&amp; readyKey.isReadable()) &#123; SocketServer1.LOGGER.info(&quot;======socket channel 数据准备完成，可以去读==读取=======&quot;); readSocketChannel(readyKey); &#125; &#125; &#125; &#125; catch(Exception e) &#123; SocketServer1.LOGGER.error(e.getMessage() , e); &#125; finally &#123; serverSocket.close(); &#125; &#125; /** * 在server socket channel接收到/准备好 一个新的 TCP连接后。 * 就会向程序返回一个新的socketChannel。&lt;br&gt; * 但是这个新的socket channel并没有在selector“选择器/代理器”中注册， * 所以程序还没法通过selector通知这个socket channel的事件。 * 于是我们拿到新的socket channel后，要做的第一个事情就是到selector“选择器/代理器”中注册这个 * socket channel感兴趣的事件 * @param socketChannel 新的socket channel * @param selector selector“选择器/代理器” * @throws Exception */ private static void registerSocketChannel(SocketChannel socketChannel , Selector selector) throws Exception &#123; socketChannel.configureBlocking(false); //socket通道可以且只可以注册三种事件SelectionKey.OP_READ | SelectionKey.OP_WRITE | SelectionKey.OP_CONNECT socketChannel.register(selector, SelectionKey.OP_READ , ByteBuffer.allocate(2048)); &#125; /** * 这个方法用于读取从客户端传来的信息。 * 并且观察从客户端过来的socket channel在经过多次传输后，是否完成传输。 * 如果传输完成，则返回一个true的标记。 * @param socketChannel * @throws Exception */ private static void readSocketChannel(SelectionKey readyKey) throws Exception &#123; SocketChannel clientSocketChannel = (SocketChannel)readyKey.channel(); //获取客户端使用的端口 InetSocketAddress sourceSocketAddress = (InetSocketAddress)clientSocketChannel.getRemoteAddress(); Integer resoucePort = sourceSocketAddress.getPort(); //拿到这个socket channel使用的缓存区，准备读取数据 //在后文，将详细讲解缓存区的用法概念，实际上重要的就是三个元素capacity,position和limit。 ByteBuffer contextBytes = (ByteBuffer)readyKey.attachment(); //将通道的数据写入到缓存区，注意是写入到缓存区。 //由于之前设置了ByteBuffer的大小为2048 byte，所以可以存在写入不完的情况 //没关系，我们后面来调整代码。这里我们暂时理解为一次接受可以完成 int realLen = -1; try &#123; realLen = clientSocketChannel.read(contextBytes); &#125; catch(Exception e) &#123; //这里抛出了异常，一般就是客户端因为某种原因终止了。所以关闭channel就行了 SocketServer1.LOGGER.error(e.getMessage()); clientSocketChannel.close(); return; &#125; //如果缓存区中没有任何数据(但实际上这个不太可能，否则就不会触发OP_READ事件了) if(realLen == -1) &#123; SocketServer1.LOGGER.warn(&quot;====缓存区没有数据? ====&quot;); return; &#125; //将缓存区从写状态切换为读状态(实际上这个方法是读写模式互切换)。 //这是java nio框架中的这个socket channel的写请求将全部等待。 contextBytes.flip(); //注意中文乱码的问题，我个人喜好是使用URLDecoder/URLEncoder，进行解编码。 //当然java nio框架本身也提供编解码方式，看个人咯 byte[] messageBytes = contextBytes.array(); String messageEncode = new String(messageBytes , &quot;UTF-8&quot;); String message = URLDecoder.decode(messageEncode, &quot;UTF-8&quot;); //如果收到了“over”关键字，才会清空buffer，并回发数据； //否则不清空缓存，还要还原buffer的“写状态” if(message.indexOf(&quot;over&quot;) != -1) &#123; //清空已经读取的缓存，并从新切换为写状态(这里要注意clear()和capacity()两个方法的区别) contextBytes.clear(); SocketServer1.LOGGER.info(&quot;端口:&quot; + resoucePort + &quot;客户端发来的信息======message : &quot; + message); //====================================================== // 当然接受完成后，可以在这里正式处理业务了 //====================================================== //回发数据，并关闭channel ByteBuffer sendBuffer = ByteBuffer.wrap(URLEncoder.encode(&quot;回发处理结果&quot;, &quot;UTF-8&quot;).getBytes()); clientSocketChannel.write(sendBuffer); clientSocketChannel.close(); &#125; else &#123; SocketServer1.LOGGER.info(&quot;端口:&quot; + resoucePort + &quot;客户端信息还未接受完，继续接受======message : &quot; + message); //这是，limit和capacity的值一致，position的位置是realLen的位置 contextBytes.position(realLen); contextBytes.limit(contextBytes.capacity()); &#125; &#125;&#125; 代码中的注释是比较清楚的，但是还是要对几个关键点进行一下讲解: serverChannel.register(Selector sel, int ops, Object att): 实际上register(Selector sel, int ops, Object att)方法是ServerSocketChannel类的父类AbstractSelectableChannel提供的一个方法，表示只要继承了AbstractSelectableChannel类的子类都可以注册到选择器中。通过观察整个AbstractSelectableChannel继承关系，下图中的这些类可以被注册到选择器中: SelectionKey.OP_ACCEPT: 不同的Channel对象可以注册的“我关心的事件”是不一样的。例如ServerSocketChannel除了能够被允许关注OP_ACCEPT事件外，不允许再关心其他事件了(否则运行时会抛出异常)。以下梳理了常使用的AbstractSelectableChannel子类可以注册的事件列表: 通道类 通道作用 可关注的事件 ServerSocketChannel 服务器端通道 SelectionKey.OP_ACCEPT DatagramChannel UDP协议通道 SelectionKey.OP_READ、SelectionKey.OP_WRITE SocketChannel TCP协议通道 SelectionKey.OP_READ、SelectionKey.OP_WRITE、SelectionKey.OP_CONNECT 实际上通过每一个AbstractSelectableChannel子类所实现的public final int validOps()方法，就可以查看这个通道“可以关心的IO事件”。 selector.selectedKeys().iterator(): 当选择器Selector收到操作系统的IO操作事件后，它的selectedKeys将在下一次轮询操作中，收到这些事件的关键描述字(不同的channel，就算关键字一样，也会存储成两个对象)。但是每一个“事件关键字”被处理后都必须移除，否则下一次轮询时，这个事件会被重复处理。 Returns this selector’s selected-key set. Keys may be removed from, but not directly added to, the selected-key set. Any attempt to add an object to the key set will cause an UnsupportedOperationException to be thrown. The selected-key set is not thread-safe. JAVA实例改进上面的代码中，我们为了讲解selector的使用，在缓存使用上就进行了简化。实际的应用中，为了节约内存资源，我们一般不会为一个通道分配那么多的缓存空间。下面的代码我们主要对其中的缓存操作进行了优化: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202package testNSocket;import java.net.InetSocketAddress;import java.net.ServerSocket;import java.net.URLDecoder;import java.net.URLEncoder;import java.nio.ByteBuffer;import java.nio.channels.SelectableChannel;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;import java.util.concurrent.ConcurrentHashMap;import java.util.concurrent.ConcurrentMap;import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory;import org.apache.log4j.BasicConfigurator;public class SocketServer2 &#123; static &#123; BasicConfigurator.configure(); &#125; /** * 日志 */ private static final Log LOGGER = LogFactory.getLog(SocketServer2.class); /** * 改进的java nio server的代码中，由于buffer的大小设置的比较小。 * 我们不再把一个client通过socket channel多次传给服务器的信息保存在beff中了(因为根本存不下)&lt;br&gt; * 我们使用socketchanel的hashcode作为key(当然您也可以自己确定一个id)，信息的stringbuffer作为value，存储到服务器端的一个内存区域MESSAGEHASHCONTEXT。 * * 如果您不清楚ConcurrentHashMap的作用和工作原理，请自行百度/Google */ private static final ConcurrentMap&lt;Integer, StringBuffer&gt; MESSAGEHASHCONTEXT = new ConcurrentHashMap&lt;Integer , StringBuffer&gt;(); public static void main(String[] args) throws Exception &#123; ServerSocketChannel serverChannel = ServerSocketChannel.open(); serverChannel.configureBlocking(false); ServerSocket serverSocket = serverChannel.socket(); serverSocket.setReuseAddress(true); serverSocket.bind(new InetSocketAddress(83)); Selector selector = Selector.open(); //注意、服务器通道只能注册SelectionKey.OP_ACCEPT事件 serverChannel.register(selector, SelectionKey.OP_ACCEPT); try &#123; while(true) &#123; //如果条件成立，说明本次询问selector，并没有获取到任何准备好的、感兴趣的事件 //java程序对多路复用IO的支持也包括了阻塞模式 和非阻塞模式两种。 if(selector.select(100) == 0) &#123; //================================================ // 这里视业务情况，可以做一些然并卵的事情 //================================================ continue; &#125; //这里就是本次询问操作系统，所获取到的“所关心的事件”的事件类型(每一个通道都是独立的) Iterator&lt;SelectionKey&gt; selecionKeys = selector.selectedKeys().iterator(); while(selecionKeys.hasNext()) &#123; SelectionKey readyKey = selecionKeys.next(); //这个已经处理的readyKey一定要移除。如果不移除，就会一直存在在selector.selectedKeys集合中 //待到下一次selector.select() &gt; 0时，这个readyKey又会被处理一次 selecionKeys.remove(); SelectableChannel selectableChannel = readyKey.channel(); if(readyKey.isValid() &amp;&amp; readyKey.isAcceptable()) &#123; SocketServer2.LOGGER.info(&quot;======channel通道已经准备好=======&quot;); /* * 当server socket channel通道已经准备好，就可以从server socket channel中获取socketchannel了 * 拿到socket channel后，要做的事情就是马上到selector注册这个socket channel感兴趣的事情。 * 否则无法监听到这个socket channel到达的数据 * */ ServerSocketChannel serverSocketChannel = (ServerSocketChannel)selectableChannel; SocketChannel socketChannel = serverSocketChannel.accept(); registerSocketChannel(socketChannel , selector); &#125; else if(readyKey.isValid() &amp;&amp; readyKey.isConnectable()) &#123; SocketServer2.LOGGER.info(&quot;======socket channel 建立连接=======&quot;); &#125; else if(readyKey.isValid() &amp;&amp; readyKey.isReadable()) &#123; SocketServer2.LOGGER.info(&quot;======socket channel 数据准备完成，可以去读==读取=======&quot;); readSocketChannel(readyKey); &#125; &#125; &#125; &#125; catch(Exception e) &#123; SocketServer2.LOGGER.error(e.getMessage() , e); &#125; finally &#123; serverSocket.close(); &#125; &#125; /** * 在server socket channel接收到/准备好 一个新的 TCP连接后。 * 就会向程序返回一个新的socketChannel。&lt;br&gt; * 但是这个新的socket channel并没有在selector“选择器/代理器”中注册， * 所以程序还没法通过selector通知这个socket channel的事件。 * 于是我们拿到新的socket channel后，要做的第一个事情就是到selector“选择器/代理器”中注册这个 * socket channel感兴趣的事件 * @param socketChannel 新的socket channel * @param selector selector“选择器/代理器” * @throws Exception */ private static void registerSocketChannel(SocketChannel socketChannel , Selector selector) throws Exception &#123; socketChannel.configureBlocking(false); //socket通道可以且只可以注册三种事件SelectionKey.OP_READ | SelectionKey.OP_WRITE | SelectionKey.OP_CONNECT //最后一个参数视为 为这个socketchanne分配的缓存区 socketChannel.register(selector, SelectionKey.OP_READ , ByteBuffer.allocate(50)); &#125; /** * 这个方法用于读取从客户端传来的信息。 * 并且观察从客户端过来的socket channel在经过多次传输后，是否完成传输。 * 如果传输完成，则返回一个true的标记。 * @param socketChannel * @throws Exception */ private static void readSocketChannel(SelectionKey readyKey) throws Exception &#123; SocketChannel clientSocketChannel = (SocketChannel)readyKey.channel(); //获取客户端使用的端口 InetSocketAddress sourceSocketAddress = (InetSocketAddress)clientSocketChannel.getRemoteAddress(); Integer resoucePort = sourceSocketAddress.getPort(); //拿到这个socket channel使用的缓存区，准备读取数据 //在后文，将详细讲解缓存区的用法概念，实际上重要的就是三个元素capacity,position和limit。 ByteBuffer contextBytes = (ByteBuffer)readyKey.attachment(); //将通道的数据写入到缓存区，注意是写入到缓存区。 //这次，为了演示buff的使用方式，我们故意缩小了buff的容量大小到50byte， //以便演示channel对buff的多次读写操作 int realLen = 0; StringBuffer message = new StringBuffer(); //这句话的意思是，将目前通道中的数据写入到缓存区 //最大可写入的数据量就是buff的容量 while((realLen = clientSocketChannel.read(contextBytes)) != 0) &#123; //一定要把buffer切换成“读”模式，否则由于limit = capacity //在read没有写满的情况下，就会导致多读 contextBytes.flip(); int position = contextBytes.position(); int capacity = contextBytes.capacity(); byte[] messageBytes = new byte[capacity]; contextBytes.get(messageBytes, position, realLen); //这种方式也是可以读取数据的，而且不用关心position的位置。 //因为是目前contextBytes所有的数据全部转出为一个byte数组。 //使用这种方式时，一定要自己控制好读取的最终位置(realLen很重要) //byte[] messageBytes = contextBytes.array(); //注意中文乱码的问题，我个人喜好是使用URLDecoder/URLEncoder，进行解编码。 //当然java nio框架本身也提供编解码方式，看个人咯 String messageEncode = new String(messageBytes , 0 , realLen , &quot;UTF-8&quot;); message.append(messageEncode); //再切换成“写”模式，直接情况缓存的方式，最快捷 contextBytes.clear(); &#125; //如果发现本次接收的信息中有over关键字，说明信息接收完了 if(URLDecoder.decode(message.toString(), &quot;UTF-8&quot;).indexOf(&quot;over&quot;) != -1) &#123; //则从messageHashContext中，取出之前已经收到的信息，组合成完整的信息 Integer channelUUID = clientSocketChannel.hashCode(); SocketServer2.LOGGER.info(&quot;端口:&quot; + resoucePort + &quot;客户端发来的信息======message : &quot; + message); StringBuffer completeMessage; //清空MESSAGEHASHCONTEXT中的历史记录 StringBuffer historyMessage = MESSAGEHASHCONTEXT.remove(channelUUID); if(historyMessage == null) &#123; completeMessage = message; &#125; else &#123; completeMessage = historyMessage.append(message); &#125; SocketServer2.LOGGER.info(&quot;端口:&quot; + resoucePort + &quot;客户端发来的完整信息======completeMessage : &quot; + URLDecoder.decode(completeMessage.toString(), &quot;UTF-8&quot;)); //====================================================== // 当然接受完成后，可以在这里正式处理业务了 //====================================================== //回发数据，并关闭channel ByteBuffer sendBuffer = ByteBuffer.wrap(URLEncoder.encode(&quot;回发处理结果&quot;, &quot;UTF-8&quot;).getBytes()); clientSocketChannel.write(sendBuffer); clientSocketChannel.close(); &#125; else &#123; //如果没有发现有“over”关键字，说明还没有接受完，则将本次接受到的信息存入messageHashContext SocketServer2.LOGGER.info(&quot;端口:&quot; + resoucePort + &quot;客户端信息还未接受完，继续接受======message : &quot; + URLDecoder.decode(message.toString(), &quot;UTF-8&quot;)); //每一个channel对象都是独立的，所以可以使用对象的hash值，作为唯一标示 Integer channelUUID = clientSocketChannel.hashCode(); //然后获取这个channel下以前已经达到的message信息 StringBuffer historyMessage = MESSAGEHASHCONTEXT.get(channelUUID); if(historyMessage == null) &#123; historyMessage = new StringBuffer(); MESSAGEHASHCONTEXT.put(channelUUID, historyMessage.append(message)); &#125; &#125; &#125;&#125; 以上代码应该没有过多需要讲解的了。当然，您还是可以加入线程池技术，进行具体的业务处理。注意，一定是线程池，因为这样可以保证线程规模的可控性。 多路复用IO的优缺点 不用再使用多线程来进行IO处理了(包括操作系统内核IO管理模块和应用程序进程而言)。当然实际业务的处理中，应用程序进程还是可以引入线程池技术的 同一个端口可以处理多种协议，例如，使用ServerSocketChannel测测的服务器端口监听，既可以处理TCP协议又可以处理UDP协议。 操作系统级别的优化: 多路复用IO技术可以是操作系统级别在一个端口上能够同时接受多个客户端的IO事件。同时具有之前我们讲到的阻塞式同步IO和非阻塞式同步IO的所有特点。Selector的一部分作用更相当于“轮询代理器”。 都是同步IO: 目前我们介绍的 阻塞式IO、非阻塞式IO甚至包括多路复用IO，这些都是基于操作系统级别对“同步IO”的实现。我们一直在说“同步IO”，一直都没有详细说，什么叫做“同步IO”。实际上一句话就可以说清楚: 只有上层(包括上层的某种代理机制)系统询问我是否有某个事件发生了，否则我不会主动告诉上层系统事件发生了: 参考文章 文章主要来源于: 银文杰，笔名“说好不能打脸”，博客地址。他的书《高性能服务系统构建与实战》。 https://blog.csdn.net/yinwenjie/article/details/48522403","tags":["Java","IO","NIO","IO多路复用"],"categories":["Java","IO","NIO"]},{"title":"7.IO 模型 - Unix IO 模型","path":"/2023/12/26/7-IO-模型-Unix-IO-模型/","content":"本文主要简要介绍 Unix I&#x2F;O 5种模型，并对5大模型比较，并重点为后续章节解释IO多路复用做铺垫。 Unix IO 模型简介一个输入操作通常包括两个阶段: 等待数据准备好 从内核向进程复制数据 对于一个套接字上的输入操作，第一步通常涉及等待数据从网络中到达。当所等待分组到达时，它被复制到内核中的某个缓冲区。第二步就是把数据从内核缓冲区复制到应用进程缓冲区。 Unix 下有五种 I&#x2F;O 模型: 阻塞式 I&#x2F;O 非阻塞式 I&#x2F;O I&#x2F;O 复用(select 和 poll) 信号驱动式 I&#x2F;O(SIGIO) 异步 I&#x2F;O(AIO) 阻塞式 I&#x2F;O应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。 应该注意到，在阻塞的过程中，其它程序还可以执行，因此阻塞不意味着整个操作系统都被阻塞。因为其他程序还可以执行，因此不消耗 CPU 时间，这种模型的执行效率会比较高。 下图中，recvfrom 用于接收 Socket 传来的数据，并复制到应用进程的缓冲区 buf 中。这里把 recvfrom() 当成系统调用。 1ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); 或者网友提供的 非阻塞式 I&#x2F;O应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I&#x2F;O 是否完成，这种方式称为轮询(polling)。 由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的。 或者网友提供的 I&#x2F;O 复用使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读，这一过程会被阻塞，当某一个套接字可读时返回。之后再使用 recvfrom 把数据从内核复制到进程中。 它可以让单个进程具有处理多个 I&#x2F;O 事件的能力。又被称为 Event Driven I&#x2F;O，即事件驱动 I&#x2F;O。 如果一个 Web 服务器没有 I&#x2F;O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I&#x2F;O 复用不需要进程线程创建和切换的开销，系统开销更小。 或者网友提供的 信号驱动 I&#x2F;O应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。 相比于非阻塞式 I&#x2F;O 的轮询方式，信号驱动 I&#x2F;O 的 CPU 利用率更高。 或者网友提供的 异步 I&#x2F;O进行 aio_read 系统调用会立即返回，应用进程继续执行，不会被阻塞，内核会在所有操作完成之后向应用进程发送信号。 异步 I&#x2F;O 与信号驱动 I&#x2F;O 的区别在于，异步 I&#x2F;O 的信号是通知应用进程 I&#x2F;O 完成，而信号驱动 I&#x2F;O 的信号是通知应用进程可以开始 I&#x2F;O。 或者网友提供的 I&#x2F;O 模型比较同步 I&#x2F;O 与异步 I&#x2F;O 同步 I&#x2F;O: 应用进程在调用 recvfrom 操作时会阻塞。 异步 I&#x2F;O: 不会阻塞。 阻塞式 I&#x2F;O、非阻塞式 I&#x2F;O、I&#x2F;O 复用和信号驱动 I&#x2F;O 都是同步 I&#x2F;O，虽然非阻塞式 I&#x2F;O 和信号驱动 I&#x2F;O 在等待数据阶段不会阻塞，但是在之后的将数据从内核复制到应用进程这个操作会阻塞。 五大 I&#x2F;O 模型比较前四种 I&#x2F;O 模型的主要区别在于第一个阶段，而第二个阶段是一样的: 将数据从内核复制到应用进程过程中，应用进程会被阻塞。 IO多路复用 IO多路复用最为重要，后面的文章Java NIO - IO多路复用详解将对IO多路复用，Ractor模型以及Java NIO对其的支持作详解。 这里主要概要性的理解: IO多路复用工作模式和应用。 IO多路复用工作模式epoll 的描述符事件有两种触发模式: LT(level trigger)和 ET(edge trigger)。 1. LT 模式当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。 2. ET 模式和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。 很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读&#x2F;阻塞写操作把处理多个文件描述符的任务饿死。 应用场景很容易产生一种错觉认为只要用 epoll 就可以了，select 和 poll 都已经过时了，其实它们都有各自的使用场景。 1. select 应用场景select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如核反应堆的控制。 select 可移植性更好，几乎被所有主流平台所支持。 2. poll 应用场景poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。 需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。 需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。 3. epoll 应用场景只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。 参考资料 Stevens W R, Fenner B, Rudoff A M. UNIX network programming[M]. Addison-Wesley Professional, 2004. Boost application performance using asynchronous I&#x2F;O在新窗口打开 Synchronous and Asynchronous I&#x2F;O在新窗口打开 Linux IO 模式及 select、poll、epoll 详解在新窗口打开 poll vs select vs event-based在新窗口打开 select &#x2F; poll &#x2F; epoll: practical difference for system architects在新窗口打开 Browse the source code of userspace&#x2F;glibc&#x2F;sysdeps&#x2F;unix&#x2F;sysv&#x2F;linux&#x2F; online","tags":["Unix","IO模型"],"categories":["Unix","IO模型"]},{"title":"6.Java IO - 常见类使用","path":"/2023/12/26/6-Java-IO-常见类使用/","content":"本文主要介绍Java IO常见类的使用，包括：磁盘操作，字节操作，字符操作，对象操作和网络操作。 @pdai IO常见类的使用Java 的 I&#x2F;O 大概可以分成以下几类: 磁盘操作: File 字节操作: InputStream 和 OutputStream 字符操作: Reader 和 Writer 对象操作: Serializable 网络操作: Socket File相关File 类可以用于表示文件和目录的信息，但是它不表示文件的内容。 递归地列出一个目录下所有文件: 123456789101112public static void listAllFiles(File dir) &#123; if (dir == null || !dir.exists()) &#123; return; &#125; if (dir.isFile()) &#123; System.out.println(dir.getName()); return; &#125; for (File file : dir.listFiles()) &#123; listAllFiles(file); &#125;&#125; 字节流相关12345678910111213141516public static void copyFile(String src, String dist) throws IOException &#123; FileInputStream in = new FileInputStream(src); FileOutputStream out = new FileOutputStream(dist); byte[] buffer = new byte[20 * 1024]; // read() 最多读取 buffer.length 个字节 // 返回的是实际读取的个数 // 返回 -1 的时候表示读到 eof，即文件尾 while (in.read(buffer, 0, buffer.length) != -1) &#123; out.write(buffer); &#125; in.close(); out.close();&#125; 实现逐行输出文本文件的内容123456789101112131415public static void readFileContent(String filePath) throws IOException &#123; FileReader fileReader = new FileReader(filePath); BufferedReader bufferedReader = new BufferedReader(fileReader); String line; while ((line = bufferedReader.readLine()) != null) &#123; System.out.println(line); &#125; // 装饰者模式使得 BufferedReader 组合了一个 Reader 对象 // 在调用 BufferedReader 的 close() 方法时会去调用 Reader 的 close() 方法 // 因此只要一个 close() 调用即可 bufferedReader.close();&#125; 序列化 &amp; Serializable &amp; transient序列化就是将一个对象转换成字节序列，方便存储和传输。 序列化: ObjectOutputStream.writeObject() 反序列化: ObjectInputStream.readObject() 不会对静态变量进行序列化，因为序列化只是保存对象的状态，静态变量属于类的状态。 Serializable 序列化的类需要实现 Serializable 接口，它只是一个标准，没有任何方法需要实现，但是如果不去实现它的话而进行序列化，会抛出异常。 123456789101112131415161718192021222324252627public static void main(String[] args) throws IOException, ClassNotFoundException &#123; A a1 = new A(123, &quot;abc&quot;); String objectFile = &quot;file/a1&quot;; ObjectOutputStream objectOutputStream = new ObjectOutputStream(new FileOutputStream(objectFile)); objectOutputStream.writeObject(a1); objectOutputStream.close(); ObjectInputStream objectInputStream = new ObjectInputStream(new FileInputStream(objectFile)); A a2 = (A) objectInputStream.readObject(); objectInputStream.close(); System.out.println(a2);&#125;private static class A implements Serializable &#123; private int x; private String y; A(int x, String y) &#123; this.x = x; this.y = y; &#125; @Override public String toString() &#123; return &quot;x = &quot; + x + &quot; &quot; + &quot;y = &quot; + y; &#125;&#125; transient transient 关键字可以使一些属性不会被序列化。 ArrayList 中存储数据的数组 elementData 是用 transient 修饰的，因为这个数组是动态扩展的，并不是所有的空间都被使用，因此就不需要所有的内容都被序列化。通过重写序列化和反序列化方法，使得可以只序列化数组中有内容的那部分数据。 1private transient Object[] elementData; Java 中的网络支持: InetAddress: 用于表示网络上的硬件资源，即 IP 地址； URL: 统一资源定位符； Sockets: 使用 TCP 协议实现网络通信； Datagram: 使用 UDP 协议实现网络通信。 InetAddress没有公有的构造函数，只能通过静态方法来创建实例。 12InetAddress.getByName(String host);InetAddress.getByAddress(byte[] address); URL可以直接从 URL 中读取字节流数据。 1234567891011121314151617181920public static void main(String[] args) throws IOException &#123; URL url = new URL(&quot;http://www.baidu.com&quot;); /* 字节流 */ InputStream is = url.openStream(); /* 字符流 */ InputStreamReader isr = new InputStreamReader(is, &quot;utf-8&quot;); /* 提供缓存功能 */ BufferedReader br = new BufferedReader(isr); String line; while ((line = br.readLine()) != null) &#123; System.out.println(line); &#125; br.close();&#125; Sockets ServerSocket: 服务器端类 Socket: 客户端类 服务器和客户端通过 InputStream 和 OutputStream 进行输入输出。 Datagram DatagramSocket: 通信类 DatagramPacket: 数据包类 常见问题 Java 字节读取流的read方法返回int的原因","tags":["Java","IO"],"categories":["Java","IO"]},{"title":"5.Java IO - 源码: OutputStream","path":"/2023/12/26/5-Java-IO-源码-OutputStream/","content":"本文主要从JDK 11源码角度分析 OutputStream。 OutputStream 类实现关系 OutputStream是输出字节流，具体的实现类层次结构如下： OutputStream 抽象类OutputStream 类重要方法设计如下： 1234567891011121314// 写入一个字节，可以看到这里的参数是一个 int 类型，对应上面的读方法，int 类型的 32 位，只有低 8 位才写入，高 24 位将舍弃。public abstract void write(int b)// 将数组中的所有字节写入，实际调用的是write(byte b[], int off, int len)方法。public void write(byte b[])// 将 byte 数组从 off 位置开始，len 长度的字节写入public void write(byte b[], int off, int len)// 强制刷新，将缓冲中的数据写入; 默认是空实现，供子类覆盖public void flush()// 关闭输出流，流被关闭后就不能再输出数据了; 默认是空实现，供子类覆盖public void close() 源码实现 梳理部分OutputStream及其实现类的源码分析。 OutputStreamOutputStream抽象类源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public abstract class OutputStream implements Closeable, Flushable &#123; // JDK11中增加了一个nullOutputStream，即空模式实现，以便可以直接调用而不用判空（可以看如下的补充说明） public static OutputStream nullOutputStream() &#123; return new OutputStream() &#123; private volatile boolean closed; private void ensureOpen() throws IOException &#123; if (closed) &#123; throw new IOException(&quot;Stream closed&quot;); &#125; &#125; @Override public void write(int b) throws IOException &#123; ensureOpen(); &#125; @Override public void write(byte b[], int off, int len) throws IOException &#123; Objects.checkFromIndexSize(off, len, b.length); ensureOpen(); &#125; @Override public void close() &#123; closed = true; &#125; &#125;; &#125; // 写入一个字节，可以看到这里的参数是一个 int 类型，对应上面的读方法，int 类型的 32 位，只有低 8 位才写入，高 24 位将舍弃。 public abstract void write(int b) throws IOException; // 将数组中的所有字节写入，实际调用的是write(byte b[], int off, int len)方法 public void write(byte b[]) throws IOException &#123; write(b, 0, b.length); &#125; // 将 byte 数组从 off 位置开始，len 长度的字节写入 public void write(byte b[], int off, int len) throws IOException &#123; // 检查边界合理性 Objects.checkFromIndexSize(off, len, b.length); // len == 0 的情况已经在如下的for循环中隐式处理了 for (int i = 0 ; i &lt; len ; i++) &#123; write(b[off + i]); &#125; &#125; // 强制刷新，将缓冲中的数据写入; 默认是空实现，供子类覆盖 public void flush() throws IOException &#123; &#125; // 关闭输出流，流被关闭后就不能再输出数据了; 默认是空实现，供子类覆盖 public void close() throws IOException &#123; &#125;&#125; 补充下JDK11为什么会增加nullOutputStream方法的设计？即空对象模式 空对象模式 举个例子： 123456789101112public class MyParser implements Parser &#123; private static Action NO_ACTION = new Action() &#123; public void doSomething() &#123; /* do nothing */ &#125; &#125;; public Action findAction(String userInput) &#123; // ... if ( /* we can&#x27;t find any actions */ ) &#123; return NO_ACTION; &#125; &#125;&#125; 然后便可以始终可以这么调用，而不用再判断空了 1ParserFactory.getParser().findAction(someInput).doSomething(); FilterOutputStreamFilterOutputStream 源码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class FilterOutputStream extends OutputStream &#123; // 被装饰的实际outputStream protected OutputStream out; // 当前stream是否已经被close private volatile boolean closed; // close stream时加锁，防止其它线程同时close private final Object closeLock = new Object(); // 初始化构造函数，传入被装饰的实际outputStream public FilterOutputStream(OutputStream out) &#123; this.out = out; &#125; // 写入数据，本质调用被装饰outputStream的方法 @Override public void write(int b) throws IOException &#123; out.write(b); &#125; // 将数组中的所有字节写入 @Override public void write(byte b[]) throws IOException &#123; write(b, 0, b.length); &#125; // 一个个写入 @Override public void write(byte b[], int off, int len) throws IOException &#123; if ((off | len | (b.length - (len + off)) | (off + len)) &lt; 0) throw new IndexOutOfBoundsException(); for (int i = 0 ; i &lt; len ; i++) &#123; write(b[off + i]); &#125; &#125; // 强制刷新，将缓冲中的数据写入; 本质调用被装饰outputStream的方法 @Override public void flush() throws IOException &#123; out.flush(); &#125; // 关闭Stream @Override public void close() throws IOException &#123; // 如果已经close, 直接退出 if (closed) &#123; return; &#125; // 加锁处理，如果已经有线程正在closing则退出； synchronized (closeLock) &#123; if (closed) &#123; return; &#125; closed = true; &#125; // close前调用flush Throwable flushException = null; try &#123; flush(); &#125; catch (Throwable e) &#123; flushException = e; throw e; &#125; finally &#123; if (flushException == null) &#123; out.close(); &#125; else &#123; try &#123; out.close(); &#125; catch (Throwable closeException) &#123; // evaluate possible precedence of flushException over closeException if ((flushException instanceof ThreadDeath) &amp;&amp; !(closeException instanceof ThreadDeath)) &#123; flushException.addSuppressed(closeException); throw (ThreadDeath) flushException; &#125; if (flushException != closeException) &#123; closeException.addSuppressed(flushException); &#125; throw closeException; &#125; &#125; &#125; &#125;&#125; 对比下JDK8中，close方法是没有加锁处理的。这种情况下你可以看JDK8源码中，直接利用java7的try with resources方式，优雅的调用flush方法后对out进行关闭。 12345public void close() throws IOException &#123; try (OutputStream ostream = out) &#123; flush(); &#125;&#125; ByteArrayOutputStreamByteArrayOutputStream 源码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118public class ByteArrayOutputStream extends OutputStream &#123; // 实际的byte数组 protected byte buf[]; // 数组中实际有效的byte的个数 protected int count; // 初始化默认构造，初始化byte数组大小为32 public ByteArrayOutputStream() &#123; this(32); &#125; // 初始化byte的大小 public ByteArrayOutputStream(int size) &#123; if (size &lt; 0) &#123; throw new IllegalArgumentException(&quot;Negative initial size: &quot; + size); &#125; buf = new byte[size]; &#125; // 扩容，确保它至少可以容纳由最小容量参数指定的元素数 private void ensureCapacity(int minCapacity) &#123; // overflow-conscious code if (minCapacity - buf.length &gt; 0) grow(minCapacity); &#125; // 分配的最大数组大小。 // 由于一些VM在数组中保留一些头字，所以尝试分配较大的阵列可能会导致OutOfMemoryError（请求的阵列大小超过VM限制） private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; // 扩容的实质方法，确保它至少可以容纳由最小容量参数指定的元素数 private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = buf.length; int newCapacity = oldCapacity &lt;&lt; 1; if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); buf = Arrays.copyOf(buf, newCapacity); &#125; private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE; &#125; // 写入，写入前确保byte数据长度 public synchronized void write(int b) &#123; ensureCapacity(count + 1); buf[count] = (byte) b; count += 1; &#125; public synchronized void write(byte b[], int off, int len) &#123; Objects.checkFromIndexSize(off, len, b.length); ensureCapacity(count + len); System.arraycopy(b, off, buf, count, len); count += len; &#125; public void writeBytes(byte b[]) &#123; write(b, 0, b.length); &#125; public synchronized void writeTo(OutputStream out) throws IOException &#123; out.write(buf, 0, count); &#125; // 重置，显然将实际有效的byte数量置为0 public synchronized void reset() &#123; count = 0; &#125; public synchronized byte[] toByteArray() &#123; return Arrays.copyOf(buf, count); &#125; // 长度，即count public synchronized int size() &#123; return count; &#125; // 转成string public synchronized String toString() &#123; return new String(buf, 0, count); &#125; // 转成string，指定的字符集 public synchronized String toString(String charsetName) throws UnsupportedEncodingException &#123; return new String(buf, 0, count, charsetName); &#125; public synchronized String toString(Charset charset) &#123; return new String(buf, 0, count, charset); &#125; // 弃用 @Deprecated public synchronized String toString(int hibyte) &#123; return new String(buf, hibyte, 0, count); &#125; // 对byte 数组而言，close没啥实质意义，所以空实现 public void close() throws IOException &#123; &#125;&#125; BufferedOutputStreamBufferedOutputStream 源码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class BufferedOutputStream extends FilterOutputStream &#123; // Buffered outputStream底层也是byte数组 protected byte buf[]; // 大小，buf[0]到buf[count-1]是实际存储的bytes protected int count; // 构造函数，被装饰的outputStream，以及默认buf大小是8192 public BufferedOutputStream(OutputStream out) &#123; this(out, 8192); &#125; public BufferedOutputStream(OutputStream out, int size) &#123; super(out); if (size &lt;= 0) &#123; throw new IllegalArgumentException(&quot;Buffer size &lt;= 0&quot;); &#125; buf = new byte[size]; &#125; /** Flush the internal buffer */ // 内部的flush方法，将buffer中的有效bytes(count是有效的bytes大小)通过被装饰的outputStream写入 private void flushBuffer() throws IOException &#123; if (count &gt; 0) &#123; out.write(buf, 0, count); count = 0; &#125; &#125; // 写入byte @Override public synchronized void write(int b) throws IOException &#123; // 当buffer满了以后，flush buffer if (count &gt;= buf.length) &#123; flushBuffer(); &#125; buf[count++] = (byte)b; &#125; // 将 byte 数组从 off 位置开始，len 长度的字节写入 @Override public synchronized void write(byte b[], int off, int len) throws IOException &#123; if (len &gt;= buf.length) &#123; // 如果请求长度已经超过输出缓冲区的大小，直接刷新输出缓冲区，然后直接写入数据。 flushBuffer(); out.write(b, off, len); return; &#125; if (len &gt; buf.length - count) &#123; flushBuffer(); &#125; System.arraycopy(b, off, buf, count, len); count += len; &#125; // flush方法，需要先将buffer中写入，最后在调用被装饰outputStream的flush方法 @Override public synchronized void flush() throws IOException &#123; flushBuffer(); out.flush(); &#125;&#125; 参考文章 JDK 11","tags":["Java","IO"],"categories":["Java","IO"]},{"title":"4.Java IO - 源码: InputStream","path":"/2023/12/26/4-Java-IO-源码-InputStream/","content":"本文主要从JDK 11 源码角度分析InputStream。 InputStream 类实现关系 InputStream是输入字节流，具体的实现类层次结构如下： InputStream 抽象类InputStream 类重要方法设计如下： 1234567891011121314151617181920212223242526272829303132333435363738// 读取下一个字节，如果没有则返回-1public abstract int read() // 将读取到的数据放在 byte 数组中，该方法实际上调用read(byte b[], int off, int len)方法public int read(byte b[]) // 从第 off 位置读取&lt;b&gt;最多(实际可能小于)&lt;/b&gt; len 长度字节的数据放到 byte 数组中，流是以 -1 来判断是否读取结束的; 此方法会一直阻止，直到输入数据可用、检测到stream结尾或引发异常为止。public int read(byte b[], int off, int len) // JDK9新增：读取 InputStream 中的所有剩余字节，调用readNBytes(Integer.MAX_VALUE)方法public byte[] readAllBytes()// JDK11更新：读取 InputStream 中的剩余字节的指定上限大小的字节内容；此方法会一直阻塞，直到读取了请求的字节数、检测到流结束或引发异常为止。此方法不会关闭输入流。public byte[] readNBytes(int len)// JDK9新增：从输入流读取请求的字节数并保存在byte数组中； 此方法会一直阻塞，直到读取了请求的字节数、检测到流结束或引发异常为止。此方法不会关闭输入流。public int readNBytes(byte[] b, int off, int len)// 跳过指定个数的字节不读取public long skip(long n) // 返回可读的字节数量public int available() // 读取完，关闭流，释放资源public void close() // 标记读取位置，下次还可以从这里开始读取，使用前要看当前流是否支持，可以使用 markSupport() 方法判断public synchronized void mark(int readlimit) // 重置读取位置为上次 mark 标记的位置public synchronized void reset() // 判断当前流是否支持标记流，和上面两个方法配套使用public boolean markSupported() // JDK9新增：读取 InputStream 中的全部字节并写入到指定的 OutputStream 中public long transferTo(OutputStream out) 源码实现 梳理部分InputStream及其实现类的源码分析。 InputStreamInputStream抽象类源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266public abstract class InputStream implements Closeable &#123; // 当使用skip方法时，最大的buffer size大小 private static final int MAX_SKIP_BUFFER_SIZE = 2048; // 默认的buffer size private static final int DEFAULT_BUFFER_SIZE = 8192; // JDK11中增加了一个nullInputStream，即空模式实现，以便可以直接调用而不用判空（可以看如下的补充说明） public static InputStream nullInputStream() &#123; return new InputStream() &#123; private volatile boolean closed; private void ensureOpen() throws IOException &#123; if (closed) &#123; throw new IOException(&quot;Stream closed&quot;); &#125; &#125; @Override public int available () throws IOException &#123; ensureOpen(); return 0; &#125; @Override public int read() throws IOException &#123; ensureOpen(); return -1; &#125; @Override public int read(byte[] b, int off, int len) throws IOException &#123; Objects.checkFromIndexSize(off, len, b.length); if (len == 0) &#123; return 0; &#125; ensureOpen(); return -1; &#125; @Override public byte[] readAllBytes() throws IOException &#123; ensureOpen(); return new byte[0]; &#125; @Override public int readNBytes(byte[] b, int off, int len) throws IOException &#123; Objects.checkFromIndexSize(off, len, b.length); ensureOpen(); return 0; &#125; @Override public byte[] readNBytes(int len) throws IOException &#123; if (len &lt; 0) &#123; throw new IllegalArgumentException(&quot;len &lt; 0&quot;); &#125; ensureOpen(); return new byte[0]; &#125; @Override public long skip(long n) throws IOException &#123; ensureOpen(); return 0L; &#125; @Override public long transferTo(OutputStream out) throws IOException &#123; Objects.requireNonNull(out); ensureOpen(); return 0L; &#125; @Override public void close() throws IOException &#123; closed = true; &#125; &#125;; &#125; // 读取下一个字节的数据，如果没有则返回-1 public abstract int read() throws IOException; // 将读取到的数据放在 byte 数组中，该方法实际上调用read(byte b[], int off, int len)方法 public int read(byte b[]) throws IOException &#123; return read(b, 0, b.length); &#125; // 从第 off 位置读取&lt;b&gt;最多(实际可能小于)&lt;/b&gt; len 长度字节的数据放到 byte 数组中，流是以 -1 来判断是否读取结束的; 此方法会一直阻止，直到输入数据可用、检测到stream结尾或引发异常为止。 public int read(byte b[], int off, int len) throws IOException &#123; // 检查边界 Objects.checkFromIndexSize(off, len, b.length); if (len == 0) &#123; return 0; &#125; // 读取下一个字节 int c = read(); if (c == -1) &#123; // 读到stream末尾，则返回读取的字节数量为-1 return -1; &#125; b[off] = (byte)c; // i用来记录取了多少个字节 int i = 1; try &#123; // 循环读取 for (; i &lt; len ; i++) &#123; c = read(); if (c == -1) &#123;// 读到stream末尾，则break break; &#125; b[off + i] = (byte)c; &#125; &#125; catch (IOException ee) &#123; &#125; // 返回读取到的字节个数 return i; &#125; // 分配的最大数组大小。 // 由于一些VM在数组中保留一些头字，所以尝试分配较大的阵列可能会导致OutOfMemoryError（请求的阵列大小超过VM限制） private static final int MAX_BUFFER_SIZE = Integer.MAX_VALUE - 8; // JDK9新增：读取 InputStream 中的所有剩余字节，调用readNBytes(Integer.MAX_VALUE)方法 public byte[] readAllBytes() throws IOException &#123; return readNBytes(Integer.MAX_VALUE); &#125; // JDK11更新：读取 InputStream 中的剩余字节的指定上限大小的字节内容；此方法会一直阻塞，直到读取了请求的字节数、检测到流结束或引发异常为止。此方法不会关闭输入流。 public byte[] readNBytes(int len) throws IOException &#123; // 边界检查 if (len &lt; 0) &#123; throw new IllegalArgumentException(&quot;len &lt; 0&quot;); &#125; List&lt;byte[]&gt; bufs = null; // 缓存每次读取到的内容放到bufs，最后组装成result byte[] result = null; // 最后读取到的内容 int total = 0; int remaining = len; // 剩余字节长度 int n; do &#123; byte[] buf = new byte[Math.min(remaining, DEFAULT_BUFFER_SIZE)]; int nread = 0; // 读取到结束为止，读取大小n可能大于或小于缓冲区大小 while ((n = read(buf, nread, Math.min(buf.length - nread, remaining))) &gt; 0) &#123; nread += n; remaining -= n; &#125; if (nread &gt; 0) &#123; if (MAX_BUFFER_SIZE - total &lt; nread) &#123; throw new OutOfMemoryError(&quot;Required array size too large&quot;); &#125; total += nread; if (result == null) &#123; result = buf; &#125; else &#123; if (bufs == null) &#123; bufs = new ArrayList&lt;&gt;(); bufs.add(result); &#125; bufs.add(buf); &#125; &#125; // 如果读不到内容（返回-1）或者没有剩余的字节，则跳出循环 &#125; while (n &gt;= 0 &amp;&amp; remaining &gt; 0); if (bufs == null) &#123; if (result == null) &#123; return new byte[0]; &#125; return result.length == total ? result : Arrays.copyOf(result, total); &#125; // 组装最后的result result = new byte[total]; int offset = 0; remaining = total; for (byte[] b : bufs) &#123; int count = Math.min(b.length, remaining); System.arraycopy(b, 0, result, offset, count); offset += count; remaining -= count; &#125; return result; &#125; // JDK9新增：从输入流读取请求的字节数并保存在byte数组中； 此方法会一直阻塞，直到读取了请求的字节数、检测到流结束或引发异常为止。此方法不会关闭输入流。 public int readNBytes(byte[] b, int off, int len) throws IOException &#123; Objects.checkFromIndexSize(off, len, b.length); int n = 0; while (n &lt; len) &#123; int count = read(b, off + n, len - n); if (count &lt; 0) break; n += count; &#125; return n; &#125; // 跳过指定个数的字节不读取 public long skip(long n) throws IOException &#123; long remaining = n; int nr; if (n &lt;= 0) &#123; return 0; &#125; int size = (int)Math.min(MAX_SKIP_BUFFER_SIZE, remaining); byte[] skipBuffer = new byte[size]; while (remaining &gt; 0) &#123; nr = read(skipBuffer, 0, (int)Math.min(size, remaining)); if (nr &lt; 0) &#123; break; &#125; remaining -= nr; &#125; return n - remaining; &#125; // 返回可读的字节数量 public int available() throws IOException &#123; return 0; &#125; // 读取完，关闭流，释放资源 public void close() throws IOException &#123;&#125; // 标记读取位置，下次还可以从这里开始读取，使用前要看当前流是否支持，可以使用 markSupport() 方法判断 public synchronized void mark(int readlimit) &#123;&#125; // 重置读取位置为上次 mark 标记的位置 public synchronized void reset() throws IOException &#123; throw new IOException(&quot;mark/reset not supported&quot;); &#125; // 判断当前流是否支持标记流，和上面两个方法配套使用。默认是false，由子类方法重写 public boolean markSupported() &#123; return false; &#125; // JDK9新增：读取 InputStream 中的全部字节并写入到指定的 OutputStream 中 public long transferTo(OutputStream out) throws IOException &#123; Objects.requireNonNull(out, &quot;out&quot;); long transferred = 0; byte[] buffer = new byte[DEFAULT_BUFFER_SIZE]; int read; while ((read = this.read(buffer, 0, DEFAULT_BUFFER_SIZE)) &gt;= 0) &#123; out.write(buffer, 0, read); transferred += read; &#125; return transferred; &#125; 总结下JDK9的更新点 类 java.io.InputStream 中增加了新的方法来读取和复制 InputStream 中包含的数据。 readAllBytes：读取 InputStream 中的所有剩余字节。 readNBytes： 从 InputStream 中读取指定数量的字节到数组中。 transferTo：读取 InputStream 中的全部字节并写入到指定的 OutputStream 中 。 1234567891011121314151617181920212223242526public class TestInputStream &#123; private InputStream inputStream; private static final String CONTENT = &quot;Hello World&quot;; @Before public void setUp() throws Exception &#123; this.inputStream = TestInputStream.class.getResourceAsStream(&quot;/input.txt&quot;); &#125; @Test public void testReadAllBytes() throws Exception &#123; final String content = new String(this.inputStream.readAllBytes()); assertEquals(CONTENT, content); &#125; @Test public void testReadNBytes() throws Exception &#123; final byte[] data = new byte[5]; this.inputStream.readNBytes(data, 0, 5); assertEquals(&quot;Hello&quot;, new String(data)); &#125; @Test public void testTransferTo() throws Exception &#123; final ByteArrayOutputStream outputStream = new ByteArrayOutputStream(); this.inputStream.transferTo(outputStream); assertEquals(CONTENT, outputStream.toString()); &#125;&#125; read(byte[], int, int) 和 readNBytes(byte[], int, int)看似是实现的相同功能，为何会设计readNBytes方法呢？ 这个问题可以参看这里 read(byte[], int, int)是尝试读到最多len个bytes，但是读取到的内容长度可能是小于len的。 readNBytes(byte[], int, int) 会一直（while循环）查找直到stream尾为止 举个例子：如果文本内容是12345&lt;end&gt;, read(s,0,10)是允许返回123的, 而readNbytes(s,0,10)会一直（while循环）查找直到stream尾为止，并返回12345. 补充下JDK11为什么会增加nullInputStream方法的设计？即空对象模式 空对象模式 举个例子： 123456789101112public class MyParser implements Parser &#123; private static Action NO_ACTION = new Action() &#123; public void doSomething() &#123; /* do nothing */ &#125; &#125;; public Action findAction(String userInput) &#123; // ... if ( /* we can&#x27;t find any actions */ ) &#123; return NO_ACTION; &#125; &#125;&#125; 然后便可以始终可以这么调用，而不用再判断空了 1ParserFactory.getParser().findAction(someInput).doSomething(); FilterInputStreamFilterInputStream 源码如下 123456789101112131415161718192021222324252627282930313233343536373839public class FilterInputStream extends InputStream &#123; // 被装饰的inputStream protected volatile InputStream in; // 构造函数，注入被装饰的inputStream protected FilterInputStream(InputStream in) &#123; this.in = in; &#125; // 本质是调用被装饰的inputStream的方法 public int read() throws IOException &#123; return in.read(); &#125; public int read(byte b[]) throws IOException &#123; return read(b, 0, b.length); &#125; public int read(byte b[], int off, int len) throws IOException &#123; return in.read(b, off, len); &#125; public long skip(long n) throws IOException &#123; return in.skip(n); &#125; public int available() throws IOException &#123; return in.available(); &#125; public void close() throws IOException &#123; in.close(); &#125; public synchronized void mark(int readlimit) &#123; in.mark(readlimit); &#125; public synchronized void reset() throws IOException &#123; in.reset(); &#125; public boolean markSupported() &#123; return in.markSupported(); &#125;&#125; 为什么被装饰的inputStream是volatile类型的？ 请参看： 关键字: volatile详解 ByteArrayInputStreamByteArrayInputStream源码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697public class ByteArrayInputStream extends InputStream &#123; // 内部保存的byte 数组 protected byte buf[]; // 读取下一个字节的数组下标，byte[pos]就是read获取的下个字节 protected int pos; // mark的数组下标位置 protected int mark = 0; // 保存的有效byte的个数 protected int count; // 构造方法 public ByteArrayInputStream(byte buf[]) &#123; this.buf = buf; this.pos = 0; this.count = buf.length; &#125; // 构造方法，带offset的 public ByteArrayInputStream(byte buf[], int offset, int length) &#123; this.buf = buf; this.pos = offset; this.count = Math.min(offset + length, buf.length); this.mark = offset; &#125; // 从流中读取下一个字节，没有读取到返回 -1 public synchronized int read() &#123; return (pos &lt; count) ? (buf[pos++] &amp; 0xff) : -1; &#125; // 从第 off 位置读取&lt;b&gt;最多(实际可能小于)&lt;/b&gt; len 长度字节的数据放到 byte 数组中，流是以 -1 来判断是否读取结束的 public synchronized int read(byte b[], int off, int len) &#123; // 边界检查 if (b == null) &#123; throw new NullPointerException(); &#125; else if (off &lt; 0 || len &lt; 0 || len &gt; b.length - off) &#123; throw new IndexOutOfBoundsException(); &#125; if (pos &gt;= count) &#123; return -1; &#125; int avail = count - pos; if (len &gt; avail) &#123; len = avail; &#125; if (len &lt;= 0) &#123; return 0; &#125; // 从buf拷贝到byte 数组b中 System.arraycopy(buf, pos, b, off, len); pos += len; return len; &#125; // 跳过指定个数的字节不读取 public synchronized long skip(long n) &#123; long k = count - pos; if (n &lt; k) &#123; k = n &lt; 0 ? 0 : n; &#125; pos += k; return k; &#125; // 还有稍稍byte在buffer中未读取，即总的count 减去 当前byte位置 public synchronized int available() &#123; return count - pos; &#125; // 支持mark所以返回true public boolean markSupported() &#123; return true; &#125; // 在流中当前位置mark, readAheadLimit参数未使用 public void mark(int readAheadLimit) &#123; mark = pos; &#125; // 重置流，即回到mark的位置 public synchronized void reset() &#123; pos = mark; &#125; // 关闭ByteArrayInputStream不会产生任何动作 public void close() throws IOException &#123; &#125;&#125; BufferedInputStreamBufferedInputStream源码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246public class BufferedInputStream extends FilterInputStream &#123; // 默认的buffer大小 private static int DEFAULT_BUFFER_SIZE = 8192; // 分配的最大数组大小。 // 由于一些VM在数组中保留一些头字，所以尝试分配较大的阵列可能会导致OutOfMemoryError（请求的阵列大小超过VM限制） private static int MAX_BUFFER_SIZE = Integer.MAX_VALUE - 8; // 内部保存在byte 数组中 protected volatile byte buf[]; // 关闭流的方法可能是异步的，所以使用原子AtomicReferenceFieldUpdater提供CAS无锁方式（可以解决CAS的ABA问题）来保证 private static final AtomicReferenceFieldUpdater&lt;BufferedInputStream, byte[]&gt; bufUpdater = AtomicReferenceFieldUpdater.newUpdater(BufferedInputStream.class, byte[].class, &quot;buf&quot;); // 有效byte的大小 protected int count; // 当前位置 protected int pos; // 最后一次，调用mark方法，标记的位置 protected int markpos = -1; /** * 该变量惟一入口就是mark(int readLimit)，好比调用方法mark(1024)，那么后面读取的数据若是 * 超过了1024字节，那么这次mark就为无效标记，子类能够选择抛弃该mark标记，从头开始。不过具体实现 * 跟具体的子类有关，在BufferedInputStream中，会抛弃mark标记，从新将markpos赋值为-1 */ protected int marklimit; // 获取被装饰的stream private InputStream getInIfOpen() throws IOException &#123; InputStream input = in; if (input == null) throw new IOException(&quot;Stream closed&quot;); return input; &#125; // 获取实际内部的buffer数组 private byte[] getBufIfOpen() throws IOException &#123; byte[] buffer = buf; if (buffer == null) throw new IOException(&quot;Stream closed&quot;); return buffer; &#125; // 构造函数，buffer是8kb public BufferedInputStream(InputStream in) &#123; this(in, DEFAULT_BUFFER_SIZE); &#125; // 构造函数，指定buffer大小 public BufferedInputStream(InputStream in, int size) &#123; super(in); if (size &lt;= 0) &#123; throw new IllegalArgumentException(&quot;Buffer size &lt;= 0&quot;); &#125; buf = new byte[size]; &#125; /** * 用更多的数据填充缓冲区,考虑到shuffling和其他处理标记的技巧， * 假设它是由同步方法调用的。该方法还假设所有数据已经被读入，因此pos &gt;count。 */ private void fill() throws IOException &#123; // 得到内部缓冲区buffer byte[] buffer = getBufIfOpen(); // 没有mark的情况下， pos为0 if (markpos &lt; 0) pos = 0; /* no mark: throw away the buffer */ // pos &gt;= buffer.length buffer已经被读取完了 else if (pos &gt;= buffer.length) /* no room left in buffer */ // markpos &gt; 0 有标记，标记处在缓存中间 if (markpos &gt; 0) &#123; /* can throw away early part of the buffer */ // 把buffer中，markpos到pos的部分移动到0-sz处，pos设置为sz，markpos为0 int sz = pos - markpos; System.arraycopy(buffer, markpos, buffer, 0, sz); pos = sz; markpos = 0; // markpos已经为0了，marklimit比buffer.length小，再读取buffer已经没有地方了 &#125; else if (buffer.length &gt;= marklimit) &#123; // 清空缓存，清空标记，markpos为-1，pos为0 markpos = -1; /* buffer got too big, invalidate mark */ pos = 0; /* drop buffer contents */ // markpos已经为0了，marklimit比buffer.length大，而buffer.length已经最大了，不能扩容 &#125; else if (buffer.length &gt;= MAX_BUFFER_SIZE) &#123; throw new OutOfMemoryError(&quot;Required array size too large&quot;); // markpos已经为0了，marklimit比buffer.length大 &#125; else &#123; /* grow buffer */ // 建立一个长度为min(2*pos,marklimit,MAX_BUFFER_SIZE),的缓存数组，然后把原来0-pos移动到新数组的0-pos处 int nsz = (pos &lt;= MAX_BUFFER_SIZE - pos) ? pos * 2 : MAX_BUFFER_SIZE; if (nsz &gt; marklimit) nsz = marklimit; byte nbuf[] = new byte[nsz]; System.arraycopy(buffer, 0, nbuf, 0, pos); // 用bufUpdater替换buffer if (!bufUpdater.compareAndSet(this, buffer, nbuf)) &#123; // Can&#x27;t replace buf if there was an async close. // Note: This would need to be changed if fill() // is ever made accessible to multiple threads. // But for now, the only way CAS can fail is via close. // assert buf == null; throw new IOException(&quot;Stream closed&quot;); &#125; buffer = nbuf; &#125; // 当前读取上限count为pos count = pos; // 从内部的输入流，读取pos到buffer.length部分，读取的字节数加到count int n = getInIfOpen().read(buffer, pos, buffer.length - pos); if (n &gt; 0) count = n + pos; &#125; // 读取byte public synchronized int read() throws IOException &#123; // 说明当前buf[]数组大小不够了，须要fill() if (pos &gt;= count) &#123; fill(); // 说明没有读取到任何数据 if (pos &gt;= count) return -1; &#125; return getBufIfOpen()[pos++] &amp; 0xff; &#125; /** * Read characters into a portion of an array, reading from the underlying * stream at most once if necessary. */ private int read1(byte[] b, int off, int len) throws IOException &#123; int avail = count - pos; if (avail &lt;= 0) &#123; // 当写入指定数组b的长度大小超过BufferedInputStream中核心缓存数组buf[]的大小而且 markpos &lt; 0，那么就直接从数据流中读取数据给b数组，而不经过buf[]缓存数组，避免buf[]数组急剧增大 if (len &gt;= getBufIfOpen().length &amp;&amp; markpos &lt; 0) &#123; return getInIfOpen().read(b, off, len); &#125; fill(); avail = count - pos; if (avail &lt;= 0) return -1; &#125; int cnt = (avail &lt; len) ? avail : len; System.arraycopy(getBufIfOpen(), pos, b, off, cnt); pos += cnt; return cnt; &#125; // 读取到byte数组b中 public synchronized int read(byte b[], int off, int len) throws IOException &#123; getBufIfOpen(); // Check for closed stream if ((off | len | (off + len) | (b.length - (off + len))) &lt; 0) &#123; throw new IndexOutOfBoundsException(); &#125; else if (len == 0) &#123; return 0; &#125; int n = 0; for (;;) &#123; int nread = read1(b, off + n, len - n); if (nread &lt;= 0) return (n == 0) ? nread : n; n += nread; if (n &gt;= len) return n; // if not closed but no bytes available, return InputStream input = in; if (input != null &amp;&amp; input.available() &lt;= 0) return n; &#125; &#125; // 跳过n个 public synchronized long skip(long n) throws IOException &#123; getBufIfOpen(); // Check for closed stream if (n &lt;= 0) &#123; return 0; &#125; long avail = count - pos; if (avail &lt;= 0) &#123; // If no mark position set then don&#x27;t keep in buffer if (markpos &lt;0) return getInIfOpen().skip(n); // Fill in buffer to save bytes for reset fill(); avail = count - pos; if (avail &lt;= 0) return 0; &#125; long skipped = (avail &lt; n) ? avail : n; pos += skipped; return skipped; &#125; // buf[]数组剩余字节数+输入流中剩余字节数 public synchronized int available() throws IOException &#123; int n = count - pos; int avail = getInIfOpen().available(); return n &gt; (Integer.MAX_VALUE - avail) ? Integer.MAX_VALUE : n + avail; &#125; // 标记位置，marklimit只有在这里才可以被赋值，readlimit表示mark()方法执行后，最多可以从流中读取的数据 // 若是超过该字节大小，那么在fill()的时候，就会认为此mark()标记无效，从新将 markpos = -1，pos = 0 public synchronized void mark(int readlimit) &#123; marklimit = readlimit; markpos = pos; &#125; // 重置位置 public synchronized void reset() throws IOException &#123; getBufIfOpen(); // 如果已经close, 则直接报错 if (markpos &lt; 0) throw new IOException(&quot;Resetting to invalid mark&quot;); pos = markpos; &#125; // 支持mark, 所以返回true public boolean markSupported() &#123; return true; &#125; // 通过AtomicReferenceFieldUpdater的CAS无锁方式close public void close() throws IOException &#123; byte[] buffer; while ( (buffer = buf) != null) &#123; if (bufUpdater.compareAndSet(this, buffer, null)) &#123; InputStream input = in; in = null; if (input != null) input.close(); return; &#125; // Else retry in case a new buf was CASed in fill() &#125; &#125;&#125; AtomicReferenceFieldUpdater具体可以参考：JUC原子类: CAS, Unsafe和原子类详解 参考文章 JDK 11 源码 https://www.cnblogs.com/winterfells/p/8745297.html https://www.cnblogs.com/AdaiCoffee/p/11369699.html","tags":["Java","IO"],"categories":["Java","IO"]},{"title":"12.结构型 - 装饰(Decorator)","path":"/2023/12/26/12-结构型-装饰-Decorator/","content":"装饰者模式(decorator pattern): 动态地将责任附加到对象上, 若要扩展功能, 装饰者提供了比继承更有弹性的替代方案。 意图为对象动态添加功能。 类图装饰者(Decorator)和具体组件(ConcreteComponent)都继承自组件(Component)，具体组件的方法实现不需要依赖于其它对象，而装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。所谓装饰，就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能。装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 实现设计不同种类的饮料，饮料可以添加配料，比如可以添加牛奶，并且支持动态添加新配料。每增加一种配料，该饮料的价格就会增加，要求计算一种饮料的价格。 下图表示在 DarkRoast 饮料上新增新添加 Mocha 配料，之后又添加了 Whip 配料。DarkRoast 被 Mocha 包裹，Mocha 又被 Whip 包裹。它们都继承自相同父类，都有 cost() 方法，外层类的 cost() 方法调用了内层类的 cost() 方法。 123public interface Beverage &#123; double cost();&#125; 123456public class DarkRoast implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125; 123456public class HouseBlend implements Beverage &#123; @Override public double cost() &#123; return 1; &#125;&#125; 123public abstract class CondimentDecorator implements Beverage &#123; protected Beverage beverage;&#125; 1234567891011public class Milk extends CondimentDecorator &#123; public Milk(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 1234567891011public class Mocha extends CondimentDecorator &#123; public Mocha(Beverage beverage) &#123; this.beverage = beverage; &#125; @Override public double cost() &#123; return 1 + beverage.cost(); &#125;&#125; 12345678public class Client &#123; public static void main(String[] args) &#123; Beverage beverage = new HouseBlend(); beverage = new Mocha(beverage); beverage = new Milk(beverage); System.out.println(beverage.cost()); &#125;&#125; 13.0 设计原则类应该对扩展开放，对修改关闭: 也就是添加新功能时不需要修改代码。饮料可以动态添加新的配料，而不需要去修改饮料的代码。 不可能把所有的类设计成都满足这一原则，应当把该原则应用于最有可能发生改变的地方。 JDK java.io.BufferedInputStream(InputStream) java.io.DataInputStream(InputStream) java.io.BufferedOutputStream(OutputStream) java.util.zip.ZipOutputStream(OutputStream) java.util.Collections#checkedList|Map|Set|SortedSet|SortedMap 著作权归@pdai所有 原文链接：https://pdai.tech/md/dev-spec/pattern/12_decorator.html","tags":["设计模式","结构性设计模式","装饰者模式","Decorator"],"categories":["设计模式","结构型设计模式"]},{"title":"7.JVM 基础 - Java 内存模型详解","path":"/2023/12/26/7-JVM-基础-Java-内存模型详解/","content":"本文主要转载自 Info 上深入理解Java内存模型, 作者程晓明。这篇文章对JMM讲的很清楚了，大致分三部分：重排序与顺序一致性；三个同步原语（lock，volatile，final）的内存语义，重排序规则及在处理器中的实现；java 内存模型的设计，及其与处理器内存模型和顺序一致性内存模型的关系。 基础并发编程模型的分类在并发编程中，我们需要处理两个关键问题：线程之间如何通信及线程之间如何同步（这里的线程是指并发执行的活动实体）。通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。 在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写 - 读内存中的公共状态来隐式进行通信。在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。 同步是指程序用于控制不同线程之间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。 Java 的并发采用的是共享内存模型，Java 线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。如果编写多线程程序的 Java 程序员不理解隐式进行的线程之间通信的工作机制，很可能会遇到各种奇怪的内存可见性问题。 Java 内存模型的抽象在 java 中，所有实例域、静态域和数组元素存储在堆内存中，堆内存在线程之间共享（本文使用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local variables），方法定义参数（java 语言规范称之为 formal method parameters）和异常处理器参数（exception handler parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。 Java 线程之间的通信由 Java 内存模型（本文简称为 JMM）控制，JMM 决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM 定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（main memory）中，每个线程都有一个私有的本地内存（local memory），本地内存中存储了该线程以读 &#x2F; 写共享变量的副本。本地内存是 JMM 的一个抽象概念，并不真实存在。它涵盖了缓存，写缓冲区，寄存器以及其他的硬件和编译器优化。Java 内存模型的抽象示意图如下： 从上图来看，线程 A 与线程 B 之间如要通信的话，必须要经历下面 2 个步骤： 首先，线程 A 把本地内存 A 中更新过的共享变量刷新到主内存中去。 然后，线程 B 到主内存中去读取线程 A 之前已更新过的共享变量。 下面通过示意图来说明这两个步骤： 如上图所示，本地内存 A 和 B 有主内存中共享变量 x 的副本。假设初始时，这三个内存中的 x 值都为 0。线程 A 在执行时，把更新后的 x 值（假设值为 1）临时存放在自己的本地内存 A 中。当线程 A 和线程 B 需要通信时，线程 A 首先会把自己本地内存中修改后的 x 值刷新到主内存中，此时主内存中的 x 值变为了 1。随后，线程 B 到主内存中去读取线程 A 更新后的 x 值，此时线程 B 的本地内存的 x 值也变为了 1。 从整体来看，这两个步骤实质上是线程 A 在向线程 B 发送消息，而且这个通信过程必须要经过主内存。JMM 通过控制主内存与每个线程的本地内存之间的交互，来为 java 程序员提供内存可见性保证。 重排序在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 &#x2F; 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 处理器重排序与内存屏障指令现代的处理器使用写缓冲区来临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。同时，通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，可以减少对内存总线的占用。虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读 &#x2F; 写操作的执行顺序，不一定与内存实际发生的读 &#x2F; 写操作顺序一致！为了具体说明，请看下面示例： 123456789// Processor Aa = 1; //A1 x = b; //A2// Processor Bb = 2; //B1 y = a; //B2// 初始状态：a = b = 0；处理器允许执行后得到结果：x = y = 0 假设处理器 A 和处理器 B 按程序的顺序并行执行内存访问，最终却可能得到 x &#x3D; y &#x3D; 0 的结果。具体的原因如下图所示： 这里处理器 A 和处理器 B 可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到 x &#x3D; y &#x3D; 0 的结果。 从内存操作实际发生的顺序来看，直到处理器 A 执行 A3 来刷新自己的写缓存区，写操作 A1 才算真正执行了。虽然处理器 A 执行内存操作的顺序为：A1-&gt;A2，但内存操作实际发生的顺序却是：A2-&gt;A1。此时，处理器 A 的内存操作顺序被重排序了（处理器 B 的情况和处理器 A 一样，这里就不赘述了）。 这里的关键是，由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。由于现代的处理器都会使用写缓冲区，因此现代的处理器都会允许对写 - 读操做重排序。 下面是常见处理器允许的重排序类型的列表： Load-Load Load-Store Store-Store Store-Load 数据依赖 sparc-TSO N N N Y N x86 N N N Y N ia64 Y Y Y Y N PowerPC Y Y Y Y N 上表单元格中的“N”表示处理器不允许两个操作重排序，“Y”表示允许重排序。 从上表我们可以看出：常见的处理器都允许 Store-Load 重排序；常见的处理器都不允许对存在数据依赖的操作做重排序。sparc-TSO 和 x86 拥有相对较强的处理器内存模型，它们仅允许对写 - 读操作做重排序（因为它们都使用了写缓冲区）。 ※注 1：sparc-TSO 是指以 TSO(Total Store Order) 内存模型运行时，sparc 处理器的特性。 ※注 2：上表中的 x86 包括 x64 及 AMD64。 ※注 3：由于 ARM 处理器的内存模型与 PowerPC 处理器的内存模型非常类似，本文将忽略它。 ※注 4：数据依赖性后文会专门说明。 为了保证内存可见性，java 编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM 把内存屏障指令分为下列四类： 屏障类型 指令示例 说明 LoadLoad Barriers Load1; LoadLoad; Load2 确保 Load1 数据的装载，之前于 Load2 及所有后续装载指令的装载。 StoreStore Barriers Store1; StoreStore; Store2 确保 Store1 数据对其他处理器可见（刷新到内存），之前于 Store2 及所有后续存储指令的存储。 LoadStore Barriers Load1; LoadStore; Store2 确保 Load1 数据装载，之前于 Store2 及所有后续的存储指令刷新到内存。 StoreLoad Barriers Store1; StoreLoad; Load2 确保 Store1 数据对其他处理器变得可见（指刷新到内存），之前于 Load2 及所有后续装载指令的装载。 StoreLoad Barriers 会使该屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。 StoreLoad Barriers 是一个“全能型”的屏障，它同时具有其他三个屏障的效果。现代的多处理器大都支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（buffer fully flush）。 happens-before从 JDK5 开始，java 使用新的 JSR -133 内存模型（本文除非特别说明，针对的都是 JSR- 133 内存模型）。JSR-133 提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。 与程序员密切相关的 happens-before 规则如下： 程序顺序规则：一个线程中的每个操作，happens- before 于该线程中的任意后续操作。 监视器锁规则：对一个监视器锁的解锁，happens- before 于随后对这个监视器锁的加锁。 volatile 变量规则：对一个 volatile 域的写，happens- before 于任意后续对这个 volatile 域的读。 传递性：如果 A happens- before B，且 B happens- before C，那么 A happens- before C。 注意，两个操作之间具有 happens-before 关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前（the first is visible to and ordered before the second）。happens- before 的定义很微妙，后文会具体说明 happens-before 为什么要这么定义。 happens-before 与 JMM 的关系如下图所示： 如上图所示，一个 happens-before 规则通常对应于多个编译器重排序规则和处理器重排序规则。对于 java 程序员来说，happens-before 规则简单易懂，它避免程序员为了理解 JMM 提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现。 重排序数据依赖性如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型： 名称 代码示例 说明 写后读 a &#x3D; 1;b &#x3D; a; 写一个变量之后，再读这个位置。 写后写 a &#x3D; 1;a &#x3D; 2; 写一个变量之后，再写这个变量。 读后写 a &#x3D; b;b &#x3D; 1; 读一个变量之后，再写这个变量。 上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。 前面提到过，编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。 注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。 as-if-serial 语义as-if-serial 语义的意思指：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器，runtime 和处理器都必须遵守 as-if-serial 语义。 为了遵守 as-if-serial 语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作可能被编译器和处理器重排序。为了具体说明，请看下面计算圆面积的代码示例： 123double pi = 3.14; //Adouble r = 1.0; //Bdouble area = pi * r * r; //C 上面三个操作的数据依赖关系如下图所示： 如上图所示，A 和 C 之间存在数据依赖关系，同时 B 和 C 之间也存在数据依赖关系。因此在最终执行的指令序列中，C 不能被重排序到 A 和 B 的前面（C 排到 A 和 B 的前面，程序的结果将会被改变）。但 A 和 B 之间没有数据依赖关系，编译器和处理器可以重排序 A 和 B 之间的执行顺序。下图是该程序的两种执行顺序： as-if-serial 语义把单线程程序保护了起来，遵守 as-if-serial 语义的编译器，runtime 和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial 语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。 程序顺序规则根据 happens- before 的程序顺序规则，上面计算圆的面积的示例代码存在三个 happens- before 关系： A happens- before B； B happens- before C； A happens- before C； 这里的第 3 个 happens- before 关系，是根据 happens- before 的传递性推导出来的。 这里 A happens- before B，但实际执行时 B 却可以排在 A 之前执行（看上面的重排序后的执行顺序）。在第一章提到过，如果 A happens- before B，JMM 并不要求 A 一定要在 B 之前执行。JMM 仅仅要求前一个操作（执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前。这里操作 A 的执行结果不需要对操作 B 可见；而且重排序操作 A 和操作 B 后的执行结果，与操作 A 和操作 B 按 happens- before 顺序执行的结果一致。在这种情况下，JMM 会认为这种重排序并不非法（not illegal），JMM 允许这种重排序。 在计算机中，软件技术和硬件技术有一个共同的目标：在不改变程序执行结果的前提下，尽可能的开发并行度。编译器和处理器遵从这一目标，从 happens- before 的定义我们可以看出，JMM 同样遵从这一目标。 重排序对多线程的影响现在让我们来看看，重排序是否会改变多线程程序的执行结果。请看下面的示例代码： 12345678910111213141516class ReorderExample &#123; int a = 0; boolean flag = false; public void writer() &#123; a = 1; //1 flag = true; //2 &#125; Public void reader() &#123; if (flag) &#123; //3 int i = a * a; //4 …… &#125; &#125;&#125; flag 变量是个标记，用来标识变量 a 是否已被写入。这里假设有两个线程 A 和 B，A 首先执行 writer() 方法，随后 B 线程接着执行 reader() 方法。线程 B 在执行操作 4 时，能否看到线程 A 在操作 1 对共享变量 a 的写入? 答案是：不一定能看到。 由于操作 1 和操作 2 没有数据依赖关系，编译器和处理器可以对这两个操作重排序；同样，操作 3 和操作 4 没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。让我们先来看看，当操作 1 和操作 2 重排序时，可能会产生什么效果? 请看下面的程序执行时序图： 如上图所示，操作 1 和操作 2 做了重排序。程序执行时，线程 A 首先写标记变量 flag，随后线程 B 读这个变量。由于条件判断为真，线程 B 将读取变量 a。此时，变量 a 还根本没有被线程 A 写入，在这里多线程程序的语义被重排序破坏了！ ※注：本文统一用红色的虚箭线表示错误的读操作，用绿色的虚箭线表示正确的读操作。 下面再让我们看看，当操作 3 和操作 4 重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。下面是操作 3 和操作 4 重排序后，程序的执行时序图： 在程序中，操作 3 和操作 4 存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程 B 的处理器可以提前读取并计算 a*a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作 3 的条件判断为真时，就把该计算结果写入变量 i 中。 从图中我们可以看出，猜测执行实质上对操作 3 和 4 做了重排序。重排序在这里破坏了多线程程序的语义！ 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是 as-if-serial 语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。 顺序一致性数据竞争与顺序一致性保证当程序未正确同步时，就会存在数据竞争。java 内存模型规范对数据竞争的定义如下： 在一个线程中写一个变量， 在另一个线程读同一个变量， 而且写和读没有通过同步来排序。 当代码中包含数据竞争时，程序的执行往往产生违反直觉的结果（前一章的示例正是如此）。如果一个多线程程序能正确同步，这个程序将是一个没有数据竞争的程序。 JMM 对正确同步的多线程程序的内存一致性做了如下保证： 如果程序是正确同步的，程序的执行将具有顺序一致性（sequentially consistent）– 即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同（马上我们将会看到，这对于程序员来说是一个极强的保证）。这里的同步是指广义上的同步，包括对常用同步原语（lock，volatile 和 final）的正确使用。 顺序一致性内存模型顺序一致性内存模型是一个被计算机科学家理想化了的理论参考模型，它为程序员提供了极强的内存可见性保证。顺序一致性内存模型有两大特性： 一个线程中的所有操作必须按照程序的顺序来执行。 +（不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。 顺序一致性内存模型为程序员提供的视图如下： 在概念上，顺序一致性模型有一个单一的全局内存，这个内存通过一个左右摆动的开关可以连接到任意一个线程。同时，每一个线程必须按程序的顺序来执行内存读 &#x2F; 写操作。从上图我们可以看出，在任意时间点最多只能有一个线程可以连接到内存。当多个线程并发执行时，图中的开关装置能把所有线程的所有内存读 &#x2F; 写操作串行化。 为了更好的理解，下面我们通过两个示意图来对顺序一致性模型的特性做进一步的说明。 假设有两个线程 A 和 B 并发执行。其中 A 线程有三个操作，它们在程序中的顺序是：A1-&gt;A2-&gt;A3。B 线程也有三个操作，它们在程序中的顺序是：B1-&gt;B2-&gt;B3。 假设这两个线程使用监视器来正确同步：A 线程的三个操作执行后释放监视器，随后 B 线程获取同一个监视器。那么程序在顺序一致性模型中的执行效果将如下图所示： 现在我们再假设这两个线程没有做同步，下面是这个未同步程序在顺序一致性模型中的执行示意图： 未同步程序在顺序一致性模型中虽然整体执行顺序是无序的，但所有线程都只能看到一个一致的整体执行顺序。以上图为例，线程 A 和 B 看到的执行顺序都是：B1-&gt;A1-&gt;A2-&gt;B2-&gt;A3-&gt;B3。之所以能得到这个保证是因为顺序一致性内存模型中的每个操作必须立即对任意线程可见。 但是，在 JMM 中就没有这个保证。未同步程序在 JMM 中不但整体的执行顺序是无序的，而且所有线程看到的操作执行顺序也可能不一致。比如，在当前线程把写过的数据缓存在本地内存中，且还没有刷新到主内存之前，这个写操作仅对当前线程可见；从其他线程的角度来观察，会认为这个写操作根本还没有被当前线程执行。只有当前线程把本地内存中写过的数据刷新到主内存之后，这个写操作才能对其他线程可见。在这种情况下，当前线程和其它线程看到的操作执行顺序将不一致。 同步程序的顺序一致性效果下面我们对前面的示例程序 ReorderExample 用监视器来同步，看看正确同步的程序如何具有顺序一致性。 请看下面的示例代码： 12345678910111213141516class SynchronizedExample &#123; int a = 0; boolean flag = false; public synchronized void writer() &#123; a = 1; flag = true; &#125; public synchronized void reader() &#123; if (flag) &#123; int i = a; …… &#125; &#125;&#125; 上面示例代码中，假设 A 线程执行 writer() 方法后，B 线程执行 reader() 方法。这是一个正确同步的多线程程序。根据 JMM 规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。下面是该程序在两个内存模型中的执行时序对比图： 在顺序一致性模型中，所有操作完全按程序的顺序串行执行。而在 JMM 中，临界区内的代码可以重排序（但 JMM 不允许临界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM 会在退出监视器和进入监视器这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性模型相同的内存视图（具体细节后文会说明）。虽然线程 A 在临界区内做了重排序，但由于监视器的互斥执行的特性，这里的线程 B 根本无法“观察”到线程 A 在临界区内的重排序。这种重排序既提高了执行效率，又没有改变程序的执行结果。 从这里我们可以看到 JMM 在具体实现上的基本方针：在不改变（正确同步的）程序执行结果的前提下，尽可能的为编译器和处理器的优化打开方便之门。 未同步程序的执行特性对于未同步或未正确同步的多线程程序，JMM 只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false），JMM 保证线程读操作读取到的值不会无中生有（out of thin air）的冒出来。为了实现最小安全性，JVM 在堆上分配对象时，首先会清零内存空间，然后才会在上面分配对象（JVM 内部会同步这两个操作）。因此，在以清零的内存空间（pre-zeroed memory）分配对象时，域的默认初始化已经完成了。 JMM 不保证未同步程序的执行结果与该程序在顺序一致性模型中的执行结果一致。因为未同步程序在顺序一致性模型中执行时，整体上是无序的，其执行结果无法预知。保证未同步程序在两个模型中的执行结果一致毫无意义。 和顺序一致性模型一样，未同步程序在 JMM 中的执行时，整体上也是无序的，其执行结果也无法预知。同时，未同步程序在这两个模型中的执行特性有下面几个差异： 顺序一致性模型保证单线程内的操作会按程序的顺序执行，而 JMM 不保证单线程内的操作会按程序的顺序执行（比如上面正确同步的多线程程序在临界区内的重排序）。这一点前面已经讲过了，这里就不再赘述。 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，而 JMM 不保证所有线程能看到一致的操作执行顺序。这一点前面也已经讲过，这里就不再赘述。 JMM 不保证对 64 位的 long 型和 double 型变量的读 &#x2F; 写操作具有原子性，而顺序一致性模型保证对所有的内存读 &#x2F; 写操作都具有原子性。 第 3 个差异与处理器总线的工作机制密切相关。在计算机中，数据通过总线在处理器和内存之间传递。每次处理器和内存之间的数据传递都是通过一系列步骤来完成的，这一系列步骤称之为总线事务（bus transaction）。总线事务包括读事务（read transaction）和写事务（write transaction）。读事务从内存传送数据到处理器，写事务从处理器传送数据到内存，每个事务会读 &#x2F; 写内存中一个或多个物理上连续的字。这里的关键是，总线会同步试图并发使用总线的事务。在一个处理器执行总线事务期间，总线会禁止其它所有的处理器和 I&#x2F;O 设备执行内存的读 &#x2F; 写。下面让我们通过一个示意图来说明总线的工作机制： 如上图所示，假设处理器 A，B 和 C 同时向总线发起总线事务，这时总线仲裁（bus arbitration）会对竞争作出裁决，这里我们假设总线在仲裁后判定处理器 A 在竞争中获胜（总线仲裁会确保所有处理器都能公平的访问内存）。此时处理器 A 继续它的总线事务，而其它两个处理器则要等待处理器 A 的总线事务完成后才能开始再次执行内存访问。假设在处理器 A 执行总线事务期间（不管这个总线事务是读事务还是写事务），处理器 D 向总线发起了总线事务，此时处理器 D 的这个请求会被总线禁止。 总线的这些工作机制可以把所有处理器对内存的访问以串行化的方式来执行；在任意时间点，最多只能有一个处理器能访问内存。这个特性确保了单个总线事务之中的内存读 &#x2F; 写操作具有原子性。 在一些 32 位的处理器上，如果要求对 64 位数据的读 &#x2F; 写操作具有原子性，会有比较大的开销。为了照顾这种处理器，java 语言规范鼓励但不强求 JVM 对 64 位的 long 型变量和 double 型变量的读 &#x2F; 写具有原子性。当 JVM 在这种处理器上运行时，会把一个 64 位 long&#x2F; double 型变量的读 &#x2F; 写操作拆分为两个 32 位的读 &#x2F; 写操作来执行。这两个 32 位的读 &#x2F; 写操作可能会被分配到不同的总线事务中执行，此时对这个 64 位变量的读 &#x2F; 写将不具有原子性。 当单个内存操作不具有原子性，将可能会产生意想不到后果。请看下面示意图： 如上图所示，假设处理器 A 写一个 long 型变量，同时处理器 B 要读这个 long 型变量。处理器 A 中 64 位的写操作被拆分为两个 32 位的写操作，且这两个 32 位的写操作被分配到不同的写事务中执行。同时处理器 B 中 64 位的读操作被拆分为两个 32 位的读操作，且这两个 32 位的读操作被分配到同一个的读事务中执行。当处理器 A 和 B 按上图的时序来执行时，处理器 B 将看到仅仅被处理器 A“写了一半“的无效值。 总结处理器内存模型顺序一致性内存模型是一个理论参考模型，JMM 和处理器内存模型在设计时通常会把顺序一致性内存模型作为参照。JMM 和处理器内存模型在设计时会对顺序一致性模型做一些放松，因为如果完全按照顺序一致性模型来实现处理器和 JMM，那么很多的处理器和编译器优化都要被禁止，这对执行性能将会有很大的影响。 根据对不同类型读 &#x2F; 写操作组合的执行顺序的放松，可以把常见处理器的内存模型划分为下面几种类型： 放松程序中写 - 读操作的顺序，由此产生了 total store ordering 内存模型（简称为 TSO）。 在前面 1 的基础上，继续放松程序中写 - 写操作的顺序，由此产生了 partial store order 内存模型（简称为 PSO）。 在前面 1 和 2 的基础上，继续放松程序中读 - 写和读 - 读操作的顺序，由此产生了 relaxed memory order 内存模型（简称为 RMO）和 PowerPC 内存模型。 注意，这里处理器对读 &#x2F; 写操作的放松，是以两个操作之间不存在数据依赖性为前提的（因为处理器要遵守 as-if-serial 语义，处理器不会对存在数据依赖性的两个内存操作做重排序）。 下面的表格展示了常见处理器内存模型的细节特征： 内存模型名称 对应的处理器 Store-Load 重排序 Store-Store 重排序 Load-Load 和 Load-Store 重排序 可以更早读取到其它处理器的写 可以更早读取到当前处理器的写 TSO sparc-TSO X64 Y Y PSO sparc-PSO Y Y Y RMO ia64 Y Y Y Y PowerPC PowerPC Y Y Y Y Y 在这个表格中，我们可以看到所有处理器内存模型都允许写 - 读重排序，原因在第一章以说明过：它们都使用了写缓存区，写缓存区可能导致写 - 读操作重排序。同时，我们可以看到这些处理器内存模型都允许更早读到当前处理器的写，原因同样是因为写缓存区：由于写缓存区仅对当前处理器可见，这个特性导致当前处理器可以比其他处理器先看到临时保存在自己的写缓存区中的写。 上面表格中的各种处理器内存模型，从上到下，模型由强变弱。越是追求性能的处理器，内存模型设计的会越弱。因为这些处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。 由于常见的处理器内存模型比 JMM 要弱，java 编译器在生成字节码时，会在执行指令序列的适当位置插入内存屏障来限制处理器的重排序。同时，由于各种处理器内存模型的强弱并不相同，为了在不同的处理器平台向程序员展示一个一致的内存模型，JMM 在不同的处理器中需要插入的内存屏障的数量和种类也不相同。下图展示了 JMM 在不同处理器内存模型中需要插入的内存屏障的示意图： 如上图所示，JMM 屏蔽了不同处理器内存模型的差异，它在不同的处理器平台之上为 java 程序员呈现了一个一致的内存模型。 JMM，处理器内存模型与顺序一致性内存模型之间的关系JMM 是一个语言级的内存模型，处理器内存模型是硬件级的内存模型，顺序一致性内存模型是一个理论参考模型。下面是语言内存模型，处理器内存模型和顺序一致性内存模型的强弱对比示意图： 从上图我们可以看出：常见的 4 种处理器内存模型比常用的 3 中语言内存模型要弱，处理器内存模型和语言内存模型都比顺序一致性内存模型要弱。同处理器内存模型一样，越是追求执行性能的语言，内存模型设计的会越弱。 JMM 的设计从 JMM 设计者的角度来说，在设计 JMM 时，需要考虑两个关键因素： 程序员对内存模型的使用。程序员希望内存模型易于理解，易于编程。程序员希望基于一个强内存模型来编写代码。 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。 由于这两个因素互相矛盾，所以 JSR-133 专家组在设计 JMM 时的核心目标就是找到一个好的平衡点：一方面要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能的放松。下面让我们看看 JSR-133 是如何实现这一目标的。 为了具体说明，请看前面提到过的计算圆面积的示例代码： 123double pi = 3.14; //Adouble r = 1.0; //Bdouble area = pi * r * r; //C 上面计算圆的面积的示例代码存在三个 happens- before 关系： A happens- before B； B happens- before C； A happens- before C； 由于 A happens- before B，happens- before 的定义会要求：A 操作执行的结果要对 B 可见，且 A 操作的执行顺序排在 B 操作之前。 但是从程序语义的角度来说，对 A 和 B 做重排序即不会改变程序的执行结果，也还能提高程序的执行性能（允许这种重排序减少了对编译器和处理器优化的束缚）。也就是说，上面这 3 个 happens- before 关系中，虽然 2 和 3 是必需要的，但 1 是不必要的。因此，JMM 把 happens- before 要求禁止的重排序分为了下面两类： 会改变程序执行结果的重排序。 不会改变程序执行结果的重排序。 JMM 对这两种不同性质的重排序，采取了不同的策略： 对于会改变程序执行结果的重排序，JMM 要求编译器和处理器必须禁止这种重排序。 对于不会改变程序执行结果的重排序，JMM 对编译器和处理器不作要求（JMM 允许这种重排序）。 下面是 JMM 的设计示意图： 从上图可以看出两点： JMM 向程序员提供的 happens- before 规则能满足程序员的需求。JMM 的 happens- before 规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证（有些内存可见性保证其实并不一定真实存在，比如上面的 A happens- before B）。 JMM 对编译器和处理器的束缚已经尽可能的少。从上面的分析我们可以看出，JMM 其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。比如，如果编译器经过细致的分析后，认定一个锁只会被单个线程访问，那么这个锁可以被消除。再比如，如果编译器经过细致的分析后，认定一个 volatile 变量仅仅只会被单个线程访问，那么编译器可以把这个 volatile 变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。 JMM 的内存可见性保证Java 程序的内存可见性保证按程序类型可以分为下列三类： 单线程程序。单线程程序不会出现内存可见性问题。编译器，runtime 和处理器会共同确保单线程程序的执行结果与该程序在顺序一致性模型中的执行结果相同。 正确同步的多线程程序。正确同步的多线程程序的执行将具有顺序一致性（程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同）。这是 JMM 关注的重点，JMM 通过限制编译器和处理器的重排序来为程序员提供内存可见性保证。 未同步 &#x2F; 未正确同步的多线程程序。JMM 为它们提供了最小安全性保障：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值（0，null，false）。 下图展示了这三类程序在 JMM 中与在顺序一致性内存模型中的执行结果的异同： 只要多线程程序是正确同步的，JMM 保证该程序在任意的处理器平台上的执行结果，与该程序在顺序一致性内存模型中的执行结果一致。 JSR-133 对旧内存模型的修补JSR-133 对 JDK5 之前的旧内存模型的修补主要有两个： 增强 volatile 的内存语义。旧内存模型允许 volatile 变量与普通变量重排序。JSR-133 严格限制 volatile 变量与普通变量的重排序，使 volatile 的写 - 读和锁的释放 - 获取具有相同的内存语义。 增强 final 的内存语义。在旧内存模型中，多次读取同一个 final 变量的值可能会不相同。为此，JSR-133 为 final 增加了两个重排序规则。现在，final 具有了初始化安全性。","tags":["Java","JVM","内存模型"],"categories":["Java","JVM"]},{"title":"4.JVM 基础 - Java 类加载机制","path":"/2023/12/26/4-JVM-基础-Java-类加载机制/","content":"这篇文章将带你深入理解Java 类加载机制。 类的生命周期其中类加载的过程包括了加载、验证、准备、解析、初始化五个阶段。在这五个阶段中，加载、验证、准备和初始化这四个阶段发生的顺序是确定的，*而解析阶段则不一定，它在某些情况下可以在初始化阶段之后开始，这是为了支持Java语言的运行时绑定(也成为动态绑定或晚期绑定)*。另外注意这里的几个阶段是按顺序开始，而不是按顺序进行或完成，因为这些阶段通常都是互相交叉地混合进行的，通常在一个阶段执行的过程中调用或激活另一个阶段。 类的加载: 查找并加载类的二进制数据加载时类加载过程的第一个阶段，在加载阶段，虚拟机需要完成以下三件事情: 通过一个类的全限定名来获取其定义的二进制字节流。 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构。 在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。 相对于类加载的其他阶段而言，加载阶段(准确地说，是加载阶段获取类的二进制字节流的动作)是可控性最强的阶段，因为开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。 加载阶段完成后，虚拟机外部的 二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在Java堆中也创建一个java.lang.Class类的对象，这样便可以通过该对象访问方法区中的这些数据。 类加载器并不需要等到某个类被“首次主动使用”时再加载它，JVM规范允许类加载器在预料某个类将要被使用时就预先加载它，如果在预先加载的过程中遇到了.class文件缺失或存在错误，类加载器必须在程序首次主动使用该类时才报告错误(LinkageError错误)如果这个类一直没有被程序主动使用，那么类加载器就不会报告错误。 加载.class文件的方式 从本地系统中直接加载 通过网络下载.class文件 从zip，jar等归档文件中加载.class文件 从专有数据库中提取.class文件 将Java源文件动态编译为.class文件 连接验证: 确保被加载的类的正确性验证是连接阶段的第一步，这一阶段的目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。验证阶段大致会完成4个阶段的检验动作: 文件格式验证: 验证字节流是否符合Class文件格式的规范；例如: 是否以0xCAFEBABE开头、主次版本号是否在当前虚拟机的处理范围之内、常量池中的常量是否有不被支持的类型。 元数据验证: 对字节码描述的信息进行语义分析(注意: 对比javac编译阶段的语义分析)，以保证其描述的信息符合Java语言规范的要求；例如: 这个类是否有父类，除了java.lang.Object之外。 字节码验证: 通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。 符号引用验证: 确保解析动作能正确执行。 验证阶段是非常重要的，但不是必须的，它对程序运行期没有影响，如果所引用的类经过反复验证，那么可以考虑采用-Xverifynone参数来关闭大部分的类验证措施，以缩短虚拟机类加载的时间。 准备: 为类的静态变量分配内存，并将其初始化为默认值准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，这些内存都将在方法区中分配。对于该阶段有以下几点需要注意: 这时候进行内存分配的仅包括类变量(static)，而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。 这里所设置的初始值通常情况下是数据类型默认的零值(如0、0L、null、false等)，而不是被在Java代码中被显式地赋予的值。 假设一个类变量的定义为: public static int value = 3；那么变量value在准备阶段过后的初始值为0，而不是3，因为这时候尚未开始执行任何Java方法，而把value赋值为3的put static指令是在程序编译后，存放于类构造器&lt;clinit&gt;()方法之中的，所以把value赋值为3的动作将在初始化阶段才会执行。 这里还需要注意如下几点 对基本数据类型来说，对于类变量(static)和全局变量，如果不显式地对其赋值而直接使用，则系统会为其赋予默认的零值，而对于局部变量来说，在使用前必须显式地为其赋值，否则编译时不通过。 对于同时被static和final修饰的常量，必须在声明的时候就为其显式地赋值，否则编译时不通过；而只被final修饰的常量则既可以在声明时显式地为其赋值，也可以在类初始化时显式地为其赋值，总之，在使用前必须为其显式地赋值，系统不会为其赋予默认零值。 对于引用数据类型reference来说，如数组引用、对象引用等，如果没有对其进行显式地赋值而直接使用，系统都会为其赋予默认的零值，即null。 如果在数组初始化时没有对数组中的各元素赋值，那么其中的元素将根据对应的数据类型而被赋予默认的零值。 如果类字段的字段属性表中存在ConstantValue属性，即同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值。假设上面的类变量value被定义为: public static final int value = 3；编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机就会根据ConstantValue的设置将value赋值为3。我们可以理解为static final常量在编译期就将其结果放入了调用它的类的常量池中 解析: 把类中的符号引用转换为直接引用解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程，解析动作主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符7类符号引用进行。符号引用就是一组符号来描述目标，可以是任何字面量。 直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。 初始化初始化，为类的静态变量赋予正确的初始值，JVM负责对类进行初始化，主要对类变量进行初始化。在Java中对类变量进行初始值设定有两种方式: 声明类变量是指定初始值 使用静态代码块为类变量指定初始值 JVM初始化步骤 假如这个类还没有被加载和连接，则程序先加载并连接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有初始化语句，则系统依次执行这些初始化语句 类初始化时机: 只有当对类的主动使用的时候才会导致类的初始化，类的主动使用包括以下六种: 创建类的实例，也就是new的方式 访问某个类或接口的静态变量，或者对该静态变量赋值 调用类的静态方法 反射(如Class.forName(“com.pdai.jvm.Test”)) 初始化某个类的子类，则其父类也会被初始化 Java虚拟机启动时被标明为启动类的类(Java Test)，直接使用java.exe命令来运行某个主类 使用类访问方法区内的数据结构的接口， 对象是Heap区的数据。 卸载Java虚拟机将结束生命周期的几种情况 执行了System.exit()方法 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程终止 类加载器， JVM类加载机制类加载器的层次 注意: 这里父类加载器并不是通过继承关系来实现的，而是采用组合实现的。 站在Java虚拟机的角度来讲，只存在两种不同的类加载器: 启动类加载器: 它使用C++实现(这里仅限于Hotspot，也就是JDK1.5之后默认的虚拟机，有很多其他的虚拟机是用Java语言实现的)，是虚拟机自身的一部分；所有其他的类加载器: 这些类加载器都由Java语言实现，独立于虚拟机之外，并且全部继承自抽象类java.lang.ClassLoader，这些类加载器需要由启动类加载器加载到内存中之后才能去加载其他的类。 站在Java开发人员的角度来看，类加载器可以大致划分为以下三类 : 启动类加载器: Bootstrap ClassLoader，负责加载存放在JDK\\jre\\lib(JDK代表JDK的安装目录，下同)下，或被-Xbootclasspath参数指定的路径中的，并且能被虚拟机识别的类库(如rt.jar，所有的java.*开头的类均被Bootstrap ClassLoader加载)。启动类加载器是无法被Java程序直接引用的。 扩展类加载器: Extension ClassLoader，该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\\jre\\lib\\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库(如javax.*开头的类)，开发者可以直接使用扩展类加载器。 应用程序类加载器: Application ClassLoader，该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径(ClassPath)所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 应用程序都是由这三种类加载器互相配合进行加载的，如果有必要，我们还可以加入自定义的类加载器。因为JVM自带的ClassLoader只是懂得从本地文件系统加载标准的java class文件，因此如果编写了自己的ClassLoader，便可以做到如下几点: 在执行非置信代码之前，自动验证数字签名。 动态地创建符合用户特定需要的定制化构建类。 从特定的场所取得java class，例如数据库中和网络中。 寻找类加载器寻找类加载器小例子如下: 123456789package com.pdai.jvm.classloader;public class ClassLoaderTest &#123; public static void main(String[] args) &#123; ClassLoader loader = Thread.currentThread().getContextClassLoader(); System.out.println(loader); System.out.println(loader.getParent()); System.out.println(loader.getParent().getParent()); &#125;&#125; 结果如下: 123sun.misc.Launcher$AppClassLoader@64fef26asun.misc.Launcher$ExtClassLoader@1ddd40f3null 从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是BootstrapLoader(引导类加载器)是用C语言实现的，找不到一个确定的返回父Loader的方式，于是就返回null。 类的加载类加载有三种方式: 1、命令行启动应用时候由JVM初始化加载 2、通过Class.forName()方法动态加载 3、通过ClassLoader.loadClass()方法动态加载 12345678910111213141516171819package com.pdai.jvm.classloader;public class loaderTest &#123; public static void main(String[] args) throws ClassNotFoundException &#123; ClassLoader loader = HelloWorld.class.getClassLoader(); System.out.println(loader); //使用ClassLoader.loadClass()来加载类，不会执行初始化块 loader.loadClass(&quot;Test2&quot;); //使用Class.forName()来加载类，默认会执行初始化块 // Class.forName(&quot;Test2&quot;); //使用Class.forName()来加载类，并指定ClassLoader，初始化时不执行静态块 // Class.forName(&quot;Test2&quot;, false, loader); &#125; &#125;public class Test2 &#123; static &#123; System.out.println(&quot;静态初始化块执行了！&quot;); &#125; &#125; 分别切换加载方式，会有不同的输出结果。 Class.forName()和ClassLoader.loadClass()区别? Class.forName(): 将类的.class文件加载到jvm中之外，还会对类进行解释，执行类中的static块； ClassLoader.loadClass(): 只干一件事情，就是将.class文件加载到jvm中，不会执行static中的内容,只有在newInstance才会去执行static块。 Class.forName(name, initialize, loader)带参函数也可控制是否加载static块。并且只有调用了newInstance()方法采用调用构造函数，创建类的对象 。 JVM类加载机制 全盘负责，当一个类加载器负责加载某个Class时，该Class所依赖的和引用的其他Class也将由该类加载器负责载入，除非显示使用另外一个类加载器来载入 父类委托，先让父类加载器试图加载该类，只有在父类加载器无法加载该类时才尝试从自己的类路径中加载该类 缓存机制，缓存机制将会保证所有加载过的Class都会被缓存，当程序中需要使用某个Class时，类加载器先从缓存区寻找该Class，只有缓存区不存在，系统才会读取该类对应的二进制数据，并将其转换成Class对象，存入缓存区。这就是为什么修改了Class后，必须重启JVM，程序的修改才会生效 双亲委派机制, 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。 双亲委派机制过程？ 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败(例如在$JAVA_HOME&#x2F;jre&#x2F;lib里未查找到该class)，会使用ExtClassLoader来尝试加载； 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 双亲委派代码实现 1234567891011121314151617181920212223242526public Class&lt;?&gt; loadClass(String name)throws ClassNotFoundException &#123; return loadClass(name, false); &#125; protected synchronized Class&lt;?&gt; loadClass(String name, boolean resolve)throws ClassNotFoundException &#123; // 首先判断该类型是否已经被加载 Class c = findLoadedClass(name); if (c == null) &#123; //如果没有被加载，就委托给父类加载或者委派给启动类加载器加载 try &#123; if (parent != null) &#123; //如果存在父类加载器，就委派给父类加载器加载 c = parent.loadClass(name, false); &#125; else &#123; //如果不存在父类加载器，就检查是否是由启动类加载器加载的类，通过调用本地方法native Class findBootstrapClass(String name) c = findBootstrapClass0(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // 如果父类加载器和启动类加载器都不能完成加载任务，才调用自身的加载功能 c = findClass(name); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125; 双亲委派优势 系统类防止内存中出现多份同样的字节码 保证Java程序安全稳定运行 自定义类加载器通常情况下，我们都是直接使用系统类加载器。但是，有的时候，我们也需要自定义类加载器。比如应用是通过网络来传输 Java 类的字节码，为保证安全性，这些字节码经过了加密处理，这时系统类加载器就无法对其进行加载，这样则需要自定义类加载器来实现。自定义类加载器一般都是继承自 ClassLoader 类，从上面对 loadClass 方法来分析来看，我们只需要重写 findClass 方法即可。下面我们通过一个示例来演示自定义类加载器的流程: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package com.pdai.jvm.classloader;import java.io.*;public class MyClassLoader extends ClassLoader &#123; private String root; protected Class&lt;?&gt; findClass(String name) throws ClassNotFoundException &#123; byte[] classData = loadClassData(name); if (classData == null) &#123; throw new ClassNotFoundException(); &#125; else &#123; return defineClass(name, classData, 0, classData.length); &#125; &#125; private byte[] loadClassData(String className) &#123; String fileName = root + File.separatorChar + className.replace(&#x27;.&#x27;, File.separatorChar) + &quot;.class&quot;; try &#123; InputStream ins = new FileInputStream(fileName); ByteArrayOutputStream baos = new ByteArrayOutputStream(); int bufferSize = 1024; byte[] buffer = new byte[bufferSize]; int length = 0; while ((length = ins.read(buffer)) != -1) &#123; baos.write(buffer, 0, length); &#125; return baos.toByteArray(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; return null; &#125; public String getRoot() &#123; return root; &#125; public void setRoot(String root) &#123; this.root = root; &#125; public static void main(String[] args) &#123; MyClassLoader classLoader = new MyClassLoader(); classLoader.setRoot(&quot;D:\\\\temp&quot;); Class&lt;?&gt; testClass = null; try &#123; testClass = classLoader.loadClass(&quot;com.pdai.jvm.classloader.Test2&quot;); Object object = testClass.newInstance(); System.out.println(object.getClass().getClassLoader()); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 自定义类加载器的核心在于对字节码文件的获取，如果是加密的字节码则需要在该类中对文件进行解密。由于这里只是演示，我并未对class文件进行加密，因此没有解密的过程。 这里有几点需要注意 : 1、这里传递的文件名需要是类的全限定性名称，即com.pdai.jvm.classloader.Test2格式的，因为 defineClass 方法是按这种格式进行处理的。 2、最好不要重写loadClass方法，因为这样容易破坏双亲委托模式。 3、这类Test 类本身可以被 AppClassLoader 类加载，因此我们不能把com&#x2F;pdai&#x2F;jvm&#x2F;classloader&#x2F;Test2.class 放在类路径下。否则，由于双亲委托机制的存在，会直接导致该类由 AppClassLoader 加载，而不会通过我们自定义类加载器来加载。 参考文章 http://www.cnblogs.com/ityouknow/p/5603287.html http://blog.csdn.net/ns_code/article/details/17881581 https://segmentfault.com/a/1190000005608960 http://www.importnew.com/18548.html http://zyjustin9.iteye.com/blog/2092131 http://www.codeceo.com/article/java-class-loader-learn.html","tags":["Java","JVM","类加载"],"categories":["Java","JVM"]},{"title":"2.JVM 基础 - 类字节码详解","path":"/2023/12/26/2-JVM-基础-类字节码详解/","content":"源代码通过编译器编译为字节码，再通过类加载子系统进行加载到JVM中运行。 多语言编译为字节码在JVM运行计算机是不能直接运行java代码的，必须要先运行java虚拟机，再由java虚拟机运行编译后的java代码。这个编译后的java代码，就是本文要介绍的java字节码。 为什么jvm不能直接运行java代码呢，这是因为在cpu层面看来计算机中所有的操作都是一个个指令的运行汇集而成的，java是高级语言，只有人类才能理解其逻辑，计算机是无法识别的，所以java代码必须要先编译成字节码文件，jvm才能正确识别代码转换后的指令并将其运行。 Java代码间接翻译成字节码，储存字节码的文件再交由运行于不同平台上的JVM虚拟机去读取执行，从而实现一次编写，到处运行的目的。 JVM也不再只支持Java，由此衍生出了许多基于JVM的编程语言，如Groovy, Scala, Koltin等等。 Java字节码文件class文件本质上是一个以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑的排列在class文件中。jvm根据其特定的规则解析该二进制数据，从而得到相关信息。 Class文件采用一种伪结构来存储数据，它有两种类型：无符号数和表。这里暂不详细的讲。 本文将通过简单的java例子编译后的文件来理解。 Class文件的结构属性在理解之前先从整体看下java字节码文件包含了哪些类型的数据： 从一个例子开始下面以一个简单的例子来逐步讲解字节码。 123456789//Main.javapublic class Main &#123; private int m; public int inc() &#123; return m + 1; &#125;&#125; 通过以下命令, 可以在当前所在路径下生成一个Main.class文件。 1javac Main.java 以文本的形式打开生成的class文件，内容如下: 123456789101112131415161718cafe babe 0000 0034 0013 0a00 0400 0f090003 0010 0700 1107 0012 0100 016d 01000149 0100 063c 696e 6974 3e01 0003 28295601 0004 436f 6465 0100 0f4c 696e 654e756d 6265 7254 6162 6c65 0100 0369 6e630100 0328 2949 0100 0a53 6f75 7263 6546696c 6501 0009 4d61 696e 2e6a 6176 610c0007 0008 0c00 0500 0601 0010 636f 6d2f7268 7974 686d 372f 4d61 696e 0100 106a6176 612f 6c61 6e67 2f4f 626a 6563 74002100 0300 0400 0000 0100 0200 0500 06000000 0200 0100 0700 0800 0100 0900 00001d00 0100 0100 0000 052a b700 01b1 00000001 000a 0000 0006 0001 0000 0003 0001000b 000c 0001 0009 0000 001f 0002 00010000 0007 2ab4 0002 0460 ac00 0000 01000a00 0000 0600 0100 0000 0800 0100 0d000000 0200 0e 文件开头的4个字节(“cafe babe”)称之为 魔数，唯有以”cafe babe”开头的class文件方可被虚拟机所接受，这4个字节就是字节码文件的身份识别。 0000是编译器jdk版本的次版本号0，0034转化为十进制是52,是主版本号，java的版本号从45开始，除1.0和1.1都是使用45.x外,以后每升一个大版本，版本号加一。也就是说，编译生成该class文件的jdk版本为1.8.0。 通过java -version命令稍加验证, 可得结果。 12Java(TM) SE Runtime Environment (build 1.8.0_131-b11)Java HotSpot(TM) 64-Bit Server VM (build 25.131-b11, mixed mode) 继续往下是常量池… 知道是这么分析的就可以了，然后我们通过工具反编译字节码文件继续去看。 反编译字节码文件 使用到java内置的一个反编译工具javap可以反编译字节码文件, 用法: javap &lt;options&gt; &lt;classes&gt; 其中&lt;options&gt;选项包括: 1234567891011121314151617-help --help -? 输出此用法消息-version 版本信息-v -verbose 输出附加信息-l 输出行号和本地变量表-public 仅显示公共类和成员-protected 显示受保护的/公共类和成员-package 显示程序包/受保护的/公共类 和成员 (默认)-p -private 显示所有类和成员-c 对代码进行反汇编-s 输出内部类型签名-sysinfo 显示正在处理的类的 系统信息 (路径, 大小, 日期, MD5 散列)-constants 显示最终常量-classpath &lt;path&gt; 指定查找用户类文件的位置-cp &lt;path&gt; 指定查找用户类文件的位置-bootclasspath &lt;path&gt; 覆盖引导类文件的位置 输入命令javap -verbose -p Main.class查看输出内容: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566Classfile /E:/JavaCode/TestProj/out/production/TestProj/com/rhythm7/Main.class Last modified 2018-4-7; size 362 bytes MD5 checksum 4aed8540b098992663b7ba08c65312de Compiled from &quot;Main.java&quot;public class com.rhythm7.Main minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_SUPERConstant pool: #1 = Methodref #4.#18 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Fieldref #3.#19 // com/rhythm7/Main.m:I #3 = Class #20 // com/rhythm7/Main #4 = Class #21 // java/lang/Object #5 = Utf8 m #6 = Utf8 I #7 = Utf8 &lt;init&gt; #8 = Utf8 ()V #9 = Utf8 Code #10 = Utf8 LineNumberTable #11 = Utf8 LocalVariableTable #12 = Utf8 this #13 = Utf8 Lcom/rhythm7/Main; #14 = Utf8 inc #15 = Utf8 ()I #16 = Utf8 SourceFile #17 = Utf8 Main.java #18 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V #19 = NameAndType #5:#6 // m:I #20 = Utf8 com/rhythm7/Main #21 = Utf8 java/lang/Object&#123; private int m; descriptor: I flags: ACC_PRIVATE public com.rhythm7.Main(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/rhythm7/Main; public int inc(); descriptor: ()I flags: ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: getfield #2 // Field m:I 4: iconst_1 5: iadd 6: ireturn LineNumberTable: line 8: 0 LocalVariableTable: Start Length Slot Name Signature 0 7 0 this Lcom/rhythm7/Main;&#125;SourceFile: &quot;Main.java&quot; 字节码文件信息开头的7行信息包括:Class文件当前所在位置，最后修改时间，文件大小，MD5值，编译自哪个文件，类的全限定名，jdk次版本号，主版本号。 然后紧接着的是该类的访问标志：ACC_PUBLIC, ACC_SUPER，访问标志的含义如下: 标志名称 标志值 含义 ACC_PUBLIC 0x0001 是否为Public类型 ACC_FINAL 0x0010 是否被声明为final，只有类可以设置 ACC_SUPER 0x0020 是否允许使用invokespecial字节码指令的新语义． ACC_INTERFACE 0x0200 标志这是一个接口 ACC_ABSTRACT 0x0400 是否为abstract类型，对于接口或者抽象类来说，次标志值为真，其他类型为假 ACC_SYNTHETIC 0x1000 标志这个类并非由用户代码产生 ACC_ANNOTATION 0x2000 标志这是一个注解 ACC_ENUM 0x4000 标志这是一个枚举 常量池Constant pool意为常量池。 常量池可以理解成Class文件中的资源仓库。主要存放的是两大类常量：字面量(Literal)和符号引用(Symbolic References)。字面量类似于java中的常量概念，如文本字符串，final常量等，而符号引用则属于编译原理方面的概念，包括以下三种: 类和接口的全限定名(Fully Qualified Name) 字段的名称和描述符号(Descriptor) 方法的名称和描述符 不同于C&#x2F;C++, JVM是在加载Class文件的时候才进行的动态链接，也就是说这些字段和方法符号引用只有在运行期转换后才能获得真正的内存入口地址。当虚拟机运行时，需要从常量池获得对应的符号引用，再在类创建或运行时解析并翻译到具体的内存地址中。 直接通过反编译文件来查看字节码内容： 123456#1 = Methodref #4.#18 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V#4 = Class #21 // java/lang/Object#7 = Utf8 &lt;init&gt;#8 = Utf8 ()V#18 = NameAndType #7:#8 // &quot;&lt;init&gt;&quot;:()V#21 = Utf8 java/lang/Object 第一个常量是一个方法定义，指向了第4和第18个常量。以此类推查看第4和第18个常量。最后可以拼接成第一个常量右侧的注释内容: 1java/lang/Object.&quot;&lt;init&gt;&quot;:()V 这段可以理解为该类的实例构造器的声明，由于Main类没有重写构造方法，所以调用的是父类的构造方法。此处也说明了Main类的直接父类是Object。 该方法默认返回值是V, 也就是void，无返回值。 第二个常量同理可得: 123456#2 = Fieldref #3.#19 // com/rhythm7/Main.m:I#3 = Class #20 // com/rhythm7/Main#5 = Utf8 m#6 = Utf8 I#19 = NameAndType #5:#6 // m:I#20 = Utf8 com/rhythm7/Main 复制代码此处声明了一个字段m，类型为I, I即是int类型。关于字节码的类型对应如下： 标识字符 含义 B 基本类型byte C 基本类型char D 基本类型double F 基本类型float I 基本类型int J 基本类型long S 基本类型short Z 基本类型boolean V 特殊类型void L 对象类型，以分号结尾，如Ljava&#x2F;lang&#x2F;Object; 对于数组类型，每一位使用一个前置的[字符来描述，如定义一个java.lang.String[][]类型的维数组，将被记录为[[Ljava/lang/String; 方法表集合在常量池之后的是对类内部的方法描述，在字节码中以表的集合形式表现，暂且不管字节码文件的16进制文件内容如何，我们直接看反编译后的内容。 123private int m; descriptor: I flags: ACC_PRIVATE 此处声明了一个私有变量m，类型为int，返回值为int 12345678910111213public com.rhythm7.Main(); descriptor: ()V flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/rhythm7/Main; 这里是构造方法：Main()，返回值为void, 公开方法。 code内的主要属性为: stack: 最大操作数栈，JVM运行时会根据这个值来分配栈帧(Frame)中的操作栈深度,此处为1 locals: 局部变量所需的存储空间，单位为Slot, Slot是虚拟机为局部变量分配内存时所使用的最小单位，为4个字节大小。方法参数(包括实例方法中的隐藏参数this)，显示异常处理器的参数(try catch中的catch块所定义的异常)，方法体中定义的局部变量都需要使用局部变量表来存放。值得一提的是，locals的大小并不一定等于所有局部变量所占的Slot之和，因为局部变量中的Slot是可以重用的。 args_size: 方法参数的个数，这里是1，因为每个实例方法都会有一个隐藏参数this attribute_info: 方法体内容，0,1,4为字节码”行号”，该段代码的意思是将第一个引用类型本地变量推送至栈顶，然后执行该类型的实例方法，也就是常量池存放的第一个变量，也就是注释里的java/lang/Object.&quot;&quot;:()V, 然后执行返回语句，结束方法。 LineNumberTable: 该属性的作用是描述源码行号与字节码行号(字节码偏移量)之间的对应关系。可以使用 -g:none 或-g:lines选项来取消或要求生成这项信息，如果选择不生成LineNumberTable，当程序运行异常时将无法获取到发生异常的源码行号，也无法按照源码的行数来调试程序。 LocalVariableTable: 该属性的作用是描述帧栈中局部变量与源码中定义的变量之间的关系。可以使用 -g:none 或 -g:vars来取消或生成这项信息，如果没有生成这项信息，那么当别人引用这个方法时，将无法获取到参数名称，取而代之的是arg0, arg1这样的占位符。 start 表示该局部变量在哪一行开始可见，length表示可见行数，Slot代表所在帧栈位置，Name是变量名称，然后是类型签名。 同理可以分析Main类中的另一个方法”inc()”: 方法体内的内容是：将this入栈，获取字段#2并置于栈顶, 将int类型的1入栈，将栈内顶部的两个数值相加，返回一个int类型的值。 类名最后很显然是源码文件： 1SourceFile: &quot;Main.java&quot; 再看两个示例分析try-catch-finally通过以上一个最简单的例子，可以大致了解源码被编译成字节码后是什么样子的。 下面利用所学的知识点来分析一些Java问题: 1234567891011121314public class TestCode &#123; public int foo() &#123; int x; try &#123; x = 1; return x; &#125; catch (Exception e) &#123; x = 2; return x; &#125; finally &#123; x = 3; &#125; &#125;&#125; 试问当不发生异常和发生异常的情况下，foo()的返回值分别是多少。 12javac TestCode.javajavap -verbose TestCode.class 查看字节码的foo方法内容: 12345678910111213141516171819202122232425262728293031323334353637public int foo(); descriptor: ()I flags: ACC_PUBLIC Code: stack=1, locals=5, args_size=1 0: iconst_1 //int型1入栈 -&gt;栈顶=1 1: istore_1 //将栈顶的int型数值存入第二个局部变量 -&gt;局部2=1 2: iload_1 //将第二个int型局部变量推送至栈顶 -&gt;栈顶=1 3: istore_2 //!!将栈顶int型数值存入第三个局部变量 -&gt;局部3=1 4: iconst_3 //int型3入栈 -&gt;栈顶=3 5: istore_1 //将栈顶的int型数值存入第二个局部变量 -&gt;局部2=3 6: iload_2 //!!将第三个int型局部变量推送至栈顶 -&gt;栈顶=1 7: ireturn //从当前方法返回栈顶int数值 -&gt;1 8: astore_2 // -&gt;局部3=Exception 9: iconst_2 // -&gt;栈顶=2 10: istore_1 // -&gt;局部2=2 11: iload_1 //-&gt;栈顶=2 12: istore_3 //!! -&gt;局部4=2 13: iconst_3 // -&gt;栈顶=3 14: istore_1 // -&gt;局部1=3 15: iload_3 //!! -&gt;栈顶=2 16: ireturn // -&gt; 2 17: astore 4 //将栈顶引用型数值存入第五个局部变量=any 19: iconst_3 //将int型数值3入栈 -&gt; 栈顶3 20: istore_1 //将栈顶第一个int数值存入第二个局部变量 -&gt; 局部2=3 21: aload 4 //将局部第五个局部变量(引用型)推送至栈顶 23: athrow //将栈顶的异常抛出 Exception table: from to target type 0 4 8 Class java/lang/Exception //0到4行对应的异常，对应#8中储存的异常 0 4 17 any //Exeption之外的其他异常 8 13 17 any 17 19 17 any 在字节码的4,5，以及13,14中执行的是同一个操作，就是将int型的3入操作数栈顶，并存入第二个局部变量。这正是我们源码在finally语句块中内容。也就是说，JVM在处理异常时，会在每个可能的分支都将finally语句重复执行一遍。 通过一步步分析字节码，可以得出最后的运行结果是： 不发生异常时: return 1 发生异常时: return 2 发生非Exception及其子类的异常，抛出异常，不返回值 以上例子来自于《深入理解Java虚拟机 JVM高级特性与最佳实践》, 关于虚拟机字节码指令表，也可以在《深入理解Java虚拟机 JVM高级特性与最佳实践-附录B》中获取。 kotlin 函数扩展的实现kotlin提供了扩展函数的语言特性，借助这个特性，我们可以给任意对象添加自定义方法。 以下示例为Object添加”sayHello”方法 123456//SayHello.ktpackage com.rhythm7fun Any.sayHello() &#123; println(&quot;Hello&quot;)&#125; 编译后，使用javap查看生成SayHelloKt.class文件的字节码。 123456789101112131415161718192021222324252627282930313233343536Classfile /E:/JavaCode/TestProj/out/production/TestProj/com/rhythm7/SayHelloKt.classLast modified 2018-4-8; size 958 bytes MD5 checksum 780a04b75a91be7605cac4655b499f19 Compiled from &quot;SayHello.kt&quot;public final class com.rhythm7.SayHelloKt minor version: 0 major version: 52 flags: ACC_PUBLIC, ACC_FINAL, ACC_SUPERConstant pool: //省略常量池部分字节码&#123; public static final void sayHello(java.lang.Object); descriptor: (Ljava/lang/Object;)V flags: ACC_PUBLIC, ACC_STATIC, ACC_FINAL Code: stack=2, locals=2, args_size=1 0: aload_0 1: ldc #9 // String $receiver 3: invokestatic #15 // Method kotlin/jvm/internal/Intrinsics.checkParameterIsNotNull:(Ljava/lang/Object;Ljava/lang/String;)V 6: ldc #17 // String Hello 8: astore_1 9: getstatic #23 // Field java/lang/System.out:Ljava/io/PrintStream; 12: aload_1 13: invokevirtual #28 // Method java/io/PrintStream.println:(Ljava/lang/Object;)V 16: return LocalVariableTable: Start Length Slot Name Signature 0 17 0 $receiver Ljava/lang/Object; LineNumberTable: line 4: 6 line 5: 16 RuntimeInvisibleParameterAnnotations: 0: 0: #7()&#125;SourceFile: &quot;SayHello.kt&quot; 观察头部发现,koltin为文件SayHello生成了一个类，类名”com.rhythm7.SayHelloKt”. 由于我们一开始编写SayHello.kt时并不希望SayHello是一个可实例化的对象类，所以，SayHelloKt是无法被实例化的，SayHelloKt并没有任何一个构造器。 再观察唯一的一个方法：发现Any.sayHello()的具体实现是静态不可变方法的形式: 1public static final void sayHello(java.lang.Object); 所以当我们在其他地方使用Any.sayHello()时，事实上等同于调用java的SayHelloKt.sayHello(Object)方法。 顺便一提的是，当扩展的方法为Any时，意味着Any是non-null的，这时，编译器会在方法体的开头检查参数的非空，即调用 kotlin.jvm.internal.Intrinsics.checkParameterIsNotNull(Object value, String paramName) 方法来检查传入的Any类型对象是否为空。如果我们扩展的函数为Any?.sayHello()，那么在编译后的文件中则不会有这段字节码的出现。 参考文章 https://www.cnblogs.com/paddix/p/5282004.html https://blog.csdn.net/sinat_37191123/article/details/84582438 https://blog.csdn.net/tyyj90/article/details/78472986 https://blog.csdn.net/a15089415104/article/details/83215598 咸鱼不思议 https://juejin.im/post/5aca2c366fb9a028c97a5609","tags":["Java","JVM","字节码"],"categories":["Java","JVM"]},{"title":"2.算法思想 - 分治算法","path":"/2023/12/26/2-算法思想-分治算法/","content":"分治算法的基本思想是将一个规模为N的问题分解为K个规模较小的子问题，这些子问题相互独立且与原问题性质相同。求出子问题的解，就可得到原问题的解。 分治相关题目给表达式加括号241. Different Ways to Add Parentheses (Medium) 1234567891011121314151617181920212223242526272829303132333435Input: &quot;2-1-1&quot;.((2-1)-1) = 0(2-(1-1)) = 2Output : [0, 2]public List&lt;Integer&gt; diffWaysToCompute(String input) &#123; List&lt;Integer&gt; ways = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; input.length(); i++) &#123; char c = input.charAt(i); if (c == &#x27;+&#x27; || c == &#x27;-&#x27; || c == &#x27;*&#x27;) &#123; List&lt;Integer&gt; left = diffWaysToCompute(input.substring(0, i)); List&lt;Integer&gt; right = diffWaysToCompute(input.substring(i + 1)); for (int l : left) &#123; for (int r : right) &#123; switch (c) &#123; case &#x27;+&#x27;: ways.add(l + r); break; case &#x27;-&#x27;: ways.add(l - r); break; case &#x27;*&#x27;: ways.add(l * r); break; &#125; &#125; &#125; &#125; &#125; if (ways.size() == 0) &#123; ways.add(Integer.valueOf(input)); &#125; return ways;&#125;","tags":["算法","算法思想","分治算法"],"categories":["算法","算法思想"]},{"title":"17.行为型 - 模板方法(Template Method)","path":"/2023/12/26/17-行为型-模板方法-Template-Method/","content":"模板方法模式(Template pattern): 在一个方法中定义一个算法的骨架, 而将一些步骤延迟到子类中. 模板方法使得子类可以在不改变算法结构的情况下, 重新定义算法中的某些步骤。 意图定义算法框架，并将一些步骤的实现延迟到子类。 通过模板方法，子类可以重新定义算法的某些步骤，而不用改变算法的结构。 类图 实现冲咖啡和冲茶都有类似的流程，但是某些步骤会有点不一样，要求复用那些相同步骤的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061public abstract class CaffeineBeverage &#123; final void prepareRecipe() &#123; boilWater(); brew(); pourInCup(); addCondiments(); &#125; abstract void brew(); abstract void addCondiments(); void boilWater() &#123; System.out.println(&quot;boilWater&quot;); &#125; void pourInCup() &#123; System.out.println(&quot;pourInCup&quot;); &#125;&#125;public class Coffee extends CaffeineBeverage &#123; @Override void brew() &#123; System.out.println(&quot;Coffee.brew&quot;); &#125; @Override void addCondiments() &#123; System.out.println(&quot;Coffee.addCondiments&quot;); &#125;&#125;public class Tea extends CaffeineBeverage &#123; @Override void brew() &#123; System.out.println(&quot;Tea.brew&quot;); &#125; @Override void addCondiments() &#123; System.out.println(&quot;Tea.addCondiments&quot;); &#125;&#125;public class Client &#123; public static void main(String[] args) &#123; CaffeineBeverage caffeineBeverage = new Coffee(); caffeineBeverage.prepareRecipe(); System.out.println(&quot;-----------&quot;); caffeineBeverage = new Tea(); caffeineBeverage.prepareRecipe(); &#125;&#125;boilWaterCoffee.brewpourInCupCoffee.addCondiments-----------boilWaterTea.brewpourInCupTea.addCondiments JDK java.util.Collections#sort() java.io.InputStream#skip() java.io.InputStream#read() java.util.AbstractList#indexOf()","tags":["设计模式","行为型","模版方法","Template Method"],"categories":["设计模式","行为型"]},{"title":"10.Java 8 - StampedLock","path":"/2023/12/26/10-Java-8-StampedLock/","content":"本文将从synchronized、Lock到Java8新增的StampedLock进行对比分析，相信StampedLock不会让大家失望。 synchronized在java5之前，实现同步主要是使用synchronized。它是Java语言的关键字，当它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。 有四种不同的同步块: 1234实例方法静态方法实例方法中的同步块静态方法中的同步块 大家对此应该不陌生，所以不多讲了，以下是代码示例 123synchronized(this)// do operation&#125; 小结: 在多线程并发编程中Synchronized一直是元老级角色，很多人都会称呼它为重量级锁，但是随着Java SE1.6对Synchronized进行了各种优化之后，性能上也有所提升。 Lock123456rwlock.writeLock().lock();try &#123;\t// do operation&#125; finally &#123;\trwlock.writeLock().unlock();&#125; 它是Java 5在java.util.concurrent.locks新增的一个API。 Lock是一个接口，核心方法是lock()，unlock()，tryLock()，实现类有ReentrantLock, ReentrantReadWriteLock.ReadLock, ReentrantReadWriteLock.WriteLock； ReentrantReadWriteLock, ReentrantLock 和synchronized锁都有相同的内存语义。 与synchronized不同的是，Lock完全用Java写成，在java这个层面是无关JVM实现的。Lock提供更灵活的锁机制，很多synchronized 没有提供的许多特性，比如锁投票，定时锁等候和中断锁等候，但因为lock是通过代码实现的，要保证锁定一定会被释放，就必须将unLock()放到finally{}中 下面是Lock的一个代码示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Point &#123; private double x, y; private final StampedLock sl = new StampedLock(); void move(double deltaX, double deltaY) &#123; // an exclusively locked method long stamp = sl.writeLock(); try &#123; x += deltaX; y += deltaY; &#125; finally &#123; sl.unlockWrite(stamp); &#125; &#125; //下面看看乐观读锁案例 double distanceFromOrigin() &#123; // A read-only method long stamp = sl.tryOptimisticRead(); //获得一个乐观读锁 double currentX = x, currentY = y; //将两个字段读入本地局部变量 if (!sl.validate(stamp)) &#123; //检查发出乐观读锁后同时是否有其他写锁发生? stamp = sl.readLock(); //如果没有，我们再次获得一个读悲观锁 try &#123; currentX = x; // 将两个字段读入本地局部变量 currentY = y; // 将两个字段读入本地局部变量 &#125; finally &#123; sl.unlockRead(stamp); &#125; &#125; return Math.sqrt(currentX * currentX + currentY * currentY); &#125;\t//下面是悲观读锁案例 void moveIfAtOrigin(double newX, double newY) &#123; // upgrade // Could instead start with optimistic, not read mode long stamp = sl.readLock(); try &#123; while (x == 0.0 &amp;&amp; y == 0.0) &#123; //循环，检查当前状态是否符合 long ws = sl.tryConvertToWriteLock(stamp); //将读锁转为写锁 if (ws != 0L) &#123; //这是确认转为写锁是否成功 stamp = ws; //如果成功 替换票据 x = newX; //进行状态改变 y = newY; //进行状态改变 break; &#125; else &#123; //如果不能成功转换为写锁 sl.unlockRead(stamp); //我们显式释放读锁 stamp = sl.writeLock(); //显式直接进行写锁 然后再通过循环再试 &#125; &#125; &#125; finally &#123; sl.unlock(stamp); //释放读锁或写锁 &#125; &#125; &#125; 小结: 比synchronized更灵活、更具可伸缩性的锁定机制，但不管怎么说还是synchronized代码要更容易书写些 StampedLock它是java8在java.util.concurrent.locks新增的一个API。 ReentrantReadWriteLock 在沒有任何读写锁时，才可以取得写入锁，这可用于实现了悲观读取(Pessimistic Reading)，即如果执行中进行读取时，经常可能有另一执行要写入的需求，为了保持同步，ReentrantReadWriteLock 的读取锁定就可派上用场。 然而，如果读取执行情况很多，写入很少的情况下，使用 ReentrantReadWriteLock 可能会使写入线程遭遇饥饿(Starvation)问题，也就是写入线程迟迟无法竞争到锁定而一直处于等待状态。 StampedLock控制锁有三种模式(写，读，乐观读)，一个StampedLock状态是由版本和模式两个部分组成，锁获取方法返回一个数字作为票据stamp，它用相应的锁状态表示并控制访问，数字0表示没有写锁被授权访问。在读锁上分为悲观锁和乐观锁。 所谓的乐观读模式，也就是若读的操作很多，写的操作很少的情况下，你可以乐观地认为，写入与读取同时发生几率很少，因此不悲观地使用完全的读取锁定，程序可以查看读取资料之后，是否遭到写入执行的变更，再采取后续的措施(重新读取变更信息，或者抛出异常) ，这一个小小改进，可大幅度提高程序的吞吐量！！ 下面是java doc提供的StampedLock一个例子 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Point &#123; private double x, y; private final StampedLock sl = new StampedLock(); void move(double deltaX, double deltaY) &#123; // an exclusively locked method long stamp = sl.writeLock(); try &#123; x += deltaX; y += deltaY; &#125; finally &#123; sl.unlockWrite(stamp); &#125; &#125; //下面看看乐观读锁案例 double distanceFromOrigin() &#123; // A read-only method long stamp = sl.tryOptimisticRead(); //获得一个乐观读锁 double currentX = x, currentY = y; //将两个字段读入本地局部变量 if (!sl.validate(stamp)) &#123; //检查发出乐观读锁后同时是否有其他写锁发生? stamp = sl.readLock(); //如果没有，我们再次获得一个读悲观锁 try &#123; currentX = x; // 将两个字段读入本地局部变量 currentY = y; // 将两个字段读入本地局部变量 &#125; finally &#123; sl.unlockRead(stamp); &#125; &#125; return Math.sqrt(currentX * currentX + currentY * currentY); &#125;\t//下面是悲观读锁案例 void moveIfAtOrigin(double newX, double newY) &#123; // upgrade // Could instead start with optimistic, not read mode long stamp = sl.readLock(); try &#123; while (x == 0.0 &amp;&amp; y == 0.0) &#123; //循环，检查当前状态是否符合 long ws = sl.tryConvertToWriteLock(stamp); //将读锁转为写锁 if (ws != 0L) &#123; //这是确认转为写锁是否成功 stamp = ws; //如果成功 替换票据 x = newX; //进行状态改变 y = newY; //进行状态改变 break; &#125; else &#123; //如果不能成功转换为写锁 sl.unlockRead(stamp); //我们显式释放读锁 stamp = sl.writeLock(); //显式直接进行写锁 然后再通过循环再试 &#125; &#125; &#125; finally &#123; sl.unlock(stamp); //释放读锁或写锁 &#125; &#125; &#125; 小结: StampedLock要比ReentrantReadWriteLock更加廉价，也就是消耗比较小。 StampedLock与ReadWriteLock性能对比是和ReadWritLock相比，在一个线程情况下，是读速度其4倍左右，写是1倍。 下图是六个线程情况下，读性能是其几十倍，写性能也是近10倍左右: 总结 synchronized是在JVM层面上实现的，不但可以通过一些监控工具监控synchronized的锁定，而且在代码执行时出现异常，JVM会自动释放锁定； ReentrantLock、ReentrantReadWriteLock,、StampedLock都是对象层面的锁定，要保证锁定一定会被释放，就必须将unLock()放到finally{}中； StampedLock 对吞吐量有巨大的改进，特别是在读线程越来越多的场景下； StampedLock有一个复杂的API，对于加锁操作，很容易误用其他方法; 当只有少量竞争者的时候，synchronized是一个很好的通用的锁实现; 当线程增长能够预估，ReentrantLock是一个很好的通用的锁实现; StampedLock 可以说是Lock的一个很好的补充，吞吐量以及性能上的提升足以打动很多人了，但并不是说要替代之前Lock的东西，毕竟他还是有些应用场景的，起码API比StampedLock容易入手。 参考 https://wizardforcel.gitbooks.io/java8-tutorials/content/Java%208%20%E5%B9%B6%E5%8F%91%E6%95%99%E7%A8%8B%20Threads%20%E5%92%8C%20Executors.html https://wizardforcel.gitbooks.io/java8-new-features/content/10.html","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"6.常用开发库 - 日志类库详解","path":"/2023/12/26/6-常用开发库-日志类库详解/","content":"Java日志库是最能体现Java库在进化中的渊源关系的，在理解时重点理解日志框架本身和日志门面，以及比较好的实践等。要关注其历史渊源和设计（比如桥接），而具体在使用时查询接口即可， 否则会陷入JUL(Java Util Log), JCL(Commons Logging), Log4j, SLF4J, Logback，Log4j2傻傻分不清楚的境地。 日志库简介 我认为全面理解日志库需要从下面三个角度去理解： 最重要的一点是 区分日志系统和日志门面; 其次是日志库的使用, 包含配置与API使用；配置侧重于日志系统的配置，API使用侧重于日志门面； 最后是选型，改造和最佳实践等 日志库之日志系统java.util.logging (JUL)JDK1.4 开始，通过 java.util.logging 提供日志功能。虽然是官方自带的log lib，JUL的使用确不广泛。主要原因: JUL从JDK1.4 才开始加入(2002年)，当时各种第三方log lib已经被广泛使用了 JUL早期存在性能问题，到JDK1.5上才有了不错的进步，但现在和Logback&#x2F;Log4j2相比还是有所不如 JUL的功能不如Logback&#x2F;Log4j2等完善，比如Output Handler就没有Logback&#x2F;Log4j2的丰富，有时候需要自己来继承定制，又比如默认没有从ClassPath里加载配置文件的功能 Log4jLog4j 是 apache 的一个开源项目，创始人 Ceki Gulcu。Log4j 应该说是 Java 领域资格最老，应用最广的日志工具。Log4j 是高度可配置的，并可通过在运行时的外部文件配置。它根据记录的优先级别，并提供机制，以指示记录信息到许多的目的地，诸如：数据库，文件，控制台，UNIX 系统日志等。 Log4j 中有三个主要组成部分： loggers - 负责捕获记录信息。 appenders - 负责发布日志信息，以不同的首选目的地。 layouts - 负责格式化不同风格的日志信息。 官网地址：http://logging.apache.org/log4j/2.x/ Log4j 的短板在于性能，在Logback 和 Log4j2 出来之后，Log4j的使用也减少了。 LogbackLogback 是由 log4j 创始人 Ceki Gulcu 设计的又一个开源日志组件，是作为 Log4j 的继承者来开发的，提供了性能更好的实现，异步 logger，Filter等更多的特性。 logback 当前分成三个模块：logback-core、logback-classic 和 logback-access。 logback-core - 是其它两个模块的基础模块。 logback-classic - 是 log4j 的一个 改良版本。此外 logback-classic 完整实现 SLF4J API 使你可以很方便地更换成其它日志系统如 log4j 或 JDK14 Logging。 logback-access - 访问模块与 Servlet 容器集成提供通过 Http 来访问日志的功能。 官网地址: http://logback.qos.ch/ Log4j2维护 Log4j 的人为了性能又搞出了 Log4j2。 Log4j2 和 Log4j1.x 并不兼容，设计上很大程度上模仿了 SLF4J&#x2F;Logback，性能上也获得了很大的提升。 Log4j2 也做了 Facade&#x2F;Implementation 分离的设计，分成了 log4j-api 和 log4j-core。 官网地址: http://logging.apache.org/log4j/2.x/ Log4j vs Logback vs Log4j2 从性能上Log4J2要强，但从生态上Logback+SLF4J优先。 初步对比 logback和log4j2都宣称自己是log4j的后代，一个是出于同一个作者，另一个则是在名字上根正苗红。 撇开血统不谈，比较一下log4j2和logback： log4j2比logback更新：log4j2的GA版在2014年底才推出，比logback晚了好几年，这期间log4j2确实吸收了slf4j和logback的一些优点（比如日志模板），同时应用了不少的新技术 由于采用了更先进的锁机制和LMAX Disruptor库，log4j2的性能优于logback，特别是在多线程环境下和使用异步日志的环境下 二者都支持Filter（应该说是log4j2借鉴了logback的Filter），能够实现灵活的日志记录规则（例如仅对一部分用户记录debug级别的日志） 二者都支持对配置文件的动态更新 二者都能够适配slf4j，logback与slf4j的适配应该会更好一些，毕竟省掉了一层适配库 logback能够自动压缩&#x2F;删除旧日志 logback提供了对日志的HTTP访问功能 log4j2实现了“无垃圾”和“低垃圾”模式。简单地说，log4j2在记录日志时，能够重用对象（如String等），尽可能避免实例化新的临时对象，减少因日志记录产生的垃圾对象，减少垃圾回收带来的性能下降 log4j2和logback各有长处，总体来说，如果对性能要求比较高的话，log4j2相对还是较优的选择。 性能对比 附上log4j2与logback性能对比的benchmark，这份benchmark是Apache Logging出的，有多大水分不知道，仅供参考 同步写文件日志的benchmark： 异步写日志的benchmark： 当然，这些benchmark都是在日志Pattern中不包含Location信息（如日志代码行号 ，调用者信息，Class名&#x2F;源码文件名等）时测定的，如果输出Location信息的话，性能谁也拯救不了： 日志库之日志门面common-logging common-logging 是 apache 的一个开源项目。也称Jakarta Commons Logging，缩写 JCL。 common-logging 的功能是提供日志功能的 API 接口，本身并不提供日志的具体实现（当然，common-logging 内部有一个 Simple logger 的简单实现，但是功能很弱，直接忽略），而是在运行时动态的绑定日志实现组件来工作（如 log4j、java.util.loggin）。 官网地址: http://commons.apache.org/proper/commons-logging/ slf4j 全称为 Simple Logging Facade for Java，即 java 简单日志门面。 什么，作者又是 Ceki Gulcu！这位大神写了 Log4j、Logback 和 slf4j，专注日志组件开发五百年，一直只能超越自己。 类似于 Common-Logging，slf4j 是对不同日志框架提供的一个 API 封装，可以在部署的时候不修改任何配置即可接入一种日志实现方案。但是，slf4j 在编译时静态绑定真正的 Log 库。使用 SLF4J 时，如果你需要使用某一种日志实现，那么你必须选择正确的 SLF4J 的 jar 包的集合（各种桥接包）。 官网地址: http://www.slf4j.org/ common-logging vs slf4j slf4j 库类似于 Apache Common-Logging。但是，他在编译时静态绑定真正的日志库。这点似乎很麻烦，其实也不过是导入桥接 jar 包而已。 slf4j 一大亮点是提供了更方便的日志记录方式： 不需要使用logger.isDebugEnabled()来解决日志因为字符拼接产生的性能问题。slf4j 的方式是使用{}作为字符串替换符，形式如下： 1logger.debug(&quot;id: &#123;&#125;, name: &#123;&#125; &quot;, id, name); 日志库使用方案使用日志解决方案基本可分为三步： 引入 jar 包 配置 使用 API 常见的各种日志解决方案的第 2 步和第 3 步基本一样，实施上的差别主要在第 1 步，也就是使用不同的库。 日志库jar包这里首选推荐使用 slf4j + logback 的组合。 如果你习惯了 common-logging，可以选择 common-logging+log4j。 强烈建议不要直接使用日志实现组件(logback、log4j、java.util.logging)，理由前面也说过，就是无法灵活替换日志库。 还有一种情况：你的老项目使用了 common-logging，或是直接使用日志实现组件。如果修改老的代码，工作量太大，需要兼容处理。在下文，都将看到各种应对方法。 注：据我所知，当前仍没有方法可以将 slf4j 桥接到 common-logging。如果我孤陋寡闻了，请不吝赐教。 slf4j 直接绑定日志组件 slf4j + logback 添加依赖到 pom.xml 中即可。 logback-classic-1.0.13.jar 会自动将 slf4j-api-1.7.21.jar 和 logback-core-1.0.13.jar 也添加到你的项目中。 12345&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.0.13&lt;/version&gt;&lt;/dependency&gt; slf4j + log4j 添加依赖到 pom.xml 中即可。 slf4j-log4j12-1.7.21.jar 会自动将 slf4j-api-1.7.21.jar 和 log4j-1.2.17.jar 也添加到你的项目中。 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.21&lt;/version&gt;&lt;/dependency&gt; slf4j + java.util.logging 添加依赖到 pom.xml 中即可。 slf4j-jdk14-1.7.21.jar 会自动将 slf4j-api-1.7.21.jar 也添加到你的项目中。 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-jdk14&lt;/artifactId&gt; &lt;version&gt;1.7.21&lt;/version&gt;&lt;/dependency&gt; slf4j 兼容非 slf4j 日志组件在介绍解决方案前，先提一个概念——桥接 什么是桥接呢 假如你正在开发应用程序所调用的组件当中已经使用了 common-logging，这时你需要 jcl-over-slf4j.jar 把日志信息输出重定向到 slf4j-api，slf4j-api 再去调用 slf4j 实际依赖的日志组件。这个过程称为桥接。下图是官方的 slf4j 桥接策略图： 从图中应该可以看出，无论你的老项目中使用的是 common-logging 或是直接使用 log4j、java.util.logging，都可以使用对应的桥接 jar 包来解决兼容问题。 slf4j 兼容 common-logging 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt;&lt;/dependency&gt; slf4j 兼容 log4j 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt;&lt;/dependency&gt; slf4j 兼容 java.util.logging 12345&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jul-to-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt;&lt;/dependency&gt; spring 集成 slf4j 做 java web 开发，基本离不开 spring 框架。很遗憾，spring 使用的日志解决方案是 common-logging + log4j。 所以，你需要一个桥接 jar 包：logback-ext-spring。 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.3&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.logback-extensions&lt;/groupId&gt; &lt;artifactId&gt;logback-ext-spring&lt;/artifactId&gt; &lt;version&gt;0.1.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;jcl-over-slf4j&lt;/artifactId&gt; &lt;version&gt;1.7.12&lt;/version&gt;&lt;/dependency&gt; common-logging 绑定日志组件 common-logging + log4j 添加依赖到 pom.xml 中即可。 12345678910&lt;dependency&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 日志库配置 - 针对于日志框架log4j2 配置log4j2 基本配置形式如下： 1234567891011121314151617181920212223&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;;&lt;Configuration&gt; &lt;Properties&gt; &lt;Property name=&quot;name1&quot;&gt;value&lt;/property&gt; &lt;Property name=&quot;name2&quot; value=&quot;value2&quot;/&gt; &lt;/Properties&gt; &lt;Filter type=&quot;type&quot; ... /&gt; &lt;Appenders&gt; &lt;Appender type=&quot;type&quot; name=&quot;name&quot;&gt; &lt;Filter type=&quot;type&quot; ... /&gt; &lt;/Appender&gt; ... &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Logger name=&quot;name1&quot;&gt; &lt;Filter type=&quot;type&quot; ... /&gt; &lt;/Logger&gt; ... &lt;Root level=&quot;level&quot;&gt; &lt;AppenderRef ref=&quot;name&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt;&lt;/Configuration&gt; 配置示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;Configuration status=&quot;debug&quot; strict=&quot;true&quot; name=&quot;XMLConfigTest&quot; packages=&quot;org.apache.logging.log4j.test&quot;&gt; &lt;Properties&gt; &lt;Property name=&quot;filename&quot;&gt;target/test.log&lt;/Property&gt; &lt;/Properties&gt; &lt;Filter type=&quot;ThresholdFilter&quot; level=&quot;trace&quot;/&gt; &lt;Appenders&gt; &lt;Appender type=&quot;Console&quot; name=&quot;STDOUT&quot;&gt; &lt;Layout type=&quot;PatternLayout&quot; pattern=&quot;%m MDC%X%n&quot;/&gt; &lt;Filters&gt; &lt;Filter type=&quot;MarkerFilter&quot; marker=&quot;FLOW&quot; onMatch=&quot;DENY&quot; onMismatch=&quot;NEUTRAL&quot;/&gt; &lt;Filter type=&quot;MarkerFilter&quot; marker=&quot;EXCEPTION&quot; onMatch=&quot;DENY&quot; onMismatch=&quot;ACCEPT&quot;/&gt; &lt;/Filters&gt; &lt;/Appender&gt; &lt;Appender type=&quot;Console&quot; name=&quot;FLOW&quot;&gt; &lt;Layout type=&quot;PatternLayout&quot; pattern=&quot;%C&#123;1&#125;.%M %m %ex%n&quot;/&gt;&lt;!-- class and line number --&gt; &lt;Filters&gt; &lt;Filter type=&quot;MarkerFilter&quot; marker=&quot;FLOW&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;NEUTRAL&quot;/&gt; &lt;Filter type=&quot;MarkerFilter&quot; marker=&quot;EXCEPTION&quot; onMatch=&quot;ACCEPT&quot; onMismatch=&quot;DENY&quot;/&gt; &lt;/Filters&gt; &lt;/Appender&gt; &lt;Appender type=&quot;File&quot; name=&quot;File&quot; fileName=&quot;$&#123;filename&#125;&quot;&gt; &lt;Layout type=&quot;PatternLayout&quot;&gt; &lt;Pattern&gt;%d %p %C&#123;1.&#125; [%t] %m%n&lt;/Pattern&gt; &lt;/Layout&gt; &lt;/Appender&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Logger name=&quot;org.apache.logging.log4j.test1&quot; level=&quot;debug&quot; additivity=&quot;false&quot;&gt; &lt;Filter type=&quot;ThreadContextMapFilter&quot;&gt; &lt;KeyValuePair key=&quot;test&quot; value=&quot;123&quot;/&gt; &lt;/Filter&gt; &lt;AppenderRef ref=&quot;STDOUT&quot;/&gt; &lt;/Logger&gt; &lt;Logger name=&quot;org.apache.logging.log4j.test2&quot; level=&quot;debug&quot; additivity=&quot;false&quot;&gt; &lt;AppenderRef ref=&quot;File&quot;/&gt; &lt;/Logger&gt; &lt;Root level=&quot;trace&quot;&gt; &lt;AppenderRef ref=&quot;STDOUT&quot;/&gt; &lt;/Root&gt; &lt;/Loggers&gt; &lt;/Configuration&gt; logback 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&gt; &lt;!-- logback中一共有5种有效级别，分别是TRACE、DEBUG、INFO、WARN、ERROR，优先级依次从低到高 --&gt;&lt;configuration scan=&quot;true&quot; scanPeriod=&quot;60 seconds&quot; debug=&quot;false&quot;&gt; &lt;property name=&quot;DIR_NAME&quot; value=&quot;spring-helloworld&quot;/&gt; &lt;!-- 将记录日志打印到控制台 --&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- RollingFileAppender begin --&gt; &lt;appender name=&quot;ALL&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;user.dir&#125;/logs/$&#123;DIR_NAME&#125;/all.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 根据文件大小来制定滚动策略 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;30MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=&quot;ERROR&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;user.dir&#125;/logs/$&#123;DIR_NAME&#125;/error.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 根据文件大小来制定滚动策略 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=&quot;WARN&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;user.dir&#125;/logs/$&#123;DIR_NAME&#125;/warn.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 根据文件大小来制定滚动策略 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;WARN&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=&quot;INFO&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;user.dir&#125;/logs/$&#123;DIR_NAME&#125;/info.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 根据文件大小来制定滚动策略 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;INFO&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=&quot;DEBUG&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;user.dir&#125;/logs/$&#123;DIR_NAME&#125;/debug.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 根据文件大小来制定滚动策略 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;DEBUG&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=&quot;TRACE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;user.dir&#125;/logs/$&#123;DIR_NAME&#125;/trace.%d&#123;yyyy-MM-dd&#125;.log&lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 根据文件大小来制定滚动策略 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;filter class=&quot;ch.qos.logback.classic.filter.LevelFilter&quot;&gt; &lt;level&gt;TRACE&lt;/level&gt; &lt;onMatch&gt;ACCEPT&lt;/onMatch&gt; &lt;onMismatch&gt;DENY&lt;/onMismatch&gt; &lt;/filter&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name=&quot;SPRING&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;!-- 根据时间来制定滚动策略 --&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.TimeBasedRollingPolicy&quot;&gt; &lt;fileNamePattern&gt;$&#123;user.dir&#125;/logs/$&#123;DIR_NAME&#125;/springframework.%d&#123;yyyy-MM-dd&#125;.log &lt;/fileNamePattern&gt; &lt;maxHistory&gt;30&lt;/maxHistory&gt; &lt;/rollingPolicy&gt; &lt;!-- 根据文件大小来制定滚动策略 --&gt; &lt;triggeringPolicy class=&quot;ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy&quot;&gt; &lt;maxFileSize&gt;10MB&lt;/maxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;HH:mm:ss.SSS&#125; [%thread] [%-5p] %c&#123;36&#125;.%M - %m%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- RollingFileAppender end --&gt; &lt;!-- logger begin --&gt; &lt;!-- 本项目的日志记录，分级打印 --&gt; &lt;logger name=&quot;org.zp.notes.spring&quot; level=&quot;TRACE&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;appender-ref ref=&quot;ERROR&quot;/&gt; &lt;appender-ref ref=&quot;WARN&quot;/&gt; &lt;appender-ref ref=&quot;INFO&quot;/&gt; &lt;appender-ref ref=&quot;DEBUG&quot;/&gt; &lt;appender-ref ref=&quot;TRACE&quot;/&gt; &lt;/logger&gt; &lt;!-- SPRING框架日志 --&gt; &lt;logger name=&quot;org.springframework&quot; level=&quot;WARN&quot; additivity=&quot;false&quot;&gt; &lt;appender-ref ref=&quot;SPRING&quot;/&gt; &lt;/logger&gt; &lt;root level=&quot;TRACE&quot;&gt; &lt;appender-ref ref=&quot;ALL&quot;/&gt; &lt;/root&gt; &lt;!-- logger end --&gt; &lt;/configuration&gt; log4j 配置完整的 log4j.xml 参考示例 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE log4j:configuration SYSTEM &quot;log4j.dtd&quot;&gt; &lt;log4j:configuration xmlns:log4j=&#x27;http://jakarta.apache.org/log4j/&#x27;&gt; &lt;appender name=&quot;STDOUT&quot; class=&quot;org.apache.log4j.ConsoleAppender&quot;&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss,SSS\\&#125; [%-5p] [%t] %c&#123;36\\&#125;.%M - %m%n&quot;/&gt; &lt;/layout&gt; &lt;!--过滤器设置输出的级别--&gt; &lt;filter class=&quot;org.apache.log4j.varia.LevelRangeFilter&quot;&gt; &lt;param name=&quot;levelMin&quot; value=&quot;debug&quot;/&gt; &lt;param name=&quot;levelMax&quot; value=&quot;fatal&quot;/&gt; &lt;param name=&quot;AcceptOnMatch&quot; value=&quot;true&quot;/&gt; &lt;/filter&gt; &lt;/appender&gt; &lt;appender name=&quot;ALL&quot; class=&quot;org.apache.log4j.DailyRollingFileAppender&quot;&gt; &lt;param name=&quot;File&quot; value=&quot;$&#123;user.dir&#125;/logs/spring-common/jcl/all&quot;/&gt; &lt;param name=&quot;Append&quot; value=&quot;true&quot;/&gt; &lt;!-- 每天重新生成日志文件 --&gt; &lt;param name=&quot;DatePattern&quot; value=&quot;&#x27;-&#x27;yyyy-MM-dd&#x27;.log&#x27;&quot;/&gt; &lt;!-- 每小时重新生成日志文件 --&gt; &lt;!--&lt;param name=&quot;DatePattern&quot; value=&quot;&#x27;-&#x27;yyyy-MM-dd-HH&#x27;.log&#x27;&quot;/&gt;--&gt; &lt;layout class=&quot;org.apache.log4j.PatternLayout&quot;&gt; &lt;param name=&quot;ConversionPattern&quot; value=&quot;%d&#123;yyyy-MM-dd HH:mm:ss,SSS\\&#125; [%-5p] [%t] %c&#123;36\\&#125;.%M - %m%n&quot;/&gt; &lt;/layout&gt; &lt;/appender&gt; &lt;!-- 指定logger的设置，additivity指示是否遵循缺省的继承机制--&gt; &lt;logger name=&quot;org.zp.notes.spring&quot; additivity=&quot;false&quot;&gt; &lt;level value=&quot;error&quot;/&gt; &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;appender-ref ref=&quot;ALL&quot;/&gt; &lt;/logger&gt; &lt;!-- 根logger的设置--&gt; &lt;root&gt; &lt;level value=&quot;warn&quot;/&gt; &lt;appender-ref ref=&quot;STDOUT&quot;/&gt; &lt;/root&gt;&lt;/log4j:configuration&gt; 日志库API - 针对于日志门面slf4j 用法使用 slf4j 的 API 很简单。使用LoggerFactory初始化一个Logger实例，然后调用 Logger 对应的打印等级函数就行了。 1234567891011121314import org.slf4j.Logger;import org.slf4j.LoggerFactory; public class App &#123; private static final Logger log = LoggerFactory.getLogger(App.class); public static void main(String[] args) &#123; String msg = &quot;print log, current level: &#123;&#125;&quot;; log.trace(msg, &quot;trace&quot;); log.debug(msg, &quot;debug&quot;); log.info(msg, &quot;info&quot;); log.warn(msg, &quot;warn&quot;); log.error(msg, &quot;error&quot;); &#125;&#125; common-logging 用法common-logging 用法和 slf4j 几乎一样，但是支持的打印等级多了一个更高级别的：fatal。 此外，common-logging 不支持{}替换参数，你只能选择拼接字符串这种方式了。 12345678910111213141516import org.apache.commons.logging.Log;import org.apache.commons.logging.LogFactory; public class JclTest &#123; private static final Log log = LogFactory.getLog(JclTest.class); public static void main(String[] args) &#123; String msg = &quot;print log, current level: &quot;; log.trace(msg + &quot;trace&quot;); log.debug(msg + &quot;debug&quot;); log.info(msg + &quot;info&quot;); log.warn(msg + &quot;warn&quot;); log.error(msg + &quot;error&quot;); log.fatal(msg + &quot;fatal&quot;); &#125;&#125; 日志库选型与改造对Java日志组件选型的建议slf4j已经成为了Java日志组件的明星选手，可以完美替代JCL，使用JCL桥接库也能完美兼容一切使用JCL作为日志门面的类库，现在的新系统已经没有不使用slf4j作为日志API的理由了。 日志记录服务方面，log4j在功能上输于logback和log4j2，在性能方面log4j2则全面超越log4j和logback。所以新系统应该在logback和log4j2中做出选择，对于性能有很高要求的系统，应优先考虑log4j2 对日志架构使用比较好的实践总是使用Log Facade，而不是具体Log Implementation正如之前所说的，使用 Log Facade 可以方便的切换具体的日志实现。而且，如果依赖多个项目，使用了不同的Log Facade，还可以方便的通过 Adapter 转接到同一个实现上。如果依赖项目使用了多个不同的日志实现，就麻烦的多了。 具体来说，现在推荐使用 Log4j-API 或者 SLF4j，不推荐继续使用 JCL。 只添加一个 Log Implementation依赖毫无疑问，项目中应该只使用一个具体的 Log Implementation，建议使用 Logback 或者Log4j2。如果有依赖的项目中，使用的 Log Facade不支持直接使用当前的 Log Implementation，就添加合适的桥接器依赖。具体的桥接关系可以看上一篇文章的图。 具体的日志实现依赖应该设置为optional和使用runtime scope在项目中，Log Implementation的依赖强烈建议设置为runtime scope，并且设置为optional。例如项目中使用了 SLF4J 作为 Log Facade，然后想使用 Log4j2 作为 Implementation，那么使用 maven 添加依赖的时候这样设置: 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 设为optional，依赖不会传递，这样如果你是个lib项目，然后别的项目使用了你这个lib，不会被引入不想要的Log Implementation 依赖； Scope设置为runtime，是为了防止开发人员在项目中直接使用Log Implementation中的类，而不适用Log Facade中的类。 如果有必要, 排除依赖的第三方库中的Log Impementation依赖这是很常见的一个问题，第三方库的开发者未必会把具体的日志实现或者桥接器的依赖设置为optional，然后你的项目继承了这些依赖——具体的日志实现未必是你想使用的，比如他依赖了Log4j，你想使用Logback，这时就很尴尬。另外，如果不同的第三方依赖使用了不同的桥接器和Log实现，也极容易形成环。 这种情况下，推荐的处理方法，是使用exclude来排除所有的这些Log实现和桥接器的依赖，只保留第三方库里面对Log Facade的依赖。 比如阿里的JStorm就没有很好的处理这个问题，依赖jstorm会引入对Logback和log4j-over-slf4j的依赖，如果你想在自己的项目中使用Log4j或其他Log实现的话，就需要加上excludes: 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;com.alibaba.jstorm&lt;/groupId&gt; &lt;artifactId&gt;jstorm-core&lt;/artifactId&gt; &lt;version&gt;2.1.1&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-over-slf4j&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 避免为不会输出的log付出代价Log库都可以灵活的设置输出界别，所以每一条程序中的log，都是有可能不会被输出的。这时候要注意不要额外的付出代价。 先看两个有问题的写法： 12logger.debug(&quot;start process request, url: &quot; + url);logger.debug(&quot;receive request: &#123;&#125;&quot;, toJson(request)); 第一条是直接做了字符串拼接，所以即使日志级别高于debug也会做一个字符串连接操作；第二条虽然用了SLF4J&#x2F;Log4j2 中的懒求值方式来避免不必要的字符串拼接开销，但是toJson()这个函数却是都会被调用并且开销更大。 推荐的写法如下: 123456logger.debug(&quot;start process request, url:&#123;&#125;&quot;, url); // SLF4J/LOG4J2logger.debug(&quot;receive request: &#123;&#125;&quot;, () -&gt; toJson(request)); // LOG4J2logger.debug(() -&gt; &quot;receive request: &quot; + toJson(request)); // LOG4J2if (logger.isDebugEnabled()) &#123; // SLF4J/LOG4J2 logger.debug(&quot;receive request: &quot; + toJson(request)); &#125; 日志格式中最好不要使用行号，函数名等字段原因是，为了获取语句所在的函数名，或者行号，log库的实现都是获取当前的stacktrace，然后分析取出这些信息，而获取stacktrace的代价是很昂贵的。如果有很多的日志输出，就会占用大量的CPU。在没有特殊需要的情况下，建议不要在日志中输出这些这些字段。 最后， log中不要输出稀奇古怪的字符！ 部分开发人员为了方便看到自己的log，会在log语句中加上醒目的前缀，比如: 1logger.debug(&quot;========================start process request=============&quot;); 虽然对于自己来说是方便了，但是如果所有人都这样来做的话，那log输出就没法看了！正确的做法是使用grep 来看只自己关心的日志。 对现有系统日志架构的改造建议如果现有系统使用JCL作为日志门面，又确实面临着JCL的ClassLoader机制带来的问题，完全可以引入slf4j并通过桥接库将JCL api输出的日志桥接至slf4j，再通过适配库适配至现有的日志输出服务（如log4j），如下图： 这样做不需要任何代码级的改造，就可以解决JCL的ClassLoader带来的问题，但没有办法享受日志模板等slf4j的api带来的优点。不过之后在现系统上开发的新功能就可以使用slf4j的api了，老代码也可以分批进行改造。 如果现有系统使用JCL作为日志门面，又头疼JCL不支持logback和log4j2等新的日志服务，也可以通过桥接库以slf4j替代JCL，但同样无法直接享受slf4j api的优点。 如果想要使用slf4j的api，那么就不得不进行代码改造了，当然改造也可以参考1中提到的方式逐步进行。 如果现系统面临着log4j的性能问题，可以使用Apache Logging提供的log4j到log4j2的桥接库log4j-1.2-api，把通过log4j api输出的日志桥接至log4j2。这样可以最快地使用上log4j2的先进性能，但组件中缺失了slf4j，对后续进行日志架构改造的灵活性有影响。另一种办法是先把log4j桥接至slf4j，再使用slf4j到log4j2的适配库。这样做稍微麻烦了一点，但可以逐步将系统中的日志输出标准化为使用slf4j的api，为后面的工作打好基础。 参考文档主要参考整理自： https://www.jianshu.com/p/85d141365d39 https://blog.csdn.net/Dome_/article/details/98489727 https://zhuanlan.zhihu.com/p/24272450 此外还参考了： http://www.slf4j.org/manual.html http://logback.qos.ch/ http://logging.apache.org/log4j/1.2/ http://commons.apache.org/proper/commons-logging/ http://blog.csdn.net/yycdaizi/article/details/8276265","tags":["开发","常用类库","日志"],"categories":["开发","常用类库"]},{"title":"6.Java 8 - 重复注解","path":"/2023/12/26/6-Java-8-重复注解/","content":"理解Java 8 重复注解需理解几个问题: Jdk8之前对重复注解是怎么做的? Jdk8对重复注解添加了什么支持? 什么是重复注解允许在同一申明类型(类，属性，或方法)的多次使用同一个注解 JDK8之前java 8之前也有重复使用注解的解决方案，但可读性不是很好，比如下面的代码: 1234567891011121314public @interface Authority &#123; String role();&#125;public @interface Authorities &#123; Authority[] value();&#125;public class RepeatAnnotationUseOldVersion &#123; @Authorities(&#123;@Authority(role=&quot;Admin&quot;),@Authority(role=&quot;Manager&quot;)&#125;) public void doSomeThing()&#123; &#125;&#125; 由另一个注解来存储重复注解，在使用时候，用存储注解Authorities来扩展重复注解。 Jdk8重复注解我们再来看看java 8里面的做法: 1234567891011121314@Repeatable(Authorities.class)public @interface Authority &#123; String role();&#125;public @interface Authorities &#123; Authority[] value();&#125;public class RepeatAnnotationUseNewVersion &#123; @Authority(role=&quot;Admin&quot;) @Authority(role=&quot;Manager&quot;) public void doSomeThing()&#123; &#125;&#125; 不同的地方是，创建重复注解Authority时，加上@Repeatable,指向存储注解Authorities，在使用时候，直接可以重复使用Authority注解。从上面例子看出，java 8里面做法更适合常规的思维，可读性强一点 总结JEP120没有太多内容，是一个小特性，仅仅是为了提高代码可读性。这次java 8对注解做了2个方面的改进(JEP 104,JEP120)，相信注解会比以前使用得更加频繁了。","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"5.Java 8 - 类型注解","path":"/2023/12/26/5-Java 8 - 类型注解/","content":"理解Java 8 类型注解需理解几个问题: 注解在JDK哪个版本中出现的，可以在哪些地方用注解? 什么是类型注解? 类型注解的作用是什么? 为什么会出现类型注解(JSR308)? 什么是类型注解 注解大家都知道，从java5开始加入这一特性，发展到现在已然是遍地开花，在很多框架中得到了广泛的使用，用来简化程序中的配置。那充满争议的类型注解究竟是什么? 复杂还是便捷? 在java 8之前，注解只能是在声明的地方所使用，比如类，方法，属性； java 8里面，注解可以应用在任何地方，比如: 创建类实例 1new @Interned MyObject(); 类型映射 1myString = (@NonNull String) str; implements 语句中 1class UnmodifiableList&lt;T&gt; implements @Readonly List&lt;@Readonly T&gt; &#123; … &#125; throw exception声明 1void monitorTemperature() throws @Critical TemperatureException &#123; … &#125; 需要注意的是，类型注解只是语法而不是语义，并不会影响java的编译时间，加载时间，以及运行时间，也就是说，编译成class文件的时候并不包含类型注解。 类型注解的作用先看看下面代码 123Collections.emptyList().add(&quot;One&quot;);int i=Integer.parseInt(&quot;hello&quot;);System.console().readLine(); 上面的代码编译是通过的，但运行是会分别报UnsupportedOperationException； NumberFormatException；NullPointerException异常，这些都是runtime error； 类型注解被用来支持在Java的程序中做强类型检查。配合插件式的check framework，可以在编译的时候检测出runtime error，以提高代码质量。这就是类型注解的作用了。 check framework是第三方工具，配合Java的类型注解效果就是1+1&gt;2。它可以嵌入到javac编译器里面，可以配合ant和maven使用, 地址是http://types.cs.washington.edu/checker-framework/。 check framework可以找到类型注解出现的地方并检查，举个简单的例子: 123456import checkers.nullness.quals.*;public class GetStarted &#123; void sample() &#123; @NonNull Object ref = new Object(); &#125;&#125; 使用javac编译上面的类 1javac -processor checkers.nullness.NullnessChecker GetStarted.java 编译是通过，但如果修改成 1@NonNull Object ref = null; 再次编译，则出现 123456GetStarted.java:5: incompatible types.found : @Nullable &lt;nulltype&gt;required: @NonNull Object @NonNull Object ref = null; ^1 error 类型注解向下兼容的解决方案如果你不想使用类型注解检测出来错误，则不需要processor，直接javac GetStarted.java是可以编译通过的，这是在java 8 with Type Annotation Support版本里面可以，但java 5,6,7版本都不行，因为javac编译器不知道@NonNull是什么东西，但check framework 有个向下兼容的解决方案，就是将类型注解nonnull用&#x2F;**&#x2F;注释起来，比如上面例子修改为 123456import checkers.nullness.quals.*;public class GetStarted &#123; void sample() &#123; /*@NonNull*/ Object ref = null; &#125;&#125; 这样javac编译器就会忽略掉注释块，但用check framework里面的javac编译器同样能够检测出nonnull错误。 通过类型注解+check framework我们可以看到，现在runtime error可以在编译时候就能找到。 关于JSR 308JSR 308想要解决在Java 1.5注解中出现的两个问题: 在句法上对注解的限制: 只能把注解写在声明的地方 类型系统在语义上的限制: 类型系统还做不到预防所有的bug JSR 308 通过如下方法解决上述两个问题: 对Java语言的句法进行扩充，允许注解出现在更多的位置上。包括: 方法接收器(method receivers，译注: 例public int size() @Readonly { … })，泛型参数，数组，类型转换，类型测试，对象创建，类型参数绑定，类继承和throws子句。其实就是类型注解，现在是java 8的一个特性 通过引入可插拔的类型系统(pluggable type systems)能够创建功能更强大的注解处理器。类型检查器对带有类型限定注解的源码进行分析，一旦发现不匹配等错误之处就会产生警告信息。其实就是check framework 对JSR308，有人反对，觉得更复杂更静态了，比如 1@NotEmpty List&lt;@NonNull String&gt; strings = new ArrayList&lt;@NonNull String&gt;()&gt; 换成动态语言为 1var strings = [&quot;one&quot;, &quot;two&quot;]; 有人赞成，说到底，代码才是“最根本”的文档。代码中包含的注解清楚表明了代码编写者的意图。当没有及时更新或者有遗漏的时候，恰恰是注解中包含的意图信息，最容易在其他文档中被丢失。而且将运行时的错误转到编译阶段，不但可以加速开发进程，还可以节省测试时检查bug的时间。 总结并不是人人都喜欢这个特性，特别是动态语言比较流行的今天，所幸，java 8并不强求大家使用这个特性，反对的人可以不使用这一特性，而对代码质量有些要求比较高的人或公司可以采用JSR 308，毕竟代码才是“最基本”的文档，这句话我是赞同的。虽然代码会增多，但可以使你的代码更具有表达意义。对这个特性有何看法，大家各抒己见。。。。","tags":["Java","Java8","新特性"],"categories":["Java","新特性","Java8"]},{"title":"3.Java IO - 设计模式(装饰者模式)","path":"/2023/12/26/3-Java-IO-设计模式-装饰者模式/","content":"Java I&#x2F;O 使用了装饰者模式来实现。 装饰者模式请参考 装饰者模式详解 装饰者(Decorator)和具体组件(ConcreteComponent)都继承自组件(Component)，具体组件的方法实现不需要依赖于其它对象，而装饰者组合了一个组件，这样它可以装饰其它装饰者或者具体组件。所谓装饰，就是把这个装饰者套在被装饰者之上，从而动态扩展被装饰者的功能。装饰者的方法有一部分是自己的，这属于它的功能，然后调用被装饰者的方法实现，从而也保留了被装饰者的功能。可以看到，具体组件应当是装饰层次的最低层，因为只有具体组件的方法实现不需要依赖于其它对象。 IO 装饰者模式以 InputStream 为例， InputStream 是抽象组件； FileInputStream 是 InputStream 的子类，属于具体组件，提供了字节流的输入操作； FilterInputStream 属于抽象装饰者，装饰者用于装饰组件，为组件提供额外的功能。例如 BufferedInputStream 为 FileInputStream 提供缓存的功能。 实例化一个具有缓存功能的字节流对象时，只需要在 FileInputStream 对象上再套一层 BufferedInputStream 对象即可。 12FileInputStream fileInputStream = new FileInputStream(filePath);BufferedInputStream bufferedInputStream = new BufferedInputStream(fileInputStream); DataInputStream 装饰者提供了对更多数据类型进行输入的操作，比如 int、double 等基本类型。","tags":["Java","IO"],"categories":["Java","IO"]},{"title":"2.Java IO - 分类(传输，操作)","path":"/2023/12/26/2-Java-IO-分类-传输，操作/","content":"本文主要从传输方式和数据操作两个方面分析Java IO的分类。 IO理解分类 - 从传输方式上从数据传输方式或者说是运输方式角度看，可以将 IO 类分为: 字节流 字符流 字节是个计算机看的，字符才是给人看的 字节流(整体结构如下，部分派生类有缺失) # 字符流(整体结构如下，部分派生类有缺失) 字节流和字符流的区别 字节流读取单个字节，字符流读取单个字符(一个字符根据编码的不同，对应的字节也不同，如 UTF-8 编码中文汉字是 3 个字节，GBK编码中文汉字是 2 个字节。) 字节流用来处理二进制文件(图片、MP3、视频文件)，字符流用来处理文本文件(可以看做是特殊的二进制文件，使用了某种编码，人可以阅读)。 简而言之，字节是给计算机看的，字符才是给人看的。 字节转字符Input&#x2F;OutputStreamReader&#x2F;Writer编码就是把字符转换为字节，而解码是把字节重新组合成字符。 如果编码和解码过程使用不同的编码方式那么就出现了乱码。 GBK 编码中，中文字符占 2 个字节，英文字符占 1 个字节； UTF-8 编码中，中文字符占 3 个字节，英文字符占 1 个字节； UTF-16be 编码中，中文字符和英文字符都占 2 个字节。 UTF-16be 中的 be 指的是 Big Endian，也就是大端。相应地也有 UTF-16le，le 指的是 Little Endian，也就是小端。 Java 使用双字节编码 UTF-16be，这不是指 Java 只支持这一种编码方式，而是说 char 这种类型使用 UTF-16be 进行编码。char 类型占 16 位，也就是两个字节，Java 使用这种双字节编码是为了让一个中文或者一个英文都能使用一个 char 来存储。 IO理解分类 - 从数据操作上从数据来源或者说是操作对象角度看，IO 类可以分为: 文件(file)FileInputStream、FileOutputStream、FileReader、FileWriter 数组([]) 字节数组(byte[]): ByteArrayInputStream、ByteArrayOutputStream 字符数组(char[]): CharArrayReader、CharArrayWriter 管道操作PipedInputStream、PipedOutputStream、PipedReader、PipedWriter 基本数据类型DataInputStream、DataOutputStream 缓冲操作BufferedInputStream、BufferedOutputStream、BufferedReader、BufferedWriter 打印PrintStream、PrintWriter 对象序列化反序列化ObjectInputStream、ObjectOutputStream 转换InputStreamReader、OutputStreamWriter","tags":["Java","IO","NIO","AIO"],"categories":["Java","IO"]},{"title":"1.Java IO知识体系详解","path":"/2023/12/26/1-Java-IO知识体系详解/","content":"本文主要梳理Java IO&#x2F;NIO&#x2F;AIO的知识体系。 知识体系 相关文章 A. Java进阶 - IO框架之知识体系：首先了解下Java IO框架包含什么，同时推荐下如何学习IO框架。@pdai Java IO&#x2F;NIO&#x2F;AIO - Overview 本文主要梳理Java IO&#x2F;NIO&#x2F;AIO的知识体系 B. Java进阶 - IO框架之基础IO：其次对Java基础IO框架进行梳理，包括其分类，使用和源码详解。@pdai Java IO - 分类(传输，操作) 本文主要从传输方式和数据操作两个方面分析Java IO的分类 Java IO - 设计模式(装饰者模式) Java I&#x2F;O 使用了装饰者模式来实现 Java IO - 源码: InputStream 本文主要从JDK源码角度分析InputStream Java IO - 源码: OutputStream 本文主要从JDK源码角度分析 OutputStream Java IO - 常见类使用 本文主要介绍Java IO常见类的使用，包括：磁盘操作，字节操作，字符操作，对象操作和网络操作 C. Java进阶 - IO框架之NIO&#x2F;AIO等：然后再对Unix IO模型学习，引入到Java BIO&#x2F;NIO&#x2F;AIO相关知识详解。@pdai IO 模型 - Unix IO 模型 本文主要简要介绍 Unix I&#x2F;O 5种模型，并对5大模型比较，并重点为后续章节解释IO多路复用做铺垫 Java IO - BIO 详解 BIO就是: blocking IO。最容易理解、最容易实现的IO工作方式，应用程序向操作系统请求网络IO操作，这时应用程序会一直等待；另一方面，操作系统收到请求后，也会等待，直到网络上有数据传到监听端口；操作系统在收集数据后，会把数据发送给应用程序；最后应用程序受到数据，并解除等待状态 Java NIO - 基础详解 新的输入&#x2F;输出 (NIO) 库是在 JDK 1.4 中引入的，弥补了原来的 I&#x2F;O 的不足，提供了高速的、面向块的 I&#x2F;O Java NIO - IO多路复用详解 本文主要对IO多路复用，Ractor模型以及Java NIO对其的支持 Java AIO - 异步IO详解 本文主要对异步IO和Java中对AIO的支持详解。 D. Java进阶 - IO框架之开源框架：最后再对常用的开源框架进行分析和详解。@pdai Java NIO - 零拷贝实现 这里转一篇Java NIO 零拷贝的实现文章，在此之前建议先理解什么是Linux中零拷贝，可以先看这篇文章。本文从源码着手分析了 Java NIO 对零拷贝的实现，主要包括基于内存映射（mmap）方式的 MappedByteBuffer 以及基于 sendfile 方式的 FileChannel。最后在篇末简单的阐述了一下 Netty 中的零拷贝机制，以及 RocketMQ 和 Kafka 两种消息队列在零拷贝实现方式上的区别。 Java N(A)IO - 框架: Netty Netty是一个高性能、异步事件驱动的NIO框架，提供了对TCP、UDP和文件传输的支持。作为当前最流行的NIO框架，Netty在互联网领域、大数据分布式计算领域、游戏行业、通信行业等获得了广泛的应用，一些业界著名的开源组件也基于Netty构建，比如RPC框架、zookeeper等 参考文章 Java 基础IO源码 https://blog.csdn.net/panweiwei1994/article/details/78046000 Linux 网络 I&#x2F;O 模型简介(图文)https://blog.csdn.net/anxpp/article/details/51503329 Java 网络IO编程总结(BIO、NIO、AIO均含完整实例代码) https://blog.csdn.net/anxpp/article/details/51512200 Java 编程思想(八)BIO&#x2F;NIO&#x2F;AIO的具体实现 https://blog.csdn.net/KingCat666/article/details/77689627 Java IO 架构设计: 系统间通信(1)——概述从“聊天”开始上篇 https://blog.csdn.net/yinwenjie/article/list/6? https://blog.csdn.net/yinwenjie/article/details/48274255 https://blog.csdn.net/yinwenjie/article/details/48344989 https://blog.csdn.net/yinwenjie/article/details/48472237 https://blog.csdn.net/yinwenjie/article/details/48522403 https://blog.csdn.net/yinwenjie/article/details/48784375 Netty https://blog.csdn.net/yinwenjie/article/details/48829419 https://blog.csdn.net/yinwenjie/article/details/48969853 https://blog.csdn.net/woaixiaopangniu521/article/details/70279143","tags":["Java","IO","NIO","AIO"],"categories":["Java","IO"]},{"title":"27.Java 并发 - ThreadLocal详解","path":"/2023/12/26/27-Java-并发-ThreadLocal详解/","content":"ThreadLocal是通过线程隔离的方式防止任务在共享资源上产生冲突, 线程本地存储是一种自动化机制，可以为使用相同变量的每个不同线程都创建不同的存储。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 什么是ThreadLocal? 用来解决什么问题的? 说说你对ThreadLocal的理解 ThreadLocal是如何实现线程隔离的? 为什么ThreadLocal会造成内存泄露? 如何解决 还有哪些使用ThreadLocal的应用场景? ThreadLocal简介我们在 Java 并发 - 并发理论基础 总结过线程安全(是指广义上的共享资源访问安全性，因为线程隔离是通过副本保证本线程访问资源安全性，它不保证线程之间还存在共享关系的狭义上的安全性)的解决思路： 互斥同步: synchronized 和 ReentrantLock 非阻塞同步: CAS, AtomicXXXX 无同步方案: 栈封闭，本地存储(Thread Local)，可重入代码 这个章节将详细的讲讲 本地存储(Thread Local)。官网的解释是这样的： This class provides thread-local variables. These variables differ from their normal counterparts in that each thread that accesses one (via its {@code get} or {@code set} method) has its own, independently initialized copy of the variable. {@code ThreadLocal} instances are typically private static fields in classes that wish to associate state with a thread (e.g., a user ID or Transaction ID) 该类提供了线程局部 (thread-local) 变量。这些变量不同于它们的普通对应物，因为访问某个变量(通过其 get 或 set 方法)的每个线程都有自己的局部变量，它独立于变量的初始化副本。ThreadLocal 实例通常是类中的 private static 字段，它们希望将状态与某一个线程(例如，用户 ID 或事务 ID)相关联。 总结而言：ThreadLocal是一个将在多线程中为每一个线程创建单独的变量副本的类; 当使用ThreadLocal来维护变量时, ThreadLocal会为每个线程创建单独的变量副本, 避免因多线程操作共享变量而导致的数据不一致的情况。 ThreadLocal理解 提到ThreadLocal被提到应用最多的是session管理和数据库链接管理，这里以数据访问为例帮助你理解ThreadLocal： 如下数据库管理类在单线程使用是没有任何问题的 123456789101112131415class ConnectionManager &#123; private static Connection connect = null; public static Connection openConnection() &#123; if (connect == null) &#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public static void closeConnection() &#123; if (connect != null) connect.close(); &#125;&#125; 很显然，在多线程中使用会存在线程安全问题：第一，这里面的2个方法都没有进行同步，很可能在openConnection方法中会多次创建connect；第二，由于connect是共享变量，那么必然在调用connect的地方需要使用到同步来保障线程安全，因为很可能一个线程在使用connect进行数据库操作，而另外一个线程调用closeConnection关闭链接。 为了解决上述线程安全的问题，第一考虑：互斥同步 你可能会说，将这段代码的两个方法进行同步处理，并且在调用connect的地方需要进行同步处理，比如用Synchronized或者ReentrantLock互斥锁。 这里再抛出一个问题：这地方到底需不需要将connect变量进行共享? 事实上，是不需要的。假如每个线程中都有一个connect变量，各个线程之间对connect变量的访问实际上是没有依赖关系的，即一个线程不需要关心其他线程是否对这个connect进行了修改的。即改后的代码可以这样： 1234567891011121314151617181920212223242526class ConnectionManager &#123; private Connection connect = null; public Connection openConnection() &#123; if (connect == null) &#123; connect = DriverManager.getConnection(); &#125; return connect; &#125; public void closeConnection() &#123; if (connect != null) connect.close(); &#125;&#125;class Dao &#123; public void insert() &#123; ConnectionManager connectionManager = new ConnectionManager(); Connection connection = connectionManager.openConnection(); // 使用connection进行操作 connectionManager.closeConnection(); &#125;&#125; 这样处理确实也没有任何问题，由于每次都是在方法内部创建的连接，那么线程之间自然不存在线程安全问题。但是这样会有一个致命的影响：导致服务器压力非常大，并且严重影响程序执行性能。由于在方法中需要频繁地开启和关闭数据库连接，这样不仅严重影响程序执行效率，还可能导致服务器压力巨大。 这时候ThreadLocal登场了 那么这种情况下使用ThreadLocal是再适合不过的了，因为ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。下面就是网上出现最多的例子： 12345678910111213141516171819202122import java.sql.Connection;import java.sql.DriverManager;import java.sql.SQLException;public class ConnectionManager &#123; private static final ThreadLocal&lt;Connection&gt; dbConnectionLocal = new ThreadLocal&lt;Connection&gt;() &#123; @Override protected Connection initialValue() &#123; try &#123; return DriverManager.getConnection(&quot;&quot;, &quot;&quot;, &quot;&quot;); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; return null; &#125; &#125;; public Connection getConnection() &#123; return dbConnectionLocal.get(); &#125;&#125; 再注意下ThreadLocal的修饰符 ThreaLocal的JDK文档中说明：ThreadLocal instances are typically private static fields in classes that wish to associate state with a thread。如果我们希望通过某个类将状态(例如用户ID、事务ID)与线程关联起来，那么通常在这个类中定义private static类型的ThreadLocal 实例。 但是要注意，虽然ThreadLocal能够解决上面说的问题，但是由于在每个线程中都创建了副本，所以要考虑它对资源的消耗，比如内存的占用会比不使用ThreadLocal要大。 ThreadLocal原理如何实现线程隔离主要是用到了Thread对象中的一个ThreadLocalMap类型的变量threadLocals, 负责存储当前线程的关于Connection的对象, dbConnectionLocal(以上述例子中为例) 这个变量为Key, 以新建的Connection对象为Value; 这样的话, 线程第一次读取的时候如果不存在就会调用ThreadLocal的initialValue方法创建一个Connection对象并且返回; 具体关于为线程分配变量副本的代码如下: 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap threadLocals = getMap(t); if (threadLocals != null) &#123; ThreadLocalMap.Entry e = threadLocals.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; 首先获取当前线程对象t, 然后从线程t中获取到ThreadLocalMap的成员属性threadLocals 如果当前线程的threadLocals已经初始化(即不为null) 并且存在以当前ThreadLocal对象为Key的值, 则直接返回当前线程要获取的对象(本例中为Connection); 如果当前线程的threadLocals已经初始化(即不为null)但是不存在以当前ThreadLocal对象为Key的的对象, 那么重新创建一个Connection对象, 并且添加到当前线程的threadLocals Map中,并返回 如果当前线程的threadLocals属性还没有被初始化, 则重新创建一个ThreadLocalMap对象, 并且创建一个Connection对象并添加到ThreadLocalMap对象中并返回。 如果存在则直接返回很好理解, 那么对于如何初始化的代码又是怎样的呢? 12345678910private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125; 首先调用我们上面写的重载过后的initialValue方法, 产生一个Connection对象 继续查看当前线程的threadLocals是不是空的, 如果ThreadLocalMap已被初始化, 那么直接将产生的对象添加到ThreadLocalMap中, 如果没有初始化, 则创建并添加对象到其中; 同时, ThreadLocal还提供了直接操作Thread对象中的threadLocals的方法 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; 这样我们也可以不实现initialValue, 将初始化工作放到DBConnectionFactory的getConnection方法中: 123456789101112public Connection getConnection() &#123; Connection connection = dbConnectionLocal.get(); if (connection == null) &#123; try &#123; connection = DriverManager.getConnection(&quot;&quot;, &quot;&quot;, &quot;&quot;); dbConnectionLocal.set(connection); &#125; catch (SQLException e) &#123; e.printStackTrace(); &#125; &#125; return connection;&#125; 那么我们看过代码之后就很清晰的知道了为什么ThreadLocal能够实现变量的多线程隔离了; 其实就是用了Map的数据结构给当前线程缓存了, 要使用的时候就从本线程的threadLocals对象中获取就可以了, key就是当前线程; 当然了在当前线程下获取当前线程里面的Map里面的对象并操作肯定没有线程并发问题了, 当然能做到变量的线程间隔离了; 现在我们知道了ThreadLocal到底是什么了, 又知道了如何使用ThreadLocal以及其基本实现原理了是不是就可以结束了呢? 其实还有一个问题就是ThreadLocalMap是个什么对象, 为什么要用这个对象呢? ThreadLocalMap对象是什么本质上来讲, 它就是一个Map, 但是这个ThreadLocalMap与我们平时见到的Map有点不一样 它没有实现Map接口; 它没有public的方法, 最多有一个default的构造方法, 因为这个ThreadLocalMap的方法仅仅在ThreadLocal类中调用, 属于静态内部类 ThreadLocalMap的Entry实现继承了WeakReference&lt;ThreadLocal&lt;?&gt;&gt; 该方法仅仅用了一个Entry数组来存储Key, Value; Entry并不是链表形式, 而是每个bucket里面仅仅放一个Entry; 要了解ThreadLocalMap的实现, 我们先从入口开始, 就是往该Map中添加一个值: 1234567891011121314151617181920212223242526272829303132private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don&#x27;t use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) &#123; e.value = value; return; &#125; if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; tab[i] = new Entry(key, value); int sz = ++size; if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125; 先进行简单的分析, 对该代码表层意思进行解读: 看下当前threadLocal的在数组中的索引位置 比如: i = 2, 看 i = 2 位置上面的元素(Entry)的Key是否等于threadLocal 这个 Key, 如果等于就很好说了, 直接将该位置上面的Entry的Value替换成最新的就可以了; 如果当前位置上面的 Entry 的 Key为空, 说明ThreadLocal对象已经被回收了, 那么就调用replaceStaleEntry 如果清理完无用条目(ThreadLocal被回收的条目)、并且数组中的数据大小 &gt; 阈值的时候对当前的Table进行重新哈希 所以, 该HashMap是处理冲突检测的机制是向后移位, 清除过期条目 最终找到合适的位置; 了解完Set方法, 后面就是Get方法了: 12345678private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e);&#125; 先找到ThreadLocal的索引位置, 如果索引位置处的entry不为空并且键与threadLocal是同一个对象, 则直接返回; 否则去后面的索引位置继续查找。 ThreadLocal造成内存泄露的问题网上有这样一个例子： 123456789101112131415161718192021222324252627282930313233import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;public class ThreadLocalDemo &#123; static class LocalVariable &#123; private Long[] a = new Long[1024 * 1024]; &#125; // (1) final static ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(5, 5, 1, TimeUnit.MINUTES, new LinkedBlockingQueue&lt;&gt;()); // (2) final static ThreadLocal&lt;LocalVariable&gt; localVariable = new ThreadLocal&lt;LocalVariable&gt;(); public static void main(String[] args) throws InterruptedException &#123; // (3) Thread.sleep(5000 * 4); for (int i = 0; i &lt; 50; ++i) &#123; poolExecutor.execute(new Runnable() &#123; public void run() &#123; // (4) localVariable.set(new LocalVariable()); // (5) System.out.println(&quot;use local varaible&quot; + localVariable.get()); localVariable.remove(); &#125; &#125;); &#125; // (6) System.out.println(&quot;pool execute over&quot;); &#125;&#125; 如果用线程池来操作ThreadLocal 对象确实会造成内存泄露, 因为对于线程池里面不会销毁的线程, 里面总会存在着&lt;ThreadLocal, LocalVariable&gt;的强引用, 因为final static 修饰的 ThreadLocal 并不会释放, 而ThreadLocalMap 对于 Key 虽然是弱引用, 但是强引用不会释放, 弱引用当然也会一直有值, 同时创建的LocalVariable对象也不会释放, 就造成了内存泄露; 如果LocalVariable对象不是一个大对象的话, 其实泄露的并不严重, 泄露的内存 = 核心线程数 * LocalVariable对象的大小; 所以, 为了避免出现内存泄露的情况, ThreadLocal提供了一个清除线程中对象的方法, 即 remove, 其实内部实现就是调用 ThreadLocalMap 的remove方法: 1234567891011121314private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 找到Key对应的Entry, 并且清除Entry的Key(ThreadLocal)置空, 随后清除过期的Entry即可避免内存泄露。 再看ThreadLocal应用场景除了上述的数据库管理类的例子，我们再看看其它一些应用： 每个线程维护了一个“序列号” 再回想上文说的，如果我们希望通过某个类将状态(例如用户ID、事务ID)与线程关联起来，那么通常在这个类中定义private static类型的ThreadLocal 实例。 每个线程维护了一个“序列号” 1234567891011121314public class SerialNum &#123; // The next serial number to be assigned private static int nextSerialNum = 0; private static ThreadLocal serialNum = new ThreadLocal() &#123; protected synchronized Object initialValue() &#123; return new Integer(nextSerialNum++); &#125; &#125;; public static int get() &#123; return ((Integer) (serialNum.get())).intValue(); &#125;&#125; Session的管理经典的另外一个例子： 1234567891011121314private static final ThreadLocal threadSession = new ThreadLocal(); public static Session getSession() throws InfrastructureException &#123; Session s = (Session) threadSession.get(); try &#123; if (s == null) &#123; s = getSessionFactory().openSession(); threadSession.set(s); &#125; &#125; catch (HibernateException ex) &#123; throw new InfrastructureException(ex); &#125; return s; &#125; 在线程内部创建ThreadLocal还有一种用法是在线程类内部创建ThreadLocal，基本步骤如下： 在多线程的类(如ThreadDemo类)中，创建一个ThreadLocal对象threadXxx，用来保存线程间需要隔离处理的对象xxx。 在ThreadDemo类中，创建一个获取要隔离访问的数据的方法getXxx()，在方法中判断，若ThreadLocal对象为null时候，应该new()一个隔离访问类型的对象，并强制转换为要应用的类型。 在ThreadDemo类的run()方法中，通过调用getXxx()方法获取要操作的数据，这样可以保证每个线程对应一个数据对象，在任何时刻都操作的是这个对象。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class ThreadLocalTest implements Runnable&#123; ThreadLocal&lt;Student&gt; StudentThreadLocal = new ThreadLocal&lt;Student&gt;(); @Override public void run() &#123; String currentThreadName = Thread.currentThread().getName(); System.out.println(currentThreadName + &quot; is running...&quot;); Random random = new Random(); int age = random.nextInt(100); System.out.println(currentThreadName + &quot; is set age: &quot; + age); Student Student = getStudentt(); //通过这个方法，为每个线程都独立的new一个Studentt对象，每个线程的的Studentt对象都可以设置不同的值 Student.setAge(age); System.out.println(currentThreadName + &quot; is first get age: &quot; + Student.getAge()); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println( currentThreadName + &quot; is second get age: &quot; + Student.getAge()); &#125; private Student getStudentt() &#123; Student Student = StudentThreadLocal.get(); if (null == Student) &#123; Student = new Student(); StudentThreadLocal.set(Student); &#125; return Student; &#125; public static void main(String[] args) &#123; ThreadLocalTest t = new ThreadLocalTest(); Thread t1 = new Thread(t,&quot;Thread A&quot;); Thread t2 = new Thread(t,&quot;Thread B&quot;); t1.start(); t2.start(); &#125; &#125;class Student&#123; int age; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; &#125; java 开发手册中推荐的 ThreadLocal看看阿里巴巴 java 开发手册中推荐的 ThreadLocal 的用法: 1234567891011import java.text.DateFormat;import java.text.SimpleDateFormat; public class DateUtils &#123; public static final ThreadLocal&lt;DateFormat&gt; df = new ThreadLocal&lt;DateFormat&gt;()&#123; @Override protected DateFormat initialValue() &#123; return new SimpleDateFormat(&quot;yyyy-MM-dd&quot;); &#125; &#125;;&#125; 然后我们再要用到 DateFormat 对象的地方，这样调用： 1DateUtils.df.get().format(new Date()); 参考文章 https://blog.csdn.net/vking_wang/article/details/14225379 https://mp.weixin.qq.com/s/mo3-y-45_ao54b5T7ez7iA https://www.xttblog.com/?p=3087 https://blog.csdn.net/whut2010hj/article/details/81413887 https://segmentfault.com/a/1190000018399795","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"26.JUC工具类: Exchanger详解","path":"/2023/12/26/26-JUC工具类-Exchanger详解/","content":"Exchanger是用于线程协作的工具类, 主要用于两个线程之间的数据交换。 带着BAT大厂的面试问题去理解Exchanger 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解Exchanger。 Exchanger主要解决什么问题? 对比SynchronousQueue，为什么说Exchanger可被视为 SynchronousQueue 的双向形式? Exchanger在不同的JDK版本中实现有什么差别? Exchanger实现机制? Exchanger已经有了slot单节点，为什么会加入arena node数组? 什么时候会用到数组? arena可以确保不同的slot在arena中是不会相冲突的，那么是怎么保证的呢? 什么是伪共享，Exchanger中如何体现的? Exchanger实现举例 Exchanger简介Exchanger用于进行两个线程之间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange()方法交换数据，当一个线程先执行exchange()方法后，它会一直等待第二个线程也执行exchange()方法，当这两个线程到达同步点时，这两个线程就可以交换数据了。 Exchanger实现机制1234567891011121314151617181920for (;;) &#123; if (slot is empty) &#123; // offer // slot为空时，将item 设置到Node 中 place item in a Node; if (can CAS slot from empty to node) &#123; // 当将node通过CAS交换到slot中时，挂起线程等待被唤醒 wait for release; // 被唤醒后返回node中匹配到的item return matching item in node; &#125; &#125; else if (can CAS slot from node to empty) &#123; // release // 将slot设置为空 // 获取node中的item，将需要交换的数据设置到匹配的item get the item in node; set matching item in node; // 唤醒等待的线程 release waiting thread; &#125; // else retry on CAS failure&#125; 比如有2条线程A和B，A线程交换数据时，发现slot为空，则将需要交换的数据放在slot中等待其它线程进来交换数据，等线程B进来，读取A设置的数据，然后设置线程B需要交换的数据，然后唤醒A线程，原理就是这么简单。但是当多个线程之间进行交换数据时就会出现问题，所以Exchanger加入了slot数组。 Exchanger源码解析内部类 - Participant123static final class Participant extends ThreadLocal&lt;Node&gt; &#123; public Node initialValue() &#123; return new Node(); &#125;&#125; Participant的作用是为每个线程保留唯一的一个Node节点, 它继承ThreadLocal，说明每个线程具有不同的状态。 内部类 - Node12345678910111213141516@sun.misc.Contended static final class Node &#123; // arena的下标，多个槽位的时候利用 int index; // 上一次记录的Exchanger.bound int bound; // 在当前bound下CAS失败的次数； int collides; // 用于自旋； int hash; // 这个线程的当前项，也就是需要交换的数据； Object item; //做releasing操作的线程传递的项； volatile Object match; //挂起时设置线程值，其他情况下为null； volatile Thread parked;&#125; 在Node定义中有两个变量值得思考：bound以及collides。前面提到了数组area是为了避免竞争而产生的，如果系统不存在竞争问题，那么完全没有必要开辟一个高效的arena来徒增系统的复杂性。首先通过单个slot的exchanger来交换数据，当探测到竞争时将安排不同的位置的slot来保存线程Node，并且可以确保没有slot会在同一个缓存行上。如何来判断会有竞争呢? CAS替换slot失败，如果失败，则通过记录冲突次数来扩展arena的尺寸，我们在记录冲突的过程中会跟踪“bound”的值，以及会重新计算冲突次数在bound的值被改变时。 核心属性123private final Participant participant;private volatile Node[] arena;private volatile Node slot; 为什么会有 arena数组槽? slot为单个槽，arena为数组槽, 他们都是Node类型。在这里可能会感觉到疑惑，slot作为Exchanger交换数据的场景，应该只需要一个就可以了啊? 为何还多了一个Participant 和数组类型的arena呢? 一个slot交换场所原则上来说应该是可以的，但实际情况却不是如此，多个参与者使用同一个交换场所时，会存在严重伸缩性问题。既然单个交换场所存在问题，那么我们就安排多个，也就是数组arena。通过数组arena来安排不同的线程使用不同的slot来降低竞争问题，并且可以保证最终一定会成对交换数据。但是Exchanger不是一来就会生成arena数组来降低竞争，只有当产生竞争是才会生成arena数组。 那么怎么将Node与当前线程绑定呢？ Participant，Participant 的作用就是为每个线程保留唯一的一个Node节点，它继承ThreadLocal，同时在Node节点中记录在arena中的下标index。 构造函数123456/*** Creates a new Exchanger.*/public Exchanger() &#123; participant = new Participant();&#125; 初始化participant对象。 核心方法 - exchange(V x)等待另一个线程到达此交换点(除非当前线程被中断)，然后将给定的对象传送给该线程，并接收该线程的对象。 123456789101112public V exchange(V x) throws InterruptedException &#123; Object v; // 当参数为null时需要将item设置为空的对象 Object item = (x == null) ? NULL_ITEM : x; // translate null args // 注意到这里的这个表达式是整个方法的核心 if ((arena != null || (v = slotExchange(item, false, 0 L)) == null) &amp;&amp; ((Thread.interrupted() || // disambiguates null return (v = arenaExchange(item, false, 0 L)) == null))) throw new InterruptedException(); return (v == NULL_ITEM) ? null : (V) v;&#125; 这个方法比较好理解：arena为数组槽，如果为null，则执行slotExchange()方法，否则判断线程是否中断，如果中断值抛出InterruptedException异常，没有中断则执行arenaExchange()方法。整套逻辑就是：如果slotExchange(Object item, boolean timed, long ns)方法执行失败了就执行arenaExchange(Object item, boolean timed, long ns)方法，最后返回结果V。 NULL_ITEM 为一个空节点，其实就是一个Object对象而已，slotExchange()为单个slot交换。 slotExchange(Object item, boolean timed, long ns)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107private final Object slotExchange(Object item, boolean timed, long ns) &#123; // 获取当前线程node对象 Node p = participant.get(); // 当前线程 Thread t = Thread.currentThread(); // 若果线程被中断，就直接返回null if (t.isInterrupted()) // preserve interrupt status so caller can recheck return null;\t// 自旋 for (Node q;;) &#123; // 将slot值赋给q if ((q = slot) != null) &#123; // slot 不为null，即表示已有线程已经把需要交换的数据设置在slot中了 // 通过CAS将slot设置成null if (U.compareAndSwapObject(this, SLOT, q, null)) &#123; // CAS操作成功后，将slot中的item赋值给对象v，以便返回。 // 这里也是就读取之前线程要交换的数据 Object v = q.item; // 将当前线程需要交给的数据设置在q中的match q.match = item; // 获取被挂起的线程 Thread w = q.parked; if (w != null) // 如果线程不为null，唤醒它 U.unpark(w); // 返回其他线程给的V return v; &#125; // create arena on contention, but continue until slot null // CAS 操作失败，表示有其它线程竞争，在此线程之前将数据已取走 // NCPU:CPU的核数 // bound == 0 表示arena数组未初始化过，CAS操作bound将其增加SEQ if (NCPU &gt; 1 &amp;&amp; bound == 0 &amp;&amp; U.compareAndSwapInt(this, BOUND, 0, SEQ)) // 初始化arena数组 arena = new Node[(FULL + 2) &lt;&lt; ASHIFT]; &#125; // 上面分析过，只有当arena不为空才会执行slotExchange方法的 // 所以表示刚好已有其它线程加入进来将arena初始化 else if (arena != null) // 这里就需要去执行arenaExchange return null; // caller must reroute to arenaExchange else &#123; // 这里表示当前线程是以第一个线程进来交换数据 // 或者表示之前的数据交换已进行完毕，这里可以看作是第一个线程 // 将需要交换的数据先存放在当前线程变量p中 p.item = item; // 将需要交换的数据通过CAS设置到交换区slot if (U.compareAndSwapObject(this, SLOT, null, p)) // 交换成功后跳出自旋 break; // CAS操作失败，表示有其它线程刚好先于当前线程将数据设置到交换区slot // 将当前线程变量中的item设置为null，然后自旋获取其它线程存放在交换区slot的数据 p.item = null; &#125; &#125; // await release // 执行到这里表示当前线程已将需要的交换的数据放置于交换区slot中了， // 等待其它线程交换数据然后唤醒当前线程 int h = p.hash; long end = timed ? System.nanoTime() + ns : 0 L; // 自旋次数 int spins = (NCPU &gt; 1) ? SPINS : 1; Object v; // 自旋等待直到p.match不为null，也就是说等待其它线程将需要交换的数据放置于交换区slot while ((v = p.match) == null) &#123; // 下面的逻辑主要是自旋等待，直到spins递减到0为止 if (spins &gt; 0) &#123; h ^= h &lt;&lt; 1; h ^= h &gt;&gt;&gt; 3; h ^= h &lt;&lt; 10; if (h == 0) h = SPINS | (int) t.getId(); else if (h &lt; 0 &amp;&amp; (--spins &amp; ((SPINS &gt;&gt;&gt; 1) - 1)) == 0) Thread.yield(); &#125; else if (slot != p) spins = SPINS; // 此处表示未设置超时或者时间未超时 else if (!t.isInterrupted() &amp;&amp; arena == null &amp;&amp; (!timed || (ns = end - System.nanoTime()) &gt; 0 L)) &#123; // 设置线程t被当前对象阻塞 U.putObject(t, BLOCKER, this); // 给p挂机线程的值赋值 p.parked = t; if (slot == p) // 如果slot还没有被置为null，也就表示暂未有线程过来交换数据，需要将当前线程挂起 U.park(false, ns); // 线程被唤醒，将被挂起的线程设置为null p.parked = null; // 设置线程t未被任何对象阻塞 U.putObject(t, BLOCKER, null); // 不是以上条件时(可能是arena已不为null或者超时) &#125; else if (U.compareAndSwapObject(this, SLOT, p, null)) &#123; // arena不为null则v为null,其它为超时则v为超市对象TIMED_OUT，并且跳出循环 v = timed &amp;&amp; ns &lt;= 0 L &amp;&amp; !t.isInterrupted() ? TIMED_OUT : null; break; &#125; &#125; // 取走match值，并将p中的match置为null U.putOrderedObject(p, MATCH, null); // 设置item为null p.item = null; p.hash = h; // 返回交换值 return v;&#125; 程序首先通过participant获取当前线程节点Node。检测是否中断，如果中断return null，等待后续抛出InterruptedException异常。 如果slot不为null，则进行slot消除，成功直接返回数据V，否则失败，则创建arena消除数组。 如果slot为null，但arena不为null，则返回null，进入arenaExchange逻辑。 如果slot为null，且arena也为null，则尝试占领该slot，失败重试，成功则跳出循环进入spin+block(自旋+阻塞)模式。 在自旋+阻塞模式中，首先取得结束时间和自旋次数。如果match(做releasing操作的线程传递的项)为null，其首先尝试spins+随机次自旋(改自旋使用当前节点中的hash，并改变之)和退让。当自旋数为0后，假如slot发生了改变(slot !&#x3D; p)则重置自旋数并重试。否则假如：当前未中断&amp;arena为null&amp;(当前不是限时版本或者限时版本+当前时间未结束)：阻塞或者限时阻塞。假如：当前中断或者arena不为null或者当前为限时版本+时间已经结束：不限时版本：置v为null；限时版本：如果时间结束以及未中断则TIMED_OUT；否则给出null(原因是探测到arena非空或者当前线程中断)。 match不为空时跳出循环。 arenaExchange(Object item, boolean timed, long ns)此方法被执行时表示多个线程进入交换区交换数据，arena数组已被初始化，此方法中的一些处理方式和slotExchange比较类似，它是通过遍历arena数组找到需要交换的数据。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106// timed 为true表示设置了超时时间，ns为&gt;0的值，反之没有设置超时时间private final Object arenaExchange(Object item, boolean timed, long ns) &#123; Node[] a = arena; // 获取当前线程中的存放的node Node p = participant.get(); //index初始值0 for (int i = p.index;;) &#123; // access slot at i // 遍历，如果在数组中找到数据则直接交换并唤醒线程，如未找到则将需要交换给其它线程的数据放置于数组中 int b, m, c; long j; // j is raw array offset // 其实这里就是向右遍历数组，只是用到了元素在内存偏移的偏移量 // q实际为arena数组偏移(i + 1) * 128个地址位上的node Node q = (Node) U.getObjectVolatile(a, j = (i &lt;&lt; ASHIFT) + ABASE); // 如果q不为null，并且CAS操作成功，将下标j的元素置为null if (q != null &amp;&amp; U.compareAndSwapObject(a, j, q, null)) &#123; // 表示当前线程已发现有交换的数据，然后获取数据，唤醒等待的线程 Object v = q.item; // release q.match = item; Thread w = q.parked; if (w != null) U.unpark(w); return v; // q 为null 并且 i 未超过数组边界 &#125; else if (i &lt;= (m = (b = bound) &amp; MMASK) &amp;&amp; q == null) &#123; // 将需要给其它线程的item赋予给p中的item p.item = item; // offer if (U.compareAndSwapObject(a, j, null, p)) &#123; // 交换成功 long end = (timed &amp;&amp; m == 0) ? System.nanoTime() + ns : 0 L; Thread t = Thread.currentThread(); // wait // 自旋直到有其它线程进入，遍历到该元素并与其交换，同时当前线程被唤醒 for (int h = p.hash, spins = SPINS;;) &#123; Object v = p.match; if (v != null) &#123; // 其它线程设置的需要交换的数据match不为null // 将match设置null,item设置为null U.putOrderedObject(p, MATCH, null); p.item = null; // clear for next use p.hash = h; return v; &#125; else if (spins &gt; 0) &#123; h ^= h &lt;&lt; 1; h ^= h &gt;&gt;&gt; 3; h ^= h &lt;&lt; 10; // xorshift if (h == 0) // initialize hash h = SPINS | (int) t.getId(); else if (h &lt; 0 &amp;&amp; // approx 50% true (--spins &amp; ((SPINS &gt;&gt;&gt; 1) - 1)) == 0) Thread.yield(); // two yields per wait &#125; else if (U.getObjectVolatile(a, j) != p) // 和slotExchange方法中的类似，arena数组中的数据已被CAS设置 // match值还未设置，让其再自旋等待match被设置 spins = SPINS; // releaser hasn&#x27;t set match yet else if (!t.isInterrupted() &amp;&amp; m == 0 &amp;&amp; (!timed || (ns = end - System.nanoTime()) &gt; 0 L)) &#123; // 设置线程t被当前对象阻塞 U.putObject(t, BLOCKER, this); // emulate LockSupport // 线程t赋值 p.parked = t; // minimize window if (U.getObjectVolatile(a, j) == p) // 数组中对象还相等，表示线程还未被唤醒，唤醒线程 U.park(false, ns); p.parked = null; // 设置线程t未被任何对象阻塞 U.putObject(t, BLOCKER, null); &#125; else if (U.getObjectVolatile(a, j) == p &amp;&amp; U.compareAndSwapObject(a, j, p, null)) &#123; // 这里给bound增加加一个SEQ if (m != 0) // try to shrink U.compareAndSwapInt(this, BOUND, b, b + SEQ - 1); p.item = null; p.hash = h; i = p.index &gt;&gt;&gt;= 1; // descend if (Thread.interrupted()) return null; if (timed &amp;&amp; m == 0 &amp;&amp; ns &lt;= 0 L) return TIMED_OUT; break; // expired; restart &#125; &#125; &#125; else // 交换失败，表示有其它线程更改了arena数组中下标i的元素 p.item = null; // clear offer &#125; else &#123; // 此时表示下标不在bound &amp; MMASK或q不为null但CAS操作失败 // 需要更新bound变化后的值 if (p.bound != b) &#123; // stale; reset p.bound = b; p.collides = 0; // 反向遍历 i = (i != m || m == 0) ? m : m - 1; &#125; else if ((c = p.collides) &lt; m || m == FULL || !U.compareAndSwapInt(this, BOUND, b, b + SEQ + 1)) &#123; // 记录CAS失败的次数 p.collides = c + 1; // 循环遍历 i = (i == 0) ? m : i - 1; // cyclically traverse &#125; else // 此时表示bound值增加了SEQ+1 i = m + 1; // grow // 设置下标 p.index = i; &#125; &#125;&#125; 首先通过participant取得当前节点Node，然后根据当前节点Node的index去取arena中相对应的节点node。 前面提到过arena可以确保不同的slot在arena中是不会相冲突的，那么是怎么保证的呢？ 123456789101112131415arena = new Node[(FULL + 2) &lt;&lt; ASHIFT];// 这个arena到底有多大呢? 我们先看FULL 和ASHIFT的定义：static final int FULL = (NCPU &gt;= (MMASK &lt;&lt; 1)) ? MMASK : NCPU &gt;&gt;&gt; 1;private static final int ASHIFT = 7;private static final int NCPU = Runtime.getRuntime().availableProcessors();private static final int MMASK = 0xff; // 255// 假如我的机器NCPU = 8 ，则得到的是768大小的arena数组。然后通过以下代码取得在arena中的节点：Node q = (Node)U.getObjectVolatile(a, j = (i &lt;&lt; ASHIFT) + ABASE);// 它仍然是通过右移ASHIFT位来取得Node的，ABASE定义如下：Class&lt;?&gt; ak = Node[].class;ABASE = U.arrayBaseOffset(ak) + (1 &lt;&lt; ASHIFT);// U.arrayBaseOffset获取对象头长度，数组元素的大小可以通过unsafe.arrayIndexScale(T[].class) 方法获取到。这也就是说要访问类型为T的第N个元素的话，你的偏移量offset应该是arrayOffset+N*arrayScale。也就是说BASE = arrayOffset+ 128 。 用@sun.misc.Contended来规避伪共享？ 伪共享说明：假设一个类的两个相互独立的属性a和b在内存地址上是连续的(比如FIFO队列的头尾指针)，那么它们通常会被加载到相同的cpu cache line里面。并发情况下，如果一个线程修改了a，会导致整个cache line失效(包括b)，这时另一个线程来读b，就需要从内存里再次加载了，这种多线程频繁修改ab的情况下，虽然a和b看似独立，但它们会互相干扰，非常影响性能。 我们再看Node节点的定义, 在Java 8 中我们是可以利用sun.misc.Contended来规避伪共享的。所以说通过 &lt;&lt; ASHIFT方式加上sun.misc.Contended，所以使得任意两个可用Node不会再同一个缓存行中。 123@sun.misc.Contended static final class Node&#123;....&#125; 我们再次回到arenaExchange()。取得arena中的node节点后，如果定位的节点q 不为空，且CAS操作成功，则交换数据，返回交换的数据，唤醒等待的线程。 如果q等于null且下标在bound &amp; MMASK范围之内，则尝试占领该位置，如果成功，则采用自旋 + 阻塞的方式进行等待交换数据。 如果下标不在bound &amp; MMASK范围之内获取由于q不为null但是竞争失败的时候：消除p。加入bound 不等于当前节点的bond(b !&#x3D; p.bound)，则更新p.bound &#x3D; b，collides &#x3D; 0 ，i &#x3D; m或者m - 1。如果冲突的次数不到m 获取m 已经为最大值或者修改当前bound的值失败，则通过增加一次collides以及循环递减下标i的值；否则更新当前bound的值成功：我们令i为m+1即为此时最大的下标。最后更新当前index的值。 更深入理解 SynchronousQueue对比？ Exchanger是一种线程间安全交换数据的机制。可以和之前分析过的SynchronousQueue对比一下：线程A通过SynchronousQueue将数据a交给线程B；线程A通过Exchanger和线程B交换数据，线程A把数据a交给线程B，同时线程B把数据b交给线程A。可见，SynchronousQueue是交给一个数据，Exchanger是交换两个数据。 不同JDK实现有何差别？ 在JDK5中Exchanger被设计成一个容量为1的容器，存放一个等待线程，直到有另外线程到来就会发生数据交换，然后清空容器，等到下一个到来的线程。 从JDK6开始，Exchanger用了类似ConcurrentMap的分段思想，提供了多个slot，增加了并发执行时的吞吐量。 JDK1.6实现可以参考 这里在新窗口打开 Exchanger示例来一个非常经典的并发问题：你有相同的数据buffer，一个或多个数据生产者，和一个或多个数据消费者。只是Exchange类只能同步2个线程，所以你只能在你的生产者和消费者问题中只有一个生产者和一个消费者时使用这个类。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class Test &#123; static class Producer extends Thread &#123; private Exchanger&lt;Integer&gt; exchanger; private static int data = 0; Producer(String name, Exchanger&lt;Integer&gt; exchanger) &#123; super(&quot;Producer-&quot; + name); this.exchanger = exchanger; &#125; @Override public void run() &#123; for (int i=1; i&lt;5; i++) &#123; try &#123; TimeUnit.SECONDS.sleep(1); data = i; System.out.println(getName()+&quot; 交换前:&quot; + data); data = exchanger.exchange(data); System.out.println(getName()+&quot; 交换后:&quot; + data); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; static class Consumer extends Thread &#123; private Exchanger&lt;Integer&gt; exchanger; private static int data = 0; Consumer(String name, Exchanger&lt;Integer&gt; exchanger) &#123; super(&quot;Consumer-&quot; + name); this.exchanger = exchanger; &#125; @Override public void run() &#123; while (true) &#123; data = 0; System.out.println(getName()+&quot; 交换前:&quot; + data); try &#123; TimeUnit.SECONDS.sleep(1); data = exchanger.exchange(data); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(getName()+&quot; 交换后:&quot; + data); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Exchanger&lt;Integer&gt; exchanger = new Exchanger&lt;Integer&gt;(); new Producer(&quot;&quot;, exchanger).start(); new Consumer(&quot;&quot;, exchanger).start(); TimeUnit.SECONDS.sleep(7); System.exit(-1); &#125;&#125; 可以看到，其结果可能如下： 1234567891011121314151617Consumer- 交换前:0Producer- 交换前:1Consumer- 交换后:1Consumer- 交换前:0Producer- 交换后:0Producer- 交换前:2Producer- 交换后:0Consumer- 交换后:2Consumer- 交换前:0Producer- 交换前:3Producer- 交换后:0Consumer- 交换后:3Consumer- 交换前:0Producer- 交换前:4Producer- 交换后:0Consumer- 交换后:4Consumer- 交换前:0 参考文章 https://cloud.tencent.com/developer/article/1529492 https://coderbee.net/index.php/concurrent/20140424/897 https://www.cnblogs.com/wanly3643/p/3939552.html https://www.iteye.com/blog/brokendreams-2253956 https://blog.csdn.net/u014634338/article/details/78385521","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"25.JUC工具类: Phaser详解","path":"/2023/12/26/25-JUC工具类-Phaser详解/","content":"Phaser是JDK 7新增的一个同步辅助类，它可以实现CyclicBarrier和CountDownLatch类似的功能，而且它支持对任务的动态调整，并支持分层结构来达到更高的吞吐量。 带着BAT大厂的面试问题去理解Phaser工具 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解Phaser工具。 Phaser主要用来解决什么问题? Phaser与CyclicBarrier和CountDownLatch的区别是什么? 如果用CountDownLatch来实现Phaser的功能应该怎么实现? Phaser运行机制是什么样的? 给一个Phaser使用的示例? Phaser运行机制 Registration(注册) 跟其他barrier不同，在phaser上注册的parties会随着时间的变化而变化。任务可以随时注册(使用方法register,bulkRegister注册，或者由构造器确定初始parties)，并且在任何抵达点可以随意地撤销注册(方法arriveAndDeregister)。就像大多数基本的同步结构一样，注册和撤销只影响内部count；不会创建更深的内部记录，所以任务不能查询他们是否已经注册。(不过，可以通过继承来实现类似的记录) Synchronization(同步机制) 和CyclicBarrier一样，Phaser也可以重复await。方法arriveAndAwaitAdvance的效果类似CyclicBarrier.await。phaser的每一代都有一个相关的phase number，初始值为0，当所有注册的任务都到达phaser时phase+1，到达最大值(Integer.MAX_VALUE)之后清零。使用phase number可以独立控制 到达phaser 和 等待其他线程 的动作，通过下面两种类型的方法: Arrival(到达机制) arrive和arriveAndDeregister方法记录到达状态。这些方法不会阻塞，但是会返回一个相关的arrival phase number；也就是说，phase number用来确定到达状态。当所有任务都到达给定phase时，可以执行一个可选的函数，这个函数通过重写onAdvance方法实现，通常可以用来控制终止状态。重写此方法类似于为CyclicBarrier提供一个barrierAction，但比它更灵活。 Waiting(等待机制) awaitAdvance方法需要一个表示arrival phase number的参数，并且在phaser前进到与给定phase不同的phase时返回。和CyclicBarrier不同，即使等待线程已经被中断，awaitAdvance方法也会一直等待。中断状态和超时时间同样可用，但是当任务等待中断或超时后未改变phaser的状态时会遭遇异常。如果有必要，在方法forceTermination之后可以执行这些异常的相关的handler进行恢复操作，Phaser也可能被ForkJoinPool中的任务使用，这样在其他任务阻塞等待一个phase时可以保证足够的并行度来执行任务。 Termination(终止机制) : 可以用isTerminated方法检查phaser的终止状态。在终止时，所有同步方法立刻返回一个负值。在终止时尝试注册也没有效果。当调用onAdvance返回true时Termination被触发。当deregistration操作使已注册的parties变为0时，onAdvance的默认实现就会返回true。也可以重写onAdvance方法来定义终止动作。forceTermination方法也可以释放等待线程并且允许它们终止。 Tiering(分层结构) : Phaser支持分层结构(树状构造)来减少竞争。注册了大量parties的Phaser可能会因为同步竞争消耗很高的成本， 因此可以设置一些子Phaser来共享一个通用的parent。这样的话即使每个操作消耗了更多的开销，但是会提高整体吞吐量。 在一个分层结构的phaser里，子节点phaser的注册和取消注册都通过父节点管理。子节点phaser通过构造或方法register、bulkRegister进行首次注册时，在其父节点上注册。子节点phaser通过调用arriveAndDeregister进行最后一次取消注册时，也在其父节点上取消注册。 Monitoring(状态监控) : 由于同步方法可能只被已注册的parties调用，所以phaser的当前状态也可能被任何调用者监控。在任何时候，可以通过getRegisteredParties获取parties数，其中getArrivedParties方法返回已经到达当前phase的parties数。当剩余的parties(通过方法getUnarrivedParties获取)到达时，phase进入下一代。这些方法返回的值可能只表示短暂的状态，所以一般来说在同步结构里并没有啥卵用。 Phaser源码详解核心参数123456789101112private volatile long state;/** * The parent of this phaser, or null if none */private final Phaser parent;/** * The root of phaser tree. Equals this if not in a tree. */private final Phaser root;//等待线程的栈顶元素，根据phase取模定义为一个奇数header和一个偶数headerprivate final AtomicReference&lt;QNode&gt; evenQ;private final AtomicReference&lt;QNode&gt; oddQ; state状态说明: Phaser使用一个long型state值来标识内部状态: 低0-15位表示未到达parties数； 中16-31位表示等待的parties数； 中32-62位表示phase当前代； 高63位表示当前phaser的终止状态。 注意: 子Phaser的phase在没有被真正使用之前，允许滞后于它的root节点。这里在后面源码分析的reconcileState方法里会讲解。 Qnode是Phaser定义的内部等待队列，用于在阻塞时记录等待线程及相关信息。实现了ForkJoinPool的一个内部接口ManagedBlocker，上面已经说过，Phaser也可能被ForkJoinPool中的任务使用，这样在其他任务阻塞等待一个phase时可以保证足够的并行度来执行任务(通过内部实现方法isReleasable和block)。 函数列表1234567891011121314151617181920212223242526272829303132333435//构造方法public Phaser() &#123; this(null, 0);&#125;public Phaser(int parties) &#123; this(null, parties);&#125;public Phaser(Phaser parent) &#123; this(parent, 0);&#125;public Phaser(Phaser parent, int parties)//注册一个新的partypublic int register()//批量注册public int bulkRegister(int parties)//使当前线程到达phaser，不等待其他任务到达。返回arrival phase numberpublic int arrive() //使当前线程到达phaser并撤销注册，返回arrival phase numberpublic int arriveAndDeregister()/* * 使当前线程到达phaser并等待其他任务到达，等价于awaitAdvance(arrive())。 * 如果需要等待中断或超时，可以使用awaitAdvance方法完成一个类似的构造。 * 如果需要在到达后取消注册，可以使用awaitAdvance(arriveAndDeregister())。 */public int arriveAndAwaitAdvance()//等待给定phase数，返回下一个 arrival phase numberpublic int awaitAdvance(int phase)//阻塞等待，直到phase前进到下一代，返回下一代的phase numberpublic int awaitAdvance(int phase) //响应中断版awaitAdvancepublic int awaitAdvanceInterruptibly(int phase) throws InterruptedExceptionpublic int awaitAdvanceInterruptibly(int phase, long timeout, TimeUnit unit) throws InterruptedException, TimeoutException//使当前phaser进入终止状态，已注册的parties不受影响，如果是分层结构，则终止所有phaserpublic void forceTermination() 方法 - register()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//注册一个新的partypublic int register() &#123; return doRegister(1);&#125;private int doRegister(int registrations) &#123; // adjustment to state long adjust = ((long)registrations &lt;&lt; PARTIES_SHIFT) | registrations; final Phaser parent = this.parent; int phase; for (;;) &#123; long s = (parent == null) ? state : reconcileState(); int counts = (int)s; int parties = counts &gt;&gt;&gt; PARTIES_SHIFT;//获取已注册parties数 int unarrived = counts &amp; UNARRIVED_MASK;//未到达数 if (registrations &gt; MAX_PARTIES - parties) throw new IllegalStateException(badRegister(s)); phase = (int)(s &gt;&gt;&gt; PHASE_SHIFT);//获取当前代 if (phase &lt; 0) break; if (counts != EMPTY) &#123; // not 1st registration if (parent == null || reconcileState() == s) &#123; if (unarrived == 0) // wait out advance root.internalAwaitAdvance(phase, null);//等待其他任务到达 else if (UNSAFE.compareAndSwapLong(this, stateOffset, s, s + adjust))//更新注册的parties数 break; &#125; &#125; else if (parent == null) &#123; // 1st root registration long next = ((long)phase &lt;&lt; PHASE_SHIFT) | adjust; if (UNSAFE.compareAndSwapLong(this, stateOffset, s, next))//更新phase break; &#125; else &#123; //分层结构，子phaser首次注册用父节点管理 synchronized (this) &#123; // 1st sub registration if (state == s) &#123; // recheck under lock phase = parent.doRegister(1);//分层结构，使用父节点注册 if (phase &lt; 0) break; // finish registration whenever parent registration // succeeded, even when racing with termination, // since these are part of the same &quot;transaction&quot;. //由于在同一个事务里，即使phaser已终止，也会完成注册 while (!UNSAFE.compareAndSwapLong (this, stateOffset, s, ((long)phase &lt;&lt; PHASE_SHIFT) | adjust)) &#123;//更新phase s = state; phase = (int)(root.state &gt;&gt;&gt; PHASE_SHIFT); // assert (int)s == EMPTY; &#125; break; &#125; &#125; &#125; &#125; return phase;&#125; 说明: register方法为phaser添加一个新的party，如果onAdvance正在运行，那么这个方法会等待它运行结束再返回结果。如果当前phaser有父节点，并且当前phaser上没有已注册的party，那么就会交给父节点注册。 register和bulkRegister都由doRegister实现，大概流程如下: 如果当前操作不是首次注册，那么直接在当前phaser上更新注册parties数 如果是首次注册，并且当前phaser没有父节点，说明是root节点注册，直接更新phase 如果当前操作是首次注册，并且当前phaser由父节点，则注册操作交由父节点，并更新当前phaser的phase 上面说过，子Phaser的phase在没有被真正使用之前，允许滞后于它的root节点。非首次注册时，如果Phaser有父节点，则调用reconcileState()方法解决root节点的phase延迟传递问题， 源码如下: 123456789101112131415161718private long reconcileState() &#123; final Phaser root = this.root; long s = state; if (root != this) &#123; int phase, p; // CAS to root phase with current parties, tripping unarrived while ((phase = (int)(root.state &gt;&gt;&gt; PHASE_SHIFT)) != (int)(s &gt;&gt;&gt; PHASE_SHIFT) &amp;&amp; !UNSAFE.compareAndSwapLong (this, stateOffset, s, s = (((long)phase &lt;&lt; PHASE_SHIFT) | ((phase &lt; 0) ? (s &amp; COUNTS_MASK) : (((p = (int)s &gt;&gt;&gt; PARTIES_SHIFT) == 0) ? EMPTY : ((s &amp; PARTIES_MASK) | p)))))) s = state; &#125; return s;&#125; 当root节点的phase已经advance到下一代，但是子节点phaser还没有，这种情况下它们必须通过更新未到达parties数 完成它们自己的advance操作(如果parties为0，重置为EMPTY状态)。 回到register方法的第一步，如果当前未到达数为0，说明上一代phase正在进行到达操作，此时调用internalAwaitAdvance()方法等待其他任务完成到达操作，源码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051//阻塞等待phase到下一代private int internalAwaitAdvance(int phase, QNode node) &#123; // assert root == this; releaseWaiters(phase-1); // ensure old queue clean boolean queued = false; // true when node is enqueued int lastUnarrived = 0; // to increase spins upon change int spins = SPINS_PER_ARRIVAL; long s; int p; while ((p = (int)((s = state) &gt;&gt;&gt; PHASE_SHIFT)) == phase) &#123; if (node == null) &#123; // spinning in noninterruptible mode int unarrived = (int)s &amp; UNARRIVED_MASK;//未到达数 if (unarrived != lastUnarrived &amp;&amp; (lastUnarrived = unarrived) &lt; NCPU) spins += SPINS_PER_ARRIVAL; boolean interrupted = Thread.interrupted(); if (interrupted || --spins &lt; 0) &#123; // need node to record intr //使用node记录中断状态 node = new QNode(this, phase, false, false, 0L); node.wasInterrupted = interrupted; &#125; &#125; else if (node.isReleasable()) // done or aborted break; else if (!queued) &#123; // push onto queue AtomicReference&lt;QNode&gt; head = (phase &amp; 1) == 0 ? evenQ : oddQ; QNode q = node.next = head.get(); if ((q == null || q.phase == phase) &amp;&amp; (int)(state &gt;&gt;&gt; PHASE_SHIFT) == phase) // avoid stale enq queued = head.compareAndSet(q, node); &#125; else &#123; try &#123; ForkJoinPool.managedBlock(node);//阻塞给定node &#125; catch (InterruptedException ie) &#123; node.wasInterrupted = true; &#125; &#125; &#125; if (node != null) &#123; if (node.thread != null) node.thread = null; // avoid need for unpark() if (node.wasInterrupted &amp;&amp; !node.interruptible) Thread.currentThread().interrupt(); if (p == phase &amp;&amp; (p = (int)(state &gt;&gt;&gt; PHASE_SHIFT)) == phase) return abortWait(phase); // possibly clean up on abort &#125; releaseWaiters(phase); return p;&#125; 简单介绍下第二个参数node，如果不为空，则说明等待线程需要追踪中断状态或超时状态。以doRegister中的调用为例，不考虑线程争用，internalAwaitAdvance大概流程如下: 首先调用releaseWaiters唤醒上一代所有等待线程，确保旧队列中没有遗留的等待线程。 循环SPINS_PER_ARRIVAL指定的次数或者当前线程被中断，创建node记录等待线程及相关信息。 继续循环调用ForkJoinPool.managedBlock运行被阻塞的任务 继续循环，阻塞任务运行成功被释放，跳出循环 最后唤醒当前phase的线程 方法 - arrive()12345678910111213141516171819202122232425262728293031323334353637383940414243444546//使当前线程到达phaser，不等待其他任务到达。返回arrival phase numberpublic int arrive() &#123; return doArrive(ONE_ARRIVAL);&#125;private int doArrive(int adjust) &#123; final Phaser root = this.root; for (;;) &#123; long s = (root == this) ? state : reconcileState(); int phase = (int)(s &gt;&gt;&gt; PHASE_SHIFT); if (phase &lt; 0) return phase; int counts = (int)s; //获取未到达数 int unarrived = (counts == EMPTY) ? 0 : (counts &amp; UNARRIVED_MASK); if (unarrived &lt;= 0) throw new IllegalStateException(badArrive(s)); if (UNSAFE.compareAndSwapLong(this, stateOffset, s, s-=adjust)) &#123;//更新state if (unarrived == 1) &#123;//当前为最后一个未到达的任务 long n = s &amp; PARTIES_MASK; // base of next state int nextUnarrived = (int)n &gt;&gt;&gt; PARTIES_SHIFT; if (root == this) &#123; if (onAdvance(phase, nextUnarrived))//检查是否需要终止phaser n |= TERMINATION_BIT; else if (nextUnarrived == 0) n |= EMPTY; else n |= nextUnarrived; int nextPhase = (phase + 1) &amp; MAX_PHASE; n |= (long)nextPhase &lt;&lt; PHASE_SHIFT; UNSAFE.compareAndSwapLong(this, stateOffset, s, n); releaseWaiters(phase);//释放等待phase的线程 &#125; //分层结构，使用父节点管理arrive else if (nextUnarrived == 0) &#123; //propagate deregistration phase = parent.doArrive(ONE_DEREGISTER); UNSAFE.compareAndSwapLong(this, stateOffset, s, s | EMPTY); &#125; else phase = parent.doArrive(ONE_ARRIVAL); &#125; return phase; &#125; &#125;&#125; 说明: arrive方法手动调整到达数，使当前线程到达phaser。arrive和arriveAndDeregister都调用了doArrive实现，大概流程如下: 首先更新state(state - adjust)； 如果当前不是最后一个未到达的任务，直接返回phase 如果当前是最后一个未到达的任务: 如果当前是root节点，判断是否需要终止phaser，CAS更新phase，最后释放等待的线程； 如果是分层结构，并且已经没有下一代未到达的parties，则交由父节点处理doArrive逻辑，然后更新state为EMPTY。 方法 - arriveAndAwaitAdvance()1234567891011121314151617181920212223242526272829303132333435public int arriveAndAwaitAdvance() &#123; // Specialization of doArrive+awaitAdvance eliminating some reads/paths final Phaser root = this.root; for (;;) &#123; long s = (root == this) ? state : reconcileState(); int phase = (int)(s &gt;&gt;&gt; PHASE_SHIFT); if (phase &lt; 0) return phase; int counts = (int)s; int unarrived = (counts == EMPTY) ? 0 : (counts &amp; UNARRIVED_MASK);//获取未到达数 if (unarrived &lt;= 0) throw new IllegalStateException(badArrive(s)); if (UNSAFE.compareAndSwapLong(this, stateOffset, s, s -= ONE_ARRIVAL)) &#123;//更新state if (unarrived &gt; 1) return root.internalAwaitAdvance(phase, null);//阻塞等待其他任务 if (root != this) return parent.arriveAndAwaitAdvance();//子Phaser交给父节点处理 long n = s &amp; PARTIES_MASK; // base of next state int nextUnarrived = (int)n &gt;&gt;&gt; PARTIES_SHIFT; if (onAdvance(phase, nextUnarrived))//全部到达，检查是否可销毁 n |= TERMINATION_BIT; else if (nextUnarrived == 0) n |= EMPTY; else n |= nextUnarrived; int nextPhase = (phase + 1) &amp; MAX_PHASE;//计算下一代phase n |= (long)nextPhase &lt;&lt; PHASE_SHIFT; if (!UNSAFE.compareAndSwapLong(this, stateOffset, s, n))//更新state return (int)(state &gt;&gt;&gt; PHASE_SHIFT); // terminated releaseWaiters(phase);//释放等待phase的线程 return nextPhase; &#125; &#125;&#125; 说明: 使当前线程到达phaser并等待其他任务到达，等价于awaitAdvance(arrive())。如果需要等待中断或超时，可以使用awaitAdvance方法完成一个类似的构造。如果需要在到达后取消注册，可以使用awaitAdvance(arriveAndDeregister())。效果类似于CyclicBarrier.await。大概流程如下: 更新state(state - 1)； 如果未到达数大于1，调用internalAwaitAdvance阻塞等待其他任务到达，返回当前phase 如果为分层结构，则交由父节点处理arriveAndAwaitAdvance逻辑 如果未到达数&lt;&#x3D;1，判断phaser终止状态，CAS更新phase到下一代，最后释放等待当前phase的线程，并返回下一代phase。 方法 - awaitAdvance(int phase)1234567891011121314151617181920212223242526public int awaitAdvance(int phase) &#123; final Phaser root = this.root; long s = (root == this) ? state : reconcileState(); int p = (int)(s &gt;&gt;&gt; PHASE_SHIFT); if (phase &lt; 0) return phase; if (p == phase) return root.internalAwaitAdvance(phase, null); return p;&#125;//响应中断版awaitAdvancepublic int awaitAdvanceInterruptibly(int phase) throws InterruptedException &#123; final Phaser root = this.root; long s = (root == this) ? state : reconcileState(); int p = (int)(s &gt;&gt;&gt; PHASE_SHIFT); if (phase &lt; 0) return phase; if (p == phase) &#123; QNode node = new QNode(this, phase, true, false, 0L); p = root.internalAwaitAdvance(phase, node); if (node.wasInterrupted) throw new InterruptedException(); &#125; return p;&#125; 说明: awaitAdvance用于阻塞等待线程到达，直到phase前进到下一代，返回下一代的phase number。方法很简单，不多赘述。awaitAdvanceInterruptibly方法是响应中断版的awaitAdvance，不同之处在于，调用阻塞时会记录线程的中断状态。 参考文章 本文主要参考自泰迪的bagwell的https://www.jianshu.com/p/e5794645ca8d，在此基础上进行了增改。","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"24.JUC工具类: Semaphore详解","path":"/2023/12/26/24-JUC工具类-Semaphore详解/","content":"Semaphore底层是基于AbstractQueuedSynchronizer来实现的。Semaphore称为计数信号量，它允许n个任务同时访问某个资源，可以将信号量看做是在向外分发使用资源的许可证，只有成功获取许可证，才能使用资源。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 什么是Semaphore? Semaphore内部原理? Semaphore常用方法有哪些? 如何实现线程同步和互斥的? Semaphore适合用在什么场景? 单独使用Semaphore是不会使用到AQS的条件队列? Semaphore中申请令牌(acquire)、释放令牌(release)的实现? Semaphore初始化有10个令牌，11个线程同时各调用1次acquire方法，会发生什么? Semaphore初始化有10个令牌，一个线程重复调用11次acquire方法，会发生什么? Semaphore初始化有1个令牌，1个线程调用一次acquire方法，然后调用两次release方法，之后另外一个线程调用acquire(2)方法，此线程能够获取到足够的令牌并继续运行吗? Semaphore初始化有2个令牌，一个线程调用1次release方法，然后一次性获取3个令牌，会获取到吗? Semaphore源码分析类的继承关系1public class Semaphore implements java.io.Serializable &#123;&#125; 说明: Semaphore实现了Serializable接口，即可以进行序列化。 类的内部类Semaphore总共有三个内部类，并且三个内部类是紧密相关的，下面先看三个类的关系。 说明: Semaphore与ReentrantLock的内部类的结构相同，类内部总共存在Sync、NonfairSync、FairSync三个类，NonfairSync与FairSync类继承自Sync类，Sync类继承自AbstractQueuedSynchronizer抽象类。下面逐个进行分析。 类的内部类 - Sync类Sync类的源码如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// 内部类，继承自AQSabstract static class Sync extends AbstractQueuedSynchronizer &#123; // 版本号 private static final long serialVersionUID = 1192457210091910933L; // 构造函数 Sync(int permits) &#123; // 设置状态数 setState(permits); &#125; // 获取许可 final int getPermits() &#123; return getState(); &#125; // 共享模式下非公平策略获取 final int nonfairTryAcquireShared(int acquires) &#123; for (;;) &#123; // 无限循环 // 获取许可数 int available = getState(); // 剩余的许可 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) // 许可小于0或者比较并且设置状态成功 return remaining; &#125; &#125; // 共享模式下进行释放 protected final boolean tryReleaseShared(int releases) &#123; for (;;) &#123; // 无限循环 // 获取许可 int current = getState(); // 可用的许可 int next = current + releases; if (next &lt; current) // overflow throw new Error(&quot;Maximum permit count exceeded&quot;); if (compareAndSetState(current, next)) // 比较并进行设置成功 return true; &#125; &#125; // 根据指定的缩减量减小可用许可的数目 final void reducePermits(int reductions) &#123; for (;;) &#123; // 无限循环 // 获取许可 int current = getState(); // 可用的许可 int next = current - reductions; if (next &gt; current) // underflow throw new Error(&quot;Permit count underflow&quot;); if (compareAndSetState(current, next)) // 比较并进行设置成功 return; &#125; &#125; // 获取并返回立即可用的所有许可 final int drainPermits() &#123; for (;;) &#123; // 无限循环 // 获取许可 int current = getState(); if (current == 0 || compareAndSetState(current, 0)) // 许可为0或者比较并设置成功 return current; &#125; &#125;&#125; 说明: Sync类的属性相对简单，只有一个版本号，Sync类存在如下方法和作用如下。 类的内部类 - NonfairSync类NonfairSync类继承了Sync类，表示采用非公平策略获取资源，其只有一个tryAcquireShared方法，重写了AQS的该方法，其源码如下: 12345678910111213static final class NonfairSync extends Sync &#123; // 版本号 private static final long serialVersionUID = -2694183684443567898L; // 构造函数 NonfairSync(int permits) &#123; super(permits); &#125; // 共享模式下获取 protected int tryAcquireShared(int acquires) &#123; return nonfairTryAcquireShared(acquires); &#125;&#125; 说明: 从tryAcquireShared方法的源码可知，其会调用父类Sync的nonfairTryAcquireShared方法，表示按照非公平策略进行资源的获取。 类的内部类 - FairSync类FairSync类继承了Sync类，表示采用公平策略获取资源，其只有一个tryAcquireShared方法，重写了AQS的该方法，其源码如下。 12345678910111213protected int tryAcquireShared(int acquires) &#123; for (;;) &#123; // 无限循环 if (hasQueuedPredecessors()) // 同步队列中存在其他节点 return -1; // 获取许可 int available = getState(); // 剩余的许可 int remaining = available - acquires; if (remaining &lt; 0 || compareAndSetState(available, remaining)) // 剩余的许可小于0或者比较设置成功 return remaining; &#125;&#125; 说明: 从tryAcquireShared方法的源码可知，它使用公平策略来获取资源，它会判断同步队列中是否存在其他的等待节点。 类的属性123456public class Semaphore implements java.io.Serializable &#123; // 版本号 private static final long serialVersionUID = -3222578661600680210L; // 属性 private final Sync sync;&#125; 说明: Semaphore自身只有两个属性，最重要的是sync属性，基于Semaphore对象的操作绝大多数都转移到了对sync的操作。 类的构造函数 Semaphore(int)型构造函数 123public Semaphore(int permits) &#123; sync = new NonfairSync(permits);&#125; 说明: 该构造函数会创建具有给定的许可数和非公平的公平设置的Semaphore。 Semaphore(int, boolean)型构造函数 123public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits);&#125; 说明: 该构造函数会创建具有给定的许可数和给定的公平设置的Semaphore。 核心函数分析 - acquire函数此方法从信号量获取一个(多个)许可，在提供一个许可前一直将线程阻塞，或者线程被中断，其源码如下 123public void acquire() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; 说明: 该方法中将会调用Sync对象的acquireSharedInterruptibly(从AQS继承而来的方法)方法，而acquireSharedInterruptibly方法在上一篇CountDownLatch中已经进行了分析，在此不再累赘。 最终可以获取大致的方法调用序列(假设使用非公平策略)。如下图所示。 说明: 上图只是给出了大体会调用到的方法，和具体的示例可能会有些差别，之后会根据具体的示例进行分析。 核心函数分析 - release函数此方法释放一个(多个)许可，将其返回给信号量，源码如下。 123public void release() &#123; sync.releaseShared(1);&#125; 说明: 该方法中将会调用Sync对象的releaseShared(从AQS继承而来的方法)方法，而releaseShared方法在上一篇CountDownLatch中已经进行了分析，在此不再累赘。 最终可以获取大致的方法调用序列(假设使用非公平策略)。如下图所示: 说明: 上图只是给出了大体会调用到的方法，和具体的示例可能会有些差别，之后会根据具体的示例进行分析。 Semaphore示例下面给出了一个使用Semaphore的示例。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import java.util.concurrent.Semaphore;class MyThread extends Thread &#123; private Semaphore semaphore; public MyThread(String name, Semaphore semaphore) &#123; super(name); this.semaphore = semaphore; &#125; public void run() &#123; int count = 3; System.out.println(Thread.currentThread().getName() + &quot; trying to acquire&quot;); try &#123; semaphore.acquire(count); System.out.println(Thread.currentThread().getName() + &quot; acquire successfully&quot;); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(count); System.out.println(Thread.currentThread().getName() + &quot; release successfully&quot;); &#125; &#125;&#125;public class SemaphoreDemo &#123; public final static int SEM_SIZE = 10; public static void main(String[] args) &#123; Semaphore semaphore = new Semaphore(SEM_SIZE); MyThread t1 = new MyThread(&quot;t1&quot;, semaphore); MyThread t2 = new MyThread(&quot;t2&quot;, semaphore); t1.start(); t2.start(); int permits = 5; System.out.println(Thread.currentThread().getName() + &quot; trying to acquire&quot;); try &#123; semaphore.acquire(permits); System.out.println(Thread.currentThread().getName() + &quot; acquire successfully&quot;); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; semaphore.release(); System.out.println(Thread.currentThread().getName() + &quot; release successfully&quot;); &#125; &#125;&#125; 运行结果(某一次): 123456789main trying to acquiremain acquire successfullyt1 trying to acquiret1 acquire successfullyt2 trying to acquiret1 release successfullymain release successfullyt2 acquire successfullyt2 release successfully 说明: 首先，生成一个信号量，信号量有10个许可，然后，main，t1，t2三个线程获取许可运行，根据结果，可能存在如下的一种时序。 说明: 如上图所示，首先，main线程执行acquire操作，并且成功获得许可，之后t1线程执行acquire操作，成功获得许可，之后t2执行acquire操作，由于此时许可数量不够，t2线程将会阻塞，直到许可可用。之后t1线程释放许可，main线程释放许可，此时的许可数量可以满足t2线程的要求，所以，此时t2线程会成功获得许可运行，t2运行完成后释放许可。下面进行详细分析。 main线程执行semaphore.acquire操作。主要的函数调用如下图所示。 说明: 此时，可以看到只是AQS的state变为了5，main线程并没有被阻塞，可以继续运行。 t1线程执行semaphore.acquire操作。主要的函数调用如下图所示。 说明: 此时，可以看到只是AQS的state变为了2，t1线程并没有被阻塞，可以继续运行。 t2线程执行semaphore.acquire操作。主要的函数调用如下图所示。 说明: 此时，t2线程获取许可不会成功，之后会导致其被禁止运行，值得注意的是，AQS的state还是为2。 t1执行semaphore.release操作。主要的函数调用如下图所示。 说明: 此时，t2线程将会被unpark，并且AQS的state为5，t2获取cpu资源后可以继续运行。 main线程执行semaphore.release操作。主要的函数调用如下图所示。 说明: 此时，t2线程还会被unpark，但是不会产生影响，此时，只要t2线程获得CPU资源就可以运行了。此时，AQS的state为10。 t2获取CPU资源，继续运行，此时t2需要恢复现场，回到parkAndCheckInterrupt函数中，也是在should继续运行。主要的函数调用如下图所示。 说明: 此时，可以看到，Sync queue中只有一个结点，头节点与尾节点都指向该结点，在setHeadAndPropagate的函数中会设置头节点并且会unpark队列中的其他结点。 t2线程执行semaphore.release操作。主要的函数调用如下图所示。 说明: t2线程经过release后，此时信号量的许可又变为10个了，此时Sync queue中的结点还是没有变化。 更深入理解单独使用Semaphore是不会使用到AQS的条件队列的不同于CyclicBarrier和ReentrantLock，单独使用Semaphore是不会使用到AQS的条件队列的，其实，只有进行await操作才会进入条件队列，其他的都是在同步队列中，只是当前线程会被park。 场景问题semaphore初始化有10个令牌，11个线程同时各调用1次acquire方法，会发生什么?答案：拿不到令牌的线程阻塞，不会继续往下运行。 semaphore初始化有10个令牌，一个线程重复调用11次acquire方法，会发生什么?答案：线程阻塞，不会继续往下运行。可能你会考虑类似于锁的重入的问题，很好，但是，令牌没有重入的概念。你只要调用一次acquire方法，就需要有一个令牌才能继续运行。 semaphore初始化有1个令牌，1个线程调用一次acquire方法，然后调用两次release方法，之后另外一个线程调用acquire(2)方法，此线程能够获取到足够的令牌并继续运行吗?答案：能，原因是release方法会添加令牌，并不会以初始化的大小为准。 semaphore初始化有2个令牌，一个线程调用1次release方法，然后一次性获取3个令牌，会获取到吗?答案：能，原因是release会添加令牌，并不会以初始化的大小为准。Semaphore中release方法的调用并没有限制要在acquire后调用。 具体示例如下，如果不相信的话，可以运行一下下面的demo，在做实验之前，笔者也认为应该是不允许的。。 12345678910111213public class TestSemaphore2 &#123; public static void main(String[] args) &#123; int permitsNum = 2; final Semaphore semaphore = new Semaphore(permitsNum); try &#123; System.out.println(&quot;availablePermits:&quot;+semaphore.availablePermits()+&quot;,semaphore.tryAcquire(3,1, TimeUnit.SECONDS):&quot;+semaphore.tryAcquire(3,1, TimeUnit.SECONDS)); semaphore.release(); System.out.println(&quot;availablePermits:&quot;+semaphore.availablePermits()+&quot;,semaphore.tryAcquire(3,1, TimeUnit.SECONDS):&quot;+semaphore.tryAcquire(3,1, TimeUnit.SECONDS)); &#125;catch (Exception e) &#123; &#125; &#125;&#125; 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5414778.html，在此基础上做了增改。 https://blog.csdn.net/u010412719/article/details/94986327","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"23.JUC工具类: CyclicBarrier详解","path":"/2023/12/26/23-JUC工具类-CyclicBarrier详解/","content":"CyclicBarrier底层是基于ReentrantLock和AbstractQueuedSynchronizer来实现的, 在理解的时候最好和CountDownLatch放在一起理解(相见本文分析)。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 什么是CyclicBarrier? CyclicBarrier底层实现原理? CountDownLatch和CyclicBarrier对比? CyclicBarrier的核心函数有哪些? CyclicBarrier适用于什么场景? CyclicBarrier简介 对于CountDownLatch，其他线程为游戏玩家，比如英雄联盟，主线程为控制游戏开始的线程。在所有的玩家都准备好之前，主线程是处于等待状态的，也就是游戏不能开始。当所有的玩家准备好之后，下一步的动作实施者为主线程，即开始游戏。 对于CyclicBarrier，假设有一家公司要全体员工进行团建活动，活动内容为翻越三个障碍物，每一个人翻越障碍物所用的时间是不一样的。但是公司要求所有人在翻越当前障碍物之后再开始翻越下一个障碍物，也就是所有人翻越第一个障碍物之后，才开始翻越第二个，以此类推。类比地，每一个员工都是一个“其他线程”。当所有人都翻越的所有的障碍物之后，程序才结束。而主线程可能早就结束了，这里我们不用管主线程。 CyclicBarrier源码分析类的继承关系CyclicBarrier没有显示继承哪个父类或者实现哪个父接口, 所有AQS和重入锁不是通过继承实现的，而是通过组合实现的。 1234567891011public class CyclicBarrier &#123;&#125;``` ### 类的内部类CyclicBarrier类存在一个内部类Generation，每一次使用的CycBarrier可以当成Generation的实例，其源代码如下```javaprivate static class Generation &#123; boolean broken = false;&#125; 说明: Generation类有一个属性broken，用来表示当前屏障是否被损坏。 类的属性1234567891011121314151617181920public class CyclicBarrier &#123; /** The lock for guarding barrier entry */ // 可重入锁 private final ReentrantLock lock = new ReentrantLock(); /** Condition to wait on until tripped */ // 条件队列 private final Condition trip = lock.newCondition(); /** The number of parties */ // 参与的线程数量 private final int parties; /* The command to run when tripped */ // 由最后一个进入 barrier 的线程执行的操作 private final Runnable barrierCommand; /** The current generation */ // 当前代 private Generation generation = new Generation(); // 正在等待进入屏障的线程数量 private int count;&#125; 说明: 该属性有一个为ReentrantLock对象，有一个为Condition对象，而Condition对象又是基于AQS的，所以，归根到底，底层还是由AQS提供支持。 类的构造函数 CyclicBarrier(int, Runnable)型构造函数 12345678910public CyclicBarrier(int parties, Runnable barrierAction) &#123; // 参与的线程数量小于等于0，抛出异常 if (parties &lt;= 0) throw new IllegalArgumentException(); // 设置parties this.parties = parties; // 设置count this.count = parties; // 设置barrierCommand this.barrierCommand = barrierAction;&#125; 说明: 该构造函数可以指定关联该CyclicBarrier的线程数量，并且可以指定在所有线程都进入屏障后的执行动作，该执行动作由最后一个进行屏障的线程执行。 CyclicBarrier(int)型构造函数 1234public CyclicBarrier(int parties) &#123; // 调用含有两个参数的构造函数 this(parties, null);&#125; 说明: 该构造函数仅仅执行了关联该CyclicBarrier的线程数量，没有设置执行动作。 核心函数 - dowait函数此函数为CyclicBarrier类的核心函数，CyclicBarrier类对外提供的await函数在底层都是调用该了doawait函数，其源代码如下。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788private int dowait(boolean timed, long nanos) throws InterruptedException, BrokenBarrierException, TimeoutException &#123; // 保存当前锁 final ReentrantLock lock = this.lock; // 锁定 lock.lock(); try &#123; // 保存当前代 final Generation g = generation; if (g.broken) // 屏障被破坏，抛出异常 throw new BrokenBarrierException(); if (Thread.interrupted()) &#123; // 线程被中断 // 损坏当前屏障，并且唤醒所有的线程，只有拥有锁的时候才会调用 breakBarrier(); // 抛出异常 throw new InterruptedException(); &#125; // 减少正在等待进入屏障的线程数量 int index = --count; if (index == 0) &#123; // 正在等待进入屏障的线程数量为0，所有线程都已经进入 // 运行的动作标识 boolean ranAction = false; try &#123; // 保存运行动作 final Runnable command = barrierCommand; if (command != null) // 动作不为空 // 运行 command.run(); // 设置ranAction状态 ranAction = true; // 进入下一代 nextGeneration(); return 0; &#125; finally &#123; if (!ranAction) // 没有运行的动作 // 损坏当前屏障 breakBarrier(); &#125; &#125; // loop until tripped, broken, interrupted, or timed out // 无限循环 for (;;) &#123; try &#123; if (!timed) // 没有设置等待时间 // 等待 trip.await(); else if (nanos &gt; 0L) // 设置了等待时间，并且等待时间大于0 // 等待指定时长 nanos = trip.awaitNanos(nanos); &#125; catch (InterruptedException ie) &#123; if (g == generation &amp;&amp; ! g.broken) &#123; // 等于当前代并且屏障没有被损坏 // 损坏当前屏障 breakBarrier(); // 抛出异常 throw ie; &#125; else &#123; // 不等于当前带后者是屏障被损坏 // We&#x27;re about to finish waiting even if we had not // been interrupted, so this interrupt is deemed to // &quot;belong&quot; to subsequent execution. // 中断当前线程 Thread.currentThread().interrupt(); &#125; &#125; if (g.broken) // 屏障被损坏，抛出异常 throw new BrokenBarrierException(); if (g != generation) // 不等于当前代 // 返回索引 return index; if (timed &amp;&amp; nanos &lt;= 0L) &#123; // 设置了等待时间，并且等待时间小于0 // 损坏屏障 breakBarrier(); // 抛出异常 throw new TimeoutException(); &#125; &#125; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 说明: dowait方法的逻辑会进行一系列的判断，大致流程如下: 核心函数 - nextGeneration函数此函数在所有线程进入屏障后会被调用，即生成下一个版本，所有线程又可以重新进入到屏障中，其源代码如下 12345678910private void nextGeneration() &#123; // signal completion of last generation // 唤醒所有线程 trip.signalAll(); // set up next generation // 恢复正在等待进入屏障的线程数量 count = parties; // 新生一代 generation = new Generation();&#125; 在此函数中会调用AQS的signalAll方法，即唤醒所有等待线程。如果所有的线程都在等待此条件，则唤醒所有线程。其源代码如下 123456789public final void signalAll() &#123; if (!isHeldExclusively()) // 不被当前线程独占，抛出异常 throw new IllegalMonitorStateException(); // 保存condition队列头节点 Node first = firstWaiter; if (first != null) // 头节点不为空 // 唤醒所有等待线程 doSignalAll(first);&#125; 说明: 此函数判断头节点是否为空，即条件队列是否为空，然后会调用doSignalAll函数，doSignalAll函数源码如下 123456789101112131415private void doSignalAll(Node first) &#123; // condition队列的头节点尾结点都设置为空 lastWaiter = firstWaiter = null; // 循环 do &#123; // 获取first结点的nextWaiter域结点 Node next = first.nextWaiter; // 设置first结点的nextWaiter域为空 first.nextWaiter = null; // 将first结点从condition队列转移到sync队列 transferForSignal(first); // 重新设置first first = next; &#125; while (first != null);&#125; 说明: 此函数会依次将条件队列中的节点转移到同步队列中，会调用到transferForSignal函数，其源码如下 12345678910111213141516171819final boolean transferForSignal(Node node) &#123; /* * If cannot change waitStatus, the node has been cancelled. */ if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; /* * Splice onto queue and try to set waitStatus of predecessor to * indicate that thread is (probably) waiting. If cancelled or * attempt to set waitStatus fails, wake up to resync (in which * case the waitStatus can be transiently and harmlessly wrong). */ Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; 说明: 此函数的作用就是将处于条件队列中的节点转移到同步队列中，并设置结点的状态信息，其中会调用到enq函数，其源代码如下。 123456789101112131415161718private Node enq(final Node node) &#123; for (;;) &#123; // 无限循环，确保结点能够成功入队列 // 保存尾结点 Node t = tail; if (t == null) &#123; // 尾结点为空，即还没被初始化 if (compareAndSetHead(new Node())) // 头节点为空，并设置头节点为新生成的结点 tail = head; // 头节点与尾结点都指向同一个新生结点 &#125; else &#123; // 尾结点不为空，即已经被初始化过 // 将node结点的prev域连接到尾结点 node.prev = t; if (compareAndSetTail(t, node)) &#123; // 比较结点t是否为尾结点，若是则将尾结点设置为node // 设置尾结点的next域为node t.next = node; return t; // 返回尾结点 &#125; &#125; &#125;&#125; 说明: 此函数完成了结点插入同步队列的过程，也很好理解。 综合上面的分析可知，newGeneration函数的主要方法的调用如下，之后会通过一个例子详细讲解: breakBarrier函数此函数的作用是损坏当前屏障，会唤醒所有在屏障中的线程。源代码如下: 12345678private void breakBarrier() &#123; // 设置状态 generation.broken = true; // 恢复正在等待进入屏障的线程数量 count = parties; // 唤醒所有线程 trip.signalAll();&#125; 说明: 可以看到，此函数也调用了AQS的signalAll函数，由signal函数提供支持。 CyclicBarrier示例下面通过一个例子来详解CyclicBarrier的使用和内部工作机制，源代码如下 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.BrokenBarrierException;import java.util.concurrent.CyclicBarrier;class MyThread extends Thread &#123; private CyclicBarrier cb; public MyThread(String name, CyclicBarrier cb) &#123; super(name); this.cb = cb; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; going to await&quot;); try &#123; cb.await(); System.out.println(Thread.currentThread().getName() + &quot; continue&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class CyclicBarrierDemo &#123; public static void main(String[] args) throws InterruptedException, BrokenBarrierException &#123; CyclicBarrier cb = new CyclicBarrier(3, new Thread(&quot;barrierAction&quot;) &#123; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; barrier action&quot;); &#125; &#125;); MyThread t1 = new MyThread(&quot;t1&quot;, cb); MyThread t2 = new MyThread(&quot;t2&quot;, cb); t1.start(); t2.start(); System.out.println(Thread.currentThread().getName() + &quot; going to await&quot;); cb.await(); System.out.println(Thread.currentThread().getName() + &quot; continue&quot;); &#125;&#125; 运行结果(某一次): 1234567t1 going to awaitmain going to awaitt2 going to awaitt2 barrier actiont2 continuet1 continuemain continue 说明: 根据结果可知，可能会存在如下的调用时序。 说明: 由上图可知，假设t1线程的cb.await是在main线程的cb.barrierAction动作是由最后一个进入屏障的线程执行的。根据时序图，进一步分析出其内部工作流程。 main(主)线程执行cb.await操作，主要调用的函数如下。 说明: 由于ReentrantLock的默认采用非公平策略，所以在dowait函数中调用的是ReentrantLock.NonfairSync的lock函数，由于此时AQS的状态是0，表示还没有被任何线程占用，故main线程可以占用，之后在dowait中会调用trip.await函数，最终的结果是条件队列中存放了一个包含main线程的结点，并且被禁止运行了，同时，main线程所拥有的资源也被释放了，可以供其他线程获取。 t1线程执行cb.await操作，其中假设t1线程的lock.lock操作在main线程释放了资源之后，则其主要调用的函数如下。 说明: 可以看到，之后condition queue(条件队列)里面有两个节点，包含t1线程的结点插入在队列的尾部，并且t1线程也被禁止了，因为执行了park操作，此时两个线程都被禁止了。 t2线程执行cb.await操作，其中假设t2线程的lock.lock操作在t1线程释放了资源之后，则其主要调用的函数如下。 说明: 由上图可知，在t2线程执行await操作后，会直接执行command.run方法，不是重新开启一个线程，而是最后进入屏障的线程执行。同时，会将Condition queue中的所有节点都转移到Sync queue中，并且最后main线程会被unpark，可以继续运行。main线程获取cpu资源，继续运行。 main线程获取cpu资源，继续运行，下图给出了主要的方法调用: 说明: 其中，由于main线程是在AQS.CO的wait中被park的，所以恢复时，会继续在该方法中运行。运行过后，t1线程被unpark，它获得cpu资源可以继续运行。 t1线程获取cpu资源，继续运行，下图给出了主要的方法调用。 说明: 其中，由于t1线程是在AQS.CO的wait方法中被park，所以恢复时，会继续在该方法中运行。运行过后，Sync queue中保持着一个空节点。头节点与尾节点均指向它。 注意: 在线程await过程中中断线程会抛出异常，所有进入屏障的线程都将被释放。至于CyclicBarrier的其他用法，读者可以自行查阅API，不再累赘。 和CountDonwLatch再对比 CountDownLatch减计数，CyclicBarrier加计数。 CountDownLatch是一次性的，CyclicBarrier可以重用。 CountDownLatch和CyclicBarrier都有让多个线程等待同步然后再开始下一步动作的意思，但是CountDownLatch的下一步的动作实施者是主线程，具有不可重复性；而CyclicBarrier的下一步动作实施者还是“其他线程”本身，具有往复多次实施动作的特点。 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5392816.html，在此基础上做了增改。","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"22.JUC工具类: CountDownLatch详解","path":"/2023/12/26/22-JUC工具类-CountDownLatch详解/","content":"CountDownLatch底层也是由AQS，用来同步一个或多个任务的常用并发工具类，强制它们等待由其他任务执行的一组操作完成。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 什么是CountDownLatch? CountDownLatch底层实现原理? CountDownLatch一次可以唤醒几个任务? 多个 CountDownLatch有哪些主要方法? await(),countDown() CountDownLatch适用于什么场景? 写道题：实现一个容器，提供两个方法，add，size 写两个线程，线程1添加10个元素到容器中，线程2实现监控元素的个数，当个数到5个时，线程2给出提示并结束? 使用CountDownLatch 代替wait notify 好处。 CountDownLatch介绍从源码可知，其底层是由AQS提供支持，所以其数据结构可以参考AQS的数据结构，而AQS的数据结构核心就是两个虚拟队列: 同步队列sync queue 和条件队列condition queue，不同的条件会有不同的条件队列。CountDownLatch典型的用法是将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。当每一个任务完成时，都会在这个锁存器上调用countDown，等待问题被解决的任务调用这个锁存器的await，将他们自己拦住，直至锁存器计数结束。 CountDownLatch源码分析类的继承关系CountDownLatch没有显示继承哪个父类或者实现哪个父接口, 它底层是AQS是通过内部类Sync来实现的。 1public class CountDownLatch &#123;&#125; 类的内部类CountDownLatch类存在一个内部类Sync，继承自AbstractQueuedSynchronizer，其源代码如下。 1234567891011121314151617181920212223242526272829303132333435private static final class Sync extends AbstractQueuedSynchronizer &#123; // 版本号 private static final long serialVersionUID = 4982264981922014374L; // 构造器 Sync(int count) &#123; setState(count); &#125; // 返回当前计数 int getCount() &#123; return getState(); &#125; // 试图在共享模式下获取对象状态 protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; // 试图设置状态来反映共享模式下的一个释放 protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero // 无限循环 for (;;) &#123; // 获取状态 int c = getState(); if (c == 0) // 没有被线程占有 return false; // 下一个状态 int nextc = c-1; if (compareAndSetState(c, nextc)) // 比较并且设置成功 return nextc == 0; &#125; &#125;&#125; 说明: 对CountDownLatch方法的调用会转发到对Sync或AQS的方法的调用，所以，AQS对CountDownLatch提供支持。 类的属性可以看到CountDownLatch类的内部只有一个Sync类型的属性: 1234public class CountDownLatch &#123; // 同步队列 private final Sync sync;&#125; 类的构造函数12345public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(&quot;count &lt; 0&quot;); // 初始化状态数 this.sync = new Sync(count);&#125; 说明: 该构造函数可以构造一个用给定计数初始化的CountDownLatch，并且构造函数内完成了sync的初始化，并设置了状态数。 核心函数 - await函数此函数将会使当前线程在锁存器倒计数至零之前一直等待，除非线程被中断。其源码如下 1234public void await() throws InterruptedException &#123; // 转发到sync对象上 sync.acquireSharedInterruptibly(1);&#125; 说明: 由源码可知，对CountDownLatch对象的await的调用会转发为对Sync的acquireSharedInterruptibly(从AQS继承的方法)方法的调用。 acquireSharedInterruptibly源码如下: 1234567public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; 说明: 从源码中可知，acquireSharedInterruptibly又调用了CountDownLatch的内部类Sync的tryAcquireShared和AQS的doAcquireSharedInterruptibly函数。 tryAcquireShared函数的源码如下: 123protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; 说明: 该函数只是简单的判断AQS的state是否为0，为0则返回1，不为0则返回-1。 doAcquireSharedInterruptibly函数的源码如下: 123456789101112131415161718192021222324252627282930private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; // 添加节点至等待队列 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; // 无限循环 // 获取node的前驱节点 final Node p = node.predecessor(); if (p == head) &#123; // 前驱节点为头节点 // 试图在共享模式下获取对象状态 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; // 获取成功 // 设置头节点并进行繁殖 setHeadAndPropagate(node, r); // 设置节点next域 p.next = null; // help GC failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) // 在获取失败后是否需要禁止线程并且进行中断检查 // 抛出异常 throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 说明: 在AQS的doAcquireSharedInterruptibly中可能会再次调用CountDownLatch的内部类Sync的tryAcquireShared方法和AQS的setHeadAndPropagate方法。 setHeadAndPropagate方法源码如下。 12345678910111213141516171819202122232425262728293031private void setHeadAndPropagate(Node node, int propagate) &#123; // 获取头节点 Node h = head; // Record old head for check below // 设置头节点 setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don&#x27;t know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ // 进行判断 if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; // 获取节点的后继 Node s = node.next; if (s == null || s.isShared()) // 后继为空或者为共享模式 // 以共享模式进行释放 doReleaseShared(); &#125;&#125; 说明: 该方法设置头节点并且释放头节点后面的满足条件的结点，该方法中可能会调用到AQS的doReleaseShared方法，其源码如下。 123456789101112131415161718192021222324252627282930313233private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ // 无限循环 for (;;) &#123; // 保存头节点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; // 头节点不为空并且头节点不为尾结点 // 获取头节点的等待状态 int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 状态为SIGNAL if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) // 不成功就继续 continue; // loop to recheck cases // 释放后继结点 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) // 状态为0并且不成功，继续 continue; // loop on failed CAS &#125; if (h == head) // 若头节点改变，继续循环 break; &#125;&#125; 说明: 该方法在共享模式下释放，具体的流程再之后会通过一个示例给出。 所以，对CountDownLatch的await调用大致会有如下的调用链。 说明: 上图给出了可能会调用到的主要方法，并非一定会调用到，之后，会通过一个示例给出详细的分析。 核心函数 - countDown函数此函数将递减锁存器的计数，如果计数到达零，则释放所有等待的线程 123public void countDown() &#123; sync.releaseShared(1);&#125; 说明: 对countDown的调用转换为对Sync对象的releaseShared(从AQS继承而来)方法的调用。 releaseShared源码如下 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 说明: 此函数会以共享模式释放对象，并且在函数中会调用到CountDownLatch的tryReleaseShared函数，并且可能会调用AQS的doReleaseShared函数。 tryReleaseShared源码如下 1234567891011121314protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero // 无限循环 for (;;) &#123; // 获取状态 int c = getState(); if (c == 0) // 没有被线程占有 return false; // 下一个状态 int nextc = c-1; if (compareAndSetState(c, nextc)) // 比较并且设置成功 return nextc == 0; &#125;&#125; 说明: 此函数会试图设置状态来反映共享模式下的一个释放。具体的流程在下面的示例中会进行分析。 AQS的doReleaseShared的源码如下 123456789101112131415161718192021222324252627282930313233private void doReleaseShared() &#123; /* * Ensure that a release propagates, even if there are other * in-progress acquires/releases. This proceeds in the usual * way of trying to unparkSuccessor of head if it needs * signal. But if it does not, status is set to PROPAGATE to * ensure that upon release, propagation continues. * Additionally, we must loop in case a new node is added * while we are doing this. Also, unlike other uses of * unparkSuccessor, we need to know if CAS to reset status * fails, if so rechecking. */ // 无限循环 for (;;) &#123; // 保存头节点 Node h = head; if (h != null &amp;&amp; h != tail) &#123; // 头节点不为空并且头节点不为尾结点 // 获取头节点的等待状态 int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; // 状态为SIGNAL if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) // 不成功就继续 continue; // loop to recheck cases // 释放后继结点 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) // 状态为0并且不成功，继续 continue; // loop on failed CAS &#125; if (h == head) // 若头节点改变，继续循环 break; &#125;&#125; 说明: 此函数在共享模式下释放资源。 所以，对CountDownLatch的countDown调用大致会有如下的调用链。 说明: 上图给出了可能会调用到的主要方法，并非一定会调用到，之后，会通过一个示例给出详细的分析。 CountDownLatch示例下面给出了一个使用CountDownLatch的示例。 1234567891011121314151617181920212223242526272829303132333435363738import java.util.concurrent.CountDownLatch;class MyThread extends Thread &#123; private CountDownLatch countDownLatch; public MyThread(String name, CountDownLatch countDownLatch) &#123; super(name); this.countDownLatch = countDownLatch; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; doing something&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; finish&quot;); countDownLatch.countDown(); &#125;&#125;public class CountDownLatchDemo &#123; public static void main(String[] args) &#123; CountDownLatch countDownLatch = new CountDownLatch(2); MyThread t1 = new MyThread(&quot;t1&quot;, countDownLatch); MyThread t2 = new MyThread(&quot;t2&quot;, countDownLatch); t1.start(); t2.start(); System.out.println(&quot;Waiting for t1 thread and t2 thread to finish&quot;); try &#123; countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot; continue&quot;); &#125;&#125; 运行结果(某一次): 123456Waiting for t1 thread and t2 thread to finisht1 doing somethingt2 doing somethingt1 finisht2 finishmain continue 说明: 本程序首先计数器初始化为2。根据结果，可能会存在如下的一种时序图。 说明: 首先main线程会调用await操作，此时main线程会被阻塞，等待被唤醒，之后t1线程执行了countDown操作，最后，t2线程执行了countDown操作，此时main线程就被唤醒了，可以继续运行。下面，进行详细分析。 main线程执行countDownLatch.await操作，主要调用的函数如下。 说明: 在最后，main线程就被park了，即禁止运行了。此时Sync queue(同步队列)中有两个节点，AQS的state为2，包含main线程的结点的nextWaiter指向SHARED结点。 t1线程执行countDownLatch.countDown操作，主要调用的函数如下。 说明: 此时，Sync queue队列里的结点个数未发生变化，但是此时，AQS的state已经变为1了。 t2线程执行countDownLatch.countDown操作，主要调用的函数如下。 说明: 经过调用后，AQS的state为0，并且此时，main线程会被unpark，可以继续运行。当main线程获取cpu资源后，继续运行。 main线程获取cpu资源，继续运行，由于main线程是在parkAndCheckInterrupt函数中被禁止的，所以此时，继续在parkAndCheckInterrupt函数运行。 说明: main线程恢复，继续在parkAndCheckInterrupt函数中运行，之后又会回到最终达到的状态为AQS的state为0，并且head与tail指向同一个结点，该节点的额nextWaiter域还是指向SHARED结点。 更深入理解写道面试题 实现一个容器，提供两个方法，add，size 写两个线程，线程1添加10个元素到容器中，线程2实现监控元素的个数，当个数到5个时，线程2给出提示并结束. 使用wait和notify实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960import java.util.ArrayList;import java.util.List;/** * 必须先让t2先进行启动 使用wait 和 notify 进行相互通讯，wait会释放锁，notify不会释放锁 */public class T2 &#123; volatile List list = new ArrayList(); public void add (int i)&#123; list.add(i); &#125; public int getSize()&#123; return list.size(); &#125; public static void main(String[] args) &#123; T2 t2 = new T2(); Object lock = new Object(); new Thread(() -&gt; &#123; synchronized(lock)&#123; System.out.println(&quot;t2 启动&quot;); if(t2.getSize() != 5)&#123; try &#123; /**会释放锁*/ lock.wait(); System.out.println(&quot;t2 结束&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; lock.notify(); &#125; &#125;,&quot;t2&quot;).start(); new Thread(() -&gt; &#123; synchronized (lock)&#123; System.out.println(&quot;t1 启动&quot;); for (int i=0;i&lt;9;i++)&#123; t2.add(i); System.out.println(&quot;add&quot;+i); if(t2.getSize() == 5)&#123; /**不会释放锁*/ lock.notify(); try &#123; lock.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; &#125;).start(); &#125;&#125; 输出： 123456789101112t2 启动t1 启动add0add1add2add3add4t2 结束add5add6add7add8 CountDownLatch实现说出使用CountDownLatch 代替wait notify 好处? 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.ArrayList;import java.util.List;import java.util.concurrent.CountDownLatch;/** * 使用CountDownLatch 代替wait notify 好处是通讯方式简单，不涉及锁定 Count 值为0时当前线程继续执行， */public class T3 &#123; volatile List list = new ArrayList(); public void add(int i)&#123; list.add(i); &#125; public int getSize()&#123; return list.size(); &#125; public static void main(String[] args) &#123; T3 t = new T3(); CountDownLatch countDownLatch = new CountDownLatch(1); new Thread(() -&gt; &#123; System.out.println(&quot;t2 start&quot;); if(t.getSize() != 5)&#123; try &#123; countDownLatch.await(); System.out.println(&quot;t2 end&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;,&quot;t2&quot;).start(); new Thread(()-&gt;&#123; System.out.println(&quot;t1 start&quot;); for (int i = 0;i&lt;9;i++)&#123; t.add(i); System.out.println(&quot;add&quot;+ i); if(t.getSize() == 5)&#123; System.out.println(&quot;countdown is open&quot;); countDownLatch.countDown(); &#125; &#125; System.out.println(&quot;t1 end&quot;); &#125;,&quot;t1&quot;).start(); &#125;&#125; 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5406191.html，在此基础上做了增改。 https://www.jianshu.com/p/40336ef1f5fe","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"21.JUC线程池: Fork/Join框架详解","path":"/2023/12/26/21-JUC线程池-Fork-Join框架详解/","content":"ForkJoinPool 是JDK 7加入的一个线程池类。Fork&#x2F;Join 技术是分治算法(Divide-and-Conquer)的并行实现，它是一项可以获得良好的并行性能的简单且高效的设计技术。目的是为了帮助我们更好地利用多处理器带来的好处，使用所有可用的运算能力来提升应用的性能。 带着BAT大厂的面试问题去理解Fork&#x2F;Join框架 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解Fork&#x2F;Join框架。 Fork&#x2F;Join主要用来解决什么样的问题? Fork&#x2F;Join框架是在哪个JDK版本中引入的? Fork&#x2F;Join框架主要包含哪三个模块? 模块之间的关系是怎么样的? ForkJoinPool类继承关系? ForkJoinTask抽象类继承关系? 在实际运用中，我们一般都会继承 RecursiveTask 、RecursiveAction 或 CountedCompleter 来实现我们的业务需求，而不会直接继承 ForkJoinTask 类。 整个Fork&#x2F;Join 框架的执行流程&#x2F;运行机制是怎么样的? 具体阐述Fork&#x2F;Join的分治思想和work-stealing 实现方式? 有哪些JDK源码中使用了Fork&#x2F;Join思想? 如何使用Executors工具类创建ForkJoinPool? 写一个例子: 用ForkJoin方式实现1+2+3+…+100000? Fork&#x2F;Join在使用时有哪些注意事项? 结合JDK中的斐波那契数列实例具体说明。 Fork&#x2F;Join框架简介Fork&#x2F;Join框架是Java并发工具包中的一种可以将一个大任务拆分为很多小任务来异步执行的工具，自JDK1.7引入。 三个模块及关系Fork&#x2F;Join框架主要包含三个模块: 任务对象: ForkJoinTask (包括RecursiveTask、RecursiveAction 和 CountedCompleter) 执行Fork&#x2F;Join任务的线程: ForkJoinWorkerThread 线程池: ForkJoinPool 这三者的关系是: ForkJoinPool可以通过池中的ForkJoinWorkerThread来处理ForkJoinTask任务。 1234567891011// from 《A Java Fork/Join Framework》Dong LeaResult solve(Problem problem) &#123;\tif (problem is small) directly solve problem else &#123; split problem into independent parts fork new subtasks to solve each part join all subtasks compose result from subresults\t&#125;&#125; ForkJoinPool 只接收 ForkJoinTask 任务(在实际使用中，也可以接收 Runnable&#x2F;Callable 任务，但在真正运行时，也会把这些任务封装成 ForkJoinTask 类型的任务)，RecursiveTask 是 ForkJoinTask 的子类，是一个可以递归执行的 ForkJoinTask，RecursiveAction 是一个无返回值的 RecursiveTask，CountedCompleter 在任务完成执行后会触发执行一个自定义的钩子函数。 在实际运用中，我们一般都会继承 RecursiveTask 、RecursiveAction 或 CountedCompleter 来实现我们的业务需求，而不会直接继承 ForkJoinTask 类。 核心思想: 分治算法(Divide-and-Conquer)分治算法(Divide-and-Conquer)把任务递归的拆分为各个子任务，这样可以更好的利用系统资源，尽可能的使用所有可用的计算能力来提升应用性能。首先看一下 Fork&#x2F;Join 框架的任务运行机制: 这里也可以一并看下: 算法思想 - 分治算法 核心思想: work-stealing(工作窃取)算法work-stealing(工作窃取)算法: 线程池内的所有工作线程都尝试找到并执行已经提交的任务，或者是被其他活动任务创建的子任务(如果不存在就阻塞等待)。这种特性使得 ForkJoinPool 在运行多个可以产生子任务的任务，或者是提交的许多小任务时效率更高。尤其是构建异步模型的 ForkJoinPool 时，对不需要合并(join)的事件类型任务也非常适用。 在 ForkJoinPool 中，线程池中每个工作线程(ForkJoinWorkerThread)都对应一个任务队列(WorkQueue)，工作线程优先处理来自自身队列的任务(LIFO或FIFO顺序，参数 mode 决定)，然后以FIFO的顺序随机窃取其他队列中的任务。 具体思路如下: 每个线程都有自己的一个WorkQueue，该工作队列是一个双端队列。 队列支持三个功能push、pop、poll push&#x2F;pop只能被队列的所有者线程调用，而poll可以被其他线程调用。 划分的子任务调用fork时，都会被push到自己的队列中。 默认情况下，工作线程从自己的双端队列获出任务并执行。 当自己的队列为空时，线程随机从另一个线程的队列末尾调用poll方法窃取任务。 Fork&#x2F;Join 框架的执行流程上图可以看出ForkJoinPool 中的任务执行分两种: 直接通过 FJP 提交的外部任务(external&#x2F;submissions task)，存放在 workQueues 的偶数槽位； 通过内部 fork 分割的子任务(Worker task)，存放在 workQueues 的奇数槽位。 那Fork&#x2F;Join 框架的执行流程是什么样的? 后续的源码解析将围绕上图进行。 Fork&#x2F;Join类关系ForkJoinPool继承关系 内部类介绍: ForkJoinWorkerThreadFactory: 内部线程工厂接口，用于创建工作线程ForkJoinWorkerThread DefaultForkJoinWorkerThreadFactory: ForkJoinWorkerThreadFactory 的默认实现类 InnocuousForkJoinWorkerThreadFactory: 实现了 ForkJoinWorkerThreadFactory，无许可线程工厂，当系统变量中有系统安全管理相关属性时，默认使用这个工厂创建工作线程。 EmptyTask: 内部占位类，用于替换队列中 join 的任务。 ManagedBlocker: 为 ForkJoinPool 中的任务提供扩展管理并行数的接口，一般用在可能会阻塞的任务(如在 Phaser 中用于等待 phase 到下一个generation)。 WorkQueue: ForkJoinPool 的核心数据结构，本质上是work-stealing 模式的双端任务队列，内部存放 ForkJoinTask 对象任务，使用 @Contented 注解修饰防止伪共享。 工作线程在运行中产生新的任务(通常是因为调用了 fork())时，此时可以把 WorkQueue 的数据结构视为一个栈，新的任务会放入栈顶(top 位)；工作线程在处理自己工作队列的任务时，按照 LIFO 的顺序。 工作线程在处理自己的工作队列同时，会尝试窃取一个任务(可能是来自于刚刚提交到 pool 的任务，或是来自于其他工作线程的队列任务)，此时可以把 WorkQueue 的数据结构视为一个 FIFO 的队列，窃取的任务位于其他线程的工作队列的队首(base位)。 伪共享状态: 缓存系统中是以缓存行(cache line)为单位存储的。缓存行是2的整数幂个连续字节，一般为32-256个字节。最常见的缓存行大小是64个字节。当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。 ForkJoinTask继承关系 ForkJoinTask 实现了 Future 接口，说明它也是一个可取消的异步运算任务，实际上ForkJoinTask 是 Future 的轻量级实现，主要用在纯粹是计算的函数式任务或者操作完全独立的对象计算任务。fork 是主运行方法，用于异步执行；而 join 方法在任务结果计算完毕之后才会运行，用来合并或返回计算结果。 其内部类都比较简单，ExceptionNode 是用于存储任务执行期间的异常信息的单向链表；其余四个类是为 Runnable&#x2F;Callable 任务提供的适配器类，用于把 Runnable&#x2F;Callable 转化为 ForkJoinTask 类型的任务(因为 ForkJoinPool 只可以运行 ForkJoinTask 类型的任务)。 Fork&#x2F;Join框架源码解析 分析思路: 在对类层次结构有了解以后，我们先看下内部核心参数，然后分析上述流程图。会分4个部分: 首先介绍任务的提交流程 - 外部任务(external&#x2F;submissions task)提交 然后介绍任务的提交流程 - 子任务(Worker task)提交 再分析任务的执行过程(ForkJoinWorkerThread.run()到ForkJoinTask.doExec()这一部分)； 最后介绍任务的结果获取(ForkJoinTask.join()和ForkJoinTask.invoke()) ForkJoinPool核心参数在后面的源码解析中，我们会看到大量的位运算，这些位运算都是通过我们接下来介绍的一些常量参数来计算的。 例如，如果要更新活跃线程数，使用公式(UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; c)；c 代表当前 ctl，UC_MASK 和 SP_MASK 分别是高位和低位掩码，AC_UNIT 为活跃线程的增量数，使用(UC_MASK &amp; (c + AC_UNIT))就可以计算出高32位，然后再加上低32位(SP_MASK &amp; c)，就拼接成了一个新的ctl。 这些运算的可读性很差，看起来有些复杂。在后面源码解析中有位运算的地方我都会加上注释，大家只需要了解它们的作用即可。 ForkJoinPool 与 内部类 WorkQueue 共享的一些常量: 123456789101112131415161718// Constants shared across ForkJoinPool and WorkQueue// 限定参数static final int SMASK = 0xffff; // 低位掩码，也是最大索引位static final int MAX_CAP = 0x7fff; // 工作线程最大容量static final int EVENMASK = 0xfffe; // 偶数低位掩码static final int SQMASK = 0x007e; // workQueues 数组最多64个槽位// ctl 子域和 WorkQueue.scanState 的掩码和标志位static final int SCANNING = 1; // 标记是否正在运行任务static final int INACTIVE = 1 &lt;&lt; 31; // 失活状态 负数static final int SS_SEQ = 1 &lt;&lt; 16; // 版本戳，防止ABA问题// ForkJoinPool.config 和 WorkQueue.config 的配置信息标记static final int MODE_MASK = 0xffff &lt;&lt; 16; // 模式掩码static final int LIFO_QUEUE = 0; //LIFO队列static final int FIFO_QUEUE = 1 &lt;&lt; 16;//FIFO队列static final int SHARED_QUEUE = 1 &lt;&lt; 31; // 共享模式队列，负数 ForkJoinPool 中的相关常量和实例字段: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// 低位和高位掩码private static final long SP_MASK = 0xffffffffL;private static final long UC_MASK = ~SP_MASK;// 活跃线程数private static final int AC_SHIFT = 48;private static final long AC_UNIT = 0x0001L &lt;&lt; AC_SHIFT; //活跃线程数增量private static final long AC_MASK = 0xffffL &lt;&lt; AC_SHIFT; //活跃线程数掩码// 工作线程数private static final int TC_SHIFT = 32;private static final long TC_UNIT = 0x0001L &lt;&lt; TC_SHIFT; //工作线程数增量private static final long TC_MASK = 0xffffL &lt;&lt; TC_SHIFT; //掩码private static final long ADD_WORKER = 0x0001L &lt;&lt; (TC_SHIFT + 15); // 创建工作线程标志// 池状态private static final int RSLOCK = 1;private static final int RSIGNAL = 1 &lt;&lt; 1;private static final int STARTED = 1 &lt;&lt; 2;private static final int STOP = 1 &lt;&lt; 29;private static final int TERMINATED = 1 &lt;&lt; 30;private static final int SHUTDOWN = 1 &lt;&lt; 31;// 实例字段volatile long ctl; // 主控制参数volatile int runState; // 运行状态锁final int config; // 并行度|模式int indexSeed; // 用于生成工作线程索引volatile WorkQueue[] workQueues; // 主对象注册信息，workQueuefinal ForkJoinWorkerThreadFactory factory;// 线程工厂final UncaughtExceptionHandler ueh; // 每个工作线程的异常信息final String workerNamePrefix; // 用于创建工作线程的名称volatile AtomicLong stealCounter; // 偷取任务总数，也可作为同步监视器/** 静态初始化字段 *///线程工厂public static final ForkJoinWorkerThreadFactory defaultForkJoinWorkerThreadFactory;//启动或杀死线程的方法调用者的权限private static final RuntimePermission modifyThreadPermission;// 公共静态poolstatic final ForkJoinPool common;//并行度，对应内部common池static final int commonParallelism;//备用线程数，在tryCompensate中使用private static int commonMaxSpares;//创建workerNamePrefix(工作线程名称前缀)时的序号private static int poolNumberSequence;//线程阻塞等待新的任务的超时值(以纳秒为单位)，默认2秒private static final long IDLE_TIMEOUT = 2000L * 1000L * 1000L; // 2sec//空闲超时时间，防止timer未命中private static final long TIMEOUT_SLOP = 20L * 1000L * 1000L; // 20ms//默认备用线程数private static final int DEFAULT_COMMON_MAX_SPARES = 256;//阻塞前自旋的次数，用在在awaitRunStateLock和awaitWork中private static final int SPINS = 0;//indexSeed的增量private static final int SEED_INCREMENT = 0x9e3779b9; 说明: ForkJoinPool 的内部状态都是通过一个64位的 long 型 变量ctl来存储，它由四个16位的子域组成: AC: 正在运行工作线程数减去目标并行度，高16位 TC: 总工作线程数减去目标并行度，中高16位 SS: 栈顶等待线程的版本计数和状态，中低16位 ID: 栈顶 WorkQueue 在池中的索引(poolIndex)，低16位 在后面的源码解析中，某些地方也提取了ctl的低32位(sp&#x3D;(int)ctl)来检查工作线程状态，例如，当sp不为0时说明当前还有空闲工作线程。 ForkJoinPool.WorkQueue 中的相关属性:1234567891011121314151617181920//初始队列容量，2的幂static final int INITIAL_QUEUE_CAPACITY = 1 &lt;&lt; 13;//最大队列容量static final int MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 26; // 64M// 实例字段volatile int scanState; // Woker状态, &lt;0: inactive; odd:scanningint stackPred; // 记录前一个栈顶的ctlint nsteals; // 偷取任务数int hint; // 记录偷取者索引，初始为随机索引int config; // 池索引和模式volatile int qlock; // 1: locked, &lt; 0: terminate; else 0volatile int base; //下一个poll操作的索引(栈底/队列头)int top; // 下一个push操作的索引(栈顶/队列尾)ForkJoinTask&lt;?&gt;[] array; // 任务数组final ForkJoinPool pool; // the containing pool (may be null)final ForkJoinWorkerThread owner; // 当前工作队列的工作线程，共享模式下为nullvolatile Thread parker; // 调用park阻塞期间为owner，其他情况为nullvolatile ForkJoinTask&lt;?&gt; currentJoin; // 记录被join过来的任务volatile ForkJoinTask&lt;?&gt; currentSteal; // 记录从其他工作队列偷取过来的任务 ForkJoinTask核心参数12345678/** 任务运行状态 */volatile int status; // 任务运行状态static final int DONE_MASK = 0xf0000000; // 任务完成状态标志位static final int NORMAL = 0xf0000000; // must be negativestatic final int CANCELLED = 0xc0000000; // must be &lt; NORMALstatic final int EXCEPTIONAL = 0x80000000; // must be &lt; CANCELLEDstatic final int SIGNAL = 0x00010000; // must be &gt;= 1 &lt;&lt; 16 等待信号static final int SMASK = 0x0000ffff; // 低位掩码 Fork&#x2F;Join框架源码解析构造函数1234567891011public ForkJoinPool(int parallelism, ForkJoinWorkerThreadFactory factory, UncaughtExceptionHandler handler, boolean asyncMode) &#123; this(checkParallelism(parallelism), checkFactory(factory), handler, asyncMode ? FIFO_QUEUE : LIFO_QUEUE, &quot;ForkJoinPool-&quot; + nextPoolId() + &quot;-worker-&quot;); checkPermission();&#125; 说明: 在 ForkJoinPool 中我们可以自定义四个参数: parallelism: 并行度，默认为CPU数，最小为1 factory: 工作线程工厂； handler: 处理工作线程运行任务时的异常情况类，默认为null； asyncMode: 是否为异步模式，默认为 false。如果为true，表示子任务的执行遵循 FIFO 顺序并且任务不能被合并(join)，这种模式适用于工作线程只运行事件类型的异步任务。 在多数场景使用时，如果没有太强的业务需求，我们一般直接使用 ForkJoinPool 中的common池，在JDK1.8之后提供了ForkJoinPool.commonPool()方法可以直接使用common池，来看一下它的构造: 1234567891011121314151617181920212223242526272829303132333435private static ForkJoinPool makeCommonPool() &#123; int parallelism = -1; ForkJoinWorkerThreadFactory factory = null; UncaughtExceptionHandler handler = null; try &#123; // ignore exceptions in accessing/parsing String pp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.parallelism&quot;);//并行度 String fp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.threadFactory&quot;);//线程工厂 String hp = System.getProperty (&quot;java.util.concurrent.ForkJoinPool.common.exceptionHandler&quot;);//异常处理类 if (pp != null) parallelism = Integer.parseInt(pp); if (fp != null) factory = ((ForkJoinWorkerThreadFactory) ClassLoader. getSystemClassLoader().loadClass(fp).newInstance()); if (hp != null) handler = ((UncaughtExceptionHandler) ClassLoader. getSystemClassLoader().loadClass(hp).newInstance()); &#125; catch (Exception ignore) &#123; &#125; if (factory == null) &#123; if (System.getSecurityManager() == null) factory = defaultForkJoinWorkerThreadFactory; else // use security-managed default factory = new InnocuousForkJoinWorkerThreadFactory(); &#125; if (parallelism &lt; 0 &amp;&amp; // default 1 less than #cores (parallelism = Runtime.getRuntime().availableProcessors() - 1) &lt;= 0) parallelism = 1;//默认并行度为1 if (parallelism &gt; MAX_CAP) parallelism = MAX_CAP; return new ForkJoinPool(parallelism, factory, handler, LIFO_QUEUE, &quot;ForkJoinPool.commonPool-worker-&quot;);&#125; 使用common pool的优点就是我们可以通过指定系统参数的方式定义“并行度、线程工厂和异常处理类”；并且它使用的是同步模式，也就是说可以支持任务合并(join)。 执行流程 - 外部任务(external&#x2F;submissions task)提交向 ForkJoinPool 提交任务有三种方式: invoke()会等待任务计算完毕并返回计算结果； execute()是直接向池提交一个任务来异步执行，无返回结果； submit()也是异步执行，但是会返回提交的任务，在适当的时候可通过task.get()获取执行结果。 这三种提交方式都都是调用externalPush()方法来完成，所以接下来我们将从externalPush()方法开始逐步分析外部任务的执行过程。 externalPush(ForkJoinTask&lt;?&gt; task)1234567891011121314151617181920212223242526//添加给定任务到submission队列中final void externalPush(ForkJoinTask&lt;?&gt; task) &#123; WorkQueue[] ws; WorkQueue q; int m; int r = ThreadLocalRandom.getProbe();//探针值，用于计算WorkQueue槽位索引 int rs = runState; if ((ws = workQueues) != null &amp;&amp; (m = (ws.length - 1)) &gt;= 0 &amp;&amp; (q = ws[m &amp; r &amp; SQMASK]) != null &amp;&amp; r != 0 &amp;&amp; rs &gt; 0 &amp;&amp; //获取随机偶数槽位的workQueue U.compareAndSwapInt(q, QLOCK, 0, 1)) &#123;//锁定workQueue ForkJoinTask&lt;?&gt;[] a; int am, n, s; if ((a = q.array) != null &amp;&amp; (am = a.length - 1) &gt; (n = (s = q.top) - q.base)) &#123; int j = ((am &amp; s) &lt;&lt; ASHIFT) + ABASE;//计算任务索引位置 U.putOrderedObject(a, j, task);//任务入列 U.putOrderedInt(q, QTOP, s + 1);//更新push slot U.putIntVolatile(q, QLOCK, 0);//解除锁定 if (n &lt;= 1) signalWork(ws, q);//任务数小于1时尝试创建或激活一个工作线程 return; &#125; U.compareAndSwapInt(q, QLOCK, 1, 0);//解除锁定 &#125; externalSubmit(task);//初始化workQueues及相关属性&#125; 首先说明一下externalPush和externalSubmit两个方法的联系: 它们的作用都是把任务放到队列中等待执行。不同的是，externalSubmit可以说是完整版的externalPush，在任务首次提交时，需要初始化workQueues及其他相关属性，这个初始化操作就是externalSubmit来完成的；而后再向池中提交的任务都是通过简化版的externalSubmit-externalPush来完成。 externalPush的执行流程很简单: 首先找到一个随机偶数槽位的 workQueue，然后把任务放入这个 workQueue 的任务数组中，并更新top位。如果队列的剩余任务数小于1，则尝试创建或激活一个工作线程来运行任务(防止在externalSubmit初始化时发生异常导致工作线程创建失败)。 externalSubmit(ForkJoinTask&lt;?&gt; task)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//任务提交private void externalSubmit(ForkJoinTask&lt;?&gt; task) &#123; //初始化调用线程的探针值，用于计算WorkQueue索引 int r; // initialize caller&#x27;s probe if ((r = ThreadLocalRandom.getProbe()) == 0) &#123; ThreadLocalRandom.localInit(); r = ThreadLocalRandom.getProbe(); &#125; for (; ; ) &#123; WorkQueue[] ws; WorkQueue q; int rs, m, k; boolean move = false; if ((rs = runState) &lt; 0) &#123;// 池已关闭 tryTerminate(false, false); // help terminate throw new RejectedExecutionException(); &#125; //初始化workQueues else if ((rs &amp; STARTED) == 0 || // initialize ((ws = workQueues) == null || (m = ws.length - 1) &lt; 0)) &#123; int ns = 0; rs = lockRunState();//锁定runState try &#123; //初始化 if ((rs &amp; STARTED) == 0) &#123; //初始化stealCounter U.compareAndSwapObject(this, STEALCOUNTER, null, new AtomicLong()); //创建workQueues，容量为2的幂次方 // create workQueues array with size a power of two int p = config &amp; SMASK; // ensure at least 2 slots int n = (p &gt; 1) ? p - 1 : 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; n = (n + 1) &lt;&lt; 1; workQueues = new WorkQueue[n]; ns = STARTED; &#125; &#125; finally &#123; unlockRunState(rs, (rs &amp; ~RSLOCK) | ns);//解锁并更新runState &#125; &#125; else if ((q = ws[k = r &amp; m &amp; SQMASK]) != null) &#123;//获取随机偶数槽位的workQueue if (q.qlock == 0 &amp;&amp; U.compareAndSwapInt(q, QLOCK, 0, 1)) &#123;//锁定 workQueue ForkJoinTask&lt;?&gt;[] a = q.array;//当前workQueue的全部任务 int s = q.top; boolean submitted = false; // initial submission or resizing try &#123; // locked version of push if ((a != null &amp;&amp; a.length &gt; s + 1 - q.base) || (a = q.growArray()) != null) &#123;//扩容 int j = (((a.length - 1) &amp; s) &lt;&lt; ASHIFT) + ABASE; U.putOrderedObject(a, j, task);//放入给定任务 U.putOrderedInt(q, QTOP, s + 1);//修改push slot submitted = true; &#125; &#125; finally &#123; U.compareAndSwapInt(q, QLOCK, 1, 0);//解除锁定 &#125; if (submitted) &#123;//任务提交成功，创建或激活工作线程 signalWork(ws, q);//创建或激活一个工作线程来运行任务 return; &#125; &#125; move = true; // move on failure 操作失败，重新获取探针值 &#125; else if (((rs = runState) &amp; RSLOCK) == 0) &#123; // create new queue q = new WorkQueue(this, null); q.hint = r; q.config = k | SHARED_QUEUE; q.scanState = INACTIVE; rs = lockRunState(); // publish index if (rs &gt; 0 &amp;&amp; (ws = workQueues) != null &amp;&amp; k &lt; ws.length &amp;&amp; ws[k] == null) ws[k] = q; // 更新索引k位值的workQueue //else terminated unlockRunState(rs, rs &amp; ~RSLOCK); &#125; else move = true; // move if busy if (move) r = ThreadLocalRandom.advanceProbe(r);//重新获取线程探针值 &#125;&#125; 说明: externalSubmit是externalPush的完整版本，主要用于第一次提交任务时初始化workQueues及相关属性，并且提交给定任务到队列中。具体执行步骤如下: 如果池为终止状态(runState&lt;0)，调用tryTerminate来终止线程池，并抛出任务拒绝异常； 如果尚未初始化，就为 FJP 执行初始化操作: 初始化stealCounter、创建workerQueues，然后继续自旋； 初始化完成后，执行在externalPush中相同的操作: 获取 workQueue，放入指定任务。任务提交成功后调用signalWork方法创建或激活线程； 如果在步骤3中获取到的 workQueue 为null，会在这一步中创建一个 workQueue，创建成功继续自旋执行第三步操作； 如果非上述情况，或者有线程争用资源导致获取锁失败，就重新获取线程探针值继续自旋。 signalWork(WorkQueue[] ws, WorkQueue q)1234567891011121314151617181920212223242526272829303132final void signalWork(WorkQueue[] ws, WorkQueue q) &#123; long c; int sp, i; WorkQueue v; Thread p; while ((c = ctl) &lt; 0L) &#123; // too few active if ((sp = (int) c) == 0) &#123; // no idle workers if ((c &amp; ADD_WORKER) != 0L) // too few workers tryAddWorker(c);//工作线程太少，添加新的工作线程 break; &#125; if (ws == null) // unstarted/terminated break; if (ws.length &lt;= (i = sp &amp; SMASK)) // terminated break; if ((v = ws[i]) == null) // terminating break; //计算ctl，加上版本戳SS_SEQ避免ABA问题 int vs = (sp + SS_SEQ) &amp; ~INACTIVE; // next scanState int d = sp - v.scanState; // screen CAS //计算活跃线程数(高32位)并更新为下一个栈顶的scanState(低32位) long nc = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; v.stackPred); if (d == 0 &amp;&amp; U.compareAndSwapLong(this, CTL, c, nc)) &#123; v.scanState = vs; // activate v if ((p = v.parker) != null) U.unpark(p);//唤醒阻塞线程 break; &#125; if (q != null &amp;&amp; q.base == q.top) // no more work break; &#125;&#125; 说明: 新建或唤醒一个工作线程，在externalPush、externalSubmit、workQueue.push、scan中调用。如果还有空闲线程，则尝试唤醒索引到的 WorkQueue 的parker线程；如果工作线程过少((ctl &amp; ADD_WORKER) !&#x3D; 0L)，则调用tryAddWorker添加一个新的工作线程。 tryAddWorker(long c)12345678910111213141516171819private void tryAddWorker(long c) &#123; boolean add = false; do &#123; long nc = ((AC_MASK &amp; (c + AC_UNIT)) | (TC_MASK &amp; (c + TC_UNIT))); if (ctl == c) &#123; int rs, stop; // check if terminating if ((stop = (rs = lockRunState()) &amp; STOP) == 0) add = U.compareAndSwapLong(this, CTL, c, nc); unlockRunState(rs, rs &amp; ~RSLOCK);//释放锁 if (stop != 0) break; if (add) &#123; createWorker();//创建工作线程 break; &#125; &#125; &#125; while (((c = ctl) &amp; ADD_WORKER) != 0L &amp;&amp; (int)c == 0);&#125; 说明: 尝试添加一个新的工作线程，首先更新ctl中的工作线程数，然后调用createWorker()创建工作线程。 createWorker()123456789101112131415private boolean createWorker() &#123; ForkJoinWorkerThreadFactory fac = factory; Throwable ex = null; ForkJoinWorkerThread wt = null; try &#123; if (fac != null &amp;&amp; (wt = fac.newThread(this)) != null) &#123; wt.start(); return true; &#125; &#125; catch (Throwable rex) &#123; ex = rex; &#125; deregisterWorker(wt, ex);//线程创建失败处理 return false;&#125; 说明: createWorker首先通过线程工厂创一个新的ForkJoinWorkerThread，然后启动这个工作线程(wt.start())。如果期间发生异常，调用deregisterWorker处理线程创建失败的逻辑(deregisterWorker在后面再详细说明)。 ForkJoinWorkerThread 的构造函数如下: 123456protected ForkJoinWorkerThread(ForkJoinPool pool) &#123; // Use a placeholder until a useful name can be set in registerWorker super(&quot;aForkJoinWorkerThread&quot;); this.pool = pool; this.workQueue = pool.registerWorker(this);&#125; 可以看到 ForkJoinWorkerThread 在构造时首先调用父类 Thread 的方法，然后为工作线程注册pool和workQueue，而workQueue的注册任务由ForkJoinPool.registerWorker来完成。 registerWorker()1234567891011121314151617181920212223242526272829303132333435363738394041final WorkQueue registerWorker(ForkJoinWorkerThread wt) &#123; UncaughtExceptionHandler handler; //设置为守护线程 wt.setDaemon(true); // configure thread if ((handler = ueh) != null) wt.setUncaughtExceptionHandler(handler); WorkQueue w = new WorkQueue(this, wt);//构造新的WorkQueue int i = 0; // assign a pool index int mode = config &amp; MODE_MASK; int rs = lockRunState(); try &#123; WorkQueue[] ws; int n; // skip if no array if ((ws = workQueues) != null &amp;&amp; (n = ws.length) &gt; 0) &#123; //生成新建WorkQueue的索引 int s = indexSeed += SEED_INCREMENT; // unlikely to collide int m = n - 1; i = ((s &lt;&lt; 1) | 1) &amp; m; // Worker任务放在奇数索引位 odd-numbered indices if (ws[i] != null) &#123; // collision 已存在，重新计算索引位 int probes = 0; // step by approx half n int step = (n &lt;= 4) ? 2 : ((n &gt;&gt;&gt; 1) &amp; EVENMASK) + 2; //查找可用的索引位 while (ws[i = (i + step) &amp; m] != null) &#123; if (++probes &gt;= n) &#123;//所有索引位都被占用，对workQueues进行扩容 workQueues = ws = Arrays.copyOf(ws, n &lt;&lt;= 1);//workQueues 扩容 m = n - 1; probes = 0; &#125; &#125; &#125; w.hint = s; // use as random seed w.config = i | mode; w.scanState = i; // publication fence ws[i] = w; &#125; &#125; finally &#123; unlockRunState(rs, rs &amp; ~RSLOCK); &#125; wt.setName(workerNamePrefix.concat(Integer.toString(i &gt;&gt;&gt; 1))); return w;&#125; 说明: registerWorker是 ForkJoinWorkerThread 构造器的回调函数，用于创建和记录工作线程的 WorkQueue。比较简单，就不多赘述了。注意在此为工作线程创建的 WorkQueue 是放在奇数索引的(代码行: i &#x3D; ((s &lt;&lt; 1) | 1) &amp; m;) 小结OK，外部任务的提交流程就先讲到这里。在createWorker()中启动工作线程后(wt.start())，当为线程分配到CPU执行时间片之后会运行 ForkJoinWorkerThread 的run方法开启线程来执行任务。工作线程执行任务的流程我们在讲完内部任务提交之后会统一讲解。 执行流程: 子任务(Worker task)提交子任务的提交相对比较简单，由任务的fork()方法完成。通过上面的流程图可以看到任务被分割(fork)之后调用了ForkJoinPool.WorkQueue.push()方法直接把任务放到队列中等待被执行。 ForkJoinTask.fork()12345678public final ForkJoinTask&lt;V&gt; fork() &#123; Thread t; if ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ((ForkJoinWorkerThread)t).workQueue.push(this); else ForkJoinPool.common.externalPush(this); return this;&#125; 说明: 如果当前线程是 Worker 线程，说明当前任务是fork分割的子任务，通过ForkJoinPool.workQueue.push()方法直接把任务放到自己的等待队列中；否则调用ForkJoinPool.externalPush()提交到一个随机的等待队列中(外部任务)。 ForkJoinPool.WorkQueue.push()123456789101112131415final void push(ForkJoinTask&lt;?&gt; task) &#123; ForkJoinTask&lt;?&gt;[] a; ForkJoinPool p; int b = base, s = top, n; if ((a = array) != null) &#123; // ignore if queue removed int m = a.length - 1; // fenced write for task visibility U.putOrderedObject(a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, task); U.putOrderedInt(this, QTOP, s + 1); if ((n = s - b) &lt;= 1) &#123;//首次提交，创建或唤醒一个工作线程 if ((p = pool) != null) p.signalWork(p.workQueues, this); &#125; else if (n &gt;= m) growArray(); &#125;&#125; 说明: 首先把任务放入等待队列并更新top位；如果当前 WorkQueue 为新建的等待队列(top-base&lt;&#x3D;1)，则调用signalWork方法为当前 WorkQueue 新建或唤醒一个工作线程；如果 WorkQueue 中的任务数组容量过小，则调用growArray()方法对其进行两倍扩容，growArray()方法源码如下: 123456789101112131415161718192021222324final ForkJoinTask&lt;?&gt;[] growArray() &#123; ForkJoinTask&lt;?&gt;[] oldA = array;//获取内部任务列表 int size = oldA != null ? oldA.length &lt;&lt; 1 : INITIAL_QUEUE_CAPACITY; if (size &gt; MAXIMUM_QUEUE_CAPACITY) throw new RejectedExecutionException(&quot;Queue capacity exceeded&quot;); int oldMask, t, b; //新建一个两倍容量的任务数组 ForkJoinTask&lt;?&gt;[] a = array = new ForkJoinTask&lt;?&gt;[size]; if (oldA != null &amp;&amp; (oldMask = oldA.length - 1) &gt;= 0 &amp;&amp; (t = top) - (b = base) &gt; 0) &#123; int mask = size - 1; //从老数组中拿出数据，放到新的数组中 do &#123; // emulate poll from old array, push to new array ForkJoinTask&lt;?&gt; x; int oldj = ((b &amp; oldMask) &lt;&lt; ASHIFT) + ABASE; int j = ((b &amp; mask) &lt;&lt; ASHIFT) + ABASE; x = (ForkJoinTask&lt;?&gt;) U.getObjectVolatile(oldA, oldj); if (x != null &amp;&amp; U.compareAndSwapObject(oldA, oldj, x, null)) U.putObjectVolatile(a, j, x); &#125; while (++b != t); &#125; return a;&#125; 小结到此，两种任务的提交流程都已经解析完毕，下一节我们来一起看看任务提交之后是如何被运行的。 执行流程: 任务执行回到我们开始时的流程图，在ForkJoinPool .createWorker()方法中创建工作线程后，会启动工作线程，系统为工作线程分配到CPU执行时间片之后会执行 ForkJoinWorkerThread 的run()方法正式开始执行任务。 ForkJoinWorkerThread.run()1234567891011121314151617181920public void run() &#123; if (workQueue.array == null) &#123; // only run once Throwable exception = null; try &#123; onStart();//钩子方法，可自定义扩展 pool.runWorker(workQueue); &#125; catch (Throwable ex) &#123; exception = ex; &#125; finally &#123; try &#123; onTermination(exception);//钩子方法，可自定义扩展 &#125; catch (Throwable ex) &#123; if (exception == null) exception = ex; &#125; finally &#123; pool.deregisterWorker(this, exception);//处理异常 &#125; &#125; &#125;&#125; 说明: 方法很简单，在工作线程运行前后会调用自定义钩子函数(onStart和onTermination)，任务的运行则是调用了ForkJoinPool.runWorker()。如果全部任务执行完毕或者期间遭遇异常，则通过ForkJoinPool.deregisterWorker关闭工作线程并处理异常信息(deregisterWorker方法我们后面会详细讲解)。 ForkJoinPool.runWorker(WorkQueue w)1234567891011121314final void runWorker(WorkQueue w) &#123; w.growArray(); // allocate queue int seed = w.hint; // initially holds randomization hint int r = (seed == 0) ? 1 : seed; // avoid 0 for xorShift for (ForkJoinTask&lt;?&gt; t; ; ) &#123; if ((t = scan(w, r)) != null)//扫描任务执行 w.runTask(t); else if (!awaitWork(w, r)) break; r ^= r &lt;&lt; 13; r ^= r &gt;&gt;&gt; 17; r ^= r &lt;&lt; 5; // xorshift &#125;&#125; 说明: runWorker是 ForkJoinWorkerThread 的主运行方法，用来依次执行当前工作线程中的任务。函数流程很简单: 调用scan方法依次获取任务，然后调用WorkQueue .runTask运行任务；如果未扫描到任务，则调用awaitWork等待，直到工作线程&#x2F;线程池终止或等待超时。 ForkJoinPool.scan(WorkQueue w, int r)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private ForkJoinTask&lt;?&gt; scan(WorkQueue w, int r) &#123; WorkQueue[] ws; int m; if ((ws = workQueues) != null &amp;&amp; (m = ws.length - 1) &gt; 0 &amp;&amp; w != null) &#123; int ss = w.scanState; // initially non-negative //初始扫描起点，自旋扫描 for (int origin = r &amp; m, k = origin, oldSum = 0, checkSum = 0; ; ) &#123; WorkQueue q; ForkJoinTask&lt;?&gt;[] a; ForkJoinTask&lt;?&gt; t; int b, n; long c; if ((q = ws[k]) != null) &#123;//获取workQueue if ((n = (b = q.base) - q.top) &lt; 0 &amp;&amp; (a = q.array) != null) &#123; // non-empty //计算偏移量 long i = (((a.length - 1) &amp; b) &lt;&lt; ASHIFT) + ABASE; if ((t = ((ForkJoinTask&lt;?&gt;) U.getObjectVolatile(a, i))) != null &amp;&amp; //取base位置任务 q.base == b) &#123;//stable if (ss &gt;= 0) &#123; //scanning if (U.compareAndSwapObject(a, i, t, null)) &#123;// q.base = b + 1;//更新base位 if (n &lt; -1) // signal others signalWork(ws, q);//创建或唤醒工作线程来运行任务 return t; &#125; &#125; else if (oldSum == 0 &amp;&amp; // try to activate 尝试激活工作线程 w.scanState &lt; 0) tryRelease(c = ctl, ws[m &amp; (int) c], AC_UNIT);//唤醒栈顶工作线程 &#125; //base位置任务为空或base位置偏移，随机移位重新扫描 if (ss &lt; 0) // refresh ss = w.scanState; r ^= r &lt;&lt; 1; r ^= r &gt;&gt;&gt; 3; r ^= r &lt;&lt; 10; origin = k = r &amp; m; // move and rescan oldSum = checkSum = 0; continue; &#125; checkSum += b;//队列任务为空，记录base位 &#125; //更新索引k 继续向后查找 if ((k = (k + 1) &amp; m) == origin) &#123; // continue until stable //运行到这里说明已经扫描了全部的 workQueues，但并未扫描到任务 if ((ss &gt;= 0 || (ss == (ss = w.scanState))) &amp;&amp; oldSum == (oldSum = checkSum)) &#123; if (ss &lt; 0 || w.qlock &lt; 0) // already inactive break;// 已经被灭活或终止,跳出循环 //对当前WorkQueue进行灭活操作 int ns = ss | INACTIVE; // try to inactivate long nc = ((SP_MASK &amp; ns) | (UC_MASK &amp; ((c = ctl) - AC_UNIT)));//计算ctl为INACTIVE状态并减少活跃线程数 w.stackPred = (int) c; // hold prev stack top U.putInt(w, QSCANSTATE, ns);//修改scanState为inactive状态 if (U.compareAndSwapLong(this, CTL, c, nc))//更新scanState为灭活状态 ss = ns; else w.scanState = ss; // back out &#125; checkSum = 0;//重置checkSum，继续循环 &#125; &#125; &#125; return null;&#125; 说明: 扫描并尝试偷取一个任务。使用w.hint进行随机索引 WorkQueue，也就是说并不一定会执行当前 WorkQueue 中的任务，而是偷取别的Worker的任务来执行。 函数的大概执行流程如下: 取随机位置的一个 WorkQueue； 获取base位的 ForkJoinTask，成功取到后更新base位并返回任务；如果取到的 WorkQueue 中任务数大于1，则调用signalWork创建或唤醒其他工作线程； 如果当前工作线程处于不活跃状态(INACTIVE)，则调用tryRelease尝试唤醒栈顶工作线程来执行。 tryRelease源码如下: 12345678910111213141516private boolean tryRelease(long c, WorkQueue v, long inc) &#123; int sp = (int) c, vs = (sp + SS_SEQ) &amp; ~INACTIVE; Thread p; //ctl低32位等于scanState，说明可以唤醒parker线程 if (v != null &amp;&amp; v.scanState == sp) &#123; // v is at top of stack //计算活跃线程数(高32位)并更新为下一个栈顶的scanState(低32位) long nc = (UC_MASK &amp; (c + inc)) | (SP_MASK &amp; v.stackPred); if (U.compareAndSwapLong(this, CTL, c, nc)) &#123; v.scanState = vs; if ((p = v.parker) != null) U.unpark(p);//唤醒线程 return true; &#125; &#125; return false;&#125; 如果base位任务为空或发生偏移，则对索引位进行随机移位，然后重新扫描； 如果扫描整个workQueues之后没有获取到任务，则设置当前工作线程为INACTIVE状态；然后重置checkSum，再次扫描一圈之后如果还没有任务则跳出循环返回null。 ForkJoinPool.awaitWork(WorkQueue w, int r)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758private boolean awaitWork(WorkQueue w, int r) &#123; if (w == null || w.qlock &lt; 0) // w is terminating return false; for (int pred = w.stackPred, spins = SPINS, ss; ; ) &#123; if ((ss = w.scanState) &gt;= 0)//正在扫描，跳出循环 break; else if (spins &gt; 0) &#123; r ^= r &lt;&lt; 6; r ^= r &gt;&gt;&gt; 21; r ^= r &lt;&lt; 7; if (r &gt;= 0 &amp;&amp; --spins == 0) &#123; // randomize spins WorkQueue v; WorkQueue[] ws; int s, j; AtomicLong sc; if (pred != 0 &amp;&amp; (ws = workQueues) != null &amp;&amp; (j = pred &amp; SMASK) &lt; ws.length &amp;&amp; (v = ws[j]) != null &amp;&amp; // see if pred parking (v.parker == null || v.scanState &gt;= 0)) spins = SPINS; // continue spinning &#125; &#125; else if (w.qlock &lt; 0) // 当前workQueue已经终止，返回false recheck after spins return false; else if (!Thread.interrupted()) &#123;//判断线程是否被中断，并清除中断状态 long c, prevctl, parkTime, deadline; int ac = (int) ((c = ctl) &gt;&gt; AC_SHIFT) + (config &amp; SMASK);//活跃线程数 if ((ac &lt;= 0 &amp;&amp; tryTerminate(false, false)) || //无active线程，尝试终止 (runState &amp; STOP) != 0) // pool terminating return false; if (ac &lt;= 0 &amp;&amp; ss == (int) c) &#123; // is last waiter //计算活跃线程数(高32位)并更新为下一个栈顶的scanState(低32位) prevctl = (UC_MASK &amp; (c + AC_UNIT)) | (SP_MASK &amp; pred); int t = (short) (c &gt;&gt;&gt; TC_SHIFT); // shrink excess spares if (t &gt; 2 &amp;&amp; U.compareAndSwapLong(this, CTL, c, prevctl))//总线程过量 return false; // else use timed wait //计算空闲超时时间 parkTime = IDLE_TIMEOUT * ((t &gt;= 0) ? 1 : 1 - t); deadline = System.nanoTime() + parkTime - TIMEOUT_SLOP; &#125; else prevctl = parkTime = deadline = 0L; Thread wt = Thread.currentThread(); U.putObject(wt, PARKBLOCKER, this); // emulate LockSupport w.parker = wt;//设置parker，准备阻塞 if (w.scanState &lt; 0 &amp;&amp; ctl == c) // recheck before park U.park(false, parkTime);//阻塞指定的时间 U.putOrderedObject(w, QPARKER, null); U.putObject(wt, PARKBLOCKER, null); if (w.scanState &gt;= 0)//正在扫描，说明等到任务，跳出循环 break; if (parkTime != 0L &amp;&amp; ctl == c &amp;&amp; deadline - System.nanoTime() &lt;= 0L &amp;&amp; U.compareAndSwapLong(this, CTL, c, prevctl))//未等到任务，更新ctl，返回false return false; // shrink pool &#125; &#125; return true;&#125; 说明: 回到runWorker方法，如果scan方法未扫描到任务，会调用awaitWork等待获取任务。函数的具体执行流程大家看源码，这里简单说一下: 在等待获取任务期间，如果工作线程或线程池已经终止则直接返回false。如果当前无 active 线程，尝试终止线程池并返回false，如果终止失败并且当前是最后一个等待的 Worker，就阻塞指定的时间(IDLE_TIMEOUT)；等到届期或被唤醒后如果发现自己是scanning(scanState &gt;&#x3D; 0)状态，说明已经等到任务，跳出等待返回true继续 scan，否则的更新ctl并返回false。 WorkQueue.runTask()1234567891011121314final void runTask(ForkJoinTask&lt;?&gt; task) &#123; if (task != null) &#123; scanState &amp;= ~SCANNING; // mark as busy (currentSteal = task).doExec();//更新currentSteal并执行任务 U.putOrderedObject(this, QCURRENTSTEAL, null); // release for GC execLocalTasks();//依次执行本地任务 ForkJoinWorkerThread thread = owner; if (++nsteals &lt; 0) // collect on overflow transferStealCount(pool);//增加偷取任务数 scanState |= SCANNING; if (thread != null) thread.afterTopLevelExec();//执行钩子函数 &#125;&#125; 说明: 在scan方法扫描到任务之后，调用WorkQueue.runTask()来执行获取到的任务，大概流程如下: 标记scanState为正在执行状态； 更新currentSteal为当前获取到的任务并执行它，任务的执行调用了ForkJoinTask.doExec()方法，源码如下: 1234567891011121314//ForkJoinTask.doExec()final int doExec() &#123; int s; boolean completed; if ((s = status) &gt;= 0) &#123; try &#123; completed = exec();//执行我们定义的任务 &#125; catch (Throwable rex) &#123; return setExceptionalCompletion(rex); &#125; if (completed) s = setCompletion(NORMAL); &#125; return s;&#125; 调用execLocalTasks依次执行当前WorkerQueue中的任务，源码如下: 1234567891011121314151617181920//执行并移除所有本地任务final void execLocalTasks() &#123; int b = base, m, s; ForkJoinTask&lt;?&gt;[] a = array; if (b - (s = top - 1) &lt;= 0 &amp;&amp; a != null &amp;&amp; (m = a.length - 1) &gt;= 0) &#123; if ((config &amp; FIFO_QUEUE) == 0) &#123;//FIFO模式 for (ForkJoinTask&lt;?&gt; t; ; ) &#123; if ((t = (ForkJoinTask&lt;?&gt;) U.getAndSetObject (a, ((m &amp; s) &lt;&lt; ASHIFT) + ABASE, null)) == null)//FIFO执行，取top任务 break; U.putOrderedInt(this, QTOP, s); t.doExec();//执行 if (base - (s = top - 1) &gt; 0) break; &#125; &#125; else pollAndExecAll();//LIFO模式执行，取base任务 &#125;&#125; 更新偷取任务数； 还原scanState并执行钩子函数。 ForkJoinPool.deregisterWorker(ForkJoinWorkerThread wt, Throwable ex)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950final void deregisterWorker(ForkJoinWorkerThread wt, Throwable ex) &#123; WorkQueue w = null; //1.移除workQueue if (wt != null &amp;&amp; (w = wt.workQueue) != null) &#123;//获取ForkJoinWorkerThread的等待队列 WorkQueue[] ws; // remove index from array int idx = w.config &amp; SMASK;//计算workQueue索引 int rs = lockRunState();//获取runState锁和当前池运行状态 if ((ws = workQueues) != null &amp;&amp; ws.length &gt; idx &amp;&amp; ws[idx] == w) ws[idx] = null;//移除workQueue unlockRunState(rs, rs &amp; ~RSLOCK);//解除runState锁 &#125; //2.减少CTL数 long c; // decrement counts do &#123;&#125; while (!U.compareAndSwapLong (this, CTL, c = ctl, ((AC_MASK &amp; (c - AC_UNIT)) | (TC_MASK &amp; (c - TC_UNIT)) | (SP_MASK &amp; c)))); //3.处理被移除workQueue内部相关参数 if (w != null) &#123; w.qlock = -1; // ensure set w.transferStealCount(this); w.cancelAll(); // cancel remaining tasks &#125; //4.如果线程未终止，替换被移除的workQueue并唤醒内部线程 for (;;) &#123; // possibly replace WorkQueue[] ws; int m, sp; //尝试终止线程池 if (tryTerminate(false, false) || w == null || w.array == null || (runState &amp; STOP) != 0 || (ws = workQueues) == null || (m = ws.length - 1) &lt; 0) // already terminating break; //唤醒被替换的线程，依赖于下一步 if ((sp = (int)(c = ctl)) != 0) &#123; // wake up replacement if (tryRelease(c, ws[sp &amp; m], AC_UNIT)) break; &#125; //创建工作线程替换 else if (ex != null &amp;&amp; (c &amp; ADD_WORKER) != 0L) &#123; tryAddWorker(c); // create replacement break; &#125; else // don&#x27;t need replacement break; &#125; //5.处理异常 if (ex == null) // help clean on way out ForkJoinTask.helpExpungeStaleExceptions(); else // rethrow ForkJoinTask.rethrow(ex);&#125; 说明: deregisterWorker方法用于工作线程运行完毕之后终止线程或处理工作线程异常，主要就是清除已关闭的工作线程或回滚创建线程之前的操作，并把传入的异常抛给 ForkJoinTask 来处理。具体步骤见源码注释。 小结本节我们对任务的执行流程进行了说明，后面我们将继续介绍任务的结果获取(join&#x2F;invoke)。 获取任务结果 - ForkJoinTask.join() &#x2F; ForkJoinTask.invoke() join() : 123456789101112131415161718//合并任务结果public final V join() &#123; int s; if ((s = doJoin() &amp; DONE_MASK) != NORMAL) reportException(s); return getRawResult();&#125;//join, get, quietlyJoin的主实现方法private int doJoin() &#123; int s; Thread t; ForkJoinWorkerThread wt; ForkJoinPool.WorkQueue w; return (s = status) &lt; 0 ? s : ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ? (w = (wt = (ForkJoinWorkerThread)t).workQueue). tryUnpush(this) &amp;&amp; (s = doExec()) &lt; 0 ? s : wt.pool.awaitJoin(w, this, 0L) : externalAwaitDone();&#125; invoke() : 1234567891011121314151617//执行任务，并等待任务完成并返回结果public final V invoke() &#123; int s; if ((s = doInvoke() &amp; DONE_MASK) != NORMAL) reportException(s); return getRawResult();&#125;//invoke, quietlyInvoke的主实现方法private int doInvoke() &#123; int s; Thread t; ForkJoinWorkerThread wt; return (s = doExec()) &lt; 0 ? s : ((t = Thread.currentThread()) instanceof ForkJoinWorkerThread) ? (wt = (ForkJoinWorkerThread)t).pool. awaitJoin(wt.workQueue, this, 0L) : externalAwaitDone();&#125; 说明: join()方法一把是在任务fork()之后调用，用来获取(或者叫“合并”)任务的执行结果。 ForkJoinTask的join()和invoke()方法都可以用来获取任务的执行结果(另外还有get方法也是调用了doJoin来获取任务结果，但是会响应运行时异常)，它们对外部提交任务的执行方式一致，都是通过externalAwaitDone方法等待执行结果。不同的是invoke()方法会直接执行当前任务；而join()方法则是在当前任务在队列 top 位时(通过tryUnpush方法判断)才能执行，如果当前任务不在 top 位或者任务执行失败调用ForkJoinPool.awaitJoin方法帮助执行或阻塞当前 join 任务。(所以在官方文档中建议了我们对ForkJoinTask任务的调用顺序，一对 fork-join操作一般按照如下顺序调用: a.fork(); b.fork(); b.join(); a.join();。因为任务 b 是后面进入队列，也就是说它是在栈顶的(top 位)，在它fork()之后直接调用join()就可以直接执行而不会调用ForkJoinPool.awaitJoin方法去等待。) 在这些方法中，join()相对比较全面，所以之后的讲解我们将从join()开始逐步向下分析，首先看一下join()的执行流程: 后面的源码分析中，我们首先讲解比较简单的外部 join 任务(externalAwaitDone)，然后再讲解内部 join 任务(从ForkJoinPool.awaitJoin()开始)。 ForkJoinTask.externalAwaitDone()12345678910111213141516171819202122232425262728private int externalAwaitDone() &#123; //执行任务 int s = ((this instanceof CountedCompleter) ? // try helping ForkJoinPool.common.externalHelpComplete( // CountedCompleter任务 (CountedCompleter&lt;?&gt;)this, 0) : ForkJoinPool.common.tryExternalUnpush(this) ? doExec() : 0); // ForkJoinTask任务 if (s &gt;= 0 &amp;&amp; (s = status) &gt;= 0) &#123;//执行失败，进入等待 boolean interrupted = false; do &#123; if (U.compareAndSwapInt(this, STATUS, s, s | SIGNAL)) &#123; //更新state synchronized (this) &#123; if (status &gt;= 0) &#123;//SIGNAL 等待信号 try &#123; wait(0L); &#125; catch (InterruptedException ie) &#123; interrupted = true; &#125; &#125; else notifyAll(); &#125; &#125; &#125; while ((s = status) &gt;= 0); if (interrupted) Thread.currentThread().interrupt(); &#125; return s;&#125; 说明: 如果当前join为外部调用，则调用此方法执行任务，如果任务执行失败就进入等待。方法本身是很简单的，需要注意的是对不同的任务类型分两种情况: 如果我们的任务为 CountedCompleter 类型的任务，则调用externalHelpComplete方法来执行任务。 其他类型的 ForkJoinTask 任务调用tryExternalUnpush来执行，源码如下: 123456789101112131415161718192021222324//为外部提交者提供 tryUnpush 功能(给定任务在top位时弹出任务)final boolean tryExternalUnpush(ForkJoinTask&lt;?&gt; task) &#123; WorkQueue[] ws; WorkQueue w; ForkJoinTask&lt;?&gt;[] a; int m, s; int r = ThreadLocalRandom.getProbe(); if ((ws = workQueues) != null &amp;&amp; (m = ws.length - 1) &gt;= 0 &amp;&amp; (w = ws[m &amp; r &amp; SQMASK]) != null &amp;&amp; (a = w.array) != null &amp;&amp; (s = w.top) != w.base) &#123; long j = (((a.length - 1) &amp; (s - 1)) &lt;&lt; ASHIFT) + ABASE; //取top位任务 if (U.compareAndSwapInt(w, QLOCK, 0, 1)) &#123; //加锁 if (w.top == s &amp;&amp; w.array == a &amp;&amp; U.getObject(a, j) == task &amp;&amp; U.compareAndSwapObject(a, j, task, null)) &#123; //符合条件，弹出 U.putOrderedInt(w, QTOP, s - 1); //更新top U.putOrderedInt(w, QLOCK, 0); //解锁，返回true return true; &#125; U.compareAndSwapInt(w, QLOCK, 1, 0); //当前任务不在top位，解锁返回false &#125; &#125; return false;&#125; tryExternalUnpush的作用就是判断当前任务是否在top位，如果是则弹出任务，然后在externalAwaitDone中调用doExec()执行任务。 ForkJoinPool.awaitJoin()12345678910111213141516171819202122232425262728293031323334353637final int awaitJoin(WorkQueue w, ForkJoinTask&lt;?&gt; task, long deadline) &#123; int s = 0; if (task != null &amp;&amp; w != null) &#123; ForkJoinTask&lt;?&gt; prevJoin = w.currentJoin; //获取给定Worker的join任务 U.putOrderedObject(w, QCURRENTJOIN, task); //把currentJoin替换为给定任务 //判断是否为CountedCompleter类型的任务 CountedCompleter&lt;?&gt; cc = (task instanceof CountedCompleter) ? (CountedCompleter&lt;?&gt;) task : null; for (; ; ) &#123; if ((s = task.status) &lt; 0) //已经完成|取消|异常 跳出循环 break; if (cc != null)//CountedCompleter任务由helpComplete来完成join helpComplete(w, cc, 0); else if (w.base == w.top || w.tryRemoveAndExec(task)) //尝试执行 helpStealer(w, task); //队列为空或执行失败，任务可能被偷，帮助偷取者执行该任务 if ((s = task.status) &lt; 0) //已经完成|取消|异常，跳出循环 break; //计算任务等待时间 long ms, ns; if (deadline == 0L) ms = 0L; else if ((ns = deadline - System.nanoTime()) &lt;= 0L) break; else if ((ms = TimeUnit.NANOSECONDS.toMillis(ns)) &lt;= 0L) ms = 1L; if (tryCompensate(w)) &#123;//执行补偿操作 task.internalWait(ms);//补偿执行成功，任务等待指定时间 U.getAndAddLong(this, CTL, AC_UNIT);//更新活跃线程数 &#125; &#125; U.putOrderedObject(w, QCURRENTJOIN, prevJoin);//循环结束，替换为原来的join任务 &#125; return s;&#125; 说明: 如果当前 join 任务不在Worker等待队列的top位，或者任务执行失败，调用此方法来帮助执行或阻塞当前 join 的任务。函数执行流程如下: 由于每次调用awaitJoin都会优先执行当前join的任务，所以首先会更新currentJoin为当前join任务； 进入自旋: 首先检查任务是否已经完成(通过task.status &lt; 0判断)，如果给定任务执行完毕|取消|异常 则跳出循环返回执行状态s； 如果是 CountedCompleter 任务类型，调用helpComplete方法来完成join操作(后面笔者会开新篇来专门讲解CountedCompleter，本篇暂时不做详细解析)； 非 CountedCompleter 任务类型调用WorkQueue.tryRemoveAndExec尝试执行任务； 如果给定 WorkQueue 的等待队列为空或任务执行失败，说明任务可能被偷，调用helpStealer帮助偷取者执行任务(也就是说，偷取者帮我执行任务，我去帮偷取者执行它的任务)； 再次判断任务是否执行完毕(task.status &lt; 0)，如果任务执行失败，计算一个等待时间准备进行补偿操作； 调用tryCompensate方法为给定 WorkQueue 尝试执行补偿操作。在执行补偿期间，如果发现 资源争用|池处于unstable状态|当前Worker已终止，则调用ForkJoinTask.internalWait()方法等待指定的时间，任务唤醒之后继续自旋，ForkJoinTask.internalWait()源码如下: 123456789101112final void internalWait(long timeout) &#123; int s; if ((s = status) &gt;= 0 &amp;&amp; // force completer to issue notify U.compareAndSwapInt(this, STATUS, s, s | SIGNAL)) &#123;//更新任务状态为SIGNAL(等待唤醒) synchronized (this) &#123; if (status &gt;= 0) try &#123; wait(timeout); &#125; catch (InterruptedException ie) &#123; &#125; else notifyAll(); &#125; &#125;&#125; 在awaitJoin中，我们总共调用了三个比较复杂的方法: tryRemoveAndExec、helpStealer和tryCompensate，下面我们依次讲解。 WorkQueue.tryRemoveAndExec(ForkJoinTask&lt;?&gt; task)1234567891011121314151617181920212223242526272829303132333435363738final boolean tryRemoveAndExec(ForkJoinTask&lt;?&gt; task) &#123; ForkJoinTask&lt;?&gt;[] a; int m, s, b, n; if ((a = array) != null &amp;&amp; (m = a.length - 1) &gt;= 0 &amp;&amp; task != null) &#123; while ((n = (s = top) - (b = base)) &gt; 0) &#123; //从top往下自旋查找 for (ForkJoinTask&lt;?&gt; t; ; ) &#123; // traverse from s to b long j = ((--s &amp; m) &lt;&lt; ASHIFT) + ABASE;//计算任务索引 if ((t = (ForkJoinTask&lt;?&gt;) U.getObject(a, j)) == null) //获取索引到的任务 return s + 1 == top; // shorter than expected else if (t == task) &#123; //给定任务为索引任务 boolean removed = false; if (s + 1 == top) &#123; // pop if (U.compareAndSwapObject(a, j, task, null)) &#123; //弹出任务 U.putOrderedInt(this, QTOP, s); //更新top removed = true; &#125; &#125; else if (base == b) // replace with proxy removed = U.compareAndSwapObject( a, j, task, new EmptyTask()); //join任务已经被移除，替换为一个占位任务 if (removed) task.doExec(); //执行 break; &#125; else if (t.status &lt; 0 &amp;&amp; s + 1 == top) &#123; //给定任务不是top任务 if (U.compareAndSwapObject(a, j, t, null)) //弹出任务 U.putOrderedInt(this, QTOP, s);//更新top break; // was cancelled &#125; if (--n == 0) //遍历结束 return false; &#125; if (task.status &lt; 0) //任务执行完毕 return false; &#125; &#125; return true;&#125; 说明: 从top位开始自旋向下找到给定任务，如果找到把它从当前 Worker 的任务队列中移除并执行它。注意返回的参数: 如果任务队列为空或者任务未执行完毕返回true；任务执行完毕返回false。 ForkJoinPool.helpStealer(WorkQueue w, ForkJoinTask&lt;?&gt; task)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667private void helpStealer(WorkQueue w, ForkJoinTask&lt;?&gt; task) &#123; WorkQueue[] ws = workQueues; int oldSum = 0, checkSum, m; if (ws != null &amp;&amp; (m = ws.length - 1) &gt;= 0 &amp;&amp; w != null &amp;&amp; task != null) &#123; do &#123; // restart point checkSum = 0; // for stability check ForkJoinTask&lt;?&gt; subtask; WorkQueue j = w, v; // v is subtask stealer descent: for (subtask = task; subtask.status &gt;= 0; ) &#123; //1. 找到给定WorkQueue的偷取者v for (int h = j.hint | 1, k = 0, i; ; k += 2) &#123;//跳两个索引，因为Worker在奇数索引位 if (k &gt; m) // can&#x27;t find stealer break descent; if ((v = ws[i = (h + k) &amp; m]) != null) &#123; if (v.currentSteal == subtask) &#123;//定位到偷取者 j.hint = i;//更新stealer索引 break; &#125; checkSum += v.base; &#125; &#125; //2. 帮助偷取者v执行任务 for (; ; ) &#123; // help v or descend ForkJoinTask&lt;?&gt;[] a; //偷取者内部的任务 int b; checkSum += (b = v.base); ForkJoinTask&lt;?&gt; next = v.currentJoin;//获取偷取者的join任务 if (subtask.status &lt; 0 || j.currentJoin != subtask || v.currentSteal != subtask) // stale break descent; // stale，跳出descent循环重来 if (b - v.top &gt;= 0 || (a = v.array) == null) &#123; if ((subtask = next) == null) //偷取者的join任务为null，跳出descent循环 break descent; j = v; break; //偷取者内部任务为空，可能任务也被偷走了；跳出本次循环，查找偷取者的偷取者 &#125; int i = (((a.length - 1) &amp; b) &lt;&lt; ASHIFT) + ABASE;//获取base偏移地址 ForkJoinTask&lt;?&gt; t = ((ForkJoinTask&lt;?&gt;) U.getObjectVolatile(a, i));//获取偷取者的base任务 if (v.base == b) &#123; if (t == null) // stale break descent; // stale，跳出descent循环重来 if (U.compareAndSwapObject(a, i, t, null)) &#123;//弹出任务 v.base = b + 1; //更新偷取者的base位 ForkJoinTask&lt;?&gt; ps = w.currentSteal;//获取调用者偷来的任务 int top = w.top; //首先更新给定workQueue的currentSteal为偷取者的base任务，然后执行该任务 //然后通过检查top来判断给定workQueue是否有自己的任务，如果有， // 则依次弹出任务(LIFO)-&gt;更新currentSteal-&gt;执行该任务(注意这里是自己偷自己的任务执行) do &#123; U.putOrderedObject(w, QCURRENTSTEAL, t); t.doExec(); // clear local tasks too &#125; while (task.status &gt;= 0 &amp;&amp; w.top != top &amp;&amp; //内部有自己的任务，依次弹出执行 (t = w.pop()) != null); U.putOrderedObject(w, QCURRENTSTEAL, ps);//还原给定workQueue的currentSteal if (w.base != w.top)//给定workQueue有自己的任务了，帮助结束，返回 return; // can&#x27;t further help &#125; &#125; &#125; &#125; &#125; while (task.status &gt;= 0 &amp;&amp; oldSum != (oldSum = checkSum)); &#125;&#125; 说明: 如果队列为空或任务执行失败，说明任务可能被偷，调用此方法来帮助偷取者执行任务。基本思想是: 偷取者帮助我执行任务，我去帮助偷取者执行它的任务。 函数执行流程如下: 循环定位偷取者，由于Worker是在奇数索引位，所以每次会跳两个索引位。定位到偷取者之后，更新调用者 WorkQueue 的hint为偷取者的索引，方便下次定位； 定位到偷取者后，开始帮助偷取者执行任务。从偷取者的base索引开始，每次偷取一个任务执行。在帮助偷取者执行任务后，如果调用者发现本身已经有任务(w.top !&#x3D; top)，则依次弹出自己的任务(LIFO顺序)并执行(也就是说自己偷自己的任务执行)。 ForkJoinPool.tryCompensate(WorkQueue w)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748//执行补偿操作: 尝试缩减活动线程量，可能释放或创建一个补偿线程来准备阻塞private boolean tryCompensate(WorkQueue w) &#123; boolean canBlock; WorkQueue[] ws; long c; int m, pc, sp; if (w == null || w.qlock &lt; 0 || // caller terminating (ws = workQueues) == null || (m = ws.length - 1) &lt;= 0 || (pc = config &amp; SMASK) == 0) // parallelism disabled canBlock = false; //调用者已终止 else if ((sp = (int) (c = ctl)) != 0) // release idle worker canBlock = tryRelease(c, ws[sp &amp; m], 0L);//唤醒等待的工作线程 else &#123;//没有空闲线程 int ac = (int) (c &gt;&gt; AC_SHIFT) + pc; //活跃线程数 int tc = (short) (c &gt;&gt; TC_SHIFT) + pc;//总线程数 int nbusy = 0; // validate saturation for (int i = 0; i &lt;= m; ++i) &#123; // two passes of odd indices WorkQueue v; if ((v = ws[((i &lt;&lt; 1) | 1) &amp; m]) != null) &#123;//取奇数索引位 if ((v.scanState &amp; SCANNING) != 0)//没有正在运行任务，跳出 break; ++nbusy;//正在运行任务，添加标记 &#125; &#125; if (nbusy != (tc &lt;&lt; 1) || ctl != c) canBlock = false; // unstable or stale else if (tc &gt;= pc &amp;&amp; ac &gt; 1 &amp;&amp; w.isEmpty()) &#123;//总线程数大于并行度 &amp;&amp; 活动线程数大于1 &amp;&amp; 调用者任务队列为空，不需要补偿 long nc = ((AC_MASK &amp; (c - AC_UNIT)) | (~AC_MASK &amp; c)); // uncompensated canBlock = U.compareAndSwapLong(this, CTL, c, nc);//更新活跃线程数 &#125; else if (tc &gt;= MAX_CAP || (this == common &amp;&amp; tc &gt;= pc + commonMaxSpares))//超出最大线程数 throw new RejectedExecutionException( &quot;Thread limit exceeded replacing blocked worker&quot;); else &#123; // similar to tryAddWorker boolean add = false; int rs; // CAS within lock long nc = ((AC_MASK &amp; c) | (TC_MASK &amp; (c + TC_UNIT)));//计算总线程数 if (((rs = lockRunState()) &amp; STOP) == 0) add = U.compareAndSwapLong(this, CTL, c, nc);//更新总线程数 unlockRunState(rs, rs &amp; ~RSLOCK); //运行到这里说明活跃工作线程数不足，需要创建一个新的工作线程来补偿 canBlock = add &amp;&amp; createWorker(); // throws on exception &#125; &#125; return canBlock;&#125; 说明: 具体的执行看源码及注释，这里我们简单总结一下需要和不需要补偿的几种情况: 需要补偿 : 调用者队列不为空，并且有空闲工作线程，这种情况会唤醒空闲线程(调用tryRelease方法) 池尚未停止，活跃线程数不足，这时会新建一个工作线程(调用createWorker方法) 不需要补偿 : 调用者已终止或池处于不稳定状态 总线程数大于并行度 &amp;&amp; 活动线程数大于1 &amp;&amp; 调用者任务队列为空 Fork&#x2F;Join的陷阱与注意事项使用Fork&#x2F;Join框架时，需要注意一些陷阱, 在下面 斐波那契数列例子中你将看到示例: 避免不必要的fork()划分成两个子任务后，不要同时调用两个子任务的fork()方法。 表面上看上去两个子任务都fork()，然后join()两次似乎更自然。但事实证明，直接调用compute()效率更高。因为直接调用子任务的compute()方法实际上就是在当前的工作线程进行了计算(线程重用)，这比“将子任务提交到工作队列，线程又从工作队列中拿任务”快得多。 当一个大任务被划分成两个以上的子任务时，尽可能使用前面说到的三个衍生的invokeAll方法，因为使用它们能避免不必要的fork()。 注意fork()、compute()、join()的顺序为了两个任务并行，三个方法的调用顺序需要万分注意。 1234right.fork(); // 计算右边的任务long leftAns = left.compute(); // 计算左边的任务(同时右边任务也在计算)long rightAns = right.join(); // 等待右边的结果return leftAns + rightAns; 如果我们写成: 1234left.fork(); // 计算完左边的任务long leftAns = left.join(); // 等待左边的计算结果long rightAns = right.compute(); // 再计算右边的任务return leftAns + rightAns; 或者 1234long rightAns = right.compute(); // 计算完右边的任务left.fork(); // 再计算左边的任务long leftAns = left.join(); // 等待左边的计算结果return leftAns + rightAns; 这两种实际上都没有并行。 选择合适的子任务粒度选择划分子任务的粒度(顺序执行的阈值)很重要，因为使用Fork&#x2F;Join框架并不一定比顺序执行任务的效率高: 如果任务太大，则无法提高并行的吞吐量；如果任务太小，子任务的调度开销可能会大于并行计算的性能提升，我们还要考虑创建子任务、fork()子任务、线程调度以及合并子任务处理结果的耗时以及相应的内存消耗。 官方文档给出的粗略经验是: 任务应该执行100~10000个基本的计算步骤。决定子任务的粒度的最好办法是实践，通过实际测试结果来确定这个阈值才是“上上策”。 和其他Java代码一样，Fork&#x2F;Join框架测试时需要“预热”或者说执行几遍才会被JIT(Just-in-time)编译器优化，所以测试性能之前跑几遍程序很重要。 避免重量级任务划分与结果合并Fork&#x2F;Join的很多使用场景都用到数组或者List等数据结构，子任务在某个分区中运行，最典型的例子如并行排序和并行查找。拆分子任务以及合并处理结果的时候，应该尽量避免System.arraycopy这样耗时耗空间的操作，从而最小化任务的处理开销。 再深入理解有哪些JDK源码中使用了Fork&#x2F;Join思想?我们常用的数组工具类 Arrays 在JDK 8之后新增的并行排序方法(parallelSort)就运用了 ForkJoinPool 的特性，还有 ConcurrentHashMap 在JDK 8之后添加的函数式方法(如forEach等)也有运用。 使用Executors工具类创建ForkJoinPoolJava8在Executors工具类中新增了两个工厂方法: 12345// parallelism定义并行级别public static ExecutorService newWorkStealingPool(int parallelism);// 默认并行级别为JVM可用的处理器个数// Runtime.getRuntime().availableProcessors()public static ExecutorService newWorkStealingPool(); 关于Fork&#x2F;Join异常处理Java的受检异常机制一直饱受诟病，所以在ForkJoinTask的invoke()、join()方法及其衍生方法中都没有像get()方法那样抛出个ExecutionException的受检异常。 所以你可以在ForkJoinTask中看到内部把受检异常转换成了运行时异常。 123456789static void rethrow(Throwable ex) &#123; if (ex != null) ForkJoinTask.&lt;RuntimeException&gt;uncheckedThrow(ex);&#125;@SuppressWarnings(&quot;unchecked&quot;)static &lt;T extends Throwable&gt; void uncheckedThrow(Throwable t) throws T &#123; throw (T)t; // rely on vacuous cast&#125; 关于Java你不知道的10件事中已经指出，JVM实际并不关心这个异常是受检异常还是运行时异常，受检异常这东西完全是给Java编译器用的: 用于警告程序员这里有个异常没有处理。 但不可否认的是invoke、join()仍可能会抛出运行时异常，所以ForkJoinTask还提供了两个不提取结果和异常的方法quietlyInvoke()、quietlyJoin()，这两个方法允许你在所有任务完成后对结果和异常进行处理。 使用quitelyInvoke()和quietlyJoin()时可以配合isCompletedAbnormally()和isCompletedNormally()方法使用。 一些Fork&#x2F;Join例子采用Fork&#x2F;Join来异步计算1+2+3+…+10000的结果12345678910111213141516171819202122232425262728293031323334353637383940public class Test &#123;\tstatic final class SumTask extends RecursiveTask&lt;Integer&gt; &#123; private static final long serialVersionUID = 1L; final int start; //开始计算的数 final int end; //最后计算的数 SumTask(int start, int end) &#123; this.start = start; this.end = end; &#125; @Override protected Integer compute() &#123; //如果计算量小于1000，那么分配一个线程执行if中的代码块，并返回执行结果 if(end - start &lt; 1000) &#123; System.out.println(Thread.currentThread().getName() + &quot; 开始执行: &quot; + start + &quot;-&quot; + end); int sum = 0; for(int i = start; i &lt;= end; i++) sum += i; return sum; &#125; //如果计算量大于1000，那么拆分为两个任务 SumTask task1 = new SumTask(start, (start + end) / 2); SumTask task2 = new SumTask((start + end) / 2 + 1, end); //执行任务 task1.fork(); task2.fork(); //获取任务执行的结果 return task1.join() + task2.join(); &#125;\t&#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; ForkJoinPool pool = new ForkJoinPool(); ForkJoinTask&lt;Integer&gt; task = new SumTask(1, 10000); pool.submit(task); System.out.println(task.get());\t&#125;&#125; 执行结果 1234567891011121314151617ForkJoinPool-1-worker-1 开始执行: 1-625ForkJoinPool-1-worker-7 开始执行: 6251-6875ForkJoinPool-1-worker-6 开始执行: 5626-6250ForkJoinPool-1-worker-10 开始执行: 3751-4375ForkJoinPool-1-worker-13 开始执行: 2501-3125ForkJoinPool-1-worker-8 开始执行: 626-1250ForkJoinPool-1-worker-11 开始执行: 5001-5625ForkJoinPool-1-worker-3 开始执行: 7501-8125ForkJoinPool-1-worker-14 开始执行: 1251-1875ForkJoinPool-1-worker-4 开始执行: 9376-10000ForkJoinPool-1-worker-8 开始执行: 8126-8750ForkJoinPool-1-worker-0 开始执行: 1876-2500ForkJoinPool-1-worker-12 开始执行: 4376-5000ForkJoinPool-1-worker-5 开始执行: 8751-9375ForkJoinPool-1-worker-7 开始执行: 6876-7500ForkJoinPool-1-worker-1 开始执行: 3126-375050005000 实现斐波那契数列 斐波那契数列: 1、1、2、3、5、8、13、21、34、…… 公式 : F(1)&#x3D;1，F(2)&#x3D;1, F(n)&#x3D;F(n-1)+F(n-2)(n&gt;&#x3D;3，n∈N*) 12345678910111213141516171819202122232425public static void main(String[] args) &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(4); // 最大并发数4 Fibonacci fibonacci = new Fibonacci(20); long startTime = System.currentTimeMillis(); Integer result = forkJoinPool.invoke(fibonacci); long endTime = System.currentTimeMillis(); System.out.println(&quot;Fork/join sum: &quot; + result + &quot; in &quot; + (endTime - startTime) + &quot; ms.&quot;);&#125;//以下为官方API文档示例static class Fibonacci extends RecursiveTask&lt;Integer&gt; &#123; final int n; Fibonacci(int n) &#123; this.n = n; &#125; @Override protected Integer compute() &#123; if (n &lt;= 1) &#123; return n; &#125; Fibonacci f1 = new Fibonacci(n - 1); f1.fork(); Fibonacci f2 = new Fibonacci(n - 2); return f2.compute() + f1.join(); &#125;&#125; 当然你也可以两个任务都fork，要注意的是两个任务都fork的情况，必须按照f1.fork()，f2.fork()， f2.join()，f1.join()这样的顺序，不然有性能问题，详见上面注意事项中的说明。 官方API文档是这样写到的，所以平日用invokeAll就好了。invokeAll会把传入的任务的第一个交给当前线程来执行，其他的任务都fork加入工作队列，这样等于利用当前线程也执行任务了。 12345678910111213141516171819202122232425262728293031323334&#123; // ... Fibonacci f1 = new Fibonacci(n - 1); Fibonacci f2 = new Fibonacci(n - 2); invokeAll(f1,f2); return f2.join() + f1.join();&#125;public static void invokeAll(ForkJoinTask&lt;?&gt;... tasks) &#123; Throwable ex = null; int last = tasks.length - 1; for (int i = last; i &gt;= 0; --i) &#123; ForkJoinTask&lt;?&gt; t = tasks[i]; if (t == null) &#123; if (ex == null) ex = new NullPointerException(); &#125; else if (i != 0) //除了第一个都fork t.fork(); else if (t.doInvoke() &lt; NORMAL &amp;&amp; ex == null) //留一个自己执行 ex = t.getException(); &#125; for (int i = 1; i &lt;= last; ++i) &#123; ForkJoinTask&lt;?&gt; t = tasks[i]; if (t != null) &#123; if (ex != null) t.cancel(false); else if (t.doJoin() &lt; NORMAL) ex = t.getException(); &#125; &#125; if (ex != null) rethrow(ex);&#125; 参考文章 首先推荐阅读ForkJoinPool的作者Doug Lea的一篇文章《A Java Fork&#x2F;Join Framework》英文原文地址在新窗口打开 本文主要参考自泰迪的bagwell的https://www.jianshu.com/p/32a15ef2f1bf和https://www.jianshu.com/p/6a14d0b54b8d，在此基础上参考了如下文章 https://blog.csdn.net/u010841296/article/details/83963637 https://blog.csdn.net/Holmofy/article/details/82714665 https://blog.csdn.net/abc123lzf/article/details/82873181 https://blog.csdn.net/yinwenjie/article/details/71524140 https://blog.csdn.net/cowbin2012/article/details/89791757","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"20.JUC线程池: ScheduledThreadPoolExecutor详解","path":"/2023/12/26/20-JUC线程池-ScheduledThreadPoolExecutor详解/","content":"在很多业务场景中，我们可能需要周期性的运行某项任务来获取结果，比如周期数据统计，定时发送数据等。在并发包出现之前，Java 早在1.3就提供了 Timer 类(只需要了解，目前已渐渐被 ScheduledThreadPoolExecutor 代替)来适应这些业务场景。随着业务量的不断增大，我们可能需要多个工作线程运行任务来尽可能的增加产品性能，或者是需要更高的灵活性来控制和监控这些周期业务。这些都是 ScheduledThreadPoolExecutor 诞生的必然性。 带着BAT大厂的面试问题去理解ScheduledThreadPoolExecutor 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解ScheduledThreadPoolExecutor。 ScheduledThreadPoolExecutor要解决什么样的问题? ScheduledThreadPoolExecutor相比ThreadPoolExecutor有哪些特性? ScheduledThreadPoolExecutor有什么样的数据结构，核心内部类和抽象类? ScheduledThreadPoolExecutor有哪两个关闭策略? 区别是什么? ScheduledThreadPoolExecutor中scheduleAtFixedRate 和 scheduleWithFixedDelay区别是什么? 为什么ThreadPoolExecutor 的调整策略却不适用于 ScheduledThreadPoolExecutor? Executors 提供了几种方法来构造 ScheduledThreadPoolExecutor? ScheduledThreadPoolExecutor简介ScheduledThreadPoolExecutor继承自 ThreadPoolExecutor，为任务提供延迟或周期执行，属于线程池的一种。和 ThreadPoolExecutor 相比，它还具有以下几种特性: 使用专门的任务类型—ScheduledFutureTask 来执行周期任务，也可以接收不需要时间调度的任务(这些任务通过 ExecutorService 来执行)。 使用专门的存储队列—DelayedWorkQueue 来存储任务，DelayedWorkQueue 是无界延迟队列DelayQueue 的一种。相比ThreadPoolExecutor也简化了执行机制(delayedExecute方法，后面单独分析)。 支持可选的run-after-shutdown参数，在池被关闭(shutdown)之后支持可选的逻辑来决定是否继续运行周期或延迟任务。并且当任务(重新)提交操作与 shutdown 操作重叠时，复查逻辑也不相同。 ScheduledThreadPoolExecutor数据结构 ScheduledThreadPoolExecutor继承自 ThreadPoolExecutor: 详情请参考: JUC线程池: ThreadPoolExecutor详解 ScheduledThreadPoolExecutor 内部构造了两个内部类 ScheduledFutureTask 和 DelayedWorkQueue: ScheduledFutureTask: 继承了FutureTask，说明是一个异步运算任务；最上层分别实现了Runnable、Future、Delayed接口，说明它是一个可以延迟执行的异步运算任务。 DelayedWorkQueue: 这是 ScheduledThreadPoolExecutor 为存储周期或延迟任务专门定义的一个延迟队列，继承了 AbstractQueue，为了契合 ThreadPoolExecutor 也实现了 BlockingQueue 接口。它内部只允许存储 RunnableScheduledFuture 类型的任务。与 DelayQueue 的不同之处就是它只允许存放 RunnableScheduledFuture 对象，并且自己实现了二叉堆(DelayQueue 是利用了 PriorityQueue 的二叉堆结构)。 ScheduledThreadPoolExecutor源码解析 以下源码的解析是基于你已经理解了FutureTask。 内部类ScheduledFutureTask属性1234567891011121314//为相同延时任务提供的顺序编号private final long sequenceNumber;//任务可以执行的时间，纳秒级private long time;//重复任务的执行周期时间，纳秒级。private final long period;//重新入队的任务RunnableScheduledFuture&lt;V&gt; outerTask = this;//延迟队列的索引，以支持更快的取消操作int heapIndex; sequenceNumber: 当两个任务有相同的延迟时间时，按照 FIFO 的顺序入队。sequenceNumber 就是为相同延时任务提供的顺序编号。 time: 任务可以执行时的时间，纳秒级，通过triggerTime方法计算得出。 period: 任务的执行周期时间，纳秒级。正数表示固定速率执行(为scheduleAtFixedRate提供服务)，负数表示固定延迟执行(为scheduleWithFixedDelay提供服务)，0表示不重复任务。 outerTask: 重新入队的任务，通过reExecutePeriodic方法入队重新排序。 核心方法run()123456789101112public void run() &#123; boolean periodic = isPeriodic();//是否为周期任务 if (!canRunInCurrentRunState(periodic))//当前状态是否可以执行 cancel(false); else if (!periodic) //不是周期任务，直接执行 ScheduledFutureTask.super.run(); else if (ScheduledFutureTask.super.runAndReset()) &#123; setNextRunTime();//设置下一次运行时间 reExecutePeriodic(outerTask);//重排序一个周期任务 &#125;&#125; 说明: ScheduledFutureTask 的run方法重写了 FutureTask 的版本，以便执行周期任务时重置&#x2F;重排序任务。任务的执行通过父类 FutureTask 的run实现。内部有两个针对周期任务的方法: setNextRunTime(): 用来设置下一次运行的时间，源码如下: 12345678910111213//设置下一次执行任务的时间private void setNextRunTime() &#123; long p = period; if (p &gt; 0) //固定速率执行，scheduleAtFixedRate time += p; else time = triggerTime(-p); //固定延迟执行，scheduleWithFixedDelay&#125;//计算固定延迟任务的执行时间long triggerTime(long delay) &#123; return now() + ((delay &lt; (Long.MAX_VALUE &gt;&gt; 1)) ? delay : overflowFree(delay));&#125; reExecutePeriodic(): 周期任务重新入队等待下一次执行，源码如下: 1234567891011//重排序一个周期任务void reExecutePeriodic(RunnableScheduledFuture&lt;?&gt; task) &#123; if (canRunInCurrentRunState(true)) &#123;//池关闭后可继续执行 super.getQueue().add(task);//任务入列 //重新检查run-after-shutdown参数，如果不能继续运行就移除队列任务，并取消任务的执行 if (!canRunInCurrentRunState(true) &amp;&amp; remove(task)) task.cancel(false); else ensurePrestart();//启动一个新的线程等待任务 &#125;&#125; reExecutePeriodic与delayedExecute的执行策略一致，只不过reExecutePeriodic不会执行拒绝策略而是直接丢掉任务。 cancel方法123456public boolean cancel(boolean mayInterruptIfRunning) &#123; boolean cancelled = super.cancel(mayInterruptIfRunning); if (cancelled &amp;&amp; removeOnCancel &amp;&amp; heapIndex &gt;= 0) remove(this); return cancelled;&#125; ScheduledFutureTask.cancel本质上由其父类 FutureTask.cancel 实现。取消任务成功后会根据removeOnCancel参数决定是否从队列中移除此任务。 核心属性1234567891011//关闭后继续执行已经存在的周期任务 private volatile boolean continueExistingPeriodicTasksAfterShutdown;//关闭后继续执行已经存在的延时任务 private volatile boolean executeExistingDelayedTasksAfterShutdown = true;//取消任务后移除 private volatile boolean removeOnCancel = false;//为相同延时的任务提供的顺序编号，保证任务之间的FIFO顺序private static final AtomicLong sequencer = new AtomicLong(); continueExistingPeriodicTasksAfterShutdown和executeExistingDelayedTasksAfterShutdown是 ScheduledThreadPoolExecutor 定义的 run-after-shutdown 参数，用来控制池关闭之后的任务执行逻辑。 removeOnCancel用来控制任务取消后是否从队列中移除。当一个已经提交的周期或延迟任务在运行之前被取消，那么它之后将不会运行。默认配置下，这种已经取消的任务在届期之前不会被移除。 通过这种机制，可以方便检查和监控线程池状态，但也可能导致已经取消的任务无限滞留。为了避免这种情况的发生，我们可以通过setRemoveOnCancelPolicy方法设置移除策略，把参数removeOnCancel设为true可以在任务取消后立即从队列中移除。 sequencer是为相同延时的任务提供的顺序编号，保证任务之间的 FIFO 顺序。与 ScheduledFutureTask 内部的sequenceNumber参数作用一致。 构造函数首先看下构造函数，ScheduledThreadPoolExecutor 内部有四个构造函数，这里我们只看这个最大构造灵活度的: 123456public ScheduledThreadPoolExecutor(int corePoolSize, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS, new DelayedWorkQueue(), threadFactory, handler);&#125; 构造函数都是通过super调用了ThreadPoolExecutor的构造，并且使用特定等待队列DelayedWorkQueue。 核心方法:Schedule12345678910public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit) &#123; if (callable == null || unit == null) throw new NullPointerException(); RunnableScheduledFuture&lt;V&gt; t = decorateTask(callable, new ScheduledFutureTask&lt;V&gt;(callable, triggerTime(delay, unit)));//构造ScheduledFutureTask任务 delayedExecute(t);//任务执行主方法 return t;&#125; 说明: schedule主要用于执行一次性(延迟)任务。函数执行逻辑分两步: 封装 Callable/Runnable: 首先通过triggerTime计算任务的延迟执行时间，然后通过 ScheduledFutureTask 的构造函数把 Runnable&#x2F;Callable 任务构造为ScheduledThreadPoolExecutor可以执行的任务类型，最后调用decorateTask方法执行用户自定义的逻辑；decorateTask是一个用户可自定义扩展的方法，默认实现下直接返回封装的RunnableScheduledFuture任务，源码如下: 1234protected &lt;V&gt; RunnableScheduledFuture&lt;V&gt; decorateTask( Runnable runnable, RunnableScheduledFuture&lt;V&gt; task) &#123; return task;&#125; 执行任务: 通过delayedExecute实现。下面我们来详细分析。 12345678910111213private void delayedExecute(RunnableScheduledFuture&lt;?&gt; task) &#123; if (isShutdown()) reject(task);//池已关闭，执行拒绝策略 else &#123; super.getQueue().add(task);//任务入队 if (isShutdown() &amp;&amp; !canRunInCurrentRunState(task.isPeriodic()) &amp;&amp;//判断run-after-shutdown参数 remove(task))//移除任务 task.cancel(false); else ensurePrestart();//启动一个新的线程等待任务 &#125;&#125; 说明: delayedExecute是执行任务的主方法，方法执行逻辑如下: 如果池已关闭(ctl &gt;&#x3D; SHUTDOWN)，执行任务拒绝策略； 池正在运行，首先把任务入队排序；然后重新检查池的关闭状态，执行如下逻辑: A: 如果池正在运行，或者 run-after-shutdown 参数值为true，则调用父类方法ensurePrestart启动一个新的线程等待执行任务。ensurePrestart源码如下: 1234567void ensurePrestart() &#123; int wc = workerCountOf(ctl.get()); if (wc &lt; corePoolSize) addWorker(null, true); else if (wc == 0) addWorker(null, false);&#125; ensurePrestart是父类 ThreadPoolExecutor 的方法，用于启动一个新的工作线程等待执行任务，即使corePoolSize为0也会安排一个新线程。 B: 如果池已经关闭，并且 run-after-shutdown 参数值为false，则执行父类(ThreadPoolExecutor)方法remove移除队列中的指定任务，成功移除后调用ScheduledFutureTask.cancel取消任务 核心方法:scheduleAtFixedRate 和 scheduleWithFixedDelay1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 创建一个周期执行的任务，第一次执行延期时间为initialDelay， * 之后每隔period执行一次，不等待第一次执行完成就开始计时 */public ScheduledFuture&lt;?&gt; scheduleAtFixedRate(Runnable command, long initialDelay, long period, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (period &lt;= 0) throw new IllegalArgumentException(); //构建RunnableScheduledFuture任务类型 ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit),//计算任务的延迟时间 unit.toNanos(period));//计算任务的执行周期 RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft);//执行用户自定义逻辑 sft.outerTask = t;//赋值给outerTask，准备重新入队等待下一次执行 delayedExecute(t);//执行任务 return t;&#125;/** * 创建一个周期执行的任务，第一次执行延期时间为initialDelay， * 在第一次执行完之后延迟delay后开始下一次执行 */public ScheduledFuture&lt;?&gt; scheduleWithFixedDelay(Runnable command, long initialDelay, long delay, TimeUnit unit) &#123; if (command == null || unit == null) throw new NullPointerException(); if (delay &lt;= 0) throw new IllegalArgumentException(); //构建RunnableScheduledFuture任务类型 ScheduledFutureTask&lt;Void&gt; sft = new ScheduledFutureTask&lt;Void&gt;(command, null, triggerTime(initialDelay, unit),//计算任务的延迟时间 unit.toNanos(-delay));//计算任务的执行周期 RunnableScheduledFuture&lt;Void&gt; t = decorateTask(command, sft);//执行用户自定义逻辑 sft.outerTask = t;//赋值给outerTask，准备重新入队等待下一次执行 delayedExecute(t);//执行任务 return t;&#125; 说明: scheduleAtFixedRate和scheduleWithFixedDelay方法的逻辑与schedule类似。 注意scheduleAtFixedRate和scheduleWithFixedDelay的区别: 乍一看两个方法一模一样，其实，在unit.toNanos这一行代码中还是有区别的。没错，scheduleAtFixedRate传的是正值，而scheduleWithFixedDelay传的则是负值，这个值就是 ScheduledFutureTask 的period属性。 核心方法:shutdown()123456789101112131415161718192021222324252627282930313233343536public void shutdown() &#123; super.shutdown();&#125;//取消并清除由于关闭策略不应该运行的所有任务@Override void onShutdown() &#123; BlockingQueue&lt;Runnable&gt; q = super.getQueue(); //获取run-after-shutdown参数 boolean keepDelayed = getExecuteExistingDelayedTasksAfterShutdownPolicy(); boolean keepPeriodic = getContinueExistingPeriodicTasksAfterShutdownPolicy(); if (!keepDelayed &amp;&amp; !keepPeriodic) &#123;//池关闭后不保留任务 //依次取消任务 for (Object e : q.toArray()) if (e instanceof RunnableScheduledFuture&lt;?&gt;) ((RunnableScheduledFuture&lt;?&gt;) e).cancel(false); q.clear();//清除等待队列 &#125; else &#123;//池关闭后保留任务 // Traverse snapshot to avoid iterator exceptions //遍历快照以避免迭代器异常 for (Object e : q.toArray()) &#123; if (e instanceof RunnableScheduledFuture) &#123; RunnableScheduledFuture&lt;?&gt; t = (RunnableScheduledFuture&lt;?&gt;)e; if ((t.isPeriodic() ? !keepPeriodic : !keepDelayed) || t.isCancelled()) &#123; // also remove if already cancelled //如果任务已经取消，移除队列中的任务 if (q.remove(t)) t.cancel(false); &#125; &#125; &#125; &#125; tryTerminate(); //终止线程池&#125; 说明: 池关闭方法调用了父类ThreadPoolExecutor的shutdown，具体分析见 ThreadPoolExecutor 篇。这里主要介绍以下在shutdown方法中调用的关闭钩子onShutdown方法，它的主要作用是在关闭线程池后取消并清除由于关闭策略不应该运行的所有任务，这里主要是根据 run-after-shutdown 参数(continueExistingPeriodicTasksAfterShutdown和executeExistingDelayedTasksAfterShutdown)来决定线程池关闭后是否关闭已经存在的任务。 再深入理解 为什么ThreadPoolExecutor 的调整策略却不适用于 ScheduledThreadPoolExecutor？ 例如: 由于 ScheduledThreadPoolExecutor 是一个固定核心线程数大小的线程池，并且使用了一个无界队列，所以调整maximumPoolSize对其没有任何影响(所以 ScheduledThreadPoolExecutor 没有提供可以调整最大线程数的构造函数，默认最大线程数固定为Integer.MAX_VALUE)。此外，设置corePoolSize为0或者设置核心线程空闲后清除(allowCoreThreadTimeOut)同样也不是一个好的策略，因为一旦周期任务到达某一次运行周期时，可能导致线程池内没有线程去处理这些任务。 Executors 提供了哪几种方法来构造 ScheduledThreadPoolExecutor？ newScheduledThreadPool: 可指定核心线程数的线程池。 newSingleThreadScheduledExecutor: 只有一个工作线程的线程池。如果内部工作线程由于执行周期任务异常而被终止，则会新建一个线程替代它的位置。 注意: newScheduledThreadPool(1, threadFactory) 不等价于newSingleThreadScheduledExecutor。newSingleThreadScheduledExecutor创建的线程池保证内部只有一个线程执行任务，并且线程数不可扩展；而通过newScheduledThreadPool(1, threadFactory)创建的线程池可以通过setCorePoolSize方法来修改核心线程数。 参考文章 文章主要参考自泰迪的bagwell的https://www.jianshu.com/p/8c97953f2751，在此基础上做了增改。","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"19.JUC线程池: ThreadPoolExecutor详解","path":"/2023/12/26/19-JUC线程池-ThreadPoolExecutor详解/","content":"本文主要对ThreadPoolExecutor详解。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 为什么要有线程池? Java是实现和管理线程池有哪些方式? 请简单举例如何使用。 为什么很多公司不允许使用Executors去创建线程池? 那么推荐怎么使用呢? ThreadPoolExecutor有哪些核心的配置参数? 请简要说明 ThreadPoolExecutor可以创建哪是哪三种线程池呢? 当队列满了并且worker的数量达到maxSize的时候，会怎么样? 说说ThreadPoolExecutor有哪些RejectedExecutionHandler策略? 默认是什么策略? 简要说下线程池的任务执行机制? execute –&gt; addWorker –&gt;runworker (getTask) 线程池中任务是如何提交的? 线程池中任务是如何关闭的? 在配置线程池的时候需要考虑哪些配置因素? 如何监控线程池的状态? 为什么要有线程池线程池能够对线程进行统一分配，调优和监控: 降低资源消耗(线程无限制地创建，然后使用完毕后销毁) 提高响应速度(无须创建线程) 提高线程的可管理性 ThreadPoolExecutor例子Java是如何实现和管理线程池的? 从JDK 5开始，把工作单元与执行机制分离开来，工作单元包括Runnable和Callable，而执行机制由Executor框架提供。 WorkerThread 12345678910111213141516171819202122232425262728public class WorkerThread implements Runnable &#123; private String command; public WorkerThread(String s)&#123; this.command=s; &#125; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()+&quot; Start. Command = &quot;+command); processCommand(); System.out.println(Thread.currentThread().getName()+&quot; End.&quot;); &#125; private void processCommand() &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; @Override public String toString()&#123; return this.command; &#125;&#125; SimpleThreadPool 123456789101112131415161718import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors; public class SimpleThreadPool &#123; public static void main(String[] args) &#123; ExecutorService executor = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 10; i++) &#123; Runnable worker = new WorkerThread(&quot;&quot; + i); executor.execute(worker); &#125; executor.shutdown(); // This will make the executor accept no new threads and finish all existing threads in the queue while (!executor.isTerminated()) &#123; // Wait until all threads are finish,and also you can use &quot;executor.awaitTermination();&quot; to wait &#125; System.out.println(&quot;Finished all threads&quot;); &#125;&#125; 程序中我们创建了固定大小为五个工作线程的线程池。然后分配给线程池十个工作，因为线程池大小为五，它将启动五个工作线程先处理五个工作，其他的工作则处于等待状态，一旦有工作完成，空闲下来工作线程就会捡取等待队列里的其他工作进行执行。 这里是以上程序的输出。 123456789101112131415161718192021pool-1-thread-2 Start. Command = 1pool-1-thread-4 Start. Command = 3pool-1-thread-1 Start. Command = 0pool-1-thread-3 Start. Command = 2pool-1-thread-5 Start. Command = 4pool-1-thread-4 End.pool-1-thread-5 End.pool-1-thread-1 End.pool-1-thread-3 End.pool-1-thread-3 Start. Command = 8pool-1-thread-2 End.pool-1-thread-2 Start. Command = 9pool-1-thread-1 Start. Command = 7pool-1-thread-5 Start. Command = 6pool-1-thread-4 Start. Command = 5pool-1-thread-2 End.pool-1-thread-4 End.pool-1-thread-3 End.pool-1-thread-5 End.pool-1-thread-1 End.Finished all threads 输出表明线程池中至始至终只有五个名为 “pool-1-thread-1” 到 “pool-1-thread-5” 的五个线程，这五个线程不随着工作的完成而消亡，会一直存在，并负责执行分配给线程池的任务，直到线程池消亡。 Executors 类提供了使用了 ThreadPoolExecutor 的简单的 ExecutorService 实现，但是 ThreadPoolExecutor 提供的功能远不止于此。我们可以在创建 ThreadPoolExecutor 实例时指定活动线程的数量，我们也可以限制线程池的大小并且创建我们自己的 RejectedExecutionHandler 实现来处理不能适应工作队列的工作。 这里是我们自定义的 RejectedExecutionHandler 接口的实现。 RejectedExecutionHandlerImpl.java 1234567891011import java.util.concurrent.RejectedExecutionHandler;import java.util.concurrent.ThreadPoolExecutor; public class RejectedExecutionHandlerImpl implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; System.out.println(r.toString() + &quot; is rejected&quot;); &#125; &#125; ThreadPoolExecutor 提供了一些方法，我们可以使用这些方法来查询 executor 的当前状态，线程池大小，活动线程数量以及任务数量。因此我是用来一个监控线程在特定的时间间隔内打印 executor 信息。 MyMonitorThread.java 123456789101112131415161718192021222324252627282930313233343536373839404142import java.util.concurrent.ThreadPoolExecutor; public class MyMonitorThread implements Runnable&#123; private ThreadPoolExecutor executor; private int seconds; private boolean run=true; public MyMonitorThread(ThreadPoolExecutor executor, int delay) &#123; this.executor = executor; this.seconds=delay; &#125; public void shutdown()&#123; this.run=false; &#125; @Override public void run() &#123; while(run)&#123; System.out.println( String.format(&quot;[monitor] [%d/%d] Active: %d, Completed: %d, Task: %d, isShutdown: %s, isTerminated: %s&quot;, this.executor.getPoolSize(), this.executor.getCorePoolSize(), this.executor.getActiveCount(), this.executor.getCompletedTaskCount(), this.executor.getTaskCount(), this.executor.isShutdown(), this.executor.isTerminated())); try &#123; Thread.sleep(seconds*1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 这里是使用 ThreadPoolExecutor 的线程池实现例子。 WorkerPool.java 123456789101112131415161718192021222324252627282930313233import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.Executors;import java.util.concurrent.ThreadFactory;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit; public class WorkerPool &#123; public static void main(String args[]) throws InterruptedException&#123; //RejectedExecutionHandler implementation RejectedExecutionHandlerImpl rejectionHandler = new RejectedExecutionHandlerImpl(); //Get the ThreadFactory implementation to use ThreadFactory threadFactory = Executors.defaultThreadFactory(); //creating the ThreadPoolExecutor ThreadPoolExecutor executorPool = new ThreadPoolExecutor(2, 4, 10, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(2), threadFactory, rejectionHandler); //start the monitoring thread MyMonitorThread monitor = new MyMonitorThread(executorPool, 3); Thread monitorThread = new Thread(monitor); monitorThread.start(); //submit work to the thread pool for(int i=0; i&lt;10; i++)&#123; executorPool.execute(new WorkerThread(&quot;cmd&quot;+i)); &#125; Thread.sleep(30000); //shut down the pool executorPool.shutdown(); //shut down the monitor thread Thread.sleep(5000); monitor.shutdown(); &#125;&#125; 注意在初始化 ThreadPoolExecutor 时，我们保持初始池大小为 2，最大池大小为 4 而工作队列大小为 2。因此如果已经有四个正在执行的任务而此时分配来更多任务的话，工作队列将仅仅保留他们(新任务)中的两个，其他的将会被 RejectedExecutionHandlerImpl 处理。 上面程序的输出可以证实以上观点。 12345678910111213141516171819202122232425262728pool-1-thread-1 Start. Command = cmd0pool-1-thread-4 Start. Command = cmd5cmd6 is rejectedpool-1-thread-3 Start. Command = cmd4pool-1-thread-2 Start. Command = cmd1cmd7 is rejectedcmd8 is rejectedcmd9 is rejected[monitor] [0/2] Active: 4, Completed: 0, Task: 6, isShutdown: false, isTerminated: false[monitor] [4/2] Active: 4, Completed: 0, Task: 6, isShutdown: false, isTerminated: falsepool-1-thread-4 End.pool-1-thread-1 End.pool-1-thread-2 End.pool-1-thread-3 End.pool-1-thread-1 Start. Command = cmd3pool-1-thread-4 Start. Command = cmd2[monitor] [4/2] Active: 2, Completed: 4, Task: 6, isShutdown: false, isTerminated: false[monitor] [4/2] Active: 2, Completed: 4, Task: 6, isShutdown: false, isTerminated: falsepool-1-thread-1 End.pool-1-thread-4 End.[monitor] [4/2] Active: 0, Completed: 6, Task: 6, isShutdown: false, isTerminated: false[monitor] [2/2] Active: 0, Completed: 6, Task: 6, isShutdown: false, isTerminated: false[monitor] [2/2] Active: 0, Completed: 6, Task: 6, isShutdown: false, isTerminated: false[monitor] [2/2] Active: 0, Completed: 6, Task: 6, isShutdown: false, isTerminated: false[monitor] [2/2] Active: 0, Completed: 6, Task: 6, isShutdown: false, isTerminated: false[monitor] [2/2] Active: 0, Completed: 6, Task: 6, isShutdown: false, isTerminated: false[monitor] [0/2] Active: 0, Completed: 6, Task: 6, isShutdown: true, isTerminated: true[monitor] [0/2] Active: 0, Completed: 6, Task: 6, isShutdown: true, isTerminated: true 注意 executor 的活动任务、完成任务以及所有完成任务，这些数量上的变化。我们可以调用 shutdown() 方法来结束所有提交的任务并终止线程池。 ThreadPoolExecutor使用详解其实java线程池的实现原理很简单，说白了就是一个线程集合workerSet和一个阻塞队列workQueue。当用户向线程池提交一个任务(也就是线程)时，线程池会先将任务放入workQueue中。workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行。 Execute原理当一个任务提交至线程池之后: 线程池首先当前运行的线程数量是否少于corePoolSize。如果是，则创建一个新的工作线程来执行任务。如果都在执行任务，则进入2. 判断BlockingQueue是否已经满了，倘若还没有满，则将线程放入BlockingQueue。否则进入3. 如果创建一个新的工作线程将使当前运行的线程数量超过maximumPoolSize，则交给RejectedExecutionHandler来处理任务。 当ThreadPoolExecutor创建新线程时，通过CAS来更新线程池的状态ctl. 参数123456public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) corePoolSize 线程池中的核心线程数，当提交一个任务时，线程池创建一个新线程执行任务，直到当前线程数等于corePoolSize, 即使有其他空闲线程能够执行新来的任务, 也会继续创建线程；如果当前线程数为corePoolSize，继续提交的任务被保存到阻塞队列中，等待被执行；如果执行了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有核心线程。 workQueue 用来保存等待被执行的任务的阻塞队列. 在JDK中提供了如下阻塞队列: 具体可以参考JUC 集合: BlockQueue详解 ArrayBlockingQueue: 基于数组结构的有界阻塞队列，按FIFO排序任务； LinkedBlockingQueue: 基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQueue； SynchronousQueue: 一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue； PriorityBlockingQueue: 具有优先级的无界阻塞队列； LinkedBlockingQueue比ArrayBlockingQueue在插入删除节点性能方面更优，但是二者在put(), take()任务的时均需要加锁，SynchronousQueue使用无锁算法，根据节点的状态判断执行，而不需要用到锁，其核心是Transfer.transfer(). maximumPoolSize 线程池中允许的最大线程数。如果当前阻塞队列满了，且继续提交任务，则创建新的线程执行任务，前提是当前线程数小于maximumPoolSize；当阻塞队列是无界队列, 则maximumPoolSize则不起作用, 因为无法提交至核心线程池的线程会一直持续地放入workQueue. keepAliveTime 线程空闲时的存活时间，即当线程没有任务执行时，该线程继续存活的时间；默认情况下，该参数只在线程数大于corePoolSize时才有用, 超过这个时间的空闲线程将被终止； unit keepAliveTime的单位 threadFactory 创建线程的工厂，通过自定义的线程工厂可以给每个新建的线程设置一个具有识别度的线程名。默认为DefaultThreadFactory handler 线程池的饱和策略，当阻塞队列满了，且没有空闲的工作线程，如果继续提交任务，必须采取一种策略处理该任务，线程池提供了4种策略: AbortPolicy: 直接抛出异常，默认策略； CallerRunsPolicy: 用调用者所在的线程来执行任务； DiscardOldestPolicy: 丢弃阻塞队列中靠最前的任务，并执行当前任务； DiscardPolicy: 直接丢弃任务； 当然也可以根据应用场景实现RejectedExecutionHandler接口，自定义饱和策略，如记录日志或持久化存储不能处理的任务。 三种类型newFixedThreadPool12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 线程池的线程数量达corePoolSize后，即使线程池没有可执行任务时，也不会释放线程。 FixedThreadPool的工作队列为无界队列LinkedBlockingQueue(队列容量为Integer.MAX_VALUE), 这会导致以下问题: 线程池里的线程数量不超过corePoolSize,这导致了maximumPoolSize和keepAliveTime将会是个无用参数 由于使用了无界队列, 所以FixedThreadPool永远不会拒绝, 即饱和策略失效 newSingleThreadExecutor123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 初始化的线程池中只有一个线程，如果该线程异常结束，会重新创建一个新的线程继续执行任务，唯一的线程可以保证所提交任务的顺序执行. 由于使用了无界队列, 所以SingleThreadPool永远不会拒绝, 即饱和策略失效 newCachedThreadPool12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 线程池的线程数可达到Integer.MAX_VALUE，即2147483647，内部使用SynchronousQueue作为阻塞队列； 和newFixedThreadPool创建的线程池不同，newCachedThreadPool在没有任务执行时，当线程的空闲时间超过keepAliveTime，会自动释放线程资源，当提交新任务时，如果没有空闲线程，则创建新线程执行任务，会导致一定的系统开销； 执行过程与前两种稍微不同: 主线程调用SynchronousQueue的offer()方法放入task, 倘若此时线程池中有空闲的线程尝试读取 SynchronousQueue的task, 即调用了SynchronousQueue的poll(), 那么主线程将该task交给空闲线程. 否则执行(2) 当线程池为空或者没有空闲的线程, 则创建新的线程执行任务. 执行完任务的线程倘若在60s内仍空闲, 则会被终止. 因此长时间空闲的CachedThreadPool不会持有任何线程资源. 关闭线程池遍历线程池中的所有线程，然后逐个调用线程的interrupt方法来中断线程. 关闭方式 - shutdown将线程池里的线程状态设置成SHUTDOWN状态, 然后中断所有没有正在执行任务的线程. 关闭方式 - shutdownNow将线程池里的线程状态设置成STOP状态, 然后停止所有正在执行或暂停任务的线程. 只要调用这两个关闭方法中的任意一个, isShutDown() 返回true. 当所有任务都成功关闭了, isTerminated()返回true. ThreadPoolExecutor源码详解几个关键属性1234567891011121314151617//这个属性是用来存放 当前运行的worker数量以及线程池状态的//int是32位的，这里把int的高3位拿来充当线程池状态的标志位,后29位拿来充当当前运行worker的数量private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//存放任务的阻塞队列private final BlockingQueue&lt;Runnable&gt; workQueue;//worker的集合,用set来存放private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;();//历史达到的worker数最大值private int largestPoolSize;//当队列满了并且worker的数量达到maxSize的时候,执行具体的拒绝策略private volatile RejectedExecutionHandler handler;//超出coreSize的worker的生存时间private volatile long keepAliveTime;//常驻worker的数量private volatile int corePoolSize;//最大worker的数量,一般当workQueue满了才会用到这个参数private volatile int maximumPoolSize; 内部状态123456789101112131415private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));private static final int COUNT_BITS = Integer.SIZE - 3;private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1;// runState is stored in the high-order bitsprivate static final int RUNNING = -1 &lt;&lt; COUNT_BITS;private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;private static final int STOP = 1 &lt;&lt; COUNT_BITS;private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;// Packing and unpacking ctlprivate static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 其中AtomicInteger变量ctl的功能非常强大: 利用低29位表示线程池中线程数，通过高3位表示线程池的运行状态: RUNNING: -1 &lt;&lt; COUNT_BITS，即高3位为111，该状态的线程池会接收新任务，并处理阻塞队列中的任务； SHUTDOWN: 0 &lt;&lt; COUNT_BITS，即高3位为000，该状态的线程池不会接收新任务，但会处理阻塞队列中的任务； STOP : 1 &lt;&lt; COUNT_BITS，即高3位为001，该状态的线程不会接收新任务，也不会处理阻塞队列中的任务，而且会中断正在运行的任务； TIDYING : 2 &lt;&lt; COUNT_BITS，即高3位为010, 所有的任务都已经终止； TERMINATED: 3 &lt;&lt; COUNT_BITS，即高3位为011, terminated()方法已经执行完成 任务的执行 execute –&gt; addWorker –&gt;runworker (getTask) 线程池的工作线程通过Woker类实现，在ReentrantLock锁的保证下，把Woker实例插入到HashSet后，并启动Woker中的线程。 从Woker类的构造方法实现可以发现: 线程工厂在创建线程thread时，将Woker实例本身this作为参数传入，当执行start方法启动线程thread时，本质是执行了Worker的runWorker方法。 firstTask执行完成之后，通过getTask方法从阻塞队列中获取等待的任务，如果队列中没有任务，getTask方法会被阻塞并挂起，不会占用cpu资源； execute()方法ThreadPoolExecutor.execute(task)实现了Executor.execute(task) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); /* * Proceed in 3 steps: * * 1. If fewer than corePoolSize threads are running, try to * start a new thread with the given command as its first * task. The call to addWorker atomically checks runState and * workerCount, and so prevents false alarms that would add * threads when it shouldn&#x27;t, by returning false. * * 2. If a task can be successfully queued, then we still need * to double-check whether we should have added a thread * (because existing ones died since last checking) or that * the pool shut down since entry into this method. So we * recheck state and if necessary roll back the enqueuing if * stopped, or start a new thread if there are none. * * 3. If we cannot queue task, then we try to add a new * thread. If it fails, we know we are shut down or saturated * and so reject the task. */ int c = ctl.get(); if (workerCountOf(c) &lt; corePoolSize) &#123; //workerCountOf获取线程池的当前线程数；小于corePoolSize，执行addWorker创建新线程执行command任务 if (addWorker(command, true)) return; c = ctl.get(); &#125; // double check: c, recheck // 线程池处于RUNNING状态，把提交的任务成功放入阻塞队列中 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // recheck and if necessary 回滚到入队操作前，即倘若线程池shutdown状态，就remove(command) //如果线程池没有RUNNING，成功从阻塞队列中删除任务，执行reject方法处理任务 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //线程池处于running状态，但是没有线程，则创建线程 else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; // 往线程池中创建新的线程失败，则reject任务 else if (!addWorker(command, false)) reject(command);&#125; 为什么需要double check线程池的状态? 在多线程环境下，线程池的状态时刻在变化，而ctl.get()是非原子操作，很有可能刚获取了线程池状态后线程池状态就改变了。判断是否将command加入workque是线程池之前的状态。倘若没有double check，万一线程池处于非running状态(在多线程环境下很有可能发生)，那么command永远不会执行。 addWorker方法从方法execute的实现可以看出: addWorker主要负责创建新的线程并执行任务 线程池创建新线程执行任务时，需要 获取全局锁: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869private final ReentrantLock mainLock = new ReentrantLock();private boolean addWorker(Runnable firstTask, boolean core) &#123; // CAS更新线程池数量 retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; // 线程池重入锁 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); // 线程启动，执行任务(Worker.thread(firstTask).start()); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; Worker类的runworker方法123456789101112private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); // 创建线程 &#125; /** Delegates main run loop to outer runWorker */ public void run() &#123; runWorker(this); &#125; // ...&#125; 继承了AQS类，可以方便的实现工作线程的中止操作； 实现了Runnable接口，可以将自身作为一个任务在工作线程中执行； 当前提交的任务firstTask作为参数传入Worker的构造方法； 一些属性还有构造方法: 12345678910111213//运行的线程,前面addWorker方法中就是直接通过启动这个线程来启动这个workerfinal Thread thread;//当一个worker刚创建的时候,就先尝试执行这个任务Runnable firstTask;//记录完成任务的数量volatile long completedTasks;Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; //创建一个Thread,将自己设置给他,后面这个thread启动的时候,也就是执行worker的run方法 this.thread = getThreadFactory().newThread(this);&#125; runWorker方法是线程池的核心: 线程启动之后，通过unlock方法释放锁，设置AQS的state为0，表示运行可中断； Worker执行firstTask或从workQueue中获取任务: 进行加锁操作，保证thread不被其他线程中断(除非线程池被中断) 检查线程池状态，倘若线程池处于中断状态，当前线程将中断。 执行beforeExecute 执行任务的run方法 执行afterExecute方法 解锁操作 通过getTask方法从阻塞队列中获取等待的任务，如果队列中没有任务，getTask方法会被阻塞并挂起，不会占用cpu资源； 123456789101112131415161718192021222324252627282930313233343536373839404142434445final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; // 先执行firstTask，再从workerQueue中取task(getTask()) while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask方法下面来看一下getTask()方法，这里面涉及到keepAliveTime的使用，从这个方法我们可以看出线程池是怎么让超过corePoolSize的那部分worker销毁的。 12345678910111213141516171819202122232425262728293031323334353637private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125; 注意这里一段代码是keepAliveTime起作用的关键: 1234boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize;Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); allowCoreThreadTimeOut为false，线程即使空闲也不会被销毁；倘若为ture，在keepAliveTime内仍空闲则会被销毁。 如果线程允许空闲等待而不被销毁timed &#x3D;&#x3D; false，workQueue.take任务: 如果阻塞队列为空，当前线程会被挂起等待；当队列中有任务加入时，线程被唤醒，take方法返回任务，并执行； 如果线程不允许无休止空闲timed &#x3D;&#x3D; true, workQueue.poll任务: 如果在keepAliveTime时间内，阻塞队列还是没有任务，则返回null； 任务的提交 submit任务，等待线程池execute 执行FutureTask类的get方法时，会把主线程封装成WaitNode节点并保存在waiters链表中， 并阻塞等待运行结果； FutureTask任务执行完成后，通过UNSAFE设置waiters相应的waitNode为null，并通过LockSupport类unpark方法唤醒主线程； 1234567891011121314151617181920212223public class Test&#123; public static void main(String[] args) &#123; ExecutorService es = Executors.newCachedThreadPool(); Future&lt;String&gt; future = es.submit(new Callable&lt;String&gt;() &#123; @Override public String call() throws Exception &#123; try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; return &quot;future result&quot;; &#125; &#125;); try &#123; String result = future.get(); System.out.println(result); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 在实际业务场景中，Future和Callable基本是成对出现的，Callable负责产生结果，Future负责获取结果。 Callable接口类似于Runnable，只是Runnable没有返回值。 Callable任务除了返回正常结果之外，如果发生异常，该异常也会被返回，即Future可以拿到异步执行任务各种结果； Future.get方法会导致主线程阻塞，直到Callable任务执行完成； submit方法AbstractExecutorService.submit()实现了ExecutorService.submit() 可以获取执行完的返回值, 而ThreadPoolExecutor 是AbstractExecutorService.submit()的子类，所以submit方法也是ThreadPoolExecutor&#96;的方法。 1234567891011121314// submit()在ExecutorService中的定义&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task);// submit方法在AbstractExecutorService中的实现public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); // 通过submit方法提交的Callable任务会被封装成了一个FutureTask对象。 RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask;&#125; 通过submit方法提交的Callable任务会被封装成了一个FutureTask对象。通过Executor.execute方法提交FutureTask到线程池中等待被执行，最终执行的是FutureTask的run方法； FutureTask对象public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 可以将FutureTask提交至线程池中等待被执行(通过FutureTask的run方法来执行) 内部状态 12345678910111213141516/* The run state of this task, initially NEW. * ... * Possible state transitions: * NEW -&gt; COMPLETING -&gt; NORMAL * NEW -&gt; COMPLETING -&gt; EXCEPTIONAL * NEW -&gt; CANCELLED * NEW -&gt; INTERRUPTING -&gt; INTERRUPTED */private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 内部状态的修改通过sun.misc.Unsafe修改 get方法 123456public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; 内部通过awaitDone方法对主线程进行阻塞，具体实现如下: 1234567891011121314151617181920212223242526272829303132333435private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123; if (Thread.interrupted()) &#123; removeWaiter(q); throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null; return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) queued = UNSAFE.compareAndSwapObject(this, waitersOffset,q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q); return state; &#125; LockSupport.parkNanos(this, nanos); &#125; else LockSupport.park(this); &#125;&#125; 如果主线程被中断，则抛出中断异常； 判断FutureTask当前的state，如果大于COMPLETING，说明任务已经执行完成，则直接返回； 如果当前state等于COMPLETING，说明任务已经执行完，这时主线程只需通过yield方法让出cpu资源，等待state变成NORMAL； 通过WaitNode类封装当前线程，并通过UNSAFE添加到waiters链表； 最终通过LockSupport的park或parkNanos挂起线程； run方法 123456789101112131415161718192021222324252627282930public void run() &#123; if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result); &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; FutureTask.run方法是在线程池中被执行的，而非主线程 通过执行Callable任务的call方法； 如果call执行成功，则通过set方法保存结果； 如果call执行有异常，则通过setException保存异常； 任务的关闭shutdown方法会将线程池的状态设置为SHUTDOWN,线程池进入这个状态后,就拒绝再接受任务,然后会将剩余的任务全部执行完 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public void shutdown() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //检查是否可以关闭线程 checkShutdownAccess(); //设置线程池状态 advanceRunState(SHUTDOWN); //尝试中断worker interruptIdleWorkers(); //预留方法,留给子类实现 onShutdown(); // hook for ScheduledThreadPoolExecutor &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate();&#125;private void interruptIdleWorkers() &#123; interruptIdleWorkers(false);&#125;private void interruptIdleWorkers(boolean onlyOne) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //遍历所有的worker for (Worker w : workers) &#123; Thread t = w.thread; //先尝试调用w.tryLock(),如果获取到锁,就说明worker是空闲的,就可以直接中断它 //注意的是,worker自己本身实现了AQS同步框架,然后实现的类似锁的功能 //它实现的锁是不可重入的,所以如果worker在执行任务的时候,会先进行加锁,这里tryLock()就会返回false if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; mainLock.unlock(); &#125;&#125; shutdownNow做的比较绝，它先将线程池状态设置为STOP，然后拒绝所有提交的任务。最后中断左右正在运行中的worker,然后清空任务队列。 123456789101112131415161718192021222324252627282930public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); //检测权限 advanceRunState(STOP); //中断所有的worker interruptWorkers(); //清空任务队列 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks;&#125;private void interruptWorkers() &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //遍历所有worker，然后调用中断方法 for (Worker w : workers) w.interruptIfStarted(); &#125; finally &#123; mainLock.unlock(); &#125;&#125; 更深入理解为什么线程池不允许使用Executors去创建? 推荐方式是什么?线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 说明：Executors各个方法的弊端： newFixedThreadPool和newSingleThreadExecutor: 主要问题是堆积的请求处理队列可能会耗费非常大的内存，甚至OOM。 newCachedThreadPool和newScheduledThreadPool: 主要问题是线程数最大数是Integer.MAX_VALUE，可能会创建数量非常多的线程，甚至OOM。 推荐方式 1首先引入：commons-lang3包 12ScheduledExecutorService executorService = new ScheduledThreadPoolExecutor(1, new BasicThreadFactory.Builder().namingPattern(&quot;example-schedule-pool-%d&quot;).daemon(true).build()); 推荐方式 2首先引入：com.google.guava包 12345678910ThreadFactory namedThreadFactory = new ThreadFactoryBuilder().setNameFormat(&quot;demo-pool-%d&quot;).build();//Common Thread PoolExecutorService pool = new ThreadPoolExecutor(5, 200, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(1024), namedThreadFactory, new ThreadPoolExecutor.AbortPolicy());// excutepool.execute(()-&gt; System.out.println(Thread.currentThread().getName())); //gracefully shutdownpool.shutdown(); 推荐方式 3spring配置线程池方式：自定义线程工厂bean需要实现ThreadFactory，可参考该接口的其它默认实现类，使用方式直接注入bean调用execute(Runnable task)方法即可 12345678910111213&lt;bean id=&quot;userThreadPool&quot; class=&quot;org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor&quot;&gt; &lt;property name=&quot;corePoolSize&quot; value=&quot;10&quot; /&gt; &lt;property name=&quot;maxPoolSize&quot; value=&quot;100&quot; /&gt; &lt;property name=&quot;queueCapacity&quot; value=&quot;2000&quot; /&gt;&lt;property name=&quot;threadFactory&quot; value= threadFactory /&gt; &lt;property name=&quot;rejectedExecutionHandler&quot;&gt; &lt;ref local=&quot;rejectedExecutionHandler&quot; /&gt; &lt;/property&gt;&lt;/bean&gt;//in codeuserThreadPool.execute(thread); 配置线程池需要考虑因素从任务的优先级，任务的执行时间长短，任务的性质(CPU密集&#x2F; IO密集)，任务的依赖关系这四个角度来分析。并且近可能地使用有界的工作队列。 性质不同的任务可用使用不同规模的线程池分开处理: CPU密集型: 尽可能少的线程，Ncpu+1 IO密集型: 尽可能多的线程, Ncpu*2，比如数据库连接池 混合型: CPU密集型的任务与IO密集型任务的执行时间差别较小，拆分为两个线程池；否则没有必要拆分。 监控线程池的状态可以使用ThreadPoolExecutor以下方法: getTaskCount() Returns the approximate total number of tasks that have ever been scheduled for execution. getCompletedTaskCount() Returns the approximate total number of tasks that have completed execution. 返回结果少于getTaskCount()。 getLargestPoolSize() Returns the largest number of threads that have ever simultaneously been in the pool. 返回结果小于等于maximumPoolSize getPoolSize() Returns the current number of threads in the pool. getActiveCount() Returns the approximate number of threads that are actively executing tasks. 参考文章 《Java并发编程艺术》 https://www.jianshu.com/p/87bff5cc8d8c https://blog.csdn.net/programmer_at/article/details/79799267 https://blog.csdn.net/u013332124/article/details/79587436 https://www.journaldev.com/1069/threadpoolexecutor-java-thread-pool-example-executorservice","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"18.JUC线程池: FutureTask详解","path":"/2023/12/26/18-JUC线程池-FutureTask详解/","content":"Future 表示了一个任务的生命周期，是一个可取消的异步运算，可以把它看作是一个异步操作的结果的占位符，它将在未来的某个时刻完成，并提供对其结果的访问。在并发包中许多异步任务类都继承自Future，其中最典型的就是 FutureTask。 带着BAT大厂的面试问题去理解FutureTask 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解FutureTask。 FutureTask用来解决什么问题的? 为什么会出现? FutureTask类结构关系怎么样的? FutureTask的线程安全是由什么保证的? FutureTask结果返回机制? FutureTask内部运行状态的转变? FutureTask通常会怎么用? 举例说明。 FutureTask简介FutureTask 为 Future 提供了基础实现，如获取任务执行结果(get)和取消任务(cancel)等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消(除非使用runAndReset执行计算)。FutureTask 常用来封装 Callable 和 Runnable，也可以作为一个任务提交到线程池中执行。除了作为一个独立的类之外，此类也提供了一些功能性函数供我们创建自定义 task 类使用。FutureTask 的线程安全由CAS来保证。 FutureTask类关系 可以看到,FutureTask实现了RunnableFuture接口，则RunnableFuture接口继承了Runnable接口和Future接口，所以FutureTask既能当做一个Runnable直接被Thread执行，也能作为Future用来得到Callable的计算结果。 FutureTask源码解析Callable接口Callable是个泛型接口，泛型V就是要call()方法返回的类型。对比Runnable接口，Runnable不会返回数据也不能抛出异常。 123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; Future接口Future接口代表异步计算的结果，通过Future接口提供的方法可以查看异步计算是否执行完成，或者等待执行结果并获取执行结果，同时还可以取消执行。Future接口的定义如下: 12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; cancel():cancel()方法用来取消异步任务的执行。如果异步任务已经完成或者已经被取消，或者由于某些原因不能取消，则会返回false。如果任务还没有被执行，则会返回true并且异步任务不会被执行。如果任务已经开始执行了但是还没有执行完成，若mayInterruptIfRunning为true，则会立即中断执行任务的线程并返回true，若mayInterruptIfRunning为false，则会返回true且不会中断任务执行线程。 isCanceled():判断任务是否被取消，如果任务在结束(正常执行结束或者执行异常结束)前被取消则返回true，否则返回false。 isDone():判断任务是否已经完成，如果完成则返回true，否则返回false。需要注意的是：任务执行过程中发生异常、任务被取消也属于任务已完成，也会返回true。 get():获取任务执行结果，如果任务还没完成则会阻塞等待直到任务执行完成。如果任务被取消则会抛出CancellationException异常，如果任务执行过程发生异常则会抛出ExecutionException异常，如果阻塞等待过程中被中断则会抛出InterruptedException异常。 get(long timeout,Timeunit unit):带超时时间的get()版本，如果阻塞等待过程中超时则会抛出TimeoutException异常。 核心属性123456789101112131415161718192021//内部持有的callable任务，运行完毕后置空private Callable&lt;V&gt; callable;//从get()中返回的结果或抛出的异常private Object outcome; // non-volatile, protected by state reads/writes//运行callable的线程private volatile Thread runner;//使用Treiber栈保存等待线程private volatile WaitNode waiters;//任务状态private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; 其中需要注意的是state是volatile类型的，也就是说只要有任何一个线程修改了这个变量，那么其他所有的线程都会知道最新的值。7种状态具体表示： NEW:表示是个新的任务或者还没被执行完的任务。这是初始状态。 COMPLETING:任务已经执行完成或者执行任务的时候发生异常，但是任务执行结果或者异常原因还没有保存到outcome字段(outcome字段用来保存任务执行结果，如果发生异常，则用来保存异常原因)的时候，状态会从NEW变更到COMPLETING。但是这个状态会时间会比较短，属于中间状态。 NORMAL:任务已经执行完成并且任务执行结果已经保存到outcome字段，状态会从COMPLETING转换到NORMAL。这是一个最终态。 EXCEPTIONAL:任务执行发生异常并且异常原因已经保存到outcome字段中后，状态会从COMPLETING转换到EXCEPTIONAL。这是一个最终态。 CANCELLED:任务还没开始执行或者已经开始执行但是还没有执行完成的时候，用户调用了cancel(false)方法取消任务且不中断任务执行线程，这个时候状态会从NEW转化为CANCELLED状态。这是一个最终态。 INTERRUPTING: 任务还没开始执行或者已经执行但是还没有执行完成的时候，用户调用了cancel(true)方法取消任务并且要中断任务执行线程但是还没有中断任务执行线程之前，状态会从NEW转化为INTERRUPTING。这是一个中间状态。 INTERRUPTED:调用interrupt()中断任务执行线程之后状态会从INTERRUPTING转换到INTERRUPTED。这是一个最终态。 有一点需要注意的是，所有值大于COMPLETING的状态都表示任务已经执行完成(任务正常执行完成，任务执行异常或者任务被取消)。 各个状态之间的可能转换关系如下图所示: 构造函数 FutureTask(Callable callable) 123456public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; // ensure visibility of callable&#125; 这个构造函数会把传入的Callable变量保存在this.callable字段中，该字段定义为private Callable&lt;V&gt; callable;用来保存底层的调用，在被执行完成以后会指向null,接着会初始化state字段为NEW。 FutureTask(Runnable runnable, V result) 1234public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; // ensure visibility of callable&#125; 这个构造函数会把传入的Runnable封装成一个Callable对象保存在callable字段中，同时如果任务执行成功的话就会返回传入的result。这种情况下如果不需要返回值的话可以传入一个null。 顺带看下Executors.callable()这个方法，这个方法的功能是把Runnable转换成Callable，代码如下: 12345public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125; 可以看到这里采用的是适配器模式，调用RunnableAdapter&lt;T&gt;(task, result)方法来适配，实现如下: 123456789101112static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; final Runnable task; final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; public T call() &#123; task.run(); return result; &#125;&#125; 这个适配器很简单，就是简单的实现了Callable接口，在call()实现中调用Runnable.run()方法，然后把传入的result作为任务的结果返回。 在new了一个FutureTask对象之后，接下来就是在另一个线程中执行这个Task,无论是通过直接new一个Thread还是通过线程池，执行的都是run()方法，接下来就看看run()方法的实现。 核心方法 - run()123456789101112131415161718192021222324252627282930313233public void run() &#123; //新建任务，CAS替换runner为当前线程 if (state != NEW || !UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; result = null; ran = false; setException(ex); &#125; if (ran) set(result);//设置执行结果 &#125; &#125; finally &#123; // runner must be non-null until state is settled to // prevent concurrent calls to run() runner = null; // state must be re-read after nulling runner to prevent // leaked interrupts int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s);//处理中断逻辑 &#125;&#125; 说明： 运行任务，如果任务状态为NEW状态，则利用CAS修改为当前线程。执行完毕调用set(result)方法设置执行结果。set(result)源码如下： 1234567protected void set(V v) &#123; if (UNSAFE.compareAndSwapInt(this, stateOffset, NEW, COMPLETING)) &#123; outcome = v; UNSAFE.putOrderedInt(this, stateOffset, NORMAL); // final state finishCompletion();//执行完毕，唤醒等待线程 &#125;&#125; 首先利用cas修改state状态为COMPLETING，设置返回结果，然后使用 lazySet(UNSAFE.putOrderedInt)的方式设置state状态为NORMAL。结果设置完毕后，调用finishCompletion()方法唤醒等待线程，源码如下： 123456789101112131415161718192021222324private void finishCompletion() &#123; // assert state &gt; COMPLETING; for (WaitNode q; (q = waiters) != null;) &#123; if (UNSAFE.compareAndSwapObject(this, waitersOffset, q, null)) &#123;//移除等待线程 for (;;) &#123;//自旋遍历等待线程 Thread t = q.thread; if (t != null) &#123; q.thread = null; LockSupport.unpark(t);//唤醒等待线程 &#125; WaitNode next = q.next; if (next == null) break; q.next = null; // unlink to help gc q = next; &#125; break; &#125; &#125; //任务完成后调用函数，自定义扩展 done(); callable = null; // to reduce footprint&#125; 回到run方法，如果在 run 期间被中断，此时需要调用handlePossibleCancellationInterrupt方法来处理中断逻辑，确保任何中断(例如cancel(true))只停留在当前run或runAndReset的任务中，源码如下： 123456private void handlePossibleCancellationInterrupt(int s) &#123; //在中断者中断线程之前可能会延迟，所以我们只需要让出CPU时间片自旋等待 if (s == INTERRUPTING) while (state == INTERRUPTING) Thread.yield(); // wait out pending interrupt&#125; 核心方法 - get()1234567//获取执行结果public V get() throws InterruptedException, ExecutionException &#123; int s = state; if (s &lt;= COMPLETING) s = awaitDone(false, 0L); return report(s);&#125; 说明：FutureTask 通过get()方法获取任务执行结果。如果任务处于未完成的状态(state &lt;= COMPLETING)，就调用awaitDone方法(后面单独讲解)等待任务完成。任务完成后，通过report方法获取执行结果或抛出执行期间的异常。report源码如下： 123456789//返回执行结果或抛出异常private V report(int s) throws ExecutionException &#123; Object x = outcome; if (s == NORMAL) return (V)x; if (s &gt;= CANCELLED) throw new CancellationException(); throw new ExecutionException((Throwable)x);&#125; 核心方法 - awaitDone(boolean timed, long nanos)12345678910111213141516171819202122232425262728293031323334353637private int awaitDone(boolean timed, long nanos) throws InterruptedException &#123; final long deadline = timed ? System.nanoTime() + nanos : 0L; WaitNode q = null; boolean queued = false; for (;;) &#123;//自旋 if (Thread.interrupted()) &#123;//获取并清除中断状态 removeWaiter(q);//移除等待WaitNode throw new InterruptedException(); &#125; int s = state; if (s &gt; COMPLETING) &#123; if (q != null) q.thread = null;//置空等待节点的线程 return s; &#125; else if (s == COMPLETING) // cannot time out yet Thread.yield(); else if (q == null) q = new WaitNode(); else if (!queued) //CAS修改waiter queued = UNSAFE.compareAndSwapObject(this, waitersOffset, q.next = waiters, q); else if (timed) &#123; nanos = deadline - System.nanoTime(); if (nanos &lt;= 0L) &#123; removeWaiter(q);//超时，移除等待节点 return state; &#125; LockSupport.parkNanos(this, nanos);//阻塞当前线程 &#125; else LockSupport.park(this);//阻塞当前线程 &#125;&#125; 说明：awaitDone用于等待任务完成，或任务因为中断或超时而终止。返回任务的完成状态。函数执行逻辑如下： 如果线程被中断，首先清除中断状态，调用removeWaiter移除等待节点，然后抛出InterruptedException。removeWaiter源码如下： 12345678910111213141516171819202122private void removeWaiter(WaitNode node) &#123; if (node != null) &#123; node.thread = null;//首先置空线程 retry: for (;;) &#123; // restart on removeWaiter race //依次遍历查找 for (WaitNode pred = null, q = waiters, s; q != null; q = s) &#123; s = q.next; if (q.thread != null) pred = q; else if (pred != null) &#123; pred.next = s; if (pred.thread == null) // check for race continue retry; &#125; else if (!UNSAFE.compareAndSwapObject(this, waitersOffset,q, s)) //cas替换 continue retry; &#125; break; &#125; &#125;&#125; 如果当前状态为结束状态(state&gt;COMPLETING),则根据需要置空等待节点的线程，并返回 Future 状态； 如果当前状态为正在完成(COMPLETING)，说明此时 Future 还不能做出超时动作，为任务让出CPU执行时间片； 如果state为NEW，先新建一个WaitNode，然后CAS修改当前waiters； 如果等待超时，则调用removeWaiter移除等待节点，返回任务状态；如果设置了超时时间但是尚未超时，则park阻塞当前线程； 其他情况直接阻塞当前线程。 核心方法 - cancel(boolean mayInterruptIfRunning)123456789101112131415161718192021public boolean cancel(boolean mayInterruptIfRunning) &#123; //如果当前Future状态为NEW，根据参数修改Future状态为INTERRUPTING或CANCELLED if (!(state == NEW &amp;&amp; UNSAFE.compareAndSwapInt(this, stateOffset, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try &#123; // in case call to interrupt throws exception if (mayInterruptIfRunning) &#123;//可以在运行时中断 try &#123; Thread t = runner; if (t != null) t.interrupt(); &#125; finally &#123; // final state UNSAFE.putOrderedInt(this, stateOffset, INTERRUPTED); &#125; &#125; &#125; finally &#123; finishCompletion();//移除并唤醒所有等待线程 &#125; return true;&#125; 说明：尝试取消任务。如果任务已经完成或已经被取消，此操作会失败。 如果当前Future状态为NEW，根据参数修改Future状态为INTERRUPTING或CANCELLED。 如果当前状态不为NEW，则根据参数mayInterruptIfRunning决定是否在任务运行中也可以中断。中断操作完成后，调用finishCompletion移除并唤醒所有等待线程。 FutureTask示例常用使用方式： 第一种方式: Future + ExecutorService 第二种方式: FutureTask + ExecutorService 第三种方式: FutureTask + Thread Future使用示例123456789101112131415161718192021222324public class FutureDemo &#123; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); Future future = executorService.submit(new Callable&lt;Object&gt;() &#123; @Override public Object call() throws Exception &#123; Long start = System.currentTimeMillis(); while (true) &#123; Long current = System.currentTimeMillis(); if ((current - start) &gt; 1000) &#123; return 1; &#125; &#125; &#125; &#125;); try &#123; Integer result = (Integer)future.get(); System.out.println(result); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125;&#125; FutureTask+Thread例子1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980import java.util.concurrent.*; public class CallDemo &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; /** * 第一种方式:Future + ExecutorService * Task task = new Task(); * ExecutorService service = Executors.newCachedThreadPool(); * Future&lt;Integer&gt; future = service.submit(task1); * service.shutdown(); */ /** * 第二种方式: FutureTask + ExecutorService * ExecutorService executor = Executors.newCachedThreadPool(); * Task task = new Task(); * FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); * executor.submit(futureTask); * executor.shutdown(); */ /** * 第三种方式:FutureTask + Thread */ // 2. 新建FutureTask,需要一个实现了Callable接口的类的实例作为构造函数参数 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(new Task()); // 3. 新建Thread对象并启动 Thread thread = new Thread(futureTask); thread.setName(&quot;Task thread&quot;); thread.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;Thread [&quot; + Thread.currentThread().getName() + &quot;] is running&quot;); // 4. 调用isDone()判断任务是否结束 if(!futureTask.isDone()) &#123; System.out.println(&quot;Task is not done&quot;); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; int result = 0; try &#123; // 5. 调用get()方法获取任务结果,如果任务没有执行完成则阻塞等待 result = futureTask.get(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;result is &quot; + result); &#125; // 1. 继承Callable接口,实现call()方法,泛型参数为要返回的类型 static class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(&quot;Thread [&quot; + Thread.currentThread().getName() + &quot;] is running&quot;); int result = 0; for(int i = 0; i &lt; 100;++i) &#123; result += i; &#125; Thread.sleep(3000); return result; &#125; &#125;&#125; 参考文章 本文主要参考了https://www.cnblogs.com/linghu-java/p/8991824.html以及https://www.jianshu.com/p/d61d7ffa6abc，在此基础上增改 https://blog.csdn.net/xingzhong128/article/details/80553789","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"17.JUC集合: BlockingQueue详解","path":"/2023/12/26/17-JUC集合-BlockingQueue详解/","content":"JUC里的 BlockingQueue 接口表示一个线程安放入和提取实例的队列。本文将给你演示如何使用这个 BlockingQueue，不会讨论如何在 Java 中实现一个你自己的 BlockingQueue。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 什么是BlockingDeque? BlockingQueue大家族有哪些? ArrayBlockingQueue, DelayQueue, LinkedBlockingQueue, SynchronousQueue… BlockingQueue适合用在什么样的场景? BlockingQueue常用的方法? BlockingQueue插入方法有哪些? 这些方法(add(o),offer(o),put(o),offer(o, timeout, timeunit))的区别是什么? BlockingDeque 与BlockingQueue有何关系，请对比下它们的方法? BlockingDeque适合用在什么样的场景? BlockingDeque大家族有哪些? BlockingDeque 与BlockingQueue实现例子? BlockingQueue和BlockingDequeBlockingQueueBlockingQueue 通常用于一个线程生产对象，而另外一个线程消费这些对象的场景。下图是对这个原理的阐述: 一个线程往里边放，另外一个线程从里边取的一个 BlockingQueue。 一个线程将会持续生产新对象并将其插入到队列之中，直到队列达到它所能容纳的临界点。也就是说，它是有限的。如果该阻塞队列到达了其临界点，负责生产的线程将会在往里边插入新对象时发生阻塞。它会一直处于阻塞之中，直到负责消费的线程从队列中拿走一个对象。 负责消费的线程将会一直从该阻塞队列中拿出对象。如果消费线程尝试去从一个空的队列中提取对象的话，这个消费线程将会处于阻塞之中，直到一个生产线程把一个对象丢进队列。 BlockingQueue 的方法BlockingQueue 具有 4 组不同的方法用于插入、移除以及对队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下: 抛异常 特定值 阻塞 超时 插入 add(o) offer(o) put(o) offer(o, timeout, timeunit) 移除 remove() poll() take() poll(timeout, timeunit) 检查 element() peek() 四组不同的行为方式解释: 抛异常: 如果试图的操作无法立即执行，抛一个异常。 特定值: 如果试图的操作无法立即执行，返回一个特定的值(常常是 true &#x2F; false)。 阻塞: 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。 超时: 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true &#x2F; false)。 无法向一个 BlockingQueue 中插入 null。如果你试图插入 null，BlockingQueue 将会抛出一个 NullPointerException。 可以访问到 BlockingQueue 中的所有元素，而不仅仅是开始和结束的元素。比如说，你将一个对象放入队列之中以等待处理，但你的应用想要将其取消掉。那么你可以调用诸如 remove(o) 方法来将队列之中的特定对象进行移除。但是这么干效率并不高(译者注: 基于队列的数据结构，获取除开始或结束位置的其他对象的效率不会太高)，因此你尽量不要用这一类的方法，除非你确实不得不那么做。 BlockingDequejava.util.concurrent 包里的 BlockingDeque 接口表示一个线程安放入和提取实例的双端队列。 BlockingDeque 类是一个双端队列，在不能够插入元素时，它将阻塞住试图插入元素的线程；在不能够抽取元素时，它将阻塞住试图抽取的线程。 deque(双端队列) 是 “Double Ended Queue” 的缩写。因此，双端队列是一个你可以从任意一端插入或者抽取元素的队列。 在线程既是一个队列的生产者又是这个队列的消费者的时候可以使用到 BlockingDeque。如果生产者线程需要在队列的两端都可以插入数据，消费者线程需要在队列的两端都可以移除数据，这个时候也可以使用 BlockingDeque。BlockingDeque 图解: BlockingDeque 的方法一个 BlockingDeque - 线程在双端队列的两端都可以插入和提取元素。 一个线程生产元素，并把它们插入到队列的任意一端。如果双端队列已满，插入线程将被阻塞，直到一个移除线程从该队列中移出了一个元素。如果双端队列为空，移除线程将被阻塞，直到一个插入线程向该队列插入了一个新元素。 BlockingDeque 具有 4 组不同的方法用于插入、移除以及对双端队列中的元素进行检查。如果请求的操作不能得到立即执行的话，每个方法的表现也不同。这些方法如下: 抛异常 特定值 阻塞 超时 插入 addFirst(o) offerFirst(o) putFirst(o) offerFirst(o, timeout, timeunit) 移除 removeFirst(o) pollFirst(o) takeFirst(o) pollFirst(timeout, timeunit) 检查 getFirst(o) peekFirst(o) 抛异常 特定值 阻塞 超时 插入 addLast(o) offerLast(o) putLast(o) offerLast(o, timeout, timeunit) 移除 removeLast(o) pollLast(o) takeLast(o) pollLast(timeout, timeunit) 检查 getLast(o) peekLast(o) 四组不同的行为方式解释: 抛异常: 如果试图的操作无法立即执行，抛一个异常。 特定值: 如果试图的操作无法立即执行，返回一个特定的值(常常是 true &#x2F; false)。 阻塞: 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。 超时: 如果试图的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会超过给定值。返回一个特定值以告知该操作是否成功(典型的是 true &#x2F; false)。 BlockingDeque 与BlockingQueue关系BlockingDeque 接口继承自 BlockingQueue 接口。这就意味着你可以像使用一个 BlockingQueue 那样使用 BlockingDeque。如果你这么干的话，各种插入方法将会把新元素添加到双端队列的尾端，而移除方法将会把双端队列的首端的元素移除。正如 BlockingQueue 接口的插入和移除方法一样。 以下是 BlockingDeque 对 BlockingQueue 接口的方法的具体内部实现: BlockingQueue BlockingDeque add() addLast() offer() x 2 offerLast() x 2 put() putLast() remove() removeFirst() poll() x 2 pollFirst() take() takeFirst() element() getFirst() peek() peekFirst() BlockingQueue 的例子这里是一个 Java 中使用 BlockingQueue 的示例。本示例使用的是 BlockingQueue 接口的 ArrayBlockingQueue 实现。 首先，BlockingQueueExample 类分别在两个独立的线程中启动了一个 Producer 和 一个 Consumer。Producer 向一个共享的 BlockingQueue 中注入字符串，而 Consumer 则会从中把它们拿出来。 123456789101112131415public class BlockingQueueExample &#123; public static void main(String[] args) throws Exception &#123; BlockingQueue queue = new ArrayBlockingQueue(1024); Producer producer = new Producer(queue); Consumer consumer = new Consumer(queue); new Thread(producer).start(); new Thread(consumer).start(); Thread.sleep(4000); &#125;&#125; 以下是 Producer 类。注意它在每次 put() 调用时是如何休眠一秒钟的。这将导致 Consumer 在等待队列中对象的时候发生阻塞。 1234567891011121314151617181920public class Producer implements Runnable&#123; protected BlockingQueue queue = null; public Producer(BlockingQueue queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; queue.put(&quot;1&quot;); Thread.sleep(1000); queue.put(&quot;2&quot;); Thread.sleep(1000); queue.put(&quot;3&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 以下是 Consumer 类。它只是把对象从队列中抽取出来，然后将它们打印到 System.out。 123456789101112131415161718public class Consumer implements Runnable&#123; protected BlockingQueue queue = null; public Consumer(BlockingQueue queue) &#123; this.queue = queue; &#125; public void run() &#123; try &#123; System.out.println(queue.take()); System.out.println(queue.take()); System.out.println(queue.take()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 数组阻塞队列 ArrayBlockingQueueArrayBlockingQueue 类实现了 BlockingQueue 接口。 ArrayBlockingQueue 是一个有界的阻塞队列，其内部实现是将对象放到一个数组里。有界也就意味着，它不能够存储无限多数量的元素。它有一个同一时间能够存储元素数量的上限。你可以在对其初始化的时候设定这个上限，但之后就无法对这个上限进行修改了(译者注: 因为它是基于数组实现的，也就具有数组的特性: 一旦初始化，大小就无法修改)。 ArrayBlockingQueue 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个，而尾元素则是最短的那个。 以下是在使用 ArrayBlockingQueue 的时候对其初始化的一个示例: 123BlockingQueue queue = new ArrayBlockingQueue(1024);queue.put(&quot;1&quot;);Object object = queue.take(); 以下是使用了 Java 泛型的一个 BlockingQueue 示例。注意其中是如何对 String 元素放入和提取的: 123BlockingQueue&lt;String&gt; queue = new ArrayBlockingQueue&lt;String&gt;(1024);queue.put(&quot;1&quot;);String string = queue.take(); 延迟队列 DelayQueueDelayQueue 实现了 BlockingQueue 接口。 DelayQueue 对元素进行持有直到一个特定的延迟到期。注入其中的元素必须实现 java.util.concurrent.Delayed 接口，该接口定义: 123public interface Delayed extends Comparable&lt;Delayed&lt; &#123; public long getDelay(TimeUnit timeUnit);&#125; DelayQueue 将会在每个元素的 getDelay() 方法返回的值的时间段之后才释放掉该元素。如果返回的是 0 或者负值，延迟将被认为过期，该元素将会在 DelayQueue 的下一次 take 被调用的时候被释放掉。 传递给 getDelay 方法的 getDelay 实例是一个枚举类型，它表明了将要延迟的时间段。TimeUnit 枚举将会取以下值: DAYS HOURS INUTES SECONDS MILLISECONDS MICROSECONDS NANOSECONDS 正如你所看到的，Delayed 接口也继承了 java.lang.Comparable 接口，这也就意味着 Delayed 对象之间可以进行对比。这个可能在对 DelayQueue 队列中的元素进行排序时有用，因此它们可以根据过期时间进行有序释放。 以下是使用 DelayQueue 的例子: 123456789public class DelayQueueExample &#123; public static void main(String[] args) &#123; DelayQueue queue = new DelayQueue(); Delayed element1 = new DelayedElement(); queue.put(element1); Delayed element2 = queue.take(); &#125;&#125; DelayedElement 是我所创建的一个 DelayedElement 接口的实现类，它不在 java.util.concurrent 包里。你需要自行创建你自己的 Delayed 接口的实现以使用 DelayQueue 类。 链阻塞队列 LinkedBlockingQueueLinkedBlockingQueue 类实现了 BlockingQueue 接口。 LinkedBlockingQueue 内部以一个链式结构(链接节点)对其元素进行存储。如果需要的话，这一链式结构可以选择一个上限。如果没有定义上限，将使用 Integer.MAX_VALUE 作为上限。 LinkedBlockingQueue 内部以 FIFO(先进先出)的顺序对元素进行存储。队列中的头元素在所有元素之中是放入时间最久的那个，而尾元素则是最短的那个。 以下是 LinkedBlockingQueue 的初始化和使用示例代码: 1234BlockingQueue&lt;String&gt; unbounded = new LinkedBlockingQueue&lt;String&gt;();BlockingQueue&lt;String&gt; bounded = new LinkedBlockingQueue&lt;String&gt;(1024);bounded.put(&quot;Value&quot;);String value = bounded.take(); 具有优先级的阻塞队列 PriorityBlockingQueuePriorityBlockingQueue 类实现了 BlockingQueue 接口。 PriorityBlockingQueue 是一个无界的并发队列。它使用了和类 java.util.PriorityQueue 一样的排序规则。你无法向这个队列中插入 null 值。 所有插入到 PriorityBlockingQueue 的元素必须实现 java.lang.Comparable 接口。因此该队列中元素的排序就取决于你自己的 Comparable 实现。 注意 PriorityBlockingQueue 对于具有相等优先级(compare() &#x3D;&#x3D; 0)的元素并不强制任何特定行为。 同时注意，如果你从一个 PriorityBlockingQueue 获得一个 Iterator 的话，该 Iterator 并不能保证它对元素的遍历是以优先级为序的。 以下是使用 PriorityBlockingQueue 的示例: 1234BlockingQueue queue = new PriorityBlockingQueue();//String implements java.lang.Comparablequeue.put(&quot;Value&quot;);String value = queue.take(); 同步队列 SynchronousQueueSynchronousQueue 类实现了 BlockingQueue 接口。 SynchronousQueue 是一个特殊的队列，它的内部同时只能够容纳单个元素。如果该队列已有一元素的话，试图向队列中插入一个新元素的线程将会阻塞，直到另一个线程将该元素从队列中抽走。同样，如果该队列为空，试图向队列中抽取一个元素的线程将会阻塞，直到另一个线程向队列中插入了一条新的元素。 据此，把这个类称作一个队列显然是夸大其词了。它更多像是一个汇合点。 BlockingDeque 的例子既然 BlockingDeque 是一个接口，那么你想要使用它的话就得使用它的众多的实现类的其中一个。java.util.concurrent 包提供了以下 BlockingDeque 接口的实现类: LinkedBlockingDeque。 以下是如何使用 BlockingDeque 方法的一个简短代码示例: 123456BlockingDeque&lt;String&gt; deque = new LinkedBlockingDeque&lt;String&gt;();deque.addFirst(&quot;1&quot;);deque.addLast(&quot;2&quot;); String two = deque.takeLast();String one = deque.takeFirst(); 链阻塞双端队列 LinkedBlockingDequeLinkedBlockingDeque 类实现了 BlockingDeque 接口。 deque(双端队列) 是 “Double Ended Queue” 的缩写。因此，双端队列是一个你可以从任意一端插入或者抽取元素的队列。 LinkedBlockingDeque 是一个双端队列，在它为空的时候，一个试图从中抽取数据的线程将会阻塞，无论该线程是试图从哪一端抽取数据。 以下是 LinkedBlockingDeque 实例化以及使用的示例: 123456BlockingDeque&lt;String&gt; deque = new LinkedBlockingDeque&lt;String&gt;();deque.addFirst(&quot;1&quot;);deque.addLast(&quot;2&quot;); String two = deque.takeLast();String one = deque.takeFirst(); 参考文章 https://blog.csdn.net/defonds/article/details/44021605#t7 http://tutorials.jenkov.com/java-concurrency/index.html https://github.com/CL0610/Java-concurrency/blob/master/19.%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E4%B9%8BBlockingQueue/%E5%B9%B6%E5%8F%91%E5%AE%B9%E5%99%A8%E4%B9%8BBlockingQueue.md https://www.javadoop.com/post/java-concurrent-queue 著作权归@pdai所有 原文链接：https://pdai.tech/md/java/thread/java-thread-x-juc-collection-BlockingQueue.html","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"16.JUC集合: ConcurrentLinkedQueue详解","path":"/2023/12/26/16-JUC集合-ConcurrentLinkedQueue详解/","content":"ConcurerntLinkedQueue一个基于链接节点的无界线程安全队列。此队列按照 FIFO(先进先出)原则对元素进行排序。队列的头部是队列中时间最长的元素。队列的尾部 是队列中时间最短的元素。新的元素插入到队列的尾部，队列获取操作从队列头部获得元素。当多个线程共享访问一个公共 collection 时，ConcurrentLinkedQueue是一个恰当的选择。此队列不允许使用null元素。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 要想用线程安全的队列有哪些选择? Vector，Collections.synchronizedList(List&lt;T&gt; list), ConcurrentLinkedQueue等 ConcurrentLinkedQueue实现的数据结构? ConcurrentLinkedQueue底层原理? 全程无锁(CAS) ConcurrentLinkedQueue的核心方法有哪些? offer()，poll()，peek()，isEmpty()等队列常用方法 说说ConcurrentLinkedQueue的HOPS(延迟更新的策略)的设计? ConcurrentLinkedQueue适合什么样的使用场景? ConcurrentLinkedQueue数据结构通过源码分析可知，ConcurrentLinkedQueue的数据结构与LinkedBlockingQueue的数据结构相同，都是使用的链表结构。ConcurrentLinkedQueue的数据结构如下: 说明: ConcurrentLinkedQueue采用的链表结构，并且包含有一个头节点和一个尾结点。 ConcurrentLinkedQueue源码分析类的继承关系12public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements Queue&lt;E&gt;, java.io.Serializable &#123;&#125; 说明: ConcurrentLinkedQueue继承了抽象类AbstractQueue，AbstractQueue定义了对队列的基本操作；同时实现了Queue接口，Queue定义了对队列的基本操作，同时，还实现了Serializable接口，表示可以被序列化。 类的内部类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950private static class Node&lt;E&gt; &#123; // 元素 volatile E item; // next域 volatile Node&lt;E&gt; next; /** * Constructs a new node. Uses relaxed write because item can * only be seen after publication via casNext. */ // 构造函数 Node(E item) &#123; // 设置item的值 UNSAFE.putObject(this, itemOffset, item); &#125; // 比较并替换item值 boolean casItem(E cmp, E val) &#123; return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val); &#125; void lazySetNext(Node&lt;E&gt; val) &#123; // 设置next域的值，并不会保证修改对其他线程立即可见 UNSAFE.putOrderedObject(this, nextOffset, val); &#125; // 比较并替换next域的值 boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val); &#125; // Unsafe mechanics // 反射机制 private static final sun.misc.Unsafe UNSAFE; // item域的偏移量 private static final long itemOffset; // next域的偏移量 private static final long nextOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = Node.class; itemOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;item&quot;)); nextOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;next&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125;&#125; 说明: Node类表示链表结点，用于存放元素，包含item域和next域，item域表示元素，next域表示下一个结点，其利用反射机制和CAS机制来更新item域和next域，保证原子性。 类的属性12345678910111213141516171819202122232425262728public class ConcurrentLinkedQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements Queue&lt;E&gt;, java.io.Serializable &#123; // 版本序列号 private static final long serialVersionUID = 196745693267521676L; // 反射机制 private static final sun.misc.Unsafe UNSAFE; // head域的偏移量 private static final long headOffset; // tail域的偏移量 private static final long tailOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = ConcurrentLinkedQueue.class; headOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;head&quot;)); tailOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;tail&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; // 头节点 private transient volatile Node&lt;E&gt; head; // 尾结点 private transient volatile Node&lt;E&gt; tail;&#125; 说明: 属性中包含了head域和tail域，表示链表的头节点和尾结点，同时，ConcurrentLinkedQueue也使用了反射机制和CAS机制来更新头节点和尾结点，保证原子性。 类的构造函数 ConcurrentLinkedQueue()型构造函数 1234public ConcurrentLinkedQueue() &#123; // 初始化头节点与尾结点 head = tail = new Node&lt;E&gt;(null);&#125; 说明: 该构造函数用于创建一个最初为空的 ConcurrentLinkedQueue，头节点与尾结点指向同一个结点，该结点的item域为null，next域也为null。 ConcurrentLinkedQueue(Collection&lt;? extends E&gt;)型构造函数 12345678910111213141516171819202122232425public ConcurrentLinkedQueue(Collection&lt;? extends E&gt; c) &#123; Node&lt;E&gt; h = null, t = null; for (E e : c) &#123; // 遍历c集合 // 保证元素不为空 checkNotNull(e); // 新生一个结点 Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); if (h == null) // 头节点为null // 赋值头节点与尾结点 h = t = newNode; else &#123; // 直接头节点的next域 t.lazySetNext(newNode); // 重新赋值头节点 t = newNode; &#125; &#125; if (h == null) // 头节点为null // 新生头节点与尾结点 h = t = new Node&lt;E&gt;(null); // 赋值头节点 head = h; // 赋值尾结点 tail = t;&#125; 说明: 该构造函数用于创建一个最初包含给定 collection 元素的 ConcurrentLinkedQueue，按照此 collection 迭代器的遍历顺序来添加元素。 核心函数分析offer函数123456789101112131415161718192021222324252627282930313233343536public boolean offer(E e) &#123; // 元素不为null checkNotNull(e); // 新生一个结点 final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) &#123; // 无限循环 // q为p结点的下一个结点 Node&lt;E&gt; q = p.next; if (q == null) &#123; // q结点为null // p is last node if (p.casNext(null, newNode)) &#123; // 比较并进行替换p结点的next域 // Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become &quot;live&quot;. if (p != t) // p不等于t结点，不一致 // hop two nodes at a time // 比较并替换尾结点 casTail(t, newNode); // Failure is OK. // 返回 return true; &#125; // Lost CAS race to another thread; re-read next &#125; else if (p == q) // p结点等于q结点 // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. // 原来的尾结点与现在的尾结点是否相等，若相等，则p赋值为head，否则，赋值为现在的尾结点 p = (t != (t = tail)) ? t : head; else // Check for tail updates after two hops. // 重新赋值p结点 p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 说明: offer函数用于将指定元素插入此队列的尾部。下面模拟offer函数的操作，队列状态的变化(假设单线程添加元素，连续添加10、20两个元素)。 若ConcurrentLinkedQueue的初始状态如上图所示，即队列为空。单线程添加元素，此时，添加元素10，则状态如下所示 如上图所示，添加元素10后，tail没有变化，还是指向之前的结点，继续添加元素20，则状态如下所示 如上图所示，添加元素20后，tail指向了最新添加的结点。 poll函数123456789101112131415161718192021222324252627282930public E poll() &#123; restartFromHead: for (;;) &#123; // 无限循环 for (Node&lt;E&gt; h = head, p = h, q;;) &#123; // 保存头节点 // item项 E item = p.item; if (item != null &amp;&amp; p.casItem(item, null)) &#123; // item不为null并且比较并替换item成功 // Successful CAS is the linearization point // for item to be removed from this queue. if (p != h) // p不等于h // hop two nodes at a time // 更新头节点 updateHead(h, ((q = p.next) != null) ? q : p); // 返回item return item; &#125; else if ((q = p.next) == null) &#123; // q结点为null // 更新头节点 updateHead(h, p); return null; &#125; else if (p == q) // p等于q // 继续循环 continue restartFromHead; else // p赋值为q p = q; &#125; &#125;&#125; 说明: 此函数用于获取并移除此队列的头，如果此队列为空，则返回null。下面模拟poll函数的操作，队列状态的变化(假设单线程操作，状态为之前offer10、20后的状态，poll两次)。 队列初始状态如上图所示，在poll操作后，队列的状态如下图所示 如上图可知，poll操作后，head改变了，并且head所指向的结点的item变为了null。再进行一次poll操作，队列的状态如下图所示。 如上图可知，poll操作后，head结点没有变化，只是指示的结点的item域变成了null。 remove函数12345678910111213141516171819202122public boolean remove(Object o) &#123; // 元素为null，返回 if (o == null) return false; Node&lt;E&gt; pred = null; for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) &#123; // 获取第一个存活的结点 // 第一个存活结点的item值 E item = p.item; if (item != null &amp;&amp; o.equals(item) &amp;&amp; p.casItem(item, null)) &#123; // 找到item相等的结点，并且将该结点的item设置为null // p的后继结点 Node&lt;E&gt; next = succ(p); if (pred != null &amp;&amp; next != null) // pred不为null并且next不为null // 比较并替换next域 pred.casNext(p, next); return true; &#125; // pred赋值为p pred = p; &#125; return false;&#125; 说明: 此函数用于从队列中移除指定元素的单个实例(如果存在)。其中，会调用到first函数和succ函数，first函数的源码如下 123456789101112131415161718192021Node&lt;E&gt; first() &#123; restartFromHead: for (;;) &#123; // 无限循环，确保成功 for (Node&lt;E&gt; h = head, p = h, q;;) &#123; // p结点的item域是否为null boolean hasItem = (p.item != null); if (hasItem || (q = p.next) == null) &#123; // item不为null或者next域为null // 更新头节点 updateHead(h, p); // 返回结点 return hasItem ? p : null; &#125; else if (p == q) // p等于q // 继续从头节点开始 continue restartFromHead; else // p赋值为q p = q; &#125; &#125;&#125; 说明: first函数用于找到链表中第一个存活的结点。succ函数源码如下 123456final Node&lt;E&gt; succ(Node&lt;E&gt; p) &#123; // p结点的next域 Node&lt;E&gt; next = p.next; // 如果next域为自身，则返回头节点，否则，返回next return (p == next) ? head : next;&#125; 说明: succ用于获取结点的下一个结点。如果结点的next域指向自身，则返回head头节点，否则，返回next结点。下面模拟remove函数的操作，队列状态的变化(假设单线程操作，状态为之前offer10、20后的状态，执行remove(10)、remove(20)操作)。 如上图所示，为ConcurrentLinkedQueue的初始状态，remove(10)后的状态如下图所示 如上图所示，当执行remove(10)后，head指向了head结点之前指向的结点的下一个结点，并且head结点的item域置为null。继续执行remove(20)，状态如下图所示 如上图所示，执行remove(20)后，head与tail指向同一个结点，item域为null。 size函数1234567891011public int size() &#123; // 计数 int count = 0; for (Node&lt;E&gt; p = first(); p != null; p = succ(p)) // 从第一个存活的结点开始往后遍历 if (p.item != null) // 结点的item域不为null // Collection.size() spec says to max out if (++count == Integer.MAX_VALUE) // 增加计数，若达到最大值，则跳出循环 break; // 返回大小 return count;&#125; 说明: 此函数用于返回ConcurrenLinkedQueue的大小，从第一个存活的结点(first)开始，往后遍历链表，当结点的item域不为null时，增加计数，之后返回大小。 ConcurrentLinkedQueue示例下面通过一个示例来了解ConcurrentLinkedQueue的使用 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950import java.util.concurrent.ConcurrentLinkedQueue;class PutThread extends Thread &#123; private ConcurrentLinkedQueue&lt;Integer&gt; clq; public PutThread(ConcurrentLinkedQueue&lt;Integer&gt; clq) &#123; this.clq = clq; &#125; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; System.out.println(&quot;add &quot; + i); clq.add(i); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class GetThread extends Thread &#123; private ConcurrentLinkedQueue&lt;Integer&gt; clq; public GetThread(ConcurrentLinkedQueue&lt;Integer&gt; clq) &#123; this.clq = clq; &#125; public void run() &#123; for (int i = 0; i &lt; 10; i++) &#123; try &#123; System.out.println(&quot;poll &quot; + clq.poll()); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;public class ConcurrentLinkedQueueDemo &#123; public static void main(String[] args) &#123; ConcurrentLinkedQueue&lt;Integer&gt; clq = new ConcurrentLinkedQueue&lt;Integer&gt;(); PutThread p1 = new PutThread(clq); GetThread g1 = new GetThread(clq); p1.start(); g1.start(); &#125;&#125; 运行结果(某一次): 1234567891011121314151617181920add 0poll nulladd 1poll 0add 2poll 1add 3poll 2add 4poll 3add 5poll 4poll 5add 6add 7poll 6poll 7add 8add 9poll 8 说明: GetThread线程不会因为ConcurrentLinkedQueue队列为空而等待，而是直接返回null，所以当实现队列不空时，等待时，则需要用户自己实现等待逻辑。 再深入理解HOPS(延迟更新的策略)的设计通过上面对offer和poll方法的分析，我们发现tail和head是延迟更新的，两者更新触发时机为： tail更新触发时机：当tail指向的节点的下一个节点不为null的时候，会执行定位队列真正的队尾节点的操作，找到队尾节点后完成插入之后才会通过casTail进行tail更新；当tail指向的节点的下一个节点为null的时候，只插入节点不更新tail。 head更新触发时机：当head指向的节点的item域为null的时候，会执行定位队列真正的队头节点的操作，找到队头节点后完成删除之后才会通过updateHead进行head更新；当head指向的节点的item域不为null的时候，只删除节点不更新head。 并且在更新操作时，源码中会有注释为：hop two nodes at a time。所以这种延迟更新的策略就被叫做HOPS的大概原因是这个(猜的 😃)，从上面更新时的状态图可以看出，head和tail的更新是“跳着的”即中间总是间隔了一个。那么这样设计的意图是什么呢? 如果让tail永远作为队列的队尾节点，实现的代码量会更少，而且逻辑更易懂。但是，这样做有一个缺点，如果大量的入队操作，每次都要执行CAS进行tail的更新，汇总起来对性能也会是大大的损耗。如果能减少CAS更新的操作，无疑可以大大提升入队的操作效率，所以doug lea大师每间隔1次(tail和队尾节点的距离为1)进行才利用CAS更新tail。对head的更新也是同样的道理，虽然，这样设计会多出在循环中定位队尾节点，但总体来说读的操作效率要远远高于写的性能，因此，多出来的在循环中定位尾节点的操作的性能损耗相对而言是很小的。 ConcurrentLinkedQueue适合的场景ConcurrentLinkedQueue通过无锁来做到了更高的并发量，是个高性能的队列，但是使用场景相对不如阻塞队列常见，毕竟取数据也要不停的去循环，不如阻塞的逻辑好设计，但是在并发量特别大的情况下，是个不错的选择，性能上好很多，而且这个队列的设计也是特别费力，尤其的使用的改良算法和对哨兵的处理。整体的思路都是比较严谨的，这个也是使用了无锁造成的，我们自己使用无锁的条件的话，这个队列是个不错的参考。 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5539142.html，在此基础上做了增改。 https://blog.csdn.net/u011521203/article/details/80214968 https://blog.csdn.net/u014493323/article/details/81177194","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"15.JUC集合: CopyOnWriteArrayList详解","path":"/2023/12/26/15-JUC集合-CopyOnWriteArrayList详解/","content":"CopyOnWriteArrayList是ArrayList 的一个线程安全的变体，其中所有可变操作(add、set 等等)都是通过对底层数组进行一次新的拷贝来实现的。COW模式的体现。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 请先说说非并发集合中Fail-fast机制? 再为什么说ArrayList查询快而增删慢? 对比ArrayList说说CopyOnWriteArrayList的增删改查实现原理? COW基于拷贝 再说下弱一致性的迭代器原理是怎么样的? COWIterator&lt;E&gt; CopyOnWriteArrayList为什么并发安全且性能比Vector好? CopyOnWriteArrayList有何缺陷，说说其应用场景? CopyOnWriteArrayList源码分析类的继承关系CopyOnWriteArrayList实现了List接口，List接口定义了对列表的基本操作；同时实现了RandomAccess接口，表示可以随机访问(数组具有随机访问的特性)；同时实现了Cloneable接口，表示可克隆；同时也实现了Serializable接口，表示可被序列化。 1public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123;&#125; 类的内部类 COWIterator类 COWIterator表示迭代器，其也有一个Object类型的数组作为CopyOnWriteArrayList数组的快照，这种快照风格的迭代器方法在创建迭代器时使用了对当时数组状态的引用。此数组在迭代器的生存期内不会更改，因此不可能发生冲突，并且迭代器保证不会抛出 ConcurrentModificationException。创建迭代器以后，迭代器就不会反映列表的添加、移除或者更改。在迭代器上进行的元素更改操作(remove、set 和 add)不受支持。这些方法将抛出 UnsupportedOperationException。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; /** Snapshot of the array */ // 快照 private final Object[] snapshot; /** Index of element to be returned by subsequent call to next. */ // 游标 private int cursor; // 构造函数 private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements; &#125; // 是否还有下一项 public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; // 是否有上一项 public boolean hasPrevious() &#123; return cursor &gt; 0; &#125; // next项 @SuppressWarnings(&quot;unchecked&quot;) public E next() &#123; if (! hasNext()) // 不存在下一项，抛出异常 throw new NoSuchElementException(); // 返回下一项 return (E) snapshot[cursor++]; &#125; @SuppressWarnings(&quot;unchecked&quot;) public E previous() &#123; if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; &#125; // 下一项索引 public int nextIndex() &#123; return cursor; &#125; // 上一项索引 public int previousIndex() &#123; return cursor-1; &#125; /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; &#123;@code remove&#125; * is not supported by this iterator. */ // 不支持remove操作 public void remove() &#123; throw new UnsupportedOperationException(); &#125; /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; &#123;@code set&#125; * is not supported by this iterator. */ // 不支持set操作 public void set(E e) &#123; throw new UnsupportedOperationException(); &#125; /** * Not supported. Always throws UnsupportedOperationException. * @throws UnsupportedOperationException always; &#123;@code add&#125; * is not supported by this iterator. */ // 不支持add操作 public void add(E e) &#123; throw new UnsupportedOperationException(); &#125; @Override public void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); Object[] elements = snapshot; final int size = elements.length; for (int i = cursor; i &lt; size; i++) &#123; @SuppressWarnings(&quot;unchecked&quot;) E e = (E) elements[i]; action.accept(e); &#125; cursor = size; &#125;&#125; 类的属性属性中有一个可重入锁，用来保证线程安全访问，还有一个Object类型的数组，用来存放具体的元素。当然，也使用到了反射机制和CAS来保证原子性的修改lock域。 1234567891011121314151617181920212223public class CopyOnWriteArrayList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; // 版本序列号 private static final long serialVersionUID = 8673264195747942595L; // 可重入锁 final transient ReentrantLock lock = new ReentrantLock(); // 对象数组，用于存放元素 private transient volatile Object[] array; // 反射机制 private static final sun.misc.Unsafe UNSAFE; // lock域的内存偏移量 private static final long lockOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = CopyOnWriteArrayList.class; lockOffset = UNSAFE.objectFieldOffset (k.getDeclaredField(&quot;lock&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125;&#125; 类的构造函数 默认构造函数 1234public CopyOnWriteArrayList() &#123; // 设置数组 setArray(new Object[0]);&#125; CopyOnWriteArrayList(Collection&lt;? extends E&gt;)型构造函数 该构造函数用于创建一个按 collection 的迭代器返回元素的顺序包含指定 collection 元素的列表。 12345678910111213141516public CopyOnWriteArrayList(Collection&lt;? extends E&gt; c) &#123; Object[] elements; if (c.getClass() == CopyOnWriteArrayList.class) // 类型相同 // 获取c集合的数组 elements = ((CopyOnWriteArrayList&lt;?&gt;)c).getArray(); else &#123; // 类型不相同 // 将c集合转化为数组并赋值给elements elements = c.toArray(); // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elements.getClass() != Object[].class) // elements类型不为Object[]类型 // 将elements数组转化为Object[]类型的数组 elements = Arrays.copyOf(elements, elements.length, Object[].class); &#125; // 设置数组 setArray(elements);&#125; 该构造函数的处理流程如下 判断传入的集合c的类型是否为CopyOnWriteArrayList类型，若是，则获取该集合类型的底层数组(Object[])，并且设置当前CopyOnWriteArrayList的数组(Object[]数组)，进入步骤③；否则，进入步骤② 将传入的集合转化为数组elements，判断elements的类型是否为Object[]类型(toArray方法可能不会返回Object类型的数组)，若不是，则将elements转化为Object类型的数组。进入步骤③ 设置当前CopyOnWriteArrayList的Object[]为elements。 CopyOnWriteArrayList(E[])型构造函数 该构造函数用于创建一个保存给定数组的副本的列表。 1234public CopyOnWriteArrayList(E[] toCopyIn) &#123; // 将toCopyIn转化为Object[]类型数组，然后设置当前数组 setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class));&#125; 核心函数分析对于CopyOnWriteArrayList的函数分析，主要明白Arrays.copyOf方法即可理解CopyOnWriteArrayList其他函数的意义。 copyOf函数该函数用于复制指定的数组，截取或用 null 填充(如有必要)，以使副本具有指定的长度。 123456789101112public static &lt;T,U&gt; T[] copyOf(U[] original, int newLength, Class&lt;? extends T[]&gt; newType) &#123; @SuppressWarnings(&quot;unchecked&quot;) // 确定copy的类型(将newType转化为Object类型，将Object[].class转化为Object类型，判断两者是否相等，若相等，则生成指定长度的Object数组 // 否则,生成指定长度的新类型的数组) T[] copy = ((Object)newType == (Object)Object[].class) ? (T[]) new Object[newLength] : (T[]) Array.newInstance(newType.getComponentType(), newLength); // 将original数组从下标0开始，复制长度为(original.length和newLength的较小者),复制到copy数组中(也从下标0开始) System.arraycopy(original, 0, copy, 0, Math.min(original.length, newLength)); return copy;&#125; add函数12345678910111213141516171819202122public boolean add(E e) &#123; // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 元素数组 Object[] elements = getArray(); // 数组长度 int len = elements.length; // 复制数组 Object[] newElements = Arrays.copyOf(elements, len + 1); // 存放元素e newElements[len] = e; // 设置数组 setArray(newElements); return true; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 此函数用于将指定元素添加到此列表的尾部，处理流程如下 获取锁(保证多线程的安全访问)，获取当前的Object数组，获取Object数组的长度为length，进入步骤②。 根据Object数组复制一个长度为length+1的Object数组为newElements(此时，newElements[length]为null)，进入下一步骤。 将下标为length的数组元素newElements[length]设置为元素e，再设置当前Object[]为newElements，释放锁，返回。这样就完成了元素的添加。 addIfAbsent方法该函数用于添加元素(如果数组中不存在，则添加；否则，不添加，直接返回)，可以保证多线程环境下不会重复添加元素。 1234567891011121314151617181920212223242526272829303132333435private boolean addIfAbsent(E e, Object[] snapshot) &#123; // 重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 获取数组 Object[] current = getArray(); // 数组长度 int len = current.length; if (snapshot != current) &#123; // 快照不等于当前数组，对数组进行了修改 // Optimize for lost race to another addXXX operation // 取较小者 int common = Math.min(snapshot.length, len); for (int i = 0; i &lt; common; i++) // 遍历 if (current[i] != snapshot[i] &amp;&amp; eq(e, current[i])) // 当前数组的元素与快照的元素不相等并且e与当前元素相等 // 表示在snapshot与current之间修改了数组，并且设置了数组某一元素为e，已经存在 // 返回 return false; if (indexOf(e, current, common, len) &gt;= 0) // 在当前数组中找到e元素 // 返回 return false; &#125; // 复制数组 Object[] newElements = Arrays.copyOf(current, len + 1); // 对数组len索引的元素赋值为e newElements[len] = e; // 设置数组 setArray(newElements); return true; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 该函数的流程如下: ① 获取锁，获取当前数组为current，current长度为len，判断数组之前的快照snapshot是否等于当前数组current，若不相等，则进入步骤②；否则，进入步骤④ ② 不相等，表示在snapshot与current之间，对数组进行了修改(如进行了add、set、remove等操作)，获取长度(snapshot与current之间的较小者)，对current进行遍历操作，若遍历过程发现snapshot与current的元素不相等并且current的元素与指定元素相等(可能进行了set操作)，进入步骤⑤，否则，进入步骤③ ③ 在当前数组中索引指定元素，若能够找到，进入步骤⑤，否则，进入步骤④ ④ 复制当前数组current为newElements，长度为len+1，此时newElements[len]为null。再设置newElements[len]为指定元素e，再设置数组，进入步骤⑤ ⑤ 释放锁，返回。 set函数此函数用于用指定的元素替代此列表指定位置上的元素，也是基于数组的复制来实现的。 1234567891011121314151617181920212223242526272829303132public E set(int index, E element) &#123; // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 获取数组 Object[] elements = getArray(); // 获取index索引的元素 E oldValue = get(elements, index); if (oldValue != element) &#123; // 旧值等于element // 数组长度 int len = elements.length; // 复制数组 Object[] newElements = Arrays.copyOf(elements, len); // 重新赋值index索引的值 newElements[index] = element; // 设置数组 setArray(newElements); &#125; else &#123; // Not quite a no-op; ensures volatile write semantics // 设置数组 setArray(elements); &#125; // 返回旧值 return oldValue; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; remove函数此函数用于移除此列表指定位置上的元素。 1234567891011121314151617181920212223242526272829303132333435public E remove(int index) &#123; // 可重入锁 final ReentrantLock lock = this.lock; // 获取锁 lock.lock(); try &#123; // 获取数组 Object[] elements = getArray(); // 数组长度 int len = elements.length; // 获取旧值 E oldValue = get(elements, index); // 需要移动的元素个数 int numMoved = len - index - 1; if (numMoved == 0) // 移动个数为0 // 复制后设置数组 setArray(Arrays.copyOf(elements, len - 1)); else &#123; // 移动个数不为0 // 新生数组 Object[] newElements = new Object[len - 1]; // 复制index索引之前的元素 System.arraycopy(elements, 0, newElements, 0, index); // 复制index索引之后的元素 System.arraycopy(elements, index + 1, newElements, index, numMoved); // 设置索引 setArray(newElements); &#125; // 返回旧值 return oldValue; &#125; finally &#123; // 释放锁 lock.unlock(); &#125;&#125; 处理流程如下 ① 获取锁，获取数组elements，数组长度为length，获取索引的值elements[index]，计算需要移动的元素个数(length - index - 1),若个数为0，则表示移除的是数组的最后一个元素，复制elements数组，复制长度为length-1，然后设置数组，进入步骤③；否则，进入步骤② ② 先复制index索引前的元素，再复制index索引后的元素，然后设置数组。 ③ 释放锁，返回旧值。 CopyOnWriteArrayList示例下面通过一个示例来了解CopyOnWriteArrayList的使用: 在程序中，有一个PutThread线程会每隔50ms就向CopyOnWriteArrayList中添加一个元素，并且两次使用了迭代器，迭代器输出的内容都是生成迭代器时，CopyOnWriteArrayList的Object数组的快照的内容，在迭代的过程中，往CopyOnWriteArrayList中添加元素也不会抛出异常。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647import java.util.Iterator;import java.util.concurrent.CopyOnWriteArrayList;class PutThread extends Thread &#123; private CopyOnWriteArrayList&lt;Integer&gt; cowal; public PutThread(CopyOnWriteArrayList&lt;Integer&gt; cowal) &#123; this.cowal = cowal; &#125; public void run() &#123; try &#123; for (int i = 100; i &lt; 110; i++) &#123; cowal.add(i); Thread.sleep(50); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;public class CopyOnWriteArrayListDemo &#123; public static void main(String[] args) &#123; CopyOnWriteArrayList&lt;Integer&gt; cowal = new CopyOnWriteArrayList&lt;Integer&gt;(); for (int i = 0; i &lt; 10; i++) &#123; cowal.add(i); &#125; PutThread p1 = new PutThread(cowal); p1.start(); Iterator&lt;Integer&gt; iterator = cowal.iterator(); while (iterator.hasNext()) &#123; System.out.print(iterator.next() + &quot; &quot;); &#125; System.out.println(); try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; iterator = cowal.iterator(); while (iterator.hasNext()) &#123; System.out.print(iterator.next() + &quot; &quot;); &#125; &#125;&#125; 运行结果(某一次) 120 1 2 3 4 5 6 7 8 9 100 0 1 2 3 4 5 6 7 8 9 100 101 102 103 更深入理解CopyOnWriteArrayList的缺陷和使用场景CopyOnWriteArrayList 有几个缺点： 由于写操作的时候，需要拷贝数组，会消耗内存，如果原数组的内容比较多的情况下，可能导致young gc或者full gc 不能用于实时读的场景，像拷贝数组、新增元素都需要时间，所以调用一个set操作后，读取到数据可能还是旧的,虽然CopyOnWriteArrayList 能做到最终一致性,但是还是没法满足实时性要求； CopyOnWriteArrayList 合适读多写少的场景，不过这类慎用 因为谁也没法保证CopyOnWriteArrayList 到底要放置多少数据，万一数据稍微有点多，每次add&#x2F;set都要重新复制数组，这个代价实在太高昂了。在高性能的互联网应用中，这种操作分分钟引起故障。 CopyOnWriteArrayList为什么并发安全且性能比Vector好?Vector对单独的add，remove等方法都是在方法上加了synchronized; 并且如果一个线程A调用size时，另一个线程B 执行了remove，然后size的值就不是最新的，然后线程A调用remove就会越界(这时就需要再加一个Synchronized)。这样就导致有了双重锁，效率大大降低，何必呢。于是vector废弃了，要用就用CopyOnWriteArrayList 吧。 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5547853.html，在此基础上做了增改。 https://blog.csdn.net/LuoZheng4698729/article/details/102824923 https://blog.csdn.net/chuanyingcao2675/article/details/101048889","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"14.JUC集合: ConcurrentHashMap详解","path":"/2023/12/25/14-JUC集合-ConcurrentHashMap详解/","content":"JDK1.7之前的ConcurrentHashMap使用分段锁机制实现，JDK1.8则使用数组+链表+红黑树数据结构和CAS原子操作实现ConcurrentHashMap；本文将分别介绍这两种方式的实现方案及其区别。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 为什么HashTable慢? 它的并发度是什么? 那么ConcurrentHashMap并发度是什么? ConcurrentHashMap在JDK1.7和JDK1.8中实现有什么差别? JDK1.8解決了JDK1.7中什么问题 ConcurrentHashMap JDK1.7实现的原理是什么? 分段锁机制 ConcurrentHashMap JDK1.8实现的原理是什么? 数组+链表+红黑树，CAS ConcurrentHashMap JDK1.7中Segment数(concurrencyLevel)默认值是多少? 为何一旦初始化就不可再扩容? ConcurrentHashMap JDK1.7说说其put的机制? ConcurrentHashMap JDK1.7是如何扩容的? rehash(注：segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry&lt;K,V&gt;[] 进行扩容) ConcurrentHashMap JDK1.8是如何扩容的? tryPresize ConcurrentHashMap JDK1.8链表转红黑树的时机是什么? 临界值为什么是8? ConcurrentHashMap JDK1.8是如何进行数据迁移的? transfer 为什么HashTable慢Hashtable之所以效率低下主要是因为其实现使用了synchronized关键字对put等操作进行加锁，而synchronized关键字加锁是对整个对象进行加锁，也就是说在进行put等修改Hash表的操作时，锁住了整个Hash表，从而使得其表现的效率低下。 ConcurrentHashMap - JDK 1.7在JDK1.5~1.7版本，Java使用了分段锁机制实现ConcurrentHashMap. 简而言之，ConcurrentHashMap在对象中保存了一个Segment数组，即将整个Hash表划分为多个分段；而每个Segment元素，即每个分段则类似于一个Hashtable；这样，在执行put操作时首先根据hash算法定位到元素属于哪个Segment，然后对该Segment加锁即可。因此，ConcurrentHashMap在多线程并发编程中可是实现多线程put操作。接下来分析JDK1.7版本中ConcurrentHashMap的实现原理。 数据结构整个 ConcurrentHashMap 由一个个 Segment 组成，Segment 代表”部分“或”一段“的意思，所以很多地方都会将其描述为分段锁。注意，行文中，我很多地方用了“槽”来代表一个 segment。 简单理解就是，ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证每个 Segment 是线程安全的，也就实现了全局的线程安全。 concurrencyLevel: 并行级别、并发数、Segment 数，怎么翻译不重要，理解它。默认是 16，也就是说 ConcurrentHashMap 有 16 个 Segments，所以理论上，这个时候，最多可以同时支持 16 个线程并发写，只要它们的操作分别分布在不同的 Segment 上。这个值可以在初始化的时候设置为其他值，但是一旦初始化以后，它是不可以扩容的。 再具体到每个 Segment 内部，其实每个 Segment 很像之前介绍的 HashMap，不过它要保证线程安全，所以处理起来要麻烦些。 初始化 initialCapacity: 初始容量，这个值指的是整个 ConcurrentHashMap 的初始容量，实际操作的时候需要平均分给每个 Segment。 loadFactor: 负载因子，之前我们说了，Segment 数组不可以扩容，所以这个负载因子是给每个 Segment 内部使用的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; int ssize = 1; // 计算并行级别 ssize，因为要保持并行级别是 2 的 n 次方 while (ssize &lt; concurrencyLevel) &#123; ++sshift; ssize &lt;&lt;= 1; &#125; // 我们这里先不要那么烧脑，用默认值，concurrencyLevel 为 16，sshift 为 4 // 那么计算出 segmentShift 为 28，segmentMask 为 15，后面会用到这两个值 this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // initialCapacity 是设置整个 map 初始的大小， // 这里根据 initialCapacity 计算 Segment 数组中每个位置可以分到的大小 // 如 initialCapacity 为 64，那么每个 Segment 或称之为&quot;槽&quot;可以分到 4 个 int c = initialCapacity / ssize; if (c * ssize &lt; initialCapacity) ++c; // 默认 MIN_SEGMENT_TABLE_CAPACITY 是 2，这个值也是有讲究的，因为这样的话，对于具体的槽上， // 插入一个元素不至于扩容，插入第二个的时候才会扩容 int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; // 创建 Segment 数组， // 并创建数组的第一个元素 segment[0] Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; // 往数组写入 segment[0] UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss;&#125; 初始化完成，我们得到了一个 Segment 数组。 我们就当是用 new ConcurrentHashMap() 无参构造函数进行初始化的，那么初始化完成后: Segment 数组长度为 16，不可以扩容 Segment[i] 的默认大小为 2，负载因子是 0.75，得出初始阈值为 1.5，也就是以后插入第一个元素不会触发扩容，插入第二个会进行第一次扩容 这里初始化了 segment[0]，其他位置还是 null，至于为什么要初始化 segment[0]，后面的代码会介绍 当前 segmentShift 的值为 32 - 4 &#x3D; 28，segmentMask 为 16 - 1 &#x3D; 15，姑且把它们简单翻译为移位数和掩码，这两个值马上就会用到 put 过程分析我们先看 put 的主流程，对于其中的一些关键细节操作，后面会进行详细介绍。 123456789101112131415161718public V put(K key, V value) &#123; Segment&lt;K,V&gt; s; if (value == null) throw new NullPointerException(); // 1. 计算 key 的 hash 值 int hash = hash(key); // 2. 根据 hash 值找到 Segment 数组中的位置 j // hash 是 32 位，无符号右移 segmentShift(28) 位，剩下高 4 位， // 然后和 segmentMask(15) 做一次与操作，也就是说 j 是 hash 值的高 4 位，也就是槽的数组下标 int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; // 刚刚说了，初始化的时候初始化了 segment[0]，但是其他位置还是 null， // ensureSegment(j) 对 segment[j] 进行初始化 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject // nonvolatile; recheck (segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) // in ensureSegment s = ensureSegment(j); // 3. 插入新值到 槽 s 中 return s.put(key, hash, value, false);&#125; 第一层皮很简单，根据 hash 值很快就能找到相应的 Segment，之后就是 Segment 内部的 put 操作了。 Segment 内部是由 数组+链表 组成的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; // 在往该 segment 写入前，需要先获取该 segment 的独占锁 // 先看主流程，后面还会具体介绍这部分内容 HashEntry&lt;K,V&gt; node = tryLock() ? null : scanAndLockForPut(key, hash, value); V oldValue; try &#123; // 这个是 segment 内部的数组 HashEntry&lt;K,V&gt;[] tab = table; // 再利用 hash 值，求应该放置的数组下标 int index = (tab.length - 1) &amp; hash; // first 是数组该位置处的链表的表头 HashEntry&lt;K,V&gt; first = entryAt(tab, index); // 下面这串 for 循环虽然很长，不过也很好理解，想想该位置没有任何元素和已经存在一个链表这两种情况 for (HashEntry&lt;K,V&gt; e = first;;) &#123; if (e != null) &#123; K k; if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; // 覆盖旧值 e.value = value; ++modCount; &#125; break; &#125; // 继续顺着链表走 e = e.next; &#125; else &#123; // node 到底是不是 null，这个要看获取锁的过程，不过和这里都没有关系。 // 如果不为 null，那就直接将它设置为链表表头；如果是null，初始化并设置为链表表头。 if (node != null) node.setNext(first); else node = new HashEntry&lt;K,V&gt;(hash, key, value, first); int c = count + 1; // 如果超过了该 segment 的阈值，这个 segment 需要扩容 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); // 扩容后面也会具体分析 else // 没有达到阈值，将 node 放到数组 tab 的 index 位置， // 其实就是将新的节点设置成原链表的表头 setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; break; &#125; &#125; &#125; finally &#123; // 解锁 unlock(); &#125; return oldValue;&#125; 整体流程还是比较简单的，由于有独占锁的保护，所以 segment 内部的操作并不复杂。至于这里面的并发问题，我们稍后再进行介绍。 到这里 put 操作就结束了，接下来，我们说一说其中几步关键的操作。 初始化槽: ensureSegmentConcurrentHashMap 初始化的时候会初始化第一个槽 segment[0]，对于其他槽来说，在插入第一个值的时候进行初始化。 这里需要考虑并发，因为很可能会有多个线程同时进来初始化同一个槽 segment[k]，不过只要有一个成功了就可以。 1234567891011121314151617181920212223242526272829private Segment&lt;K,V&gt; ensureSegment(int k) &#123; final Segment&lt;K,V&gt;[] ss = this.segments; long u = (k &lt;&lt; SSHIFT) + SBASE; // raw offset Segment&lt;K,V&gt; seg; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // 这里看到为什么之前要初始化 segment[0] 了， // 使用当前 segment[0] 处的数组长度和负载因子来初始化 segment[k] // 为什么要用“当前”，因为 segment[0] 可能早就扩容过了 Segment&lt;K,V&gt; proto = ss[0]; int cap = proto.table.length; float lf = proto.loadFactor; int threshold = (int)(cap * lf); // 初始化 segment[k] 内部的数组 HashEntry&lt;K,V&gt;[] tab = (HashEntry&lt;K,V&gt;[])new HashEntry[cap]; if ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; // 再次检查一遍该槽是否被其他线程初始化了。 Segment&lt;K,V&gt; s = new Segment&lt;K,V&gt;(lf, threshold, tab); // 使用 while 循环，内部用 CAS，当前线程成功设值或其他线程成功设值后，退出 while ((seg = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(ss, u)) == null) &#123; if (UNSAFE.compareAndSwapObject(ss, u, null, seg = s)) break; &#125; &#125; &#125; return seg;&#125; 总的来说，ensureSegment(int k) 比较简单，对于并发操作使用 CAS 进行控制。 获取写入锁: scanAndLockForPut前面我们看到，在往某个 segment 中 put 的时候，首先会调用 node &#x3D; tryLock() ? null : scanAndLockForPut(key, hash, value)，也就是说先进行一次 tryLock() 快速获取该 segment 的独占锁，如果失败，那么进入到 scanAndLockForPut 这个方法来获取锁。 下面我们来具体分析这个方法中是怎么控制加锁的。 123456789101112131415161718192021222324252627282930313233343536373839private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // negative while locating node // 循环获取锁 while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) &#123; if (e == null) &#123; if (node == null) // speculatively create node // 进到这里说明数组该位置的链表是空的，没有任何元素 // 当然，进到这里的另一个原因是 tryLock() 失败，所以该槽存在并发，不一定是该位置 node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0; &#125; else if (key.equals(e.key)) retries = 0; else // 顺着链表往下走 e = e.next; &#125; // 重试次数如果超过 MAX_SCAN_RETRIES(单核1多核64)，那么不抢了，进入到阻塞队列等待锁 // lock() 是阻塞方法，直到获取锁后返回 else if (++retries &gt; MAX_SCAN_RETRIES) &#123; lock(); break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; // 这个时候是有大问题了，那就是有新的元素进到了链表，成为了新的表头 // 所以这边的策略是，相当于重新走一遍这个 scanAndLockForPut 方法 (f = entryForHash(this, hash)) != first) &#123; e = first = f; // re-traverse if entry changed retries = -1; &#125; &#125; return node;&#125; 这个方法有两个出口，一个是 tryLock() 成功了，循环终止，另一个就是重试次数超过了 MAX_SCAN_RETRIES，进到 lock() 方法，此方法会阻塞等待，直到成功拿到独占锁。 这个方法就是看似复杂，但是其实就是做了一件事，那就是获取该 segment 的独占锁，如果需要的话顺便实例化了一下 node。 扩容: rehash重复一下，segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry&lt;K,V&gt;[] 进行扩容，扩容后，容量为原来的 2 倍。 首先，我们要回顾一下触发扩容的地方，put 的时候，如果判断该值的插入会导致该 segment 的元素个数超过阈值，那么先进行扩容，再插值，读者这个时候可以回去 put 方法看一眼。 该方法不需要考虑并发，因为到这里的时候，是持有该 segment 的独占锁的。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 方法参数上的 node 是这次扩容后，需要添加到新的数组中的数据。private void rehash(HashEntry&lt;K,V&gt; node) &#123; HashEntry&lt;K,V&gt;[] oldTable = table; int oldCapacity = oldTable.length; // 2 倍 int newCapacity = oldCapacity &lt;&lt; 1; threshold = (int)(newCapacity * loadFactor); // 创建新数组 HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; // 新的掩码，如从 16 扩容到 32，那么 sizeMask 为 31，对应二进制 ‘000...00011111’ int sizeMask = newCapacity - 1; // 遍历原数组，老套路，将原数组位置 i 处的链表拆分到 新数组位置 i 和 i+oldCap 两个位置 for (int i = 0; i &lt; oldCapacity ; i++) &#123; // e 是链表的第一个元素 HashEntry&lt;K,V&gt; e = oldTable[i]; if (e != null) &#123; HashEntry&lt;K,V&gt; next = e.next; // 计算应该放置在新数组中的位置， // 假设原数组长度为 16，e 在 oldTable[3] 处，那么 idx 只可能是 3 或者是 3 + 16 = 19 int idx = e.hash &amp; sizeMask; if (next == null) // 该位置处只有一个元素，那比较好办 newTable[idx] = e; else &#123; // Reuse consecutive sequence at same slot // e 是链表表头 HashEntry&lt;K,V&gt; lastRun = e; // idx 是当前链表的头节点 e 的新位置 int lastIdx = idx; // 下面这个 for 循环会找到一个 lastRun 节点，这个节点之后的所有元素是将要放到一起的 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; lastIdx = k; lastRun = last; &#125; &#125; // 将 lastRun 及其之后的所有节点组成的这个链表放到 lastIdx 这个位置 newTable[lastIdx] = lastRun; // 下面的操作是处理 lastRun 之前的节点， // 这些节点可能分配在另一个链表中，也可能分配到上面的那个链表中 for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; // 将新来的 node 放到新数组中刚刚的 两个链表之一 的 头部 int nodeIndex = node.hash &amp; sizeMask; // add the new node node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; table = newTable;&#125; 这里的扩容比之前的 HashMap 要复杂一些，代码难懂一点。上面有两个挨着的 for 循环，第一个 for 有什么用呢? 仔细一看发现，如果没有第一个 for 循环，也是可以工作的，但是，这个 for 循环下来，如果 lastRun 的后面还有比较多的节点，那么这次就是值得的。因为我们只需要克隆 lastRun 前面的节点，后面的一串节点跟着 lastRun 走就是了，不需要做任何操作。 我觉得 Doug Lea 的这个想法也是挺有意思的，不过比较坏的情况就是每次 lastRun 都是链表的最后一个元素或者很靠后的元素，那么这次遍历就有点浪费了。不过 Doug Lea 也说了，根据统计，如果使用默认的阈值，大约只有 1&#x2F;6 的节点需要克隆。 get 过程分析相对于 put 来说，get 就很简单了。 计算 hash 值，找到 segment 数组中的具体位置，或我们前面用的“槽” 槽中也是一个数组，根据 hash 找到数组中具体的位置 到这里是链表了，顺着链表进行查找即可 1234567891011121314151617181920public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; // 1. hash 值 int h = hash(key); long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; // 2. 根据 hash 找到对应的 segment if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; // 3. 找到segment 内部数组相应位置的链表，遍历 for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) return e.value; &#125; &#125; return null;&#125; 并发问题分析现在我们已经说完了 put 过程和 get 过程，我们可以看到 get 过程中是没有加锁的，那自然我们就需要去考虑并发问题。 添加节点的操作 put 和删除节点的操作 remove 都是要加 segment 上的独占锁的，所以它们之间自然不会有问题，我们需要考虑的问题就是 get 的时候在同一个 segment 中发生了 put 或 remove 操作。 put 操作的线程安全性。 初始化槽，这个我们之前就说过了，使用了 CAS 来初始化 Segment 中的数组。 添加节点到链表的操作是插入到表头的，所以，如果这个时候 get 操作在链表遍历的过程已经到了中间，是不会影响的。当然，另一个并发问题就是 get 操作在 put 之后，需要保证刚刚插入表头的节点被读取，这个依赖于 setEntryAt 方法中使用的 UNSAFE.putOrderedObject。 扩容。扩容是新创建了数组，然后进行迁移数据，最后面将 newTable 设置给属性 table。所以，如果 get 操作此时也在进行，那么也没关系，如果 get 先行，那么就是在旧的 table 上做查询操作；而 put 先行，那么 put 操作的可见性保证就是 table 使用了 volatile 关键字。 remove 操作的线程安全性。 remove 操作我们没有分析源码，所以这里说的读者感兴趣的话还是需要到源码中去求实一下的。 get 操作需要遍历链表，但是 remove 操作会”破坏”链表。 如果 remove 破坏的节点 get 操作已经过去了，那么这里不存在任何问题。 如果 remove 先破坏了一个节点，分两种情况考虑。 1、如果此节点是头节点，那么需要将头节点的 next 设置为数组该位置的元素，table 虽然使用了 volatile 修饰，但是 volatile 并不能提供数组内部操作的可见性保证，所以源码中使用了 UNSAFE 来操作数组，请看方法 setEntryAt。2、如果要删除的节点不是头节点，它会将要删除节点的后继节点接到前驱节点中，这里的并发保证就是 next 属性是 volatile 的。 ConcurrentHashMap - JDK 1.8在JDK1.7之前，ConcurrentHashMap是通过分段锁机制来实现的，所以其最大并发度受Segment的个数限制。因此，在JDK1.8中，ConcurrentHashMap的实现原理摒弃了这种设计，而是选择了与HashMap类似的数组+链表+红黑树的方式实现，而加锁则采用CAS和synchronized实现。 数据结构 结构上和 Java8 的 HashMap 基本上一样，不过它要保证线程安全性，所以在源码上确实要复杂一些。 初始化1234567891011// 这构造函数里，什么都不干public ConcurrentHashMap() &#123;&#125;public ConcurrentHashMap(int initialCapacity) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(); int cap = ((initialCapacity &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(initialCapacity + (initialCapacity &gt;&gt;&gt; 1) + 1)); this.sizeCtl = cap;&#125; 这个初始化方法有点意思，通过提供初始容量，计算了 sizeCtl，sizeCtl &#x3D; 【 (1.5 * initialCapacity + 1)，然后向上取最近的 2 的 n 次方】。如 initialCapacity 为 10，那么得到 sizeCtl 为 16，如果 initialCapacity 为 11，得到 sizeCtl 为 32。 sizeCtl 这个属性使用的场景很多，不过只要跟着文章的思路来，就不会被它搞晕了。 put 过程分析仔细地一行一行代码看下去: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public V put(K key, V value) &#123; return putVal(key, value, false);&#125;final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); // 得到 hash 值 int hash = spread(key.hashCode()); // 用于记录相应链表的长度 int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; // 如果数组&quot;空&quot;，进行数组初始化 if (tab == null || (n = tab.length) == 0) // 初始化数组，后面会详细介绍 tab = initTable(); // 找该 hash 值对应的数组下标，得到第一个节点 f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; // 如果数组该位置为空， // 用一次 CAS 操作将这个新值放入其中即可，这个 put 操作差不多就结束了，可以拉到最后面了 // 如果 CAS 失败，那就是有并发操作，进到下一个循环就好了 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; // hash 居然可以等于 MOVED，这个需要到后面才能看明白，不过从名字上也能猜到，肯定是因为在扩容 else if ((fh = f.hash) == MOVED) // 帮助数据迁移，这个等到看完数据迁移部分的介绍后，再理解这个就很简单了 tab = helpTransfer(tab, f); else &#123; // 到这里就是说，f 是该位置的头节点，而且不为空 V oldVal = null; // 获取数组该位置的头节点的监视器锁 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; // 头节点的 hash 值大于 0，说明是链表 // 用于累加，记录链表的长度 binCount = 1; // 遍历链表 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; // 如果发现了&quot;相等&quot;的 key，判断是否要进行值覆盖，然后也就可以 break 了 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; // 到了链表的最末端，将这个新值放到链表的最后面 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; // 红黑树 Node&lt;K,V&gt; p; binCount = 2; // 调用红黑树的插值方法插入新节点 if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; // 判断是否要将链表转换为红黑树，临界值和 HashMap 一样，也是 8 if (binCount &gt;= TREEIFY_THRESHOLD) // 这个方法和 HashMap 中稍微有一点点不同，那就是它不是一定会进行红黑树转换， // 如果当前数组的长度小于 64，那么会选择进行数组扩容，而不是转换为红黑树 // 具体源码我们就不看了，扩容部分后面说 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; // addCount(1L, binCount); return null;&#125; 初始化数组: initTable这个比较简单，主要就是初始化一个合适大小的数组，然后会设置 sizeCtl。 初始化方法中的并发问题是通过对 sizeCtl 进行一个 CAS 操作来控制的。 1234567891011121314151617181920212223242526272829private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; // 初始化的&quot;功劳&quot;被其他线程&quot;抢去&quot;了 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin // CAS 一下，将 sizeCtl 设置为 -1，代表抢到了锁 else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if ((tab = table) == null || tab.length == 0) &#123; // DEFAULT_CAPACITY 默认初始容量是 16 int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; // 初始化数组，长度为 16 或初始化时提供的长度 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; // 将这个数组赋值给 table，table 是 volatile 的 table = tab = nt; // 如果 n 为 16 的话，那么这里 sc = 12 // 其实就是 0.75 * n sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; // 设置 sizeCtl 为 sc，我们就当是 12 吧 sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 链表转红黑树: treeifyBin前面我们在 put 源码分析也说过，treeifyBin 不一定就会进行红黑树转换，也可能是仅仅做数组扩容。我们还是进行源码分析吧。 123456789101112131415161718192021222324252627282930313233private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; // MIN_TREEIFY_CAPACITY 为 64 // 所以，如果数组长度小于 64 的时候，其实也就是 32 或者 16 或者更小的时候，会进行数组扩容 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) // 后面我们再详细分析这个方法 tryPresize(n &lt;&lt; 1); // b 是头节点 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; // 加锁 synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; // 下面就是遍历链表，建立一颗红黑树 TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; // 将红黑树设置到数组相应位置中 setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; 扩容: tryPresize如果说 Java8 ConcurrentHashMap 的源码不简单，那么说的就是扩容操作和迁移操作。 这个方法要完完全全看懂还需要看之后的 transfer 方法，读者应该提前知道这点。 这里的扩容也是做翻倍扩容的，扩容后数组容量为原来的 2 倍。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 首先要说明的是，方法参数 size 传进来的时候就已经翻了倍了private final void tryPresize(int size) &#123; // c: size 的 1.5 倍，再加 1，再往上取最近的 2 的 n 次方。 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; // 这个 if 分支和之前说的初始化数组的代码基本上是一样的，在这里，我们可以不用管这块代码 if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings(&quot;unchecked&quot;) Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); // 0.75 * n &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; // 我没看懂 rs 的真正含义是什么，不过也关系不大 int rs = resizeStamp(n); if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 2. 用 CAS 将 sizeCtl 加 1，然后执行 transfer 方法 // 此时 nextTab 不为 null if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 1. 将 sizeCtl 设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 我是没看懂这个值真正的意义是什么? 不过可以计算出来的是，结果是一个比较大的负数 // 调用 transfer 方法，此时 nextTab 参数为 null else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); &#125; &#125;&#125; 这个方法的核心在于 sizeCtl 值的操作，首先将其设置为一个负数，然后执行 transfer(tab, null)，再下一个循环将 sizeCtl 加 1，并执行 transfer(tab, nt)，之后可能是继续 sizeCtl 加 1，并执行 transfer(tab, nt)。 所以，可能的操作就是执行 1 次 transfer(tab, null) + 多次 transfer(tab, nt)，这里怎么结束循环的需要看完 transfer 源码才清楚。 数据迁移: transfer下面这个方法有点长，将原来的 tab 数组的元素迁移到新的 nextTab 数组中。 虽然我们之前说的 tryPresize 方法中多次调用 transfer 不涉及多线程，但是这个 transfer 方法可以在其他地方被调用，典型地，我们之前在说 put 方法的时候就说过了，请往上看 put 方法，是不是有个地方调用了 helpTransfer 方法，helpTransfer 方法会调用 transfer 方法的。 此方法支持多线程执行，外围调用此方法的时候，会保证第一个发起数据迁移的线程，nextTab 参数为 null，之后再调用此方法的时候，nextTab 不会为 null。 阅读源码之前，先要理解并发操作的机制。原数组长度为 n，所以我们有 n 个迁移任务，让每个线程每次负责一个小任务是最简单的，每做完一个任务再检测是否有其他没做完的任务，帮助迁移就可以了，而 Doug Lea 使用了一个 stride，简单理解就是步长，每个线程每次负责迁移其中的一部分，如每次迁移 16 个小任务。所以，我们就需要一个全局的调度者来安排哪个线程执行哪几个任务，这个就是属性 transferIndex 的作用。 第一个发起数据迁移的线程会将 transferIndex 指向原数组最后的位置，然后从后往前的 stride 个任务属于第一个线程，然后将 transferIndex 指向新的位置，再往前的 stride 个任务属于第二个线程，依此类推。当然，这里说的第二个线程不是真的一定指代了第二个线程，也可以是同一个线程，这个读者应该能理解吧。其实就是将一个大的迁移任务分为了一个个任务包。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // stride 在单核下直接等于 n，多核模式下为 (n&gt;&gt;&gt;3)/NCPU，最小值是 16 // stride 可以理解为”步长“，有 n 个位置是需要进行迁移的， // 将这 n 个任务分为多个任务包，每个任务包有 stride 个任务 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // 如果 nextTab 为 null，先进行一次初始化 // 前面我们说了，外围会保证第一个发起迁移的线程调用此方法时，参数 nextTab 为 null // 之后参与迁移的线程调用此方法时，nextTab 不会为 null if (nextTab == null) &#123; try &#123; // 容量翻倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; // nextTable 是 ConcurrentHashMap 中的属性 nextTable = nextTab; // transferIndex 也是 ConcurrentHashMap 的属性，用于控制迁移的位置 transferIndex = n; &#125; int nextn = nextTab.length; // ForwardingNode 翻译过来就是正在被迁移的 Node // 这个构造方法会生成一个Node，key、value 和 next 都为 null，关键是 hash 为 MOVED // 后面我们会看到，原数组中位置 i 处的节点完成迁移工作后， // 就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了 // 所以它其实相当于是一个标志。 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // advance 指的是做完了一个位置的迁移工作，可以准备做下一个位置的了 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab /* * 下面这个 for 循环，最难理解的在前面，而要看懂它们，应该先看懂后面的，然后再倒回来看 * */ // i 是位置索引，bound 是边界，注意是从后往前 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // 下面这个 while 真的是不好理解 // advance 为 true 表示可以进行下一个位置的迁移了 // 简单理解结局: i 指向了 transferIndex，bound 指向了 transferIndex-stride while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; // 将 transferIndex 值赋给 nextIndex // 这里 transferIndex 一旦小于等于 0，说明原数组的所有位置都有相应的线程去处理了 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; // 看括号中的代码，nextBound 是这次迁移任务的边界，注意，是从后往前 bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; // 所有的迁移操作已经完成 nextTable = null; // 将新的 nextTab 赋值给 table 属性，完成迁移 table = nextTab; // 重新计算 sizeCtl: n 是原数组长度，所以 sizeCtl 得出的值将是新数组长度的 0.75 倍 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; // 之前我们说过，sizeCtl 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 // 然后，每有一个线程参与迁移就会将 sizeCtl 加 1， // 这里使用 CAS 操作对 sizeCtl 进行减 1，代表做完了属于自己的任务 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 任务结束，方法退出 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 到这里，说明 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT， // 也就是说，所有的迁移任务都做完了，也就会进入到上面的 if(finishing)&#123;&#125; 分支了 finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 如果位置 i 处是空的，没有任何节点，那么放入刚刚初始化的 ForwardingNode ”空节点“ else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 该位置处是一个 ForwardingNode，代表该位置已经迁移过了 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 对数组该位置处的结点加锁，开始处理数组该位置处的迁移工作 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // 头节点的 hash 大于 0，说明是链表的 Node 节点 if (fh &gt;= 0) &#123; // 下面这一块和 Java7 中的 ConcurrentHashMap 迁移是差不多的， // 需要将链表一分为二， // 找到原链表中的 lastRun，然后 lastRun 及其之后的节点是一起进行迁移的 // lastRun 之前的节点需要进行克隆，然后分到两个链表中 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 其中的一个链表放在新数组的位置 i setTabAt(nextTab, i, ln); // 另一个链表放在新数组的位置 i+n setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; &#125; else if (f instanceof TreeBin) &#123; // 红黑树的迁移 TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 如果一分为二后，节点数小于等于6，那么将红黑树转换回链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; // 将 ln 放置在新数组的位置 i setTabAt(nextTab, i, ln); // 将 hn 放置在新数组的位置 i+n setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; &#125; &#125; &#125; &#125; &#125;&#125; 说到底，transfer 这个方法并没有实现所有的迁移任务，每次调用这个方法只实现了 transferIndex 往前 stride 个位置的迁移工作，其他的需要由外围来控制。 这个时候，再回去仔细看 tryPresize 方法可能就会更加清晰一些了。 get 过程分析get 方法从来都是最简单的，这里也不例外: 计算 hash 值 根据 hash 值找到数组对应位置: (n - 1) &amp; h 根据该位置处结点性质进行相应查找 如果该位置为 null，那么直接返回 null 就可以了 如果该位置处的节点刚好就是我们需要的，返回该节点的值即可 如果该位置节点的 hash 值小于 0，说明正在扩容，或者是红黑树，后面我们再介绍 find 方法 如果以上 3 条都不满足，那就是链表，进行遍历比对即可 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; // 判断头节点是否就是我们需要的节点 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; // 如果头节点的 hash 小于 0，说明 正在扩容，或者该位置是红黑树 else if (eh &lt; 0) // 参考 ForwardingNode.find(int h, Object k) 和 TreeBin.find(int h, Object k) return (p = e.find(h, key)) != null ? p.val : null; // 遍历链表 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 简单说一句，此方法的大部分内容都很简单，只有正好碰到扩容的情况，ForwardingNode.find(int h, Object k) 稍微复杂一些，不过在了解了数据迁移的过程后，这个也就不难了，所以限于篇幅这里也不展开说了。 对比总结 HashTable : 使用了synchronized关键字对put等操作进行加锁; ConcurrentHashMap JDK1.7: 使用分段锁机制实现; ConcurrentHashMap JDK1.8: 则使用数组+链表+红黑树数据结构和CAS原子操作实现; 参考文章 https://blog.csdn.net/defonds/article/details/44021605#t7 http://tutorials.jenkov.com/java-concurrency/index.html https://juejin.im/post/5aeeaba8f265da0b9d781d16 https://www.javadoop.com/post/hashmap#Java7%20ConcurrentHashMap https://blog.csdn.net/Bill_Xiang_/article/details/81122044 https://www.cnblogs.com/leesf456/p/5453341.html https://www.cnblogs.com/huaizuo/archive/2016/04/20/5413069.html","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"13.JUC锁: ReentrantReadWriteLock详解","path":"/2023/12/25/13-JUC锁-ReentrantReadWriteLock详解/","content":"ReentrantReadWriteLock表示可重入读写锁，ReentrantReadWriteLock中包含了两种锁，读锁ReadLock和写锁WriteLock，可以通过这两种锁实现线程间的同步。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 为了有了ReentrantLock还需要ReentrantReadWriteLock? ReentrantReadWriteLock底层实现原理? ReentrantReadWriteLock底层读写状态如何设计的? 高16位为读锁，低16位为写锁 读锁和写锁的最大数量是多少? 本地线程计数器ThreadLocalHoldCounter是用来做什么的? 缓存计数器HoldCounter是用来做什么的? 写锁的获取与释放是怎么实现的? 读锁的获取与释放是怎么实现的? RentrantReadWriteLock为什么不支持锁升级? 什么是锁的升降级? RentrantReadWriteLock为什么不支持锁升级? ReentrantReadWriteLock数据结构ReentrantReadWriteLock底层是基于ReentrantLock和AbstractQueuedSynchronizer来实现的，所以，ReentrantReadWriteLock的数据结构也依托于AQS的数据结构。 ReentrantReadWriteLock源码分析类的继承关系1public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123;&#125; 说明: 可以看到，ReentrantReadWriteLock实现了ReadWriteLock接口，ReadWriteLock接口定义了获取读锁和写锁的规范，具体需要实现类去实现；同时其还实现了Serializable接口，表示可以进行序列化，在源代码中可以看到ReentrantReadWriteLock实现了自己的序列化逻辑。 类的内部类ReentrantReadWriteLock有五个内部类，五个内部类之间也是相互关联的。内部类的关系如下图所示。 说明: 如上图所示，Sync继承自AQS、NonfairSync继承自Sync类、FairSync继承自Sync类；ReadLock实现了Lock接口、WriteLock也实现了Lock接口。 内部类 - Sync类 类的继承关系 1abstract static class Sync extends AbstractQueuedSynchronizer &#123;&#125; 说明: Sync抽象类继承自AQS抽象类，Sync类提供了对ReentrantReadWriteLock的支持。 类的内部类 Sync类内部存在两个内部类，分别为HoldCounter和ThreadLocalHoldCounter，其中HoldCounter主要与读锁配套使用，其中，HoldCounter源码如下。 12345678// 计数器static final class HoldCounter &#123; // 计数 int count = 0; // Use id, not reference, to avoid garbage retention // 获取当前线程的TID属性的值 final long tid = getThreadId(Thread.currentThread());&#125; 说明: HoldCounter主要有两个属性，count和tid，其中count表示某个读线程重入的次数，tid表示该线程的tid字段的值，该字段可以用来唯一标识一个线程。ThreadLocalHoldCounter的源码如下 12345678// 本地线程计数器static final class ThreadLocalHoldCounter extends ThreadLocal&lt;HoldCounter&gt; &#123; // 重写初始化方法，在没有进行set的情况下，获取的都是该HoldCounter值 public HoldCounter initialValue() &#123; return new HoldCounter(); &#125;&#125; 说明: ThreadLocalHoldCounter重写了ThreadLocal的initialValue方法，ThreadLocal类可以将线程与对象相关联。在没有进行set的情况下，get到的均是initialValue方法里面生成的那个HolderCounter对象。 类的属性 1234567891011121314151617181920abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 版本序列号 private static final long serialVersionUID = 6317671515068378041L; // 高16位为读锁，低16位为写锁 static final int SHARED_SHIFT = 16; // 读锁单位 static final int SHARED_UNIT = (1 &lt;&lt; SHARED_SHIFT); // 读锁最大数量 static final int MAX_COUNT = (1 &lt;&lt; SHARED_SHIFT) - 1; // 写锁最大数量 static final int EXCLUSIVE_MASK = (1 &lt;&lt; SHARED_SHIFT) - 1; // 本地线程计数器 private transient ThreadLocalHoldCounter readHolds; // 缓存的计数器 private transient HoldCounter cachedHoldCounter; // 第一个读线程 private transient Thread firstReader = null; // 第一个读线程的计数 private transient int firstReaderHoldCount;&#125; 说明: 该属性中包括了读锁、写锁线程的最大量。本地线程计数器等。 类的构造函数 1234567// 构造函数Sync() &#123; // 本地线程计数器 readHolds = new ThreadLocalHoldCounter(); // 设置AQS的状态 setState(getState()); // ensures visibility of readHolds&#125; 说明: 在Sync的构造函数中设置了本地线程计数器和AQS的状态state。 内部类 - Sync核心函数分析对ReentrantReadWriteLock对象的操作绝大多数都转发至Sync对象进行处理。下面对Sync类中的重点函数进行分析 sharedCount函数 表示占有读锁的线程数量，源码如下 1static int sharedCount(int c) &#123; return c &gt;&gt;&gt; SHARED_SHIFT; &#125; 说明: 直接将state右移16位，就可以得到读锁的线程数量，因为state的高16位表示读锁，对应的低十六位表示写锁数量。 exclusiveCount函数 表示占有写锁的线程数量，源码如下 1static int exclusiveCount(int c) &#123; return c &amp; EXCLUSIVE_MASK; &#125; 说明: 直接将状态state和(2^16 - 1)做与运算，其等效于将state模上2^16。写锁数量由state的低十六位表示。 tryRelease函数 12345678910111213141516171819/** Note that tryRelease and tryAcquire can be called by* Conditions. So it is possible that their arguments contain* both read and write holds that are all released during a* condition wait and re-established in tryAcquire.*/protected final boolean tryRelease(int releases) &#123; // 判断是否伪独占线程 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 计算释放资源后的写锁的数量 int nextc = getState() - releases; boolean free = exclusiveCount(nextc) == 0; // 是否释放成功 if (free) setExclusiveOwnerThread(null); // 设置独占线程为空 setState(nextc); // 设置状态 return free;&#125; 说明: 此函数用于释放写锁资源，首先会判断该线程是否为独占线程，若不为独占线程，则抛出异常，否则，计算释放资源后的写锁的数量，若为0，表示成功释放，资源不将被占用，否则，表示资源还被占用。其函数流程图如下。 tryAcquire函数 123456789101112131415161718192021222324252627282930313233343536protected final boolean tryAcquire(int acquires) &#123; /* * Walkthrough: * 1. If read count nonzero or write count nonzero * and owner is a different thread, fail. * 2. If count would saturate, fail. (This can only * happen if count is already nonzero.) * 3. Otherwise, this thread is eligible for lock if * it is either a reentrant acquire or * queue policy allows it. If so, update state * and set owner. */ // 获取当前线程 Thread current = Thread.currentThread(); // 获取状态 int c = getState(); // 写线程数量 int w = exclusiveCount(c); if (c != 0) &#123; // 状态不为0 // (Note: if c != 0 and w == 0 then shared count != 0) if (w == 0 || current != getExclusiveOwnerThread()) // 写线程数量为0或者当前线程没有占有独占资源 return false; if (w + exclusiveCount(acquires) &gt; MAX_COUNT) // 判断是否超过最高写线程数量 throw new Error(&quot;Maximum lock count exceeded&quot;); // Reentrant acquire // 设置AQS状态 setState(c + acquires); return true; &#125; if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) // 写线程是否应该被阻塞 return false; // 设置独占线程 setExclusiveOwnerThread(current); return true;&#125; 说明: 此函数用于获取写锁，首先会获取state，判断是否为0，若为0，表示此时没有读锁线程，再判断写线程是否应该被阻塞，而在非公平策略下总是不会被阻塞，在公平策略下会进行判断(判断同步队列中是否有等待时间更长的线程，若存在，则需要被阻塞，否则，无需阻塞)，之后在设置状态state，然后返回true。若state不为0，则表示此时存在读锁或写锁线程，若写锁线程数量为0或者当前线程为独占锁线程，则返回false，表示不成功，否则，判断写锁线程的重入次数是否大于了最大值，若是，则抛出异常，否则，设置状态state，返回true，表示成功。其函数流程图如下 tryReleaseShared函数 1234567891011121314151617181920212223242526272829303132333435363738protected final boolean tryReleaseShared(int unused) &#123; // 获取当前线程 Thread current = Thread.currentThread(); if (firstReader == current) &#123; // 当前线程为第一个读线程 // assert firstReaderHoldCount &gt; 0; if (firstReaderHoldCount == 1) // 读线程占用的资源数为1 firstReader = null; else // 减少占用的资源 firstReaderHoldCount--; &#125; else &#123; // 当前线程不为第一个读线程 // 获取缓存的计数器 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) // 计数器为空或者计数器的tid不为当前正在运行的线程的tid // 获取当前线程对应的计数器 rh = readHolds.get(); // 获取计数 int count = rh.count; if (count &lt;= 1) &#123; // 计数小于等于1 // 移除 readHolds.remove(); if (count &lt;= 0) // 计数小于等于0，抛出异常 throw unmatchedUnlockException(); &#125; // 减少计数 --rh.count; &#125; for (;;) &#123; // 无限循环 // 获取状态 int c = getState(); // 获取状态 int nextc = c - SHARED_UNIT; if (compareAndSetState(c, nextc)) // 比较并进行设置 // Releasing the read lock has no effect on readers, // but it may allow waiting writers to proceed if // both read and write locks are now free. return nextc == 0; &#125;&#125; 说明: 此函数表示读锁线程释放锁。首先判断当前线程是否为第一个读线程firstReader，若是，则判断第一个读线程占有的资源数firstReaderHoldCount是否为1，若是，则设置第一个读线程firstReader为空，否则，将第一个读线程占有的资源数firstReaderHoldCount减1；若当前线程不是第一个读线程，那么首先会获取缓存计数器(上一个读锁线程对应的计数器 )，若计数器为空或者tid不等于当前线程的tid值，则获取当前线程的计数器，如果计数器的计数count小于等于1，则移除当前线程对应的计数器，如果计数器的计数count小于等于0，则抛出异常，之后再减少计数即可。无论何种情况，都会进入无限循环，该循环可以确保成功设置状态state。其流程图如下 tryAcquireShared函数 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657private IllegalMonitorStateException unmatchedUnlockException() &#123; return new IllegalMonitorStateException( &quot;attempt to unlock read lock, not locked by current thread&quot;);&#125;// 共享模式下获取资源protected final int tryAcquireShared(int unused) &#123; /* * Walkthrough: * 1. If write lock held by another thread, fail. * 2. Otherwise, this thread is eligible for * lock wrt state, so ask if it should block * because of queue policy. If not, try * to grant by CASing state and updating count. * Note that step does not check for reentrant * acquires, which is postponed to full version * to avoid having to check hold count in * the more typical non-reentrant case. * 3. If step 2 fails either because thread * apparently not eligible or CAS fails or count * saturated, chain to version with full retry loop. */ // 获取当前线程 Thread current = Thread.currentThread(); // 获取状态 int c = getState(); if (exclusiveCount(c) != 0 &amp;&amp; getExclusiveOwnerThread() != current) // 写线程数不为0并且占有资源的不是当前线程 return -1; // 读锁数量 int r = sharedCount(c); if (!readerShouldBlock() &amp;&amp; r &lt; MAX_COUNT &amp;&amp; compareAndSetState(c, c + SHARED_UNIT)) &#123; // 读线程是否应该被阻塞、并且小于最大值、并且比较设置成功 if (r == 0) &#123; // 读锁数量为0 // 设置第一个读线程 firstReader = current; // 读线程占用的资源数为1 firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; // 当前线程为第一个读线程 // 占用资源数加1 firstReaderHoldCount++; &#125; else &#123; // 读锁数量不为0并且不为当前线程 // 获取计数器 HoldCounter rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) // 计数器为空或者计数器的tid不为当前正在运行的线程的tid // 获取当前线程对应的计数器 cachedHoldCounter = rh = readHolds.get(); else if (rh.count == 0) // 计数为0 // 设置 readHolds.set(rh); rh.count++; &#125; return 1; &#125; return fullTryAcquireShared(current);&#125; 说明: 此函数表示读锁线程获取读锁。首先判断写锁是否为0并且当前线程不占有独占锁，直接返回；否则，判断读线程是否需要被阻塞并且读锁数量是否小于最大值并且比较设置状态成功，若当前没有读锁，则设置第一个读线程firstReader和firstReaderHoldCount；若当前线程线程为第一个读线程，则增加firstReaderHoldCount；否则，将设置当前线程对应的HoldCounter对象的值。流程图如下。 fullTryAcquireShared函数 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758final int fullTryAcquireShared(Thread current) &#123; /* * This code is in part redundant with that in * tryAcquireShared but is simpler overall by not * complicating tryAcquireShared with interactions between * retries and lazily reading hold counts. */ HoldCounter rh = null; for (;;) &#123; // 无限循环 // 获取状态 int c = getState(); if (exclusiveCount(c) != 0) &#123; // 写线程数量不为0 if (getExclusiveOwnerThread() != current) // 不为当前线程 return -1; // else we hold the exclusive lock; blocking here // would cause deadlock. &#125; else if (readerShouldBlock()) &#123; // 写线程数量为0并且读线程被阻塞 // Make sure we&#x27;re not acquiring read lock reentrantly if (firstReader == current) &#123; // 当前线程为第一个读线程 // assert firstReaderHoldCount &gt; 0; &#125; else &#123; // 当前线程不为第一个读线程 if (rh == null) &#123; // 计数器不为空 // rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) &#123; // 计数器为空或者计数器的tid不为当前正在运行的线程的tid rh = readHolds.get(); if (rh.count == 0) readHolds.remove(); &#125; &#125; if (rh.count == 0) return -1; &#125; &#125; if (sharedCount(c) == MAX_COUNT) // 读锁数量为最大值，抛出异常 throw new Error(&quot;Maximum lock count exceeded&quot;); if (compareAndSetState(c, c + SHARED_UNIT)) &#123; // 比较并且设置成功 if (sharedCount(c) == 0) &#123; // 读线程数量为0 // 设置第一个读线程 firstReader = current; // firstReaderHoldCount = 1; &#125; else if (firstReader == current) &#123; firstReaderHoldCount++; &#125; else &#123; if (rh == null) rh = cachedHoldCounter; if (rh == null || rh.tid != getThreadId(current)) rh = readHolds.get(); else if (rh.count == 0) readHolds.set(rh); rh.count++; cachedHoldCounter = rh; // cache for release &#125; return 1; &#125; &#125;&#125; 说明: 在tryAcquireShared函数中，如果下列三个条件不满足(读线程是否应该被阻塞、小于最大值、比较设置成功)则会进行fullTryAcquireShared函数中，它用来保证相关操作可以成功。其逻辑与tryAcquireShared逻辑类似，不再累赘。 而其他内部类的操作基本上都是转化到了对Sync对象的操作，在此不再累赘。 类的属性1234567891011121314151617181920212223242526public class ReentrantReadWriteLock implements ReadWriteLock, java.io.Serializable &#123; // 版本序列号 private static final long serialVersionUID = -6992448646407690164L; // 读锁 private final ReentrantReadWriteLock.ReadLock readerLock; // 写锁 private final ReentrantReadWriteLock.WriteLock writerLock; // 同步队列 final Sync sync; private static final sun.misc.Unsafe UNSAFE; // 线程ID的偏移地址 private static final long TID_OFFSET; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; tk = Thread.class; // 获取线程的tid字段的内存地址 TID_OFFSET = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;tid&quot;)); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125;&#125; 说明: 可以看到ReentrantReadWriteLock属性包括了一个ReentrantReadWriteLock.ReadLock对象，表示读锁；一个ReentrantReadWriteLock.WriteLock对象，表示写锁；一个Sync对象，表示同步队列。 类的构造函数 ReentrantReadWriteLock()型构造函数 123public ReentrantReadWriteLock() &#123; this(false);&#125; 说明: 此构造函数会调用另外一个有参构造函数。 ReentrantReadWriteLock(boolean)型构造函数 12345678public ReentrantReadWriteLock(boolean fair) &#123; // 公平策略或者是非公平策略 sync = fair ? new FairSync() : new NonfairSync(); // 读锁 readerLock = new ReadLock(this); // 写锁 writerLock = new WriteLock(this);&#125; 说明: 可以指定设置公平策略或者非公平策略，并且该构造函数中生成了读锁与写锁两个对象。 核心函数分析对ReentrantReadWriteLock的操作基本上都转化为了对Sync对象的操作，而Sync的函数已经分析过，不再累赘。 ReentrantReadWriteLock示例下面给出了一个使用ReentrantReadWriteLock的示例，源代码如下。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.concurrent.locks.ReentrantReadWriteLock;class ReadThread extends Thread &#123; private ReentrantReadWriteLock rrwLock; public ReadThread(String name, ReentrantReadWriteLock rrwLock) &#123; super(name); this.rrwLock = rrwLock; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; trying to lock&quot;); try &#123; rrwLock.readLock().lock(); System.out.println(Thread.currentThread().getName() + &quot; lock successfully&quot;); Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; rrwLock.readLock().unlock(); System.out.println(Thread.currentThread().getName() + &quot; unlock successfully&quot;); &#125; &#125;&#125;class WriteThread extends Thread &#123; private ReentrantReadWriteLock rrwLock; public WriteThread(String name, ReentrantReadWriteLock rrwLock) &#123; super(name); this.rrwLock = rrwLock; &#125; public void run() &#123; System.out.println(Thread.currentThread().getName() + &quot; trying to lock&quot;); try &#123; rrwLock.writeLock().lock(); System.out.println(Thread.currentThread().getName() + &quot; lock successfully&quot;); &#125; finally &#123; rrwLock.writeLock().unlock(); System.out.println(Thread.currentThread().getName() + &quot; unlock successfully&quot;); &#125; &#125;&#125;public class ReentrantReadWriteLockDemo &#123; public static void main(String[] args) &#123; ReentrantReadWriteLock rrwLock = new ReentrantReadWriteLock(); ReadThread rt1 = new ReadThread(&quot;rt1&quot;, rrwLock); ReadThread rt2 = new ReadThread(&quot;rt2&quot;, rrwLock); WriteThread wt1 = new WriteThread(&quot;wt1&quot;, rrwLock); rt1.start(); rt2.start(); wt1.start(); &#125; &#125; 运行结果(某一次): 123456789rt1 trying to lockrt2 trying to lockwt1 trying to lockrt1 lock successfullyrt2 lock successfullyrt1 unlock successfullyrt2 unlock successfullywt1 lock successfullywt1 unlock successfully 说明: 程序中生成了一个ReentrantReadWriteLock对象，并且设置了两个读线程，一个写线程。根据结果，可能存在如下的时序图。 rt1线程执行rrwLock.readLock().lock操作，主要的函数调用如下。 说明: 此时，AQS的状态state为2^16 次方，即表示此时读线程数量为1。 rt2线程执行rrwLock.readLock().lock操作，主要的函数调用如下。 说明: 此时，AQS的状态state为2 * 2^16次方，即表示此时读线程数量为2。 wt1线程执行rrwLock.writeLock().lock操作，主要的函数调用如下。 说明: 此时，在同步队列Sync queue中存在两个结点，并且wt1线程会被禁止运行。 rt1线程执行rrwLock.readLock().unlock操作，主要的函数调用如下。 说明: 此时，AQS的state为2^16次方，表示还有一个读线程。 rt2线程执行rrwLock.readLock().unlock操作，主要的函数调用如下。 说明: 当rt2线程执行unlock操作后，AQS的state为0，并且wt1线程将会被unpark，其获得CPU资源就可以运行。 wt1线程获得CPU资源，继续运行，需要恢复。由于之前acquireQueued函数中的parkAndCheckInterrupt函数中被禁止的，所以，恢复到parkAndCheckInterrupt函数中，主要的函数调用如下 说明: 最后，sync queue队列中只有一个结点，并且头节点尾节点均指向它，AQS的state值为1，表示此时有一个写线程。 wt1执行rrwLock.writeLock().unlock操作，主要的函数调用如下。 说明: 此时，AQS的state为0，表示没有任何读线程或者写线程了。并且Sync queue结构与上一个状态的结构相同，没有变化。 更深入理解什么是锁升降级?锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住(当前拥有的)写锁，再获取到读锁，随后释放(先前拥有的)写锁的过程。 接下来看一个锁降级的示例。因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作，如代码如下所示： 123456789101112131415161718192021222324public void processData() &#123; readLock.lock(); if (!update) &#123; // 必须先释放读锁 readLock.unlock(); // 锁降级从写锁获取到开始 writeLock.lock(); try &#123; if (!update) &#123; // 准备数据的流程(略) update = true; &#125; readLock.lock(); &#125; finally &#123; writeLock.unlock(); &#125; // 锁降级完成，写锁降级为读锁 &#125; try &#123; // 使用数据的流程(略) &#125; finally &#123; readLock.unlock(); &#125;&#125; 上述示例中，当数据发生变更后，update变量(布尔类型且volatile修饰)被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。 锁降级中读锁的获取是否必要呢? 答案是必要的。主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程(记作线程T)获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。 RentrantReadWriteLock不支持锁升级(把持读锁、获取写锁，最后释放读锁的过程)。目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的。 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5419132.html，在此基础上做了增改。 https://blog.csdn.net/jiankunking/article/details/83954263","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"谷歌大模型-Gemini 快速开始","path":"/2023/12/25/谷歌大模型-Gemini-快速开始/","content":"引言近期相信大家都听说了谷歌大模型：Gemini Gemini官网访问官方网站： 官网地址：Google AI for Developers 官方已经提供了体验入口，大家可以很方便地体验谷歌发布的最大且能力最强的AI模型。 「使用条件：」 Google账号 科学上网 如何Gemini使用点击上图中 Get API key in Google AI Studio, 打开Google AI Studio。如果是首次打开，则需要同意相关服务条款： 第一条必须选择，第二条和第三条可以不选! 服务条款 使用Gemini的两种方式如下图，Google目前提供了两种使用Gemini的方式：Google AI Studio 和 Develop in your own environment，即在类似于ChatGPT的页面上直接使用和方便开发者在自己的环境中使用的API方式。 选择使用Gemini方式 方式一：使用Google AI Studio，这里了不起也就探索了一下页面方式 Google AI Studio Google AI Studio提供了三种类型的Prompt方式： 「FreeForm prompt（自由式提示语）」 该提示为生成内容和对应指令的响应提供了开放式的提示体验。您可以使用图像和文本作为提示。 「Structured prompt（结构化提示语）」 这种提示技术允许您通过提供一组示例请求和应答来指导模型输出。当您需要对模型输出的结构进行更多的控制时，可以使用这种方法。 「Chat prompt（对话式提示语）」 使用对话式提示构建对话体验。该提示技术允许多次输入和响应轮流生成输出。 自由格式提示示例：详细了解建筑物Gemini 的多模态功能可让您结合使用图像和文本来提示模型。例如，您可以使用此功能详细了解图片中显示的建筑物。 第 1 步 - 使用文本和图片创建提示如需创建多模态提示，请执行以下操作： 进入 Google AI Studio。 在左侧面板中，依次选择 新建 &gt; 自由格式提示 。 在右侧列的模型字段中，选择支持图像的模型，例如 Gemini Pro Vision 模型。 在提示文本区域中，输入以下文本： 1look at the following picture and tell me who is the architect 从提示区域上方的插入栏中，选择 图片 ，然后选择某个建筑物的示例图片。 在应用窗口的底部，选择 Run 以生成此请求的回复。 第 2 步 - 在提示符中添加可替换的变量在第 1 步中，您使用固定的文本字符串和图像提示模型。但有时，您希望能够动态更改提示的某些部分。例如，如果您要构建交互式应用，可能需要使用不同的用户输入来修改提示。为此，您可以使用变量将提示参数化。 如需向提示添加变量，请执行以下操作： 选择要在问题中替换的字词或短语。在本例中，请选择文本：who is the architect。 从提示上方的 Insert: 标头中，选择 &#123;&#123; &#125;&#125; Test input 。 在提示下方的 Test yourPrompt 表格中，为您的提示添加一个额外的值，方法是选择Add test example并输入额外的提示值。您可以随意添加几个新的输入值。 在应用窗口的底部，选择 Run 以为每个不同的请求生成回复。 第 3 步 - 用模型参数进行实验在对提示进行原型设计时，您还可以在应用右侧的试用模型运行设置。以下是需要了解的关键设置： 模型 - 选择您要回答问题的模型。如需详细了解可用的模型和功能，请参阅模型。 温度 - 控制模型响应可以允许多大程度的随机性。提高此值可让模型生成更意外且更具创造性的响应。 最大输出 - 增加模型为每个请求返回的响应数。此选项能够针对单个提示生成多个响应，有助于快速测试提示。 Safety settings - 调整用于管理模型响应的安全设置。如需详细了解这些控制措施，请参阅安全设置。 第 4 步 - 后续步骤现在，您已经为生成式 AI 应用设计了原型，接下来可以保存您的工作或生成代码，以便在您自己的开发环境中使用此提示。 如需保存您创建的提示，请执行以下操作： 在 Google AI Studio 应用的右上角，选择 保存 。 如果您尚未将应用关联到您的 Google 云端硬盘帐号，请执行此操作。 在保存提示对话框中，输入提示名称和可选的 说明 ，然后选择 保存 。 如需将您创建的提示以代码的形式导出，请执行以下操作： 在 Google AI Studio 应用的右上角，选择 获取代码 。 选择一个编程语言标签页。 选择复制以将此代码复制到剪贴板。 注意 ：您需要使用 API 密钥才能在 Google AI Studio 之外运行提示代码，因此请务必创建一个密钥，并将其包含在提示代码中。注意 ：请将 API 密钥视为密码并妥善保护。请勿将您的密钥嵌入到公开发布的代码中。 结构化提示示例：构建商品文案生成器到目前为止，您已经了解了如何使用指令（“看图片，告诉我架构师是谁”）来提示模型。但是，有时，您可以通过结合说明和示例来向模型发出提示，从而获得更好的结果。Google AI Studio 中的结构化提示可帮助您做到这一点 - 将指令与示例相结合，向模型显示您想要的输出类型，而不是仅仅指示模型要执行什么操作。如果您希望模型保持一致的输出格式（即结构化 json）或难以描述模型的具体风格，这种提示非常有用。在本部分中，您将了解如何在 Google AI Studio 中创建结构化提示。 注意 ：您可以直接在 Google AI Studio 中从示例库中尝试此示例。 第 1 步 - 创建结构化提示在此示例中，您将创建一个结构化提示，用于为产品生成广告文案。首先，您需要创建两列（Product 输入列和 Product copy 输出列）来定义提示的结构。 如需创建结构化提示，请执行以下操作： 在 Google AI Studio Web 应用的左上角，依次选择 新建 &gt; 结构化提示 。 在 Insert: 标头下方，添加结构化提示的说明： 123You are a product marketer targeting a Gen Z audience. Create exciting andfresh advertising copy for products and their simple description. Keep copyunder a few sentences long. 通过将默认的 input: 文本说明替换为 Product:，为 INPUT 添加描述性标题。 通过将默认的 output: 文本说明替换为 Product copy:，为 OUTPUT 添加描述性标题。 提示 ：在列名称末尾添加英文冒号，以便模型更轻松地解析结构。 第 2 步 - 添加示例现在您已为列命名，请提供一些示例行。这些行应包含示例输入（本例中的产品名称）和示例输出（对应的产品说明）。通过为模型提供几个示例产品说明，您可以指导模型在生成自己的输出时复制类似的风格。您可以手动输入示例，也可以使用“导入数据”菜单从文件导入。 要手动输入示例，请执行以下操作： 在顶部的示例数据表中，选择 Product: 标题下方的字段，然后输入产品说明。 选择 Product copy: 标题下的字段，然后为此商品输入 marketing copy。 以下示例展示了此提示的输入和输出值： 产品： 产品文案： 老式运动鞋 让我们系上安全带！这些鞋子的外观和颜色也别具一格，拥有别具一格的风格和功能。 超柔软连帽衫 穿上我们全新的男女通用连帽衫，舒适又时尚！这款连帽衫由 100% 棉制成，柔软舒适，全天佩戴。即使是在最冷的日子，里面的半刷墙也能让你保持温暖。 提示 ：如果您让作者屏蔽或者没有示例产品文案示例，则可以使用自由格式提示让文本模型为您生成一些示例。如需从文件导入示例，请执行以下操作： 在示例表的右上角，依次选择 操作 &gt; 导入示例 。 在对话框中，选择 Google 云端硬盘中的 CSV 或 Google 表格文件，或者从计算机上传。 在“导入示例”对话框中，选择要导入的列，要排除哪些列。通过该对话框，您还可以在结构化提示中指定将哪个数据列导入哪个表列。 第 3 步 - 测试您的提示准备好向模型显示所需内容的示例后，在底部的测试您的提示表中使用新输入来测试提示。与文本提示类型一样，您可以调整模型参数，以测试这些参数是否有助于为您的使用场景生成更好的结果。 查看如何将样本发送到模型从本质上讲，Google AI Studio 会将指令与您提供的示例相结合来构建提示。随着您添加更多样本，这些样本会添加到发送给模型的文本中。根据样本的长度，您可能会开始达到模型的词元限制。所有生成式 AI 模型都有令牌限制，即它们可以接受作为输入的文本的最大长度。 如需查看提示的完整内容，请执行以下操作： 选择 Google AI Studio Web 应用底部的 文本预览 。 注意 ：模型令牌限制显示在预览窗格底部。 第 4 步 - 后续步骤如果您对提示感到满意，可以点击获取代码按钮将其保存或导出到代码中。 您还可以将各个少样本样本导出到 CSV 文件或 Google 表格中。选择操作菜单下的导出示例选项以导出您的示例。 聊天提示示例：构建自定义聊天应用如果您使用过 Bard 等通用聊天机器人，就能亲身体验生成式 AI 模型在开放式对话方面的强大之处。虽然这些通用聊天机器人非常有用，但它们通常需要针对特定使用场景进行定制。例如，您可能希望构建一个客户服务聊天机器人，它仅支持有关公司产品的对话的对话。您可能需要构建一个使用特定语气或风格的聊天机器人：一个可以讲大量笑话、像诗人押韵的机器人，或在回答中使用大量表情符号。 此示例展示了如何使用 Google AI Studio 构建一个友好的聊天机器人，它就像是居住在木星的一颗卫星“欧罗巴”上的外星人一样进行沟通。 第 1 步 - 创建聊天提示在上一部分中，您设计了使用输入和输出示例组合的结构化提示。同样，如需构建聊天机器人，您需要提供用户和聊天机器人之间的互动示例，以指导模型提供您需要的响应。 如需创建聊天提示，请执行以下操作： 在 Google AI Studio Web 应用的左上角，依次选择 新建 &gt; Chat 提示 。 在提示界面的编写提示示例列中，您可以开始提供互动示例。您还可以在第一个示例中提供其他上下文，例如： 123User: You are Tim, a friendly alien that lives on Europa, one ofJupiter&#x27;s moons.Model: Ok User 和 Model 字段中提供了用户和聊天机器人之间的互动示例： 123User: Hi!Model: Hi! My name is Tim and I live on Europa, one of Jupiter&#x27;s moons. Brr!It&#x27;s cold down here! 填写完示例后，通过在聊天提示界面的右侧窗格中与模型聊天来开始测试您的应用。 如需测试聊天机器人的行为，请执行以下操作： 在测试提示面板中，选择底部的输入字段。 输入用户可能提出的问题或观察结果，例如： 1What&#x27;s the weather like? 选择输入字段右侧的菱形按钮，以获取聊天机器人的响应，响应可能如下所示： 1Model:The weather on Europais very cold and icy.... 第 2 步 - 训练聊天机器人更好地聊天通过提供一个语句和响应示例，您可以构建一个基本的欧罗巴外星聊天机器人。但是，单个样本通常不足以确保模型响应的一致性和质量。如果没有进一步输入，模型对天气相关问题的回答往往会很长，听起来像是教科书里的回答，而不是友好的外星人给出的回答。 使用模型响应并对其进行修改，以匹配外星聊天机器人所需的语气和风格，从而自定义聊天机器人的语气。 如需添加和修改聊天机器人定义的示例，请执行以下操作： 在 Test yourPrompt 面板中，将光标悬停在 User 标题的左侧，然后选择 Add to examples 按钮。 在编写提示示例列中，修改复制的输入和响应，以匹配聊天机器人的预期风格和语气。 您可以使用此方法添加更多示例。提出更多问题、修改答案，并提高聊天机器人的质量。继续添加示例，并测试这些示例会如何修改聊天机器人的行为。通常，示例越多，聊天机器人响应的质量越高。 在后台，Google AI Studio 会通过组合以下各项来构建提示： 对话框示例 对话记录 文本块传递给模型。如需查看完整的提示是什么样子，请点击屏幕底部的 Preview ，以调出预览窗格。 请注意，由于模型与用户之间的每条消息都包含在提示中（这就是“对话记录”），因此对话提示可能会随着对话的进行而增长。最终，您可能会达到模型的词元限制，即模型可以接受的文本长度上限。您可以在预览标签页中查看完整的对话和令牌数量。 第 3 步 - 用模型参数进行实验您还可以尝试调整模型参数，以查看它们是否为您的使用场景生成了更合适的结果。 第 4 步 - 后续步骤与其他提示类型类似，一旦对提示的原型设计符合您的要求，您就可以使用获取代码按钮开始编写代码，或保存提示，以便稍后处理并与他人分享。 参考：https://ai.google.dev/tutorials/ai-studio_quickstart","tags":["Google","人工智能","Gemini"],"categories":["人工智能"]},{"title":"12.JUC锁: ReentrantLock详解","path":"/2023/12/25/12-JUC锁-ReentrantLock详解/","content":"可重入锁ReentrantLock的底层是通过AbstractQueuedSynchronizer实现，所以先要学习上一章节AbstractQueuedSynchronizer详解。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 什么是可重入，什么是可重入锁? 它用来解决什么问题? ReentrantLock的核心是AQS，那么它怎么来实现的，继承吗? 说说其类内部结构关系。 ReentrantLock是如何实现公平锁的? ReentrantLock是如何实现非公平锁的? ReentrantLock默认实现的是公平还是非公平锁? 使用ReentrantLock实现公平和非公平锁的示例? ReentrantLock和Synchronized的对比? ReentrantLock源码分析类的继承关系ReentrantLock实现了Lock接口，Lock接口中定义了lock与unlock相关操作，并且还存在newCondition方法，表示生成一个条件。 1public class ReentrantLock implements Lock, java.io.Serializable 类的内部类ReentrantLock总共有三个内部类，并且三个内部类是紧密相关的，下面先看三个类的关系。 说明: ReentrantLock类内部总共存在Sync、NonfairSync、FairSync三个类，NonfairSync与FairSync类继承自Sync类，Sync类继承自AbstractQueuedSynchronizer抽象类。下面逐个进行分析。 Sync类 Sync类的源码如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687abstract static class Sync extends AbstractQueuedSynchronizer &#123; // 序列号 private static final long serialVersionUID = -5179523762034025860L; // 获取锁 abstract void lock(); // 非公平方式获取 final boolean nonfairTryAcquire(int acquires) &#123; // 当前线程 final Thread current = Thread.currentThread(); // 获取状态 int c = getState(); if (c == 0) &#123; // 表示没有线程正在竞争该锁 if (compareAndSetState(0, acquires)) &#123; // 比较并设置状态成功，状态0表示锁没有被占用 // 设置当前线程独占 setExclusiveOwnerThread(current); return true; // 成功 &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 当前线程拥有该锁 int nextc = c + acquires; // 增加重入次数 if (nextc &lt; 0) // overflow throw new Error(&quot;Maximum lock count exceeded&quot;); // 设置状态 setState(nextc); // 成功 return true; &#125; // 失败 return false; &#125; // 试图在共享模式下获取对象状态，此方法应该查询是否允许它在共享模式下获取对象状态，如果允许，则获取它 protected final boolean tryRelease(int releases) &#123; int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) // 当前线程不为独占线程 throw new IllegalMonitorStateException(); // 抛出异常 // 释放标识 boolean free = false; if (c == 0) &#123; free = true; // 已经释放，清空独占 setExclusiveOwnerThread(null); &#125; // 设置标识 setState(c); return free; &#125; // 判断资源是否被当前线程占有 protected final boolean isHeldExclusively() &#123; // While we must in general read state before owner, // we don&#x27;t need to do so to check if current thread is owner return getExclusiveOwnerThread() == Thread.currentThread(); &#125; // 新生一个条件 final ConditionObject newCondition() &#123; return new ConditionObject(); &#125; // Methods relayed from outer class // 返回资源的占用线程 final Thread getOwner() &#123; return getState() == 0 ? null : getExclusiveOwnerThread(); &#125; // 返回状态 final int getHoldCount() &#123; return isHeldExclusively() ? getState() : 0; &#125; // 资源是否被占用 final boolean isLocked() &#123; return getState() != 0; &#125; /** * Reconstitutes the instance from a stream (that is, deserializes it). */ // 自定义反序列化逻辑 private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125;&#125; Sync类存在如下方法和作用如下。 NonfairSync类 NonfairSync类继承了Sync类，表示采用非公平策略获取锁，其实现了Sync类中抽象的lock方法，源码如下: 12345678910111213141516171819// 非公平锁static final class NonfairSync extends Sync &#123; // 版本号 private static final long serialVersionUID = 7316153563782823691L; // 获得锁 final void lock() &#123; if (compareAndSetState(0, 1)) // 比较并设置状态成功，状态0表示锁没有被占用 // 把当前线程设置独占了锁 setExclusiveOwnerThread(Thread.currentThread()); else // 锁已经被占用，或者set失败 // 以独占模式获取对象，忽略中断 acquire(1); &#125; protected final boolean tryAcquire(int acquires) &#123; return nonfairTryAcquire(acquires); &#125;&#125; 说明: 从lock方法的源码可知，每一次都尝试获取锁，而并不会按照公平等待的原则进行等待，让等待时间最久的线程获得锁。 FairSyn类 FairSync类也继承了Sync类，表示采用公平策略获取锁，其实现了Sync类中的抽象lock方法，源码如下: 12345678910111213141516171819202122232425262728293031323334353637383940// 公平锁static final class FairSync extends Sync &#123; // 版本序列化 private static final long serialVersionUID = -3000897897090466540L; final void lock() &#123; // 以独占模式获取对象，忽略中断 acquire(1); &#125; /** * Fair version of tryAcquire. Don&#x27;t grant access unless * recursive call or no waiters or is first. */ // 尝试公平获取锁 protected final boolean tryAcquire(int acquires) &#123; // 获取当前线程 final Thread current = Thread.currentThread(); // 获取状态 int c = getState(); if (c == 0) &#123; // 状态为0 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; // 不存在已经等待更久的线程并且比较并且设置状态成功 // 设置当前线程独占 setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; // 状态不为0，即资源已经被线程占据 // 下一个状态 int nextc = c + acquires; if (nextc &lt; 0) // 超过了int的表示范围 throw new Error(&quot;Maximum lock count exceeded&quot;); // 设置状态 setState(nextc); return true; &#125; return false; &#125;&#125; 说明: 跟踪lock方法的源码可知，当资源空闲时，它总是会先判断sync队列(AbstractQueuedSynchronizer中的数据结构)是否有等待时间更长的线程，如果存在，则将该线程加入到等待队列的尾部，实现了公平获取原则。其中，FairSync类的lock的方法调用如下，只给出了主要的方法。 说明: 可以看出只要资源被其他线程占用，该线程就会添加到sync queue中的尾部，而不会先尝试获取资源。这也是和Nonfair最大的区别，Nonfair每一次都会尝试去获取资源，如果此时该资源恰好被释放，则会被当前线程获取，这就造成了不公平的现象，当获取不成功，再加入队列尾部。 类的属性ReentrantLock类的sync非常重要，对ReentrantLock类的操作大部分都直接转化为对Sync和AbstractQueuedSynchronizer类的操作。 123456public class ReentrantLock implements Lock, java.io.Serializable &#123; // 序列号 private static final long serialVersionUID = 7373984872572414699L; // 同步队列 private final Sync sync;&#125; 类的构造函数 ReentrantLock()型构造函数 默认是采用的非公平策略获取锁 1234public ReentrantLock() &#123; // 默认非公平策略 sync = new NonfairSync();&#125; ReentrantLock(boolean)型构造函数 可以传递参数确定采用公平策略或者是非公平策略，参数为true表示公平策略，否则，采用非公平策略: 123public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; 核心函数分析通过分析ReentrantLock的源码，可知对其操作都转化为对Sync对象的操作，由于Sync继承了AQS，所以基本上都可以转化为对AQS的操作。如将ReentrantLock的lock函数转化为对Sync的lock函数的调用，而具体会根据采用的策略(如公平策略或者非公平策略)的不同而调用到Sync的不同子类。 所以可知，在ReentrantLock的背后，是AQS对其服务提供了支持，由于之前我们分析AQS的核心源码，遂不再累赘。下面还是通过例子来更进一步分析源码。 示例分析公平锁12345678910111213141516171819202122232425262728293031323334353637import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class MyThread extends Thread &#123; private Lock lock; public MyThread(String name, Lock lock) &#123; super(name); this.lock = lock; &#125; public void run () &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread() + &quot; running&quot;); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;public class AbstractQueuedSynchronizerDemo &#123; public static void main(String[] args) throws InterruptedException &#123; Lock lock = new ReentrantLock(true); MyThread t1 = new MyThread(&quot;t1&quot;, lock); MyThread t2 = new MyThread(&quot;t2&quot;, lock); MyThread t3 = new MyThread(&quot;t3&quot;, lock); t1.start(); t2.start(); t3.start(); &#125;&#125; 运行结果(某一次): 123Thread[t1,5,main] runningThread[t2,5,main] runningThread[t3,5,main] running 说明: 该示例使用的是公平策略，由结果可知，可能会存在如下一种时序。 说明: 首先，t1线程的lock操作 -&gt; t2线程的lock操作 -&gt; t3线程的lock操作 -&gt; t1线程的unlock操作 -&gt; t2线程的unlock操作 -&gt; t3线程的unlock操作。根据这个时序图来进一步分析源码的工作流程。 t1线程执行lock.lock，下图给出了方法调用中的主要方法。 说明: 由调用流程可知，t1线程成功获取了资源，可以继续执行。 t2线程执行lock.lock，下图给出了方法调用中的主要方法。 说明: 由上图可知，最后的结果是t2线程会被禁止，因为调用了LockSupport.park。 t3线程执行lock.lock，下图给出了方法调用中的主要方法。 说明: 由上图可知，最后的结果是t3线程会被禁止，因为调用了LockSupport.park。 t1线程调用了lock.unlock，下图给出了方法调用中的主要方法。 说明: 如上图所示，最后，head的状态会变为0，t2线程会被unpark，即t2线程可以继续运行。此时t3线程还是被禁止。 t2获得cpu资源，继续运行，由于t2之前被park了，现在需要恢复之前的状态，下图给出了方法调用中的主要方法。 说明: 在setHead函数中会将head设置为之前head的下一个结点，并且将pre域与thread域都设置为null，在acquireQueued返回之前，sync queue就只有两个结点了。 t2执行lock.unlock，下图给出了方法调用中的主要方法。 说明: 由上图可知，最终unpark t3线程，让t3线程可以继续运行。 t3线程获取cpu资源，恢复之前的状态，继续运行。 说明: 最终达到的状态是sync queue中只剩下了一个结点，并且该节点除了状态为0外，其余均为null。 t3执行lock.unlock，下图给出了方法调用中的主要方法。 说明: 最后的状态和之前的状态是一样的，队列中有一个空节点，头节点为尾节点均指向它。 使用公平策略和Condition的情况可以参考上一篇关于AQS的源码示例分析部分，不再累赘。 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5383609.html，在此基础上做了增改。","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"11.JUC锁: 锁核心类AQS详解","path":"/2023/12/25/11-JUC锁-锁核心类AQS详解/","content":"AbstractQueuedSynchronizer抽象类是核心，需要重点掌握。它提供了一个基于FIFO队列，可以用于构建锁或者其他相关同步装置的基础框架。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 什么是AQS? 为什么它是核心? AQS的核心思想是什么? 它是怎么实现的? 底层数据结构等 AQS有哪些核心的方法? AQS定义什么样的资源获取方式? AQS定义了两种资源获取方式：独占(只有一个线程能访问执行，又根据是否按队列的顺序分为公平锁和非公平锁，如ReentrantLock) 和共享(多个线程可同时访问执行，如Semaphore、CountDownLatch、 CyclicBarrier )。ReentrantReadWriteLock可以看成是组合式，允许多个线程同时对某一资源进行读。 AQS底层使用了什么样的设计模式? 模板 AQS的应用示例? AbstractQueuedSynchronizer简介AQS是一个用来构建锁和同步器的框架，使用AQS能简单且高效地构造出应用广泛的大量的同步器，比如我们提到的ReentrantLock，Semaphore，其他的诸如ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。当然，我们自己也能利用AQS非常轻松容易地构造出符合我们自己需求的同步器。 AQS 核心思想AQS核心思想是，如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中。 CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。 AQS使用一个int成员变量来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。AQS使用CAS对该同步状态进行原子操作实现对其值的修改。 1private volatile int state;//共享变量，使用volatile修饰保证线程可见性 状态信息通过procted类型的getState，setState，compareAndSetState进行操作 123456789101112//返回同步状态的当前值protected final int getState() &#123; return state;&#125; // 设置同步状态的值protected final void setState(int newState) &#123; state = newState;&#125;//原子地(CAS操作)将同步状态值设置为给定值update如果当前同步状态的值等于expect(期望值)protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; AQS 对资源的共享方式AQS定义两种资源共享方式 Exclusive(独占)：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁： 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share(共享)：多个线程可同时执行，如Semaphore&#x2F;CountDownLatch。Semaphore、CountDownLatCh、 CyclicBarrier、ReadWriteLock 我们都会在后面讲到。 ReentrantReadWriteLock 可以看成是组合式，因为ReentrantReadWriteLock也就是读写锁允许多个线程同时对某一资源进行读。 不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护(如获取资源失败入队&#x2F;唤醒出队等)，AQS已经在上层已经帮我们实现好了。 AQS底层使用了模板方法模式 同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样(模板方法模式很经典的一个应用)： 使用者继承AbstractQueuedSynchronizer并重写指定的方法。(这些重写方法很简单，无非是对于共享资源state的获取和释放) 将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。 这和我们以往通过实现接口的方式有很大区别，模板方法模式请参看：通设计模式行为型 - 模板方法(Template Method 详解 AQS使用了模板方法模式，自定义同步器时需要重写下面几个AQS提供的模板方法： 12345isHeldExclusively()//该线程是否正在独占资源。只有用到condition才需要去实现它。tryAcquire(int)//独占方式。尝试获取资源，成功则返回true，失败则返回false。tryRelease(int)//独占方式。尝试释放资源，成功则返回true，失败则返回false。tryAcquireShared(int)//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。tryReleaseShared(int)//共享方式。尝试释放资源，成功则返回true，失败则返回false。 默认情况下，每个方法都抛出 UnsupportedOperationException。 这些方法的实现必须是内部线程安全的，并且通常应该简短而不是阻塞。AQS类中的其他方法都是final ，所以无法被其他类使用，只有这几个方法可以被其他类使用。 以ReentrantLock为例，state初始化为0，表示未锁定状态。A线程lock()时，会调用tryAcquire()独占该锁并将state+1。此后，其他线程再tryAcquire()时就会失败，直到A线程unlock()到state&#x3D;0(即释放锁)为止，其它线程才有机会获取该锁。当然，释放锁之前，A线程自己是可以重复获取此锁的(state会累加)，这就是可重入的概念。但要注意，获取多少次就要释放多么次，这样才能保证state是能回到零态的。 AbstractQueuedSynchronizer数据结构AbstractQueuedSynchronizer类底层的数据结构是使用CLH(Craig,Landin,and Hagersten)队列是一个虚拟的双向队列(虚拟的双向队列即不存在队列实例，仅存在结点之间的关联关系)。AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。其中Sync queue，即同步队列，是双向链表，包括head结点和tail结点，head结点主要用作后续的调度。而Condition queue不是必须的，其是一个单向链表，只有当使用Condition时，才会存在此单向链表。并且可能会有多个Condition queue。 AbstractQueuedSynchronizer源码分析类的继承关系AbstractQueuedSynchronizer继承自AbstractOwnableSynchronizer抽象类，并且实现了Serializable接口，可以进行序列化。 1public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable 其中AbstractOwnableSynchronizer抽象类的源码如下: 12345678910111213141516171819public abstract class AbstractOwnableSynchronizer implements java.io.Serializable &#123; // 版本序列号 private static final long serialVersionUID = 3737899427754241961L; // 构造方法 protected AbstractOwnableSynchronizer() &#123; &#125; // 独占模式下的线程 private transient Thread exclusiveOwnerThread; // 设置独占线程 protected final void setExclusiveOwnerThread(Thread thread) &#123; exclusiveOwnerThread = thread; &#125; // 获取独占线程 protected final Thread getExclusiveOwnerThread() &#123; return exclusiveOwnerThread; &#125;&#125; AbstractOwnableSynchronizer抽象类中，可以设置独占资源线程和获取独占资源线程。分别为setExclusiveOwnerThread与getExclusiveOwnerThread方法，这两个方法会被子类调用。 AbstractQueuedSynchronizer类有两个内部类，分别为Node类与ConditionObject类。下面分别做介绍。 类的内部类 - Node类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859static final class Node &#123; // 模式，分为共享与独占 // 共享模式 static final Node SHARED = new Node(); // 独占模式 static final Node EXCLUSIVE = null; // 结点状态 // CANCELLED，值为1，表示当前的线程被取消 // SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark // CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中 // PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行 // 值为0，表示当前节点在sync队列中，等待着获取锁 static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; // 结点状态 volatile int waitStatus; // 前驱结点 volatile Node prev; // 后继结点 volatile Node next; // 结点所对应的线程 volatile Thread thread; // 下一个等待者 Node nextWaiter; // 结点是否在共享模式下等待 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 获取前驱结点，若前驱结点为空，抛出异常 final Node predecessor() throws NullPointerException &#123; // 保存前驱结点 Node p = prev; if (p == null) // 前驱结点为空，抛出异常 throw new NullPointerException(); else // 前驱结点不为空，返回 return p; &#125; // 无参构造方法 Node() &#123; // Used to establish initial head or SHARED marker &#125; // 构造方法 Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; // 构造方法 Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125;&#125; 每个线程被阻塞的线程都会被封装成一个Node结点，放入队列。每个节点包含了一个Thread类型的引用，并且每个节点都存在一个状态，具体状态如下。 CANCELLED，值为1，表示当前的线程被取消。 SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，需要进行unpark操作。 CONDITION，值为-2，表示当前节点在等待condition，也就是在condition queue中。 PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行。 值为0，表示当前节点在sync queue中，等待着获取锁。 类的内部类 - ConditionObject类这个类有点长，耐心看下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472// 内部类public class ConditionObject implements Condition, java.io.Serializable &#123; // 版本号 private static final long serialVersionUID = 1173984872572414699L; /** First node of condition queue. */ // condition队列的头节点 private transient Node firstWaiter; /** Last node of condition queue. */ // condition队列的尾结点 private transient Node lastWaiter; /** * Creates a new &#123;@code ConditionObject&#125; instance. */ // 构造方法 public ConditionObject() &#123; &#125; // Internal methods /** * Adds a new waiter to wait queue. * @return its new wait node */ // 添加新的waiter到wait队列 private Node addConditionWaiter() &#123; // 保存尾结点 Node t = lastWaiter; // If lastWaiter is cancelled, clean out. if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; // 尾结点不为空，并且尾结点的状态不为CONDITION // 清除状态为CONDITION的结点 unlinkCancelledWaiters(); // 将最后一个结点重新赋值给t t = lastWaiter; &#125; // 新建一个结点 Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) // 尾结点为空 // 设置condition队列的头节点 firstWaiter = node; else // 尾结点不为空 // 设置为节点的nextWaiter域为node结点 t.nextWaiter = node; // 更新condition队列的尾结点 lastWaiter = node; return node; &#125; /** * Removes and transfers nodes until hit non-cancelled one or * null. Split out from signal in part to encourage compilers * to inline the case of no waiters. * @param first (non-null) the first node on condition queue */ private void doSignal(Node first) &#123; // 循环 do &#123; if ( (firstWaiter = first.nextWaiter) == null) // 该节点的nextWaiter为空 // 设置尾结点为空 lastWaiter = null; // 设置first结点的nextWaiter域 first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); // 将结点从condition队列转移到sync队列失败并且condition队列中的头节点不为空，一直循环 &#125; /** * Removes and transfers all nodes. * @param first (non-null) the first node on condition queue */ private void doSignalAll(Node first) &#123; // condition队列的头节点尾结点都设置为空 lastWaiter = firstWaiter = null; // 循环 do &#123; // 获取first结点的nextWaiter域结点 Node next = first.nextWaiter; // 设置first结点的nextWaiter域为空 first.nextWaiter = null; // 将first结点从condition队列转移到sync队列 transferForSignal(first); // 重新设置first first = next; &#125; while (first != null); &#125; /** * Unlinks cancelled waiter nodes from condition queue. * Called only while holding lock. This is called when * cancellation occurred during condition wait, and upon * insertion of a new waiter when lastWaiter is seen to have * been cancelled. This method is needed to avoid garbage * retention in the absence of signals. So even though it may * require a full traversal, it comes into play only when * timeouts or cancellations occur in the absence of * signals. It traverses all nodes rather than stopping at a * particular target to unlink all pointers to garbage nodes * without requiring many re-traversals during cancellation * storms. */ // 从condition队列中清除状态为CANCEL的结点 private void unlinkCancelledWaiters() &#123; // 保存condition队列头节点 Node t = firstWaiter; Node trail = null; while (t != null) &#123; // t不为空 // 下一个结点 Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; // t结点的状态不为CONDTION状态 // 设置t节点的nextWaiter域为空 t.nextWaiter = null; if (trail == null) // trail为空 // 重新设置condition队列的头节点 firstWaiter = next; else // trail不为空 // 设置trail结点的nextWaiter域为next结点 trail.nextWaiter = next; if (next == null) // next结点为空 // 设置condition队列的尾结点 lastWaiter = trail; &#125; else // t结点的状态为CONDTION状态 // 设置trail结点 trail = t; // 设置t结点 t = next; &#125; &#125; // public methods /** * Moves the longest-waiting thread, if one exists, from the * wait queue for this condition to the wait queue for the * owning lock. * * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ // 唤醒一个等待线程。如果所有的线程都在等待此条件，则选择其中的一个唤醒。在从 await 返回之前，该线程必须重新获取锁。 public final void signal() &#123; if (!isHeldExclusively()) // 不被当前线程独占，抛出异常 throw new IllegalMonitorStateException(); // 保存condition队列头节点 Node first = firstWaiter; if (first != null) // 头节点不为空 // 唤醒一个等待线程 doSignal(first); &#125; /** * Moves all threads from the wait queue for this condition to * the wait queue for the owning lock. * * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ // 唤醒所有等待线程。如果所有的线程都在等待此条件，则唤醒所有线程。在从 await 返回之前，每个线程都必须重新获取锁。 public final void signalAll() &#123; if (!isHeldExclusively()) // 不被当前线程独占，抛出异常 throw new IllegalMonitorStateException(); // 保存condition队列头节点 Node first = firstWaiter; if (first != null) // 头节点不为空 // 唤醒所有等待线程 doSignalAll(first); &#125; /** * Implements uninterruptible condition wait. * &lt;ol&gt; * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;/ol&gt; */ // 等待，当前线程在接到信号之前一直处于等待状态，不响应中断 public final void awaitUninterruptibly() &#123; // 添加一个结点到等待队列 Node node = addConditionWaiter(); // 获取释放的状态 int savedState = fullyRelease(node); boolean interrupted = false; while (!isOnSyncQueue(node)) &#123; // // 阻塞当前线程 LockSupport.park(this); if (Thread.interrupted()) // 当前线程被中断 // 设置interrupted状态 interrupted = true; &#125; if (acquireQueued(node, savedState) || interrupted) // selfInterrupt(); &#125; /* * For interruptible waits, we need to track whether to throw * InterruptedException, if interrupted while blocked on * condition, versus reinterrupt current thread, if * interrupted while blocked waiting to re-acquire. */ /** Mode meaning to reinterrupt on exit from wait */ private static final int REINTERRUPT = 1; /** Mode meaning to throw InterruptedException on exit from wait */ private static final int THROW_IE = -1; /** * Checks for interrupt, returning THROW_IE if interrupted * before signalled, REINTERRUPT if after signalled, or * 0 if not interrupted. */ private int checkInterruptWhileWaiting(Node node) &#123; return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0; &#125; /** * Throws InterruptedException, reinterrupts current thread, or * does nothing, depending on mode. */ private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; if (interruptMode == THROW_IE) throw new InterruptedException(); else if (interruptMode == REINTERRUPT) selfInterrupt(); &#125; /** * Implements interruptible condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled or interrupted. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;/ol&gt; */ // // 等待，当前线程在接到信号或被中断之前一直处于等待状态 public final void await() throws InterruptedException &#123; if (Thread.interrupted()) // 当前线程被中断，抛出异常 throw new InterruptedException(); // 在wait队列上添加一个结点 Node node = addConditionWaiter(); // int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; // 阻塞当前线程 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) // 检查结点等待时的中断类型 break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; /** * Implements timed condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled, interrupted, or timed out. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;/ol&gt; */ // 等待，当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态 public final long awaitNanos(long nanosTimeout) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return deadline - System.nanoTime(); &#125; /** * Implements absolute timed condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled, interrupted, or timed out. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;li&gt; If timed out while blocked in step 4, return false, else true. * &lt;/ol&gt; */ // 等待，当前线程在接到信号、被中断或到达指定最后期限之前一直处于等待状态 public final boolean awaitUntil(Date deadline) throws InterruptedException &#123; long abstime = deadline.getTime(); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (System.currentTimeMillis() &gt; abstime) &#123; timedout = transferAfterCancelledWait(node); break; &#125; LockSupport.parkUntil(this, abstime); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; /** * Implements timed condition wait. * &lt;ol&gt; * &lt;li&gt; If current thread is interrupted, throw InterruptedException. * &lt;li&gt; Save lock state returned by &#123;@link #getState&#125;. * &lt;li&gt; Invoke &#123;@link #release&#125; with saved state as argument, * throwing IllegalMonitorStateException if it fails. * &lt;li&gt; Block until signalled, interrupted, or timed out. * &lt;li&gt; Reacquire by invoking specialized version of * &#123;@link #acquire&#125; with saved state as argument. * &lt;li&gt; If interrupted while blocked in step 4, throw InterruptedException. * &lt;li&gt; If timed out while blocked in step 4, return false, else true. * &lt;/ol&gt; */ // 等待，当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。此方法在行为上等效于: awaitNanos(unit.toNanos(time)) &gt; 0 public final boolean await(long time, TimeUnit unit) throws InterruptedException &#123; long nanosTimeout = unit.toNanos(time); if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); final long deadline = System.nanoTime() + nanosTimeout; boolean timedout = false; int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; if (nanosTimeout &lt;= 0L) &#123; timedout = transferAfterCancelledWait(node); break; &#125; if (nanosTimeout &gt;= spinForTimeoutThreshold) LockSupport.parkNanos(this, nanosTimeout); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; nanosTimeout = deadline - System.nanoTime(); &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); return !timedout; &#125; // support for instrumentation /** * Returns true if this condition was created by the given * synchronization object. * * @return &#123;@code true&#125; if owned */ final boolean isOwnedBy(AbstractQueuedSynchronizer sync) &#123; return sync == AbstractQueuedSynchronizer.this; &#125; /** * Queries whether any threads are waiting on this condition. * Implements &#123;@link AbstractQueuedSynchronizer#hasWaiters(ConditionObject)&#125;. * * @return &#123;@code true&#125; if there are any waiting threads * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ // 查询是否有正在等待此条件的任何线程 protected final boolean hasWaiters() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) return true; &#125; return false; &#125; /** * Returns an estimate of the number of threads waiting on * this condition. * Implements &#123;@link AbstractQueuedSynchronizer#getWaitQueueLength(ConditionObject)&#125;. * * @return the estimated number of waiting threads * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ // 返回正在等待此条件的线程数估计值 protected final int getWaitQueueLength() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); int n = 0; for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) ++n; &#125; return n; &#125; /** * Returns a collection containing those threads that may be * waiting on this Condition. * Implements &#123;@link AbstractQueuedSynchronizer#getWaitingThreads(ConditionObject)&#125;. * * @return the collection of threads * @throws IllegalMonitorStateException if &#123;@link #isHeldExclusively&#125; * returns &#123;@code false&#125; */ // 返回包含那些可能正在等待此条件的线程集合 protected final Collection&lt;Thread&gt; getWaitingThreads() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); ArrayList&lt;Thread&gt; list = new ArrayList&lt;Thread&gt;(); for (Node w = firstWaiter; w != null; w = w.nextWaiter) &#123; if (w.waitStatus == Node.CONDITION) &#123; Thread t = w.thread; if (t != null) list.add(t); &#125; &#125; return list; &#125;&#125; 此类实现了Condition接口，Condition接口定义了条件操作规范，具体如下 1234567891011121314151617181920212223public interface Condition &#123; // 等待，当前线程在接到信号或被中断之前一直处于等待状态 void await() throws InterruptedException; // 等待，当前线程在接到信号之前一直处于等待状态，不响应中断 void awaitUninterruptibly(); //等待，当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态 long awaitNanos(long nanosTimeout) throws InterruptedException; // 等待，当前线程在接到信号、被中断或到达指定等待时间之前一直处于等待状态。此方法在行为上等效于: awaitNanos(unit.toNanos(time)) &gt; 0 boolean await(long time, TimeUnit unit) throws InterruptedException; // 等待，当前线程在接到信号、被中断或到达指定最后期限之前一直处于等待状态 boolean awaitUntil(Date deadline) throws InterruptedException; // 唤醒一个等待线程。如果所有的线程都在等待此条件，则选择其中的一个唤醒。在从 await 返回之前，该线程必须重新获取锁。 void signal(); // 唤醒所有等待线程。如果所有的线程都在等待此条件，则唤醒所有线程。在从 await 返回之前，每个线程都必须重新获取锁。 void signalAll();&#125; Condition接口中定义了await、signal方法，用来等待条件、释放条件。之后会详细分析CondtionObject的源码。 类的属性属性中包含了头节点head，尾结点tail，状态state、自旋时间spinForTimeoutThreshold，还有AbstractQueuedSynchronizer抽象的属性在内存中的偏移地址，通过该偏移地址，可以获取和设置该属性的值，同时还包括一个静态初始化块，用于加载内存偏移地址。 123456789101112131415161718192021222324252627282930313233343536373839404142public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable &#123; // 版本号 private static final long serialVersionUID = 7373984972572414691L; // 头节点 private transient volatile Node head; // 尾结点 private transient volatile Node tail; // 状态 private volatile int state; // 自旋时间 static final long spinForTimeoutThreshold = 1000L; // Unsafe类实例 private static final Unsafe unsafe = Unsafe.getUnsafe(); // state内存偏移地址 private static final long stateOffset; // head内存偏移地址 private static final long headOffset; // state内存偏移地址 private static final long tailOffset; // tail内存偏移地址 private static final long waitStatusOffset; // next内存偏移地址 private static final long nextOffset; // 静态初始化块 static &#123; try &#123; stateOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;state&quot;)); headOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;head&quot;)); tailOffset = unsafe.objectFieldOffset (AbstractQueuedSynchronizer.class.getDeclaredField(&quot;tail&quot;)); waitStatusOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(&quot;waitStatus&quot;)); nextOffset = unsafe.objectFieldOffset (Node.class.getDeclaredField(&quot;next&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125;&#125; 类的构造方法此类构造方法为从抽象构造方法，供子类调用。 1protected AbstractQueuedSynchronizer() &#123; &#125; 类的核心方法 - acquire方法该方法以独占模式获取(资源)，忽略中断，即线程在aquire过程中，中断此线程是无效的。源码如下: 1234public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; 由上述源码可以知道，当一个线程调用acquire时，调用方法流程如下 首先调用tryAcquire方法，调用此方法的线程会试图在独占模式下获取对象状态。此方法应该查询是否允许它在独占模式下获取对象状态，如果允许，则获取它。在AbstractQueuedSynchronizer源码中默认会抛出一个异常，即需要子类去重写此方法完成自己的逻辑。之后会进行分析。 若tryAcquire失败，则调用addWaiter方法，addWaiter方法完成的功能是将调用此方法的线程封装成为一个结点并放入Sync queue。 调用acquireQueued方法，此方法完成的功能是Sync queue中的结点不断尝试获取资源，若成功，则返回true，否则，返回false。 由于tryAcquire默认实现是抛出异常，所以此时，不进行分析，之后会结合一个例子进行分析。 首先分析addWaiter方法 12345678910111213141516171819// 添加等待者private Node addWaiter(Node mode) &#123; // 新生成一个结点，默认为独占模式 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 保存尾结点 Node pred = tail; if (pred != null) &#123; // 尾结点不为空，即已经被初始化 // 将node结点的prev域连接到尾结点 node.prev = pred; if (compareAndSetTail(pred, node)) &#123; // 比较pred是否为尾结点，是则将尾结点设置为node // 设置尾结点的next域为node pred.next = node; return node; // 返回新生成的结点 &#125; &#125; enq(node); // 尾结点为空(即还没有被初始化过)，或者是compareAndSetTail操作失败，则入队列 return node;&#125; addWaiter方法使用快速添加的方式往sync queue尾部添加结点，如果sync queue队列还没有初始化，则会使用enq插入队列中，enq方法源码如下 123456789101112131415161718private Node enq(final Node node) &#123; for (;;) &#123; // 无限循环，确保结点能够成功入队列 // 保存尾结点 Node t = tail; if (t == null) &#123; // 尾结点为空，即还没被初始化 if (compareAndSetHead(new Node())) // 头节点为空，并设置头节点为新生成的结点 tail = head; // 头节点与尾结点都指向同一个新生结点 &#125; else &#123; // 尾结点不为空，即已经被初始化过 // 将node结点的prev域连接到尾结点 node.prev = t; if (compareAndSetTail(t, node)) &#123; // 比较结点t是否为尾结点，若是则将尾结点设置为node // 设置尾结点的next域为node t.next = node; return t; // 返回尾结点 &#125; &#125; &#125;&#125; enq方法会使用无限循环来确保节点的成功插入。 现在，分析acquireQueue方法。其源码如下 12345678910111213141516171819202122232425// sync队列中的结点在独占且忽略中断的模式下获取(资源)final boolean acquireQueued(final Node node, int arg) &#123; // 标志 boolean failed = true; try &#123; // 中断标志 boolean interrupted = false; for (;;) &#123; // 无限循环 // 获取node节点的前驱结点 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 前驱为头节点并且成功获得锁 setHead(node); // 设置头节点 p.next = null; // help GC failed = false; // 设置标志 return interrupted; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125; 首先获取当前节点的前驱节点，如果前驱节点是头节点并且能够获取(资源)，代表该当前节点能够占有锁，设置头节点为当前节点，返回。否则，调用shouldParkAfterFailedAcquire和parkAndCheckInterrupt方法，首先，我们看shouldParkAfterFailedAcquire方法，代码如下 123456789101112131415161718192021222324252627282930313233// 当获取(资源)失败后，检查并且更新结点状态private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 获取前驱结点的状态 int ws = pred.waitStatus; if (ws == Node.SIGNAL) // 状态为SIGNAL，为-1 /* * This node has already set status asking a release * to signal it, so it can safely park. */ // 可以进行park操作 return true; if (ws &gt; 0) &#123; // 表示状态为CANCELLED，为1 /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); // 找到pred结点前面最近的一个状态不为CANCELLED的结点 // 赋值pred结点的next域 pred.next = node; &#125; else &#123; // 为PROPAGATE -3 或者是0 表示无状态,(为CONDITION -2时，表示此节点在condition queue中) /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don&#x27;t park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ // 比较并设置前驱结点的状态为SIGNAL compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; // 不能进行park操作 return false;&#125; 只有当该节点的前驱结点的状态为SIGNAL时，才可以对该结点所封装的线程进行park操作。否则，将不能进行park操作。再看parkAndCheckInterrupt方法，源码如下 123456// 进行park操作并且返回该线程是否被中断private final boolean parkAndCheckInterrupt() &#123; // 在许可可用之前禁用当前线程，并且设置了blocker LockSupport.park(this); return Thread.interrupted(); // 当前线程是否已被中断，并清除中断标记位&#125; parkAndCheckInterrupt方法里的逻辑是首先执行park操作，即禁用当前线程，然后返回该线程是否已经被中断。再看final块中的cancelAcquire方法，其源码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 取消继续获取(资源)private void cancelAcquire(Node node) &#123; // Ignore if node doesn&#x27;t exist // node为空，返回 if (node == null) return; // 设置node结点的thread为空 node.thread = null; // Skip cancelled predecessors // 保存node的前驱结点 Node pred = node.prev; while (pred.waitStatus &gt; 0) // 找到node前驱结点中第一个状态小于0的结点，即不为CANCELLED状态的结点 node.prev = pred = pred.prev; // predNext is the apparent node to unsplice. CASes below will // fail if not, in which case, we lost race vs another cancel // or signal, so no further action is necessary. // 获取pred结点的下一个结点 Node predNext = pred.next; // Can use unconditional write instead of CAS here. // After this atomic step, other Nodes can skip past us. // Before, we are free of interference from other threads. // 设置node结点的状态为CANCELLED node.waitStatus = Node.CANCELLED; // If we are the tail, remove ourselves. if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; // node结点为尾结点，则设置尾结点为pred结点 // 比较并设置pred结点的next节点为null compareAndSetNext(pred, predNext, null); &#125; else &#123; // node结点不为尾结点，或者比较设置不成功 // If successor needs signal, try to set pred&#x27;s next-link // so it will get one. Otherwise wake it up to propagate. int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; // (pred结点不为头节点，并且pred结点的状态为SIGNAL)或者 // pred结点状态小于等于0，并且比较并设置等待状态为SIGNAL成功，并且pred结点所封装的线程不为空 // 保存结点的后继 Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) // 后继不为空并且后继的状态小于等于0 compareAndSetNext(pred, predNext, next); // 比较并设置pred.next = next; &#125; else &#123; unparkSuccessor(node); // 释放node的前一个结点 &#125; node.next = node; // help GC &#125;&#125; 该方法完成的功能就是取消当前线程对资源的获取，即设置该结点的状态为CANCELLED，接着我们再看unparkSuccessor方法，源码如下 123456789101112131415161718192021222324252627282930313233// 释放后继结点private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ // 获取node结点的等待状态 int ws = node.waitStatus; if (ws &lt; 0) // 状态值小于0，为SIGNAL -1 或 CONDITION -2 或 PROPAGATE -3 // 比较并且设置结点等待状态，设置为0 compareAndSetWaitStatus(node, ws, 0); /* * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ // 获取node节点的下一个结点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; // 下一个结点为空或者下一个节点的等待状态大于0，即为CANCELLED // s赋值为空 s = null; // 从尾结点开始从后往前开始遍历 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) // 找到等待状态小于等于0的结点，找到最前的状态小于等于0的结点 // 保存结点 s = t; &#125; if (s != null) // 该结点不为为空，释放许可 LockSupport.unpark(s.thread);&#125; 该方法的作用就是为了释放node节点的后继结点。 对于cancelAcquire与unparkSuccessor方法，如下示意图可以清晰的表示: 其中node为参数，在执行完cancelAcquire方法后的效果就是unpark了s结点所包含的t4线程。 现在，再来看acquireQueued方法的整个的逻辑。逻辑如下: 判断结点的前驱是否为head并且是否成功获取(资源)。 若步骤1均满足，则设置结点为head，之后会判断是否finally模块，然后返回。 若步骤2不满足，则判断是否需要park当前线程，是否需要park当前线程的逻辑是判断结点的前驱结点的状态是否为SIGNAL，若是，则park当前结点，否则，不进行park操作。 若park了当前线程，之后某个线程对本线程unpark后，并且本线程也获得机会运行。那么，将会继续进行步骤①的判断。 类的核心方法 - release方法以独占模式释放对象，其源码如下: 12345678910public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; // 释放成功 // 保存头节点 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) // 头节点不为空并且头节点状态不为0 unparkSuccessor(h); //释放头节点的后继结点 return true; &#125; return false;&#125; 其中，tryRelease的默认实现是抛出异常，需要具体的子类实现，如果tryRelease成功，那么如果头节点不为空并且头节点的状态不为0，则释放头节点的后继结点，unparkSuccessor方法已经分析过，不再累赘。 对于其他方法我们也可以分析，与前面分析的方法大同小异，所以，不再累赘。 AbstractQueuedSynchronizer示例详解一借助下面示例来分析AbstractQueuedSyncrhonizer内部的工作机制。示例源码如下 1234567891011121314151617181920212223242526272829import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;class MyThread extends Thread &#123; private Lock lock; public MyThread(String name, Lock lock) &#123; super(name); this.lock = lock; &#125; public void run () &#123; lock.lock(); try &#123; System.out.println(Thread.currentThread() + &quot; running&quot;); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;public class AbstractQueuedSynchronizerDemo &#123; public static void main(String[] args) &#123; Lock lock = new ReentrantLock(); MyThread t1 = new MyThread(&quot;t1&quot;, lock); MyThread t2 = new MyThread(&quot;t2&quot;, lock); t1.start(); t2.start(); &#125;&#125; 运行结果(可能的一种): 12Thread[t1,5,main] runningThread[t2,5,main] running 结果分析: 从示例可知，线程t1与t2共用了一把锁，即同一个lock。可能会存在如下一种时序。 说明: 首先线程t1先执行lock.lock操作，然后t2执行lock.lock操作，然后t1执行lock.unlock操作，最后t2执行lock.unlock操作。基于这样的时序，分析AbstractQueuedSynchronizer内部的工作机制。 t1线程调用lock.lock方法，其方法调用顺序如下，只给出了主要的方法调用。 说明: 其中，前面的部分表示哪个类，后面是具体的类中的哪个方法，AQS表示AbstractQueuedSynchronizer类，AOS表示AbstractOwnableSynchronizer类。 t2线程调用lock.lock方法，其方法调用顺序如下，只给出了主要的方法调用。 说明: 经过一系列的方法调用，最后达到的状态是禁用t2线程，因为调用了LockSupport.park。 t1线程调用lock.unlock，其方法调用顺序如下，只给出了主要的方法调用。 说明: t1线程中调用lock.unlock后，经过一系列的调用，最终的状态是释放了许可，因为调用了LockSupport.unpark。这时，t2线程就可以继续运行了。此时，会继续恢复t2线程运行环境，继续执行LockSupport.park后面的语句，即进一步调用如下。 说明: 在上一步调用了LockSupport.unpark后，t2线程恢复运行，则运行parkAndCheckInterrupt，之后，继续运行acquireQueued方法，最后达到的状态是头节点head与尾结点tail均指向了t2线程所在的结点，并且之前的头节点已经从sync队列中断开了。 t2线程调用lock.unlock，其方法调用顺序如下，只给出了主要的方法调用。 说明: t2线程执行lock.unlock后，最终达到的状态还是与之前的状态一样。 AbstractQueuedSynchronizer示例详解二下面我们结合Condition实现生产者与消费者，来进一步分析AbstractQueuedSynchronizer的内部工作机制。 Depot(仓库)类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;public class Depot &#123; private int size; private int capacity; private Lock lock; private Condition fullCondition; private Condition emptyCondition; public Depot(int capacity) &#123; this.capacity = capacity; lock = new ReentrantLock(); fullCondition = lock.newCondition(); emptyCondition = lock.newCondition(); &#125; public void produce(int no) &#123; lock.lock(); int left = no; try &#123; while (left &gt; 0) &#123; while (size &gt;= capacity) &#123; System.out.println(Thread.currentThread() + &quot; before await&quot;); fullCondition.await(); System.out.println(Thread.currentThread() + &quot; after await&quot;); &#125; int inc = (left + size) &gt; capacity ? (capacity - size) : left; left -= inc; size += inc; System.out.println(&quot;produce = &quot; + inc + &quot;, size = &quot; + size); emptyCondition.signal(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void consume(int no) &#123; lock.lock(); int left = no; try &#123; while (left &gt; 0) &#123; while (size &lt;= 0) &#123; System.out.println(Thread.currentThread() + &quot; before await&quot;); emptyCondition.await(); System.out.println(Thread.currentThread() + &quot; after await&quot;); &#125; int dec = (size - left) &gt; 0 ? left : size; left -= dec; size -= dec; System.out.println(&quot;consume = &quot; + dec + &quot;, size = &quot; + size); fullCondition.signal(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 测试类 123456789101112131415161718192021222324252627282930313233343536373839404142class Consumer &#123; private Depot depot; public Consumer(Depot depot) &#123; this.depot = depot; &#125; public void consume(int no) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; depot.consume(no); &#125; &#125;, no + &quot; consume thread&quot;).start(); &#125;&#125;class Producer &#123; private Depot depot; public Producer(Depot depot) &#123; this.depot = depot; &#125; public void produce(int no) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; depot.produce(no); &#125; &#125;, no + &quot; produce thread&quot;).start(); &#125;&#125;public class ReentrantLockDemo &#123; public static void main(String[] args) throws InterruptedException &#123; Depot depot = new Depot(500); new Producer(depot).produce(500); new Producer(depot).produce(200); new Consumer(depot).consume(500); new Consumer(depot).consume(200); &#125;&#125; 运行结果(可能的一种): 12345678produce = 500, size = 500Thread[200 produce thread,5,main] before awaitconsume = 500, size = 0Thread[200 consume thread,5,main] before awaitThread[200 produce thread,5,main] after awaitproduce = 200, size = 200Thread[200 consume thread,5,main] after awaitconsume = 200, size = 0 说明: 根据结果，我们猜测一种可能的时序如下 说明: p1代表produce 500的那个线程，p2代表produce 200的那个线程，c1代表consume 500的那个线程，c2代表consume 200的那个线程。 p1线程调用lock.lock，获得锁，继续运行，方法调用顺序在前面已经给出。 p2线程调用lock.lock，由前面的分析可得到如下的最终状态。 说明: p2线程调用lock.lock后，会禁止p2线程的继续运行，因为执行了LockSupport.park操作。 c1线程调用lock.lock，由前面的分析得到如下的最终状态。 说明: 最终c1线程会在sync queue队列的尾部，并且其结点的前驱结点(包含p2的结点)的waitStatus变为了SIGNAL。 c2线程调用lock.lock，由前面的分析得到如下的最终状态。 说明: 最终c1线程会在sync queue队列的尾部，并且其结点的前驱结点(包含c1的结点)的waitStatus变为了SIGNAL。 p1线程执行emptyCondition.signal，其方法调用顺序如下，只给出了主要的方法调用。 说明: AQS.CO表示AbstractQueuedSynchronizer.ConditionObject类。此时调用signal方法不会产生任何其他效果。 p1线程执行lock.unlock，根据前面的分析可知，最终的状态如下。 说明: 此时，p2线程所在的结点为头节点，并且其他两个线程(c1、c2)依旧被禁止，所以，此时p2线程继续运行，执行用户逻辑。 p2线程执行fullCondition.await，其方法调用顺序如下，只给出了主要的方法调用。 说明: 最终到达的状态是新生成了一个结点，包含了p2线程，此结点在condition queue中；并且sync queue中p2线程被禁止了，因为在执行了LockSupport.park操作。从方法一些调用可知，在await操作中线程会释放锁资源，供其他线程获取。同时，head结点后继结点的包含的线程的许可被释放了，故其可以继续运行。由于此时，只有c1线程可以运行，故运行c1。 继续运行c1线程，c1线程由于之前被park了，所以此时恢复，继续之前的步骤，即还是执行前面提到的acquireQueued方法，之后，c1判断自己的前驱结点为head，并且可以获取锁资源，最终到达的状态如下。 说明: 其中，head设置为包含c1线程的结点，c1继续运行。 c1线程执行fullCondtion.signal，其方法调用顺序如下，只给出了主要的方法调用。 说明: signal方法达到的最终结果是将包含p2线程的结点从condition queue中转移到sync queue中，之后condition queue为null，之前的尾结点的状态变为SIGNAL。 c1线程执行lock.unlock操作，根据之前的分析，经历的状态变化如下。 说明: 最终c2线程会获取锁资源，继续运行用户逻辑。 c2线程执行emptyCondition.await，由前面的第七步分析，可知最终的状态如下。 说明: await操作将会生成一个结点放入condition queue中与之前的一个condition queue是不相同的，并且unpark头节点后面的结点，即包含线程p2的结点。 p2线程被unpark，故可以继续运行，经过CPU调度后，p2继续运行，之后p2线程在AQS:await方法中被park，继续AQS.CO:await方法的运行，其方法调用顺序如下，只给出了主要的方法调用。 p2继续运行，执行emptyCondition.signal，根据第九步分析可知，最终到达的状态如下。 说明: 最终，将condition queue中的结点转移到sync queue中，并添加至尾部，condition queue会为空，并且将head的状态设置为SIGNAL。 p2线程执行lock.unlock操作，根据前面的分析可知，最后的到达的状态如下。 说明: unlock操作会释放c2线程的许可，并且将头节点设置为c2线程所在的结点。 c2线程继续运行，执行fullCondition. signal，由于此时fullCondition的condition queue已经不存在任何结点了，故其不会产生作用。 c2执行lock.unlock，由于c2是sync队列中最后一个结点，故其不会再调用unparkSuccessor了，直接返回true。即整个流程就完成了。 AbstractQueuedSynchronizer总结对于AbstractQueuedSynchronizer的分析，最核心的就是sync queue的分析。 每一个结点都是由前一个结点唤醒 当结点发现前驱结点是head并且尝试获取成功，则会轮到该线程运行。 condition queue中的结点向sync queue中转移是通过signal操作完成的。 当结点的状态为SIGNAL时，表示后面的结点需要运行。 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5350186.html，在此基础上做了增改。 http://ifeve.com/introduce-abstractqueuedsynchronizer/ http://blog.csdn.net/chen77716/article/details/6641477 https://blog.csdn.net/mulinsen77/article/details/84583716","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"10.JUC锁: LockSupport详解","path":"/2023/12/25/10-JUC锁-LockSupport详解/","content":"LockSupport是锁中的基础，是一个提供锁机制的工具类，所以先对其进行分析。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 为什么LockSupport也是核心基础类? AQS框架借助于两个类：Unsafe(提供CAS操作)和LockSupport(提供park&#x2F;unpark操作) 写出分别通过wait&#x2F;notify和LockSupport的park&#x2F;unpark实现同步? LockSupport.park()会释放锁资源吗? 那么Condition.await()呢? Thread.sleep()、Object.wait()、Condition.await()、LockSupport.park()的区别? 重点 如果在wait()之前执行了notify()会怎样? 如果在park()之前执行了unpark()会怎样? LockSupport简介LockSupport用来创建锁和其他同步类的基本线程阻塞原语。简而言之，当调用LockSupport.park时，表示当前线程将会等待，直至获得许可，当调用LockSupport.unpark时，必须把等待获得许可的线程作为参数进行传递，好让此线程继续运行。 LockSupport源码分析类的属性123456789101112131415161718192021222324252627282930313233public class LockSupport &#123; // Hotspot implementation via intrinsics API private static final sun.misc.Unsafe UNSAFE; // 表示内存偏移地址 private static final long parkBlockerOffset; // 表示内存偏移地址 private static final long SEED; // 表示内存偏移地址 private static final long PROBE; // 表示内存偏移地址 private static final long SECONDARY; static &#123; try &#123; // 获取Unsafe实例 UNSAFE = sun.misc.Unsafe.getUnsafe(); // 线程类类型 Class&lt;?&gt; tk = Thread.class; // 获取Thread的parkBlocker字段的内存偏移地址 parkBlockerOffset = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;parkBlocker&quot;)); // 获取Thread的threadLocalRandomSeed字段的内存偏移地址 SEED = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSeed&quot;)); // 获取Thread的threadLocalRandomProbe字段的内存偏移地址 PROBE = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomProbe&quot;)); // 获取Thread的threadLocalRandomSecondarySeed字段的内存偏移地址 SECONDARY = UNSAFE.objectFieldOffset (tk.getDeclaredField(&quot;threadLocalRandomSecondarySeed&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125;&#125; 说明: UNSAFE字段表示sun.misc.Unsafe类，查看其源码，点击在这里，一般程序中不允许直接调用，而long型的表示实例对象相应字段在内存中的偏移地址，可以通过该偏移地址获取或者设置该字段的值。 类的构造函数12// 私有构造函数，无法被实例化private LockSupport() &#123;&#125; 说明: LockSupport只有一个私有构造函数，无法被实例化。 核心函数分析在分析LockSupport函数之前，先引入sun.misc.Unsafe类中的park和unpark函数，因为LockSupport的核心函数都是基于Unsafe类中定义的park和unpark函数，下面给出两个函数的定义: 12public native void park(boolean isAbsolute, long time);public native void unpark(Thread thread); 说明: 对两个函数的说明如下: park函数，阻塞线程，并且该线程在下列情况发生之前都会被阻塞: ① 调用unpark函数，释放该线程的许可。② 该线程被中断。③ 设置的时间到了。并且，当time为绝对时间时，isAbsolute为true，否则，isAbsolute为false。当time为0时，表示无限等待，直到unpark发生。 unpark函数，释放线程的许可，即激活调用park后阻塞的线程。这个函数不是安全的，调用这个函数时要确保线程依旧存活。 park函数park函数有两个重载版本，方法摘要如下 12public static void park()；public static void park(Object blocker)； 说明: 两个函数的区别在于park()函数没有没有blocker，即没有设置线程的parkBlocker字段。park(Object)型函数如下。 12345678910public static void park(Object blocker) &#123; // 获取当前线程 Thread t = Thread.currentThread(); // 设置Blocker setBlocker(t, blocker); // 获取许可 UNSAFE.park(false, 0L); // 重新可运行后再此设置Blocker setBlocker(t, null);&#125; 说明: 调用park函数时，首先获取当前线程，然后设置当前线程的parkBlocker字段，即调用setBlocker函数，之后调用Unsafe类的park函数，之后再调用setBlocker函数。那么问题来了，为什么要在此park函数中要调用两次setBlocker函数呢? 原因其实很简单，调用park函数时，当前线程首先设置好parkBlocker字段，然后再调用Unsafe的park函数，此后，当前线程就已经阻塞了，等待该线程的unpark函数被调用，所以后面的一个setBlocker函数无法运行，unpark函数被调用，该线程获得许可后，就可以继续运行了，也就运行第二个setBlocker，把该线程的parkBlocker字段设置为null，这样就完成了整个park函数的逻辑。如果没有第二个setBlocker，那么之后没有调用park(Object blocker)，而直接调用getBlocker函数，得到的还是前一个park(Object blocker)设置的blocker，显然是不符合逻辑的。总之，必须要保证在park(Object blocker)整个函数执行完后，该线程的parkBlocker字段又恢复为null。所以，park(Object)型函数里必须要调用setBlocker函数两次。setBlocker方法如下。 1234private static void setBlocker(Thread t, Object arg) &#123; // 设置线程t的parkBlocker字段的值为arg UNSAFE.putObject(t, parkBlockerOffset, arg);&#125; 说明: 此方法用于设置线程t的parkBlocker字段的值为arg。 另外一个无参重载版本，park()函数如下。 1234public static void park() &#123; // 获取许可，设置时间为无限长，直到可以获取许可 UNSAFE.park(false, 0L);&#125; 说明: 调用了park函数后，会禁用当前线程，除非许可可用。在以下三种情况之一发生之前，当前线程都将处于休眠状态，即下列情况发生时，当前线程会获取许可，可以继续运行。 其他某个线程将当前线程作为目标调用 unpark。 其他某个线程中断当前线程。 该调用不合逻辑地(即毫无理由地)返回。 parkNanos函数此函数表示在许可可用前禁用当前线程，并最多等待指定的等待时间。具体函数如下。 123456789101112public static void parkNanos(Object blocker, long nanos) &#123; if (nanos &gt; 0) &#123; // 时间大于0 // 获取当前线程 Thread t = Thread.currentThread(); // 设置Blocker setBlocker(t, blocker); // 获取许可，并设置了时间 UNSAFE.park(false, nanos); // 设置许可 setBlocker(t, null); &#125;&#125; 说明: 该函数也是调用了两次setBlocker函数，nanos参数表示相对时间，表示等待多长时间。 parkUntil函数此函数表示在指定的时限前禁用当前线程，除非许可可用, 具体函数如下: 123456789public static void parkUntil(Object blocker, long deadline) &#123; // 获取当前线程 Thread t = Thread.currentThread(); // 设置Blocker setBlocker(t, blocker); UNSAFE.park(true, deadline); // 设置Blocker为null setBlocker(t, null);&#125; 说明: 该函数也调用了两次setBlocker函数，deadline参数表示绝对时间，表示指定的时间。 unpark函数此函数表示如果给定线程的许可尚不可用，则使其可用。如果线程在 park 上受阻塞，则它将解除其阻塞状态。否则，保证下一次调用 park 不会受阻塞。如果给定线程尚未启动，则无法保证此操作有任何效果。具体函数如下: 1234public static void unpark(Thread thread) &#123; if (thread != null) // 线程为不空 UNSAFE.unpark(thread); // 释放该线程许可&#125; 说明: 释放许可，指定线程可以继续运行。 LockSupport示例说明使用wait&#x2F;notify实现线程同步1234567891011121314151617181920212223242526272829class MyThread extends Thread &#123; public void run() &#123; synchronized (this) &#123; System.out.println(&quot;before notify&quot;); notify(); System.out.println(&quot;after notify&quot;); &#125; &#125;&#125;public class WaitAndNotifyDemo &#123; public static void main(String[] args) throws InterruptedException &#123; MyThread myThread = new MyThread(); synchronized (myThread) &#123; try &#123; myThread.start(); // 主线程睡眠3s Thread.sleep(3000); System.out.println(&quot;before wait&quot;); // 阻塞主线程 myThread.wait(); System.out.println(&quot;after wait&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 运行结果 1234before waitbefore notifyafter notifyafter wait 说明: 具体的流程图如下 使用wait&#x2F;notify实现同步时，必须先调用wait，后调用notify，如果先调用notify，再调用wait，将起不了作用。具体代码如下 12345678910111213141516171819202122232425262728class MyThread extends Thread &#123; public void run() &#123; synchronized (this) &#123; System.out.println(&quot;before notify&quot;); notify(); System.out.println(&quot;after notify&quot;); &#125; &#125;&#125;public class WaitAndNotifyDemo &#123; public static void main(String[] args) throws InterruptedException &#123; MyThread myThread = new MyThread(); myThread.start(); // 主线程睡眠3s Thread.sleep(3000); synchronized (myThread) &#123; try &#123; System.out.println(&quot;before wait&quot;); // 阻塞主线程 myThread.wait(); System.out.println(&quot;after wait&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 运行结果: 123before notifyafter notifybefore wait 说明: 由于先调用了notify，再调用的wait，此时主线程还是会一直阻塞。 使用park&#x2F;unpark实现线程同步12345678910111213141516171819202122232425262728293031323334353637383940414243import java.util.concurrent.locks.LockSupport;class MyThread extends Thread &#123; private Object object; public MyThread(Object object) &#123; this.object = object; &#125; public void run() &#123; System.out.println(&quot;before unpark&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 获取blocker System.out.println(&quot;Blocker info &quot; + LockSupport.getBlocker((Thread) object)); // 释放许可 LockSupport.unpark((Thread) object); // 休眠500ms，保证先执行park中的setBlocker(t, null); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 再次获取blocker System.out.println(&quot;Blocker info &quot; + LockSupport.getBlocker((Thread) object)); System.out.println(&quot;after unpark&quot;); &#125;&#125;public class test &#123; public static void main(String[] args) &#123; MyThread myThread = new MyThread(Thread.currentThread()); myThread.start(); System.out.println(&quot;before park&quot;); // 获取许可 LockSupport.park(&quot;ParkAndUnparkDemo&quot;); System.out.println(&quot;after park&quot;); &#125;&#125; 运行结果: 123456before parkbefore unparkBlocker info ParkAndUnparkDemoafter parkBlocker info nullafter unpark 说明: 本程序先执行park，然后在执行unpark，进行同步，并且在unpark的前后都调用了getBlocker，可以看到两次的结果不一样，并且第二次调用的结果为null，这是因为在调用unpark之后，执行了Lock.park(Object blocker)函数中的setBlocker(t, null)函数，所以第二次调用getBlocker时为null。 上例是先调用park，然后调用unpark，现在修改程序，先调用unpark，然后调用park，看能不能正确同步。具体代码如下 123456789101112131415161718192021222324252627282930313233import java.util.concurrent.locks.LockSupport;class MyThread extends Thread &#123; private Object object; public MyThread(Object object) &#123; this.object = object; &#125; public void run() &#123; System.out.println(&quot;before unpark&quot;); // 释放许可 LockSupport.unpark((Thread) object); System.out.println(&quot;after unpark&quot;); &#125;&#125;public class ParkAndUnparkDemo &#123; public static void main(String[] args) &#123; MyThread myThread = new MyThread(Thread.currentThread()); myThread.start(); try &#123; // 主线程睡眠3s Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;before park&quot;); // 获取许可 LockSupport.park(&quot;ParkAndUnparkDemo&quot;); System.out.println(&quot;after park&quot;); &#125;&#125; 运行结果: 1234before unparkafter unparkbefore parkafter park 说明: 可以看到，在先调用unpark，再调用park时，仍能够正确实现同步，不会造成由wait&#x2F;notify调用顺序不当所引起的阻塞。因此park&#x2F;unpark相比wait&#x2F;notify更加的灵活。 中断响应看下面示例 12345678910111213141516171819202122232425262728293031323334import java.util.concurrent.locks.LockSupport;class MyThread extends Thread &#123; private Object object; public MyThread(Object object) &#123; this.object = object; &#125; public void run() &#123; System.out.println(&quot;before interrupt&quot;); try &#123; // 休眠3s Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Thread thread = (Thread) object; // 中断线程 thread.interrupt(); System.out.println(&quot;after interrupt&quot;); &#125;&#125;public class InterruptDemo &#123; public static void main(String[] args) &#123; MyThread myThread = new MyThread(Thread.currentThread()); myThread.start(); System.out.println(&quot;before park&quot;); // 获取许可 LockSupport.park(&quot;ParkAndUnparkDemo&quot;); System.out.println(&quot;after park&quot;); &#125;&#125; 运行结果: 1234before parkbefore interruptafter interruptafter park 说明: 可以看到，在主线程调用park阻塞后，在myThread线程中发出了中断信号，此时主线程会继续运行，也就是说明此时interrupt起到的作用与unpark一样。 更深入的理解Thread.sleep()和Object.wait()的区别首先，我们先来看看Thread.sleep()和Object.wait()的区别，这是一个烂大街的题目了，大家应该都能说上来两点。 Thread.sleep()不会释放占有的锁，Object.wait()会释放占有的锁； Thread.sleep()必须传入时间，Object.wait()可传可不传，不传表示一直阻塞下去； Thread.sleep()到时间了会自动唤醒，然后继续执行； Object.wait()不带时间的，需要另一个线程使用Object.notify()唤醒； Object.wait()带时间的，假如没有被notify，到时间了会自动唤醒，这时又分好两种情况，一是立即获取到了锁，线程自然会继续执行；二是没有立即获取锁，线程进入同步队列等待获取锁； 其实，他们俩最大的区别就是Thread.sleep()不会释放锁资源，Object.wait()会释放锁资源。 Object.wait()和Condition.await()的区别Object.wait()和Condition.await()的原理是基本一致的，不同的是Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的。 实际上，它在阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程。 Thread.sleep()和LockSupport.park()的区别LockSupport.park()还有几个兄弟方法——parkNanos()、parkUtil()等，我们这里说的park()方法统称这一类方法。 从功能上来说，Thread.sleep()和LockSupport.park()方法类似，都是阻塞当前线程的执行，且都不会释放当前线程占有的锁资源； Thread.sleep()没法从外部唤醒，只能自己醒过来； LockSupport.park()方法可以被另一个线程调用LockSupport.unpark()方法唤醒； Thread.sleep()方法声明上抛出了InterruptedException中断异常，所以调用者需要捕获这个异常或者再抛出； LockSupport.park()方法不需要捕获中断异常； Thread.sleep()本身就是一个native方法； LockSupport.park()底层是调用的Unsafe的native方法； Object.wait()和LockSupport.park()的区别二者都会阻塞当前线程的运行，他们有什么区别呢? 经过上面的分析相信你一定很清楚了，真的吗? 往下看！ Object.wait()方法需要在synchronized块中执行； LockSupport.park()可以在任意地方执行； Object.wait()方法声明抛出了中断异常，调用者需要捕获或者再抛出； LockSupport.park()不需要捕获中断异常； Object.wait()不带超时的，需要另一个线程执行notify()来唤醒，但不一定继续执行后续内容； LockSupport.park()不带超时的，需要另一个线程执行unpark()来唤醒，一定会继续执行后续内容； park()&#x2F;unpark()底层的原理是“二元信号量”，你可以把它相像成只有一个许可证的Semaphore，只不过这个信号量在重复执行unpark()的时候也不会再增加许可证，最多只有一个许可证。 如果在wait()之前执行了notify()会怎样?如果当前的线程不是此对象锁的所有者，却调用该对象的notify()或wait()方法时抛出IllegalMonitorStateException异常； 如果当前线程是此对象锁的所有者，wait()将一直阻塞，因为后续将没有其它notify()唤醒它。 如果在park()之前执行了unpark()会怎样?线程不会被阻塞，直接跳过park()，继续执行后续内容 LockSupport.park()会释放锁资源吗?不会，它只负责阻塞当前线程，释放锁资源实际上是在Condition的await()方法中实现的。 参考文章 文章主要参考自leesf的https://www.cnblogs.com/leesf456/p/5347293.html，在此基础上做了增改。 https://blog.csdn.net/tangtong1/article/details/102829724","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"9.JUC原子类: CAS, Unsafe和原子类详解","path":"/2023/12/25/9-JUC原子类-CAS-Unsafe和原子类详解/","content":"JUC中多数类是通过volatile和CAS来实现的，CAS本质上提供的是一种无锁方案，而Synchronized和Lock是互斥锁方案; java原子类本质上使用的是CAS，而CAS底层是通过Unsafe类实现的。所以本章将对CAS, Unsafe和原子类详解。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 线程安全的实现方法有哪些? 什么是CAS? CAS使用示例，结合AtomicInteger给出示例? CAS会有哪些问题? 针对这这些问题，Java提供了哪几个解决的? AtomicInteger底层实现? CAS+volatile 请阐述你对Unsafe类的理解? 说说你对Java原子类的理解? 包含13个，4组分类，说说作用和使用场景。 AtomicStampedReference是什么? AtomicStampedReference是怎么解决ABA的? 内部使用Pair来存储元素值及其版本号 java中还有哪些类可以解决ABA的问题? AtomicMarkableReference CAS前面我们说到，线程安全的实现方法包含: 互斥同步: synchronized 和 ReentrantLock 非阻塞同步: CAS, AtomicXXXX 无同步方案: 栈封闭，Thread Local，可重入代码 具体可以参看：线程安全的实现方法，这里我们将对CAS重点阐释。 什么是CASCAS的全称为Compare-And-Swap，直译就是对比交换。是一条CPU的原子指令，其作用是让CPU先进行比较两个值是否相等，然后原子地更新某个位置的值，经过调查发现，其实现方式是基于硬件平台的汇编指令，就是说CAS是靠硬件实现的，JVM只是封装了汇编调用，那些AtomicInteger类便是使用了这些封装后的接口。 简单解释：CAS操作需要输入两个数值，一个旧值(期望操作前的值)和一个新值，在操作期间先比较下在旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。 CAS操作是原子性的，所以多线程并发使用CAS更新数据时，可以不使用锁。JDK中大量使用了CAS来更新数据而防止加锁(synchronized 重量级锁)来保持原子更新。 相信sql大家都熟悉，类似sql中的条件更新一样：update set id&#x3D;3 from table where id&#x3D;2。因为单条sql执行具有原子性，如果有多个线程同时执行此sql语句，只有一条能更新成功。 CAS使用示例如果不使用CAS，在高并发下，多线程同时修改一个变量的值我们需要synchronized加锁(可能有人说可以用Lock加锁，Lock底层的AQS也是基于CAS进行获取锁的)。 123456public class Test &#123; private int i=0; public synchronized int add()&#123; return i++; &#125;&#125; java中为我们提供了AtomicInteger 原子类(底层基于CAS进行更新数据的)，不需要加锁就在多线程并发场景下实现数据的一致性。 123456public class Test &#123; private AtomicInteger i = new AtomicInteger(0); public int add()&#123; return i.addAndGet(1); &#125;&#125; CAS 问题CAS 方式为乐观锁，synchronized 为悲观锁。因此使用 CAS 解决并发问题通常情况下性能更优。 但使用 CAS 方式也会有几个问题： ABA问题因为CAS需要在操作值的时候，检查值有没有发生变化，比如没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时则会发现它的值没有发生变化，但是实际上却变化了。 ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A-&gt;B-&gt;A就会变成1A-&gt;2B-&gt;3A。 从Java 1.5开始，JDK的Atomic包里提供了一个类AtomicStampedReference来解决ABA问题。这个类的compareAndSet方法的作用是首先检查当前引用是否等于预期引用，并且检查当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。 循环时间长开销大自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令，那么效率会有一定的提升。pause指令有两个作用：第一，它可以延迟流水线执行命令(de-pipeline)，使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零；第二，它可以避免在退出循环的时候因内存顺序冲突(Memory Order Violation)而引起CPU流水线被清空(CPU Pipeline Flush)，从而提高CPU的执行效率。 只能保证一个共享变量的原子操作当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。 还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i &#x3D; 2，j &#x3D; a，合并一下ij &#x3D; 2a，然后用CAS来操作ij。 从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。 UnSafe类详解 上文我们了解到Java原子类是通过UnSafe类实现的，这节主要分析下UnSafe类。UnSafe类在J.U.C中CAS操作有很广泛的应用。 Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。 这个类尽管里面的方法都是 public 的，但是并没有办法使用它们，JDK API 文档也没有提供任何关于这个类的方法的解释。总而言之，对于 Unsafe 类的使用都是受限制的，只有授信的代码才能获得该类的实例，当然 JDK 库里面的类是可以随意使用的。 先来看下这张图，对UnSafe类总体功能： 如上图所示，Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类，下面将对其相关方法和应用场景进行详细介绍。 Unsafe与CAS反编译出来的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344public final int getAndAddInt(Object paramObject, long paramLong, int paramInt) &#123; int i; do i = getIntVolatile(paramObject, paramLong); while (!compareAndSwapInt(paramObject, paramLong, i, i + paramInt)); return i; &#125; public final long getAndAddLong(Object paramObject, long paramLong1, long paramLong2) &#123; long l; do l = getLongVolatile(paramObject, paramLong1); while (!compareAndSwapLong(paramObject, paramLong1, l, l + paramLong2)); return l; &#125; public final int getAndSetInt(Object paramObject, long paramLong, int paramInt) &#123; int i; do i = getIntVolatile(paramObject, paramLong); while (!compareAndSwapInt(paramObject, paramLong, i, paramInt)); return i; &#125; public final long getAndSetLong(Object paramObject, long paramLong1, long paramLong2) &#123; long l; do l = getLongVolatile(paramObject, paramLong1); while (!compareAndSwapLong(paramObject, paramLong1, l, paramLong2)); return l; &#125; public final Object getAndSetObject(Object paramObject1, long paramLong, Object paramObject2) &#123; Object localObject; do localObject = getObjectVolatile(paramObject1, paramLong); while (!compareAndSwapObject(paramObject1, paramLong, localObject, paramObject2)); return localObject; &#125; 从源码中发现，内部使用自旋的方式进行CAS更新(while循环进行CAS更新，如果更新失败，则循环再次重试)。 又从Unsafe类中发现，原子操作其实只支持下面三个方法。 12345public final native boolean compareAndSwapObject(Object paramObject1, long paramLong, Object paramObject2, Object paramObject3);public final native boolean compareAndSwapInt(Object paramObject, long paramLong, int paramInt1, int paramInt2);public final native boolean compareAndSwapLong(Object paramObject, long paramLong1, long paramLong2, long paramLong3); 我们发现Unsafe只提供了3种CAS方法：compareAndSwapObject、compareAndSwapInt和compareAndSwapLong。都是native方法。 Unsafe底层不妨再看看Unsafe的compareAndSwap*方法来实现CAS操作，它是一个本地方法，实现位于unsafe.cpp中。 123456UNSAFE_ENTRY(jboolean, Unsafe_CompareAndSwapInt(JNIEnv *env, jobject unsafe, jobject obj, jlong offset, jint e, jint x)) UnsafeWrapper(&quot;Unsafe_CompareAndSwapInt&quot;); oop p = JNIHandles::resolve(obj); jint* addr = (jint *) index_oop_from_field_offset_long(p, offset); return (jint)(Atomic::cmpxchg(x, addr, e)) == e;UNSAFE_END 可以看到它通过 Atomic::cmpxchg 来实现比较和替换操作。其中参数x是即将更新的值，参数e是原内存的值。 如果是Linux的x86，Atomic::cmpxchg方法的实现如下： 12345678inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; int mp = os::is_MP(); __asm__ volatile (LOCK_IF_MP(%4) &quot;cmpxchgl %1,(%3)&quot; : &quot;=a&quot; (exchange_value) : &quot;r&quot; (exchange_value), &quot;a&quot; (compare_value), &quot;r&quot; (dest), &quot;r&quot; (mp) : &quot;cc&quot;, &quot;memory&quot;); return exchange_value;&#125; 而windows的x86的实现如下： 12345678910111213141516171819inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; int mp = os::isMP(); //判断是否是多处理器 _asm &#123; mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx &#125;&#125;// Adding a lock prefix to an instruction on MP machine// VC++ doesn&#x27;t like the lock prefix to be on a single line// so we can&#x27;t insert a label after the lock prefix.// By emitting a lock prefix, we can define a label after it.#define LOCK_IF_MP(mp) __asm cmp mp, 0 \\ __asm je L0 \\ __asm _emit 0xF0 \\ __asm L0: 如果是多处理器，为cmpxchg指令添加lock前缀。反之，就省略lock前缀(单处理器会不需要lock前缀提供的内存屏障效果)。这里的lock前缀就是使用了处理器的总线锁(最新的处理器都使用缓存锁代替总线锁来提高性能)。 cmpxchg(void* ptr, int old, int new)，如果ptr和old的值一样，则把new写到ptr内存，否则返回ptr的值，整个操作是原子的。在Intel平台下，会用lock cmpxchg来实现，使用lock触发缓存锁，这样另一个线程想访问ptr的内存，就会被block住。 Unsafe其它功能Unsafe 提供了硬件级别的操作，比如说获取某个属性在内存中的位置，比如说修改对象的字段值，即使它是私有的。不过 Java 本身就是为了屏蔽底层的差异，对于一般的开发而言也很少会有这样的需求。 举两个例子，比方说： 1public native long staticFieldOffset(Field paramField); 这个方法可以用来获取给定的 paramField 的内存地址偏移量，这个值对于给定的 field 是唯一的且是固定不变的。 再比如说： 12public native int arrayBaseOffset(Class paramClass);public native int arrayIndexScale(Class paramClass); 前一个方法是用来获取数组第一个元素的偏移地址，后一个方法是用来获取数组的转换因子即数组中元素的增量地址的。 最后看三个方法： 123public native long allocateMemory(long paramLong);public native long reallocateMemory(long paramLong1, long paramLong2);public native void freeMemory(long paramLong); 分别用来分配内存，扩充内存和释放内存的。 更多相关功能，推荐你看下这篇文章：来自美团技术团队：Java魔法类：Unsafe应用解析在 AtomicInteger使用举例以 AtomicInteger 为例，常用 API： 123456public final int get()：获取当前的值public final int getAndSet(int newValue)：获取当前的值，并设置新的值public final int getAndIncrement()：获取当前的值，并自增public final int getAndDecrement()：获取当前的值，并自减public final int getAndAdd(int delta)：获取当前的值，并加上预期的值void lazySet(int newValue): 最终会设置成newValue,使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。 相比 Integer 的优势，多线程中让变量自增： 12345678private volatile int count = 0;// 若要线程安全执行执行 count++，需要加锁public synchronized void increment() &#123; count++;&#125;public int getCount() &#123; return count;&#125; 使用 AtomicInteger 后： 12345678private AtomicInteger count = new AtomicInteger();public void increment() &#123; count.incrementAndGet();&#125;// 使用 AtomicInteger 后，不需要加锁，也可以实现线程安全public int getCount() &#123; return count.get();&#125; 源码解析1234567891011121314151617181920212223242526272829public class AtomicInteger extends Number implements java.io.Serializable &#123; private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; //用于获取value字段相对当前对象的“起始地址”的偏移量 valueOffset = unsafe.objectFieldOffset(AtomicInteger.class.getDeclaredField(&quot;value&quot;)); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; //返回当前值 public final int get() &#123; return value; &#125; //递增加detla public final int getAndAdd(int delta) &#123; //三个参数，1、当前的实例 2、value实例变量的偏移量 3、当前value要加上的数(value+delta)。 return unsafe.getAndAddInt(this, valueOffset, delta); &#125; //递增加1 public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125;...&#125; 我们可以看到 AtomicInteger 底层用的是volatile的变量和CAS来进行更改数据的。 volatile保证线程的可见性，多线程并发时，一个线程修改数据，可以保证其它线程立马看到修改后的值 CAS 保证数据更新的原子性。 延伸到所有原子类：共12个 JDK中提供了12个原子操作类。 原子更新基本类型使用原子的方式更新基本类型，Atomic包提供了以下3个类。 AtomicBoolean: 原子更新布尔类型。 AtomicInteger: 原子更新整型。 AtomicLong: 原子更新长整型。 以上3个类提供的方法几乎一模一样，可以参考上面AtomicInteger中的相关方法。 原子更新数组通过原子的方式更新数组里的某个元素，Atomic包提供了以下的3个类： AtomicIntegerArray: 原子更新整型数组里的元素。 AtomicLongArray: 原子更新长整型数组里的元素。 AtomicReferenceArray: 原子更新引用类型数组里的元素。 这三个类的最常用的方法是如下两个方法： get(int index)：获取索引为index的元素值。 compareAndSet(int i,E expect,E update): 如果当前值等于预期值，则以原子方式将数组位置i的元素设置为update值。 举个AtomicIntegerArray例子： 12345678910import java.util.concurrent.atomic.AtomicIntegerArray;public class Demo5 &#123; public static void main(String[] args) throws InterruptedException &#123; AtomicIntegerArray array = new AtomicIntegerArray(new int[] &#123; 0, 0 &#125;); System.out.println(array); System.out.println(array.getAndAdd(1, 2)); System.out.println(array); &#125;&#125; 输出结果： 123[0, 0]0[0, 2] 原子更新引用类型Atomic包提供了以下三个类： AtomicReference: 原子更新引用类型。 AtomicStampedReference: 原子更新引用类型, 内部使用Pair来存储元素值及其版本号。 AtomicMarkableReferce: 原子更新带有标记位的引用类型。 这三个类提供的方法都差不多，首先构造一个引用对象，然后把引用对象set进Atomic类，然后调用compareAndSet等一些方法去进行原子操作，原理都是基于Unsafe实现，但AtomicReferenceFieldUpdater略有不同，更新的字段必须用volatile修饰。 举个AtomicReference例子： 1234567891011121314151617181920212223242526272829import java.util.concurrent.atomic.AtomicReference;public class AtomicReferenceTest &#123; public static void main(String[] args)&#123; // 创建两个Person对象，它们的id分别是101和102。 Person p1 = new Person(101); Person p2 = new Person(102); // 新建AtomicReference对象，初始化它的值为p1对象 AtomicReference ar = new AtomicReference(p1); // 通过CAS设置ar。如果ar的值为p1的话，则将其设置为p2。 ar.compareAndSet(p1, p2); Person p3 = (Person)ar.get(); System.out.println(&quot;p3 is &quot;+p3); System.out.println(&quot;p3.equals(p1)=&quot;+p3.equals(p1)); &#125;&#125;class Person &#123; volatile long id; public Person(long id) &#123; this.id = id; &#125; public String toString() &#123; return &quot;id:&quot;+id; &#125;&#125; 结果输出： 12p3 is id:102p3.equals(p1)=false 结果说明： 新建AtomicReference对象ar时，将它初始化为p1。 紧接着，通过CAS函数对它进行设置。如果ar的值为p1的话，则将其设置为p2。 最后，获取ar对应的对象，并打印结果。p3.equals(p1)的结果为false，这是因为Person并没有覆盖equals()方法，而是采用继承自Object.java的equals()方法；而Object.java中的equals()实际上是调用”&#x3D;&#x3D;”去比较两个对象，即比较两个对象的地址是否相等。 原子更新字段类Atomic包提供了四个类进行原子字段更新： AtomicIntegerFieldUpdater: 原子更新整型的字段的更新器。 AtomicLongFieldUpdater: 原子更新长整型字段的更新器。 AtomicReferenceFieldUpdater: 上面已经说过此处不在赘述。 这四个类的使用方式都差不多，是基于反射的原子更新字段的值。要想原子地更新字段类需要两步: 第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。 第二步，更新类的字段必须使用public volatile修饰。 举个例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class TestAtomicIntegerFieldUpdater &#123; public static void main(String[] args)&#123; TestAtomicIntegerFieldUpdater tIA = new TestAtomicIntegerFieldUpdater(); tIA.doIt(); &#125; public AtomicIntegerFieldUpdater&lt;DataDemo&gt; updater(String name)&#123; return AtomicIntegerFieldUpdater.newUpdater(DataDemo.class,name); &#125; public void doIt()&#123; DataDemo data = new DataDemo(); System.out.println(&quot;publicVar = &quot;+updater(&quot;publicVar&quot;).getAndAdd(data, 2)); /* * 由于在DataDemo类中属性value2/value3,在TestAtomicIntegerFieldUpdater中不能访问 * */ //System.out.println(&quot;protectedVar = &quot;+updater(&quot;protectedVar&quot;).getAndAdd(data,2)); //System.out.println(&quot;privateVar = &quot;+updater(&quot;privateVar&quot;).getAndAdd(data,2)); //System.out.println(&quot;staticVar = &quot;+updater(&quot;staticVar&quot;).getAndIncrement(data));//报java.lang.IllegalArgumentException /* * 下面报异常：must be integer * */ //System.out.println(&quot;integerVar = &quot;+updater(&quot;integerVar&quot;).getAndIncrement(data)); //System.out.println(&quot;longVar = &quot;+updater(&quot;longVar&quot;).getAndIncrement(data)); &#125;&#125;class DataDemo&#123; public volatile int publicVar=3; protected volatile int protectedVar=4; private volatile int privateVar=5; public volatile static int staticVar = 10; //public final int finalVar = 11; public volatile Integer integerVar = 19; public volatile Long longVar = 18L;&#125; 再说下对于AtomicIntegerFieldUpdater 的使用稍微有一些限制和约束，约束如下： 字段必须是volatile类型的，在线程之间共享变量时保证立即可见.eg:volatile int value &#x3D; 3 字段的描述类型(修饰符public&#x2F;protected&#x2F;default&#x2F;private)是与调用者与操作对象字段的关系一致。也就是说调用者能够直接操作对象字段，那么就可以反射进行原子操作。但是对于父类的字段，子类是不能直接操作的，尽管子类可以访问父类的字段。 只能是实例变量，不能是类变量，也就是说不能加static关键字。 只能是可修改变量，不能使final变量，因为final的语义就是不可修改。实际上final的语义和volatile是有冲突的，这两个关键字不能同时存在。 对于AtomicIntegerFieldUpdater和AtomicLongFieldUpdater只能修改int&#x2F;long类型的字段，不能修改其包装类型(Integer&#x2F;Long)。如果要修改包装类型就需要使用AtomicReferenceFieldUpdater。 再讲讲AtomicStampedReference解决CAS的ABA问题AtomicStampedReference解决ABA问题AtomicStampedReference主要维护包含一个对象引用以及一个可以自动更新的整数”stamp”的pair对象来解决ABA问题。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class AtomicStampedReference&lt;V&gt; &#123; private static class Pair&lt;T&gt; &#123; final T reference; //维护对象引用 final int stamp; //用于标志版本 private Pair(T reference, int stamp) &#123; this.reference = reference; this.stamp = stamp; &#125; static &lt;T&gt; Pair&lt;T&gt; of(T reference, int stamp) &#123; return new Pair&lt;T&gt;(reference, stamp); &#125; &#125; private volatile Pair&lt;V&gt; pair; .... /** * expectedReference ：更新之前的原始值 * newReference : 将要更新的新值 * expectedStamp : 期待更新的标志版本 * newStamp : 将要更新的标志版本 */ public boolean compareAndSet(V expectedReference, V newReference, int expectedStamp, int newStamp) &#123; // 获取当前的(元素值，版本号)对 Pair&lt;V&gt; current = pair; return // 引用没变 expectedReference == current.reference &amp;&amp; // 版本号没变 expectedStamp == current.stamp &amp;&amp; // 新引用等于旧引用 ((newReference == current.reference &amp;&amp; // 新版本号等于旧版本号 newStamp == current.stamp) || // 构造新的Pair对象并CAS更新 casPair(current, Pair.of(newReference, newStamp))); &#125; private boolean casPair(Pair&lt;V&gt; cmp, Pair&lt;V&gt; val) &#123; // 调用Unsafe的compareAndSwapObject()方法CAS更新pair的引用为新引用 return UNSAFE.compareAndSwapObject(this, pairOffset, cmp, val); &#125; 如果元素值和版本号都没有变化，并且和新的也相同，返回true； 如果元素值和版本号都没有变化，并且和新的不完全相同，就构造一个新的Pair对象并执行CAS更新pair。 可以看到，java中的实现跟我们上面讲的ABA的解决方法是一致的。 首先，使用版本号控制； 其次，不重复使用节点(Pair)的引用，每次都新建一个新的Pair来作为CAS比较的对象，而不是复用旧的； 最后，外部传入元素值及版本号，而不是节点(Pair)的引用。 使用举例12345678910111213141516171819202122232425262728293031323334public class AtomicTester &#123; private static AtomicStampedReference&lt;Integer&gt; atomicStampedRef = new AtomicStampedReference&lt;&gt;(1, 0); public static void main(String[] args)&#123; first().start(); second().start(); &#125; private static Thread first() &#123; return new Thread(() -&gt; &#123; System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,初始值 a = &quot; + atomicStampedRef.getReference()); int stamp = atomicStampedRef.getStamp(); //获取当前标识别 try &#123; Thread.sleep(1000); //等待1秒 ，以便让干扰线程执行 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; boolean isCASSuccess = atomicStampedRef.compareAndSet(1,2,stamp,stamp +1); //此时expectedReference未发生改变，但是stamp已经被修改了,所以CAS失败 System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,CAS操作结果: &quot; + isCASSuccess); &#125;,&quot;主操作线程&quot;); &#125; private static Thread second() &#123; return new Thread(() -&gt; &#123; Thread.yield(); // 确保thread-first 优先执行 atomicStampedRef.compareAndSet(1,2,atomicStampedRef.getStamp(),atomicStampedRef.getStamp() +1); System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,【increment】 ,值 = &quot;+ atomicStampedRef.getReference()); atomicStampedRef.compareAndSet(2,1,atomicStampedRef.getStamp(),atomicStampedRef.getStamp() +1); System.out.println(&quot;操作线程&quot; + Thread.currentThread() +&quot;,【decrement】 ,值 = &quot;+ atomicStampedRef.getReference()); &#125;,&quot;干扰线程&quot;); &#125;&#125; 输出结果： 1234操作线程Thread[主操作线程,5,main],初始值 a = 1操作线程Thread[干扰线程,5,main],【increment】 ,值 = 2操作线程Thread[干扰线程,5,main],【decrement】 ,值 = 1操作线程Thread[主操作线程,5,main],CAS操作结果: false java中还有哪些类可以解决ABA的问题?AtomicMarkableReference，它不是维护一个版本号，而是维护一个boolean类型的标记，标记值有修改，了解一下。 参考文章 https://benjaminwhx.com/2018/05/03/%E3%80%90%E7%BB%86%E8%B0%88Java%E5%B9%B6%E5%8F%91%E3%80%91%E8%B0%88%E8%B0%88CAS/ https://www.jianshu.com/p/9a1e6940987a https://www.jianshu.com/p/a533cbb740c6 https://blog.csdn.net/qq_36236890/article/details/81914871 https://www.cnblogs.com/lodor/p/7492805.html https://blog.csdn.net/u010412719/article/details/52068888 https://www.jianshu.com/p/18dfc5fa0171 https://www.jianshu.com/p/8b227a8adbc1 https://www.jianshu.com/p/77f75b398be9 https://tech.meituan.com/2019/02/14/talk-about-java-magic-class-unsafe.html","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"8.JUC - 类汇总和学习指南","path":"/2023/12/25/8-JUC-类汇总和学习指南/","content":"提示 本文对J.U.C进行知识体系解读，后续的文章还针对几乎所有的核心的类以及常用的工具类作了详细的解读; 如果没有时间详细阅读相关章节，可以跟着本文站在一定的高度了解JUC下包的设计和实现；同时对重要的章节提供跳转链接，您可以链接过去详读。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解相关知识点。 JUC框架包含几个部分? 每个部分有哪些核心的类? 最最核心的类有哪些? Overview阅读前，推荐你学习下并发相关基础 Java 并发 - 理论基础 Java 并发 - 线程基础 关键字: synchronized详解 J关键字: volatile详解 关键字: final详解 正式学习时先了解五个部分： 主要包含: (注意: 上图是网上找的图，无法表述一些继承关系，同时少了部分类；但是主体上可以看出其分类关系也够了) Lock框架和Tools类(把图中这两个放到一起理解) Collections: 并发集合 Atomic: 原子类 Executors: 线程池 Lock框架和Tools类类结构总览 接口: Condition Condition为接口类型，它将 Object 监视器方法(wait、notify 和 notifyAll)分解成截然不同的对象，以便通过将这些对象与任意 Lock 实现组合使用，为每个对象提供多个等待 set (wait-set)。其中，Lock 替代了 synchronized 方法和语句的使用，Condition 替代了 Object 监视器方法的使用。可以通过await(),signal()来休眠&#x2F;唤醒线程。 在JUC锁: AbstractQueuedSynchronizer详解中类的内部类-conditionobject类有具体分析。 接口: Lock Lock为接口类型，Lock实现提供了比使用synchronized方法和语句可获得的更广泛的锁定操作。此实现允许更灵活的结构，可以具有差别很大的属性，可以支持多个相关的Condition对象。 接口: ReadWriteLock ReadWriteLock为接口类型， 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。 抽象类: AbstractOwnableSynchonizer AbstractOwnableSynchonizer为抽象类，可以由线程以独占方式拥有的同步器。此类为创建锁和相关同步器(伴随着所有权的概念)提供了基础。AbstractOwnableSynchronizer 类本身不管理或使用此信息。但是，子类和工具可以使用适当维护的值帮助控制和监视访问以及提供诊断。 抽象类(long): AbstractQueuedLongSynchronizer AbstractQueuedLongSynchronizer为抽象类，以 long 形式维护同步状态的一个 AbstractQueuedSynchronizer 版本。此类具有的结构、属性和方法与 AbstractQueuedSynchronizer 完全相同，但所有与状态相关的参数和结果都定义为 long 而不是 int。当创建需要 64 位状态的多级别锁和屏障等同步器时，此类很有用。 核心抽象类(int): AbstractQueuedSynchronizer AbstractQueuedSynchronizer为抽象类，其为实现依赖于先进先出 (FIFO) 等待队列的阻塞锁和相关同步器(信号量、事件，等等)提供一个框架。此类的设计目标是成为依靠单个原子 int 值来表示状态的大多数同步器的一个有用基础。 详细分析请看: JUC锁: AbstractQueuedSynchronizer详解 锁常用类: LockSupport LockSupport为常用类，用来创建锁和其他同步类的基本线程阻塞原语。LockSupport的功能和”Thread中的 Thread.suspend()和Thread.resume()有点类似”，LockSupport中的park() 和 unpark() 的作用分别是阻塞线程和解除阻塞线程。但是park()和unpark()不会遇到“Thread.suspend 和 Thread.resume所可能引发的死锁”问题。 详细分析请看: JUC锁: LockSupport详解 锁常用类: ReentrantLock ReentrantLock为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。 详细分析请看: JUC锁: ReentrantLock详解 锁常用类: ReentrantReadWriteLock ReentrantReadWriteLock是读写锁接口ReadWriteLock的实现类，它包括Lock子类ReadLock和WriteLock。ReadLock是共享锁，WriteLock是独占锁。 详细分析请看: JUC锁: ReentrantReadWriteLock详解 锁常用类: StampedLock 它是java8在java.util.concurrent.locks新增的一个API。StampedLock控制锁有三种模式(写，读，乐观读)，一个StampedLock状态是由版本和模式两个部分组成，锁获取方法返回一个数字作为票据stamp，它用相应的锁状态表示并控制访问，数字0表示没有写锁被授权访问。在读锁上分为悲观锁和乐观锁。 详细分析请看: Java 8 - StampedLock详解 工具常用类: CountDownLatch CountDownLatch为常用类，它是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 详细分析请看: JUC工具类: CountDownLatch详解 工具常用类: CyclicBarrier CyclicBarrier为常用类，其是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)。在涉及一组固定大小的线程的程序中，这些线程必须不时地互相等待，此时 CyclicBarrier 很有用。因为该 barrier 在释放等待线程后可以重用，所以称它为循环 的 barrier。 详细分析请看: JUC工具类: CyclicBarrier详解 工具常用类: Phaser Phaser是JDK 7新增的一个同步辅助类，它可以实现CyclicBarrier和CountDownLatch类似的功能，而且它支持对任务的动态调整，并支持分层结构来达到更高的吞吐量。 详细分析请看: JUC工具类: Phaser详解 工具常用类: Semaphore Semaphore为常用类，其是一个计数信号量，从概念上讲，信号量维护了一个许可集。如有必要，在许可可用前会阻塞每一个 acquire()，然后再获取该许可。每个 release() 添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。通常用于限制可以访问某些资源(物理或逻辑的)的线程数目。 详细分析请看: JUC工具类: Semaphore详解 工具常用类: Exchanger Exchanger是用于线程协作的工具类, 主要用于两个线程之间的数据交换。它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange()方法交换数据，当一个线程先执行exchange()方法后，它会一直等待第二个线程也执行exchange()方法，当这两个线程到达同步点时，这两个线程就可以交换数据了。 详细分析请看: JUC工具类: Exchanger详解 Collections: 并发集合类结构关系 Queue: ArrayBlockingQueue 一个由数组支持的有界阻塞队列。此队列按 FIFO(先进先出)原则对元素进行排序。队列的头部 是在队列中存在时间最长的元素。队列的尾部 是在队列中存在时间最短的元素。新元素插入到队列的尾部，队列获取操作则是从队列头部开始获得元素。 详细分析请看: JUC并发集合: BlockingQueue详解 Queue: LinkedBlockingQueue 一个基于已链接节点的、范围任意的 blocking queue。此队列按 FIFO(先进先出)排序元素。队列的头部 是在队列中时间最长的元素。队列的尾部 是在队列中时间最短的元素。新元素插入到队列的尾部，并且队列获取操作会获得位于队列头部的元素。链接队列的吞吐量通常要高于基于数组的队列，但是在大多数并发应用程序中，其可预知的性能要低。 详细分析请看: JUC并发集合: BlockingQueue详解 Queue: LinkedBlockingDeque 一个基于已链接节点的、任选范围的阻塞双端队列。 详细分析请看: JUC并发集合: BlockingQueue详解 Queue: ConcurrentLinkedQueue 一个基于链接节点的无界线程安全队列。此队列按照 FIFO(先进先出)原则对元素进行排序。队列的头部 是队列中时间最长的元素。队列的尾部 是队列中时间最短的元素。新的元素插入到队列的尾部，队列获取操作从队列头部获得元素。当多个线程共享访问一个公共 collection 时，ConcurrentLinkedQueue 是一个恰当的选择。此队列不允许使用 null 元素。 详细分析请看: JUC并发集合: ConcurrentLinkedQueue详解 Queue: ConcurrentLinkedDeque 是双向链表实现的无界队列，该队列同时支持FIFO和FILO两种操作方式。 Queue: DelayQueue 延时无界阻塞队列，使用Lock机制实现并发访问。队列里只允许放可以“延期”的元素，队列中的head是最先“到期”的元素。如果队里中没有元素到“到期”，那么就算队列中有元素也不能获取到。 Queue: PriorityBlockingQueue 无界优先级阻塞队列，使用Lock机制实现并发访问。priorityQueue的线程安全版，不允许存放null值，依赖于comparable的排序，不允许存放不可比较的对象类型。 Queue: SynchronousQueue 没有容量的同步队列，通过CAS实现并发访问，支持FIFO和FILO。 Queue: LinkedTransferQueue JDK 7新增，单向链表实现的无界阻塞队列，通过CAS实现并发访问，队列元素使用 FIFO(先进先出)方式。LinkedTransferQueue可以说是ConcurrentLinkedQueue、SynchronousQueue(公平模式)和LinkedBlockingQueue的超集, 它不仅仅综合了这几个类的功能，同时也提供了更高效的实现。 List: CopyOnWriteArrayList ArrayList 的一个线程安全的变体，其中所有可变操作(add、set 等等)都是通过对底层数组进行一次新的复制来实现的。这一般需要很大的开销，但是当遍历操作的数量大大超过可变操作的数量时，这种方法可能比其他替代方法更 有效。在不能或不想进行同步遍历，但又需要从并发线程中排除冲突时，它也很有用。 详细分析请看: JUC并发集合: CopyOnWriteArrayList详解 Set: CopyOnWriteArraySet 对其所有操作使用内部CopyOnWriteArrayList的Set。即将所有操作转发至CopyOnWriteArayList来进行操作，能够保证线程安全。在add时，会调用addIfAbsent，由于每次add时都要进行数组遍历，因此性能会略低于CopyOnWriteArrayList。 Set: ConcurrentSkipListSet 一个基于ConcurrentSkipListMap 的可缩放并发 NavigableSet 实现。set 的元素可以根据它们的自然顺序进行排序，也可以根据创建 set 时所提供的 Comparator 进行排序，具体取决于使用的构造方法。 Map: ConcurrentHashMap 是线程安全HashMap的。ConcurrentHashMap在JDK 7之前是通过Lock和segment(分段锁)实现，JDK 8 之后改为CAS+synchronized来保证并发安全。 详细分析请看: JUC并发集合: ConcurrentHashMap详解, 包含了对JDK 7和JDK 8版本的源码分析。 Map: ConcurrentSkipListMap 线程安全的有序的哈希表(相当于线程安全的TreeMap);映射可以根据键的自然顺序进行排序，也可以根据创建映射时所提供的 Comparator 进行排序，具体取决于使用的构造方法。 Atomic: 原子类其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。实际上是借助硬件的相关指令来实现的，不会阻塞线程(或者说只是在硬件级别上阻塞了)。 对CAS，Unsafe类，以及13个原子类详解请参考：详细分析请看: JUC原子类: CAS, Unsafe和原子类详解 基础类型：AtomicBoolean，AtomicInteger，AtomicLong AtomicBoolean，AtomicInteger，AtomicLong是类似的，分别针对bool，interger，long的原子类。 数组：AtomicIntegerArray，AtomicLongArray，BooleanArray AtomicIntegerArray，AtomicLongArray，AtomicBooleanArray是数组原子类。 引用：AtomicReference，AtomicMarkedReference，AtomicStampedReference AtomicReference，AtomicMarkedReference，AtomicStampedReference是引用相关的原子类。 FieldUpdater：AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater AtomicLongFieldUpdater，AtomicIntegerFieldUpdater，AtomicReferenceFieldUpdater是FieldUpdater原子类。 Executors: 线程池类结构关系 接口: Executor Executor接口提供一种将任务提交与每个任务将如何运行的机制(包括线程使用的细节、调度等)分离开来的方法。通常使用 Executor 而不是显式地创建线程。 ExecutorService ExecutorService继承自Executor接口，ExecutorService提供了管理终止的方法，以及可为跟踪一个或多个异步任务执行状况而生成 Future 的方法。 可以关闭 ExecutorService，这将导致其停止接受新任务。关闭后，执行程序将最后终止，这时没有任务在执行，也没有任务在等待执行，并且无法提交新任务。 ScheduledExecutorService ScheduledExecutorService继承自ExecutorService接口，可安排在给定的延迟后运行或定期执行的命令。 AbstractExecutorService AbstractExecutorService继承自ExecutorService接口，其提供 ExecutorService 执行方法的默认实现。此类使用 newTaskFor 返回的 RunnableFuture 实现 submit、invokeAny 和 invokeAll 方法，默认情况下，RunnableFuture 是此包中提供的 FutureTask 类。 FutureTask FutureTask 为 Future 提供了基础实现，如获取任务执行结果(get)和取消任务(cancel)等。如果任务尚未完成，获取任务执行结果时将会阻塞。一旦执行结束，任务就不能被重启或取消(除非使用runAndReset执行计算)。FutureTask 常用来封装 Callable 和 Runnable，也可以作为一个任务提交到线程池中执行。除了作为一个独立的类之外，此类也提供了一些功能性函数供我们创建自定义 task 类使用。FutureTask 的线程安全由CAS来保证。 详细分析请看: JUC线程池: FutureTask详解 核心: ThreadPoolExecutor ThreadPoolExecutor实现了AbstractExecutorService接口，也是一个 ExecutorService，它使用可能的几个池线程之一执行每个提交的任务，通常使用 Executors 工厂方法配置。 线程池可以解决两个不同问题: 由于减少了每个任务调用的开销，它们通常可以在执行大量异步任务时提供增强的性能，并且还可以提供绑定和管理资源(包括执行任务集时使用的线程)的方法。每个 ThreadPoolExecutor 还维护着一些基本的统计数据，如完成的任务数。 详细分析请看: JUC线程池: ThreadPoolExecutor详解 核心: ScheduledThreadExecutor ScheduledThreadPoolExecutor实现ScheduledExecutorService接口，可安排在给定的延迟后运行命令，或者定期执行命令。需要多个辅助线程时，或者要求 ThreadPoolExecutor 具有额外的灵活性或功能时，此类要优于 Timer。 详细分析请看: JUC线程池: ScheduledThreadExecutor详解 核心: Fork&#x2F;Join框架 ForkJoinPool 是JDK 7加入的一个线程池类。Fork&#x2F;Join 技术是分治算法(Divide-and-Conquer)的并行实现，它是一项可以获得良好的并行性能的简单且高效的设计技术。目的是为了帮助我们更好地利用多处理器带来的好处，使用所有可用的运算能力来提升应用的性能。 详细分析请看: JUC线程池: Fork&#x2F;Join框架详解 工具类: Executors Executors是一个工具类，用其可以创建ExecutorService、ScheduledExecutorService、ThreadFactory、Callable等对象。它的使用融入到了ThreadPoolExecutor, ScheduledThreadExecutor和ForkJoinPool中。 参考文章 https://www.cnblogs.com/leesf456/p/5344133.html https://www.cnblogs.com/leesf456/p/5428630.html https://www.cnblogs.com/leesf456/p/5550043.html https://www.jianshu.com/p/8cb5d816cb69 泰迪的bagwell https://www.jianshu.com/p/af9c0f404a93","tags":["Java","多线程与并发","JUC"],"categories":["Java","多线程与并发","JUC"]},{"title":"7.关键字: final详解","path":"/2023/12/25/7-关键字-final详解/","content":"final 关键字看上去简单，但是真正深入理解的人可以说少之又少，读完本文你就知道我在说什么了。本文将常规的用法简化，提出一些用法和深入的思考。 带着BAT大厂的面试问题去理解final 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解final。 所有的final修饰的字段都是编译期常量吗? 如何理解private所修饰的方法是隐式的final? 说说final类型的类如何拓展? 比如String是final类型，我们想写个MyString复用所有String中方法，同时增加一个新的toMyString()的方法，应该如何做? final方法可以被重载吗? 可以 父类的final方法能不能够被子类重写? 不可以 说说final域重排序规则? 说说final的原理? 使用 final 的限制条件和局限性? 看本文最后的一个思考题 final基础使用修饰类当某个类的整体定义为final时，就表明了你不能打算继承该类，而且也不允许别人这么做。即这个类是不能有子类的。 注意：final类中的所有方法都隐式为final，因为无法覆盖他们，所以在final类中给任何方法添加final关键字是没有任何意义的。 这里顺道说说final类型的类如何拓展? 比如String是final类型，我们想写个MyString复用所有String中方法，同时增加一个新的toMyString()的方法，应该如何做? 设计模式中最重要的两种关系，一种是继承&#x2F;实现；另外一种是组合关系。所以当遇到不能用继承的(final修饰的类),应该考虑用组合, 如下代码大概写个组合实现的意思： 12345678910111213141516171819/*** @pdai*/class MyString&#123; private String innerString; // ...init &amp; other methods // 支持老的方法 public int length()&#123; return innerString.length(); // 通过innerString调用老的方法 &#125; // 添加新方法 public String toMyString()&#123; //... &#125;&#125; 修饰方法 常规的使用就不说了，这里说下: private 方法是隐式的final final方法是可以被重载的 private final类中所有private方法都隐式地指定为final的，由于无法取用private方法，所以也就不能覆盖它。可以对private方法增添final关键字，但这样做并没有什么好处。看下下面的例子： 1234567891011121314public class Base &#123; private void test() &#123; &#125;&#125;public class Son extends Base&#123; public void test() &#123; &#125; public static void main(String[] args) &#123; Son son = new Son(); Base father = son; //father.test(); &#125;&#125; Base和Son都有方法test(),但是这并不是一种覆盖，因为private所修饰的方法是隐式的final，也就是无法被继承，所以更不用说是覆盖了，在Son中的test()方法不过是属于Son的新成员罢了，Son进行向上转型得到father，但是father.test()是不可执行的，因为Base中的test方法是private的，无法被访问到。 final方法是可以被重载的我们知道父类的final方法是不能够被子类重写的，那么final方法可以被重载吗? 答案是可以的，下面代码是正确的。 1234567public class FinalExampleParent &#123; public final void test() &#123; &#125; public final void test(String str) &#123; &#125;&#125; 修饰参数Java允许在参数列表中以声明的方式将参数指明为final，这意味这你无法在方法中更改参数引用所指向的对象。这个特性主要用来向匿名内部类传递数据。 修饰变量 常规的用法比较简单，这里通过下面三个问题进一步说明。 所有的final修饰的字段都是编译期常量吗?现在来看编译期常量和非编译期常量, 如： 12345678910111213public class Test &#123; //编译期常量 final int i = 1; final static int J = 1; final int[] a = &#123;1,2,3,4&#125;; //非编译期常量 Random r = new Random(); final int k = r.nextInt(); public static void main(String[] args) &#123; &#125;&#125; k的值由随机数对象决定，所以不是所有的final修饰的字段都是编译期常量，只是k的值在被初始化后无法被更改。 static final一个既是static又是final 的字段只占据一段不能改变的存储空间，它必须在定义的时候进行赋值，否则编译器将不予通过。 123456789101112import java.util.Random;public class Test &#123; static Random r = new Random(); final int k = r.nextInt(10); static final int k2 = r.nextInt(10); public static void main(String[] args) &#123; Test t1 = new Test(); System.out.println(&quot;k=&quot;+t1.k+&quot; k2=&quot;+t1.k2); Test t2 = new Test(); System.out.println(&quot;k=&quot;+t2.k+&quot; k2=&quot;+t2.k2); &#125;&#125; 上面代码某次输出结果： 12k=2 k2=7k=8 k2=7 我们可以发现对于不同的对象k的值是不同的，但是k2的值却是相同的，这是为什么呢? 因为static关键字所修饰的字段并不属于一个对象，而是属于这个类的。也可简单的理解为static final所修饰的字段仅占据内存的一个一份空间，一旦被初始化之后便不会被更改。 blank finalJava允许生成空白final，也就是说被声明为final但又没有给出定值的字段,但是必须在该字段被使用之前被赋值，这给予我们两种选择： 在定义处进行赋值(这不叫空白final) 在构造器中进行赋值，保证了该值在被使用前赋值。 这增强了final的灵活性。 看下面代码: 12345678910public class Test &#123; final int i1 = 1; final int i2;//空白final public Test() &#123; i2 = 1; &#125; public Test(int x) &#123; this.i2 = x; &#125;&#125; 可以看到i2的赋值更为灵活。但是请注意，如果字段由static和final修饰，仅能在声明时赋值或声明后在静态代码块中赋值，因为该字段不属于对象，属于这个类。 final域重排序规则上面我们聊的final使用，应该属于Java基础层面的，当理解这些后我们就真的算是掌握了final吗? 有考虑过final在多线程并发的情况吗? 在java内存模型中我们知道java内存模型为了能让处理器和编译器底层发挥他们的最大优势，对底层的约束就很少，也就是说针对底层来说java内存模型就是一弱内存数据模型。同时，处理器和编译为了性能优化会对指令序列有编译器和处理器重排序。那么，在多线程情况下,final会进行怎样的重排序? 会导致线程安全的问题吗? 下面，就来看看final的重排序。 final域为基本类型先看一段示例性的代码： 1234567891011121314151617181920public class FinalDemo &#123; private int a; //普通域 private final int b; //final域 private static FinalDemo finalDemo; public FinalDemo() &#123; a = 1; // 1. 写普通域 b = 2; // 2. 写final域 &#125; public static void writer() &#123; finalDemo = new FinalDemo(); &#125; public static void reader() &#123; FinalDemo demo = finalDemo; // 3.读对象引用 int a = demo.a; //4.读普通域 int b = demo.b; //5.读final域 &#125;&#125; 假设线程A在执行writer()方法，线程B执行reader()方法。 写final域重排序规则写final域的重排序规则禁止对final域的写重排序到构造函数之外，这个规则的实现主要包含了两个方面： JMM禁止编译器把final域的写重排序到构造函数之外； 编译器会在final域写之后，构造函数return之前，插入一个storestore屏障。这个屏障可以禁止处理器把final域的写重排序到构造函数之外。 我们再来分析writer方法，虽然只有一行代码，但实际上做了两件事情： 构造了一个FinalDemo对象； 把这个对象赋值给成员变量finalDemo。 我们来画下存在的一种可能执行时序图，如下： 由于a,b之间没有数据依赖性，普通域(普通变量)a可能会被重排序到构造函数之外，线程B就有可能读到的是普通变量a初始化之前的值(零值)，这样就可能出现错误。而final域变量b，根据重排序规则，会禁止final修饰的变量b重排序到构造函数之外，从而b能够正确赋值，线程B就能够读到final变量初始化后的值。 因此，写final域的重排序规则可以确保：在对象引用为任意线程可见之前，对象的final域已经被正确初始化过了，而普通域就不具有这个保障。比如在上例，线程B有可能就是一个未正确初始化的对象finalDemo。 读final域重排序规则读final域重排序规则为：在一个线程中，初次读对象引用和初次读该对象包含的final域，JMM会禁止这两个操作的重排序。(注意，这个规则仅仅是针对处理器)，处理器会在读final域操作的前面插入一个LoadLoad屏障。实际上，读对象的引用和读该对象的final域存在间接依赖性，一般处理器不会重排序这两个操作。但是有一些处理器会重排序，因此，这条禁止重排序规则就是针对这些处理器而设定的。 read()方法主要包含了三个操作： 初次读引用变量finalDemo; 初次读引用变量finalDemo的普通域a; 初次读引用变量finalDemo的final域b; 假设线程A写过程没有重排序，那么线程A和线程B有一种的可能执行时序为下图： 读对象的普通域被重排序到了读对象引用的前面就会出现线程B还未读到对象引用就在读取该对象的普通域变量，这显然是错误的操作。而final域的读操作就“限定”了在读final域变量前已经读到了该对象的引用，从而就可以避免这种情况。 读final域的重排序规则可以确保：在读一个对象的final域之前，一定会先读这个包含这个final域的对象的引用。 final域为引用类型我们已经知道了final域是基本数据类型的时候重排序规则是怎么的了? 如果是引用数据类型了? 我们接着继续来探讨。 对final修饰的对象的成员域写操作针对引用数据类型，final域写针对编译器和处理器重排序增加了这样的约束：在构造函数内对一个final修饰的对象的成员域的写入，与随后在构造函数之外把这个被构造的对象的引用赋给一个引用变量，这两个操作是不能被重排序的。注意这里的是“增加”也就说前面对final基本数据类型的重排序规则在这里还是使用。这句话是比较拗口的，下面结合实例来看。 1234567891011121314151617181920212223public class FinalReferenceDemo &#123; final int[] arrays; private FinalReferenceDemo finalReferenceDemo; public FinalReferenceDemo() &#123; arrays = new int[1]; //1 arrays[0] = 1; //2 &#125; public void writerOne() &#123; finalReferenceDemo = new FinalReferenceDemo(); //3 &#125; public void writerTwo() &#123; arrays[0] = 2; //4 &#125; public void reader() &#123; if (finalReferenceDemo != null) &#123; //5 int temp = finalReferenceDemo.arrays[0]; //6 &#125; &#125;&#125; 针对上面的实例程序，线程线程A执行wirterOne方法，执行完后线程B执行writerTwo方法，然后线程C执行reader方法。下图就以这种执行时序出现的一种情况来讨论(耐心看完才有收获)。 由于对final域的写禁止重排序到构造方法外，因此1和3不能被重排序。由于一个final域的引用对象的成员域写入不能与随后将这个被构造出来的对象赋给引用变量重排序，因此2和3不能重排序。 对final修饰的对象的成员域读操作JMM可以确保线程C至少能看到写线程A对final引用的对象的成员域的写入，即能看下arrays[0] &#x3D; 1，而写线程B对数组元素的写入可能看到可能看不到。JMM不保证线程B的写入对线程C可见，线程B和线程C之间存在数据竞争，此时的结果是不可预知的。如果可见的，可使用锁或者volatile。 关于final重排序的总结按照final修饰的数据类型分类： 基本数据类型: final域写：禁止final域写与构造方法重排序，即禁止final域写重排序到构造方法之外，从而保证该对象对所有线程可见时，该对象的final域全部已经初始化过。 final域读：禁止初次读对象的引用与读该对象包含的final域的重排序。 引用数据类型： 额外增加约束：禁止在构造函数对一个final修饰的对象的成员域的写入与随后将这个被构造的对象的引用赋值给引用变量 重排序 final再深入理解final的实现原理上面我们提到过，写final域会要求编译器在final域写之后，构造函数返回前插入一个StoreStore屏障。读final域的重排序规则会要求编译器在读final域的操作前插入一个LoadLoad屏障。 很有意思的是，如果以X86处理为例，X86不会对写-写重排序，所以StoreStore屏障可以省略。由于不会对有间接依赖性的操作重排序，所以在X86处理器中，读final域需要的LoadLoad屏障也会被省略掉。也就是说，以X86为例的话，对final域的读&#x2F;写的内存屏障都会被省略！具体是否插入还是得看是什么处理器 为什么final引用不能从构造函数中“溢出”这里还有一个比较有意思的问题：上面对final域写重排序规则可以确保我们在使用一个对象引用的时候该对象的final域已经在构造函数被初始化过了。但是这里其实是有一个前提条件的，也就是：在构造函数，不能让这个被构造的对象被其他线程可见，也就是说该对象引用不能在构造函数中“溢出”。以下面的例子来说： 12345678910111213141516171819public class FinalReferenceEscapeDemo &#123; private final int a; private FinalReferenceEscapeDemo referenceDemo; public FinalReferenceEscapeDemo() &#123; a = 1; //1 referenceDemo = this; //2 &#125; public void writer() &#123; new FinalReferenceEscapeDemo(); &#125; public void reader() &#123; if (referenceDemo != null) &#123; //3 int temp = referenceDemo.a; //4 &#125; &#125;&#125; 可能的执行时序如图所示： 假设一个线程A执行writer方法另一个线程执行reader方法。因为构造函数中操作1和2之间没有数据依赖性，1和2可以重排序，先执行了2，这个时候引用对象referenceDemo是个没有完全初始化的对象，而当线程B去读取该对象时就会出错。尽管依然满足了final域写重排序规则：在引用对象对所有线程可见时，其final域已经完全初始化成功。但是，引用对象“this”逸出，该代码依然存在线程安全的问题。 使用 final 的限制条件和局限性当声明一个 final 成员时，必须在构造函数退出前设置它的值。 123456public class MyClass &#123; private final int myField = 1; public MyClass() &#123; ... &#125;&#125; 或者 12345678public class MyClass &#123; private final int myField; public MyClass() &#123; ... myField = 1; ... &#125;&#125; 将指向对象的成员声明为 final 只能将该引用设为不可变的，而非所指的对象。 下面的方法仍然可以修改该 list。 12private final List myList = new ArrayList();myList.add(&quot;Hello&quot;); 声明为 final 可以保证如下操作不合法 12myList = new ArrayList();myList = someOtherList; 如果一个对象将会在多个线程中访问并且你并没有将其成员声明为 final，则必须提供其他方式保证线程安全。 “ 其他方式 “ 可以包括声明成员为 volatile，使用 synchronized 或者显式 Lock 控制所有该成员的访问。 再思考一个有趣的现象：123byte b1=1;byte b2=3;byte b3=b1+b2;//当程序执行到这一行的时候会出错，因为b1、b2可以自动转换成int类型的变量，运算时java虚拟机对它进行了转换，结果导致把一个int赋值给byte-----出错 如果对b1 b2加上final就不会出错 123final byte b1=1;final byte b2=3;byte b3=b1+b2;//不会出错，相信你看了上面的解释就知道原因了。 参考文章 https://www.jianshu.com/p/1e82c75034b7 《java并发编程的艺术》 《疯狂java讲义》","tags":["Java","多线程与并发"],"categories":["Java","多线程与并发"]},{"title":"6.关键字: volatile详解","path":"/2023/12/25/6-关键字-volatile详解/","content":"相比Sychronized(重量级锁，对系统性能影响较大)，volatile提供了另一种解决可见性和有序性问题的方案。 带着BAT大厂的面试问题去理解volatile 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解volatile。 volatile关键字的作用是什么? volatile能保证原子性吗? 之前32位机器上共享的long和double变量的为什么要用volatile? 现在64位机器上是否也要设置呢? i++为什么不能保证原子性? volatile是如何实现可见性的? 内存屏障。 volatile是如何实现有序性的? happens-before等 说下volatile的应用场景? volatile的作用详解防重排序我们从一个最经典的例子来分析重排序问题。大家应该都很熟悉单例模式的实现，而在并发环境下的单例实现方式，我们通常可以采用双重检查加锁(DCL)的方式来实现。其源码如下： 1234567891011121314151617public class Singleton &#123; public static volatile Singleton singleton; /** * 构造函数私有，禁止外部实例化 */ private Singleton() &#123;&#125;; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 现在我们分析一下为什么要在变量singleton之间加上volatile关键字。要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤： 分配内存空间。 初始化对象。 将内存空间的地址赋值给对应的引用。 但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程： 分配内存空间。 将内存空间的地址赋值给对应的引用。 初始化对象 如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。 实现可见性可见性问题主要指一个线程修改了共享变量值，而另一个线程却看不到。引起可见性问题的主要原因是每个线程拥有自己的一个高速缓存区——线程工作内存。volatile关键字能有效的解决这个问题，我们看下下面的例子，就可以知道其作用： 123456789101112131415161718192021222324public class TestVolatile &#123; private static boolean stop = false; public static void main(String[] args) &#123; // Thread-A new Thread(&quot;Thread A&quot;) &#123; @Override public void run() &#123; while (!stop) &#123; &#125; System.out.println(Thread.currentThread() + &quot; stopped&quot;); &#125; &#125;.start(); // Thread-main try &#123; TimeUnit.SECONDS.sleep(1); System.out.println(Thread.currentThread() + &quot; after 1 seconds&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; stop = true; &#125;&#125; 执行输出如下 123Thread[main,5,main] after 1 seconds// Thread A一直在loop, 因为Thread A 由于可见性原因看不到Thread Main 已经修改stop的值 可以看到 Thread-main 休眠1秒之后，设置 stop &#x3D; ture，但是Thread A根本没停下来，这就是可见性问题。如果通过在stop变量前面加上volatile关键字则会真正stop: 1234Thread[main,5,main] after 1 secondsThread[Thread A,5,main] stoppedProcess finished with exit code 0 保证原子性:单次读&#x2F;写volatile不能保证完全的原子性，只能保证单次的读&#x2F;写操作具有原子性。先从如下两个问题来理解（后文再从内存屏障的角度理解）： 问题1： i++为什么不能保证原子性?对于原子性，需要强调一点，也是大家容易误解的一点：对volatile变量的单次读&#x2F;写操作可以保证原子性的，如long和double类型变量，但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作。 现在我们就通过下列程序来演示一下这个问题： 1234567891011121314151617181920212223242526public class VolatileTest01 &#123; volatile int i; public void addI()&#123; i++; &#125; public static void main(String[] args) throws InterruptedException &#123; final VolatileTest01 test01 = new VolatileTest01(); for (int n = 0; n &lt; 1000; n++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; test01.addI(); &#125; &#125;).start(); &#125; Thread.sleep(10000);//等待10秒，保证上面程序执行完成 System.out.println(test01.i); &#125;&#125; 大家可能会误认为对变量i加上关键字volatile后，这段程序就是线程安全的。大家可以尝试运行上面的程序。下面是我本地运行的结果：981 可能每个人运行的结果不相同。不过应该能看出，volatile是无法保证原子性的(否则结果应该是1000)。原因也很简单，i++其实是一个复合操作，包括三步骤： 读取i的值。 对i加1。 将i的值写回内存。 volatile是无法保证这三个操作是具有原子性的，我们可以通过AtomicInteger或者Synchronized来保证+1操作的原子性。 注：上面几段代码中多处执行了Thread.sleep()方法，目的是为了增加并发问题的产生几率，无其他作用。 问题2： 共享的long和double变量的为什么要用volatile?因为long和double两种数据类型的操作可分为高32位和低32位两部分，因此普通的long或double类型读&#x2F;写可能不是原子的。因此，鼓励大家将共享的long和double变量设置为volatile类型，这样能保证任何情况下对long和double的单次读&#x2F;写操作都具有原子性。 如下是JLS中的解释： 17.7 Non-Atomic Treatment of double and long For the purposes of the Java programming language memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half. This can result in a situation where a thread sees the first 32 bits of a 64-bit value from one write, and the second 32 bits from another write. Writes and reads of volatile long and double values are always atomic. Writes to and reads of references are always atomic, regardless of whether they are implemented as 32-bit or 64-bit values. Some implementations may find it convenient to divide a single write action on a 64-bit long or double value into two write actions on adjacent 32-bit values. For efficiency’s sake, this behavior is implementation-specific; an implementation of the Java Virtual Machine is free to perform writes to long and double values atomically or in two parts. Implementations of the Java Virtual Machine are encouraged to avoid splitting 64-bit values where possible. Programmers are encouraged to declare shared 64-bit values as volatile or synchronize their programs correctly to avoid possible complications. 目前各种平台下的商用虚拟机都选择把 64 位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不把long 和 double 变量专门声明为 volatile多数情况下也是不会错的。 volatile 的实现原理volatile 可见性实现 volatile 变量的内存可见性是基于内存屏障(Memory Barrier)实现: 内存屏障，又称内存栅栏，是一个 CPU 指令。 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止+ 特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和 CPU：不管什么指令都不能和这条 Memory Barrier 指令重排序。 写一段简单的 Java 代码，声明一个 volatile 变量，并赋值。 12345678910public class Test &#123; private volatile int a; public void update() &#123; a = 1; &#125; public static void main(String[] args) &#123; Test test = new Test(); test.update(); &#125;&#125; 通过 hsdis 和 jitwatch 工具可以得到编译后的汇编代码: 123456789101112131415161718...... 0x0000000002951563: and $0xffffffffffffff87,%rdi 0x0000000002951567: je 0x00000000029515f8 0x000000000295156d: test $0x7,%rdi 0x0000000002951574: jne 0x00000000029515bd 0x0000000002951576: test $0x300,%rdi 0x000000000295157d: jne 0x000000000295159c 0x000000000295157f: and $0x37f,%rax 0x0000000002951586: mov %rax,%rdi 0x0000000002951589: or %r15,%rdi 0x000000000295158c: lock cmpxchg %rdi,(%rdx) //在 volatile 修饰的共享变量进行写操作的时候会多出 lock 前缀的指令 0x0000000002951591: jne 0x0000000002951a15 0x0000000002951597: jmpq 0x00000000029515f8 0x000000000295159c: mov 0x8(%rdx),%edi 0x000000000295159f: shl $0x3,%rdi 0x00000000029515a3: mov 0xa8(%rdi),%rdi 0x00000000029515aa: or %r15,%rdi...... lock 前缀的指令在多核处理器下会引发两件事情: 将当前处理器缓存行的数据写回到系统内存。 写回内存的操作会使在其他 CPU 里缓存了该内存地址的数据无效。 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存(L1，L2 或其他)后再进行操作，但操作完不知道何时会写到内存。 如果对声明了 volatile 的变量进行写操作，JVM 就会向处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。 为了保证各个处理器的缓存是一致的，实现了缓存一致性协议(MESI)，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。 所有多核处理器下还会完成：当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值。 volatile 变量通过这样的机制就使得每个线程都能获得该变量的最新值。 lock 指令在 Pentium 和早期的 IA-32 处理器中，lock 前缀会使处理器执行当前指令时产生一个 LOCK# 信号，会对总线进行锁定，其它 CPU 对内存的读写请求都会被阻塞，直到锁释放。 后来的处理器，加锁操作是由高速缓存锁代替总线锁来处理。 因为锁总线的开销比较大，锁总线期间其他 CPU 没法访问内存。 这种场景多缓存的数据一致通过缓存一致性协议(MESI)来保证。 缓存一致性缓存是分段(line)的，一个段对应一块存储空间，称之为缓存行，它是 CPU 缓存中可分配的最小存储单元，大小 32 字节、64 字节、128 字节不等，这与 CPU 架构有关，通常来说是 64 字节。 LOCK# 因为锁总线效率太低，因此使用了多组缓存。 为了使其行为看起来如同一组缓存那样。因而设计了 缓存一致性协议。 缓存一致性协议有多种，但是日常处理的大多数计算机设备都属于 “ 嗅探(snooping)” 协议。 所有内存的传输都发生在一条共享的总线上，而所有的处理器都能看到这条总线。 缓存本身是独立的，但是内存是共享资源，所有的内存访问都要经过仲裁(同一个指令周期中，只有一个 CPU 缓存可以读写内存)。 CPU 缓存不仅仅在做内存传输的时候才与总线打交道，而是不停在嗅探总线上发生的数据交换，跟踪其他缓存在做什么。 当一个缓存代表它所属的处理器去读写内存时，其它处理器都会得到通知，它们以此来使自己的缓存保持同步。 只要某个处理器写内存，其它处理器马上知道这块内存在它们的缓存段中已经失效。 volatile 有序性实现volatile 的 happens-before 关系happens-before 规则中有一条是 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。 1234567891011121314151617//假设线程A执行writer方法，线程B执行reader方法class VolatileExample &#123; int a = 0; volatile boolean flag = false; public void writer() &#123; a = 1; // 1 线程A修改共享变量 flag = true; // 2 线程A写volatile变量 &#125; public void reader() &#123; if (flag) &#123; // 3 线程B读同一个volatile变量 int i = a; // 4 线程B读共享变量 …… &#125; &#125;&#125; 根据 happens-before 规则，上面过程会建立 3 类 happens-before 关系。 根据程序次序规则：1 happens-before 2 且 3 happens-before 4。 根据 volatile 规则：2 happens-before 3。 根据 happens-before 的传递性规则：1 happens-before 4。 因为以上规则，当线程 A 将 volatile 变量 flag 更改为 true 后，线程 B 能够迅速感知。 volatile 禁止重排序为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。 Java 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。 JMM 会针对编译器制定 volatile 重排序规则表。 “ NO “ 表示禁止重排序。 为了实现 volatile 内存语义时，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎是不可能的，为此，JMM 采取了保守的策略。 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。 volatile 写是在前面和后面分别插入内存屏障，而 volatile 读操作是在后面插入两个内存屏障。 内存屏障 说明 StoreStore 屏障 禁止上面的普通写和下面的 volatile 写重排序。 StoreLoad 屏障 防止上面的 volatile 写与下面可能有的 volatile 读&#x2F;写重排序。 LoadLoad 屏障 禁止下面所有的普通读操作和上面的 volatile 读重排序。 LoadStore 屏障 禁止下面所有的普通写操作和上面的 volatile 读重排序。 volatile 的应用场景使用 volatile 必须具备的条件 对变量的写操作不依赖于当前值。 该变量没有包含在具有其他变量的不变式中。 只有在状态真正独立于程序内其他内容时才能使用 volatile。 模式1：状态标志也许实现 volatile 变量的规范使用仅仅是使用一个布尔状态标志，用于指示发生了一个重要的一次性事件，例如完成初始化或请求停机。 12345678volatile boolean shutdownRequested;......public void shutdown() &#123; shutdownRequested = true; &#125;public void doWork() &#123; while (!shutdownRequested) &#123; // do stuff &#125;&#125; 模式2：一次性安全发布(one-time safe publication)缺乏同步会导致无法实现可见性，这使得确定何时写入对象引用而不是原始值变得更加困难。在缺乏同步的情况下，可能会遇到某个对象引用的更新值(由另一个线程写入)和该对象状态的旧值同时存在。(这就是造成著名的双重检查锁定(double-checked-locking)问题的根源，其中对象引用在没有同步的情况下进行读操作，产生的问题是您可能会看到一个更新的引用，但是仍然会通过该引用看到不完全构造的对象)。 12345678910111213141516171819public class BackgroundFloobleLoader &#123; public volatile Flooble theFlooble; public void initInBackground() &#123; // do lots of stuff theFlooble = new Flooble(); // this is the only write to theFlooble &#125;&#125; public class SomeOtherClass &#123; public void doWork() &#123; while (true) &#123; // do some stuff... // use the Flooble, but only if it is ready if (floobleLoader.theFlooble != null) doSomething(floobleLoader.theFlooble); &#125; &#125;&#125; 模式3：独立观察(independent observation)安全使用 volatile 的另一种简单模式是定期 发布 观察结果供程序内部使用。例如，假设有一种环境传感器能够感觉环境温度。一个后台线程可能会每隔几秒读取一次该传感器，并更新包含当前文档的 volatile 变量。然后，其他线程可以读取这个变量，从而随时能够看到最新的温度值。 12345678910111213public class UserManager &#123; public volatile String lastUser; public boolean authenticate(String user, String password) &#123; boolean valid = passwordIsValid(user, password); if (valid) &#123; User u = new User(); activeUsers.add(u); lastUser = user; &#125; return valid; &#125;&#125; 模式4：volatile bean 模式在 volatile bean 模式中，JavaBean 的所有数据成员都是 volatile 类型的，并且 getter 和 setter 方法必须非常普通 —— 除了获取或设置相应的属性外，不能包含任何逻辑。此外，对于对象引用的数据成员，引用的对象必须是有效不可变的。(这将禁止具有数组值的属性，因为当数组引用被声明为 volatile 时，只有引用而不是数组本身具有 volatile 语义)。对于任何 volatile 变量，不变式或约束都不能包含 JavaBean 属性。 12345678910111213141516171819202122@ThreadSafepublic class Person &#123; private volatile String firstName; private volatile String lastName; private volatile int age; public String getFirstName() &#123; return firstName; &#125; public String getLastName() &#123; return lastName; &#125; public int getAge() &#123; return age; &#125; public void setFirstName(String firstName) &#123; this.firstName = firstName; &#125; public void setLastName(String lastName) &#123; this.lastName = lastName; &#125; public void setAge(int age) &#123; this.age = age; &#125;&#125; 模式5：开销较低的读－写锁策略volatile 的功能还不足以实现计数器。因为 ++x 实际上是三种操作(读、添加、存储)的简单组合，如果多个线程凑巧试图同时对 volatile 计数器执行增量操作，那么它的更新值有可能会丢失。 如果读操作远远超过写操作，可以结合使用内部锁和 volatile 变量来减少公共代码路径的开销。 安全的计数器使用 synchronized 确保增量操作是原子的，并使用 volatile 保证当前结果的可见性。如果更新不频繁的话，该方法可实现更好的性能，因为读路径的开销仅仅涉及 volatile 读操作，这通常要优于一个无竞争的锁获取的开销。 123456789101112@ThreadSafepublic class CheesyCounter &#123; // Employs the cheap read-write lock trick // All mutative operations MUST be done with the &#x27;this&#x27; lock held @GuardedBy(&quot;this&quot;) private volatile int value; public int getValue() &#123; return value; &#125; public synchronized int increment() &#123; return value++; &#125;&#125; 模式6：双重检查(double-checked)就是我们上文举的例子。 单例模式的一种实现方式，但很多人会忽略 volatile 关键字，因为没有该关键字，程序也可以很好的运行，只不过代码的稳定性总不是 100%，说不定在未来的某个时刻，隐藏的 bug 就出来了。 123456789101112131415class Singleton &#123; private volatile static Singleton instance; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (instance == null) &#123; syschronized(Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125; &#125; 参考文章 https://blog.csdn.net/devotion987/article/details/68486942 https://www.jianshu.com/p/ccfe24b63d87","tags":["Java","多线程与并发"],"categories":["Java","多线程与并发"]},{"title":"5.关键字: synchronized详解","path":"/2023/12/25/5-关键字-synchronized详解/","content":"在C程序代码中我们可以利用操作系统提供的互斥锁来实现同步块的互斥访问及线程的阻塞及唤醒等工作。在Java中除了提供Lock API外还在语法层面上提供了synchronized关键字来实现互斥同步原语, 本文将对synchronized关键字详细分析。 带着BAT大厂的面试问题去理解Synchronized 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解synchronized。 Synchronized可以作用在哪里? 分别通过对象锁和类锁进行举例。 Synchronized本质上是通过什么保证线程安全的? 分三个方面回答：加锁和释放锁的原理，可重入原理，保证可见性原理。 Synchronized由什么样的缺陷? Java Lock是怎么弥补这些缺陷的。 Synchronized和Lock的对比，和选择? Synchronized在使用时有何注意事项? Synchronized修饰的方法在抛出异常时,会释放锁吗? 多个线程等待同一个Synchronized锁的时候，JVM如何选择下一个获取锁的线程? Synchronized使得同时只有一个线程可以执行，性能比较差，有什么提升的方法? 我想更加灵活的控制锁的释放和获取(现在释放锁和获取锁的时机都被规定死了)，怎么办? 什么是锁的升级和降级? 什么是JVM里的偏斜锁、轻量级锁、重量级锁? 不同的JDK中对Synchronized有何优化? Synchronized的使用在应用Sychronized关键字时需要把握如下注意点： 一把锁只能同时被一个线程获取，没有获得锁的线程只能等待； 每个实例都对应有自己的一把锁(this),不同实例之间互不影响；例外：锁对象是*.class以及synchronized修饰的是static方法的时候，所有对象公用同一把锁 synchronized修饰的方法，无论方法正常执行完毕还是抛出异常，都会释放锁 对象锁包括方法锁(默认锁对象为this,当前实例对象)和同步代码块锁(自己指定锁对象) 代码块形式：手动指定锁定对象，也可是是this,也可以是自定义的锁 示例1 123456789101112131415161718192021222324public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instance = new SynchronizedObjectLock(); @Override public void run() &#123; // 同步代码块形式——锁为this,两个线程使用的锁是一样的,线程1必须要等到线程0释放了该锁后，才能执行 synchronized (this) &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instance); Thread t2 = new Thread(instance); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 示例2 12345678910111213141516171819202122232425262728293031323334353637public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instance = new SynchronizedObjectLock(); // 创建2把锁 Object block1 = new Object(); Object block2 = new Object(); @Override public void run() &#123; // 这个代码块使用的是第一把锁，当他释放后，后面的代码块由于使用的是第二把锁，因此可以马上执行 synchronized (block1) &#123; System.out.println(&quot;block1锁,我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;block1锁,&quot;+Thread.currentThread().getName() + &quot;结束&quot;); &#125; synchronized (block2) &#123; System.out.println(&quot;block2锁,我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;block2锁,&quot;+Thread.currentThread().getName() + &quot;结束&quot;); &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instance); Thread t2 = new Thread(instance); t1.start(); t2.start(); &#125;&#125; 输出结果： 12345678block1锁,我是线程Thread-0block1锁,Thread-0结束block2锁,我是线程Thread-0 // 可以看到当第一个线程在执行完第一段同步代码块之后，第二个同步代码块可以马上得到执行，因为他们使用的锁不是同一把block1锁,我是线程Thread-1block2锁,Thread-0结束block1锁,Thread-1结束block2锁,我是线程Thread-1block2锁,Thread-1结束 方法锁形式：synchronized修饰普通方法，锁对象默认为this12345678910111213141516171819202122232425public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instance = new SynchronizedObjectLock(); @Override public void run() &#123; method(); &#125; public synchronized void method() &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instance); Thread t2 = new Thread(instance); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 类锁指synchronize修饰静态的方法或指定锁对象为Class对象 synchronize修饰静态方法 示例1 12345678910111213141516171819202122232425262728public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instance1 = new SynchronizedObjectLock(); static SynchronizedObjectLock instance2 = new SynchronizedObjectLock(); @Override public void run() &#123; method(); &#125; // synchronized用在普通方法上，默认的锁就是this，当前实例 public synchronized void method() &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; public static void main(String[] args) &#123; // t1和t2对应的this是两个不同的实例，所以代码不会串行 Thread t1 = new Thread(instance1); Thread t2 = new Thread(instance2); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0我是线程Thread-1Thread-1结束Thread-0结束 示例2 123456789101112131415161718192021222324252627public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instance1 = new SynchronizedObjectLock(); static SynchronizedObjectLock instance2 = new SynchronizedObjectLock(); @Override public void run() &#123; method(); &#125; // synchronized用在静态方法上，默认的锁就是当前所在的Class类，所以无论是哪个线程访问它，需要的锁都只有一把 public static synchronized void method() &#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instance1); Thread t2 = new Thread(instance2); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 synchronized指定锁对象为Class对象12345678910111213141516171819202122232425public class SynchronizedObjectLock implements Runnable &#123; static SynchronizedObjectLock instance1 = new SynchronizedObjectLock(); static SynchronizedObjectLock instance2 = new SynchronizedObjectLock(); @Override public void run() &#123; // 所有线程需要的锁都是同一把 synchronized(SynchronizedObjectLock.class)&#123; System.out.println(&quot;我是线程&quot; + Thread.currentThread().getName()); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + &quot;结束&quot;); &#125; &#125; public static void main(String[] args) &#123; Thread t1 = new Thread(instance1); Thread t2 = new Thread(instance2); t1.start(); t2.start(); &#125;&#125; 输出结果： 1234我是线程Thread-0Thread-0结束我是线程Thread-1Thread-1结束 Synchronized原理分析加锁和释放锁的原理 现象、时机(内置锁this)、深入JVM看字节码(反编译看monitor指令) 深入JVM看字节码，创建如下的代码： 1234567891011121314public class SynchronizedDemo2 &#123; Object object = new Object(); public void method1() &#123; synchronized (object) &#123; &#125; method2(); &#125; private static void method2() &#123; &#125;&#125; 使用javac命令进行编译生成.class文件 1&gt;javac SynchronizedDemo2.java 使用javap命令反编译查看.class文件的信息 1&gt;javap -verbose SynchronizedDemo2.class 得到如下的信息： 关注红色方框里的monitorenter和monitorexit即可。 Monitorenter和Monitorexit指令，会让对象在执行，使其锁计数器加1或者减1。每一个对象在同一时间只与一个monitor(锁)相关联，而一个monitor在同一时间只能被一个线程获得，一个对象在尝试获得与这个对象相关联的Monitor锁的所有权的时候，monitorenter指令会发生如下3中情况之一： monitor计数器为0，意味着目前还没有被获得，那这个线程就会立刻获得然后把锁计数器+1，一旦+1，别的线程再想获取，就需要等待 如果这个monitor已经拿到了这个锁的所有权，又重入了这把锁，那锁计数器就会累加，变成2，并且随着重入的次数，会一直累加 这把锁已经被别的线程获取了，等待锁释放 monitorexit指令：释放对于monitor的所有权，释放过程很简单，就是讲monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。 下图表现了对象，对象监视器，同步队列以及执行线程状态之间的关系： 该图可以看出，任意线程对Object的访问，首先要获得Object的监视器，如果获取失败，该线程就进入同步状态，线程状态变为BLOCKED，当Object的监视器占有者释放后，在同步队列中得线程就会有机会重新获取该监视器。 可重入原理：加锁次数计数器 什么是可重入？可重入锁？ 可重入：（来源于维基百科）若一个程序或子程序可以“在任意时刻被中断然后操作系统调度执行另外一段代码，这段代码又调用了该子程序不会出错”，则称其为可重入（reentrant或re-entrant）的。即当该子程序正在运行时，执行线程可以再次进入并执行它，仍然获得符合设计时预期的结果。与多线程并发执行的线程安全不同，可重入强调对单个线程执行时重新进入同一个子程序仍然是安全的。 可重入锁：又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。 看如下的例子 123456789101112131415161718192021public class SynchronizedDemo &#123; public static void main(String[] args) &#123; SynchronizedDemo demo = new SynchronizedDemo(); demo.method1(); &#125; private synchronized void method1() &#123; System.out.println(Thread.currentThread().getId() + &quot;: method1()&quot;); method2(); &#125; private synchronized void method2() &#123; System.out.println(Thread.currentThread().getId()+ &quot;: method2()&quot;); method3(); &#125; private synchronized void method3() &#123; System.out.println(Thread.currentThread().getId()+ &quot;: method3()&quot;); &#125;&#125; 结合前文中加锁和释放锁的原理，不难理解： 执行monitorenter获取锁 （monitor计数器&#x3D;0，可获取锁） 执行method1()方法，monitor计数器+1 -&gt; 1 （获取到锁） 执行method2()方法，monitor计数器+1 -&gt; 2 执行method3()方法，monitor计数器+1 -&gt; 3 执行monitorexit命令 method3()方法执行完，monitor计数器-1 -&gt; 2 method2()方法执行完，monitor计数器-1 -&gt; 1 method2()方法执行完，monitor计数器-1 -&gt; 0 （释放了锁） （monitor计数器&#x3D;0，锁被释放了） 这就是Synchronized的重入性，即在同一锁程中，每个对象拥有一个monitor计数器，当线程获取该对象锁后，monitor计数器就会加一，释放锁后就会将monitor计数器减一，线程不需要再次获取同一把锁。 保证可见性的原理：内存模型和happens-before规则Synchronized的happens-before规则，即监视器锁规则：对同一个监视器的解锁，happens-before于对该监视器的加锁。继续来看代码： 1234567891011public class MonitorDemo &#123; private int a = 0; public synchronized void writer() &#123; // 1 a++; // 2 &#125; // 3 public synchronized void reader() &#123; // 4 int i = a; // 5 &#125; // 6&#125; 该代码的happens-before关系如图所示： 在图中每一个箭头连接的两个节点就代表之间的happens-before关系，黑色的是通过程序顺序规则推导出来，红色的为监视器锁规则推导而出：线程A释放锁happens-before线程B加锁，蓝色的则是通过程序顺序规则和监视器锁规则推测出来happens-befor关系，通过传递性规则进一步推导的happens-before关系。现在我们来重点关注2 happens-before 5，通过这个关系我们可以得出什么? 根据happens-before的定义中的一条:如果A happens-before B，则A的执行结果对B可见，并且A的执行顺序先于B。线程A先对共享变量A进行加一，由2 happens-before 5关系可知线程A的执行结果对线程B可见即线程B所读取到的a的值为1。 JVM中锁的优化简单来说在JVM中monitorenter和monitorexit字节码依赖于底层的操作系统的Mutex Lock来实现的，但是由于使用Mutex Lock需要将当前线程挂起并从用户态切换到内核态来执行，这种切换的代价是非常昂贵的；然而在现实中的大部分情况下，同步方法是运行在单线程环境(无锁竞争环境)如果每次都调用Mutex Lock那么将严重的影响程序的性能。不过在jdk1.6中对锁的实现引入了大量的优化，如锁粗化(Lock Coarsening)、锁消除(Lock Elimination)、轻量级锁(Lightweight Locking)、偏向锁(Biased Locking)、适应性自旋(Adaptive Spinning)等技术来减少锁操作的开销。 锁粗化(Lock Coarsening)：也就是减少不必要的紧连在一起的unlock，lock操作，将多个连续的锁扩展成一个范围更大的锁。 锁消除(Lock Elimination)：通过运行时JIT编译器的逃逸分析来消除一些没有在当前同步块以外被其他线程共享的数据的锁保护，通过逃逸分析也可以在线程本的Stack上进行对象空间的分配(同时还可以减少Heap上的垃圾收集开销)。 轻量级锁(Lightweight Locking)：这种锁实现的背后基于这样一种假设，即在真实的情况下我们程序中的大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，取而代之的是在monitorenter和monitorexit中只需要依靠一条CAS原子指令就可以完成锁的获取及释放。当存在锁竞争的情况下，执行CAS指令失败的线程将调用操作系统互斥锁进入到阻塞状态，当锁被释放的时候被唤醒(具体处理步骤下面详细讨论)。 偏向锁(Biased Locking)：是为了在无锁竞争的情况下避免在锁获取过程中执行不必要的CAS原子指令，因为CAS原子指令虽然相对于重量级锁来说开销比较小但还是存在非常可观的本地延迟。 适应性自旋(Adaptive Spinning)：当线程在获取轻量级锁的过程中执行CAS操作失败时，在进入与monitor相关联的操作系统重量级锁(mutex semaphore)前会进入忙等待(Spinning)然后再次尝试，当尝试一定的次数后如果仍然没有成功则调用与该monitor关联的semaphore(即互斥锁)进入到阻塞状态。 下面来详细讲解下，先从Synchronied同步锁开始讲起： 锁的类型在Java SE 1.6里Synchronied同步锁，一共有四种状态：无锁、偏向锁、轻量级锁、重量级锁，它会随着竞争情况逐渐升级。锁可以升级但是不可以降级，目的是为了提供获取锁和释放锁的效率。 锁膨胀方向： 无锁 → 偏向锁 → 轻量级锁 → 重量级锁 (此过程是不可逆的) 自旋锁与自适应自旋锁自旋锁 引入背景：大家都知道，在没有加入锁优化时，Synchronized是一个非常“胖大”的家伙。在多线程竞争锁时，当一个线程获取锁时，它会阻塞所有正在竞争的线程，这样对性能带来了极大的影响。在挂起线程和恢复线程的操作都需要转入内核态中完成，这些操作对系统的并发性能带来了很大的压力。同时HotSpot团队注意到在很多情况下，共享数据的锁定状态只会持续很短的一段时间，为了这段时间去挂起和回复阻塞线程并不值得。在如今多处理器环境下，完全可以让另一个没有获取到锁的线程在门外等待一会(自旋)，但不放弃CPU的执行时间。等待持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环(自旋)，这便是自旋锁由来的原因。 自旋锁早在JDK1.4 中就引入了，只是当时默认时关闭的。在JDK 1.6后默认为开启状态。自旋锁本质上与阻塞并不相同，先不考虑其对多处理器的要求，如果锁占用的时间非常的短，那么自旋锁的性能会非常的好，相反，其会带来更多的性能开销(因为在线程自旋时，始终会占用CPU的时间片，如果锁占用的时间太长，那么自旋的线程会白白消耗掉CPU资源)。因此自旋等待的时间必须要有一定的限度，如果自旋超过了限定的次数仍然没有成功获取到锁，就应该使用传统的方式去挂起线程了，在JDK定义中，自旋锁默认的自旋次数为10次，用户可以使用参数-XX:PreBlockSpin来更改。 可是现在又出现了一个问题：如果线程锁在线程自旋刚结束就释放掉了锁，那么是不是有点得不偿失。所以这时候我们需要更加聪明的锁来实现更加灵活的自旋。来提高并发的性能。(这里则需要自适应自旋锁！) 自适应自旋锁 在JDK 1.6中引入了自适应自旋锁。这就意味着自旋的时间不再固定了，而是由前一次在同一个锁上的自旋 时间及锁的拥有者的状态来决定的。如果在同一个锁对象上，自旋等待刚刚成功获取过锁，并且持有锁的线程正在运行中，那么JVM会认为该锁自旋获取到锁的可能性很大，会自动增加等待时间。比如增加到100此循环。相反，如果对于某个锁，自旋很少成功获取锁。那再以后要获取这个锁时将可能省略掉自旋过程，以避免浪费处理器资源。有了自适应自旋，JVM对程序的锁的状态预测会越来越准确，JVM也会越来越聪明。 锁消除锁消除是指虚拟机即时编译器再运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判定依据来源于逃逸分析的数据支持。意思就是：JVM会判断再一段程序中的同步明显不会逃逸出去从而被其他线程访问到，那JVM就把它们当作栈上数据对待，认为这些数据是线程独有的，不需要加同步。此时就会进行锁消除。 当然在实际开发中，我们很清楚的知道哪些是线程独有的，不需要加同步锁，但是在Java API中有很多方法都是加了同步的，那么此时JVM会判断这段代码是否需要加锁。如果数据并不会逃逸，则会进行锁消除。比如如下操作：在操作String类型数据时，由于String是一个不可变类，对字符串的连接操作总是通过生成的新的String对象来进行的。因此Javac编译器会对String连接做自动优化。在JDK 1.5之前会使用StringBuffer对象的连续append()操作，在JDK 1.5及以后的版本中，会转化为StringBuidler对象的连续append()操作。 1234public static String test03(String s1, String s2, String s3) &#123; String s = s1 + s2 + s3; return s;&#125; 上述代码使用javap 编译结果 众所周知，StringBuilder不是安全同步的，但是在上述代码中，JVM判断该段代码并不会逃逸，则将该代码带默认为线程独有的资源，并不需要同步，所以执行了锁消除操作。(还有Vector中的各种操作也可实现锁消除。在没有逃逸出数据安全防卫内) 锁粗化原则上，我们都知道在加同步锁时，尽可能的将同步块的作用范围限制到尽量小的范围(只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小。在存在锁同步竞争中，也可以使得等待锁的线程尽早的拿到锁)。 大部分上述情况是完美正确的，但是如果存在连串的一系列操作都对同一个对象反复加锁和解锁，甚至加锁操作时出现在循环体中的，那即使没有线程竞争，频繁的进行互斥同步操作也会导致不必要的性能操作。 这里贴上根据上述Javap 编译的情况编写的实例java类 1234567public static String test04(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 在上述的连续append()操作中就属于这类情况。JVM会检测到这样一连串的操作都是对同一个对象加锁，那么JVM会将加锁同步的范围扩展(粗化)到整个一系列操作的 外部，使整个一连串的append()操作只需要加锁一次就可以了。 轻量级锁在JDK 1.6之后引入的轻量级锁，需要注意的是轻量级锁并不是替代重量级锁的，而是对在大多数情况下同步块并不会有竞争出现提出的一种优化。它可以减少重量级锁对线程的阻塞带来的线程开销。从而提高并发性能。 如果要理解轻量级锁，那么必须先要了解HotSpot虚拟机中对象头的内存布局。上面介绍Java对象头也详细介绍过。在对象头中(Object Header)存在两部分。第一部分用于存储对象自身的运行时数据，HashCode、GC Age、锁标记位、是否为偏向锁。等。一般为32位或者64位(视操作系统位数定)。官方称之为Mark Word，它是实现轻量级锁和偏向锁的关键。 另外一部分存储的是指向方法区对象类型数据的指针(Klass Point)，如果对象是数组的话，还会有一个额外的部分用于存储数据的长度。 轻量级锁加锁在线程执行同步块之前，JVM会先在当前线程的栈帧中创建一个名为锁记录(Lock Record)的空间，用于存储锁对象目前的Mark Word的拷贝(JVM会将对象头中的Mark Word拷贝到锁记录中，官方称为Displaced Mark Ward)这个时候线程堆栈与对象头的状态如图： 如上图所示：如果当前对象没有被锁定，那么锁标志位为01状态，JVM在执行当前线程时，首先会在当前线程栈帧中创建锁记录Lock Record的空间用于存储锁对象目前的Mark Word的拷贝。 然后，虚拟机使用CAS操作将标记字段Mark Word拷贝到锁记录中，并且将Mark Word更新为指向Lock Record的指针。如果更新成功了，那么这个线程就拥用了该对象的锁，并且对象Mark Word的锁标志位更新为(Mark Word中最后的2bit)00，即表示此对象处于轻量级锁定状态，如图： 如果这个更新操作失败，JVM会检查当前的Mark Word中是否存在指向当前线程的栈帧的指针，如果有，说明该锁已经被获取，可以直接调用。如果没有，则说明该锁被其他线程抢占了，如果有两条以上的线程竞争同一个锁，那轻量级锁就不再有效，直接膨胀为重量级锁，没有获得锁的线程会被阻塞。此时，锁的标志位为10.Mark Word中存储的指向重量级锁的指针。 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头中，如果成功，则表示没有发生竞争关系。如果失败，表示当前锁存在竞争关系。锁就会膨胀成重量级锁。两个线程同时争夺锁，导致锁膨胀的流程图如下： 偏向锁 引入背景：在大多实际环境下，锁不仅不存在多线程竞争，而且总是由同一个线程多次获取，那么在同一个线程反复获取所释放锁中，其中并还没有锁的竞争，那么这样看上去，多次的获取锁和释放锁带来了很多不必要的性能开销和上下文切换。 为了解决这一问题，HotSpot的作者在Java SE 1.6 中对Synchronized进行了优化，引入了偏向锁。当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁。只需要简单的测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果成功，表示线程已经获取到了锁。 偏向锁的撤销 偏向锁使用了一种等待竞争出现才会释放锁的机制。所以当其他线程尝试获取偏向锁时，持有偏向锁的线程才会释放锁。但是偏向锁的撤销需要等到全局安全点(就是当前线程没有正在执行的字节码)。它会首先暂停拥有偏向锁的线程，让你后检查持有偏向锁的线程是否活着。如果线程不处于活动状态，直接将对象头设置为无锁状态。如果线程活着，JVM会遍历栈帧中的锁记录，栈帧中的锁记录和对象头要么偏向于其他线程，要么恢复到无锁状态或者标记对象不适合作为偏向锁。 锁的优缺点对比 锁 优点 缺点 使用场景 偏向锁 加锁和解锁不需要CAS操作，没有额外的性能消耗，和执行非同步方法相比仅存在纳秒级的差距 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步块的场景 轻量级锁 竞争的线程不会阻塞，提高了响应速度 如线程始终得不到锁竞争的线程，使用自旋会消耗CPU性能 追求响应时间，同步块执行速度非常快 重量级锁 线程竞争不适用自旋，不会消耗CPU 线程阻塞，响应时间缓慢，在多线程下，频繁的获取释放锁，会带来巨大的性能消耗 追求吞吐量，同步块执行速度较长 Synchronized与Locksynchronized的缺陷 效率低：锁的释放情况少，只有代码执行完毕或者异常结束才会释放锁；试图获取锁的时候不能设定超时，不能中断一个正在使用锁的线程，相对而言，Lock可以中断和设置超时 不够灵活：加锁和释放的时机单一，每个锁仅有一个单一的条件(某个对象)，相对而言，读写锁更加灵活 无法知道是否成功获得锁，相对而言，Lock可以拿到状态，如果成功获取锁，….，如果获取失败，….. Lock解决相应问题Lock类这里不做过多解释，主要看里面的4个方法: lock(): 加锁 unlock(): 解锁 tryLock(): 尝试获取锁，返回一个boolean值 tryLock(long,TimeUtil): 尝试获取锁，可以设置超时 Synchronized加锁只与一个条件(是否获取锁)相关联，不灵活，后来Condition与Lock的结合解决了这个问题。 多线程竞争一个锁时，其余未得到锁的线程只能不停的尝试获得锁，而不能中断。高并发的情况下会导致性能下降。ReentrantLock的lockInterruptibly()方法可以优先考虑响应中断。 一个线程等待时间过长，它可以中断自己，然后ReentrantLock响应这个中断，不再让这个线程继续等待。有了这个机制，使用ReentrantLock时就不会像synchronized那样产生死锁了。 ReentrantLock为常用类，它是一个可重入的互斥锁 Lock，它具有与使用 synchronized 方法和语句所访问的隐式监视器锁相同的一些基本行为和语义，但功能更强大。详细分析请看: JUC锁: ReentrantLock详解 再深入理解synchronized是通过软件(JVM)实现的，简单易用，即使在JDK5之后有了Lock，仍然被广泛的使用。 使用Synchronized有哪些要注意的？ 锁对象不能为空，因为锁的信息都保存在对象头里 作用域不宜过大，影响程序执行的速度，控制范围过大，编写代码也容易出错 避免死锁 在能选择的情况下，既不要用Lock也不要用synchronized关键字，用java.util.concurrent包中的各种各样的类，如果不用该包下的类，在满足业务的情况下，可以使用synchronized关键，因为代码量少，避免出错 synchronized是公平锁吗？ synchronized实际上是非公平的，新来的线程有可能立即获得监视器，而在等待区中等候已久的线程可能再次等待，这样有利于提高性能，但是也可能会导致饥饿现象。 参考文章+《深入理解Java虚拟机》 +《Java并发编程的艺术》 https://juejin.im/post/5ae6dc04f265da0ba351d3ff https://www.cnblogs.com/javaminer/p/3889023.html https://www.jianshu.com/p/dab7745c0954 https://www.cnblogs.com/wuchaodzxx/p/6867546.html https://www.cnblogs.com/xyabk/p/10901291.html https://www.jianshu.com/p/64240319ed60","tags":["Java","多线程与并发"],"categories":["Java","多线程与并发"]},{"title":"4.Java并发 - Java中所有的锁","path":"/2023/12/25/4-Java并发-Java中所有的锁/","content":"Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 前言Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8和Netty 3.10.6）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 Java中往往是按照是否含有某一特性来定义锁，我们通过特性将锁进行分组归类，再使用对比的方式进行介绍，帮助大家更快捷的理解相关知识。下面给出本文内容的总体分类目录： 1. 乐观锁 VS 悲观锁 乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。 先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。 而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。 乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。 根据从上面的概念描述我们可以发现： 悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。 乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。 光说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例： 12345678910111213141516// ------------------------- 悲观锁的调用方式 -------------------------// synchronizedpublic synchronized void testMethod() &#123;\t// 操作同步资源&#125;// ReentrantLockprivate ReentrantLock lock = new ReentrantLock(); // 需要保证多个线程使用的是同一个锁public void modifyPublicResources() &#123;\tlock.lock();\t// 操作同步资源\tlock.unlock();&#125;// ------------------------- 乐观锁的调用方式 -------------------------private AtomicInteger atomicInteger = new AtomicInteger(); // 需要保证多个线程使用的是同一个AtomicIntegeratomicInteger.incrementAndGet(); //执行自增1 通过调用方式示例，我们可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。那么，为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？具体可以参看 JUC原子类: CAS, Unsafe和原子类详解。 2. 自旋锁 VS 适应性自旋锁 在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。 阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。 在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。 而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。 自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBlockSpin来更改）没有成功获得锁，就应当挂起线程。 自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。 自旋锁相关可以看关键字 - synchronized详解 - 自旋锁与自适应自旋锁 3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁 这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。 总结而言： 偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。 相关可以看关键字 - synchronized详解 - 锁的类型 4. 公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。 非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。 直接用语言描述可能有点抽象，这里作者用从别处看到的一个例子来讲述一下公平锁和非公平锁。 如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。 但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示： 更多请参看JUC - ReentrantLock详解。 5. 可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析： 12345678910public class Widget &#123; public synchronized void doSomething() &#123; System.out.println(&quot;方法1执行...&quot;); doOthers(); &#125; public synchronized void doOthers() &#123; System.out.println(&quot;方法2执行...&quot;); &#125;&#125; 在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。 如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。 而为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？我们通过图示和源码来分别解析一下。 还是打水的例子，有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。 但如果是非可重入锁的话，此时管理员只允许锁和同一个人的一个水桶绑定。第一个水桶和锁绑定打完水之后并不会释放锁，导致第二个水桶不能和锁绑定也无法打水。当前线程出现死锁，整个等待队列中的所有线程都无法被唤醒。 之前我们说过ReentrantLock和synchronized都是重入锁，那么我们通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。 首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。 当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status &#x3D;&#x3D; 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status !&#x3D; 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status !&#x3D; 0的话会导致其获取锁失败，当前线程阻塞。 释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 &#x3D;&#x3D; 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。 更多请参看： JUC锁: LockSupport详解 JUC锁: AbstractQueuedSynchronizer详解 JUC锁 - ReentrantLock详解 关键字 - synchronized详解 6. 独享锁(排他锁) VS 共享锁 独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。 独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。 共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。 独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。 下图为ReentrantReadWriteLock的部分源码： 我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。 在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。 更多请参看 JUC锁: ReentrantReadWriteLock详解 结语本文Java中常用的锁以及常见的锁的概念进行了基本介绍，并从源码以及实际应用的角度进行了对比分析。限于篇幅以及个人水平，没有在本篇文章中对所有内容进行深层次的讲解。 其实Java本身已经对锁本身进行了良好的封装，降低了研发同学在平时工作中的使用难度。但是研发同学也需要熟悉锁的底层原理，不同场景下选择最适合的锁。而且源码中的思路都是非常好的思路，也是值得大家去学习和借鉴的。 参考资料 《Java并发编程艺术》 Java中的锁 Java CAS 原理剖析 Java并发——关键字synchronized解析 Java synchronized原理总结 聊聊并发（二）——Java SE1.6中的Synchronized 深入理解读写锁—ReadWriteLock源码分析 【JUC】JDK1.8源码分析之ReentrantReadWriteLock Java多线程（十）之ReentrantReadWriteLock深入分析 Java–读写锁的实现原理 作者简介家琪，美团点评后端工程师。2017 年加入美团点评，负责美团点评境内度假的业务开发。 文章来源本文主要在美团技术团队家琪的文章基础上进行调整，以满足整体的知识体系。","tags":["Java","多线程与并发"],"categories":["Java","多线程与并发"]},{"title":"3.Java 并发 - 线程基础","path":"/2023/12/25/3-Java-并发-线程基础/","content":"本文主要概要性的介绍线程的基础，为后面的章节深入介绍Java并发的知识提供基础。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解线程基础。 线程有哪几种状态? 分别说明从一种状态到另一种状态转变有哪些方式? 通常线程有哪几种使用方式? 基础线程机制有哪些? 线程的中断方式有哪些? 线程的互斥同步方式有哪些? 如何比较和选择? 线程之间有哪些协作方式? 线程状态转换 新建(New)创建后尚未启动。 可运行(Runnable)可能正在运行，也可能正在等待 CPU 时间片。 包含了操作系统线程状态中的 Running 和 Ready。 阻塞(Blocking)等待获取一个排它锁，如果其线程释放了锁就会结束此状态。 无限期等待(Waiting)等待其它线程显式地唤醒，否则不会被分配 CPU 时间片。 进入方法 退出方法 没有设置 Timeout 参数的 Object.wait() 方法 Object.notify() &#x2F; Object.notifyAll() 没有设置 Timeout 参数的 Thread.join() 方法 被调用的线程执行完毕 LockSupport.park() 方法 - 限期等待(Timed Waiting)无需等待其它线程显式地唤醒，在一定时间之后会被系统自动唤醒。 调用 Thread.sleep() 方法使线程进入限期等待状态时，常常用“使一个线程睡眠”进行描述。 调用 Object.wait() 方法使线程进入限期等待或者无限期等待时，常常用“挂起一个线程”进行描述。 睡眠和挂起是用来描述行为，而阻塞和等待用来描述状态。 阻塞和等待的区别在于，阻塞是被动的，它是在等待获取一个排它锁。而等待是主动的，通过调用 Thread.sleep() 和 Object.wait() 等方法进入。 进入方法 退出方法 Thread.sleep() 方法 时间结束 设置了 Timeout 参数的 Object.wait() 方法 时间结束 &#x2F; Object.notify() &#x2F; Object.notifyAll() 设置了 Timeout 参数的 Thread.join() 方法 时间结束 &#x2F; 被调用的线程执行完毕 LockSupport.parkNanos() 方法 - LockSupport.parkUntil() 方法 - 死亡(Terminated)可以是线程结束任务之后自己结束，或者产生了异常而结束。 线程使用方式有三种使用线程的方法: 实现 Runnable 接口； 实现 Callable 接口； 继承 Thread 类。 实现 Runnable 和 Callable 接口的类只能当做一个可以在线程中运行的任务，不是真正意义上的线程，因此最后还需要通过 Thread 来调用。可以说任务是通过线程驱动从而执行的。 实现 Runnable 接口需要实现 run() 方法。 通过 Thread 调用 start() 方法来启动线程。 12345public class MyRunnable implements Runnable &#123; public void run() &#123; // ... &#125;&#125; 12345public static void main(String[] args) &#123; MyRunnable instance = new MyRunnable(); Thread thread = new Thread(instance); thread.start();&#125; 实现 Callable 接口与 Runnable 相比，Callable 可以有返回值，返回值通过 FutureTask 进行封装。 12345public class MyCallable implements Callable&lt;Integer&gt; &#123; public Integer call() &#123; return 123; &#125;&#125; 1234567public static void main(String[] args) throws ExecutionException, InterruptedException &#123; MyCallable mc = new MyCallable(); FutureTask&lt;Integer&gt; ft = new FutureTask&lt;&gt;(mc); Thread thread = new Thread(ft); thread.start(); System.out.println(ft.get());&#125; 继承 Thread 类同样也是需要实现 run() 方法，因为 Thread 类也实现了 Runable 接口。 当调用 start() 方法启动一个线程时，虚拟机会将该线程放入就绪队列中等待被调度，当一个线程被调度时会执行该线程的 run() 方法。 12345public class MyThread extends Thread &#123; public void run() &#123; // ... &#125;&#125; 1234public static void main(String[] args) &#123; MyThread mt = new MyThread(); mt.start();&#125; 实现接口 VS 继承 Thread实现接口会更好一些，因为: Java 不支持多重继承，因此继承了 Thread 类就无法继承其它类，但是可以实现多个接口； 类可能只要求可执行就行，继承整个 Thread 类开销过大。 基础线程机制ExecutorExecutor 管理多个异步任务的执行，而无需程序员显式地管理线程的生命周期。这里的异步是指多个任务的执行互不干扰，不需要进行同步操作。 主要有三种 Executor: CachedThreadPool: 一个任务创建一个线程； FixedThreadPool: 所有任务只能使用固定大小的线程； SingleThreadExecutor: 相当于大小为 1 的 FixedThreadPool。 1234567public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 5; i++) &#123; executorService.execute(new MyRunnable()); &#125; executorService.shutdown();&#125; Daemon守护线程是程序运行时在后台提供服务的线程，不属于程序中不可或缺的部分。 当所有非守护线程结束时，程序也就终止，同时会杀死所有守护线程。 main() 属于非守护线程。 使用 setDaemon() 方法将一个线程设置为守护线程。 1234public static void main(String[] args) &#123; Thread thread = new Thread(new MyRunnable()); thread.setDaemon(true);&#125; sleep()Thread.sleep(millisec) 方法会休眠当前正在执行的线程，millisec 单位为毫秒。 sleep() 可能会抛出 InterruptedException，因为异常不能跨线程传播回 main() 中，因此必须在本地进行处理。线程中抛出的其它异常也同样需要在本地进行处理。 1234567public void run() &#123; try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;&#125; yield()对静态方法 Thread.yield() 的调用声明了当前线程已经完成了生命周期中最重要的部分，可以切换给其它线程来执行。该方法只是对线程调度器的一个建议，而且也只是建议具有相同优先级的其它线程可以运行。 123public void run() &#123; Thread.yield();&#125; 线程中断一个线程执行完毕之后会自动结束，如果在运行过程中发生异常也会提前结束。 InterruptedException通过调用一个线程的 interrupt() 来中断该线程，如果该线程处于阻塞、限期等待或者无限期等待状态，那么就会抛出 InterruptedException，从而提前结束该线程。但是不能中断 I&#x2F;O 阻塞和 synchronized 锁阻塞。 对于以下代码，在 main() 中启动一个线程之后再中断它，由于线程中调用了 Thread.sleep() 方法，因此会抛出一个 InterruptedException，从而提前结束线程，不执行之后的语句。 1234567891011121314public class InterruptExample &#123; private static class MyThread1 extends Thread &#123; @Override public void run() &#123; try &#123; Thread.sleep(2000); System.out.println(&quot;Thread run&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) throws InterruptedException &#123; Thread thread1 = new MyThread1(); thread1.start(); thread1.interrupt(); System.out.println(&quot;Main run&quot;);&#125; 123456Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at InterruptExample.lambda$main$0(InterruptExample.java:5) at InterruptExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) interrupted()如果一个线程的 run() 方法执行一个无限循环，并且没有执行 sleep() 等会抛出 InterruptedException 的操作，那么调用线程的 interrupt() 方法就无法使线程提前结束。 但是调用 interrupt() 方法会设置线程的中断标记，此时调用 interrupted() 方法会返回 true。因此可以在循环体中使用 interrupted() 方法来判断线程是否处于中断状态，从而提前结束线程。 123456789101112public class InterruptExample &#123; private static class MyThread2 extends Thread &#123; @Override public void run() &#123; while (!interrupted()) &#123; // .. &#125; System.out.println(&quot;Thread end&quot;); &#125; &#125;&#125; 12345public static void main(String[] args) throws InterruptedException &#123; Thread thread2 = new MyThread2(); thread2.start(); thread2.interrupt();&#125; 1Thread end Executor 的中断操作调用 Executor 的 shutdown() 方法会等待线程都执行完毕之后再关闭，但是如果调用的是 shutdownNow() 方法，则相当于调用每个线程的 interrupt() 方法。 以下使用 Lambda 创建线程，相当于创建了一个匿名内部线程。 12345678910111213public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; try &#123; Thread.sleep(2000); System.out.println(&quot;Thread run&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;); executorService.shutdownNow(); System.out.println(&quot;Main run&quot;);&#125; 12345678Main runjava.lang.InterruptedException: sleep interrupted at java.lang.Thread.sleep(Native Method) at ExecutorInterruptExample.lambda$main$0(ExecutorInterruptExample.java:9) at ExecutorInterruptExample$$Lambda$1/1160460865.run(Unknown Source) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745)\\ 如果只想中断 Executor 中的一个线程，可以通过使用 submit() 方法来提交一个线程，它会返回一个 Future&lt;?&gt; 对象，通过调用该对象的 cancel(true) 方法就可以中断线程。 1234Future&lt;?&gt; future = executorService.submit(() -&gt; &#123; // ..&#125;);future.cancel(true); 线程互斥同步Java 提供了两种锁机制来控制多个线程对共享资源的互斥访问，第一个是 JVM 实现的 synchronized，而另一个是 JDK 实现的 ReentrantLock。 synchronized1. 同步一个代码块 12345public void func() &#123; synchronized (this) &#123; // ... &#125;&#125; 它只作用于同一个对象，如果调用两个对象上的同步代码块，就不会进行同步。 对于以下代码，使用 ExecutorService 执行了两个线程，由于调用的是同一个对象的同步代码块，因此这两个线程会进行同步，当一个线程进入同步语句块时，另一个线程就必须等待。 12345678910public class SynchronizedExample &#123; public void func1() &#123; synchronized (this) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; &#125;&#125; 123456public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e1.func1());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 对于以下代码，两个线程调用了不同对象的同步代码块，因此这两个线程就不需要同步。从输出结果可以看出，两个线程交叉执行。 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func1()); executorService.execute(() -&gt; e2.func1());&#125; 10 0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 2. 同步一个方法 123public synchronized void func () &#123; // ...&#125; 它和同步代码块一样，作用于同一个对象。 3. 同步一个类 12345public void func() &#123; synchronized (SynchronizedExample.class) &#123; // ... &#125;&#125; 作用于整个类，也就是说两个线程调用同一个类的不同对象上的这种同步语句，也会进行同步。 12345678910public class SynchronizedExample &#123; public void func2() &#123; synchronized (SynchronizedExample.class) &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; &#125;&#125; 1234567public static void main(String[] args) &#123; SynchronizedExample e1 = new SynchronizedExample(); SynchronizedExample e2 = new SynchronizedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; e1.func2()); executorService.execute(() -&gt; e2.func2());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 4. 同步一个静态方法 123public synchronized static void fun() &#123; // ...&#125; 作用于整个类。 ReentrantLockReentrantLock 是 java.util.concurrent(J.U.C)包中的锁。 123456789101112131415public class LockExample &#123; private Lock lock = new ReentrantLock(); public void func() &#123; lock.lock(); try &#123; for (int i = 0; i &lt; 10; i++) &#123; System.out.print(i + &quot; &quot;); &#125; &#125; finally &#123; lock.unlock(); // 确保释放锁，从而避免发生死锁。 &#125; &#125;&#125; 123456public static void main(String[] args) &#123; LockExample lockExample = new LockExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; lockExample.func()); executorService.execute(() -&gt; lockExample.func());&#125; 10 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 比较1. 锁的实现 synchronized 是 JVM 实现的，而 ReentrantLock 是 JDK 实现的。 2. 性能 新版本 Java 对 synchronized 进行了很多优化，例如自旋锁等，synchronized 与 ReentrantLock 大致相同。 3. 等待可中断 当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情。 ReentrantLock 可中断，而 synchronized 不行。 4. 公平锁 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁。 synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但是也可以是公平的。 5. 锁绑定多个条件 一个 ReentrantLock 可以同时绑定多个 Condition 对象。 使用选择除非需要使用 ReentrantLock 的高级功能，否则优先使用 synchronized。这是因为 synchronized 是 JVM 实现的一种锁机制，JVM 原生地支持它，而 ReentrantLock 不是所有的 JDK 版本都支持。并且使用 synchronized 不用担心没有释放锁而导致死锁问题，因为 JVM 会确保锁的释放。 线程之间的协作当多个线程可以一起工作去解决某个问题时，如果某些部分必须在其它部分之前完成，那么就需要对线程进行协调。 join()在线程中调用另一个线程的 join() 方法，会将当前线程挂起，而不是忙等待，直到目标线程结束。 对于以下代码，虽然 b 线程先启动，但是因为在 b 线程中调用了 a 线程的 join() 方法，b 线程会等待 a 线程结束才继续执行，因此最后能够保证 a 线程的输出先于 b 线程的输出。 1234567891011121314151617181920212223242526272829303132333435public class JoinExample &#123; private class A extends Thread &#123; @Override public void run() &#123; System.out.println(&quot;A&quot;); &#125; &#125; private class B extends Thread &#123; private A a; B(A a) &#123; this.a = a; &#125; @Override public void run() &#123; try &#123; a.join(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;B&quot;); &#125; &#125; public void test() &#123; A a = new A(); B b = new B(a); b.start(); a.start(); &#125;&#125; 1234public static void main(String[] args) &#123; JoinExample example = new JoinExample(); example.test();&#125; 12AB wait() notify() notifyAll()调用 wait() 使得线程等待某个条件满足，线程在等待时会被挂起，当其他线程的运行使得这个条件满足时，其它线程会调用 notify() 或者 notifyAll() 来唤醒挂起的线程。 它们都属于 Object 的一部分，而不属于 Thread。 只能用在同步方法或者同步控制块中使用，否则会在运行时抛出 IllegalMonitorStateExeception。 使用 wait() 挂起期间，线程会释放锁。这是因为，如果没有释放锁，那么其它线程就无法进入对象的同步方法或者同步控制块中，那么就无法执行 notify() 或者 notifyAll() 来唤醒挂起的线程，造成死锁。 123456789101112131415public class WaitNotifyExample &#123; public synchronized void before() &#123; System.out.println(&quot;before&quot;); notifyAll(); &#125; public synchronized void after() &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(&quot;after&quot;); &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyExample example = new WaitNotifyExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter wait() 和 sleep() 的区别 wait() 是 Object 的方法，而 sleep() 是 Thread 的静态方法； wait() 会释放锁，sleep() 不会。 await() signal() signalAll()java.util.concurrent 类库中提供了 Condition 类来实现线程之间的协调，可以在 Condition 上调用 await() 方法使线程等待，其它线程调用 signal() 或 signalAll() 方法唤醒等待的线程。相比于 wait() 这种等待方式，await() 可以指定等待的条件，因此更加灵活。 使用 Lock 来获取一个 Condition 对象。 1234567891011121314151617181920212223242526public class AwaitSignalExample &#123; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); public void before() &#123; lock.lock(); try &#123; System.out.println(&quot;before&quot;); condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void after() &#123; lock.lock(); try &#123; condition.await(); System.out.println(&quot;after&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 123456public static void main(String[] args) &#123; ExecutorService executorService = Executors.newCachedThreadPool(); AwaitSignalExample example = new AwaitSignalExample(); executorService.execute(() -&gt; example.after()); executorService.execute(() -&gt; example.before());&#125; 12beforeafter","tags":["Java","多线程与并发"],"categories":["Java","多线程与并发"]},{"title":"2.Java 并发 - 理论基础","path":"/2023/12/25/2-Java-并发-理论基础/","content":"本文从理论的角度引入并发安全问题以及JMM应对并发问题的原理。 带着BAT大厂的面试问题去理解 提示 请带着这些问题继续后文，会很大程度上帮助你更好的理解并发理论基础。 多线程的出现是要解决什么问题的? 线程不安全是指什么? 举例说明 并发出现线程不安全的本质什么? 可见性，原子性和有序性。 Java是怎么解决并发问题的? 3个关键字，JMM和8个Happens-Before 线程安全是不是非真即假? 不是 线程安全有哪些实现思路? 如何理解并发和并行的区别? 为什么需要多线程众所周知，CPU、内存、I&#x2F;O 设备的速度是有极大差异的，为了合理利用 CPU 的高性能，平衡这三者的速度差异，计算机体系结构、操作系统、编译程序都做出了贡献，主要体现为: CPU 增加了缓存，以均衡与内存的速度差异；&#x2F;&#x2F; 导致 可见性问题 操作系统增加了进程、线程，以分时复用 CPU，进而均衡 CPU 与 I&#x2F;O 设备的速度差异；&#x2F;&#x2F; 导致 原子性问题 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。&#x2F;&#x2F; 导致 有序性问题 线程不安全示例如果多个线程对同一个共享数据进行访问而不采取同步操作的话，那么操作的结果是不一致的。 以下代码演示了 1000 个线程同时对 cnt 执行自增操作，操作结束之后它的值有可能小于 1000。 12345678910111213141516171819202122232425262728public class ThreadUnsafeExample &#123; private int cnt = 0; public void add() &#123; cnt++; &#125; public int get() &#123; return cnt; &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; final int threadSize = 1000; ThreadUnsafeExample example = new ThreadUnsafeExample(); final CountDownLatch countDownLatch = new CountDownLatch(threadSize); ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i &lt; threadSize; i++) &#123; executorService.execute(() -&gt; &#123; example.add(); countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println(example.get());&#125;997 // 结果总是小于1000 并发出现问题的根源: 并发三要素上述代码输出为什么不是1000? 并发出现问题的根源是什么? 可见性: CPU缓存引起可见性：一个线程对共享变量的修改，另外一个线程能够立刻看到。 举个简单的例子，看下面这段代码： 123456//线程1执行的代码int i = 0;i = 10; //线程2执行的代码j = i; 假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i &#x3D;10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。 此时线程2执行 j &#x3D; i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10. 这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。 原子性: 分时复用引起原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。 举个简单的例子，看下面这段代码： 1234567int i = 1;// 线程1执行i += 1;// 线程2执行i += 1; 这里需要注意的是：i += 1需要三条 CPU 指令 将变量 i 从内存读取到 CPU寄存器； 在CPU寄存器中执行 i + 1 操作； 将最后的结果i写入内存（缓存机制导致可能写入的是 CPU 缓存而不是内存）。 由于CPU分时复用（线程切换）的存在，线程1执行了第一条指令后，就切换到线程2执行，假如线程2执行了这三条指令后，再切换会线程1执行后续两条指令，将造成最后写到内存中的i值是2而不是3。 有序性: 重排序引起有序性：即程序执行的顺序按照代码的先后顺序执行。举个简单的例子，看下面这段代码： 1234int i = 0; boolean flag = false;i = 1; //语句1 flag = true; //语句2 上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗? 不一定，为什么呢? 这里可能会发生指令重排序（Instruction Reorder）。 在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型： 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序。由于处理器使用缓存和读 &#x2F; 写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序： 上述的 1 属于编译器重排序，2 和 3 属于处理器重排序。这些重排序都可能会导致多线程程序出现内存可见性问题。对于编译器，JMM 的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM 的处理器重排序规则会要求 java 编译器在生成指令序列时，插入特定类型的内存屏障（memory barriers，intel 称之为 memory fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。 具体可以参看：Java 内存模型详解的重排序章节。 JAVA是怎么解决并发问题的: JMM(Java内存模型)Java 内存模型是个很复杂的规范，强烈推荐你看后续（应该是网上能找到最好的材料之一了）：Java 内存模型详解。 理解的第一个维度：核心知识点 JMM本质上可以理解为，Java 内存模型规范了 JVM 如何提供按需禁用缓存和编译优化的方法。具体来说，这些方法包括： volatile、synchronized 和 final 三个关键字 Happens-Before 规则 理解的第二个维度：可见性，有序性，原子性 原子性 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。 请分析以下哪些操作是原子性操作： 1234x = 10; //语句1: 直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中y = x; //语句2: 包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。x++; //语句3： x++包括3个操作：读取x的值，进行加1操作，写入新的值。x = x + 1; //语句4： 同语句3 上面4个语句只有语句1的操作具备原子性。 也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。 从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 可见性 Java提供了volatile关键字来保证可见性。 当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。 而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。 另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 有序性 在Java里面，可以通过volatile关键字来保证一定的“有序性”（具体原理在下一节讲述）。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。当然JMM是通过Happens-Before 规则来保证有序性的。 关键字: volatile、synchronized 和 final以下三篇文章详细分析了这三个关键字： 关键字: synchronized详解 关键字: volatile详解 关键字: final详解 Happens-Before 规则上面提到了可以用 volatile 和 synchronized 来保证有序性。除此之外，JVM 还规定了先行发生原则，让一个操作无需控制就能先于另一个操作完成。 1. 单一线程原则 Single Thread rule 在一个线程内，在程序前面的操作先行发生于后面的操作。 2. 管程锁定规则 Monitor Lock Rule 一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。 3. volatile 变量规则 Volatile Variable Rule 对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。 4. 线程启动规则 Thread Start Rule Thread 对象的 start() 方法调用先行发生于此线程的每一个动作。 5. 线程加入规则 Thread Join Rule Thread 对象的结束先行发生于 join() 方法返回。 6. 线程中断规则 Thread Interruption Rule 对线程 interrupt() 方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 interrupted() 方法检测到是否有中断发生。 7. 对象终结规则 Finalizer Rule 一个对象的初始化完成(构造函数执行结束)先行发生于它的 finalize() 方法的开始。 8. 传递性 Transitivity 如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么操作 A 先行发生于操作 C。 线程安全: 不是一个非真即假的命题一个类在可以被多个线程安全调用时就是线程安全的。 线程安全不是一个非真即假的命题，可以将共享数据按照安全程度的强弱顺序分成以下五类: 不可变、绝对线程安全、相对线程安全、线程兼容和线程对立。 1. 不可变不可变(Immutable)的对象一定是线程安全的，不需要再采取任何的线程安全保障措施。只要一个不可变的对象被正确地构建出来，永远也不会看到它在多个线程之中处于不一致的状态。 多线程环境下，应当尽量使对象成为不可变，来满足线程安全。 不可变的类型: final 关键字修饰的基本数据类型 String 枚举类型 Number 部分子类，如 Long 和 Double 等数值包装类型，BigInteger 和 BigDecimal 等大数据类型。但同为 Number 的原子类 AtomicInteger 和 AtomicLong 则是可变的。 对于集合类型，可以使用 Collections.unmodifiableXXX() 方法来获取一个不可变的集合。 12345678910public class ImmutableExample &#123; public static void main(String[] args) &#123; Map&lt;String, Integer&gt; map = new HashMap&lt;&gt;(); Map&lt;String, Integer&gt; unmodifiableMap = Collections.unmodifiableMap(map); unmodifiableMap.put(&quot;a&quot;, 1); &#125;&#125;Exception in thread &quot;main&quot; java.lang.UnsupportedOperationException at java.util.Collections$UnmodifiableMap.put(Collections.java:1457) at ImmutableExample.main(ImmutableExample.java:9) Collections.unmodifiableXXX() 先对原始的集合进行拷贝，需要对集合进行修改的方法都直接抛出异常。 123public V put(K key, V value) &#123; throw new UnsupportedOperationException();&#125; 2. 绝对线程安全不管运行时环境如何，调用者都不需要任何额外的同步措施。 3. 相对线程安全相对线程安全需要保证对这个对象单独的操作是线程安全的，在调用的时候不需要做额外的保障措施。但是对于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。 在 Java 语言中，大部分的线程安全类都属于这种类型，例如 Vector、HashTable、Collections 的 synchronizedCollection() 方法包装的集合等。 对于下面的代码，如果删除元素的线程删除了 Vector 的一个元素，而获取元素的线程试图访问一个已经被删除的元素，那么就会抛出 ArrayIndexOutOfBoundsException。 12345678910111213141516171819202122232425262728public class VectorUnsafeExample &#123; private static Vector&lt;Integer&gt; vector = new Vector&lt;&gt;(); public static void main(String[] args) &#123; while (true) &#123; for (int i = 0; i &lt; 100; i++) &#123; vector.add(i); &#125; ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125;); executorService.execute(() -&gt; &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.get(i); &#125; &#125;); executorService.shutdown(); &#125; &#125;&#125;Exception in thread &quot;Thread-159738&quot; java.lang.ArrayIndexOutOfBoundsException: Array index out of range: 3 at java.util.Vector.remove(Vector.java:831) at VectorUnsafeExample.lambda$main$0(VectorUnsafeExample.java:14) at VectorUnsafeExample$$Lambda$1/713338599.run(Unknown Source) at java.lang.Thread.run(Thread.java:745) 如果要保证上面的代码能正确执行下去，就需要对删除元素和获取元素的代码进行同步。 1234567891011121314executorService.execute(() -&gt; &#123; synchronized (vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125;&#125;);executorService.execute(() -&gt; &#123; synchronized (vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.get(i); &#125; &#125;&#125;); 4. 线程兼容线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用，我们平常说一个类不是线程安全的，绝大多数时候指的是这一种情况。Java API 中大部分的类都是属于线程兼容的，如与前面的 Vector 和 HashTable 相对应的集合类 ArrayList 和 HashMap 等。 5. 线程对立线程对立是指无论调用端是否采取了同步措施，都无法在多线程环境中并发使用的代码。由于 Java 语言天生就具备多线程特性，线程对立这种排斥多线程的代码是很少出现的，而且通常都是有害的，应当尽量避免。 线程安全的实现方法1. 互斥同步synchronized 和 ReentrantLock。 初步了解你可以看： [Java 并发 - 线程基础：线程互斥同步](/2023/12/25/3-Java-%E5%B9%B6%E5%8F%91-%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/#线程互斥同步) 详细分析请看： 关键字: Synchronized详解 JUC锁: ReentrantLock详解 2. 非阻塞同步互斥同步最主要的问题就是线程阻塞和唤醒所带来的性能问题，因此这种同步也称为阻塞同步。 互斥同步属于一种悲观的并发策略，总是认为只要不去做正确的同步措施，那就肯定会出现问题。无论共享数据是否真的会出现竞争，它都要进行加锁(这里讨论的是概念模型，实际上虚拟机会优化掉很大一部分不必要的加锁)、用户态核心态转换、维护锁计数器和检查是否有被阻塞的线程需要唤醒等操作。 (一)CAS 随着硬件指令集的发展，我们可以使用基于冲突检测的乐观并发策略: 先进行操作，如果没有其它线程争用共享数据，那操作就成功了，否则采取补偿措施(不断地重试，直到成功为止)。这种乐观的并发策略的许多实现都不需要将线程阻塞，因此这种同步操作称为非阻塞同步。 乐观锁需要操作和冲突检测这两个步骤具备原子性，这里就不能再使用互斥同步来保证了，只能靠硬件来完成。硬件支持的原子性操作最典型的是: 比较并交换(Compare-and-Swap，CAS)。CAS 指令需要有 3 个操作数，分别是内存地址 V、旧的预期值 A 和新值 B。当执行操作时，只有当 V 的值等于 A，才将 V 的值更新为 B。 (二)AtomicInteger J.U.C 包里面的整数原子类 AtomicInteger，其中的 compareAndSet() 和 getAndIncrement() 等方法都使用了 Unsafe 类的 CAS 操作。 以下代码使用了 AtomicInteger 执行了自增的操作。 12345private AtomicInteger cnt = new AtomicInteger();public void add() &#123; cnt.incrementAndGet();&#125; 以下代码是 incrementAndGet() 的源码，它调用了 unsafe 的 getAndAddInt() 。 123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1;&#125; 以下代码是 getAndAddInt() 源码，var1 指示对象内存地址，var2 指示该字段相对对象内存地址的偏移，var4 指示操作需要加的数值，这里为 1。通过 getIntVolatile(var1, var2) 得到旧的预期值，通过调用 compareAndSwapInt() 来进行 CAS 比较，如果该字段内存地址中的值等于 var5，那么就更新内存地址为 var1+var2 的变量为 var5+var4。 可以看到 getAndAddInt() 在一个循环中进行，发生冲突的做法是不断的进行重试。 12345678public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; (三)ABA 如果一个变量初次读取的时候是 A 值，它的值被改成了 B，后来又被改回为 A，那 CAS 操作就会误认为它从来没有被改变过。 J.U.C 包提供了一个带有标记的原子引用类 AtomicStampedReference 来解决这个问题，它可以通过控制变量值的版本来保证 CAS 的正确性。大部分情况下 ABA 问题不会影响程序并发的正确性，如果需要解决 ABA 问题，改用传统的互斥同步可能会比原子类更高效。 CAS, Unsafe和原子类详细分析请看： JUC原子类: CAS, Unsafe和原子类详解 3. 无同步方案要保证线程安全，并不是一定就要进行同步。如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性。 (一)栈封闭 多个线程访问同一个方法的局部变量时，不会出现线程安全问题，因为局部变量存储在虚拟机栈中，属于线程私有的。 123456789101112131415161718192021import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;public class StackClosedExample &#123; public void add100() &#123; int cnt = 0; for (int i = 0; i &lt; 100; i++) &#123; cnt++; &#125; System.out.println(cnt); &#125;&#125;public static void main(String[] args) &#123; StackClosedExample example = new StackClosedExample(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(() -&gt; example.add100()); executorService.execute(() -&gt; example.add100()); executorService.shutdown();&#125;100100 更详细的分析请看J.U.C中线程池相关内容详解： JUC线程池: FutureTask详解 JUC线程池: ThreadPoolExecutor详解 JUC线程池: ScheduledThreadPool详解 JUC线程池: Fork&#x2F;Join框架详解 (二)线程本地存储(Thread Local Storage) 如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行。如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。 符合这种特点的应用并不少见，大部分使用消费队列的架构模式(如“生产者-消费者”模式)都会将产品的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典 Web 交互模型中的“一个请求对应一个服务器线程”(Thread-per-Request)的处理方式，这种处理方式的广泛应用使得很多 Web 服务端应用都可以使用线程本地存储来解决线程安全问题。 可以使用 java.lang.ThreadLocal 类来实现线程本地存储功能。 对于以下代码，thread1 中设置 threadLocal 为 1，而 thread2 设置 threadLocal 为 2。过了一段时间之后，thread1 读取 threadLocal 依然是 1，不受 thread2 的影响。 123456789101112131415161718192021public class ThreadLocalExample &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal.set(1); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(threadLocal.get()); threadLocal.remove(); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal.set(2); threadLocal.remove(); &#125;); thread1.start(); thread2.start(); &#125;&#125; 输出结果 11 为了理解 ThreadLocal，先看以下代码: 12345678910111213141516public class ThreadLocalExample1 &#123; public static void main(String[] args) &#123; ThreadLocal threadLocal1 = new ThreadLocal(); ThreadLocal threadLocal2 = new ThreadLocal(); Thread thread1 = new Thread(() -&gt; &#123; threadLocal1.set(1); threadLocal2.set(1); &#125;); Thread thread2 = new Thread(() -&gt; &#123; threadLocal1.set(2); threadLocal2.set(2); &#125;); thread1.start(); thread2.start(); &#125;&#125; 它所对应的底层结构图为: 每个 Thread 都有一个 ThreadLocal.ThreadLocalMap 对象，Thread 类中就定义了 ThreadLocal.ThreadLocalMap 成员。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ThreadLocal.ThreadLocalMap threadLocals = null; 当调用一个 ThreadLocal 的 set(T value) 方法时，先得到当前线程的 ThreadLocalMap 对象，然后将 ThreadLocal-&gt;value 键值对插入到该 Map 中。 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; get() 方法类似。 12345678910111213public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(&quot;unchecked&quot;) T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125; ThreadLocal 从理论上讲并不是用来解决多线程并发问题的，因为根本不存在多线程竞争。 在一些场景 (尤其是使用线程池) 下，由于 ThreadLocal.ThreadLocalMap 的底层数据结构导致 ThreadLocal 有内存泄漏的情况，应该尽可能在每次使用 ThreadLocal 后手动调用 remove()，以避免出现 ThreadLocal 经典的内存泄漏甚至是造成自身业务混乱的风险。 更详细的分析看：Java 并发 - ThreadLocal详解 (三)可重入代码(Reentrant Code) 这种代码也叫做纯代码(Pure Code)，可以在代码执行的任何时刻中断它，转而去执行另外一段代码(包括递归调用它本身)，而在控制权返回后，原来的程序不会出现任何错误。 可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。","tags":["Java","多线程与并发"],"categories":["Java","多线程与并发"]},{"title":"1.Java并发知识体系详解","path":"/2023/12/25/1-Java并发知识体系详解/","content":"Java 并发相关知识体系详解，包含理论基础，线程基础，synchronized，volatile，final关键字, JUC框架等内容。 知识体系 相关文章 A. Java进阶 - Java 并发之基础：首先全局的了解并发的知识体系，同时了解并发理论基础和线程基础，并发关键字等，这些是你理解Java并发框架的基础。 Java 并发 - 知识体系 Java 并发 - 理论基础 多线程的出现是要解决什么问题的? 线程不安全是指什么? 举例说明 并发出现线程不安全的本质什么? 可见性，原子性和有序性。 Java是怎么解决并发问题的? 3个关键字，JMM和8个Happens-Before 线程安全是不是非真即假? 不是 线程安全有哪些实现思路? 如何理解并发和并行的区别? Java 并发 - 线程基础 线程有哪几种状态? 分别说明从一种状态到另一种状态转变有哪些方式? 通常线程有哪几种使用方式? 基础线程机制有哪些? 线程的中断方式有哪些? 线程的互斥同步方式有哪些? 如何比较和选择? 线程之间有哪些协作方式? Java并发 - Java中所有的锁 Java提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。 关键字: synchronized详解 Synchronized可以作用在哪里? 分别通过对象锁和类锁进行举例。 Synchronized本质上是通过什么保证线程安全的? 分三个方面回答：加锁和释放锁的原理，可重入原理，保证可见性原理。 Synchronized由什么样的缺陷? Java Lock是怎么弥补这些缺陷的。 Synchronized和Lock的对比，和选择? Synchronized在使用时有何注意事项? Synchronized修饰的方法在抛出异常时,会释放锁吗? 多个线程等待同一个Synchronized锁的时候，JVM如何选择下一个获取锁的线程? Synchronized使得同时只有一个线程可以执行，性能比较差，有什么提升的方法? 我想更加灵活地控制锁的释放和获取(现在释放锁和获取锁的时机都被规定死了)，怎么办? 什么是锁的升级和降级? 什么是JVM里的偏斜锁、轻量级锁、重量级锁? 不同的JDK中对Synchronized有何优化? 关键字: volatile详解 volatile关键字的作用是什么? volatile能保证原子性吗? 之前32位机器上共享的long和double变量的为什么要用volatile? 现在64位机器上是否也要设置呢? i++为什么不能保证原子性? volatile是如何实现可见性的? 内存屏障。 volatile是如何实现有序性的? happens-before等 说下volatile的应用场景? 关键字: final详解 所有的final修饰的字段都是编译期常量吗? 如何理解private所修饰的方法是隐式的final? 说说final类型的类如何拓展? 比如String是final类型，我们想写个MyString复用所有String中方法，同时增加一个新的toMyString()的方法，应该如何做? final方法可以被重载吗? 可以 父类的final方法能不能够被子类重写? 不可以 说说final域重排序规则? 说说final的原理? 使用 final 的限制条件和局限性? 看本文最后的一个思考题 B. Java进阶 - Java 并发之J.U.C框架：然后需要对J.U.C框架五大类详细解读，包括：Lock框架，并发集合, 原子类, 线程池和工具类。 JUC - 类汇总和学习指南 JUC框架包含几个部分? 每个部分有哪些核心的类? 最最核心的类有哪些? B.1 Java进阶 - Java 并发之J.U.C框架【1&#x2F;5】：CAS及原子类：从最核心的CAS, Unsafe和原子类开始分析。 JUC原子类: CAS, Unsafe和原子类详解 线程安全的实现方法有哪些? 什么是CAS? CAS使用示例，结合AtomicInteger给出示例? CAS会有哪些问题? 针对这这些问题，Java提供了哪几个解决的? AtomicInteger底层实现? CAS+volatile 请阐述你对Unsafe类的理解? 说说你对Java原子类的理解? 包含13个，4组分类，说说作用和使用场景。 AtomicStampedReference是什么? AtomicStampedReference是怎么解决ABA的? 内部使用Pair来存储元素值及其版本号 java中还有哪些类可以解决ABA的问题? AtomicMarkableReference B.2 Java进阶 - Java 并发之J.U.C框架【2&#x2F;5】：锁：然后分析JUC中锁。 JUC锁: LockSupport详解 为什么LockSupport也是核心基础类? AQS框架借助于两个类：Unsafe(提供CAS操作)和LockSupport(提供park&#x2F;unpark操作) 写出分别通过wait&#x2F;notify和LockSupport的park&#x2F;unpark实现同步? LockSupport.park()会释放锁资源吗? 那么Condition.await()呢? Thread.sleep()、Object.wait()、Condition.await()、LockSupport.park()的区别? 重点 如果在wait()之前执行了notify()会怎样? 如果在park()之前执行了unpark()会怎样? JUC锁: 锁核心类AQS详解 什么是AQS? 为什么它是核心? AQS的核心思想是什么? 它是怎么实现的? 底层数据结构等 AQS有哪些核心的方法? AQS定义什么样的资源获取方式? AQS定义了两种资源获取方式：独占(只有一个线程能访问执行，又根据是否按队列的顺序分为公平锁和非公平锁，如ReentrantLock) 和共享(多个线程可同时访问执行，如Semaphore、CountDownLatch、 CyclicBarrier )。ReentrantReadWriteLock可以看成是组合式，允许多个线程同时对某一资源进行读。 AQS底层使用了什么样的设计模式? 模板 AQS的应用示例? JUC锁: ReentrantLock详解 什么是可重入，什么是可重入锁? 它用来解决什么问题? ReentrantLock的核心是AQS，那么它怎么来实现的，继承吗? 说说其类内部结构关系。 ReentrantLock是如何实现公平锁的? ReentrantLock是如何实现非公平锁的? ReentrantLock默认实现的是公平还是非公平锁? 使用ReentrantLock实现公平和非公平锁的示例? ReentrantLock和Synchronized的对比? JUC锁: ReentrantReadWriteLock详解 为了有了ReentrantLock还需要ReentrantReadWriteLock? ReentrantReadWriteLock底层实现原理? ReentrantReadWriteLock底层读写状态如何设计的? 高16位为读锁，低16位为写锁 读锁和写锁的最大数量是多少? 本地线程计数器ThreadLocalHoldCounter是用来做什么的? 缓存计数器HoldCounter是用来做什么的? 写锁的获取与释放是怎么实现的? 读锁的获取与释放是怎么实现的? RentrantReadWriteLock为什么不支持锁升级? 什么是锁的升降级? RentrantReadWriteLock为什么不支持锁升级? B.3 Java进阶 - Java 并发之J.U.C框架【3&#x2F;5】：集合：再理解JUC中重要的支持并发的集合。 JUC集合: ConcurrentHashMap详解 为什么HashTable慢? 它的并发度是什么? 那么ConcurrentHashMap并发度是什么? ConcurrentHashMap在JDK1.7和JDK1.8中实现有什么差别? JDK1.8解決了JDK1.7中什么问题 ConcurrentHashMap JDK1.7实现的原理是什么? 分段锁机制 ConcurrentHashMap JDK1.8实现的原理是什么? 数组+链表+红黑树，CAS ConcurrentHashMap JDK1.7中Segment数(concurrencyLevel)默认值是多少? 为何一旦初始化就不可再扩容? ConcurrentHashMap JDK1.7说说其put的机制? ConcurrentHashMap JDK1.7是如何扩容的? rehash(注：segment 数组不能扩容，扩容是 segment 数组某个位置内部的数组 HashEntry&lt;K,V&gt;[] 进行扩容) ConcurrentHashMap JDK1.8是如何扩容的? tryPresize ConcurrentHashMap JDK1.8链表转红黑树的时机是什么? 临界值为什么是8? ConcurrentHashMap JDK1.8是如何进行数据迁移的? transfer JUC集合: CopyOnWriteArrayList详解 请先说说非并发集合中Fail-fast机制? 再为什么说ArrayList查询快而增删慢? 对比ArrayList说说CopyOnWriteArrayList的增删改查实现原理? COW基于拷贝 再说下弱一致性的迭代器原理是怎么样的? COWIterator&lt;E&gt; CopyOnWriteArrayList为什么并发安全且性能比Vector好? CopyOnWriteArrayList有何缺陷，说说其应用场景? JUC集合: ConcurrentLinkedQueue详解 要想用线程安全的队列有哪些选择? Vector，Collections.synchronizedList( List&lt;T&gt; list), ConcurrentLinkedQueue等 ConcurrentLinkedQueue实现的数据结构? ConcurrentLinkedQueue底层原理? 全程无锁(CAS) ConcurrentLinkedQueue的核心方法有哪些? offer()，poll()，peek()，isEmpty()等队列常用方法 说说ConcurrentLinkedQueue的HOPS(延迟更新的策略)的设计? ConcurrentLinkedQueue适合什么样的使用场景? JUC集合: BlockingQueue详解 什么是BlockingDeque? BlockingQueue大家族有哪些? ArrayBlockingQueue, DelayQueue, LinkedBlockingQueue, SynchronousQueue… BlockingQueue适合用在什么样的场景? BlockingQueue常用的方法? BlockingQueue插入方法有哪些? 这些方法(add(o),offer(o),put(o),offer(o, timeout, timeunit))的区别是什么? BlockingDeque 与BlockingQueue有何关系，请对比下它们的方法? BlockingDeque适合用在什么样的场景? BlockingDeque大家族有哪些? BlockingDeque 与BlockingQueue实现例子? B.4 Java进阶 - Java 并发之J.U.C框架【4&#x2F;5】：线程池：再者分析JUC中非常常用的线程池等。 JUC线程池: FutureTask详解 FutureTask用来解决什么问题的? 为什么会出现? FutureTask类结构关系怎么样的? FutureTask的线程安全是由什么保证的? FutureTask结果返回机制? FutureTask内部运行状态的转变? FutureTask通常会怎么用? 举例说明。 JUC线程池: ThreadPoolExecutor详解 为什么要有线程池? Java是实现和管理线程池有哪些方式? 请简单举例如何使用。 为什么很多公司不允许使用Executors去创建线程池? 那么推荐怎么使用呢? ThreadPoolExecutor有哪些核心的配置参数? 请简要说明 ThreadPoolExecutor可以创建哪是哪三种线程池呢? 当队列满了并且worker的数量达到maxSize的时候，会怎么样? 说说ThreadPoolExecutor有哪些RejectedExecutionHandler策略? 默认是什么策略? 简要说下线程池的任务执行机制? execute –&gt; addWorker –&gt;runworker (getTask) 线程池中任务是如何提交的? 线程池中任务是如何关闭的? 在配置线程池的时候需要考虑哪些配置因素? 如何监控线程池的状态? JUC线程池: ScheduledThreadPool详解 ScheduledThreadPoolExecutor要解决什么样的问题? ScheduledThreadPoolExecutor相比ThreadPoolExecutor有哪些特性? ScheduledThreadPoolExecutor有什么样的数据结构，核心内部类和抽象类? ScheduledThreadPoolExecutor有哪两个关闭策略? 区别是什么? ScheduledThreadPoolExecutor中scheduleAtFixedRate 和 scheduleWithFixedDelay区别是什么? 为什么ThreadPoolExecutor 的调整策略却不适用于 ScheduledThreadPoolExecutor? Executors 提供了几种方法来构造 ScheduledThreadPoolExecutor? JUC线程池: Fork&#x2F;Join框架详解 Fork&#x2F;Join主要用来解决什么样的问题? Fork&#x2F;Join框架是在哪个JDK版本中引入的? Fork&#x2F;Join框架主要包含哪三个模块? 模块之间的关系是怎么样的? ForkJoinPool类继承关系? ForkJoinTask抽象类继承关系? 在实际运用中，我们一般都会继承 RecursiveTask 、RecursiveAction 或 CountedCompleter 来实现我们的业务需求，而不会直接继承 ForkJoinTask 类。 整个Fork&#x2F;Join 框架的执行流程&#x2F;运行机制是怎么样的? 具体阐述Fork&#x2F;Join的分治思想和work-stealing 实现方式? 有哪些JDK源码中使用了Fork&#x2F;Join思想? 如何使用Executors工具类创建ForkJoinPool? 写一个例子: 用ForkJoin方式实现1+2+3+…+100000? Fork&#x2F;Join在使用时有哪些注意事项? 结合JDK中的斐波那契数列实例具体说明。 B.5 Java进阶 - Java 并发之J.U.C框架【5&#x2F;5】：工具类：最后来看下JUC中有哪些工具类，以及线程隔离术ThreadLocal。 JUC工具类: CountDownLatch详解 什么是CountDownLatch? CountDownLatch底层实现原理? CountDownLatch一次可以唤醒几个任务? 多个 CountDownLatch有哪些主要方法? await(),countDown() CountDownLatch适用于什么场景? 写道题：实现一个容器，提供两个方法，add，size 写两个线程，线程1添加10个元素到容器中，线程2实现监控元素的个数，当个数到5个时，线程2给出提示并结束? 使用CountDownLatch 代替wait notify 好处。 JUC工具类: CyclicBarrier详解 什么是CyclicBarrier? CyclicBarrier底层实现原理? CountDownLatch和CyclicBarrier对比? CyclicBarrier的核心函数有哪些? CyclicBarrier适用于什么场景? JUC工具类: Semaphore详解 什么是Semaphore? Semaphore内部原理? Semaphore常用方法有哪些? 如何实现线程同步和互斥的? Semaphore适合用在什么场景? 单独使用Semaphore是不会使用到AQS的条件队列? Semaphore中申请令牌(acquire)、释放令牌(release)的实现? Semaphore初始化有10个令牌，11个线程同时各调用1次acquire方法，会发生什么? Semaphore初始化有10个令牌，一个线程重复调用11次acquire方法，会发生什么? Semaphore初始化有1个令牌，1个线程调用一次acquire方法，然后调用两次release方法，之后另外一个线程调用acquire(2)方法，此线程能够获取到足够的令牌并继续运行吗? Semaphore初始化有2个令牌，一个线程调用1次release方法，然后一次性获取3个令牌，会获取到吗? JUC工具类: Phaser详解 Phaser主要用来解决什么问题? Phaser与CyclicBarrier和CountDownLatch的区别是什么? 如果用CountDownLatch来实现Phaser的功能应该怎么实现? Phaser运行机制是什么样的? 给一个Phaser使用的示例? JUC工具类: Exchanger详解 Exchanger主要解决什么问题? 对比SynchronousQueue，为什么说Exchanger可被视为 SynchronousQueue 的双向形式? Exchanger在不同的JDK版本中实现有什么差别? Exchanger实现机制? Exchanger已经有了slot单节点，为什么会加入arena node数组? 什么时候会用到数组? arena可以确保不同的slot在arena中是不会相冲突的，那么是怎么保证的呢? 什么是伪共享，Exchanger中如何体现的? Exchanger实现举例 Java 并发 - ThreadLocal详解 什么是ThreadLocal? 用来解决什么问题的? 说说你对ThreadLocal的理解 ThreadLocal是如何实现线程隔离的? 为什么ThreadLocal会造成内存泄露? 如何解决 还有哪些使用ThreadLocal的应用场景? C. Java进阶 - Java 并发之 本质与模式：最后站在更高的角度看其本质(协作，分工和互斥)，同时总结上述知识点所使用的模式。 TODO：Java 并发 - 并发的本质：协作,分工和互斥 TODO：Java 并发 - 并发的模式梳理 参考文档官方文档 https://docs.oracle.com/javase/specs/jls/se7/html/jls-17.html 并发官方教程 https://docs.oracle.com/javase/tutorial/essential/concurrency/atomic.html Doug Lea并发编程文章全部译文 http://ifeve.com/doug-lea/ Java并发知识点总结 https://github.com/CL0610/Java-concurrency 线程与多线程必知必会(基础篇) https://zhuanlan.zhihu.com/p/33616143","tags":["Java","多线程与并发"],"categories":["Java","多线程与并发"]},{"title":"9.Map - WeakHashMap源码解析","path":"/2023/12/25/9-Map-WeakHashMap源码解析/","content":"本文主要对Map - WeakHashMap源码解析 源码解析。 Java 7- WeakHashMap总体介绍在Java集合框架系列文章的最后，笔者打算介绍一个特殊的成员: WeakHashMap，从名字可以看出它是某种 Map。它的特殊之处在于 WeakHashMap 里的entry可能会被GC自动删除，即使程序员没有调用remove()或者clear()方法。 更直观的说，当使用 WeakHashMap 时，即使没有显示的添加或删除任何元素，也可能发生如下情况: 调用两次size()方法返回不同的值； 两次调用isEmpty()方法，第一次返回false，第二次返回true； 两次调用containsKey()方法，第一次返回true，第二次返回false，尽管两次使用的是同一个key； 两次调用get()方法，第一次返回一个value，第二次返回null，尽管两次使用的是同一个对象。 遇到这么奇葩的现象，你是不是觉得使用者一定会疯掉? 其实不然，*WeakHashMap* 的这个特点特别适用于需要缓存的场景。在缓存场景下，由于内存是有限的，不能缓存所有对象；对象缓存命中可以提高系统效率，但缓存MISS也不会造成错误，因为可以通过计算重新得到。 要明白 WeakHashMap 的工作原理，还需要引入一个概念 : 弱引用(WeakReference)。我们都知道Java中内存是通过GC自动管理的，GC会在程序运行过程中自动判断哪些对象是可以被回收的，并在合适的时机进行内存释放。GC判断某个对象是否可被回收的依据是，是否有有效的引用指向该对象。如果没有有效引用指向该对象(基本意味着不存在访问该对象的方式)，那么该对象就是可回收的。这里的有效引用 并不包括弱引用。也就是说，虽然弱引用可以用来访问对象，但进行垃圾回收时弱引用并不会被考虑在内，仅有弱引用指向的对象仍然会被GC回收。 WeakHashMap 内部是通过弱引用来管理entry的，弱引用的特性对应到 WeakHashMap 上意味着什么呢？将一对key, value放入到 *WeakHashMap* 里并不能避免该key值被GC回收，除非在 *WeakHashMap* 之外还有对该key的强引用。 关于强引用，弱引用等概念以后再具体讲解，这里只需要知道Java中引用也是分种类的，并且不同种类的引用对GC的影响不同就够了。 具体实现WeakHashMap的存储结构类似于Map - HashSet &amp; HashMap 源码解析，这里不再赘述。 关于强弱引用的管理方式，博主将会另开专题单独讲解。 Weak HashSet?如果你看过前几篇关于 Map 和 Set 的讲解，一定会问: 既然有 WeakHashMap，是否有 WeekHashSet 呢? 答案是没有:( 。不过Java Collections工具类给出了解决方案，Collections.newSetFromMap(Map&lt;E,Boolean&gt; map)方法可以将任何 Map包装成一个Set。通过如下方式可以快速得到一个 Weak HashSet: 123// 将WeakHashMap包装成一个SetSet&lt;Object&gt; weakHashSet = Collections.newSetFromMap( new WeakHashMap&lt;Object, Boolean&gt;()); 不出你所料，newSetFromMap()方法只是对传入的 Map做了简单包装: 12345678910111213141516171819202122232425262728293031323334// Collections.newSetFromMap()用于将任何Map包装成一个Setpublic static &lt;E&gt; Set&lt;E&gt; newSetFromMap(Map&lt;E, Boolean&gt; map) &#123; return new SetFromMap&lt;&gt;(map);&#125;private static class SetFromMap&lt;E&gt; extends AbstractSet&lt;E&gt; implements Set&lt;E&gt;, Serializable&#123; private final Map&lt;E, Boolean&gt; m; // The backing map private transient Set&lt;E&gt; s; // Its keySet SetFromMap(Map&lt;E, Boolean&gt; map) &#123; if (!map.isEmpty()) throw new IllegalArgumentException(&quot;Map is non-empty&quot;); m = map; s = map.keySet(); &#125; public void clear() &#123; m.clear(); &#125; public int size() &#123; return m.size(); &#125; public boolean isEmpty() &#123; return m.isEmpty(); &#125; public boolean contains(Object o) &#123; return m.containsKey(o); &#125; public boolean remove(Object o) &#123; return m.remove(o) != null; &#125; public boolean add(E e) &#123; return m.put(e, Boolean.TRUE) == null; &#125; public Iterator&lt;E&gt; iterator() &#123; return s.iterator(); &#125; public Object[] toArray() &#123; return s.toArray(); &#125; public &lt;T&gt; T[] toArray(T[] a) &#123; return s.toArray(a); &#125; public String toString() &#123; return s.toString(); &#125; public int hashCode() &#123; return s.hashCode(); &#125; public boolean equals(Object o) &#123; return o == this || s.equals(o); &#125; public boolean containsAll(Collection&lt;?&gt; c) &#123;return s.containsAll(c);&#125; public boolean removeAll(Collection&lt;?&gt; c) &#123;return s.removeAll(c);&#125; public boolean retainAll(Collection&lt;?&gt; c) &#123;return s.retainAll(c);&#125; // addAll is the only inherited implementation ......&#125; 参考文章 浅谈WeakHashMap https://www.cnblogs.com/CarpenterLee/p/5544598.html","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"8.Map - TreeSet & TreeMap 源码解析","path":"/2023/12/25/8-Map-TreeSet-TreeMap-源码解析/","content":"本文主要对Map - TreeSet &amp; TreeMap 源码解析。 Java 7 - TreeSet &amp; TreeMap总体介绍之所以把TreeSet和TreeMap放在一起讲解，是因为二者在Java里有着相同的实现，前者仅仅是对后者做了一层包装，也就是说**TreeSet*里面有一个*TreeMap(适配器模式)*。因此本文将重点分析TreeMap*。 Java TreeMap实现了SortedMap接口，也就是说会按照key的大小顺序对Map中的元素进行排序，key大小的评判可以通过其本身的自然顺序(natural ordering)，也可以通过构造时传入的比较器(Comparator)。 *TreeMap*底层通过红黑树(Red-Black tree)实现，也就意味着containsKey(), get(), put(), remove()都有着log(n)的时间复杂度。其具体算法实现参照了《算法导论》。 出于性能原因，TreeMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将TreeMap包装成(wrapped)同步的: 1SortedMap m = Collections.synchronizedSortedMap(new TreeMap(...)); 红黑树是一种近似平衡的二叉查找树，它能够确保任何一个节点的左右子树的高度差不会超过二者中较低那个的一倍。具体来说，红黑树是满足如下条件的二叉查找树(binary search tree): 每个节点要么是红色，要么是黑色。 根节点必须是黑色 红色节点不能连续(也即是，红色节点的孩子和父亲都不能是红色)。 对于每个节点，从该点至null(树尾端)的任何路径，都含有相同个数的黑色节点。 在树的结构发生改变时(插入或者删除操作)，往往会破坏上述条件3或条件4，需要通过调整使得查找树重新满足红黑树的约束条件。 预备知识前文说到当查找树的结构发生改变时，红黑树的约束条件可能被破坏，需要通过调整使得查找树重新满足红黑树的约束条件。调整可以分为两类: 一类是颜色调整，即改变某个节点的颜色；另一类是结构调整，即改变检索树的结构关系。结构调整过程包含两个基本操作** : 左旋(Rotate Left)，右旋(RotateRight)**。 左旋左旋的过程是将x的右子树绕x逆时针旋转，使得x的右子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。 TreeMap中左旋代码如下: 123456789101112131415161718//Rotate Leftprivate void rotateLeft(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; r = p.right; p.right = r.left; if (r.left != null) r.left.parent = p; r.parent = p.parent; if (p.parent == null) root = r; else if (p.parent.left == p) p.parent.left = r; else p.parent.right = r; r.left = p; p.parent = r; &#125;&#125; 右旋右旋的过程是将x的左子树绕x顺时针旋转，使得x的左子树成为x的父亲，同时修改相关节点的引用。旋转之后，二叉查找树的属性仍然满足。 TreeMap中右旋代码如下: 12345678910111213141516//Rotate Rightprivate void rotateRight(Entry&lt;K,V&gt; p) &#123; if (p != null) &#123; Entry&lt;K,V&gt; l = p.left; p.left = l.right; if (l.right != null) l.right.parent = p; l.parent = p.parent; if (p.parent == null) root = l; else if (p.parent.right == p) p.parent.right = l; else p.parent.left = l; l.right = p; p.parent = l; &#125;&#125; 寻找节点后继对于一棵二叉查找树，给定节点t，其后继(树中比大于t的最小的那个元素)可以通过如下方式找到: t的右子树不空，则t的后继是其右子树中最小的那个元素。 t的右孩子为空，则t的后继是其第一个向左走的祖先。 后继节点在红黑树的删除操作中将会用到。 TreeMap中寻找节点后继的代码如下: 12345678910111213141516171819// 寻找节点后继函数successor()static &lt;K,V&gt; TreeMap.Entry&lt;K,V&gt; successor(Entry&lt;K,V&gt; t) &#123; if (t == null) return null; else if (t.right != null) &#123;// 1. t的右子树不空，则t的后继是其右子树中最小的那个元素 Entry&lt;K,V&gt; p = t.right; while (p.left != null) p = p.left; return p; &#125; else &#123;// 2. t的右孩子为空，则t的后继是其第一个向左走的祖先 Entry&lt;K,V&gt; p = t.parent; Entry&lt;K,V&gt; ch = t; while (p != null &amp;&amp; ch == p.right) &#123; ch = p; p = p.parent; &#125; return p; &#125;&#125; 方法剖析get()get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.value。因此getEntry()是算法的核心。算法思想是根据key的自然顺序(或者比较器顺序)对二叉查找树进行查找，直到找到满足k.compareTo(p.key) == 0的entry。 具体代码如下: 123456789101112131415161718//getEntry()方法final Entry&lt;K,V&gt; getEntry(Object key) &#123; ...... if (key == null)//不允许key值为null throw new NullPointerException(); Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序 Entry&lt;K,V&gt; p = root; while (p != null) &#123; int cmp = k.compareTo(p.key); if (cmp &lt; 0)//向左找 p = p.left; else if (cmp &gt; 0)//向右找 p = p.right; else return p; &#125; return null;&#125; put()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到则会在红黑树中插入新的entry，如果插入之后破坏了红黑树的约束条件，还需要进行调整(旋转，改变某些节点的颜色)。 123456789101112131415161718192021public V put(K key, V value) &#123;\t...... int cmp; Entry&lt;K,V&gt; parent; if (key == null) throw new NullPointerException(); Comparable&lt;? super K&gt; k = (Comparable&lt;? super K&gt;) key;//使用元素的自然顺序 do &#123; parent = t; cmp = k.compareTo(t.key); if (cmp &lt; 0) t = t.left;//向左找 else if (cmp &gt; 0) t = t.right;//向右找 else return t.setValue(value); &#125; while (t != null); Entry&lt;K,V&gt; e = new Entry&lt;&gt;(key, value, parent);//创建并插入新的entry if (cmp &lt; 0) parent.left = e; else parent.right = e; fixAfterInsertion(e);//调整 size++; return null;&#125; 上述代码的插入部分并不难理解: 首先在红黑树上找到合适的位置，然后创建新的entry并插入(当然，新插入的节点一定是树的叶子)。难点是调整函数fixAfterInsertion()，前面已经说过，调整往往需要1.改变某些节点的颜色，2.对某些节点进行旋转。 调整函数fixAfterInsertion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况2其实是落在情况3内的。情况4～情况6跟前三种情况是对称的，因此图解中并没有画出后三种情况，读者可以参考代码自行理解。 12345678910111213141516171819202122232425262728293031323334353637383940//红黑树调整函数fixAfterInsertion()private void fixAfterInsertion(Entry&lt;K,V&gt; x) &#123; x.color = RED; while (x != null &amp;&amp; x != root &amp;&amp; x.parent.color == RED) &#123; if (parentOf(x) == leftOf(parentOf(parentOf(x)))) &#123; Entry&lt;K,V&gt; y = rightOf(parentOf(parentOf(x))); if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); // 情况1 setColor(y, BLACK); // 情况1 setColor(parentOf(parentOf(x)), RED); // 情况1 x = parentOf(parentOf(x)); // 情况1 &#125; else &#123; if (x == rightOf(parentOf(x))) &#123; x = parentOf(x); // 情况2 rotateLeft(x); // 情况2 &#125; setColor(parentOf(x), BLACK); // 情况3 setColor(parentOf(parentOf(x)), RED); // 情况3 rotateRight(parentOf(parentOf(x))); // 情况3 &#125; &#125; else &#123; Entry&lt;K,V&gt; y = leftOf(parentOf(parentOf(x))); if (colorOf(y) == RED) &#123; setColor(parentOf(x), BLACK); // 情况4 setColor(y, BLACK); // 情况4 setColor(parentOf(parentOf(x)), RED); // 情况4 x = parentOf(parentOf(x)); // 情况4 &#125; else &#123; if (x == leftOf(parentOf(x))) &#123; x = parentOf(x); // 情况5 rotateRight(x); // 情况5 &#125; setColor(parentOf(x), BLACK); // 情况6 setColor(parentOf(parentOf(x)), RED); // 情况6 rotateLeft(parentOf(parentOf(x))); // 情况6 &#125; &#125; &#125; root.color = BLACK;&#125; remove()remove(Object key)的作用是删除key值对应的entry，该方法首先通过上文中提到的getEntry(Object key)方法找到key值对应的entry，然后调用deleteEntry(Entry&lt;K,V&gt; entry)删除对应的entry。由于删除操作会改变红黑树的结构，有可能破坏红黑树的约束条件，因此有可能要进行调整。 getEntry()函数前面已经讲解过，这里重点放deleteEntry()上，该函数删除指定的entry并在红黑树的约束被破坏时进行调用fixAfterDeletion(Entry&lt;K,V&gt; x)进行调整。 由于红黑树是一棵增强版的二叉查找树，红黑树的删除操作跟普通二叉查找树的删除操作也就非常相似，唯一的区别是红黑树在节点删除之后可能需要进行调整。现在考虑一棵普通二叉查找树的删除过程，可以简单分为两种情况: 删除点p的左右子树都为空，或者只有一棵子树非空。 删除点p的左右子树都非空。 对于上述情况1，处理起来比较简单，直接将p删除(左右子树都为空时)，或者用非空子树替代p(只有一棵子树非空时)；对于情况2，可以用p的后继s(树中大于x的最小的那个元素)代替p，然后使用情况1删除s(此时s一定满足情况1.可以画画看)。 基于以上逻辑，红黑树的节点删除函数deleteEntry()代码如下: 123456789101112131415161718192021222324252627282930313233343536// 红黑树entry删除函数deleteEntry()private void deleteEntry(Entry&lt;K,V&gt; p) &#123; modCount++; size--; if (p.left != null &amp;&amp; p.right != null) &#123;// 2. 删除点p的左右子树都非空。 Entry&lt;K,V&gt; s = successor(p);// 后继 p.key = s.key; p.value = s.value; p = s; &#125; Entry&lt;K,V&gt; replacement = (p.left != null ? p.left : p.right); if (replacement != null) &#123;// 1. 删除点p只有一棵子树非空。 replacement.parent = p.parent; if (p.parent == null) root = replacement; else if (p == p.parent.left) p.parent.left = replacement; else p.parent.right = replacement; p.left = p.right = p.parent = null; if (p.color == BLACK) fixAfterDeletion(replacement);// 调整 &#125; else if (p.parent == null) &#123; root = null; &#125; else &#123; // 1. 删除点p的左右子树都为空 if (p.color == BLACK) fixAfterDeletion(p);// 调整 if (p.parent != null) &#123; if (p == p.parent.left) p.parent.left = null; else if (p == p.parent.right) p.parent.right = null; p.parent = null; &#125; &#125;&#125; 上述代码中占据大量代码行的，是用来修改父子节点间引用关系的代码，其逻辑并不难理解。下面着重讲解删除后调整函数fixAfterDeletion()。首先请思考一下，删除了哪些点才会导致调整？只有删除点是BLACK的时候，才会触发调整函数，因为删除RED节点不会破坏红黑树的任何约束，而删除BLACK节点会破坏规则4。 跟上文中讲过的fixAfterInsertion()函数一样，这里也要分成若干种情况。记住，无论有多少情况，具体的调整操作只有两种: 1.改变某些节点的颜色，2.对某些节点进行旋转。 上述图解的总体思想是: 将情况1首先转换成情况2，或者转换成情况3和情况4。当然，该图解并不意味着调整过程一定是从情况1开始。通过后续代码我们还会发现几个有趣的规则: a).如果是由情况1之后紧接着进入的情况2，那么情况2之后一定会退出循环(因为x为红色)；b).一旦进入情况3和情况4，一定会退出循环(因为x为root)。 删除后调整函数fixAfterDeletion()的具体代码如下，其中用到了上文中提到的rotateLeft()和rotateRight()函数。通过代码我们能够看到，情况3其实是落在情况4内的。情况5～情况8跟前四种情况是对称的，因此图解中并没有画出后四种情况，读者可以参考代码自行理解。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556private void fixAfterDeletion(Entry&lt;K,V&gt; x) &#123; while (x != root &amp;&amp; colorOf(x) == BLACK) &#123; if (x == leftOf(parentOf(x))) &#123; Entry&lt;K,V&gt; sib = rightOf(parentOf(x)); if (colorOf(sib) == RED) &#123; setColor(sib, BLACK); // 情况1 setColor(parentOf(x), RED); // 情况1 rotateLeft(parentOf(x)); // 情况1 sib = rightOf(parentOf(x)); // 情况1 &#125; if (colorOf(leftOf(sib)) == BLACK &amp;&amp; colorOf(rightOf(sib)) == BLACK) &#123; setColor(sib, RED); // 情况2 x = parentOf(x); // 情况2 &#125; else &#123; if (colorOf(rightOf(sib)) == BLACK) &#123; setColor(leftOf(sib), BLACK); // 情况3 setColor(sib, RED); // 情况3 rotateRight(sib); // 情况3 sib = rightOf(parentOf(x)); // 情况3 &#125; setColor(sib, colorOf(parentOf(x))); // 情况4 setColor(parentOf(x), BLACK); // 情况4 setColor(rightOf(sib), BLACK); // 情况4 rotateLeft(parentOf(x)); // 情况4 x = root; // 情况4 &#125; &#125; else &#123; // 跟前四种情况对称 Entry&lt;K,V&gt; sib = leftOf(parentOf(x)); if (colorOf(sib) == RED) &#123; setColor(sib, BLACK); // 情况5 setColor(parentOf(x), RED); // 情况5 rotateRight(parentOf(x)); // 情况5 sib = leftOf(parentOf(x)); // 情况5 &#125; if (colorOf(rightOf(sib)) == BLACK &amp;&amp; colorOf(leftOf(sib)) == BLACK) &#123; setColor(sib, RED); // 情况6 x = parentOf(x); // 情况6 &#125; else &#123; if (colorOf(leftOf(sib)) == BLACK) &#123; setColor(rightOf(sib), BLACK); // 情况7 setColor(sib, RED); // 情况7 rotateLeft(sib); // 情况7 sib = leftOf(parentOf(x)); // 情况7 &#125; setColor(sib, colorOf(parentOf(x))); // 情况8 setColor(parentOf(x), BLACK); // 情况8 setColor(leftOf(sib), BLACK); // 情况8 rotateRight(parentOf(x)); // 情况8 x = root; // 情况8 &#125; &#125; &#125; setColor(x, BLACK);&#125; TreeSet前面已经说过TreeSet是对TreeMap的简单包装，对TreeSet的函数调用都会转换成合适的TreeMap方法，因此TreeSet的实现非常简单。这里不再赘述。 1234567891011121314151617// TreeSet是对TreeMap的简单包装public class TreeSet&lt;E&gt; extends AbstractSet&lt;E&gt; implements NavigableSet&lt;E&gt;, Cloneable, java.io.Serializable&#123;\t...... private transient NavigableMap&lt;E,Object&gt; m; // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public TreeSet() &#123; this.m = new TreeMap&lt;E,Object&gt;();// TreeSet里面有一个TreeMap &#125; ...... public boolean add(E e) &#123; return m.put(e, PRESENT)==null; &#125; ......&#125;","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"7.Map - LinkedHashSet&Map源码解析","path":"/2023/12/25/7-Map-LinkedHashSet-Map源码解析/","content":"本文主要对Map - LinkedHashSet&amp;Map 源码解析。 Java 7 - LinkedHashSet&amp;Map总体介绍如果你已看过前面关于HashSet和HashMap，以及TreeSet和TreeMap的讲解，一定能够想到本文将要讲解的LinkedHashSet和LinkedHashMap其实也是一回事。LinkedHashSet和LinkedHashMap在Java里也有着相同的实现，前者仅仅是对后者做了一层包装，也就是说**LinkedHashSet里面有一个LinkedHashMap(适配器模式)*。因此本文将重点分析LinkedHashMap*。 LinkedHashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素。从名字上可以看出该容器是linked list和HashMap的混合体，也就是说它同时满足HashMap和linked list的某些特性。可将*LinkedHashMap*看作采用*linked list*增强的*HashMap*。 事实上LinkedHashMap是HashMap的直接子类，二者唯一的区别是*LinkedHashMap*在*HashMap*的基础上，采用双向链表(doubly-linked list)的形式将所有entry连接起来，这样是为保证元素的迭代顺序跟插入顺序相同。上图给出了LinkedHashMap的结构图，主体部分跟HashMap完全一样，多了header指向双向链表的头部(是一个哑元)，该双向链表的迭代顺序就是entry的插入顺序。 除了可以保迭代历顺序，这种结构还有一个好处 : 迭代*LinkedHashMap*时不需要像*HashMap*那样遍历整个table，而只需要直接遍历header指向的双向链表即可，也就是说LinkedHashMap的迭代时间就只跟entry的个数相关，而跟table的大小无关。 有两个参数可以影响LinkedHashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。 将对象放入到LinkedHashMap或LinkedHashSet中时，有两个方法需要特别关心: hashCode()和equals()。**hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”**。所以，如果要将自定义的对象放入到LinkedHashMap或LinkedHashSet中，需要@Override hashCode()和equals()方法。 通过如下方式可以得到一个跟源Map 迭代顺序一样的LinkedHashMap: 1234void foo(Map m) &#123; Map copy = new LinkedHashMap(m); ...&#125; 出于性能原因，LinkedHashMap是非同步的(not synchronized)，如果需要在多线程环境使用，需要程序员手动同步；或者通过如下方式将LinkedHashMap包装成(wrapped)同步的: 1Map m = Collections.synchronizedMap(new LinkedHashMap(...)); 方法剖析get()get(Object key)方法根据指定的key值返回对应的value。该方法跟HashMap.get()方法的流程几乎完全一样，读者可自行[参考前文在新窗口打开](https://github.com/CarpenterLee/JCFInternals/blob/master/markdown/6-HashSet and HashMap.md#get)，这里不再赘述。 put()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于get()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry。 注意，这里的插入有两重含义: 从table的角度看，新的entry需要插入到对应的bucket里，当有哈希冲突时，采用头插法将新的entry插入到冲突链表的头部。 从header的角度看，新的entry需要插入到双向链表的尾部。 addEntry()代码如下: 123456789101112131415// LinkedHashMap.addEntry()void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length);// 自动扩容，并重新哈希 hash = (null != key) ? hash(key) : 0; bucketIndex = hash &amp; (table.length-1);// hash%table.length &#125; // 1.在冲突链表头部插入新的entry HashMap.Entry&lt;K,V&gt; old = table[bucketIndex]; Entry&lt;K,V&gt; e = new Entry&lt;&gt;(hash, key, value, old); table[bucketIndex] = e; // 2.在双向链表的尾部插入新的entry e.addBefore(header); size++;&#125; 上述代码中用到了addBefore()方法将新entry e插入到双向链表头引用header的前面，这样e就成为双向链表中的最后一个元素。addBefore()的代码如下: 1234567// LinkedHashMap.Entry.addBefor()，将this插入到existingEntry的前面private void addBefore(Entry&lt;K,V&gt; existingEntry) &#123; after = existingEntry; before = existingEntry.before; before.after = this; after.before = this;&#125; 上述代码只是简单修改相关entry的引用而已。 remove()remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry(修改链表的相应引用)。查找过程跟get()方法类似。 注意，这里的删除也有两重含义: 从table的角度看，需要将该entry从对应的bucket里删除，如果对应的冲突链表不空，需要修改冲突链表的相应引用。 从header的角度来看，需要将该entry从双向链表中删除，同时修改链表中前面以及后面元素的相应引用。 removeEntryForKey()对应的代码如下: 12345678910111213141516171819202122232425// LinkedHashMap.removeEntryForKey()，删除key值对应的entryfinal Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123;\t......\tint hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length);// hash&amp;(table.length-1) Entry&lt;K,V&gt; prev = table[i];// 得到冲突链表 Entry&lt;K,V&gt; e = prev; while (e != null) &#123;// 遍历冲突链表 Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123;// 找到要删除的entry modCount++; size--; // 1. 将e从对应bucket的冲突链表中删除 if (prev == e) table[i] = next; else prev.next = next; // 2. 将e从双向链表中删除 e.before.after = e.after; e.after.before = e.before; return e; &#125; prev = e; e = next; &#125; return e;&#125; LinkedHashSet前面已经说过LinkedHashSet是对LinkedHashMap的简单包装，对LinkedHashSet的函数调用都会转换成合适的LinkedHashMap方法，因此LinkedHashSet的实现非常简单，这里不再赘述。 1234567891011121314public class LinkedHashSet&lt;E&gt; extends HashSet&lt;E&gt; implements Set&lt;E&gt;, Cloneable, java.io.Serializable &#123; ...... // LinkedHashSet里面有一个LinkedHashMap public LinkedHashSet(int initialCapacity, float loadFactor) &#123; map = new LinkedHashMap&lt;&gt;(initialCapacity, loadFactor); &#125;\t...... public boolean add(E e) &#123;//简单的方法转换 return map.put(e, PRESENT)==null; &#125; ......&#125; LinkedHashMap经典用法LinkedHashMap除了可以保证迭代顺序外，还有一个非常有用的用法: 可以轻松实现一个采用了FIFO替换策略的缓存。具体说来，LinkedHashMap有一个子类方法protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)，该方法的作用是告诉Map是否要删除“最老”的Entry，所谓最老就是当前Map中最早插入的Entry，如果该方法返回true，最老的那个元素就会被删除。在每次插入新元素的之后LinkedHashMap会自动询问removeEldestEntry()是否要删除最老的元素。这样只需要在子类中重载该方法，当元素个数超过一定数量时让removeEldestEntry()返回true，就能够实现一个固定大小的FIFO策略的缓存。示例代码如下: 12345678910111213/** 一个固定大小的FIFO替换策略的缓存 */class FIFOCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt;&#123; private final int cacheSize; public FIFOCache(int cacheSize)&#123; this.cacheSize = cacheSize; &#125; // 当Entry个数超过cacheSize时，删除最老的Entry @Override protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return size() &gt; cacheSize; &#125;&#125;","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"6.Map - HashSet & HashMap 源码解析","path":"/2023/12/25/6-Map-HashSet-HashMap-源码解析/","content":"本文主要对Map - HashSet &amp; HashMap进行源码解析。 Java7 HashMap概述之所以把HashSet和HashMap放在一起讲解，是因为二者在Java里有着相同的实现，前者仅仅是对后者做了一层包装，也就是说HashSet里面有一个HashMap(适配器模式)。因此本文将重点分析HashMap。 HashMap实现了Map接口，即允许放入key为null的元素，也允许插入value为null的元素；除该类未实现同步外，其余跟Hashtable大致相同；跟TreeMap不同，该容器不保证元素顺序，根据需要该容器可能会对元素重新哈希，元素的顺序也会被重新打散，因此不同时间迭代同一个HashMap的顺序可能会不同。 根据对冲突的处理方式不同，哈希表有两种实现方式，一种开放地址方式(Open addressing)，另一种是冲突链表方式(Separate chaining with linked lists)。Java7 *HashMap*采用的是冲突链表方式。 从上图容易看出，如果选择合适的哈希函数，put()和get()方法可以在常数时间内完成。但在对HashMap进行迭代时，需要遍历整个table以及后面跟的冲突链表。因此对于迭代比较频繁的场景，不宜将HashMap的初始大小设的过大。 有两个参数可以影响HashMap的性能: 初始容量(inital capacity)和负载系数(load factor)。初始容量指定了初始table的大小，负载系数用来指定自动扩容的临界值。当entry的数量超过capacity*load_factor时，容器将自动扩容并重新哈希。对于插入元素较多的场景，将初始容量设大可以减少重新哈希的次数。 将对象放入到HashMap或HashSet中时，有两个方法需要特别关心: hashCode()和equals()。**hashCode()方法决定了对象会被放到哪个bucket里，当多个对象的哈希值冲突时，equals()方法决定了这些对象是否是“同一个对象”。所以，如果要将自定义的对象放入到HashMap或HashSet中，需要@Override** hashCode()和equals()方法。 get()get(Object key)方法根据指定的key值返回对应的value，该方法调用了getEntry(Object key)得到相应的entry，然后返回entry.getValue()。因此getEntry()是算法的核心。 算法思想是首先通过hash()函数得到对应bucket的下标，然后依次遍历冲突链表，通过key.equals(k)方法来判断是否是要找的那个entry。 上图中hash(k)&amp;(table.length-1)等价于hash(k)%table.length，原因是HashMap要求table.length必须是2的指数，因此table.length-1就是二进制低位全是1，跟hash(k)相与会将哈希值的高位全抹掉，剩下的就是余数了。 1234567891011121314//getEntry()方法final Entry&lt;K,V&gt; getEntry(Object key) &#123;\t......\tint hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[hash&amp;(table.length-1)];//得到冲突链表 e != null; e = e.next) &#123;//依次遍历冲突链表中的每个entry Object k; //依据equals()方法判断是否相等 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; put()put(K key, V value)方法是将指定的key, value对添加到map里。该方法首先会对map做一次查找，看是否包含该元组，如果已经包含则直接返回，查找过程类似于getEntry()方法；如果没有找到，则会通过addEntry(int hash, K key, V value, int bucketIndex)方法插入新的entry，插入方式为头插法。 123456789101112//addEntry()void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length);//自动扩容，并重新哈希 hash = (null != key) ? hash(key) : 0; bucketIndex = hash &amp; (table.length-1);//hash%table.length &#125; //在冲突链表头部插入新的entry Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; remove()remove(Object key)的作用是删除key值对应的entry，该方法的具体逻辑是在removeEntryForKey(Object key)里实现的。removeEntryForKey()方法会首先找到key值对应的entry，然后删除该entry(修改链表的相应引用)。查找过程跟getEntry()过程类似。 123456789101112131415161718192021//removeEntryForKey()final Entry&lt;K,V&gt; removeEntryForKey(Object key) &#123;\t......\tint hash = (key == null) ? 0 : hash(key); int i = indexFor(hash, table.length);//hash&amp;(table.length-1) Entry&lt;K,V&gt; prev = table[i];//得到冲突链表 Entry&lt;K,V&gt; e = prev; while (e != null) &#123;//遍历冲突链表 Entry&lt;K,V&gt; next = e.next; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123;//找到要删除的entry modCount++; size--; if (prev == e) table[i] = next;//删除的是冲突链表的第一个entry else prev.next = next; return e; &#125; prev = e; e = next; &#125; return e;&#125; Java8 HashMapJava8 对 HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+红黑树 组成。 根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。 为了降低这部分的开销，在 Java8 中，当链表中的元素达到了 8 个时，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。 来一张图简单示意一下吧： 注意，上图是示意图，主要是描述结构，不会达到这个状态的，因为这么多数据的时候早就扩容了。 下面，我们还是用代码来介绍吧，个人感觉，Java8 的源码可读性要差一些，不过精简一些。 Java7 中使用 Entry 来代表每个 HashMap 中的数据节点，Java8 中使用 Node，基本没有区别，都是 key，value，hash 和 next 这四个属性，不过，Node 只能用于链表的情况，红黑树的情况需要使用 TreeNode。 我们根据数组元素中，第一个节点数据类型是 Node 还是 TreeNode 来判断该位置下是链表还是红黑树的。 put 过程分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;// 第四个参数 onlyIfAbsent 如果是 true，那么只有在不存在该 key 时才会进行 put 操作// 第五个参数 evict 我们这里不关心final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 第一次 put 值的时候，会触发下面的 resize()，类似 java7 的第一次 put 也要初始化数组长度 // 第一次 resize 和后续的扩容有些不一样，因为这次是数组从 null 初始化到默认的 16 或自定义的初始容量 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 找到具体的数组下标，如果此位置没有值，那么直接初始化一下 Node 并放置在这个位置就可以了 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123;// 数组该位置有数据 Node&lt;K,V&gt; e; K k; // 首先，判断该位置的第一个数据和我们要插入的数据，key 是不是&quot;相等&quot;，如果是，取出这个节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; // 如果该节点是代表红黑树的节点，调用红黑树的插值方法，本文不展开说红黑树 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 到这里，说明数组该位置上是一个链表 for (int binCount = 0; ; ++binCount) &#123; // 插入到链表的最后面(Java7 是插入到链表的最前面) if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // TREEIFY_THRESHOLD 为 8，所以，如果新插入的值是链表中的第 8 个 // 会触发下面的 treeifyBin，也就是将链表转换为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; // 如果在该链表中找到了&quot;相等&quot;的 key(== 或 equals) if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) // 此时 break，那么 e 为链表中[与要插入的新值的 key &quot;相等&quot;]的 node break; p = e; &#125; &#125; // e!=null 说明存在旧值的key与要插入的key&quot;相等&quot; // 对于我们分析的put操作，下面这个 if 其实就是进行 &quot;值覆盖&quot;，然后返回旧值 if (e != null) &#123; V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; // 如果 HashMap 由于新插入这个值导致 size 已经超过了阈值，需要进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 和 Java7 稍微有点不一样的地方就是，Java7 是先扩容后插入新值的，Java8 先插值再扩容，不过这个不重要。 数组扩容resize() 方法用于初始化数组或数组扩容，每次扩容后，容量为原来的 2 倍，并进行数据迁移。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; // 对应数组扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; // 将数组大小扩大一倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 将阈值扩大一倍 newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // 对应使用 new HashMap(int initialCapacity) 初始化后，第一次 put 的时候 newCap = oldThr; else &#123;// 对应使用 new HashMap() 初始化后，第一次 put 的时候 newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; // 用新的数组大小初始化新的数组 Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 如果是初始化数组，到这里就结束了，返回 newTab 即可 if (oldTab != null) &#123; // 开始遍历原数组，进行数据迁移。 for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; // 如果该数组位置上只有单个元素，那就简单了，简单迁移这个元素就可以了 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; // 如果是红黑树，具体我们就不展开了 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // 这块是处理链表的情况， // 需要将此链表拆成两个链表，放到新的数组中，并且保留原来的先后顺序 // loHead、loTail 对应一条链表，hiHead、hiTail 对应另一条链表，代码还是比较简单的 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; // 第一条链表 newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; // 第二条链表的新的位置是 j + oldCap，这个很好理解 newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; get 过程分析相对于 put 来说，get 真的太简单了。 计算 key 的 hash 值，根据 hash 值找到对应数组下标: hash &amp; (length-1) 判断数组该位置处的元素是否刚好就是我们要找的，如果不是，走第三步 判断该元素类型是否是 TreeNode，如果是，用红黑树的方法取数据，如果不是，走第四步 遍历链表，直到找到相等(&#x3D;&#x3D;或equals)的 key 123456789101112131415161718192021222324252627public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断第一个节点是不是就是需要的 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; // 判断是否是红黑树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表遍历 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; HashSet前面已经说过HashSet是对HashMap的简单包装，对HashSet的函数调用都会转换成合适的HashMap方法，因此HashSet的实现非常简单，只有不到300行代码。这里不再赘述。 12345678910111213141516//HashSet是对HashMap的简单包装public class HashSet&lt;E&gt;&#123;\t......\tprivate transient HashMap&lt;E,Object&gt; map;//HashSet里面有一个HashMap // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; ...... public boolean add(E e) &#123;//简单的方法转换 return map.put(e, PRESENT)==null; &#125; ......&#125;","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"5.Collection - PriorityQueue源码解析","path":"/2023/12/25/5-Collection-PriorityQueue源码解析/","content":"本文主要对Collection - PriorityQueue进行源码解析。 概述前面以Java ArrayDeque为例讲解了Stack和Queue，其实还有一种特殊的队列叫做PriorityQueue，即优先队列。优先队列的作用是能保证每次取出的元素都是队列中权值最小的(Java的优先队列每次取最小元素，C++的优先队列每次取最大元素)。这里牵涉到了大小关系，元素大小的评判可以通过元素本身的自然顺序(*natural ordering*)，也可以通过构造时传入的比较器(Comparator，类似于C++的仿函数)。 Java中PriorityQueue实现了Queue接口，不允许放入null元素；其通过堆实现，具体说是通过完全二叉树(complete binary tree)实现的小顶堆(任意一个非叶子节点的权值，都不大于其左右子节点的权值)，也就意味着可以通过数组来作为PriorityQueue的底层实现。 上图中我们给每个元素按照层序遍历的方式进行了编号，如果你足够细心，会发现父节点和子节点的编号是有联系的，更确切的说父子节点的编号之间有如下关系: 123leftNo = parentNo*2+1rightNo = parentNo*2+2parentNo = (nodeNo-1)/2 通过上述三个公式，可以轻易计算出某个节点的父节点以及子节点的下标。这也就是为什么可以直接用数组来存储堆的原因。 PriorityQueue的peek()和element操作是常数时间，add(), offer(), 无参数的remove()以及poll()方法的时间复杂度都是*log(N)*。 方法剖析add()和offer()add(E e)和offer(E e)的语义相同，都是向优先队列中插入元素，只是Queue接口规定二者对插入失败时的处理不同，前者在插入失败时抛出异常，后则则会返回false。对于PriorityQueue这两个方法其实没什么差别。 新加入的元素可能会破坏小顶堆的性质，因此需要进行必要的调整。 123456789101112131415//offer(E e)public boolean offer(E e) &#123; if (e == null)//不允许放入null元素 throw new NullPointerException(); modCount++; int i = size; if (i &gt;= queue.length) grow(i + 1);//自动扩容 size = i + 1; if (i == 0)//队列原来为空，这是插入的第一个元素 queue[0] = e; else siftUp(i, e);//调整 return true;&#125; 上述代码中，扩容函数grow()类似于ArrayList里的grow()函数，就是再申请一个更大的数组，并将原数组的元素复制过去，这里不再赘述。需要注意的是siftUp(int k, E x)方法，该方法用于插入元素x并维持堆的特性。 123456789101112//siftUp()private void siftUp(int k, E x) &#123; while (k &gt; 0) &#123; int parent = (k - 1) &gt;&gt;&gt; 1;//parentNo = (nodeNo-1)/2 Object e = queue[parent]; if (comparator.compare(x, (E) e) &gt;= 0)//调用比较器的比较方法 break; queue[k] = e; k = parent; &#125; queue[k] = x;&#125; 新加入的元素x可能会破坏小顶堆的性质，因此需要进行调整。调整的过程为** : 从k指定的位置开始，将x逐层与当前点的parent进行比较并交换，直到满足x &gt;= queue[parent]为止**。注意这里的比较可以是元素的自然顺序，也可以是依靠比较器的顺序。 element()和peek()element()和peek()的语义完全相同，都是获取但不删除队首元素，也就是队列中权值最小的那个元素，二者唯一的区别是当方法失败时前者抛出异常，后者返回null。根据小顶堆的性质，堆顶那个元素就是全局最小的那个；由于堆用数组表示，根据下标关系，0下标处的那个元素既是堆顶元素。所以直接返回数组0下标处的那个元素即可。 代码也就非常简洁: 123456//peek()public E peek() &#123; if (size == 0) return null; return (E) queue[0];//0下标处的那个元素就是最小的那个&#125; remove()和poll()remove()和poll()方法的语义也完全相同，都是获取并删除队首元素，区别是当方法失败时前者抛出异常，后者返回null。由于删除操作会改变队列的结构，为维护小顶堆的性质，需要进行必要的调整。 123456789101112public E poll() &#123; if (size == 0) return null; int s = --size; modCount++; E result = (E) queue[0];//0下标处的那个元素就是最小的那个 E x = (E) queue[s]; queue[s] = null; if (s != 0) siftDown(0, x);//调整 return result;&#125; 上述代码首先记录0下标处的元素，并用最后一个元素替换0下标位置的元素，之后调用siftDown()方法对堆进行调整，最后返回原来0下标处的那个元素(也就是最小的那个元素)。重点是siftDown(int k, E x)方法，该方法的作用是从k指定的位置开始，将x逐层向下与当前点的左右孩子中较小的那个交换，直到x小于或等于左右孩子中的任何一个为止。 123456789101112131415161718//siftDown()private void siftDown(int k, E x) &#123; int half = size &gt;&gt;&gt; 1; while (k &lt; half) &#123; //首先找到左右孩子中较小的那个，记录到c里，并用child记录其下标 int child = (k &lt;&lt; 1) + 1;//leftNo = parentNo*2+1 Object c = queue[child]; int right = child + 1; if (right &lt; size &amp;&amp; comparator.compare((E) c, (E) queue[right]) &gt; 0) c = queue[child = right]; if (comparator.compare(x, (E) c) &lt;= 0) break; queue[k] = c;//然后用c取代原来的值 k = child; &#125; queue[k] = x;&#125; remove(Object o)remove(Object o)方法用于删除队列中跟o相等的某一个元素(如果有多个相等，只删除一个)，该方法不是Queue接口内的方法，而是Collection接口的方法。由于删除操作会改变队列结构，所以要进行调整；又由于删除元素的位置可能是任意的，所以调整过程比其它函数稍加繁琐。具体来说，remove(Object o)可以分为2种情况: 1. 删除的是最后一个元素。直接删除即可，不需要调整。2. 删除的不是最后一个元素，从删除点开始以最后一个元素为参照调用一次siftDown()即可。此处不再赘述。 具体代码如下: 1234567891011121314151617//remove(Object o)public boolean remove(Object o) &#123;\t//通过遍历数组的方式找到第一个满足o.equals(queue[i])元素的下标 int i = indexOf(o); if (i == -1) return false; int s = --size; if (s == i) //情况1 queue[i] = null; else &#123; E moved = (E) queue[s]; queue[s] = null; siftDown(i, moved);//情况2 ...... &#125; return true;&#125; 参考 深入理解Java PriorityQueue 结合源码对PriorityQueue进行讲解 http://www.cnblogs.com/CarpenterLee/p/5488070.html","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"4.Collection - Stack & Queue 源码解析","path":"/2023/12/25/4-Collection-Stack-Queue-源码解析/","content":"本文主要对Collection - Stack &amp; Queue进行源码解析。 Stack &amp; Queue概述Java里有一个叫做Stack的类，却没有叫做Queue的类(它是个接口名字)。当需要使用栈时，Java已不推荐使用Stack，而是推荐使用更高效的ArrayDeque；既然Queue只是一个接口，当需要使用队列时也就首选ArrayDeque了(次选是LinkedList)。 QueueQueue接口继承自Collection接口，除了最基本的Collection的方法之外，它还支持额外的insertion, extraction和inspection操作。这里有两组格式，共6个方法，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。 Throws exception Returns special value Insert add(e) offer(e) Remove remove() poll() Examine element() peek() DequeDeque是”double ended queue”, 表示双向的队列，英文读作”deck”. Deque 继承自 Queue接口，除了支持Queue的方法之外，还支持insert, remove和examine操作，由于Deque是双向的，所以可以对队列的头和尾都进行操作，它同时也支持两组格式，一组是抛出异常的实现；另外一组是返回值的实现(没有则返回null)。共12个方法如下: First Element - Head Last Element - Tail Throws exception Special value Throws exception Special value Insert addFirst(e) offerFirst(e) addLast(e) offerLast(e) Remove removeFirst() pollFirst() removeLast() pollLast() Examine getFirst() peekFirst() getLast() peekLast() 当把Deque当做FIFO的queue来使用时，元素是从deque的尾部添加，从头部进行删除的； 所以deque的部分方法是和queue是等同的。具体如下: Queue Method Equivalent Deque Method add(e) addLast(e) offer(e) offerLast(e) remove() removeFirst() poll() pollFirst() element() getFirst() peek() peekFirst() Deque的含义是“double ended queue”，即双端队列，它既可以当作栈使用，也可以当作队列使用。下表列出了Deque与Queue相对应的接口: Queue Method Equivalent Deque Method 说明 add(e) addLast(e) 向队尾插入元素，失败则抛出异常 offer(e) offerLast(e) 向队尾插入元素，失败则返回false remove() removeFirst() 获取并删除队首元素，失败则抛出异常 poll() pollFirst() 获取并删除队首元素，失败则返回null element() getFirst() 获取但不删除队首元素，失败则抛出异常 peek() peekFirst() 获取但不删除队首元素，失败则返回null 下表列出了Deque与Stack对应的接口: Stack Method Equivalent Deque Method 说明 push(e) addFirst(e) 向栈顶插入元素，失败则抛出异常 无 offerFirst(e) 向栈顶插入元素，失败则返回false pop() removeFirst() 获取并删除栈顶元素，失败则抛出异常 无 pollFirst() 获取并删除栈顶元素，失败则返回null peek() getFirst() 获取但不删除栈顶元素，失败则抛出异常 无 peekFirst() 获取但不删除栈顶元素，失败则返回null 上面两个表共定义了Deque的12个接口。添加，删除，取值都有两套接口，它们功能相同，区别是对失败情况的处理不同。一套接口遇到失败就会抛出异常，另一套遇到失败会返回特殊值(false或null)。除非某种实现对容量有限制，大多数情况下，添加操作是不会失败的。虽然*Deque*的接口有12个之多，但无非就是对容器的两端进行操作，或添加，或删除，或查看。明白了这一点讲解起来就会非常简单。 ArrayDeque和LinkedList是Deque的两个通用实现，由于官方更推荐使用AarryDeque用作栈和队列，加之上一篇已经讲解过LinkedList，本文将着重讲解ArrayDeque的具体实现。 从名字可以看出ArrayDeque底层通过数组实现，为了满足可以同时在数组两端插入或删除元素的需求，该数组还必须是循环的，即**循环数组(circular array)*，也就是说数组的任何一点都可能被看作起点或者终点。ArrayDeque*是非线程安全的(not thread-safe)，当多个线程同时使用的时候，需要程序员手动同步；另外，该容器不允许放入null元素。 上图中我们看到，**head指向首端第一个有效元素，tail指向尾端第一个可以插入元素的空位**。因为是循环数组，所以head不一定总等于0，tail也不一定总是比head大。 方法剖析addFirst()addFirst(E e)的作用是在Deque的首端插入元素，也就是在head的前面插入元素，在空间足够且下标没有越界的情况下，只需要将elements[--head] = e即可。 实际需要考虑: 1.空间是否够用，以及2.下标是否越界的问题。上图中，如果head为0之后接着调用addFirst()，虽然空余空间还够用，但head为-1，下标越界了。下列代码很好的解决了这两个问题。 12345678//addFirst(E e)public void addFirst(E e) &#123; if (e == null)//不允许放入null throw new NullPointerException(); elements[head = (head - 1) &amp; (elements.length - 1)] = e;//2.下标是否越界 if (head == tail)//1.空间是否够用 doubleCapacity();//扩容&#125; 上述代码我们看到，空间问题是在插入之后解决的，因为tail总是指向下一个可插入的空位，也就意味着elements数组至少有一个空位，所以插入元素的时候不用考虑空间问题。 下标越界的处理解决起来非常简单，head = (head - 1) &amp; (elements.length - 1)就可以了，这段代码相当于取余，同时解决了head为负值的情况。因为elements.length必需是2的指数倍，elements - 1就是二进制低位全1，跟head - 1相与之后就起到了取模的作用，如果head - 1为负数(其实只可能是-1)，则相当于对其取相对于elements.length的补码。 下面再说说扩容函数doubleCapacity()，其逻辑是申请一个更大的数组(原数组的两倍)，然后将原数组复制过去。过程如下图所示: 图中我们看到，复制分两次进行，第一次复制head右边的元素，第二次复制head左边的元素。 12345678910111213141516//doubleCapacity()private void doubleCapacity() &#123; assert head == tail; int p = head; int n = elements.length; int r = n - p; // head右边元素的个数 int newCapacity = n &lt;&lt; 1;//原空间的2倍 if (newCapacity &lt; 0) throw new IllegalStateException(&quot;Sorry, deque too big&quot;); Object[] a = new Object[newCapacity]; System.arraycopy(elements, p, a, 0, r);//复制右半部分，对应上图中绿色部分 System.arraycopy(elements, 0, a, r, p);//复制左半部分，对应上图中灰色部分 elements = (E[])a; head = 0; tail = n;&#125; addLast()addLast(E e)的作用是在Deque的尾端插入元素，也就是在tail的位置插入元素，由于tail总是指向下一个可以插入的空位，因此只需要elements[tail] = e;即可。插入完成后再检查空间，如果空间已经用光，则调用doubleCapacity()进行扩容。 1234567public void addLast(E e) &#123; if (e == null)//不允许放入null throw new NullPointerException(); elements[tail] = e;//赋值 if ( (tail = (tail + 1) &amp; (elements.length - 1)) == head)//下标越界处理 doubleCapacity();//扩容&#125; 下标越界处理方式addFirt()中已经讲过，不再赘述。 pollFirst()pollFirst()的作用是删除并返回Deque首端元素，也即是head位置处的元素。如果容器不空，只需要直接返回elements[head]即可，当然还需要处理下标的问题。由于ArrayDeque中不允许放入null，当elements[head] == null时，意味着容器为空。 123456789public E pollFirst() &#123; int h = head; E result = elements[head]; if (result == null)//null值意味着deque为空 return null; elements[h] = null;//let GC work head = (head + 1) &amp; (elements.length - 1);//下标越界处理 return result;&#125; pollLast()pollLast()的作用是删除并返回Deque尾端元素，也即是tail位置前面的那个元素。 123456789public E pollLast() &#123; int t = (tail - 1) &amp; (elements.length - 1);//tail的上一个位置是最后一个元素 E result = elements[t]; if (result == null)//null值意味着deque为空 return null; elements[t] = null;//let GC work tail = t; return result;&#125; peekFirst()peekFirst()的作用是返回但不删除Deque首端元素，也即是head位置处的元素，直接返回elements[head]即可。 123public E peekFirst() &#123; return elements[head]; // elements[head] is null if deque empty&#125; peekLast()peekLast()的作用是返回但不删除Deque尾端元素，也即是tail位置前面的那个元素。 123public E peekLast() &#123; return elements[(tail - 1) &amp; (elements.length - 1)];&#125;","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"3.Collection - LinkedList源码解析","path":"/2023/12/25/3-Collection-LinkedList源码解析/","content":"本文主要对Collection - LinkedList进行源码解析。 概述LinkedList同时实现了List接口和Deque接口，也就是说它既可以看作一个顺序容器，又可以看作一个队列(Queue)，同时又可以看作一个栈(Stack)。这样看来，LinkedList简直就是个全能冠军。当你需要使用栈或者队列时，可以考虑使用LinkedList，一方面是因为Java官方已经声明不建议使用Stack类，更遗憾的是，Java里根本没有一个叫做Queue的类(它是个接口名字)。关于栈或队列，现在的首选是ArrayDeque，它有着比LinkedList(当作栈或队列使用时)有着更好的性能。 LinkedList的实现方式决定了所有跟下标相关的操作都是线性时间，而在首段或者末尾删除元素只需要常数时间。为追求效率LinkedList没有实现同步(synchronized)，如果需要多个线程并发访问，可以先采用Collections.synchronizedList()方法对其进行包装。 LinkedList实现底层数据结构LinkedList底层通过双向链表实现，本节将着重讲解插入和删除元素时双向链表的维护过程，也即是之间解跟List接口相关的函数，而将Queue和Stack以及Deque相关的知识放在下一节讲。双向链表的每个节点用内部类Node表示。LinkedList通过first和last引用分别指向链表的第一个和最后一个元素。注意这里没有所谓的哑元，当链表为空的时候first和last都指向null。 123456789101112131415transient int size = 0;/** * Pointer to first node. * Invariant: (first == null &amp;&amp; last == null) || * (first.prev == null &amp;&amp; first.item != null) */transient Node&lt;E&gt; first;/** * Pointer to last node. * Invariant: (first == null &amp;&amp; last == null) || * (last.next == null &amp;&amp; last.item != null) */transient Node&lt;E&gt; last; 其中Node是私有的内部类: 1234567891011private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 构造函数123456789101112131415161718/** * Constructs an empty list. */public LinkedList() &#123;&#125;/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection&#x27;s * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public LinkedList(Collection&lt;? extends E&gt; c) &#123; this(); addAll(c);&#125; getFirst(), getLast()获取第一个元素， 和获取最后一个元素: 12345678910111213141516171819202122232425/** * Returns the first element in this list. * * @return the first element in this list * @throws NoSuchElementException if this list is empty */public E getFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return f.item;&#125;/** * Returns the last element in this list. * * @return the last element in this list * @throws NoSuchElementException if this list is empty */public E getLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return l.item;&#125; removeFirst(), removeLast(), remove(e), remove(index)remove()方法也有两个版本，一个是删除跟指定元素相等的第一个元素remove(Object o)，另一个是删除指定下标处的元素remove(int index)。 删除元素 - 指的是删除第一次出现的这个元素, 如果没有这个元素，则返回false；判断的依据是equals方法， 如果equals，则直接unlink这个node；由于LinkedList可存放null元素，故也可以删除第一次出现null的元素； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/** * Removes the first occurrence of the specified element from this list, * if it is present. If this list does not contain the element, it is * unchanged. More formally, removes the element with the lowest index * &#123;@code i&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt; * (if such an element exists). Returns &#123;@code true&#125; if this list * contained the specified element (or equivalently, if this list * changed as a result of the call). * * @param o element to be removed from this list, if present * @return &#123;@code true&#125; if this list contained the specified element */public boolean remove(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125;/** * Unlinks non-null node x. */E unlink(Node&lt;E&gt; x) &#123; // assert x != null; final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; if (prev == null) &#123;// 第一个元素 first = next; &#125; else &#123; prev.next = next; x.prev = null; &#125; if (next == null) &#123;// 最后一个元素 last = prev; &#125; else &#123; next.prev = prev; x.next = null; &#125; x.item = null; // GC size--; modCount++; return element;&#125; remove(int index)使用的是下标计数， 只需要判断该index是否有元素即可，如果有则直接unlink这个node。 12345678910111213/** * Removes the element at the specified position in this list. Shifts any * subsequent elements to the left (subtracts one from their indices). * Returns the element that was removed from the list. * * @param index the index of the element to be removed * @return the element previously at the specified position * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125; 删除head元素: 1234567891011121314151617181920212223242526272829303132/** * Removes and returns the first element from this list. * * @return the first element from this list * @throws NoSuchElementException if this list is empty */public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125;/** * Unlinks non-null first node f. */private E unlinkFirst(Node&lt;E&gt; f) &#123; // assert f == first &amp;&amp; f != null; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125; 删除last元素: 12345678910111213141516171819202122232425262728293031/** * Removes and returns the last element from this list. * * @return the last element from this list * @throws NoSuchElementException if this list is empty */ public E removeLast() &#123; final Node&lt;E&gt; l = last; if (l == null) throw new NoSuchElementException(); return unlinkLast(l); &#125; /** * Unlinks non-null last node l. */ private E unlinkLast(Node&lt;E&gt; l) &#123; // assert l == last &amp;&amp; l != null; final E element = l.item; final Node&lt;E&gt; prev = l.prev; l.item = null; l.prev = null; // help GC last = prev; if (prev == null) first = null; else prev.next = null; size--; modCount++; return element; &#125; add()add()*方法有两个版本，一个是add(E e)，该方法在*LinkedList的末尾插入元素，因为有last指向链表末尾，在末尾插入元素的花费是常数时间。只需要简单修改几个相关引用即可；另一个是add(int index, E element)，该方法是在指定下表处插入元素，需要先通过线性查找找到具体位置，然后修改相关引用完成插入操作。 123456789101112131415161718192021222324252627/** * Appends the specified element to the end of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #addLast&#125;. * * @param e element to be appended to this list * @return &#123;@code true&#125; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; linkLast(e); return true;&#125;/** * Links e as last element. */void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++;&#125; add(int index, E element), 当index&#x3D;&#x3D;size时，等同于add(E e); 如果不是，则分两步: 1.先根据index找到要插入的位置,即node(index)方法；2.修改引用，完成插入操作。 1234567891011121314151617/** * Inserts the specified element at the specified position in this list. * Shifts the element currently at that position (if any) and any * subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125; 上面代码中的node(int index)函数有一点小小的trick，因为链表双向的，可以从开始往后找，也可以从结尾往前找，具体朝那个方向找取决于条件index &lt; (size &gt;&gt; 1)，也即是index是靠近前端还是后端。从这里也可以看出，linkedList通过index检索元素的效率没有arrayList高。 123456789101112131415161718/** * Returns the (non-null) Node at the specified element index. */Node&lt;E&gt; node(int index) &#123; // assert isElementIndex(index); if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; addAll()addAll(index, c) 实现方式并不是直接调用add(index,e)来实现，主要是因为效率的问题，另一个是fail-fast中modCount只会增加1次； 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * Appends all of the elements in the specified collection to the end of * this list, in the order that they are returned by the specified * collection&#x27;s iterator. The behavior of this operation is undefined if * the specified collection is modified while the operation is in * progress. (Note that this will occur if the specified collection is * this list, and it&#x27;s nonempty.) * * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; return addAll(size, c);&#125;/** * Inserts all of the elements in the specified collection into this * list, starting at the specified position. Shifts the element * currently at that position (if any) and any subsequent elements to * the right (increases their indices). The new elements will appear * in the list in the order that they are returned by the * specified collection&#x27;s iterator. * * @param index index at which to insert the first element * from the specified collection * @param c collection containing elements to be added to this list * @return &#123;@code true&#125; if this list changed as a result of the call * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified collection is null */public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; checkPositionIndex(index); Object[] a = c.toArray(); int numNew = a.length; if (numNew == 0) return false; Node&lt;E&gt; pred, succ; if (index == size) &#123; succ = null; pred = last; &#125; else &#123; succ = node(index); pred = succ.prev; &#125; for (Object o : a) &#123; @SuppressWarnings(&quot;unchecked&quot;) E e = (E) o; Node&lt;E&gt; newNode = new Node&lt;&gt;(pred, e, null); if (pred == null) first = newNode; else pred.next = newNode; pred = newNode; &#125; if (succ == null) &#123; last = pred; &#125; else &#123; pred.next = succ; succ.prev = pred; &#125; size += numNew; modCount++; return true;&#125; clear()为了让GC更快可以回收放置的元素，需要将node之间的引用关系赋空。 1234567891011121314151617181920/** * Removes all of the elements from this list. * The list will be empty after this call returns. */public void clear() &#123; // Clearing all of the links between nodes is &quot;unnecessary&quot;, but: // - helps a generational GC if the discarded nodes inhabit // more than one generation // - is sure to free memory even if there is a reachable Iterator for (Node&lt;E&gt; x = first; x != null; ) &#123; Node&lt;E&gt; next = x.next; x.item = null; x.next = null; x.prev = null; x = next; &#125; first = last = null; size = 0; modCount++;&#125; Positional Access 方法通过index获取元素 1234567891011/** * Returns the element at the specified position in this list. * * @param index index of the element to return * @return the element at the specified position in this list * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E get(int index) &#123; checkElementIndex(index); return node(index).item;&#125; 将某个位置的元素重新赋值: 12345678910111213141516/** * Replaces the element at the specified position in this list with the * specified element. * * @param index index of the element to replace * @param element element to be stored at the specified position * @return the element previously at the specified position * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E set(int index, E element) &#123; checkElementIndex(index); Node&lt;E&gt; x = node(index); E oldVal = x.item; x.item = element; return oldVal;&#125; 将元素插入到指定index位置: 1234567891011121314151617/** * Inserts the specified element at the specified position in this list. * Shifts the element currently at that position (if any) and any * subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; checkPositionIndex(index); if (index == size) linkLast(element); else linkBefore(element, node(index));&#125; 删除指定位置的元素: 12345678910111213/** * Removes the element at the specified position in this list. Shifts any * subsequent elements to the left (subtracts one from their indices). * Returns the element that was removed from the list. * * @param index the index of the element to be removed * @return the element previously at the specified position * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; checkElementIndex(index); return unlink(node(index));&#125; 其它位置的方法: 123456789101112131415161718192021222324252627282930313233/** * Tells if the argument is the index of an existing element. */private boolean isElementIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt; size;&#125;/** * Tells if the argument is the index of a valid position for an * iterator or an add operation. */private boolean isPositionIndex(int index) &#123; return index &gt;= 0 &amp;&amp; index &lt;= size;&#125;/** * Constructs an IndexOutOfBoundsException detail message. * Of the many possible refactorings of the error handling code, * this &quot;outlining&quot; performs best with both server and client VMs. */private String outOfBoundsMsg(int index) &#123; return &quot;Index: &quot;+index+&quot;, Size: &quot;+size;&#125;private void checkElementIndex(int index) &#123; if (!isElementIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125;private void checkPositionIndex(int index) &#123; if (!isPositionIndex(index)) throw new IndexOutOfBoundsException(outOfBoundsMsg(index));&#125; 查找操作查找操作的本质是查找元素的下标: 查找第一次出现的index, 如果找不到返回-1； 12345678910111213141516171819202122232425262728/** * Returns the index of the first occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the lowest index &#123;@code i&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. * * @param o element to search for * @return the index of the first occurrence of the specified element in * this list, or -1 if this list does not contain the element */public int indexOf(Object o) &#123; int index = 0; if (o == null) &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (x.item == null) return index; index++; &#125; &#125; else &#123; for (Node&lt;E&gt; x = first; x != null; x = x.next) &#123; if (o.equals(x.item)) return index; index++; &#125; &#125; return -1;&#125; 查找最后一次出现的index, 如果找不到返回-1； 12345678910111213141516171819202122232425262728/** * Returns the index of the last occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the highest index &#123;@code i&#125; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. * * @param o element to search for * @return the index of the last occurrence of the specified element in * this list, or -1 if this list does not contain the element */public int lastIndexOf(Object o) &#123; int index = size; if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (x.item == null) return index; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; index--; if (o.equals(x.item)) return index; &#125; &#125; return -1;&#125; Queue 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * Retrieves, but does not remove, the head (first element) of this list. * * @return the head of this list, or &#123;@code null&#125; if this list is empty * @since 1.5 */public E peek() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item;&#125;/** * Retrieves, but does not remove, the head (first element) of this list. * * @return the head of this list * @throws NoSuchElementException if this list is empty * @since 1.5 */public E element() &#123; return getFirst();&#125;/** * Retrieves and removes the head (first element) of this list. * * @return the head of this list, or &#123;@code null&#125; if this list is empty * @since 1.5 */public E poll() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);&#125;/** * Retrieves and removes the head (first element) of this list. * * @return the head of this list * @throws NoSuchElementException if this list is empty * @since 1.5 */public E remove() &#123; return removeFirst();&#125;/** * Adds the specified element as the tail (last element) of this list. * * @param e the element to add * @return &#123;@code true&#125; (as specified by &#123;@link Queue#offer&#125;) * @since 1.5 */public boolean offer(E e) &#123; return add(e);&#125; Deque 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144/** * Inserts the specified element at the front of this list. * * @param e the element to insert * @return &#123;@code true&#125; (as specified by &#123;@link Deque#offerFirst&#125;) * @since 1.6 */public boolean offerFirst(E e) &#123; addFirst(e); return true;&#125;/** * Inserts the specified element at the end of this list. * * @param e the element to insert * @return &#123;@code true&#125; (as specified by &#123;@link Deque#offerLast&#125;) * @since 1.6 */public boolean offerLast(E e) &#123; addLast(e); return true;&#125;/** * Retrieves, but does not remove, the first element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the first element of this list, or &#123;@code null&#125; * if this list is empty * @since 1.6 */public E peekFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : f.item; &#125;/** * Retrieves, but does not remove, the last element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the last element of this list, or &#123;@code null&#125; * if this list is empty * @since 1.6 */public E peekLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : l.item;&#125;/** * Retrieves and removes the first element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the first element of this list, or &#123;@code null&#125; if * this list is empty * @since 1.6 */public E pollFirst() &#123; final Node&lt;E&gt; f = first; return (f == null) ? null : unlinkFirst(f);&#125;/** * Retrieves and removes the last element of this list, * or returns &#123;@code null&#125; if this list is empty. * * @return the last element of this list, or &#123;@code null&#125; if * this list is empty * @since 1.6 */public E pollLast() &#123; final Node&lt;E&gt; l = last; return (l == null) ? null : unlinkLast(l);&#125;/** * Pushes an element onto the stack represented by this list. In other * words, inserts the element at the front of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #addFirst&#125;. * * @param e the element to push * @since 1.6 */public void push(E e) &#123; addFirst(e);&#125;/** * Pops an element from the stack represented by this list. In other * words, removes and returns the first element of this list. * * &lt;p&gt;This method is equivalent to &#123;@link #removeFirst()&#125;. * * @return the element at the front of this list (which is the top * of the stack represented by this list) * @throws NoSuchElementException if this list is empty * @since 1.6 */public E pop() &#123; return removeFirst();&#125;/** * Removes the first occurrence of the specified element in this * list (when traversing the list from head to tail). If the list * does not contain the element, it is unchanged. * * @param o element to be removed from this list, if present * @return &#123;@code true&#125; if the list contained the specified element * @since 1.6 */public boolean removeFirstOccurrence(Object o) &#123; return remove(o);&#125;/** * Removes the last occurrence of the specified element in this * list (when traversing the list from head to tail). If the list * does not contain the element, it is unchanged. * * @param o element to be removed from this list, if present * @return &#123;@code true&#125; if the list contained the specified element * @since 1.6 */public boolean removeLastOccurrence(Object o) &#123; if (o == null) &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (x.item == null) &#123; unlink(x); return true; &#125; &#125; &#125; else &#123; for (Node&lt;E&gt; x = last; x != null; x = x.prev) &#123; if (o.equals(x.item)) &#123; unlink(x); return true; &#125; &#125; &#125; return false;&#125; 参考 Java LinkedList源码剖析 结合源码对LinkedList进行讲解 http://www.cnblogs.com/CarpenterLee/p/5457150.html","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"2.Collection - ArrayList 源码解析","path":"/2023/12/25/2-Collection-ArrayList-源码解析/","content":"本文主要对Collection - ArrayList进行源码解析。 概述ArrayList实现了List接口，是顺序容器，即元素存放的数据与放进去的顺序相同，允许放入null元素，底层通过数组实现。除该类未实现同步外，其余跟Vector大致相同。每个ArrayList都有一个容量(capacity)，表示底层数组的实际大小，容器内存储元素的个数不能多于当前容量。当向容器中添加元素时，如果容量不足，容器会自动增大底层数组的大小。前面已经提过，Java泛型只是编译器提供的语法糖，所以这里的数组是一个Object数组，以便能够容纳任何类型的对象。 size(), isEmpty(), get(), set()方法均能在常数时间内完成，add()方法的时间开销跟插入位置有关，addAll()方法的时间开销跟添加元素的个数成正比。其余方法大都是线性时间。 为追求效率，ArrayList没有实现同步(synchronized)，如果需要多个线程并发访问，用户可以手动同步，也可使用Vector替代。 ArrayList的实现底层数据结构1234567891011121314/** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */ transient Object[] elementData; // non-private to simplify nested class access /** * The size of the ArrayList (the number of elements it contains). * * @serial */ private int size; 构造函数1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * Constructs an empty list with the specified initial capacity. * * @param initialCapacity the initial capacity of the list * @throws IllegalArgumentException if the specified initial capacity * is negative */ public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125; &#125; /** * Constructs an empty list with an initial capacity of ten. */ public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; /** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection&#x27;s * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */ public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125; &#125; 自动扩容每当向数组中添加元素时，都要去检查添加后元素的个数是否会超出当前数组的长度，如果超出，数组将会进行扩容，以满足添加数据的需求。数组扩容通过一个公开的方法ensureCapacity(int minCapacity)来实现。在实际添加大量元素前，我也可以使用ensureCapacity来手动增加ArrayList实例的容量，以减少递增式再分配的数量。 数组进行扩容时，会将老数组中的元素重新拷贝一份到新的数组中，每次数组容量的增长大约是其原容量的1.5倍。这种操作的代价是很高的，因此在实际使用时，我们应该尽量避免数组容量的扩张。当我们可预知要保存的元素的多少时，要在构造ArrayList实例时，就指定其容量，以避免数组扩容的发生。或者根据实际需求，通过调用ensureCapacity方法来手动增加ArrayList实例的容量。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * Increases the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance, if * necessary, to ensure that it can hold at least the number of elements * specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */public void ensureCapacity(int minCapacity) &#123; int minExpand = (elementData != DEFAULTCAPACITY_EMPTY_ELEMENTDATA) // any size if not default element table ? 0 // larger than default for default empty table. It&#x27;s already // supposed to be at default size. : DEFAULT_CAPACITY; if (minCapacity &gt; minExpand) &#123; ensureExplicitCapacity(minCapacity); &#125;&#125;private void ensureCapacityInternal(int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; ensureExplicitCapacity(minCapacity);&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * The maximum size of array to allocate. * Some VMs reserve some header words in an array. * Attempts to allocate larger arrays may result in * OutOfMemoryError: Requested array size exceeds VM limit */private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * @param minCapacity the desired minimum capacity */private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; add(), addAll()跟C++ 的vector不同，ArrayList没有push_back()方法，对应的方法是add(E e)，ArrayList也没有insert()方法，对应的方法是add(int index, E e)。这两个方法都是向容器中添加新元素，这可能会导致capacity不足，因此在添加元素之前，都需要进行剩余空间检查，如果需要则自动扩容。扩容操作最终是通过grow()方法完成的。 123456789101112131415161718192021222324252627282930/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;/** * Inserts the specified element at the specified position in this * list. Shifts the element currently at that position (if any) and * any subsequent elements to the right (adds one to their indices). * * @param index index at which the specified element is to be inserted * @param element element to be inserted * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public void add(int index, E element) &#123; rangeCheckForAdd(index); ensureCapacityInternal(size + 1); // Increments modCount!! System.arraycopy(elementData, index, elementData, index + 1, size - index); elementData[index] = element; size++;&#125; add(int index, E e)需要先对元素进行移动，然后完成插入操作，也就意味着该方法有着线性的时间复杂度。 addAll()方法能够一次添加多个元素，根据位置不同也有两个版本，一个是在末尾添加的addAll(Collection&lt;? extends E&gt; c)方法，一个是从指定位置开始插入的addAll(int index, Collection&lt;? extends E&gt; c)方法。跟add()方法类似，在插入之前也需要进行空间检查，如果需要则自动扩容；如果从指定位置插入，也会存在移动元素的情况。 addAll()的时间复杂度不仅跟插入元素的多少有关，也跟插入的位置相关。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * Appends all of the elements in the specified collection to the end of * this list, in the order that they are returned by the * specified collection&#x27;s Iterator. The behavior of this operation is * undefined if the specified collection is modified while the operation * is in progress. (This implies that the behavior of this call is * undefined if the specified collection is this list, and this * list is nonempty.) * * @param c collection containing elements to be added to this list * @return &lt;tt&gt;true&lt;/tt&gt; if this list changed as a result of the call * @throws NullPointerException if the specified collection is null */public boolean addAll(Collection&lt;? extends E&gt; c) &#123; Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount System.arraycopy(a, 0, elementData, size, numNew); size += numNew; return numNew != 0;&#125;/** * Inserts all of the elements in the specified collection into this * list, starting at the specified position. Shifts the element * currently at that position (if any) and any subsequent elements to * the right (increases their indices). The new elements will appear * in the list in the order that they are returned by the * specified collection&#x27;s iterator. * * @param index index at which to insert the first element from the * specified collection * @param c collection containing elements to be added to this list * @return &lt;tt&gt;true&lt;/tt&gt; if this list changed as a result of the call * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; * @throws NullPointerException if the specified collection is null */public boolean addAll(int index, Collection&lt;? extends E&gt; c) &#123; rangeCheckForAdd(index); Object[] a = c.toArray(); int numNew = a.length; ensureCapacityInternal(size + numNew); // Increments modCount int numMoved = size - index; if (numMoved &gt; 0) System.arraycopy(elementData, index, elementData, index + numNew, numMoved); System.arraycopy(a, 0, elementData, index, numNew); size += numNew; return numNew != 0;&#125; set()既然底层是一个数组ArrayList的set()方法也就变得非常简单，直接对数组的指定位置赋值即可。 123456public E set(int index, E element) &#123; rangeCheck(index);//下标越界检查 E oldValue = elementData(index); elementData[index] = element;//赋值到指定位置，复制的仅仅是引用 return oldValue;&#125; get()get()方法同样很简单，唯一要注意的是由于底层数组是Object[]，得到元素后需要进行类型转换。 1234public E get(int index) &#123; rangeCheck(index); return (E) elementData[index];//注意类型转换&#125; remove()remove()方法也有两个版本，一个是remove(int index)删除指定位置的元素，另一个是remove(Object o)删除第一个满足o.equals(elementData[index])的元素。删除操作是add()操作的逆过程，需要将删除点之后的元素向前移动一个位置。需要注意的是为了让GC起作用，必须显式的为最后一个位置赋null值。 12345678910public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; //清除该位置的引用，让GC起作用 return oldValue;&#125; 关于Java GC这里需要特别说明一下，有了垃圾收集器并不意味着一定不会有内存泄漏。对象能否被GC的依据是是否还有引用指向它，上面代码中如果不手动赋null值，除非对应的位置被其他元素覆盖，否则原来的对象就一直不会被回收。 trimToSize()ArrayList还给我们提供了将底层数组的容量调整为当前列表保存的实际元素的大小的功能。它可以通过trimToSize方法来实现。代码如下: 12345678910111213/** * Trims the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance to be the * list&#x27;s current size. An application can use this operation to minimize * the storage of an &lt;tt&gt;ArrayList&lt;/tt&gt; instance. */public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125; indexOf(), lastIndexOf()获取元素的第一次出现的index: 12345678910111213141516171819/** * Returns the index of the first occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the lowest index &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. */ public int indexOf(Object o) &#123; if (o == null) &#123; for (int i = 0; i &lt; size; i++) if (elementData[i]==null) return i; &#125; else &#123; for (int i = 0; i &lt; size; i++) if (o.equals(elementData[i])) return i; &#125; return -1; &#125; 获取元素的最后一次出现的index: 12345678910111213141516171819/** * Returns the index of the last occurrence of the specified element * in this list, or -1 if this list does not contain the element. * More formally, returns the highest index &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt;, * or -1 if there is no such index. */public int lastIndexOf(Object o) &#123; if (o == null) &#123; for (int i = size-1; i &gt;= 0; i--) if (elementData[i]==null) return i; &#125; else &#123; for (int i = size-1; i &gt;= 0; i--) if (o.equals(elementData[i])) return i; &#125; return -1;&#125; Fail-Fast机制:ArrayList也采用了快速失败的机制，通过记录modCount参数来实现。在面对并发的修改时，迭代器很快就会完全失败，而不是冒着在将来某个不确定时间发生任意不确定行为的风险。 参考 深入Java集合学习系列: ArrayList的实现原理 http://zhangshixi.iteye.com/blog/674856 Java ArrayList源码剖析 结合源码对ArrayList进行讲解 http://www.cnblogs.com/CarpenterLee/p/5419880.html","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"1.Collection 类关系图","path":"/2023/12/25/1-Collection-类关系图/","content":"本文主要介绍JDK中Collection和Map相关知识体系，后续章节将对主要对类进行源码解读。 知识体系结构 介绍容器，就是可以容纳其他Java对象的对象。*Java Collections Framework(JCF)*为Java开发者提供了通用的容器，其始于JDK 1.2，优点是: 降低编程难度 提高程序性能 提高API间的互操作性 降低学习难度 降低设计和实现相关API的难度 增加程序的重用性 Java容器里只能放对象，对于基本类型(int, long, float, double等)，需要将其包装成对象类型后(Integer, Long, Float, Double等)才能放到容器里。很多时候拆包装和解包装能够自动完成。这虽然会导致额外的性能和空间开销，但简化了设计和编程。 Collection 容器主要包括 Collection 和 Map 两种，Collection 存储着对象的集合，而 Map 存储着键值对(两个对象)的映射表。 SetTreeSet基于红黑树实现，支持有序性操作，例如根据一个范围查找元素的操作。但是查找效率不如 HashSet，HashSet 查找的时间复杂度为 O(1)，TreeSet 则为 O(logN)。 HashSet基于哈希表实现，支持快速查找，但不支持有序性操作。并且失去了元素的插入顺序信息，也就是说使用 Iterator 遍历 HashSet 得到的结果是不确定的。 LinkedHashSet具有 HashSet 的查找效率，且内部使用双向链表维护元素的插入顺序。 ListArrayList基于动态数组实现，支持随机访问。 Vector和 ArrayList 类似，但它是线程安全的。 LinkedList基于双向链表实现，只能顺序访问，但是可以快速地在链表中间插入和删除元素。不仅如此，LinkedList 还可以用作栈、队列和双向队列。 QueueLinkedList可以用它来实现双向队列。 PriorityQueue基于堆结构实现，可以用它来实现优先队列。 MapTreeMap基于红黑树实现。 HashMap基于哈希表实现。 HashTable和 HashMap 类似，但它是线程安全的，这意味着同一时刻多个线程可以同时写入 HashTable 并且不会导致数据不一致。它是遗留类，不应该去使用它。现在可以使用 ConcurrentHashMap 来支持线程安全，并且 ConcurrentHashMap 的效率会更高，因为 ConcurrentHashMap 引入了分段锁。 LinkedHashMap使用双向链表来维护元素的顺序，顺序为插入顺序或者最近最少使用(LRU)顺序。 参考内容 CarpenterLee&#x2F;JCFInternals https://github.com/CarpenterLee/JCFInternals","tags":["Java","Collection集合框架"],"categories":["Java","Collection集合框架"]},{"title":"8.Java常用机制 - SPI机制详解","path":"/2023/12/25/8-Java常用机制-SPI机制详解/","content":"SPI（Service Provider Interface），是JDK内置的一种 服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用。 什么是SPI机制SPI（Service Provider Interface），是JDK内置的一种 服务提供发现机制，可以用来启用框架扩展和替换组件，主要是被框架的开发人员使用，比如java.sql.Driver接口，其他不同厂商可以针对同一接口做出不同的实现，MySQL和PostgreSQL都有不同的实现提供给用户，而Java的SPI机制可以为某个接口寻找服务实现。Java中SPI机制主要思想是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要，其核心思想就是 解耦。 SPI整体机制图如下： 当服务的提供者提供了一种接口的实现之后，需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件，这个文件里的内容就是这个接口的具体的实现类。当其他的程序需要这个服务的时候，就可以通过查找这个jar包（一般都是以jar包做依赖）的META-INF/services/中的配置文件，配置文件中有接口的具体实现类名，可以根据这个类名进行加载实例化，就可以使用该服务了。JDK中查找服务的实现的工具类是：java.util.ServiceLoader。 SPI机制的简单示例 网上找了个例子：这里 我们现在需要使用一个内容搜索接口，搜索的实现可能是基于文件系统的搜索，也可能是基于数据库的搜索。 先定义好接口 123public interface Search &#123; public List&lt;String&gt; searchDoc(String keyword); &#125; 文件搜索实现 1234567public class FileSearch implements Search&#123; @Override public List&lt;String&gt; searchDoc(String keyword) &#123; System.out.println(&quot;文件搜索 &quot;+keyword); return null; &#125;&#125; 数据库搜索实现 1234567public class DatabaseSearch implements Search&#123; @Override public List&lt;String&gt; searchDoc(String keyword) &#123; System.out.println(&quot;数据搜索 &quot;+keyword); return null; &#125;&#125; resources 接下来可以在resources下新建META-INF&#x2F;services&#x2F;目录，然后新建接口全限定名的文件：com.cainiao.ys.spi.learn.Search，里面加上我们需要用到的实现类 1com.cainiao.ys.spi.learn.FileSearch 测试方法 12345678910public class TestCase &#123; public static void main(String[] args) &#123; ServiceLoader&lt;Search&gt; s = ServiceLoader.load(Search.class); Iterator&lt;Search&gt; iterator = s.iterator(); while (iterator.hasNext()) &#123; Search search = iterator.next(); search.searchDoc(&quot;hello world&quot;); &#125; &#125;&#125; 可以看到输出结果：文件搜索 hello world 如果在com.cainiao.ys.spi.learn.Search文件里写上两个实现类，那最后的输出结果就是两行了。 这就是因为ServiceLoader.load(Search.class)在加载某接口时，会去META-INF/services下找接口的全限定名文件，再根据里面的内容加载相应的实现类。 这就是spi的思想，接口的实现由provider实现，provider只用在提交的jar包里的META-INF/services下根据平台定义的接口新建文件，并添加进相应的实现类内容就好。 SPI机制的广泛应用SPI机制 - JDBC DriverManager 在JDBC4.0之前，我们开发有连接数据库的时候，通常会用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)这句先加载数据库相关的驱动，然后再进行获取连接等的操作。而JDBC4.0之后不需要用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动，直接获取连接就可以了，现在这种方式就是使用了Java的SPI扩展机制来实现。 JDBC接口定义首先在java中定义了接口java.sql.Driver，并没有具体的实现，具体的实现都是由不同厂商来提供的。 mysql实现在mysql的jar包mysql-connector-java-6.0.6.jar中，可以找到META-INF/services目录，该目录下会有一个名字为java.sql.Driver的文件，文件内容是com.mysql.cj.jdbc.Driver，这里面的内容就是针对Java中定义的接口的实现。 postgresql实现同样在postgresql的jar包postgresql-42.0.0.jar中，也可以找到同样的配置文件，文件内容是org.postgresql.Driver，这是postgresql对Java的java.sql.Driver的实现。 使用方法上面说了，现在使用SPI扩展来加载具体的驱动，我们在Java中写连接数据库的代码的时候，不需要再使用Class.forName(&quot;com.mysql.jdbc.Driver&quot;)来加载驱动了，而是直接使用如下代码： 123String url = &quot;jdbc:xxxx://xxxx:xxxx/xxxx&quot;;Connection conn = DriverManager.getConnection(url,username,password);..... 这里并没有涉及到spi的使用，接着看下面的解析。 源码实现上面的使用方法，就是我们普通的连接数据库的代码，并没有涉及到SPI的东西，但是有一点我们可以确定的是，我们没有写有关具体驱动的硬编码Class.forName(&quot;com.mysql.jdbc.Driver&quot;)！ 上面的代码可以直接获取数据库连接进行操作，但是跟SPI有啥关系呢？上面代码没有了加载驱动的代码，我们怎么去确定使用哪个数据库连接的驱动呢？这里就涉及到使用Java的SPI扩展机制来查找相关驱动的东西了，关于驱动的查找其实都在DriverManager中，DriverManager是Java中的实现，用来获取数据库连接，在DriverManager中有一个静态代码块如下： 1234static &#123; loadInitialDrivers(); println(&quot;JDBC DriverManager initialized&quot;);&#125; 可以看到是加载实例化驱动的，接着看loadInitialDrivers方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static void loadInitialDrivers() &#123; String drivers; try &#123; drivers = AccessController.doPrivileged(new PrivilegedAction&lt;String&gt;() &#123; public String run() &#123; return System.getProperty(&quot;jdbc.drivers&quot;); &#125; &#125;); &#125; catch (Exception ex) &#123; drivers = null; &#125; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; //使用SPI的ServiceLoader来加载接口的实现 ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator(); try&#123; while(driversIterator.hasNext()) &#123; driversIterator.next(); &#125; &#125; catch(Throwable t) &#123; // Do nothing &#125; return null; &#125; &#125;); println(&quot;DriverManager.initialize: jdbc.drivers = &quot; + drivers); if (drivers == null || drivers.equals(&quot;&quot;)) &#123; return; &#125; String[] driversList = drivers.split(&quot;:&quot;); println(&quot;number of Drivers:&quot; + driversList.length); for (String aDriver : driversList) &#123; try &#123; println(&quot;DriverManager.Initialize: loading &quot; + aDriver); Class.forName(aDriver, true, ClassLoader.getSystemClassLoader()); &#125; catch (Exception ex) &#123; println(&quot;DriverManager.Initialize: load failed: &quot; + ex); &#125; &#125;&#125; 上面的代码主要步骤是： 从系统变量中获取有关驱动的定义。 使用SPI来获取驱动的实现。 遍历使用SPI获取到的具体实现，实例化各个实现类。 根据第一步获取到的驱动列表来实例化具体实现类。 我们主要关注2,3步，这两步是SPI的用法，首先看第二步，使用SPI来获取驱动的实现，对应的代码是： 1ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class); 这里没有去META-INF/services目录下查找配置文件，也没有加载具体实现类，做的事情就是封装了我们的接口类型和类加载器，并初始化了一个迭代器。 接着看第三步，遍历使用SPI获取到的具体实现，实例化各个实现类，对应的代码如下： 123456//获取迭代器Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();//遍历所有的驱动实现while(driversIterator.hasNext()) &#123; driversIterator.next();&#125; 在遍历的时候，首先调用driversIterator.hasNext()方法，这里会搜索classpath下以及jar包中所有的META-INF/services目录下的java.sql.Driver文件，并找到文件中的实现类的名字，此时并没有实例化具体的实现类（ServiceLoader具体的源码实现在下面）。 然后是调用driversIterator.next();方法，此时就会根据驱动名字具体实例化各个实现类了。现在驱动就被找到并实例化了。 可以看下截图，我在测试项目中添加了两个jar包，mysql-connector-java-6.0.6.jar和postgresql-42.0.0.0.jar，跟踪到DriverManager中之后： 可以看到此时迭代器中有两个驱动，mysql和postgresql的都被加载了。 SPI机制 - Common-Logging common-logging（也称Jakarta Commons Logging，缩写 JCL）是常用的日志库门面，具体日志库相关可以看这篇常用开发库 - 日志类库详解。我们看下它是怎么解耦的。 首先，日志实例是通过LogFactory的getLog(String)方法创建的： 123public static getLog(Class clazz) throws LogConfigurationException &#123; return getFactory().getInstance(clazz);&#125; LogFatory是一个抽象类，它负责加载具体的日志实现，分析其Factory.getFactory()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235public static org.apache.commons.logging.LogFactory getFactory() throws LogConfigurationException &#123; // Identify the class loader we will be using ClassLoader contextClassLoader = getContextClassLoaderInternal(); if (contextClassLoader == null) &#123; // This is an odd enough situation to report about. This // output will be a nuisance on JDK1.1, as the system // classloader is null in that environment. if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;Context classloader is null.&quot;); &#125; &#125; // Return any previously registered factory for this class loader org.apache.commons.logging.LogFactory factory = getCachedFactory(contextClassLoader); if (factory != null) &#123; return factory; &#125; if (isDiagnosticsEnabled()) &#123; logDiagnostic( &quot;[LOOKUP] LogFactory implementation requested for the first time for context classloader &quot; + objectId(contextClassLoader)); logHierarchy(&quot;[LOOKUP] &quot;, contextClassLoader); &#125; // Load properties file. // // If the properties file exists, then its contents are used as // &quot;attributes&quot; on the LogFactory implementation class. One particular // property may also control which LogFactory concrete subclass is // used, but only if other discovery mechanisms fail.. // // As the properties file (if it exists) will be used one way or // another in the end we may as well look for it first. // classpath根目录下寻找commons-logging.properties Properties props = getConfigurationFile(contextClassLoader, FACTORY_PROPERTIES); // Determine whether we will be using the thread context class loader to // load logging classes or not by checking the loaded properties file (if any). // classpath根目录下commons-logging.properties是否配置use_tccl ClassLoader baseClassLoader = contextClassLoader; if (props != null) &#123; String useTCCLStr = props.getProperty(TCCL_KEY); if (useTCCLStr != null) &#123; // The Boolean.valueOf(useTCCLStr).booleanValue() formulation // is required for Java 1.2 compatibility. if (Boolean.valueOf(useTCCLStr).booleanValue() == false) &#123; // Don&#x27;t use current context classloader when locating any // LogFactory or Log classes, just use the class that loaded // this abstract class. When this class is deployed in a shared // classpath of a container, it means webapps cannot deploy their // own logging implementations. It also means that it is up to the // implementation whether to load library-specific config files // from the TCCL or not. baseClassLoader = thisClassLoader; &#125; &#125; &#125; // 这里真正开始决定使用哪个factory // 首先，尝试查找vm系统属性org.apache.commons.logging.LogFactory，其是否指定factory // Determine which concrete LogFactory subclass to use. // First, try a global system property if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] Looking for system property [&quot; + FACTORY_PROPERTY + &quot;] to define the LogFactory subclass to use...&quot;); &#125; try &#123; String factoryClass = getSystemProperty(FACTORY_PROPERTY, null); if (factoryClass != null) &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] Creating an instance of LogFactory class &#x27;&quot; + factoryClass + &quot;&#x27; as specified by system property &quot; + FACTORY_PROPERTY); &#125; factory = newFactory(factoryClass, baseClassLoader, contextClassLoader); &#125; else &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] No system property [&quot; + FACTORY_PROPERTY + &quot;] defined.&quot;); &#125; &#125; &#125; catch (SecurityException e) &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] A security exception occurred while trying to create an&quot; + &quot; instance of the custom factory class&quot; + &quot;: [&quot; + trim(e.getMessage()) + &quot;]. Trying alternative implementations...&quot;); &#125; // ignore &#125; catch (RuntimeException e) &#123; // This is not consistent with the behaviour when a bad LogFactory class is // specified in a services file. // // One possible exception that can occur here is a ClassCastException when // the specified class wasn&#x27;t castable to this LogFactory type. if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] An exception occurred while trying to create an&quot; + &quot; instance of the custom factory class&quot; + &quot;: [&quot; + trim(e.getMessage()) + &quot;] as specified by a system property.&quot;); &#125; throw e; &#125; // 第二，尝试使用java spi服务发现机制，载META-INF/services下寻找org.apache.commons.logging.LogFactory实现 // Second, try to find a service by using the JDK1.3 class // discovery mechanism, which involves putting a file with the name // of an interface class in the META-INF/services directory, where the // contents of the file is a single line specifying a concrete class // that implements the desired interface. if (factory == null) &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] Looking for a resource file of name [&quot; + SERVICE_ID + &quot;] to define the LogFactory subclass to use...&quot;); &#125; try &#123; // META-INF/services/org.apache.commons.logging.LogFactory, SERVICE_ID final InputStream is = getResourceAsStream(contextClassLoader, SERVICE_ID); if (is != null) &#123; // This code is needed by EBCDIC and other strange systems. // It&#x27;s a fix for bugs reported in xerces BufferedReader rd; try &#123; rd = new BufferedReader(new InputStreamReader(is, &quot;UTF-8&quot;)); &#125; catch (java.io.UnsupportedEncodingException e) &#123; rd = new BufferedReader(new InputStreamReader(is)); &#125; String factoryClassName = rd.readLine(); rd.close(); if (factoryClassName != null &amp;&amp; !&quot;&quot;.equals(factoryClassName)) &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] Creating an instance of LogFactory class &quot; + factoryClassName + &quot; as specified by file &#x27;&quot; + SERVICE_ID + &quot;&#x27; which was present in the path of the context classloader.&quot;); &#125; factory = newFactory(factoryClassName, baseClassLoader, contextClassLoader); &#125; &#125; else &#123; // is == null if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] No resource file with name &#x27;&quot; + SERVICE_ID + &quot;&#x27; found.&quot;); &#125; &#125; &#125; catch (Exception ex) &#123; // note: if the specified LogFactory class wasn&#x27;t compatible with LogFactory // for some reason, a ClassCastException will be caught here, and attempts will // continue to find a compatible class. if (isDiagnosticsEnabled()) &#123; logDiagnostic( &quot;[LOOKUP] A security exception occurred while trying to create an&quot; + &quot; instance of the custom factory class&quot; + &quot;: [&quot; + trim(ex.getMessage()) + &quot;]. Trying alternative implementations...&quot;); &#125; // ignore &#125; &#125; // 第三，尝试从classpath根目录下的commons-logging.properties中查找org.apache.commons.logging.LogFactory属性指定的factory // Third try looking into the properties file read earlier (if found) if (factory == null) &#123; if (props != null) &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic( &quot;[LOOKUP] Looking in properties file for entry with key &#x27;&quot; + FACTORY_PROPERTY + &quot;&#x27; to define the LogFactory subclass to use...&quot;); &#125; String factoryClass = props.getProperty(FACTORY_PROPERTY); if (factoryClass != null) &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic( &quot;[LOOKUP] Properties file specifies LogFactory subclass &#x27;&quot; + factoryClass + &quot;&#x27;&quot;); &#125; factory = newFactory(factoryClass, baseClassLoader, contextClassLoader); // TODO: think about whether we need to handle exceptions from newFactory &#125; else &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] Properties file has no entry specifying LogFactory subclass.&quot;); &#125; &#125; &#125; else &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic(&quot;[LOOKUP] No properties file available to determine&quot; + &quot; LogFactory subclass from..&quot;); &#125; &#125; &#125; // 最后，使用后备factory实现，org.apache.commons.logging.impl.LogFactoryImpl // Fourth, try the fallback implementation class if (factory == null) &#123; if (isDiagnosticsEnabled()) &#123; logDiagnostic( &quot;[LOOKUP] Loading the default LogFactory implementation &#x27;&quot; + FACTORY_DEFAULT + &quot;&#x27; via the same classloader that loaded this LogFactory&quot; + &quot; class (ie not looking in the context classloader).&quot;); &#125; // Note: unlike the above code which can try to load custom LogFactory // implementations via the TCCL, we don&#x27;t try to load the default LogFactory // implementation via the context classloader because: // * that can cause problems (see comments in newFactory method) // * no-one should be customising the code of the default class // Yes, we do give up the ability for the child to ship a newer // version of the LogFactoryImpl class and have it used dynamically // by an old LogFactory class in the parent, but that isn&#x27;t // necessarily a good idea anyway. factory = newFactory(FACTORY_DEFAULT, thisClassLoader, contextClassLoader); &#125; if (factory != null) &#123; /** * Always cache using context class loader. */ cacheFactory(contextClassLoader, factory); if (props != null) &#123; Enumeration names = props.propertyNames(); while (names.hasMoreElements()) &#123; String name = (String) names.nextElement(); String value = props.getProperty(name); factory.setAttribute(name, value); &#125; &#125; &#125; return factory;&#125; 可以看出，抽象类LogFactory加载具体实现的步骤如下： 从vm系统属性org.apache.commons.logging.LogFactory 使用SPI服务发现机制，发现org.apache.commons.logging.LogFactory的实现 查找classpath根目录commons-logging.properties的org.apache.commons.logging.LogFactory属性是否指定factory实现 使用默认factory实现，org.apache.commons.logging.impl.LogFactoryImpl LogFactory的getLog()方法返回类型是org.apache.commons.logging.Log接口，提供了从trace到fatal方法。可以确定，如果日志实现提供者只要实现该接口，并且使用继承自org.apache.commons.logging.LogFactory的子类创建Log，必然可以构建一个松耦合的日志系统。 SPI机制 - 插件体系 其实最具spi思想的应该属于插件开发，我们项目中也用到的这种思想，后面再说，这里具体说一下eclipse的插件思想。 Eclipse使用OSGi作为插件系统的基础，动态添加新插件和停止现有插件，以动态的方式管理组件生命周期。 一般来说，插件的文件结构必须在指定目录下包含以下三个文件： META-INF/MANIFEST.MF: 项目基本配置信息，版本、名称、启动器等 build.properties: 项目的编译配置信息，包括，源代码路径、输出路径 plugin.xml：插件的操作配置信息，包含弹出菜单及点击菜单后对应的操作执行类等 当eclipse启动时，会遍历plugins文件夹中的目录，扫描每个插件的清单文件MANIFEST.MF，并建立一个内部模型来记录它所找到的每个插件的信息，就实现了动态添加新的插件。 这也意味着是eclipse制定了一系列的规则，像是文件结构、类型、参数等。插件开发者遵循这些规则去开发自己的插件，eclipse并不需要知道插件具体是怎样开发的，只需要在启动的时候根据配置文件解析、加载到系统里就好了，是spi思想的一种体现。 SPI机制 - Spring中SPI机制在springboot的自动装配过程中，最终会加载META-INF/spring.factories文件，而加载的过程是由SpringFactoriesLoader加载的。从CLASSPATH下的每个Jar包中搜寻所有META-INF/spring.factories配置文件，然后将解析properties文件，找到指定名称的配置后返回。需要注意的是，其实这里不仅仅是会去ClassPath路径下查找，会扫描所有路径下的Jar包，只不过这个文件只会在Classpath下的jar包中。 1234567891011121314151617181920public static final String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;;// spring.factories文件的格式为：key=value1,value2,value3// 从所有的jar包中找到META-INF/spring.factories文件// 然后从文件中解析出key=factoryClass类名称的所有value值public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); // 取得资源文件的URL Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); List&lt;String&gt; result = new ArrayList&lt;String&gt;(); // 遍历所有的URL while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); // 根据资源文件URL解析properties文件，得到对应的一组@Configuration类 Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); // 组装数据，并返回 result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result;&#125; SPI机制深入理解 提示 接下来，我们深入理解下SPI相关内容 SPI机制通常怎么使用看完上面的几个例子解析，应该都能知道大概的流程了： 有关组织或者公司定义标准。 具体厂商或者框架开发者实现。 程序猿使用。 定义标准定义标准，就是定义接口。比如接口java.sql.Driver 具体厂商或者框架开发者实现厂商或者框架开发者开发具体的实现： 在META-INF/services目录下定义一个名字为接口全限定名的文件，比如java.sql.Driver文件，文件内容是具体的实现名字，比如me.cxis.sql.MyDriver。 写具体的实现me.cxis.sql.MyDriver，都是对接口Driver的实现。 程序猿使用我们会引用具体厂商的jar包来实现我们的功能： 12345678ServiceLoader&lt;Driver&gt; loadedDrivers = ServiceLoader.load(Driver.class);//获取迭代器Iterator&lt;Driver&gt; driversIterator = loadedDrivers.iterator();//遍历while(driversIterator.hasNext()) &#123; driversIterator.next(); //可以做具体的业务逻辑&#125; 使用规范最后总结一下jdk spi需要遵循的规范 SPI和API的区别是什么 这里实际包含两个问题，第一个SPI和API的区别？第二个什么时候用API，什么时候用SPI？ SPI - “接口”位于“调用方”所在的“包”中 概念上更依赖调用方。 组织上位于调用方所在的包中。 实现位于独立的包中。 常见的例子是：插件模式的插件。 API - “接口”位于“实现方”所在的“包”中 概念上更接近实现方。 组织上位于实现方所在的包中。 实现和接口在一个包中。 参考： difference-between-spi-and-api在新窗口打开 设计原则：小议 SPI 和 API在新窗口打开 SPI机制实现原理不妨看下JDK中ServiceLoader&lt;S&gt;方法的具体实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259//ServiceLoader实现了Iterable接口，可以遍历所有的服务实现者public final class ServiceLoader&lt;S&gt; implements Iterable&lt;S&gt;&#123; //查找配置文件的目录 private static final String PREFIX = &quot;META-INF/services/&quot;; //表示要被加载的服务的类或接口 private final Class&lt;S&gt; service; //这个ClassLoader用来定位，加载，实例化服务提供者 private final ClassLoader loader; // 访问控制上下文 private final AccessControlContext acc; // 缓存已经被实例化的服务提供者，按照实例化的顺序存储 private LinkedHashMap&lt;String,S&gt; providers = new LinkedHashMap&lt;&gt;(); // 迭代器 private LazyIterator lookupIterator; //重新加载，就相当于重新创建ServiceLoader了，用于新的服务提供者安装到正在运行的Java虚拟机中的情况。 public void reload() &#123; //清空缓存中所有已实例化的服务提供者 providers.clear(); //新建一个迭代器，该迭代器会从头查找和实例化服务提供者 lookupIterator = new LazyIterator(service, loader); &#125; //私有构造器 //使用指定的类加载器和服务创建服务加载器 //如果没有指定类加载器，使用系统类加载器，就是应用类加载器。 private ServiceLoader(Class&lt;S&gt; svc, ClassLoader cl) &#123; service = Objects.requireNonNull(svc, &quot;Service interface cannot be null&quot;); loader = (cl == null) ? ClassLoader.getSystemClassLoader() : cl; acc = (System.getSecurityManager() != null) ? AccessController.getContext() : null; reload(); &#125; //解析失败处理的方法 private static void fail(Class&lt;?&gt; service, String msg, Throwable cause) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg, cause); &#125; private static void fail(Class&lt;?&gt; service, String msg) throws ServiceConfigurationError &#123; throw new ServiceConfigurationError(service.getName() + &quot;: &quot; + msg); &#125; private static void fail(Class&lt;?&gt; service, URL u, int line, String msg) throws ServiceConfigurationError &#123; fail(service, u + &quot;:&quot; + line + &quot;: &quot; + msg); &#125; //解析服务提供者配置文件中的一行 //首先去掉注释校验，然后保存 //返回下一行行号 //重复的配置项和已经被实例化的配置项不会被保存 private int parseLine(Class&lt;?&gt; service, URL u, BufferedReader r, int lc, List&lt;String&gt; names) throws IOException, ServiceConfigurationError &#123; //读取一行 String ln = r.readLine(); if (ln == null) &#123; return -1; &#125; //#号代表注释行 int ci = ln.indexOf(&#x27;#&#x27;); if (ci &gt;= 0) ln = ln.substring(0, ci); ln = ln.trim(); int n = ln.length(); if (n != 0) &#123; if ((ln.indexOf(&#x27; &#x27;) &gt;= 0) || (ln.indexOf(&#x27;\\t&#x27;) &gt;= 0)) fail(service, u, lc, &quot;Illegal configuration-file syntax&quot;); int cp = ln.codePointAt(0); if (!Character.isJavaIdentifierStart(cp)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); for (int i = Character.charCount(cp); i &lt; n; i += Character.charCount(cp)) &#123; cp = ln.codePointAt(i); if (!Character.isJavaIdentifierPart(cp) &amp;&amp; (cp != &#x27;.&#x27;)) fail(service, u, lc, &quot;Illegal provider-class name: &quot; + ln); &#125; if (!providers.containsKey(ln) &amp;&amp; !names.contains(ln)) names.add(ln); &#125; return lc + 1; &#125; //解析配置文件，解析指定的url配置文件 //使用parseLine方法进行解析，未被实例化的服务提供者会被保存到缓存中去 private Iterator&lt;String&gt; parse(Class&lt;?&gt; service, URL u) throws ServiceConfigurationError &#123; InputStream in = null; BufferedReader r = null; ArrayList&lt;String&gt; names = new ArrayList&lt;&gt;(); try &#123; in = u.openStream(); r = new BufferedReader(new InputStreamReader(in, &quot;utf-8&quot;)); int lc = 1; while ((lc = parseLine(service, u, r, lc, names)) &gt;= 0); &#125; return names.iterator(); &#125; //服务提供者查找的迭代器 private class LazyIterator implements Iterator&lt;S&gt; &#123; Class&lt;S&gt; service;//服务提供者接口 ClassLoader loader;//类加载器 Enumeration&lt;URL&gt; configs = null;//保存实现类的url Iterator&lt;String&gt; pending = null;//保存实现类的全名 String nextName = null;//迭代器中下一个实现类的全名 private LazyIterator(Class&lt;S&gt; service, ClassLoader loader) &#123; this.service = service; this.loader = loader; &#125; private boolean hasNextService() &#123; if (nextName != null) &#123; return true; &#125; if (configs == null) &#123; try &#123; String fullName = PREFIX + service.getName(); if (loader == null) configs = ClassLoader.getSystemResources(fullName); else configs = loader.getResources(fullName); &#125; &#125; while ((pending == null) || !pending.hasNext()) &#123; if (!configs.hasMoreElements()) &#123; return false; &#125; pending = parse(service, configs.nextElement()); &#125; nextName = pending.next(); return true; &#125; private S nextService() &#123; if (!hasNextService()) throw new NoSuchElementException(); String cn = nextName; nextName = null; Class&lt;?&gt; c = null; try &#123; c = Class.forName(cn, false, loader); &#125; if (!service.isAssignableFrom(c)) &#123; fail(service, &quot;Provider &quot; + cn + &quot; not a subtype&quot;); &#125; try &#123; S p = service.cast(c.newInstance()); providers.put(cn, p); return p; &#125; &#125; public boolean hasNext() &#123; if (acc == null) &#123; return hasNextService(); &#125; else &#123; PrivilegedAction&lt;Boolean&gt; action = new PrivilegedAction&lt;Boolean&gt;() &#123; public Boolean run() &#123; return hasNextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public S next() &#123; if (acc == null) &#123; return nextService(); &#125; else &#123; PrivilegedAction&lt;S&gt; action = new PrivilegedAction&lt;S&gt;() &#123; public S run() &#123; return nextService(); &#125; &#125;; return AccessController.doPrivileged(action, acc); &#125; &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125; //获取迭代器 //返回遍历服务提供者的迭代器 //以懒加载的方式加载可用的服务提供者 //懒加载的实现是：解析配置文件和实例化服务提供者的工作由迭代器本身完成 public Iterator&lt;S&gt; iterator() &#123; return new Iterator&lt;S&gt;() &#123; //按照实例化顺序返回已经缓存的服务提供者实例 Iterator&lt;Map.Entry&lt;String,S&gt;&gt; knownProviders = providers.entrySet().iterator(); public boolean hasNext() &#123; if (knownProviders.hasNext()) return true; return lookupIterator.hasNext(); &#125; public S next() &#123; if (knownProviders.hasNext()) return knownProviders.next().getValue(); return lookupIterator.next(); &#125; public void remove() &#123; throw new UnsupportedOperationException(); &#125; &#125;; &#125; //为指定的服务使用指定的类加载器来创建一个ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service, ClassLoader loader) &#123; return new ServiceLoader&lt;&gt;(service, loader); &#125; //使用线程上下文的类加载器来创建ServiceLoader public static &lt;S&gt; ServiceLoader&lt;S&gt; load(Class&lt;S&gt; service) &#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return ServiceLoader.load(service, cl); &#125; //使用扩展类加载器为指定的服务创建ServiceLoader //只能找到并加载已经安装到当前Java虚拟机中的服务提供者，应用程序类路径中的服务提供者将被忽略 public static &lt;S&gt; ServiceLoader&lt;S&gt; loadInstalled(Class&lt;S&gt; service) &#123; ClassLoader cl = ClassLoader.getSystemClassLoader(); ClassLoader prev = null; while (cl != null) &#123; prev = cl; cl = cl.getParent(); &#125; return ServiceLoader.load(service, prev); &#125; public String toString() &#123; return &quot;java.util.ServiceLoader[&quot; + service.getName() + &quot;]&quot;; &#125;&#125; 首先，ServiceLoader实现了Iterable接口，所以它有迭代器的属性，这里主要都是实现了迭代器的hasNext和next方法。这里主要都是调用的lookupIterator的相应hasNext和next方法，lookupIterator是懒加载迭代器。 其次，LazyIterator中的hasNext方法，静态变量PREFIX就是”META-INF/services/”目录，这也就是为什么需要在classpath下的META-INF/services/目录里创建一个以服务接口命名的文件。 最后，通过反射方法Class.forName()加载类对象，并用newInstance方法将类实例化，并把实例化后的类缓存到providers对象中，(LinkedHashMap&lt;String,S&gt;类型）然后返回实例对象。 所以我们可以看到ServiceLoader不是实例化以后，就去读取配置文件中的具体实现，并进行实例化。而是等到使用迭代器去遍历的时候，才会加载对应的配置文件去解析，调用hasNext方法的时候会去加载配置文件进行解析，调用next方法的时候进行实例化并缓存。 所有的配置文件只会加载一次，服务提供者也只会被实例化一次，重新加载配置文件可使用reload方法。 SPI机制的缺陷通过上面的解析，可以发现，我们使用SPI机制的缺陷： 不能按需加载，需要遍历所有的实现，并实例化，然后在循环中才能找到我们需要的实现。如果不想用某些实现类，或者某些类实例化很耗时，它也被载入并实例化了，这就造成了浪费。 获取某个实现类的方式不够灵活，只能通过 Iterator 形式获取，不能根据某个参数来获取对应的实现类。 多个并发多线程使用 ServiceLoader 类的实例是不安全的。 参考文章 https://cxis.me/2017/04/17/Java%E4%B8%ADSPI%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%85%A5%E5%8F%8A%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/ https://stackoverflow.com/questions/2954372/difference-between-spi-and-api?answertab=votes#tab-top https://zhuanlan.zhihu.com/p/28909673 http://blog.itpub.net/69912579/viewspace-2656555/ https://www.cnblogs.com/happyframework/archive/2013/09/17/3325560.html https://blog.csdn.net/sakurainluojia/article/details/53534949 https://www.jianshu.com/p/0d196ad23915","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"7.Java 基础 - 反射机制详解","path":"/2023/12/25/7.Java-基础-反射机制详解/","content":"JAVA反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为java语言的反射机制。Java反射机制在框架设计中极为广泛，需要深入理解。本文综合多篇文章后，总结了Java 反射的相关知识，希望可以提升你对Java中反射的认知效率。 反射基础RTTI（Run-Time Type Identification）运行时类型识别。在《Thinking in Java》一书第十四章中有提到，其作用是在运行时识别一个对象的类型和类的信息。主要有两种方式：一种是“传统的”RTTI，它假定我们在编译时已经知道了所有的类型；另一种是“反射”机制，它允许我们在运行时发现和使用类的信息。 反射就是把java类中的各种成分映射成一个个的Java对象 例如：一个类有：成员变量、方法、构造方法、包等等信息，利用反射技术可以对一个类进行解剖，把个个组成部分映射成一个个对象。 这里我们首先需要理解 Class类，以及类的加载机制； 然后基于此我们如何通过反射获取Class类以及类中的成员变量、方法、构造方法等。 Class类Class类，Class类也是一个实实在在的类，存在于JDK的java.lang包中。Class类的实例表示java应用运行时的类(class ans enum)或接口(interface and annotation)（每个java类运行时都在JVM里表现为一个class对象，可通过类名.class、类型.getClass()、Class.forName(&quot;类名&quot;)等方法获取class对象）。数组同样也被映射为class 对象的一个类，所有具有相同元素类型和维数的数组都共享该 Class 对象。基本类型boolean，byte，char，short，int，long，float，double和关键字void同样表现为 class 对象。 1234567891011121314151617181920212223public final class Class&lt;T&gt; implements java.io.Serializable, GenericDeclaration, Type, AnnotatedElement &#123; private static final int ANNOTATION= 0x00002000; private static final int ENUM = 0x00004000; private static final int SYNTHETIC = 0x00001000; private static native void registerNatives(); static &#123; registerNatives(); &#125; /* * Private constructor. Only the Java Virtual Machine creates Class objects. //私有构造器，只有JVM才能调用创建Class对象 * This constructor is not used and prevents the default constructor being * generated. */ private Class(ClassLoader loader) &#123; // Initialize final field for classLoader. The initialization value of non-null // prevents future JIT optimizations from assuming this final field is null. classLoader = loader; &#125; 到这我们也就可以得出以下几点信息： Class类也是类的一种，与class关键字是不一样的。 手动编写的类被编译后会产生一个Class对象，其表示的是创建的类的类型信息，而且这个Class对象保存在同名.class的文件中(字节码文件) 每个通过关键字class标识的类，在内存中有且只有一个与之对应的Class对象来描述其类型信息，无论创建多少个实例对象，其依据的都是用一个Class对象。 Class类只存私有构造函数，因此对应Class对象只能有JVM创建和加载 Class类的对象作用是运行时提供或获得某个对象的类型信息，这点对于反射技术很重要(关于反射稍后分析)。 类加载类加载机制和类字节码技术可以参考如下两篇文章： JVM基础 - 类字节码详解 源代码通过编译器编译为字节码，再通过类加载子系统进行加载到JVM中运行 JVM基础 - Java 类加载机制 这篇文章将带你深入理解Java 类加载机制 其中，这里我们需要回顾的是： 类加载机制流程 类的加载 反射的使用 提示 基于此我们如何通过反射获取Class类对象以及类中的成员变量、方法、构造方法等 在Java中，Class类与java.lang.reflect类库一起对反射技术进行了全力的支持。在反射包中，我们常用的类主要有Constructor类表示的是Class 对象所表示的类的构造方法，利用它可以在运行时动态创建对象、Field表示Class对象所表示的类的成员变量，通过它可以在运行时动态修改成员变量的属性值(包含private)、Method表示Class对象所表示的类的成员方法，通过它可以动态调用对象的方法(包含private)，下面将对这几个重要类进行分别说明。 Class类对象的获取在类加载的时候，jvm会创建一个class对象 class对象是可以说是反射中最常用的，获取class对象的方式的主要有三种 根据类名：类名.class 根据对象：对象.getClass() 根据全限定类名：Class.forName(全限定类名) 1234567891011121314151617181920212223242526272829303132333435363738394041@Testpublic void classTest() throws Exception &#123; // 获取Class对象的三种方式 logger.info(&quot;根据类名: \\t&quot; + User.class); logger.info(&quot;根据对象: \\t&quot; + new User().getClass()); logger.info(&quot;根据全限定类名:\\t&quot; + Class.forName(&quot;com.test.User&quot;)); // 常用的方法 logger.info(&quot;获取全限定类名:\\t&quot; + userClass.getName()); logger.info(&quot;获取类名:\\t&quot; + userClass.getSimpleName()); logger.info(&quot;实例化:\\t&quot; + userClass.newInstance());&#125;// ...package com.test;public class User &#123; private String name = &quot;init&quot;; private int age; public User() &#123;&#125; public User(String name, int age) &#123; super(); this.name = name; this.age = age; &#125; private String getName() &#123; return name; &#125; private void setName(String name) &#123; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; @Override public String toString() &#123; return &quot;User [name=&quot; + name + &quot;, age=&quot; + age + &quot;]&quot;; &#125;&#125; 输出结果： 123456根据类名: class com.test.User根据对象: class com.test.User根据全限定类名:\tclass com.test.User获取全限定类名:\tcom.test.User获取类名:\tUser实例化:\tUser [name=init, age=0] 再来看看 Class类的方法 方法名 说明 forName() (1)获取Class对象的一个引用，但引用的类还没有加载(该类的第一个对象没有生成)就加载了这个类。 (2)为了产生Class引用，forName()立即就进行了初始化。 Object-getClass() 获取Class对象的一个引用，返回表示该对象的实际类型的Class引用。 getName() 取全限定的类名(包括包名)，即类的完整名字。 getSimpleName() 获取类名(不包括包名) getCanonicalName() 获取全限定的类名(包括包名) isInterface() 判断Class对象是否是表示一个接口 getInterfaces() 返回Class对象数组，表示Class对象所引用的类所实现的所有接口。 getSupercalss() 返回Class对象，表示Class对象所引用的类所继承的直接基类。应用该方法可在运行时发现一个对象完整的继承结构。 newInstance() 返回一个Oject对象，是实现“虚拟构造器”的一种途径。使用该方法创建的类，必须带有无参的构造器。 getFields() 获得某个类的所有的公共（public）的字段，包括继承自父类的所有公共字段。 类似的还有getMethods和getConstructors。 getDeclaredFields 获得某个类的自己声明的字段，即包括public、private和proteced，默认但是不包括父类声明的任何字段。类似的还有getDeclaredMethods和getDeclaredConstructors。 简单测试下（这里例子源于https://blog.csdn.net/mcryeasy/article/details/52344729） 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package com.cry;import java.lang.reflect.Field;interface I1 &#123;&#125;interface I2 &#123;&#125;class Cell&#123; public int mCellPublic;&#125;class Animal extends Cell&#123; private int mAnimalPrivate; protected int mAnimalProtected; int mAnimalDefault; public int mAnimalPublic; private static int sAnimalPrivate; protected static int sAnimalProtected; static int sAnimalDefault; public static int sAnimalPublic;&#125;class Dog extends Animal implements I1, I2 &#123; private int mDogPrivate; public int mDogPublic; protected int mDogProtected; private int mDogDefault; private static int sDogPrivate; protected static int sDogProtected; static int sDogDefault; public static int sDogPublic;&#125;public class Test &#123; public static void main(String[] args) throws IllegalAccessException, InstantiationException &#123; Class&lt;Dog&gt; dog = Dog.class; //类名打印 System.out.println(dog.getName()); //com.cry.Dog System.out.println(dog.getSimpleName()); //Dog System.out.println(dog.getCanonicalName());//com.cry.Dog //接口 System.out.println(dog.isInterface()); //false for (Class iI : dog.getInterfaces()) &#123; System.out.println(iI); &#125; /* interface com.cry.I1 interface com.cry.I2 */ //父类 System.out.println(dog.getSuperclass());//class com.cry.Animal //创建对象 Dog d = dog.newInstance(); //字段 for (Field f : dog.getFields()) &#123; System.out.println(f.getName()); &#125; /* mDogPublic sDogPublic mAnimalPublic sAnimalPublic mCellPublic //父类的父类的公共字段也打印出来了 */ System.out.println(&quot;---------&quot;); for (Field f : dog.getDeclaredFields()) &#123; System.out.println(f.getName()); &#125; /** 只有自己类声明的字段 mDogPrivate mDogPublic mDogProtected mDogDefault sDogPrivate sDogProtected sDogDefault sDogPublic */ &#125;&#125; getName、getCanonicalName与getSimpleName的区别： getSimpleName：只获取类名 getName：类的全限定名，jvm中Class的表示，可以用于动态加载Class对象，例如Class.forName。 getCanonicalName：返回更容易理解的表示，主要用于输出（toString）或log打印，大多数情况下和getName一样，但是在内部类、数组等类型的表示形式就不同了。 12345678910111213141516171819202122package com.cry;public class Test &#123; private class inner&#123; &#125; public static void main(String[] args) throws ClassNotFoundException &#123; //普通类 System.out.println(Test.class.getSimpleName()); //Test System.out.println(Test.class.getName()); //com.cry.Test System.out.println(Test.class.getCanonicalName()); //com.cry.Test //内部类 System.out.println(inner.class.getSimpleName()); //inner System.out.println(inner.class.getName()); //com.cry.Test$inner System.out.println(inner.class.getCanonicalName()); //com.cry.Test.inner //数组 System.out.println(args.getClass().getSimpleName()); //String[] System.out.println(args.getClass().getName()); //[Ljava.lang.String; System.out.println(args.getClass().getCanonicalName()); //java.lang.String[] //我们不能用getCanonicalName去加载类对象，必须用getName //Class.forName(inner.class.getCanonicalName()); 报错 Class.forName(inner.class.getName()); &#125;&#125; Constructor类及其用法 Constructor类存在于反射包(java.lang.reflect)中，反映的是Class 对象所表示的类的构造方法。 获取Constructor对象是通过Class类中的方法获取的，Class类与Constructor相关的主要方法如下： 方法返回值 方法名称 方法说明 static Class&lt;?&gt; forName(String className) 返回与带有给定字符串名的类或接口相关联的 Class 对象。 Constructor getConstructor(Class&lt;?&gt;… parameterTypes) 返回指定参数类型、具有public访问权限的构造函数对象 Constructor&lt;?&gt;[] getConstructors() 返回所有具有public访问权限的构造函数的Constructor对象数组 Constructor getDeclaredConstructor(Class&lt;?&gt;… parameterTypes) 返回指定参数类型、所有声明的（包括private）构造函数对象 Constructor&lt;?&gt;[] getDeclaredConstructors() 返回所有声明的（包括private）构造函数对象 T newInstance() 调用无参构造器创建此 Class 对象所表示的类的一个新实例。 下面看一个简单例子来了解Constructor对象的使用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101public class ConstructionTest implements Serializable &#123; public static void main(String[] args) throws Exception &#123; Class&lt;?&gt; clazz = null; //获取Class对象的引用 clazz = Class.forName(&quot;com.example.javabase.User&quot;); //第一种方法，实例化默认构造方法，User必须无参构造函数,否则将抛异常 User user = (User) clazz.newInstance(); user.setAge(20); user.setName(&quot;Jack&quot;); System.out.println(user); System.out.println(&quot;--------------------------------------------&quot;); //获取带String参数的public构造函数 Constructor cs1 =clazz.getConstructor(String.class); //创建User User user1= (User) cs1.newInstance(&quot;hiway&quot;); user1.setAge(22); System.out.println(&quot;user1:&quot;+user1.toString()); System.out.println(&quot;--------------------------------------------&quot;); //取得指定带int和String参数构造函数,该方法是私有构造private Constructor cs2=clazz.getDeclaredConstructor(int.class,String.class); //由于是private必须设置可访问 cs2.setAccessible(true); //创建user对象 User user2= (User) cs2.newInstance(25,&quot;hiway2&quot;); System.out.println(&quot;user2:&quot;+user2.toString()); System.out.println(&quot;--------------------------------------------&quot;); //获取所有构造包含private Constructor&lt;?&gt; cons[] = clazz.getDeclaredConstructors(); // 查看每个构造方法需要的参数 for (int i = 0; i &lt; cons.length; i++) &#123; //获取构造函数参数类型 Class&lt;?&gt; clazzs[] = cons[i].getParameterTypes(); System.out.println(&quot;构造函数[&quot;+i+&quot;]:&quot;+cons[i].toString() ); System.out.print(&quot;参数类型[&quot;+i+&quot;]:(&quot;); for (int j = 0; j &lt; clazzs.length; j++) &#123; if (j == clazzs.length - 1) System.out.print(clazzs[j].getName()); else System.out.print(clazzs[j].getName() + &quot;,&quot;); &#125; System.out.println(&quot;)&quot;); &#125; &#125;&#125;class User &#123; private int age; private String name; public User() &#123; super(); &#125; public User(String name) &#123; super(); this.name = name; &#125; /** * 私有构造 * @param age * @param name */ private User(int age, String name) &#123; super(); this.age = age; this.name = name; &#125; public int getAge() &#123; return age; &#125; public void setAge(int age) &#123; this.age = age; &#125; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; @Override public String toString() &#123; return &quot;User&#123;&quot; + &quot;age=&quot; + age + &quot;, name=&#x27;&quot; + name + &#x27;\\&#x27;&#x27; + &#x27;&#125;&#x27;; &#125;&#125; 输出结果 12345678910111213/* output User&#123;age=20, name=&#x27;Jack&#x27;&#125;--------------------------------------------user1:User&#123;age=22, name=&#x27;hiway&#x27;&#125;--------------------------------------------user2:User&#123;age=25, name=&#x27;hiway2&#x27;&#125;--------------------------------------------构造函数[0]:private com.example.javabase.User(int,java.lang.String)参数类型[0]:(int,java.lang.String)构造函数[1]:public com.example.javabase.User(java.lang.String)参数类型[1]:(java.lang.String)构造函数[2]:public com.example.javabase.User()参数类型[2]:() 关于**Constructor类本身一些常用方法**如下(仅部分，其他可查API) 方法返回值 方法名称 方法说明 Class getDeclaringClass() 返回 Class 对象，该对象表示声明由此 Constructor 对象表示的构造方法的类,其实就是返回真实类型（不包含参数） Type[] getGenericParameterTypes() 按照声明顺序返回一组 Type 对象，返回的就是 Constructor对象构造函数的形参类型。 String getName() 以字符串形式返回此构造方法的名称。 Class&lt;?&gt;[] getParameterTypes() 按照声明顺序返回一组 Class 对象，即返回Constructor 对象所表示构造方法的形参类型 T newInstance(Object… initargs) 使用此 Constructor对象表示的构造函数来创建新实例 String toGenericString() 返回描述此 Constructor 的字符串，其中包括类型参数。 代码演示如下： 12345678910111213141516171819202122232425Constructor cs3 = clazz.getDeclaredConstructor(int.class,String.class);System.out.println(&quot;-----getDeclaringClass-----&quot;);Class uclazz=cs3.getDeclaringClass();//Constructor对象表示的构造方法的类System.out.println(&quot;构造方法的类:&quot;+uclazz.getName());System.out.println(&quot;-----getGenericParameterTypes-----&quot;);//对象表示此 Constructor 对象所表示的方法的形参类型Type[] tps=cs3.getGenericParameterTypes();for (Type tp:tps) &#123; System.out.println(&quot;参数名称tp:&quot;+tp);&#125;System.out.println(&quot;-----getParameterTypes-----&quot;);//获取构造函数参数类型Class&lt;?&gt; clazzs[] = cs3.getParameterTypes();for (Class claz:clazzs) &#123; System.out.println(&quot;参数名称:&quot;+claz.getName());&#125;System.out.println(&quot;-----getName-----&quot;);//以字符串形式返回此构造方法的名称System.out.println(&quot;getName:&quot;+cs3.getName());System.out.println(&quot;-----getoGenericString-----&quot;);//返回描述此 Constructor 的字符串，其中包括类型参数。System.out.println(&quot;getoGenericString():&quot;+cs3.toGenericString()); 输出结果 123456789101112-----getDeclaringClass-----构造方法的类:com.example.javabase.User-----getGenericParameterTypes-----参数名称tp:int参数名称tp:class java.lang.String-----getParameterTypes-----参数名称:int参数名称:java.lang.String-----getName-----getName:com.example.javabase.User-----getoGenericString-----getoGenericString():private com.example.javabase.User(int,java.lang.String) Field类及其用法 Field 提供有关类或接口的单个字段的信息，以及对它的动态访问权限。反射的字段可能是一个类（静态）字段或实例字段。 同样的道理，我们可以通过Class类的提供的方法来获取代表字段信息的Field对象，Class类与Field对象相关方法如下： 方法返回值 方法名称 方法说明 Field getDeclaredField(String name) 获取指定name名称的(包含private修饰的)字段，不包括继承的字段 Field[] getDeclaredFields() 获取Class对象所表示的类或接口的所有(包含private修饰的)字段,不包括继承的字段 Field getField(String name) 获取指定name名称、具有public修饰的字段，包含继承字段 Field[] getFields() 获取修饰符为public的字段，包含继承字段 下面的代码演示了上述方法的使用过程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class ReflectField &#123; public static void main(String[] args) throws ClassNotFoundException, NoSuchFieldException &#123; Class&lt;?&gt; clazz = Class.forName(&quot;reflect.Student&quot;); //获取指定字段名称的Field类,注意字段修饰符必须为public而且存在该字段, // 否则抛NoSuchFieldException Field field = clazz.getField(&quot;age&quot;); System.out.println(&quot;field:&quot;+field); //获取所有修饰符为public的字段,包含父类字段,注意修饰符为public才会获取 Field fields[] = clazz.getFields(); for (Field f:fields) &#123; System.out.println(&quot;f:&quot;+f.getDeclaringClass()); &#125; System.out.println(&quot;================getDeclaredFields====================&quot;); //获取当前类所字段(包含private字段),注意不包含父类的字段 Field fields2[] = clazz.getDeclaredFields(); for (Field f:fields2) &#123; System.out.println(&quot;f2:&quot;+f.getDeclaringClass()); &#125; //获取指定字段名称的Field类,可以是任意修饰符的自动,注意不包含父类的字段 Field field2 = clazz.getDeclaredField(&quot;desc&quot;); System.out.println(&quot;field2:&quot;+field2); &#125; /** 输出结果: field:public int reflect.Person.age f:public java.lang.String reflect.Student.desc f:public int reflect.Person.age f:public java.lang.String reflect.Person.name ================getDeclaredFields==================== f2:public java.lang.String reflect.Student.desc f2:private int reflect.Student.score field2:public java.lang.String reflect.Student.desc */&#125;class Person&#123; public int age; public String name; //省略set和get方法&#125;class Student extends Person&#123; public String desc; private int score; //省略set和get方法&#125; 上述方法需要注意的是，如果我们不期望获取其父类的字段，则需使用Class类的getDeclaredField&#x2F;getDeclaredFields方法来获取字段即可，倘若需要连带获取到父类的字段，那么请使用Class类的getField&#x2F;getFields，但是也只能获取到public修饰的的字段，无法获取父类的私有字段。下面将通过Field类本身的方法对指定类属性赋值，代码演示如下： 123456789101112131415161718192021222324//获取Class对象引用Class&lt;?&gt; clazz = Class.forName(&quot;reflect.Student&quot;);Student st= (Student) clazz.newInstance();//获取父类public字段并赋值Field ageField = clazz.getField(&quot;age&quot;);ageField.set(st,18);Field nameField = clazz.getField(&quot;name&quot;);nameField.set(st,&quot;Lily&quot;);//只获取当前类的字段,不获取父类的字段Field descField = clazz.getDeclaredField(&quot;desc&quot;);descField.set(st,&quot;I am student&quot;);Field scoreField = clazz.getDeclaredField(&quot;score&quot;);//设置可访问，score是private的scoreField.setAccessible(true);scoreField.set(st,88);System.out.println(st.toString());//输出结果：Student&#123;age=18, name=&#x27;Lily ,desc=&#x27;I am student&#x27;, score=88&#125; //获取字段值System.out.println(scoreField.get(st));// 88 其中的set(Object obj, Object value)方法是Field类本身的方法，用于设置字段的值，而get(Object obj)则是获取字段的值，当然关于Field类还有其他常用的方法如下： 方法返回值 方法名称 方法说明 void set(Object obj, Object value) 将指定对象变量上此 Field 对象表示的字段设置为指定的新值。 Object get(Object obj) 返回指定对象上此 Field 表示的字段的值 Class&lt;?&gt; getType() 返回一个 Class 对象，它标识了此Field 对象所表示字段的声明类型。 boolean isEnumConstant() 如果此字段表示枚举类型的元素则返回 true；否则返回 false String toGenericString() 返回一个描述此 Field（包括其一般类型）的字符串 String getName() 返回此 Field 对象表示的字段的名称 Class&lt;?&gt; getDeclaringClass() 返回表示类或接口的 Class 对象，该类或接口声明由此 Field 对象表示的字段 void setAccessible(boolean flag) 将此对象的 accessible 标志设置为指示的布尔值,即设置其可访问性 上述方法可能是较为常用的，事实上在设置值的方法上，Field类还提供了专门针对基本数据类型的方法，如setInt()/getInt()、setBoolean()/getBoolean、setChar()/getChar()等等方法，这里就不全部列出了，需要时查API文档即可。需要特别注意的是被final关键字修饰的Field字段是安全的，在运行时可以接收任何修改，但最终其实际值是不会发生改变的。 Method类及其用法 Method 提供关于类或接口上单独某个方法（以及如何访问该方法）的信息，所反映的方法可能是类方法或实例方法（包括抽象方法）。 下面是Class类获取Method对象相关的方法： 方法返回值 方法名称 方法说明 Method getDeclaredMethod(String name, Class&lt;?&gt;… parameterTypes) 返回一个指定参数的Method对象，该对象反映此 Class 对象所表示的类或接口的指定已声明方法。 Method[] getDeclaredMethods() 返回 Method 对象的一个数组，这些对象反映此 Class 对象表示的类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法。 Method getMethod(String name, Class&lt;?&gt;… parameterTypes) 返回一个 Method 对象，它反映此 Class 对象所表示的类或接口的指定公共成员方法。 Method[] getMethods() 返回一个包含某些 Method 对象的数组，这些对象反映此 Class 对象所表示的类或接口（包括那些由该类或接口声明的以及从超类和超接口继承的那些的类或接口）的公共 member 方法。 同样通过案例演示上述方法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152import java.lang.reflect.Method;public class ReflectMethod &#123; public static void main(String[] args) throws ClassNotFoundException, NoSuchMethodException &#123; Class clazz = Class.forName(&quot;reflect.Circle&quot;); //根据参数获取public的Method,包含继承自父类的方法 Method method = clazz.getMethod(&quot;draw&quot;,int.class,String.class); System.out.println(&quot;method:&quot;+method); //获取所有public的方法: Method[] methods =clazz.getMethods(); for (Method m:methods)&#123; System.out.println(&quot;m::&quot;+m); &#125; System.out.println(&quot;=========================================&quot;); //获取当前类的方法包含private,该方法无法获取继承自父类的method Method method1 = clazz.getDeclaredMethod(&quot;drawCircle&quot;); System.out.println(&quot;method1::&quot;+method1); //获取当前类的所有方法包含private,该方法无法获取继承自父类的method Method[] methods1=clazz.getDeclaredMethods(); for (Method m:methods1)&#123; System.out.println(&quot;m1::&quot;+m); &#125; &#125;&#125;class Shape &#123; public void draw()&#123; System.out.println(&quot;draw&quot;); &#125; public void draw(int count , String name)&#123; System.out.println(&quot;draw &quot;+ name +&quot;,count=&quot;+count); &#125;&#125;class Circle extends Shape&#123; private void drawCircle()&#123; System.out.println(&quot;drawCircle&quot;); &#125; public int getAllCount()&#123; return 100; &#125;&#125; 输出结果: 1234567891011121314151617181920method:public void reflect.Shape.draw(int,java.lang.String)m::public int reflect.Circle.getAllCount()m::public void reflect.Shape.draw()m::public void reflect.Shape.draw(int,java.lang.String)m::public final void java.lang.Object.wait(long,int) throws java.lang.InterruptedExceptionm::public final native void java.lang.Object.wait(long) throws java.lang.InterruptedExceptionm::public final void java.lang.Object.wait() throws java.lang.InterruptedExceptionm::public boolean java.lang.Object.equals(java.lang.Object)m::public java.lang.String java.lang.Object.toString()m::public native int java.lang.Object.hashCode()m::public final native java.lang.Class java.lang.Object.getClass()m::public final native void java.lang.Object.notify()m::public final native void java.lang.Object.notifyAll()=========================================method1::private void reflect.Circle.drawCircle()m1::public int reflect.Circle.getAllCount()m1::private void reflect.Circle.drawCircle() 在通过getMethods方法获取Method对象时，会把父类的方法也获取到，如上的输出结果，把Object类的方法都打印出来了。而getDeclaredMethod/getDeclaredMethods方法都只能获取当前类的方法。我们在使用时根据情况选择即可。下面将演示通过Method对象调用指定类的方法： 1234567891011121314151617181920Class clazz = Class.forName(&quot;reflect.Circle&quot;);//创建对象Circle circle = (Circle) clazz.newInstance();//获取指定参数的方法对象MethodMethod method = clazz.getMethod(&quot;draw&quot;,int.class,String.class);//通过Method对象的invoke(Object obj,Object... args)方法调用method.invoke(circle,15,&quot;圈圈&quot;);//对私有无参方法的操作Method method1 = clazz.getDeclaredMethod(&quot;drawCircle&quot;);//修改私有方法的访问标识method1.setAccessible(true);method1.invoke(circle);//对有返回值得方法操作Method method2 =clazz.getDeclaredMethod(&quot;getAllCount&quot;);Integer count = (Integer) method2.invoke(circle);System.out.println(&quot;count:&quot;+count); 输出结果 123draw 圈圈,count=15drawCirclecount:100 在上述代码中调用方法，使用了Method类的invoke(Object obj,Object... args)第一个参数代表调用的对象，第二个参数传递的调用方法的参数。这样就完成了类方法的动态调用。 方法返回值 方法名称 方法说明 Object invoke(Object obj, Object… args) 对带有指定参数的指定对象调用由此 Method 对象表示的底层方法。 Class&lt;?&gt; getReturnType() 返回一个 Class 对象，该对象描述了此 Method 对象所表示的方法的正式返回类型,即方法的返回类型 Type getGenericReturnType() 返回表示由此 Method 对象所表示方法的正式返回类型的 Type 对象，也是方法的返回类型。 Class&lt;?&gt;[] getParameterTypes() 按照声明顺序返回 Class 对象的数组，这些对象描述了此 Method 对象所表示的方法的形参类型。即返回方法的参数类型组成的数组 Type[] getGenericParameterTypes() 按照声明顺序返回 Type 对象的数组，这些对象描述了此 Method 对象所表示的方法的形参类型的，也是返回方法的参数类型 String getName() 以 String 形式返回此 Method 对象表示的方法名称，即返回方法的名称 boolean isVarArgs() 判断方法是否带可变参数，如果将此方法声明为带有可变数量的参数，则返回 true；否则，返回 false。 String toGenericString() 返回描述此 Method 的字符串，包括类型参数。 getReturnType方法/getGenericReturnType方法都是获取Method对象表示的方法的返回类型，只不过前者返回的Class类型后者返回的Type(前面已分析过)，Type就是一个接口而已，在Java8中新增一个默认的方法实现，返回的就参数类型信息 123456public interface Type &#123; //1.8新增 default String getTypeName() &#123; return toString(); &#125;&#125; 而getParameterTypes/getGenericParameterTypes也是同样的道理，都是获取Method对象所表示的方法的参数类型，其他方法与前面的Field和Constructor是类似的。 反射机制执行的流程 这部分主要参考自https://www.cnblogs.com/yougewe/p/10125073.html 先看个例子 12345678910111213141516171819202122232425262728public class HelloReflect &#123; public static void main(String[] args) &#123; try &#123; // 1. 使用外部配置的实现，进行动态加载类 TempFunctionTest test = (TempFunctionTest)Class.forName(&quot;com.tester.HelloReflect&quot;).newInstance(); test.sayHello(&quot;call directly&quot;); // 2. 根据配置的函数名，进行方法调用（不需要通用的接口抽象） Object t2 = new TempFunctionTest(); Method method = t2.getClass().getDeclaredMethod(&quot;sayHello&quot;, String.class); method.invoke(test, &quot;method invoke&quot;); &#125; catch (ClassNotFoundException e) &#123; e.printStackTrace(); &#125; catch (InstantiationException e) &#123; e.printStackTrace(); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; catch (NoSuchMethodException e ) &#123; e.printStackTrace(); &#125; catch (InvocationTargetException e) &#123; e.printStackTrace(); &#125; &#125; public void sayHello(String word) &#123; System.out.println(&quot;hello,&quot; + word); &#125;&#125; 来看执行流程 反射获取类实例首先调用了 java.lang.Class 的静态方法，获取类信息。 12345678@CallerSensitivepublic static Class&lt;?&gt; forName(String className) throws ClassNotFoundException &#123; // 先通过反射，获取调用进来的类信息，从而获取当前的 classLoader Class&lt;?&gt; caller = Reflection.getCallerClass(); // 调用native方法进行获取class信息 return forName0(className, true, ClassLoader.getClassLoader(caller), caller);&#125; forName()反射获取类信息，并没有将实现留给了java,而是交给了jvm去加载。 主要是先获取 ClassLoader, 然后调用 native 方法，获取信息，加载类则是回调 java.lang.ClassLoader. 最后，jvm又会回调 ClassLoader 进类加载。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091// public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; return loadClass(name, false);&#125; // sun.misc.Launcher public Class&lt;?&gt; loadClass(String var1, boolean var2) throws ClassNotFoundException &#123; int var3 = var1.lastIndexOf(46); if(var3 != -1) &#123; SecurityManager var4 = System.getSecurityManager(); if(var4 != null) &#123; var4.checkPackageAccess(var1.substring(0, var3)); &#125; &#125; if(this.ucp.knownToNotExist(var1)) &#123; Class var5 = this.findLoadedClass(var1); if(var5 != null) &#123; if(var2) &#123; this.resolveClass(var5); &#125; return var5; &#125; else &#123; throw new ClassNotFoundException(var1); &#125; &#125; else &#123; return super.loadClass(var1, var2); &#125; &#125;// java.lang.ClassLoaderprotected Class&lt;?&gt; loadClass(String name, boolean resolve) throws ClassNotFoundException&#123; // 先获取锁 synchronized (getClassLoadingLock(name)) &#123; // First, check if the class has already been loaded // 如果已经加载了的话，就不用再加载了 Class&lt;?&gt; c = findLoadedClass(name); if (c == null) &#123; long t0 = System.nanoTime(); try &#123; // 双亲委托加载 if (parent != null) &#123; c = parent.loadClass(name, false); &#125; else &#123; c = findBootstrapClassOrNull(name); &#125; &#125; catch (ClassNotFoundException e) &#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &#125; // 父类没有加载到时，再自己加载 if (c == null) &#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); &#125; &#125; if (resolve) &#123; resolveClass(c); &#125; return c; &#125;&#125;protected Object getClassLoadingLock(String className) &#123; Object lock = this; if (parallelLockMap != null) &#123; // 使用 ConcurrentHashMap来保存锁 Object newLock = new Object(); lock = parallelLockMap.putIfAbsent(className, newLock); if (lock == null) &#123; lock = newLock; &#125; &#125; return lock;&#125;protected final Class&lt;?&gt; findLoadedClass(String name) &#123; if (!checkName(name)) return null; return findLoadedClass0(name);&#125; 下面来看一下 newInstance() 的实现方式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// 首先肯定是 Class.newInstance@CallerSensitivepublic T newInstance() throws InstantiationException, IllegalAccessException&#123; if (System.getSecurityManager() != null) &#123; checkMemberAccess(Member.PUBLIC, Reflection.getCallerClass(), false); &#125; // NOTE: the following code may not be strictly correct under // the current Java memory model. // Constructor lookup // newInstance() 其实相当于调用类的无参构造函数，所以，首先要找到其无参构造器 if (cachedConstructor == null) &#123; if (this == Class.class) &#123; // 不允许调用 Class 的 newInstance() 方法 throw new IllegalAccessException( &quot;Can not call newInstance() on the Class for java.lang.Class&quot; ); &#125; try &#123; // 获取无参构造器 Class&lt;?&gt;[] empty = &#123;&#125;; final Constructor&lt;T&gt; c = getConstructor0(empty, Member.DECLARED); // Disable accessibility checks on the constructor // since we have to do the security check here anyway // (the stack depth is wrong for the Constructor&#x27;s // security check to work) java.security.AccessController.doPrivileged( new java.security.PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; c.setAccessible(true); return null; &#125; &#125;); cachedConstructor = c; &#125; catch (NoSuchMethodException e) &#123; throw (InstantiationException) new InstantiationException(getName()).initCause(e); &#125; &#125; Constructor&lt;T&gt; tmpConstructor = cachedConstructor; // Security check (same as in java.lang.reflect.Constructor) int modifiers = tmpConstructor.getModifiers(); if (!Reflection.quickCheckMemberAccess(this, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); if (newInstanceCallerCache != caller) &#123; Reflection.ensureMemberAccess(caller, this, null, modifiers); newInstanceCallerCache = caller; &#125; &#125; // Run constructor try &#123; // 调用无参构造器 return tmpConstructor.newInstance((Object[])null); &#125; catch (InvocationTargetException e) &#123; Unsafe.getUnsafe().throwException(e.getTargetException()); // Not reached return null; &#125;&#125; newInstance() 主要做了三件事： 权限检测，如果不通过直接抛出异常； 查找无参构造器，并将其缓存起来； 调用具体方法的无参构造方法，生成实例并返回； 下面是获取构造器的过程： 12345678910111213private Constructor&lt;T&gt; getConstructor0(Class&lt;?&gt;[] parameterTypes, int which) throws NoSuchMethodException&#123; // 获取所有构造器 Constructor&lt;T&gt;[] constructors = privateGetDeclaredConstructors((which == Member.PUBLIC)); for (Constructor&lt;T&gt; constructor : constructors) &#123; if (arrayContentsEq(parameterTypes, constructor.getParameterTypes())) &#123; return getReflectionFactory().copyConstructor(constructor); &#125; &#125; throw new NoSuchMethodException(getName() + &quot;.&lt;init&gt;&quot; + argumentTypesToString(parameterTypes));&#125; getConstructor0() 为获取匹配的构造方器；分三步： 先获取所有的constructors, 然后通过进行参数类型比较； 找到匹配后，通过 ReflectionFactory copy一份constructor返回； 否则抛出 NoSuchMethodException; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172// 获取当前类所有的构造方法，通过jvm或者缓存// Returns an array of &quot;root&quot; constructors. These Constructor// objects must NOT be propagated to the outside world, but must// instead be copied via ReflectionFactory.copyConstructor.private Constructor&lt;T&gt;[] privateGetDeclaredConstructors(boolean publicOnly) &#123; checkInitted(); Constructor&lt;T&gt;[] res; // 调用 reflectionData(), 获取保存的信息，使用软引用保存，从而使内存不够可以回收 ReflectionData&lt;T&gt; rd = reflectionData(); if (rd != null) &#123; res = publicOnly ? rd.publicConstructors : rd.declaredConstructors; // 存在缓存，则直接返回 if (res != null) return res; &#125; // No cached value available; request value from VM if (isInterface()) &#123; @SuppressWarnings(&quot;unchecked&quot;) Constructor&lt;T&gt;[] temporaryRes = (Constructor&lt;T&gt;[]) new Constructor&lt;?&gt;[0]; res = temporaryRes; &#125; else &#123; // 使用native方法从jvm获取构造器 res = getDeclaredConstructors0(publicOnly); &#125; if (rd != null) &#123; // 最后，将从jvm中读取的内容，存入缓存 if (publicOnly) &#123; rd.publicConstructors = res; &#125; else &#123; rd.declaredConstructors = res; &#125; &#125; return res;&#125;// Lazily create and cache ReflectionDataprivate ReflectionData&lt;T&gt; reflectionData() &#123; SoftReference&lt;ReflectionData&lt;T&gt;&gt; reflectionData = this.reflectionData; int classRedefinedCount = this.classRedefinedCount; ReflectionData&lt;T&gt; rd; if (useCaches &amp;&amp; reflectionData != null &amp;&amp; (rd = reflectionData.get()) != null &amp;&amp; rd.redefinedCount == classRedefinedCount) &#123; return rd; &#125; // else no SoftReference or cleared SoftReference or stale ReflectionData // -&gt; create and replace new instance return newReflectionData(reflectionData, classRedefinedCount);&#125;// 新创建缓存，保存反射信息private ReflectionData&lt;T&gt; newReflectionData(SoftReference&lt;ReflectionData&lt;T&gt;&gt; oldReflectionData, int classRedefinedCount) &#123; if (!useCaches) return null; // 使用cas保证更新的线程安全性，所以反射是保证线程安全的 while (true) &#123; ReflectionData&lt;T&gt; rd = new ReflectionData&lt;&gt;(classRedefinedCount); // try to CAS it... if (Atomic.casReflectionData(this, oldReflectionData, new SoftReference&lt;&gt;(rd))) &#123; return rd; &#125; // 先使用CAS更新，如果更新成功，则立即返回，否则测查当前已被其他线程更新的情况，如果和自己想要更新的状态一致，则也算是成功了 oldReflectionData = this.reflectionData; classRedefinedCount = this.classRedefinedCount; if (oldReflectionData != null &amp;&amp; (rd = oldReflectionData.get()) != null &amp;&amp; rd.redefinedCount == classRedefinedCount) &#123; return rd; &#125; &#125;&#125; 如上，privateGetDeclaredConstructors(), 获取所有的构造器主要步骤； 先尝试从缓存中获取； 如果缓存没有，则从jvm中重新获取，并存入缓存，缓存使用软引用进行保存，保证内存可用； 另外，使用 relactionData() 进行缓存保存；ReflectionData 的数据结构如下。 1234567891011121314151617181920// reflection data that might get invalidated when JVM TI RedefineClasses() is calledprivate static class ReflectionData&lt;T&gt; &#123; volatile Field[] declaredFields; volatile Field[] publicFields; volatile Method[] declaredMethods; volatile Method[] publicMethods; volatile Constructor&lt;T&gt;[] declaredConstructors; volatile Constructor&lt;T&gt;[] publicConstructors; // Intermediate results for getFields and getMethods volatile Field[] declaredPublicFields; volatile Method[] declaredPublicMethods; volatile Class&lt;?&gt;[] interfaces; // Value of classRedefinedCount when we created this ReflectionData instance final int redefinedCount; ReflectionData(int redefinedCount) &#123; this.redefinedCount = redefinedCount; &#125;&#125; 其中，还有一个点，就是如何比较构造是否是要查找构造器，其实就是比较类型完成相等就完了，有一个不相等则返回false。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253private static boolean arrayContentsEq(Object[] a1, Object[] a2) &#123; if (a1 == null) &#123; return a2 == null || a2.length == 0; &#125; if (a2 == null) &#123; return a1.length == 0; &#125; if (a1.length != a2.length) &#123; return false; &#125; for (int i = 0; i &lt; a1.length; i++) &#123; if (a1[i] != a2[i]) &#123; return false; &#125; &#125; return true;&#125;// sun.reflect.ReflectionFactory/** Makes a copy of the passed constructor. The returned constructor is a &quot;child&quot; of the passed one; see the comments in Constructor.java for details. */public &lt;T&gt; Constructor&lt;T&gt; copyConstructor(Constructor&lt;T&gt; arg) &#123; return langReflectAccess().copyConstructor(arg);&#125;// java.lang.reflect.Constructor, copy 其实就是新new一个 Constructor 出来Constructor&lt;T&gt; copy() &#123; // This routine enables sharing of ConstructorAccessor objects // among Constructor objects which refer to the same underlying // method in the VM. (All of this contortion is only necessary // because of the &quot;accessibility&quot; bit in AccessibleObject, // which implicitly requires that new java.lang.reflect // objects be fabricated for each reflective call on Class // objects.) if (this.root != null) throw new IllegalArgumentException(&quot;Can not copy a non-root Constructor&quot;); Constructor&lt;T&gt; res = new Constructor&lt;&gt;(clazz, parameterTypes, exceptionTypes, modifiers, slot, signature, annotations, parameterAnnotations); // root 指向当前 constructor res.root = this; // Might as well eagerly propagate this if already present res.constructorAccessor = constructorAccessor; return res;&#125; 通过上面，获取到 Constructor 了。 接下来就只需调用其相应构造器的 newInstance()，即返回实例了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// return tmpConstructor.newInstance((Object[])null); // java.lang.reflect.Constructor@CallerSensitivepublic T newInstance(Object ... initargs) throws InstantiationException, IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, null, modifiers); &#125; &#125; if ((clazz.getModifiers() &amp; Modifier.ENUM) != 0) throw new IllegalArgumentException(&quot;Cannot reflectively create enum objects&quot;); ConstructorAccessor ca = constructorAccessor; // read volatile if (ca == null) &#123; ca = acquireConstructorAccessor(); &#125; @SuppressWarnings(&quot;unchecked&quot;) T inst = (T) ca.newInstance(initargs); return inst;&#125;// sun.reflect.DelegatingConstructorAccessorImplpublic Object newInstance(Object[] args) throws InstantiationException, IllegalArgumentException, InvocationTargetException&#123; return delegate.newInstance(args);&#125;// sun.reflect.NativeConstructorAccessorImplpublic Object newInstance(Object[] args) throws InstantiationException, IllegalArgumentException, InvocationTargetException&#123; // We can&#x27;t inflate a constructor belonging to a vm-anonymous class // because that kind of class can&#x27;t be referred to by name, hence can&#x27;t // be found from the generated bytecode. if (++numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(c.getDeclaringClass())) &#123; ConstructorAccessorImpl acc = (ConstructorAccessorImpl) new MethodAccessorGenerator(). generateConstructor(c.getDeclaringClass(), c.getParameterTypes(), c.getExceptionTypes(), c.getModifiers()); parent.setDelegate(acc); &#125; // 调用native方法，进行调用 constructor return newInstance0(c, args);&#125; 返回构造器的实例后，可以根据外部进行进行类型转换，从而使用接口或方法进行调用实例功能了。 反射获取方法 第一步，先获取 Method; 1234567891011// java.lang.Class@CallerSensitivepublic Method getDeclaredMethod(String name, Class&lt;?&gt;... parameterTypes) throws NoSuchMethodException, SecurityException &#123; checkMemberAccess(Member.DECLARED, Reflection.getCallerClass(), true); Method method = searchMethods(privateGetDeclaredMethods(false), name, parameterTypes); if (method == null) &#123; throw new NoSuchMethodException(getName() + &quot;.&quot; + name + argumentTypesToString(parameterTypes)); &#125; return method;&#125; 忽略第一个检查权限，剩下就只有两个动作了。 获取所有方法列表； 根据方法名称和方法列表，选出符合要求的方法； 如果没有找到相应方法，抛出异常，否则返回对应方法； 所以，先看一下怎样获取类声明的所有方法？ 12345678910111213141516171819202122// Returns an array of &quot;root&quot; methods. These Method objects must NOT// be propagated to the outside world, but must instead be copied// via ReflectionFactory.copyMethod.private Method[] privateGetDeclaredMethods(boolean publicOnly) &#123; checkInitted(); Method[] res; ReflectionData&lt;T&gt; rd = reflectionData(); if (rd != null) &#123; res = publicOnly ? rd.declaredPublicMethods : rd.declaredMethods; if (res != null) return res; &#125; // No cached value available; request value from VM res = Reflection.filterMethods(this, getDeclaredMethods0(publicOnly)); if (rd != null) &#123; if (publicOnly) &#123; rd.declaredPublicMethods = res; &#125; else &#123; rd.declaredMethods = res; &#125; &#125; return res;&#125; 很相似，和获取所有构造器的方法很相似，都是先从缓存中获取方法，如果没有，则从jvm中获取。 不同的是，方法列表需要进行过滤 Reflection.filterMethods;当然后面看来，这个方法我们一般不会派上用场。 12345678910111213141516171819202122232425262728293031323334353637383940414243// sun.misc.Reflectionpublic static Method[] filterMethods(Class&lt;?&gt; containingClass, Method[] methods) &#123; if (methodFilterMap == null) &#123; // Bootstrapping return methods; &#125; return (Method[])filter(methods, methodFilterMap.get(containingClass));&#125;// 可以过滤指定的方法，一般为空，如果要指定过滤，可以调用 registerMethodsToFilter(), 或者...private static Member[] filter(Member[] members, String[] filteredNames) &#123; if ((filteredNames == null) || (members.length == 0)) &#123; return members; &#125; int numNewMembers = 0; for (Member member : members) &#123; boolean shouldSkip = false; for (String filteredName : filteredNames) &#123; if (member.getName() == filteredName) &#123; shouldSkip = true; break; &#125; &#125; if (!shouldSkip) &#123; ++numNewMembers; &#125; &#125; Member[] newMembers = (Member[])Array.newInstance(members[0].getClass(), numNewMembers); int destIdx = 0; for (Member member : members) &#123; boolean shouldSkip = false; for (String filteredName : filteredNames) &#123; if (member.getName() == filteredName) &#123; shouldSkip = true; break; &#125; &#125; if (!shouldSkip) &#123; newMembers[destIdx++] = member; &#125; &#125; return newMembers;&#125; 第二步，根据方法名和参数类型过滤指定方法返回： 123456789101112131415161718private static Method searchMethods(Method[] methods, String name, Class&lt;?&gt;[] parameterTypes)&#123; Method res = null; // 使用常量池，避免重复创建String String internedName = name.intern(); for (int i = 0; i &lt; methods.length; i++) &#123; Method m = methods[i]; if (m.getName() == internedName &amp;&amp; arrayContentsEq(parameterTypes, m.getParameterTypes()) &amp;&amp; (res == null || res.getReturnType().isAssignableFrom(m.getReturnType()))) res = m; &#125; return (res == null ? res : getReflectionFactory().copyMethod(res));&#125; 大概意思看得明白，就是匹配到方法名，然后参数类型匹配，才可以。 但是可以看到，匹配到一个方法，并没有退出for循环，而是继续进行匹配。 这里是匹配最精确的子类进行返回（最优匹配） 最后，还是通过 ReflectionFactory, copy 方法后返回。 调用 method.invoke() 方法1234567891011121314151617@CallerSensitivepublic Object invoke(Object obj, Object... args) throws IllegalAccessException, IllegalArgumentException, InvocationTargetException&#123; if (!override) &#123; if (!Reflection.quickCheckMemberAccess(clazz, modifiers)) &#123; Class&lt;?&gt; caller = Reflection.getCallerClass(); checkAccess(caller, clazz, obj, modifiers); &#125; &#125; MethodAccessor ma = methodAccessor; // read volatile if (ma == null) &#123; ma = acquireMethodAccessor(); &#125; return ma.invoke(obj, args);&#125; invoke时，是通过 MethodAccessor 进行调用的，而 MethodAccessor 是个接口，在第一次时调用 acquireMethodAccessor() 进行新创建。 1234567891011121314151617181920212223242526272829303132333435363738// probably make the implementation more scalable.private MethodAccessor acquireMethodAccessor() &#123; // First check to see if one has been created yet, and take it // if so MethodAccessor tmp = null; if (root != null) tmp = root.getMethodAccessor(); if (tmp != null) &#123; // 存在缓存时，存入 methodAccessor，否则调用 ReflectionFactory 创建新的 MethodAccessor methodAccessor = tmp; &#125; else &#123; // Otherwise fabricate one and propagate it up to the root tmp = reflectionFactory.newMethodAccessor(this); setMethodAccessor(tmp); &#125; return tmp;&#125;// sun.reflect.ReflectionFactorypublic MethodAccessor newMethodAccessor(Method method) &#123; checkInitted(); if (noInflation &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; return new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); &#125; else &#123; NativeMethodAccessorImpl acc = new NativeMethodAccessorImpl(method); DelegatingMethodAccessorImpl res = new DelegatingMethodAccessorImpl(acc); acc.setParent(res); return res; &#125;&#125; 两个Accessor详情： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455// NativeMethodAccessorImpl / DelegatingMethodAccessorImplclass NativeMethodAccessorImpl extends MethodAccessorImpl &#123; private final Method method; private DelegatingMethodAccessorImpl parent; private int numInvocations; NativeMethodAccessorImpl(Method method) &#123; this.method = method; &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; // We can&#x27;t inflate methods belonging to vm-anonymous classes because // that kind of class can&#x27;t be referred to by name, hence can&#x27;t be // found from the generated bytecode. if (++numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); &#125; return invoke0(method, obj, args); &#125; void setParent(DelegatingMethodAccessorImpl parent) &#123; this.parent = parent; &#125; private static native Object invoke0(Method m, Object obj, Object[] args);&#125;class DelegatingMethodAccessorImpl extends MethodAccessorImpl &#123; private MethodAccessorImpl delegate; DelegatingMethodAccessorImpl(MethodAccessorImpl delegate) &#123; setDelegate(delegate); &#125; public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException &#123; return delegate.invoke(obj, args); &#125; void setDelegate(MethodAccessorImpl delegate) &#123; this.delegate = delegate; &#125;&#125; 进行 ma.invoke(obj, args); 调用时，调用 DelegatingMethodAccessorImpl.invoke(); 最后被委托到 NativeMethodAccessorImpl.invoke(), 即： 12345678910111213141516171819202122public Object invoke(Object obj, Object[] args) throws IllegalArgumentException, InvocationTargetException&#123; // We can&#x27;t inflate methods belonging to vm-anonymous classes because // that kind of class can&#x27;t be referred to by name, hence can&#x27;t be // found from the generated bytecode. if (++numInvocations &gt; ReflectionFactory.inflationThreshold() &amp;&amp; !ReflectUtil.isVMAnonymousClass(method.getDeclaringClass())) &#123; MethodAccessorImpl acc = (MethodAccessorImpl) new MethodAccessorGenerator(). generateMethod(method.getDeclaringClass(), method.getName(), method.getParameterTypes(), method.getReturnType(), method.getExceptionTypes(), method.getModifiers()); parent.setDelegate(acc); &#125; // invoke0 是个 native 方法，由jvm进行调用业务方法。从而完成反射调用功能。 return invoke0(method, obj, args);&#125; 其中， generateMethod() 是生成具体类的方法： 123456789101112131415161718/** This routine is not thread-safe */public MethodAccessor generateMethod(Class&lt;?&gt; declaringClass, String name, Class&lt;?&gt;[] parameterTypes, Class&lt;?&gt; returnType, Class&lt;?&gt;[] checkedExceptions, int modifiers)&#123; return (MethodAccessor) generate(declaringClass, name, parameterTypes, returnType, checkedExceptions, modifiers, false, false, null);&#125; generate() 戳详情。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287/** This routine is not thread-safe */private MagicAccessorImpl generate(final Class&lt;?&gt; declaringClass, String name, Class&lt;?&gt;[] parameterTypes, Class&lt;?&gt; returnType, Class&lt;?&gt;[] checkedExceptions, int modifiers, boolean isConstructor, boolean forSerialization, Class&lt;?&gt; serializationTargetClass)&#123; ByteVector vec = ByteVectorFactory.create(); asm = new ClassFileAssembler(vec); this.declaringClass = declaringClass; this.parameterTypes = parameterTypes; this.returnType = returnType; this.modifiers = modifiers; this.isConstructor = isConstructor; this.forSerialization = forSerialization; asm.emitMagicAndVersion(); // Constant pool entries: // ( * = Boxing information: optional) // (+ = Shared entries provided by AccessorGenerator) // (^ = Only present if generating SerializationConstructorAccessor) // [UTF-8] [This class&#x27;s name] // [CONSTANT_Class_info] for above // [UTF-8] &quot;sun/reflect/&#123;MethodAccessorImpl,ConstructorAccessorImpl,SerializationConstructorAccessorImpl&#125;&quot; // [CONSTANT_Class_info] for above // [UTF-8] [Target class&#x27;s name] // [CONSTANT_Class_info] for above // ^ [UTF-8] [Serialization: Class&#x27;s name in which to invoke constructor] // ^ [CONSTANT_Class_info] for above // [UTF-8] target method or constructor name // [UTF-8] target method or constructor signature // [CONSTANT_NameAndType_info] for above // [CONSTANT_Methodref_info or CONSTANT_InterfaceMethodref_info] for target method // [UTF-8] &quot;invoke&quot; or &quot;newInstance&quot; // [UTF-8] invoke or newInstance descriptor // [UTF-8] descriptor for type of non-primitive parameter 1 // [CONSTANT_Class_info] for type of non-primitive parameter 1 // ... // [UTF-8] descriptor for type of non-primitive parameter n // [CONSTANT_Class_info] for type of non-primitive parameter n // + [UTF-8] &quot;java/lang/Exception&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/ClassCastException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/NullPointerException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/IllegalArgumentException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;java/lang/InvocationTargetException&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;&lt;init&gt;&quot; // + [UTF-8] &quot;()V&quot; // + [CONSTANT_NameAndType_info] for above // + [CONSTANT_Methodref_info] for NullPointerException&#x27;s constructor // + [CONSTANT_Methodref_info] for IllegalArgumentException&#x27;s constructor // + [UTF-8] &quot;(Ljava/lang/String;)V&quot; // + [CONSTANT_NameAndType_info] for &quot;&lt;init&gt;(Ljava/lang/String;)V&quot; // + [CONSTANT_Methodref_info] for IllegalArgumentException&#x27;s constructor taking a String // + [UTF-8] &quot;(Ljava/lang/Throwable;)V&quot; // + [CONSTANT_NameAndType_info] for &quot;&lt;init&gt;(Ljava/lang/Throwable;)V&quot; // + [CONSTANT_Methodref_info] for InvocationTargetException&#x27;s constructor // + [CONSTANT_Methodref_info] for &quot;super()&quot; // + [UTF-8] &quot;java/lang/Object&quot; // + [CONSTANT_Class_info] for above // + [UTF-8] &quot;toString&quot; // + [UTF-8] &quot;()Ljava/lang/String;&quot; // + [CONSTANT_NameAndType_info] for &quot;toString()Ljava/lang/String;&quot; // + [CONSTANT_Methodref_info] for Object&#x27;s toString method // + [UTF-8] &quot;Code&quot; // + [UTF-8] &quot;Exceptions&quot; // * [UTF-8] &quot;java/lang/Boolean&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(Z)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;booleanValue&quot; // * [UTF-8] &quot;()Z&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Byte&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(B)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;byteValue&quot; // * [UTF-8] &quot;()B&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Character&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(C)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;charValue&quot; // * [UTF-8] &quot;()C&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Double&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(D)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;doubleValue&quot; // * [UTF-8] &quot;()D&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Float&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(F)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;floatValue&quot; // * [UTF-8] &quot;()F&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Integer&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(I)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;intValue&quot; // * [UTF-8] &quot;()I&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Long&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(J)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;longValue&quot; // * [UTF-8] &quot;()J&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;java/lang/Short&quot; // * [CONSTANT_Class_info] for above // * [UTF-8] &quot;(S)V&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above // * [UTF-8] &quot;shortValue&quot; // * [UTF-8] &quot;()S&quot; // * [CONSTANT_NameAndType_info] for above // * [CONSTANT_Methodref_info] for above short numCPEntries = NUM_BASE_CPOOL_ENTRIES + NUM_COMMON_CPOOL_ENTRIES; boolean usesPrimitives = usesPrimitiveTypes(); if (usesPrimitives) &#123; numCPEntries += NUM_BOXING_CPOOL_ENTRIES; &#125; if (forSerialization) &#123; numCPEntries += NUM_SERIALIZATION_CPOOL_ENTRIES; &#125; // Add in variable-length number of entries to be able to describe // non-primitive parameter types and checked exceptions. numCPEntries += (short) (2 * numNonPrimitiveParameterTypes()); asm.emitShort(add(numCPEntries, S1)); final String generatedName = generateName(isConstructor, forSerialization); asm.emitConstantPoolUTF8(generatedName); asm.emitConstantPoolClass(asm.cpi()); thisClass = asm.cpi(); if (isConstructor) &#123; if (forSerialization) &#123; asm.emitConstantPoolUTF8 (&quot;sun/reflect/SerializationConstructorAccessorImpl&quot;); &#125; else &#123; asm.emitConstantPoolUTF8(&quot;sun/reflect/ConstructorAccessorImpl&quot;); &#125; &#125; else &#123; asm.emitConstantPoolUTF8(&quot;sun/reflect/MethodAccessorImpl&quot;); &#125; asm.emitConstantPoolClass(asm.cpi()); superClass = asm.cpi(); asm.emitConstantPoolUTF8(getClassName(declaringClass, false)); asm.emitConstantPoolClass(asm.cpi()); targetClass = asm.cpi(); short serializationTargetClassIdx = (short) 0; if (forSerialization) &#123; asm.emitConstantPoolUTF8(getClassName(serializationTargetClass, false)); asm.emitConstantPoolClass(asm.cpi()); serializationTargetClassIdx = asm.cpi(); &#125; asm.emitConstantPoolUTF8(name); asm.emitConstantPoolUTF8(buildInternalSignature()); asm.emitConstantPoolNameAndType(sub(asm.cpi(), S1), asm.cpi()); if (isInterface()) &#123; asm.emitConstantPoolInterfaceMethodref(targetClass, asm.cpi()); &#125; else &#123; if (forSerialization) &#123; asm.emitConstantPoolMethodref(serializationTargetClassIdx, asm.cpi()); &#125; else &#123; asm.emitConstantPoolMethodref(targetClass, asm.cpi()); &#125; &#125; targetMethodRef = asm.cpi(); if (isConstructor) &#123; asm.emitConstantPoolUTF8(&quot;newInstance&quot;); &#125; else &#123; asm.emitConstantPoolUTF8(&quot;invoke&quot;); &#125; invokeIdx = asm.cpi(); if (isConstructor) &#123; asm.emitConstantPoolUTF8(&quot;([Ljava/lang/Object;)Ljava/lang/Object;&quot;); &#125; else &#123; asm.emitConstantPoolUTF8 (&quot;(Ljava/lang/Object;[Ljava/lang/Object;)Ljava/lang/Object;&quot;); &#125; invokeDescriptorIdx = asm.cpi(); // Output class information for non-primitive parameter types nonPrimitiveParametersBaseIdx = add(asm.cpi(), S2); for (int i = 0; i &lt; parameterTypes.length; i++) &#123; Class&lt;?&gt; c = parameterTypes[i]; if (!isPrimitive(c)) &#123; asm.emitConstantPoolUTF8(getClassName(c, false)); asm.emitConstantPoolClass(asm.cpi()); &#125; &#125; // Entries common to FieldAccessor, MethodAccessor and ConstructorAccessor emitCommonConstantPoolEntries(); // Boxing entries if (usesPrimitives) &#123; emitBoxingContantPoolEntries(); &#125; if (asm.cpi() != numCPEntries) &#123; throw new InternalError(&quot;Adjust this code (cpi = &quot; + asm.cpi() + &quot;, numCPEntries = &quot; + numCPEntries + &quot;)&quot;); &#125; // Access flags asm.emitShort(ACC_PUBLIC); // This class asm.emitShort(thisClass); // Superclass asm.emitShort(superClass); // Interfaces count and interfaces asm.emitShort(S0); // Fields count and fields asm.emitShort(S0); // Methods count and methods asm.emitShort(NUM_METHODS); emitConstructor(); emitInvoke(); // Additional attributes (none) asm.emitShort(S0); // Load class vec.trim(); final byte[] bytes = vec.getData(); // Note: the class loader is the only thing that really matters // here -- it&#x27;s important to get the generated code into the // same namespace as the target class. Since the generated code // is privileged anyway, the protection domain probably doesn&#x27;t // matter. return AccessController.doPrivileged( new PrivilegedAction&lt;MagicAccessorImpl&gt;() &#123; public MagicAccessorImpl run() &#123; try &#123; return (MagicAccessorImpl) ClassDefiner.defineClass (generatedName, bytes, 0, bytes.length, declaringClass.getClassLoader()).newInstance(); &#125; catch (InstantiationException | IllegalAccessException e) &#123; throw new InternalError(e); &#125; &#125; &#125;);&#125; 咱们主要看这一句：ClassDefiner.defineClass(xx, declaringClass.getClassLoader()).newInstance(); 在ClassDefiner.defineClass方法实现中，每被调用一次都会生成一个DelegatingClassLoader类加载器对象 ，这里每次都生成新的类加载器，是为了性能考虑，在某些情况下可以卸载这些生成的类，因为类的卸载是只有在类加载器可以被回收的情况下才会被回收的，如果用了原来的类加载器，那可能导致这些新创建的类一直无法被卸载。 而反射生成的类，有时候可能用了就可以卸载了，所以使用其独立的类加载器，从而使得更容易控制反射类的生命周期。 反射调用流程小结最后，用几句话总结反射的实现原理： 反射类及反射方法的获取，都是通过从列表中搜寻查找匹配的方法，所以查找性能会随类的大小方法多少而变化； 每个类都会有一个与之对应的Class实例，从而每个类都可以获取method反射方法，并作用到其他实例身上； 反射也是考虑了线程安全的，放心使用； 反射使用软引用relectionData缓存class信息，避免每次重新从jvm获取带来的开销； 反射调用多次生成新代理Accessor, 而通过字节码生存的则考虑了卸载功能，所以会使用独立的类加载器； 当找到需要的方法，都会copy一份出来，而不是使用原来的实例，从而保证数据隔离； 调度反射方法，最终是由jvm执行invoke0()执行； 参考文章 https://www.codercto.com/a/46094.html https://blog.csdn.net/sinat_38259539/article/details/71799078 https://blog.csdn.net/qq_40896997/article/details/94483820 https://www.cnblogs.com/zhaoguhong/p/6937364.html https://juejin.im/post/5c160420e51d452a60684431 https://blog.csdn.net/mcryeasy/java/article/details/52344729","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"6.Java 基础 - 异常机制详解","path":"/2023/12/25/6.Java-基础-异常机制详解/","content":"Java异常是Java提供的一种识别及响应错误的一致性机制，java异常机制可以使程序中异常处理代码和正常业务代码分离，保证程序代码更加优雅，并提高程序健壮性。本文综合多篇文章后，总结了Java 异常的相关知识，希望可以提升你对Java中异常的认知效率。 异常的层次结构异常指不期而至的各种状况，如：文件找不到、网络连接失败、非法参数等。异常是一个事件，它发生在程序运行期间，干扰了正常的指令流程。Java通 过API中Throwable类的众多子类描述各种不同的异常。因而，Java异常都是对象，是Throwable子类的实例，描述了出现在一段编码中的 错误条件。当条件生成时，错误将引发异常。 Java异常类层次结构图： ThrowableThrowable 是 Java 语言中所有错误与异常的超类。 Throwable 包含两个子类：Error（错误）和 Exception（异常），它们通常用于指示发生了异常情况。 Throwable 包含了其线程创建时线程执行堆栈的快照，它提供了 printStackTrace() 等接口用于获取堆栈跟踪数据等信息。 Error（错误）Error 类及其子类：程序中无法处理的错误，表示运行应用程序中出现了严重的错误。 此类错误一般表示代码运行时 JVM 出现问题。通常有 VirtualMachineError（虚拟机运行错误）、NoClassDefFoundError（类定义错误）等。比如 OutOfMemoryError：内存不足错误；StackOverflowError：栈溢出错误。此类错误发生时，JVM 将终止线程。 这些错误是不受检异常，非代码性错误。因此，当此类错误发生时，应用程序不应该去处理此类错误。按照Java惯例，我们是不应该实现任何新的Error子类的！ Exception（异常）程序本身可以捕获并且可以处理的异常。Exception 这种异常又分为两类：运行时异常和编译时异常。 运行时异常 都是RuntimeException类及其子类异常，如NullPointerException(空指针异常)、IndexOutOfBoundsException(下标越界异常)等，这些异常是不检查异常，程序中可以选择捕获处理，也可以不处理。这些异常一般是由程序逻辑错误引起的，程序应该从逻辑角度尽可能避免这类异常的发生。 运行时异常的特点是Java编译器不会检查它，也就是说，当程序中可能出现这类异常，即使没有用try-catch语句捕获它，也没有用throws子句声明抛出它，也会编译通过。 非运行时异常 （编译异常） 是RuntimeException以外的异常，类型上都属于Exception类及其子类。从程序语法角度讲是必须进行处理的异常，如果不处理，程序就不能编译通过。如IOException、SQLException等以及用户自定义的Exception异常，一般情况下不自定义检查异常。 可查的异常（checked exceptions）和不可查的异常（unchecked exceptions） 可查异常（编译器要求必须处置的异常）： 正确的程序在运行中，很容易出现的、情理可容的异常状况。可查异常虽然是异常状况，但在一定程度上它的发生是可以预计的，而且一旦发生这种异常状况，就必须采取某种方式进行处理。 除了RuntimeException及其子类以外，其他的Exception类及其子类都属于可查异常。这种异常的特点是Java编译器会检查它，也就是说，当程序中可能出现这类异常，要么用try-catch语句捕获它，要么用throws子句声明抛出它，否则编译不会通过。 不可查异常(编译器不要求强制处置的异常) 包括运行时异常（RuntimeException与其子类）和错误（Error）。 异常基础提示 接下来我们看下异常使用的基础。 异常关键字 try – 用于监听。将要被监听的代码(可能抛出异常的代码)放在try语句块之内，当try语句块内发生异常时，异常就被抛出。 catch – 用于捕获异常。catch用来捕获try语句块中发生的异常。 finally – finally语句块总是会被执行。它主要用于回收在try块里打开的物力资源(如数据库连接、网络连接和磁盘文件)。只有finally块，执行完成之后，才会回来执行try或者catch块中的return或者throw语句，如果finally中使用了return或者throw等终止方法的语句，则就不会跳回执行，直接停止。 throw – 用于抛出异常。 throws – 用在方法签名中，用于声明该方法可能抛出的异常。 异常的申明(throws)在Java中，当前执行的语句必属于某个方法，Java解释器调用main方法执行开始执行程序。若方法中存在检查异常，如果不对其捕获，那必须在方法头中显式声明该异常，以便于告知方法调用者此方法有异常，需要进行处理。 在方法中声明一个异常，方法头中使用关键字throws，后面接上要声明的异常。若声明多个异常，则使用逗号分割。如下所示： 123public static void method() throws IOException, FileNotFoundException&#123; //something statements&#125; 注意：若是父类的方法没有声明异常，则子类继承方法后，也不能声明异常。 通常，应该捕获那些知道如何处理的异常，将不知道如何处理的异常继续传递下去。传递异常可以在方法签名处使用 throws 关键字声明可能会抛出的异常。 123456789private static void readFile(String filePath) throws IOException &#123; File file = new File(filePath); String result; BufferedReader reader = new BufferedReader(new FileReader(file)); while((result = reader.readLine())!=null) &#123; System.out.println(result); &#125; reader.close();&#125; Throws抛出异常的规则： 如果是不可查异常（unchecked exception），即Error、RuntimeException或它们的子类，那么可以不使用throws关键字来声明要抛出的异常，编译仍能顺利通过，但在运行时会被系统抛出。 必须声明方法可抛出的任何可查异常（checked exception）。即如果一个方法可能出现受可查异常，要么用try-catch语句捕获，要么用throws子句声明将它抛出，否则会导致编译错误 仅当抛出了异常，该方法的调用者才必须处理或者重新抛出该异常。当方法的调用者无力处理该异常的时候，应该继续抛出，而不是囫囵吞枣。 调用方法必须遵循任何可查异常的处理和声明规则。若覆盖一个方法，则不能声明与覆盖方法不同的异常。声明的任何异常必须是被覆盖方法所声明异常的同类或子类。 异常的抛出(throw)如果代码可能会引发某种错误，可以创建一个合适的异常类实例并抛出它，这就是抛出异常。如下所示： 123456public static double method(int value) &#123; if(value == 0) &#123; throw new ArithmeticException(&quot;参数不能为0&quot;); //抛出一个运行时异常 &#125; return 5.0 / value;&#125; 大部分情况下都不需要手动抛出异常，因为Java的大部分方法要么已经处理异常，要么已声明异常。所以一般都是捕获异常或者再往上抛。 有时我们会从 catch 中抛出一个异常，目的是为了改变异常的类型。多用于在多系统集成时，当某个子系统故障，异常类型可能有多种，可以用统一的异常类型向外暴露，不需暴露太多内部异常细节。 123456789private static void readFile(String filePath) throws MyException &#123; try &#123; // code &#125; catch (IOException e) &#123; MyException ex = new MyException(&quot;read file failed.&quot;); ex.initCause(e); throw ex; &#125;&#125; 异常的自定义习惯上，定义一个异常类应包含两个构造函数，一个无参构造函数和一个带有详细描述信息的构造函数（Throwable 的 toString 方法会打印这些详细信息，调试时很有用）, 比如上面用到的自定义MyException： 1234567public class MyException extends Exception &#123; public MyException()&#123; &#125; public MyException(String msg)&#123; super(msg); &#125; // ...&#125; 异常的捕获异常捕获处理的方法通常有： try-catch try-catch-finally try-finally try-with-resource try-catch在一个 try-catch 语句块中可以捕获多个异常类型，并对不同类型的异常做出不同的处理 123456789private static void readFile(String filePath) &#123; try &#123; // code &#125; catch (FileNotFoundException e) &#123; // handle FileNotFoundException &#125; catch (IOException e)&#123; // handle IOException &#125;&#125; 同一个 catch 也可以捕获多种类型异常，用 | 隔开 123456789private static void readFile(String filePath) &#123; try &#123; // code &#125; catch (FileNotFoundException | UnknownHostException e) &#123; // handle FileNotFoundException or UnknownHostException &#125; catch (IOException e)&#123; // handle IOException &#125;&#125; try-catch-finally 常规语法 1234567try &#123; //执行程序代码，可能会出现异常 &#125; catch(Exception e) &#123; //捕获异常并处理 &#125; finally &#123; //必执行的代码&#125; 执行的顺序 当try没有捕获到异常时：try语句块中的语句逐一被执行，程序将跳过catch语句块，执行finally语句块和其后的语句； 当try捕获到异常，catch语句块里没有处理此异常的情况：当try语句块里的某条语句出现异常时，而没有处理此异常的catch语句块时，此异常将会抛给JVM处理，finally语句块里的语句还是会被执行，但finally语句块后的语句不会被执行； 当try捕获到异常，catch语句块里有处理此异常的情况：在try语句块中是按照顺序来执行的，当执行到某一条语句出现异常时，程序将跳到catch语句块，并与catch语句块逐一匹配，找到与之对应的处理程序，其他的catch语句块将不会被执行，而try语句块中，出现异常之后的语句也不会被执行，catch语句块执行完后，执行finally语句块里的语句，最后执行finally语句块后的语句； 一个完整的例子 12345678910111213141516171819202122232425private static void readFile(String filePath) throws MyException &#123; File file = new File(filePath); String result; BufferedReader reader = null; try &#123; reader = new BufferedReader(new FileReader(file)); while((result = reader.readLine())!=null) &#123; System.out.println(result); &#125; &#125; catch (IOException e) &#123; System.out.println(&quot;readFile method catch block.&quot;); MyException ex = new MyException(&quot;read file failed.&quot;); ex.initCause(e); throw ex; &#125; finally &#123; System.out.println(&quot;readFile method finally block.&quot;); if (null != reader) &#123; try &#123; reader.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; try-finally 可以直接用try-finally吗？ 可以。 try块中引起异常，异常代码之后的语句不再执行，直接执行finally语句。 try块没有引发异常，则执行完try块就执行finally语句。 try-finally可用在不需要捕获异常的代码，可以保证资源在使用后被关闭。例如IO流中执行完相应操作后，关闭相应资源；使用Lock对象保证线程同步，通过finally可以保证锁会被释放；数据库连接代码时，关闭连接操作等等。 1234567//以Lock加锁为例，演示try-finallyReentrantLock lock = new ReentrantLock();try &#123; //需要加锁的代码&#125; finally &#123; lock.unlock(); //保证锁一定被释放&#125; finally遇见如下情况不会执行 在前面的代码中用了System.exit()退出程序。 finally语句块中发生了异常。 程序所在的线程死亡。 关闭CPU。 try-with-resource try-with-resource是Java 7中引入的，很容易被忽略。 上面例子中，finally 中的 close 方法也可能抛出 IOException, 从而覆盖了原始异常。JAVA 7 提供了更优雅的方式来实现资源的自动释放，自动释放的资源需要是实现了 AutoCloseable 接口的类。 代码实现 1234567private static void tryWithResourceTest()&#123; try (Scanner scanner = new Scanner(new FileInputStream(&quot;c:/abc&quot;),&quot;UTF-8&quot;))&#123; // code &#125; catch (IOException e)&#123; // handle exception &#125;&#125; 看下Scanner 123456public final class Scanner implements Iterator&lt;String&gt;, Closeable &#123; // ...&#125;public interface Closeable extends AutoCloseable &#123; public void close() throws IOException;&#125; try 代码块退出时，会自动调用 scanner.close 方法，和把 scanner.close 方法放在 finally 代码块中不同的是，若 scanner.close 抛出异常，则会被抑制，抛出的仍然为原始异常。被抑制的异常会由 addSusppressed 方法添加到原来的异常，如果想要获取被抑制的异常列表，可以调用 getSuppressed 方法来获取。 异常基础总结 try、catch和finally都不能单独使用，只能是try-catch、try-finally或者try-catch-finally。 try语句块监控代码，出现异常就停止执行下面的代码，然后将异常移交给catch语句块来处理。 finally语句块中的代码一定会被执行，常用于回收资源 。 throws：声明一个异常，告知方法调用者。 throw ：抛出一个异常，至于该异常被捕获还是继续抛出都与它无关。 Java编程思想一书中，对异常的总结。 在恰当的级别处理问题。（在知道该如何处理的情况下了捕获异常。） 解决问题并且重新调用产生异常的方法。 进行少许修补，然后绕过异常发生的地方继续执行。 用别的数据进行计算，以代替方法预计会返回的值。 把当前运行环境下能做的事尽量做完，然后把相同的异常重抛到更高层。 把当前运行环境下能做的事尽量做完，然后把不同的异常抛到更高层。 终止程序。 进行简化（如果你的异常模式使问题变得太复杂，那么用起来会非常痛苦）。 让类库和程序更安全。 常用的异常在Java中提供了一些异常用来描述经常发生的错误，对于这些异常，有的需要程序员进行捕获处理或声明抛出，有的是由Java虚拟机自动进行捕获处理。Java中常见的异常类: RuntimeException java.lang.ArrayIndexOutOfBoundsException 数组索引越界异常。当对数组的索引值为负数或大于等于数组大小时抛出。 java.lang.ArithmeticException 算术条件异常。譬如：整数除零等。 java.lang.NullPointerException 空指针异常。当应用试图在要求使用对象的地方使用了null时，抛出该异常。譬如：调用null对象的实例方法、访问null对象的属性、计算null对象的长度、使用throw语句抛出null等等 java.lang.ClassNotFoundException 找不到类异常。当应用试图根据字符串形式的类名构造类，而在遍历CLASSPAH之后找不到对应名称的class文件时，抛出该异常。 java.lang.NegativeArraySizeException 数组长度为负异常 java.lang.ArrayStoreException 数组中包含不兼容的值抛出的异常 java.lang.SecurityException 安全性异常 java.lang.IllegalArgumentException 非法参数异常 IOException IOException：操作输入流和输出流时可能出现的异常。 EOFException 文件已结束异常 FileNotFoundException 文件未找到异常 其他 ClassCastException 类型转换异常类 ArrayStoreException 数组中包含不兼容的值抛出的异常 SQLException 操作数据库异常类 NoSuchFieldException 字段未找到异常 NoSuchMethodException 方法未找到抛出的异常 NumberFormatException 字符串转换为数字抛出的异常 StringIndexOutOfBoundsException 字符串索引超出范围抛出的异常 IllegalAccessException 不允许访问某类异常 InstantiationException 当应用程序试图使用Class类中的newInstance()方法创建一个类的实例，而指定的类对象无法被实例化时，抛出该异常 异常实践提示 在 Java 中处理异常并不是一个简单的事情。不仅仅初学者很难理解，即使一些有经验的开发者也需要花费很多时间来思考如何处理异常，包括需要处理哪些异常，怎样处理等等。这也是绝大多数开发团队都会制定一些规则来规范进行异常处理的原因。 当你抛出或捕获异常的时候，有很多不同的情况需要考虑，而且大部分事情都是为了改善代码的可读性或者 API 的可用性。 异常不仅仅是一个错误控制机制，也是一个通信媒介。因此，为了和同事更好的合作，一个团队必须要制定出一个最佳实践和规则，只有这样，团队成员才能理解这些通用概念，同时在工作中使用它。 这里给出几个被很多团队使用的异常处理最佳实践。 只针对不正常的情况才使用异常 异常只应该被用于不正常的条件，它们永远不应该被用于正常的控制流。《阿里手册》中：【强制】Java 类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过catch 的方式来处理，比如：NullPointerException，IndexOutOfBoundsException等等。 比如，在解析字符串形式的数字时，可能存在数字格式错误，不得通过catch Exception来实现 代码1 123if (obj != null) &#123; //...&#125; 代码2 12345try &#123; obj.method(); &#125; catch (NullPointerException e) &#123; //...&#125; 主要原因有三点： 异常机制的设计初衷是用于不正常的情况，所以很少会会JVM实现试图对它们的性能进行优化。所以，创建、抛出和捕获异常的开销是很昂贵的。 把代码放在try-catch中返回阻止了JVM实现本来可能要执行的某些特定的优化。 对数组进行遍历的标准模式并不会导致冗余的检查，有些现代的JVM实现会将它们优化掉。 在 finally 块中清理资源或者使用 try-with-resource 语句当使用类似InputStream这种需要使用后关闭的资源时，一个常见的错误就是在try块的最后关闭资源。 错误示例 1234567891011121314public void doNotCloseResourceInTry() &#123; FileInputStream inputStream = null; try &#123; File file = new File(&quot;./tmp.txt&quot;); inputStream = new FileInputStream(file); // use the inputStream to read a file // do NOT do this inputStream.close(); &#125; catch (FileNotFoundException e) &#123; log.error(e); &#125; catch (IOException e) &#123; log.error(e); &#125;&#125; 问题就是，只有没有异常抛出的时候，这段代码才可以正常工作。try 代码块内代码会正常执行，并且资源可以正常关闭。但是，使用 try 代码块是有原因的，一般调用一个或多个可能抛出异常的方法，而且，你自己也可能会抛出一个异常，这意味着代码可能不会执行到 try 代码块的最后部分。结果就是，你并没有关闭资源。 所以，你应该把清理工作的代码放到 finally 里去，或者使用 try-with-resource 特性。 方法一：使用 finally 代码块 与前面几行 try 代码块不同，finally 代码块总是会被执行。不管 try 代码块成功执行之后还是你在 catch 代码块中处理完异常后都会执行。因此，你可以确保你清理了所有打开的资源。 123456789101112131415161718public void closeResourceInFinally() &#123; FileInputStream inputStream = null; try &#123; File file = new File(&quot;./tmp.txt&quot;); inputStream = new FileInputStream(file); // use the inputStream to read a file &#125; catch (FileNotFoundException e) &#123; log.error(e); &#125; finally &#123; if (inputStream != null) &#123; try &#123; inputStream.close(); &#125; catch (IOException e) &#123; log.error(e); &#125; &#125; &#125;&#125; 方法二：Java 7 的 try-with-resource 语法 如果你的资源实现了 AutoCloseable 接口，你可以使用这个语法。大多数的 Java 标准资源都继承了这个接口。当你在 try 子句中打开资源，资源会在 try 代码块执行后或异常处理后自动关闭。 12345678910public void automaticallyCloseResource() &#123; File file = new File(&quot;./tmp.txt&quot;); try (FileInputStream inputStream = new FileInputStream(file);) &#123; // use the inputStream to read a file &#125; catch (FileNotFoundException e) &#123; log.error(e); &#125; catch (IOException e) &#123; log.error(e); &#125;&#125; 尽量使用标准的异常 代码重用是值得提倡的，这是一条通用规则，异常也不例外。 重用现有的异常有几个好处： 它使得你的API更加易于学习和使用，因为它与程序员原来已经熟悉的习惯用法是一致的。 对于用到这些API的程序而言，它们的可读性更好，因为它们不会充斥着程序员不熟悉的异常。 异常类越少，意味着内存占用越小，并且转载这些类的时间开销也越小。 Java标准异常中有几个是经常被使用的异常。如下表格： 异常 使用场合 IllegalArgumentException 参数的值不合适 IllegalStateException 参数的状态不合适 NullPointerException 在null被禁止的情况下参数值为null IndexOutOfBoundsException 下标越界 ConcurrentModificationException 在禁止并发修改的情况下，对象检测到并发修改 UnsupportedOperationException 对象不支持客户请求的方法 虽然它们是Java平台库迄今为止最常被重用的异常，但是，在许可的条件下，其它的异常也可以被重用。例如，如果你要实现诸如复数或者矩阵之类的算术对象，那么重用ArithmeticException和NumberFormatException将是非常合适的。如果一个异常满足你的需要，则不要犹豫，使用就可以，不过你一定要确保抛出异常的条件与该异常的文档中描述的条件一致。这种重用必须建立在语义的基础上，而不是名字的基础上。 最后，一定要清楚，选择重用哪一种异常并没有必须遵循的规则。例如，考虑纸牌对象的情形，假设有一个用于发牌操作的方法，它的参数(handSize)是发一手牌的纸牌张数。假设调用者在这个参数中传递的值大于整副牌的剩余张数。那么这种情形既可以被解释为IllegalArgumentException(handSize的值太大)，也可以被解释为IllegalStateException(相对客户的请求而言，纸牌对象的纸牌太少)。 对异常进行文档说明 当在方法上声明抛出异常时，也需要进行文档说明。目的是为了给调用者提供尽可能多的信息，从而可以更好地避免或处理异常。 在 Javadoc 添加 @throws 声明，并且描述抛出异常的场景。 12345678/*** Method description* * @throws MyBusinessException - businuess exception description*/public void doSomething(String input) throws MyBusinessException &#123; // ...&#125; 同时，在抛出MyBusinessException 异常时，需要尽可能精确地描述问题和相关信息，这样无论是打印到日志中还是在监控工具中，都能够更容易被人阅读，从而可以更好地定位具体错误信息、错误的严重程度等。 优先捕获最具体的异常 大多数 IDE 都可以帮助你实现这个最佳实践。当你尝试首先捕获较不具体的异常时，它们会报告无法访问的代码块。 但问题在于，只有匹配异常的第一个 catch 块会被执行。 因此，如果首先捕获 IllegalArgumentException ，则永远不会到达应该处理更具体的 NumberFormatException 的 catch 块，因为它是 IllegalArgumentException 的子类。 总是优先捕获最具体的异常类，并将不太具体的 catch 块添加到列表的末尾。 你可以在下面的代码片断中看到这样一个 try-catch 语句的例子。 第一个 catch 块处理所有 NumberFormatException 异常，第二个处理所有非 NumberFormatException 异常的IllegalArgumentException 异常。 123456789public void catchMostSpecificExceptionFirst() &#123; try &#123; doSomething(&quot;A message&quot;); &#125; catch (NumberFormatException e) &#123; log.error(e); &#125; catch (IllegalArgumentException e) &#123; log.error(e) &#125;&#125; 不要捕获 Throwable 类 Throwable 是所有异常和错误的超类。你可以在 catch 子句中使用它，但是你永远不应该这样做！ 如果在 catch 子句中使用 Throwable ，它不仅会捕获所有异常，也将捕获所有的错误。JVM 抛出错误，指出不应该由应用程序处理的严重问题。 典型的例子是 OutOfMemoryError 或者 StackOverflowError 。两者都是由应用程序控制之外的情况引起的，无法处理。 所以，最好不要捕获 Throwable ，除非你确定自己处于一种特殊的情况下能够处理错误。 1234567public void doNotCatchThrowable() &#123; try &#123; // do something &#125; catch (Throwable t) &#123; // don&#x27;t do this! &#125;&#125; 不要忽略异常 很多时候，开发者很有自信不会抛出异常，因此写了一个catch块，但是没有做任何处理或者记录日志。 1234567public void doNotIgnoreExceptions() &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; // this will never happen &#125;&#125; 但现实是经常会出现无法预料的异常，或者无法确定这里的代码未来是不是会改动(删除了阻止异常抛出的代码)，而此时由于异常被捕获，使得无法拿到足够的错误信息来定位问题。 合理的做法是至少要记录异常的信息。 1234567public void logAnException() &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; log.error(&quot;This should never happen: &quot; + e); // see this line &#125;&#125; 不要记录并抛出异常 这可能是本文中最常被忽略的最佳实践。 可以发现很多代码甚至类库中都会有捕获异常、记录日志并再次抛出的逻辑。如下： 123456try &#123; new Long(&quot;xyz&quot;);&#125; catch (NumberFormatException e) &#123; log.error(e); throw e;&#125; 这个处理逻辑看着是合理的。但这经常会给同一个异常输出多条日志。如下： 123456717:44:28,945 ERROR TestExceptionHandling:65 - java.lang.NumberFormatException: For input string: &quot;xyz&quot;Exception in thread &quot;main&quot; java.lang.NumberFormatException: For input string: &quot;xyz&quot;at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)at java.lang.Long.parseLong(Long.java:589)at java.lang.Long.(Long.java:965)at com.stackify.example.TestExceptionHandling.logAndThrowException(TestExceptionHandling.java:63)at com.stackify.example.TestExceptionHandling.main(TestExceptionHandling.java:58) 如上所示，后面的日志也没有附加更有用的信息。如果想要提供更加有用的信息，那么可以将异常包装为自定义异常。 1234567public void wrapException(String input) throws MyBusinessException &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; throw new MyBusinessException(&quot;A message that describes the error.&quot;, e); &#125;&#125; 因此，仅仅当想要处理异常时才去捕获，否则只需要在方法签名中声明让调用者去处理。 包装异常时不要抛弃原始的异常捕获标准异常并包装为自定义异常是一个很常见的做法。这样可以添加更为具体的异常信息并能够做针对的异常处理。 在你这样做时，请确保将原始异常设置为原因（注：参考下方代码 NumberFormatException e 中的原始异常 e ）。Exception 类提供了特殊的构造函数方法，它接受一个 Throwable 作为参数。否则，你将会丢失堆栈跟踪和原始异常的消息，这将会使分析导致异常的异常事件变得困难。 1234567public void wrapException(String input) throws MyBusinessException &#123; try &#123; // do something &#125; catch (NumberFormatException e) &#123; throw new MyBusinessException(&quot;A message that describes the error.&quot;, e); &#125;&#125; 不要使用异常控制程序的流程不应该使用异常控制应用的执行流程，例如，本应该使用if语句进行条件判断的情况下，你却使用异常处理，这是非常不好的习惯，会严重影响应用的性能。 不要在finally块中使用return。try块中的return语句执行成功后，并不马上返回，而是继续执行finally块中的语句，如果此处存在return语句，则在此直接返回，无情丢弃掉try块中的返回点。 如下是一个反例： 12345678910private int x = 0;public int checkReturn() &#123; try &#123; // x等于1，此处不返回 return ++x; &#125; finally &#123; // 返回的结果是2 return ++x; &#125;&#125; 深入理解异常 提示 我们再深入理解下异常，看下底层实现。 JVM处理异常的机制？提到JVM处理异常的机制，就需要提及Exception Table，以下称为异常表。我们暂且不急于介绍异常表，先看一个简单的 Java 处理异常的小例子。 1234567public static void simpleTryCatch() &#123; try &#123; testNPE(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125;&#125; 上面的代码是一个很简单的例子，用来捕获处理一个潜在的空指针异常。 当然如果只是看简简单单的代码，我们很难看出什么高深之处，更没有了今天文章要谈论的内容。 所以这里我们需要借助一把神兵利器，它就是javap,一个用来拆解class文件的工具，和javac一样由JDK提供。 然后我们使用javap来分析这段代码（需要先使用javac编译） 123456789101112//javap -c Main public static void simpleTryCatch(); Code: 0: invokestatic #3 // Method testNPE:()V 3: goto 11 6: astore_0 7: aload_0 8: invokevirtual #5 // Method java/lang/Exception.printStackTrace:()V 11: return Exception table: from to target type 0 3 6 Class java/lang/Exception 看到上面的代码，应该会有会心一笑，因为终于看到了Exception table，也就是我们要研究的异常表。 异常表中包含了一个或多个异常处理者(Exception Handler)的信息，这些信息包含如下 from 可能发生异常的起始点 to 可能发生异常的结束点 target 上述from和to之前发生异常后的异常处理者的位置 type 异常处理者处理的异常的类信息 那么异常表用在什么时候呢 答案是异常发生的时候，当一个异常发生时 1.JVM会在当前出现异常的方法中，查找异常表，是否有合适的处理者来处理 2.如果当前方法异常表不为空，并且异常符合处理者的from和to节点，并且type也匹配，则JVM调用位于target的调用者来处理。 3.如果上一条未找到合理的处理者，则继续查找异常表中的剩余条目 4.如果当前方法的异常表无法处理，则向上查找（弹栈处理）刚刚调用该方法的调用处，并重复上面的操作。 5.如果所有的栈帧被弹出，仍然没有处理，则抛给当前的Thread，Thread则会终止。 6.如果当前Thread为最后一个非守护线程，且未处理异常，则会导致JVM终止运行。 以上就是JVM处理异常的一些机制。 try-catch -finally 除了简单的try-catch外，我们还常常和finally做结合使用。比如这样的代码 123456789public static void simpleTryCatchFinally() &#123; try &#123; testNPE(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(&quot;Finally&quot;); &#125;&#125; 同样我们使用javap分析一下代码 1234567891011121314151617181920212223242526public static void simpleTryCatchFinally(); Code: 0: invokestatic #3 // Method testNPE:()V 3: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 6: ldc #7 // String Finally 8: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 11: goto 41 14: astore_0 15: aload_0 16: invokevirtual #5 // Method java/lang/Exception.printStackTrace:()V 19: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 22: ldc #7 // String Finally 24: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 27: goto 41 30: astore_1 31: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 34: ldc #7 // String Finally 36: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 39: aload_1 40: athrow 41: return Exception table: from to target type 0 3 14 Class java/lang/Exception 0 3 30 any 14 19 30 any 和之前有所不同，这次异常表中，有三条数据，而我们仅仅捕获了一个Exception, 异常表的后两个item的type为any; 上面的三条异常表item的意思为: 如果0到3之间，发生了Exception类型的异常，调用14位置的异常处理者。 如果0到3之间，无论发生什么异常，都调用30位置的处理者 如果14到19之间（即catch部分），不论发生什么异常，都调用30位置的处理者。 再次分析上面的Java代码，finally里面的部分已经被提取到了try部分和catch部分。我们再次调一下代码来看一下 1234567891011121314151617181920212223242526public static void simpleTryCatchFinally(); Code: //try 部分提取finally代码，如果没有异常发生，则执行输出finally操作，直至goto到41位置，执行返回操作。 0: invokestatic #3 // Method testNPE:()V 3: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 6: ldc #7 // String Finally 8: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 11: goto 41 //catch部分提取finally代码，如果没有异常发生，则执行输出finally操作，直至执行got到41位置，执行返回操作。 14: astore_0 15: aload_0 16: invokevirtual #5 // Method java/lang/Exception.printStackTrace:()V 19: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 22: ldc #7 // String Finally 24: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 27: goto 41 //finally部分的代码如果被调用，有可能是try部分，也有可能是catch部分发生异常。 30: astore_1 31: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 34: ldc #7 // String Finally 36: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 39: aload_1 40: athrow //如果异常没有被catch捕获，而是到了这里，执行完finally的语句后，仍然要把这个异常抛出去，传递给调用处。 41: return Catch先后顺序的问题 我们在代码中的catch的顺序决定了异常处理者在异常表的位置，所以，越是具体的异常要先处理，否则就会出现下面的问题 123456789private static void misuseCatchException() &#123; try &#123; testNPE(); &#125; catch (Throwable t) &#123; t.printStackTrace(); &#125; catch (Exception e) &#123; //error occurs during compilings with tips Exception Java.lang.Exception has already benn caught. e.printStackTrace(); &#125;&#125; 这段代码会导致编译失败，因为先捕获Throwable后捕获Exception，会导致后面的catch永远无法被执行。 Return 和finally的问题 这算是我们扩展的一个相对比较极端的问题，就是类似这样的代码，既有return，又有finally，那么finally导致会不会执行 12345678910public static String tryCatchReturn() &#123; try &#123; testNPE(); return &quot;OK&quot;; &#125; catch (Exception e) &#123; return &quot;ERROR&quot;; &#125; finally &#123; System.out.println(&quot;tryCatchReturn&quot;); &#125;&#125; 答案是finally会执行，那么还是使用上面的方法，我们来看一下为什么finally会执行。 123456789101112131415161718192021222324public static java.lang.String tryCatchReturn(); Code: 0: invokestatic #3 // Method testNPE:()V 3: ldc #6 // String OK 5: astore_0 6: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 9: ldc #8 // String tryCatchReturn 11: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 14: aload_0 15: areturn 返回OK字符串，areturn意思为return a reference from a method 16: astore_0 17: ldc #10 // String ERROR 19: astore_1 20: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 23: ldc #8 // String tryCatchReturn 25: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 28: aload_1 29: areturn //返回ERROR字符串 30: astore_2 31: getstatic #7 // Field java/lang/System.out:Ljava/io/PrintStream; 34: ldc #8 // String tryCatchReturn 36: invokevirtual #9 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 39: aload_2 40: athrow 如果catch有未处理的异常，抛出去。 异常是否耗时？为什么会耗时？说用异常慢，首先来看看异常慢在哪里？有多慢？下面的测试用例简单的测试了建立对象、建立异常对象、抛出并接住异常对象三者的耗时对比： 123456789101112131415161718192021222324252627282930313233343536373839404142public class ExceptionTest &#123; private int testTimes; public ExceptionTest(int testTimes) &#123; this.testTimes = testTimes; &#125; public void newObject() &#123; long l = System.nanoTime(); for (int i = 0; i &lt; testTimes; i++) &#123; new Object(); &#125; System.out.println(&quot;建立对象：&quot; + (System.nanoTime() - l)); &#125; public void newException() &#123; long l = System.nanoTime(); for (int i = 0; i &lt; testTimes; i++) &#123; new Exception(); &#125; System.out.println(&quot;建立异常对象：&quot; + (System.nanoTime() - l)); &#125; public void catchException() &#123; long l = System.nanoTime(); for (int i = 0; i &lt; testTimes; i++) &#123; try &#123; throw new Exception(); &#125; catch (Exception e) &#123; &#125; &#125; System.out.println(&quot;建立、抛出并接住异常对象：&quot; + (System.nanoTime() - l)); &#125; public static void main(String[] args) &#123; ExceptionTest test = new ExceptionTest(10000); test.newObject(); test.newException(); test.catchException(); &#125; &#125; 运行结果： 123建立对象：575817 建立异常对象：9589080 建立、抛出并接住异常对象：47394475 建立一个异常对象，是建立一个普通Object耗时的约20倍（实际上差距会比这个数字更大一些，因为循环也占用了时间，追求精确的读者可以再测一下空循环的耗时然后在对比前减掉这部分），而抛出、接住一个异常对象，所花费时间大约是建立异常对象的4倍。 那占用时间的“大头”：抛出、接住异常，系统到底做了什么事情？请参考这篇文章： https://www.iteye.com/blog/icyfenix-857722 参考文章 https://blog.csdn.net/MacWx/article/details/90204111 https://blog.csdn.net/hguisu/article/details/6155636 https://blog.csdn.net/ThinkWon/article/details/101681073 https://www.cnblogs.com/skywang12345/p/3544287.html https://www.codercto.com/a/33350.html","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"5.Java 基础 - 注解机制详解","path":"/2023/12/25/5.Java-基础-注解机制详解/","content":"注解是JDK1.5版本开始引入的一个特性，用于对代码进行说明，可以对包、类、接口、字段、方法参数、局部变量等进行注解。它是框架学习和设计者必须掌握的基础。 注解基础注解是JDK1.5版本开始引入的一个特性，用于对代码进行说明，可以对包、类、接口、字段、方法参数、局部变量等进行注解。它主要的作用有以下四方面： 生成文档，通过代码里标识的元数据生成javadoc文档。 编译检查，通过代码里标识的元数据让编译器在编译期间进行检查验证。 编译时动态处理，编译时通过代码里标识的元数据动态处理，例如动态生成代码。 运行时动态处理，运行时通过代码里标识的元数据动态处理，例如使用反射注入实例。 这么来说是比较抽象的，我们具体看下注解的常见分类： Java自带的标准注解，包括@Override、@Deprecated和@SuppressWarnings，分别用于标明重写某个方法、标明某个类或方法过时、标明要忽略的警告，用这些注解标明后编译器就会进行检查。 元注解，元注解是用于定义注解的注解，包括@Retention、@Target、@Inherited、@Documented，@Retention用于标明注解被保留的阶段，@Target用于标明注解使用的范围，@Inherited用于标明注解可继承，@Documented用于标明是否生成javadoc文档。 自定义注解，可以根据自己的需求定义注解，并可用元注解对自定义注解进行注解。 接下来我们通过这个分类角度来理解注解。 Java内置注解我们从最为常见的Java内置的注解开始说起，先看下下面的代码： 123456789101112131415161718192021222324252627282930313233class A&#123; public void test() &#123; &#125;&#125;class B extends A&#123; /** * 重载父类的test方法 */ @Override public void test() &#123; &#125; /** * 被弃用的方法 */ @Deprecated public void oldMethod() &#123; &#125; /** * 忽略告警 * * @return */ @SuppressWarnings(&quot;rawtypes&quot;) public List processList() &#123; List list = new ArrayList(); return list; &#125;&#125; Java 1.5开始自带的标准注解，包括@Override、@Deprecated和@SuppressWarnings： @Override：表示当前的方法定义将覆盖父类中的方法 @Deprecated：表示代码被弃用，如果使用了被@Deprecated注解的代码则编译器将发出警告 @SuppressWarnings：表示关闭编译器警告信息 我们再具体看下这几个内置注解，同时通过这几个内置注解中的元注解的定义来引出元注解。 内置注解 - @Override我们先来看一下这个注解类型的定义： 1234@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override &#123;&#125; 从它的定义我们可以看到，这个注解可以被用来修饰方法，并且它只在编译时有效，在编译后的class文件中便不再存在。这个注解的作用我们大家都不陌生，那就是告诉编译器被修饰的方法是重写的父类的中的相同签名的方法，编译器会对此做出检查，若发现父类中不存在这个方法或是存在的方法签名不同，则会报错。 内置注解 - @Deprecated这个注解的定义如下： 12345@Documented@Retention(RetentionPolicy.RUNTIME)@Target(value=&#123;CONSTRUCTOR, FIELD, LOCAL_VARIABLE, METHOD, PACKAGE, PARAMETER, TYPE&#125;)public @interface Deprecated &#123;&#125; 从它的定义我们可以知道，它会被文档化，能够保留到运行时，能够修饰构造方法、属性、局部变量、方法、包、参数、类型。这个注解的作用是告诉编译器被修饰的程序元素已被“废弃”，不再建议用户使用。 内置注解 - @SuppressWarnings这个注解我们也比较常用到，先来看下它的定义： 12345@Target(&#123;TYPE, FIELD, METHOD, PARAMETER, CONSTRUCTOR, LOCAL_VARIABLE&#125;)@Retention(RetentionPolicy.SOURCE)public @interface SuppressWarnings &#123; String[] value();&#125; 它能够修饰的程序元素包括类型、属性、方法、参数、构造器、局部变量，只能存活在源码时，取值为String[]。它的作用是告诉编译器忽略指定的警告信息，它可以取的值如下所示： 参数 作用 原描述 all 抑制所有警告 to suppress all warnings boxing 抑制装箱、拆箱操作时候的警告 to suppress warnings relative to boxing&#x2F;unboxing operations cast 抑制映射相关的警告 to suppress warnings relative to cast operations dep-ann 抑制启用注释的警告 to suppress warnings relative to deprecated annotation deprecation 抑制过期方法警告 to suppress warnings relative to deprecation fallthrough 抑制确在switch中缺失breaks的警告 to suppress warnings relative to missing breaks in switch statements finally 抑制finally模块没有返回的警告 to suppress warnings relative to finally block that don’t return hiding 抑制与隐藏变数的区域变数相关的警告 to suppress warnings relative to locals that hide variable（） incomplete-switch 忽略没有完整的switch语句 to suppress warnings relative to missing entries in a switch statement (enum case) nls 忽略非nls格式的字符 to suppress warnings relative to non-nls string literals null 忽略对null的操作 to suppress warnings relative to null analysis rawtype 使用generics时忽略没有指定相应的类型 to suppress warnings relative to un-specific types when using restriction 抑制与使用不建议或禁止参照相关的警告 to suppress warnings relative to usage of discouraged or serial 忽略在serializable类中没有声明serialVersionUID变量 to suppress warnings relative to missing serialVersionUID field for a serializable class static-access 抑制不正确的静态访问方式警告 to suppress warnings relative to incorrect static access synthetic-access 抑制子类没有按最优方法访问内部类的警告 to suppress warnings relative to unoptimized access from inner classes unchecked 抑制没有进行类型检查操作的警告 to suppress warnings relative to unchecked operations unqualified-field-access 抑制没有权限访问的域的警告 to suppress warnings relative to field access unqualified unused 抑制没被使用过的代码的警告 to suppress warnings relative to unused code 元注解上述内置注解的定义中使用了一些元注解（注解类型进行注解的注解类），在JDK 1.5中提供了4个标准的元注解：@Target，@Retention，@Documented，@Inherited, 在JDK 1.8中提供了两个元注解 @Repeatable和@Native。 元注解 - @Target Target注解的作用是：描述注解的使用范围（即：被修饰的注解可以用在什么地方） 。 Target注解用来说明那些被它所注解的注解类可修饰的对象范围：注解可以用于修饰 packages、types（类、接口、枚举、注解类）、类成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数），在定义注解类时使用了@Target 能够更加清晰的知道它能够被用来修饰哪些对象，它的取值范围定义在ElementType 枚举中。 1234567891011121314151617181920212223public enum ElementType &#123; TYPE, // 类、接口、枚举类 FIELD, // 成员变量（包括：枚举常量） METHOD, // 成员方法 PARAMETER, // 方法参数 CONSTRUCTOR, // 构造方法 LOCAL_VARIABLE, // 局部变量 ANNOTATION_TYPE, // 注解类 PACKAGE, // 可用于修饰：包 TYPE_PARAMETER, // 类型参数，JDK 1.8 新增 TYPE_USE // 使用类型的任何地方，JDK 1.8 新增 &#125; 元注解 - @Retention &amp; @RetentionTarget Reteniton注解的作用是：描述注解保留的时间范围（即：被描述的注解在它所修饰的类中可以被保留到何时） 。 Reteniton注解用来限定那些被它所注解的注解类在注解到其他类上以后，可被保留到何时，一共有三种策略，定义在RetentionPolicy枚举中。 123456public enum RetentionPolicy &#123; SOURCE, // 源文件保留 CLASS, // 编译期保留，默认值 RUNTIME // 运行期保留，可通过反射去获取注解信息&#125; 为了验证应用了这三种策略的注解类有何区别，分别使用三种策略各定义一个注解类做测试。 123456789101112@Retention(RetentionPolicy.SOURCE)public @interface SourcePolicy &#123; &#125;@Retention(RetentionPolicy.CLASS)public @interface ClassPolicy &#123; &#125;@Retention(RetentionPolicy.RUNTIME)public @interface RuntimePolicy &#123; &#125; 用定义好的三个注解类分别去注解一个方法。 1234567891011121314public class RetentionTest &#123; @SourcePolicy\tpublic void sourcePolicy() &#123;\t&#125; @ClassPolicy\tpublic void classPolicy() &#123;\t&#125; @RuntimePolicy\tpublic void runtimePolicy() &#123;\t&#125;&#125; 通过执行 javap -verbose RetentionTest命令获取到的RetentionTest 的 class 字节码内容如下。 123456789101112131415161718192021222324252627282930313233343536373839&#123; public retention.RetentionTest(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 public void sourcePolicy(); flags: ACC_PUBLIC Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 7: 0 public void classPolicy(); flags: ACC_PUBLIC Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 11: 0 RuntimeInvisibleAnnotations: 0: #11() public void runtimePolicy(); flags: ACC_PUBLIC Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 15: 0 RuntimeVisibleAnnotations: 0: #14()&#125; 从 RetentionTest 的字节码内容我们可以得出以下两点结论： 编译器并没有记录下 sourcePolicy() 方法的注解信息； 编译器分别使用了 RuntimeInvisibleAnnotations 和 RuntimeVisibleAnnotations 属性去记录了classPolicy()方法 和 runtimePolicy()方法 的注解信息； 元注解 - @Documented Documented注解的作用是：描述在使用 javadoc 工具为类生成帮助文档时是否要保留其注解信息。 以下代码在使用Javadoc工具可以生成@TestDocAnnotation注解信息。 1234567891011121314import java.lang.annotation.Documented;import java.lang.annotation.ElementType;import java.lang.annotation.Target; @Documented@Target(&#123;ElementType.TYPE,ElementType.METHOD&#125;)public @interface TestDocAnnotation &#123; public String value() default &quot;default&quot;;&#125;@TestDocAnnotation(&quot;myMethodDoc&quot;)public void testDoc() &#123;&#125; 元注解 - @Inherited Inherited注解的作用：被它修饰的Annotation将具有继承性。如果某个类使用了被@Inherited修饰的Annotation，则其子类将自动具有该注解。 我们来测试下这个注解： 定义@Inherited注解： 1234567@Inherited@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE,ElementType.METHOD&#125;)public @interface TestInheritedAnnotation &#123; String [] values(); int number();&#125; 使用这个注解 1234567891011121314@TestInheritedAnnotation(values = &#123;&quot;value&quot;&#125;, number = 10)public class Person &#123;&#125;class Student extends Person&#123;\t@Test public void test()&#123; Class clazz = Student.class; Annotation[] annotations = clazz.getAnnotations(); for (Annotation annotation : annotations) &#123; System.out.println(annotation.toString()); &#125; &#125;&#125; 输出 1xxxxxxx.TestInheritedAnnotation(values=[value], number=10) 即使Student类没有显示地被注解@TestInheritedAnnotation，但是它的父类Person被注解，而且@TestInheritedAnnotation被@Inherited注解，因此Student类自动有了该注解。 元注解 - @Repeatable (Java8)@Repeatable请参考 Java 8 - 重复注解 元注解 - @Native (Java8)使用 @Native 注解修饰成员变量，则表示这个变量可以被本地代码引用，常常被代码生成工具使用。对于 @Native 注解不常使用，了解即可 注解与反射接口 定义注解后，如何获取注解中的内容呢？反射包java.lang.reflect下的AnnotatedElement接口提供这些方法。这里注意：只有注解被定义为RUNTIME后，该注解才能是运行时可见，当class文件被装载时被保存在class文件中的Annotation才会被虚拟机读取。 AnnotatedElement 接口是所有程序元素（Class、Method和Constructor）的父接口，所以程序通过反射获取了某个类的AnnotatedElement对象之后，程序就可以调用该对象的方法来访问Annotation信息。我们看下具体的先关接口 boolean isAnnotationPresent(Class&lt;?extends Annotation&gt; annotationClass) 判断该程序元素上是否包含指定类型的注解，存在则返回true，否则返回false。注意：此方法会忽略注解对应的注解容器。 &lt;T extends Annotation&gt; T getAnnotation(Class&lt;T&gt; annotationClass) 返回该程序元素上存在的、指定类型的注解，如果该类型注解不存在，则返回null。 Annotation[] getAnnotations() 返回该程序元素上存在的所有注解，若没有注解，返回长度为0的数组。 &lt;T extends Annotation&gt; T[] getAnnotationsByType(Class&lt;T&gt; annotationClass) 返回该程序元素上存在的、指定类型的注解数组。没有注解对应类型的注解时，返回长度为0的数组。该方法的调用者可以随意修改返回的数组，而不会对其他调用者返回的数组产生任何影响。getAnnotationsByType方法与 getAnnotation的区别在于，getAnnotationsByType会检测注解对应的重复注解容器。若程序元素为类，当前类上找不到注解，且该注解为可继承的，则会去父类上检测对应的注解。 &lt;T extends Annotation&gt; T getDeclaredAnnotation(Class&lt;T&gt; annotationClass) 返回直接存在于此元素上的所有注解。与此接口中的其他方法不同，该方法将忽略继承的注释。如果没有注释直接存在于此元素上，则返回null &lt;T extends Annotation&gt; T[] getDeclaredAnnotationsByType(Class&lt;T&gt; annotationClass) 返回直接存在于此元素上的所有注解。与此接口中的其他方法不同，该方法将忽略继承的注释 Annotation[] getDeclaredAnnotations() 返回直接存在于此元素上的所有注解及注解对应的重复注解容器。与此接口中的其他方法不同，该方法将忽略继承的注解。如果没有注释直接存在于此元素上，则返回长度为零的一个数组。该方法的调用者可以随意修改返回的数组，而不会对其他调用者返回的数组产生任何影响。 自定义注解 当我们理解了内置注解, 元注解和获取注解的反射接口后，我们便可以开始自定义注解了。这个例子我把上述的知识点全部融入进来, 代码很简单： 定义自己的注解 12345678910111213141516package com.pdai.java.annotation;import java.lang.annotation.ElementType;import java.lang.annotation.Retention;import java.lang.annotation.RetentionPolicy;import java.lang.annotation.Target;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface MyMethodAnnotation &#123; public String title() default &quot;&quot;; public String description() default &quot;&quot;;&#125; 使用注解 123456789101112131415161718192021222324252627282930package com.pdai.java.annotation;import java.io.FileNotFoundException;import java.lang.annotation.Annotation;import java.lang.reflect.Method;import java.util.ArrayList;import java.util.List;public class TestMethodAnnotation &#123; @Override @MyMethodAnnotation(title = &quot;toStringMethod&quot;, description = &quot;override toString method&quot;) public String toString() &#123; return &quot;Override toString method&quot;; &#125; @Deprecated @MyMethodAnnotation(title = &quot;old static method&quot;, description = &quot;deprecated old static method&quot;) public static void oldMethod() &#123; System.out.println(&quot;old method, don&#x27;t use it.&quot;); &#125; @SuppressWarnings(&#123;&quot;unchecked&quot;, &quot;deprecation&quot;&#125;) @MyMethodAnnotation(title = &quot;test method&quot;, description = &quot;suppress warning static method&quot;) public static void genericsTest() throws FileNotFoundException &#123; List l = new ArrayList(); l.add(&quot;abc&quot;); oldMethod(); &#125;&#125; 用反射接口获取注解信息 在TestMethodAnnotation中添加Main方法进行测试： 123456789101112131415161718192021222324252627282930313233public static void main(String[] args) &#123; try &#123; // 获取所有methods Method[] methods = TestMethodAnnotation.class.getClassLoader() .loadClass((&quot;com.pdai.java.annotation.TestMethodAnnotation&quot;)) .getMethods(); // 遍历 for (Method method : methods) &#123; // 方法上是否有MyMethodAnnotation注解 if (method.isAnnotationPresent(MyMethodAnnotation.class)) &#123; try &#123; // 获取并遍历方法上的所有注解 for (Annotation anno : method.getDeclaredAnnotations()) &#123; System.out.println(&quot;Annotation in Method &#x27;&quot; + method + &quot;&#x27; : &quot; + anno); &#125; // 获取MyMethodAnnotation对象信息 MyMethodAnnotation methodAnno = method .getAnnotation(MyMethodAnnotation.class); System.out.println(methodAnno.title()); &#125; catch (Throwable ex) &#123; ex.printStackTrace(); &#125; &#125; &#125; &#125; catch (SecurityException | ClassNotFoundException e) &#123; e.printStackTrace(); &#125;&#125; 测试的输出 1234567Annotation in Method &#x27;public static void com.pdai.java.annotation.TestMethodAnnotation.oldMethod()&#x27; : @java.lang.Deprecated()Annotation in Method &#x27;public static void com.pdai.java.annotation.TestMethodAnnotation.oldMethod()&#x27; : @com.pdai.java.annotation.MyMethodAnnotation(title=old static method, description=deprecated old static method)old static methodAnnotation in Method &#x27;public static void com.pdai.java.annotation.TestMethodAnnotation.genericsTest() throws java.io.FileNotFoundException&#x27; : @com.pdai.java.annotation.MyMethodAnnotation(title=test method, description=suppress warning static method)test methodAnnotation in Method &#x27;public java.lang.String com.pdai.java.annotation.TestMethodAnnotation.toString()&#x27; : @com.pdai.java.annotation.MyMethodAnnotation(title=toStringMethod, description=override toString method)toStringMethod 深入理解注解提示 接下来，我们从其它角度深入理解注解 Java8提供了哪些新的注解？ @Repeatable 请参考 Java 8 - 重复注解 ElementType.TYPE_USE 请参考 Java 8 - 类型注解 ElementType.TYPE_PARAMETER ElementType.TYPE_USE(此类型包括类型声明和类型参数声明，是为了方便设计者进行类型检查)包含了ElementType.TYPE(类、接口（包括注解类型）和枚举的声明)和ElementType.TYPE_PARAMETER(类型参数声明), 不妨再看个例子 123456789101112131415161718192021222324252627// 自定义ElementType.TYPE_PARAMETER注解@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE_PARAMETER)public @interface MyNotEmpty &#123;&#125;// 自定义ElementType.TYPE_USE注解@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE_USE)public @interface MyNotNull &#123;&#125;// 测试类public class TypeParameterAndTypeUseAnnotation&lt;@MyNotEmpty T&gt;&#123; //使用TYPE_PARAMETER类型，会编译不通过// public @MyNotEmpty T test(@MyNotEmpty T a)&#123;// new ArrayList&lt;@MyNotEmpty String&gt;();// return a;// &#125; //使用TYPE_USE类型，编译通过 public @MyNotNull T test2(@MyNotNull T a)&#123; new ArrayList&lt;@MyNotNull String&gt;(); return a; &#125;&#125; 注解支持继承吗？ 注解是不支持继承的 不能使用关键字extends来继承某个@interface，但注解在编译后，编译器会自动继承java.lang.annotation.Annotation接口. 虽然反编译后发现注解继承了Annotation接口，请记住，即使Java的接口可以实现多继承，但定义注解时依然无法使用extends关键字继承@interface。 区别于注解的继承，被注解的子类继承父类注解可以用@Inherited： 如果某个类使用了被@Inherited修饰的Annotation，则其子类将自动具有该注解。 注解实现的原理？ 网上很多标注解的原理文章根本没有说到点子上。 这里推荐你两篇文章： https://blog.csdn.net/qq_20009015/article/details/106038023 https://www.race604.com/annotation-processing/ 注解的应用场景提示 最后我们再看看实际开发中注解的一些应用场景。@pdai 配置化到注解化 - 框架的演进Spring 框架 配置化到注解化的转变。 继承实现到注解实现 - Junit3到Junit4 一个模块的封装大多数人都是通过继承和组合等模式来实现的，但是如果结合注解将可以极大程度提高实现的优雅度（降低耦合度）。而Junit3 到Junit4的演化就是最好的一个例子。 被测试类 12345678910111213141516public class HelloWorld &#123; public void sayHello()&#123; System.out.println(&quot;hello....&quot;); throw new NumberFormatException(); &#125; public void sayWorld()&#123; System.out.println(&quot;world....&quot;); &#125; public String say()&#123; return &quot;hello world!&quot;; &#125; &#125; Junit3 实现UT 通过继承 TestCase来实现，初始化是通过Override父类方法来进行，测试方式通过test的前缀方法获取。 12345678910111213141516171819202122232425262728293031323334353637public class HelloWorldTest extends TestCase&#123; private HelloWorld hw; @Override protected void setUp() throws Exception &#123; super.setUp(); hw=new HelloWorld(); &#125; //1.测试没有返回值 public void testHello()&#123; try &#123; hw.sayHello(); &#125; catch (Exception e) &#123; System.out.println(&quot;发生异常.....&quot;); &#125; &#125; public void testWorld()&#123; hw.sayWorld(); &#125; //2.测试有返回值的方法 // 返回字符串 public void testSay()&#123; assertEquals(&quot;测试失败&quot;, hw.say(), &quot;hello world!&quot;); &#125; //返回对象 public void testObj()&#123; assertNull(&quot;测试对象不为空&quot;, null); assertNotNull(&quot;测试对象为空&quot;,new String()); &#125; @Override protected void tearDown() throws Exception &#123; super.tearDown(); hw=null; &#125;\t&#125; Junit4 实现UT 通过定义@Before，@Test，@After等等注解来实现。 1234567891011121314151617181920212223242526272829303132333435363738public class HelloWorldTest &#123; private HelloWorld hw; @Before public void setUp() &#123; hw = new HelloWorld(); &#125; @Test(expected=NumberFormatException.class) // 1.测试没有返回值,有别于junit3的使用，更加方便 public void testHello() &#123; hw.sayHello(); &#125; @Test public void testWorld() &#123; hw.sayWorld(); &#125; @Test // 2.测试有返回值的方法 // 返回字符串 public void testSay() &#123; assertEquals(&quot;测试失败&quot;, hw.say(), &quot;hello world!&quot;); &#125; @Test // 返回对象 public void testObj() &#123; assertNull(&quot;测试对象不为空&quot;, null); assertNotNull(&quot;测试对象为空&quot;, new String()); &#125; @After public void tearDown() throws Exception &#123; hw = null; &#125; &#125; 这里我们发现通过注解的方式，我们实现单元测试时将更为优雅。如果你还期望了解Junit4是如何实现运行的呢？可以看这篇文章：JUnit4源码分析运行原理在新窗口打开。 自定义注解和AOP - 通过切面实现解耦 最为常见的就是使用Spring AOP切面实现统一的操作日志管理，我这里找了一个开源项目中的例子（只展示主要代码），给你展示下如何通过注解实现解耦的。 自定义Log注解 123456789101112131415161718192021222324@Target(&#123; ElementType.PARAMETER, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Log &#123; /** * 模块 */ public String title() default &quot;&quot;; /** * 功能 */ public BusinessType businessType() default BusinessType.OTHER; /** * 操作人类别 */ public OperatorType operatorType() default OperatorType.MANAGE; /** * 是否保存请求的参数 */ public boolean isSaveRequestData() default true;&#125; 实现日志的切面, 对自定义注解Log作切点进行拦截 即对注解了@Log的方法进行切点拦截， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133@Aspect@Componentpublic class LogAspect &#123; private static final Logger log = LoggerFactory.getLogger(LogAspect.class); /** * 配置织入点 - 自定义注解的包路径 * */ @Pointcut(&quot;@annotation(com.xxx.aspectj.lang.annotation.Log)&quot;) public void logPointCut() &#123; &#125; /** * 处理完请求后执行 * * @param joinPoint 切点 */ @AfterReturning(pointcut = &quot;logPointCut()&quot;, returning = &quot;jsonResult&quot;) public void doAfterReturning(JoinPoint joinPoint, Object jsonResult) &#123; handleLog(joinPoint, null, jsonResult); &#125; /** * 拦截异常操作 * * @param joinPoint 切点 * @param e 异常 */ @AfterThrowing(value = &quot;logPointCut()&quot;, throwing = &quot;e&quot;) public void doAfterThrowing(JoinPoint joinPoint, Exception e) &#123; handleLog(joinPoint, e, null); &#125; protected void handleLog(final JoinPoint joinPoint, final Exception e, Object jsonResult) &#123; try &#123; // 获得注解 Log controllerLog = getAnnotationLog(joinPoint); if (controllerLog == null) &#123; return; &#125; // 获取当前的用户 User currentUser = ShiroUtils.getSysUser(); // *========数据库日志=========*// OperLog operLog = new OperLog(); operLog.setStatus(BusinessStatus.SUCCESS.ordinal()); // 请求的地址 String ip = ShiroUtils.getIp(); operLog.setOperIp(ip); // 返回参数 operLog.setJsonResult(JSONObject.toJSONString(jsonResult)); operLog.setOperUrl(ServletUtils.getRequest().getRequestURI()); if (currentUser != null) &#123; operLog.setOperName(currentUser.getLoginName()); if (StringUtils.isNotNull(currentUser.getDept()) &amp;&amp; StringUtils.isNotEmpty(currentUser.getDept().getDeptName())) &#123; operLog.setDeptName(currentUser.getDept().getDeptName()); &#125; &#125; if (e != null) &#123; operLog.setStatus(BusinessStatus.FAIL.ordinal()); operLog.setErrorMsg(StringUtils.substring(e.getMessage(), 0, 2000)); &#125; // 设置方法名称 String className = joinPoint.getTarget().getClass().getName(); String methodName = joinPoint.getSignature().getName(); operLog.setMethod(className + &quot;.&quot; + methodName + &quot;()&quot;); // 设置请求方式 operLog.setRequestMethod(ServletUtils.getRequest().getMethod()); // 处理设置注解上的参数 getControllerMethodDescription(controllerLog, operLog); // 保存数据库 AsyncManager.me().execute(AsyncFactory.recordOper(operLog)); &#125; catch (Exception exp) &#123; // 记录本地异常日志 log.error(&quot;==前置通知异常==&quot;); log.error(&quot;异常信息:&#123;&#125;&quot;, exp.getMessage()); exp.printStackTrace(); &#125; &#125; /** * 获取注解中对方法的描述信息 用于Controller层注解 * * @param log 日志 * @param operLog 操作日志 * @throws Exception */ public void getControllerMethodDescription(Log log, OperLog operLog) throws Exception &#123; // 设置action动作 operLog.setBusinessType(log.businessType().ordinal()); // 设置标题 operLog.setTitle(log.title()); // 设置操作人类别 operLog.setOperatorType(log.operatorType().ordinal()); // 是否需要保存request，参数和值 if (log.isSaveRequestData()) &#123; // 获取参数的信息，传入到数据库中。 setRequestValue(operLog); &#125; &#125; /** * 获取请求的参数，放到log中 * * @param operLog * @param request */ private void setRequestValue(OperLog operLog) &#123; Map&lt;String, String[]&gt; map = ServletUtils.getRequest().getParameterMap(); String params = JSONObject.toJSONString(map); operLog.setOperParam(StringUtils.substring(params, 0, 2000)); &#125; /** * 是否存在注解，如果存在就获取 */ private Log getAnnotationLog(JoinPoint joinPoint) throws Exception &#123; Signature signature = joinPoint.getSignature(); MethodSignature methodSignature = (MethodSignature) signature; Method method = methodSignature.getMethod(); if (method != null) &#123; return method.getAnnotation(Log.class); &#125; return null; &#125;&#125; 使用@Log注解 以一个简单的CRUD操作为例, 这里展示部分代码：每对“部门”进行操作就会产生一条操作日志存入数据库。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657@Controller@RequestMapping(&quot;/system/dept&quot;)public class DeptController extends BaseController &#123; private String prefix = &quot;system/dept&quot;; @Autowired private IDeptService deptService; /** * 新增保存部门 */ @Log(title = &quot;部门管理&quot;, businessType = BusinessType.INSERT) @RequiresPermissions(&quot;system:dept:add&quot;) @PostMapping(&quot;/add&quot;) @ResponseBody public AjaxResult addSave(@Validated Dept dept) &#123; if (UserConstants.DEPT_NAME_NOT_UNIQUE.equals(deptService.checkDeptNameUnique(dept))) &#123; return error(&quot;新增部门&#x27;&quot; + dept.getDeptName() + &quot;&#x27;失败，部门名称已存在&quot;); &#125; return toAjax(deptService.insertDept(dept)); &#125; /** * 保存 */ @Log(title = &quot;部门管理&quot;, businessType = BusinessType.UPDATE) @RequiresPermissions(&quot;system:dept:edit&quot;) @PostMapping(&quot;/edit&quot;) @ResponseBody public AjaxResult editSave(@Validated Dept dept) &#123; if (UserConstants.DEPT_NAME_NOT_UNIQUE.equals(deptService.checkDeptNameUnique(dept))) &#123; return error(&quot;修改部门&#x27;&quot; + dept.getDeptName() + &quot;&#x27;失败，部门名称已存在&quot;); &#125; else if(dept.getParentId().equals(dept.getDeptId())) &#123; return error(&quot;修改部门&#x27;&quot; + dept.getDeptName() + &quot;&#x27;失败，上级部门不能是自己&quot;); &#125; return toAjax(deptService.updateDept(dept)); &#125; /** * 删除 */ @Log(title = &quot;部门管理&quot;, businessType = BusinessType.DELETE) @RequiresPermissions(&quot;system:dept:remove&quot;) @GetMapping(&quot;/remove/&#123;deptId&#125;&quot;) @ResponseBody public AjaxResult remove(@PathVariable(&quot;deptId&quot;) Long deptId) &#123; if (deptService.selectDeptCount(deptId) &gt; 0) &#123; return AjaxResult.warn(&quot;存在下级部门,不允许删除&quot;); &#125; if (deptService.checkDeptExistUser(deptId)) &#123; return AjaxResult.warn(&quot;部门存在用户,不允许删除&quot;); &#125; return toAjax(deptService.deleteDeptById(deptId)); &#125; // ...&#125; 同样的，你也可以看到权限管理也是通过类似的注解（@RequiresPermissions）机制来实现的。所以我们可以看到，通过注解+AOP最终的目标是为了实现模块的解耦。 参考文章 https://blog.csdn.net/javazejian/article/details/71860633 https://blog.csdn.net/qq_20009015/article/details/106038023 https://www.zhihu.com/question/47449512 https://www.race604.com/annotation-processing/ https://www.runoob.com/w3cnote/java-annotation.html","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"4.Java 基础 - 泛型机制详解","path":"/2023/12/25/4.Java-基础-泛型机制详解/","content":"Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。本文综合多篇文章后，总结了Java 泛型的相关知识，希望可以提升你对Java中泛型的认知效率。 为什么会引入泛型 泛型的本质是为了参数化类型（在不创建新的类型的情况下，通过泛型指定的不同类型来控制形参具体限制的类型）。也就是说在泛型使用过程中，操作的数据类型被指定为一个参数，这种参数类型可以用在类、接口和方法中，分别被称为泛型类、泛型接口、泛型方法。 引入泛型的意义在于： 适用于多种数据类型执行相同的代码（代码复用） 我们通过一个例子来阐述，先看下下面的代码： 1234567891011121314private static int add(int a, int b) &#123; System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b)); return a + b;&#125;private static float add(float a, float b) &#123; System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b)); return a + b;&#125;private static double add(double a, double b) &#123; System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a + b)); return a + b;&#125; 如果没有泛型，要实现不同类型的加法，每种类型都需要重载一个add方法；通过泛型，我们可以复用为一个方法： 1234private static &lt;T extends Number&gt; double add(T a, T b) &#123; System.out.println(a + &quot;+&quot; + b + &quot;=&quot; + (a.doubleValue() + b.doubleValue())); return a.doubleValue() + b.doubleValue();&#125; 泛型中的类型在使用时指定，不需要强制类型转换（类型安全，编译器会检查类型） 看下这个例子： 1234List list = new ArrayList();list.add(&quot;xxString&quot;);list.add(100d);list.add(new Person()); 我们在使用上述list中，list中的元素都是Object类型（无法约束其中的类型），所以在取出集合元素时需要人为的强制类型转化到具体的目标类型，且很容易出现java.lang.ClassCastException异常。 引入泛型，它将提供类型的约束，提供编译前的检查： 123List&lt;String&gt; list = new ArrayList&lt;String&gt;();// list中只能放String, 不能放其它类型的元素 泛型的基本使用 提示 我们通过一些例子来学习泛型的使用；泛型有三种使用方式，分别为：泛型类、泛型接口、泛型方法。一些例子可以参考《李兴华 - Java实战经典》。 泛型类 从一个简单的泛型类看起： 12345678910111213141516class Point&lt;T&gt;&#123; // 此处可以随便写标识符号，T是type的简称 private T var ; // var的类型由T指定，即：由外部指定 public T getVar()&#123; // 返回值的类型由外部决定 return var ; &#125; public void setVar(T var)&#123; // 设置的类型也由外部决定 this.var = var ; &#125; &#125; public class GenericsDemo06&#123; public static void main(String args[])&#123; Point&lt;String&gt; p = new Point&lt;String&gt;() ; // 里面的var类型为String类型 p.setVar(&quot;it&quot;) ; // 设置字符串 System.out.println(p.getVar().length()) ; // 取得字符串的长度 &#125; &#125; 多元泛型 123456789101112131415161718192021222324252627class Notepad&lt;K,V&gt;&#123; // 此处指定了两个泛型类型 private K key ; // 此变量的类型由外部决定 private V value ; // 此变量的类型由外部决定 public K getKey()&#123; return this.key ; &#125; public V getValue()&#123; return this.value ; &#125; public void setKey(K key)&#123; this.key = key ; &#125; public void setValue(V value)&#123; this.value = value ; &#125; &#125; public class GenericsDemo09&#123; public static void main(String args[])&#123; Notepad&lt;String,Integer&gt; t = null ; // 定义两个泛型类型的对象 t = new Notepad&lt;String,Integer&gt;() ; // 里面的key为String，value为Integer t.setKey(&quot;汤姆&quot;) ; // 设置第一个内容 t.setValue(20) ; // 设置第二个内容 System.out.print(&quot;姓名；&quot; + t.getKey()) ; // 取得信息 System.out.print(&quot;，年龄；&quot; + t.getValue()) ; // 取得信息 &#125; &#125; 泛型接口 简单的泛型接口 12345678910111213141516171819202122interface Info&lt;T&gt;&#123; // 在接口上定义泛型 public T getVar() ; // 定义抽象方法，抽象方法的返回值就是泛型类型 &#125; class InfoImpl&lt;T&gt; implements Info&lt;T&gt;&#123; // 定义泛型接口的子类 private T var ; // 定义属性 public InfoImpl(T var)&#123; // 通过构造方法设置属性内容 this.setVar(var) ; &#125; public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; &#125; public class GenericsDemo24&#123; public static void main(String arsg[])&#123; Info&lt;String&gt; i = null; // 声明接口对象 i = new InfoImpl&lt;String&gt;(&quot;汤姆&quot;) ; // 通过子类实例化对象 System.out.println(&quot;内容：&quot; + i.getVar()) ; &#125; &#125; 泛型方法泛型方法，是在调用方法的时候指明泛型的具体类型。重点看下泛型的方法（图参考自：https://www.cnblogs.com/iyangyuan/archive/2013/04/09/3011274.html） 定义泛型方法语法格式 调用泛型方法语法格式 说明一下，定义泛型方法时，必须在返回值前边加一个&lt;T&gt;，来声明这是一个泛型方法，持有一个泛型T，然后才可以用泛型T作为方法的返回值。 Class&lt;T&gt;的作用就是指明泛型的具体类型，而Class&lt;T&gt;类型的变量c，可以用来创建泛型类的对象。 为什么要用变量c来创建对象呢？既然是泛型方法，就代表着我们不知道具体的类型是什么，也不知道构造方法如何，因此没有办法去new一个对象，但可以利用变量c的newInstance方法去创建对象，也就是利用反射创建对象。 泛型方法要求的参数是Class&lt;T&gt;类型，而Class.forName()方法的返回值也是Class&lt;T&gt;，因此可以用Class.forName()作为参数。其中，forName()方法中的参数是何种类型，返回的Class&lt;T&gt;就是何种类型。在本例中，forName()方法中传入的是User类的完整路径，因此返回的是Class&lt;User&gt;类型的对象，因此调用泛型方法时，变量c的类型就是Class&lt;User&gt;，因此泛型方法中的泛型T就被指明为User，因此变量obj的类型为User。 当然，泛型方法不是仅仅可以有一个参数Class&lt;T&gt;，可以根据需要添加其他参数。 为什么要使用泛型方法呢？因为泛型类要在实例化的时候就指明类型，如果想换一种类型，不得不重新new一次，可能不够灵活；而泛型方法可以在调用的时候指明类型，更加灵活。 泛型的上下限 先看下如下的代码，很明显是会报错的 （具体错误原因请参考后文）。 1234567891011121314151617181920class A&#123;&#125;class B extends A &#123;&#125;// 如下两个方法不会报错public static void funA(A a) &#123; // ... &#125;public static void funB(B b) &#123; funA(b); // ... &#125;// 如下funD方法会报错public static void funC(List&lt;A&gt; listA) &#123; // ... &#125;public static void funD(List&lt;B&gt; listB) &#123; funC(listB); // Unresolved compilation problem: The method doPrint(List&lt;A&gt;) in the type test is not applicable for the arguments (List&lt;B&gt;) // ... &#125; 那么如何解决呢？ 为了解决泛型中隐含的转换问题，Java泛型加入了类型参数的上下边界机制。&lt;? extends A&gt;表示该类型参数可以是A(上边界)或者A的子类类型。编译时擦除到类型A，即用A类型代替类型参数。这种方法可以解决开始遇到的问题，编译器知道类型参数的范围，如果传入的实例类型B是在这个范围内的话允许转换，这时只要一次类型转换就可以了，运行时会把对象当做A的实例看待。 1234567public static void funC(List&lt;? extends A&gt; listA) &#123; // ... &#125;public static void funD(List&lt;B&gt; listB) &#123; funC(listB); // OK // ... &#125; 泛型上下限的引入 在使用泛型的时候，我们可以为传入的泛型类型实参进行上下边界的限制，如：类型实参只准传入某种类型的父类或某种类型的子类。 上限 1234567891011121314151617class Info&lt;T extends Number&gt;&#123; // 此处泛型只能是数字类型 private T var ; // 定义泛型变量 public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; public String toString()&#123; // 直接打印 return this.var.toString() ; &#125;&#125;public class demo1&#123; public static void main(String args[])&#123; Info&lt;Integer&gt; i1 = new Info&lt;Integer&gt;() ; // 声明Integer的泛型对象 &#125;&#125; 下限 12345678910111213141516171819202122232425class Info&lt;T&gt;&#123; private T var ; // 定义泛型变量 public void setVar(T var)&#123; this.var = var ; &#125; public T getVar()&#123; return this.var ; &#125; public String toString()&#123; // 直接打印 return this.var.toString() ; &#125;&#125;public class GenericsDemo21&#123; public static void main(String args[])&#123; Info&lt;String&gt; i1 = new Info&lt;String&gt;() ; // 声明String的泛型对象 Info&lt;Object&gt; i2 = new Info&lt;Object&gt;() ; // 声明Object的泛型对象 i1.setVar(&quot;hello&quot;) ; i2.setVar(new Object()) ; fun(i1) ; fun(i2) ; &#125; public static void fun(Info&lt;? super String&gt; temp)&#123; // 只能接收String或Object类型的泛型，String类的父类只有Object类 System.out.print(temp + &quot;, &quot;) ; &#125;&#125; 小结 123456789&lt;?&gt; 无限制通配符&lt;? extends E&gt; extends 关键字声明了类型的上界，表示参数化的类型可能是所指定的类型，或者是此类型的子类&lt;? super E&gt; super 关键字声明了类型的下界，表示参数化的类型可能是指定的类型，或者是此类型的父类// 使用原则《Effictive Java》// 为了获得最大限度的灵活性，要在表示 生产者或者消费者 的输入参数上使用通配符，使用的规则就是：生产者有上限、消费者有下限1. 如果参数化类型表示一个 T 的生产者，使用 &lt; ? extends T&gt;;2. 如果它表示一个 T 的消费者，就使用 &lt; ? super T&gt;；3. 如果既是生产又是消费，那使用通配符就没什么意义了，因为你需要的是精确的参数类型。 再看一个实际例子，加深印象 123456789101112131415private &lt;E extends Comparable&lt;? super E&gt;&gt; E max(List&lt;? extends E&gt; e1) &#123; if (e1 == null)&#123; return null; &#125; //迭代器返回的元素属于 E 的某个子类型 Iterator&lt;? extends E&gt; iterator = e1.iterator(); E result = iterator.next(); while (iterator.hasNext())&#123; E next = iterator.next(); if (next.compareTo(result) &gt; 0)&#123; result = next; &#125; &#125; return result;&#125; 上述代码中的类型参数 E 的范围是&lt;E extends Comparable&lt;? super E&gt;&gt;，我们可以分步查看： 要进行比较，所以 E 需要是可比较的类，因此需要 extends Comparable&lt;…&gt;（注意这里不要和继承的 extends 搞混了，不一样） Comparable&lt; ? super E&gt; 要对 E 进行比较，即 E 的消费者，所以需要用 super 而参数 List&lt; ? extends E&gt; 表示要操作的数据是 E 的子类的列表，指定上限，这样容器才够大 多个限制 使用&amp;符号 1234567891011public class Client &#123; //工资低于2500元的上斑族并且站立的乘客车票打8折 public static &lt;T extends Staff &amp; Passenger&gt; void discount(T t)&#123; if(t.getSalary()&lt;2500 &amp;&amp; t.isStanding())&#123; System.out.println(&quot;恭喜你！您的车票打八折！&quot;); &#125; &#125; public static void main(String[] args) &#123; discount(new Me()); &#125;&#125; 泛型数组 具体可以参考下文中关于泛型数组的理解。 首先，我们泛型数组相关的申明： 123456List&lt;String&gt;[] list11 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 List&lt;String&gt;[] list12 = new ArrayList&lt;?&gt;[10]; //编译错误，需要强转类型 List&lt;String&gt;[] list13 = (List&lt;String&gt;[]) new ArrayList&lt;?&gt;[10]; //OK，但是会有警告 List&lt;?&gt;[] list14 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 List&lt;?&gt;[] list15 = new ArrayList&lt;?&gt;[10]; //OK List&lt;String&gt;[] list6 = new ArrayList[10]; //OK，但是会有警告 那么通常我们如何用呢？ 讨巧的使用场景 123456789101112131415public class GenericsDemo30&#123; public static void main(String args[])&#123; Integer i[] = fun1(1,2,3,4,5,6) ; // 返回泛型数组 fun2(i) ; &#125; public static &lt;T&gt; T[] fun1(T...arg)&#123; // 接收可变参数 return arg ; // 返回泛型数组 &#125; public static &lt;T&gt; void fun2(T param[])&#123; // 输出 System.out.print(&quot;接收泛型数组：&quot;) ; for(T t:param)&#123; System.out.print(t + &quot;、&quot;) ; &#125; &#125; &#125; 合理使用 123public ArrayWithTypeToken(Class&lt;T&gt; type, int size) &#123; array = (T[]) Array.newInstance(type, size);&#125; 具体可以查看后文解释。 深入理解泛型 提示 我们通过泛型背后的类型擦除以及相关的问题来进一步理解泛型。 如何理解Java中的泛型是伪泛型？泛型中类型擦除 Java泛型这个特性是从JDK 1.5才开始加入的，因此为了兼容之前的版本，Java泛型的实现采取了“伪泛型”的策略，即Java在语法上支持泛型，但是在编译阶段会进行所谓的“类型擦除”（Type Erasure），将所有的泛型表示（尖括号中的内容）都替换为具体的类型（其对应的原生态类型），就像完全没有泛型一样。理解类型擦除对于用好泛型是很有帮助的，尤其是一些看起来“疑难杂症”的问题，弄明白了类型擦除也就迎刃而解了。 泛型的类型擦除原则是： 消除类型参数声明，即删除&lt;&gt;及其包围的部分。 根据类型参数的上下界推断并替换所有的类型参数为原生态类型：如果类型参数是无限制通配符或没有上下界限定则替换为Object，如果存在上下界限定则根据子类替换原则取类型参数的最左边限定类型（即父类）。 为了保证类型安全，必要时插入强制类型转换代码。 自动产生“桥接方法”以保证擦除类型后的代码仍然具有泛型的“多态性”。 那么如何进行擦除的呢？ 参考自：http://softlab.sdut.edu.cn/blog/subaochen/2017/01/generics-type-erasure/ 擦除类定义中的类型参数 - 无限制类型擦除 当类定义中的类型参数没有任何限制时，在类型擦除中直接被替换为Object，即形如&lt;T&gt;和&lt;?&gt;的类型参数都被替换为Object。 擦除类定义中的类型参数 - 有限制类型擦除 当类定义中的类型参数存在限制（上下界）时，在类型擦除中替换为类型参数的上界或者下界，比如形如&lt;T extends Number&gt;和&lt;? extends Number&gt;的类型参数被替换为Number，&lt;? super Number&gt;被替换为Object。 擦除方法定义中的类型参数 擦除方法定义中的类型参数原则和擦除类定义中的类型参数是一样的，这里仅以擦除方法定义中的有限制类型参数为例。 如何证明类型的擦除呢？ 我们通过两个例子证明Java类型的类型擦除 原始类型相等 12345678910111213public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;(); list1.add(&quot;abc&quot;); ArrayList&lt;Integer&gt; list2 = new ArrayList&lt;Integer&gt;(); list2.add(123); System.out.println(list1.getClass() == list2.getClass()); // true &#125;&#125; 在这个例子中，我们定义了两个ArrayList数组，不过一个是ArrayList&lt;String&gt;泛型类型的，只能存储字符串；一个是ArrayList&lt;Integer&gt;泛型类型的，只能存储整数，最后，我们通过list1对象和list2对象的getClass()方法获取他们的类的信息，最后发现结果为true。说明泛型类型String和Integer都被擦除掉了，只剩下原始类型。 通过反射添加其它类型元素 12345678910111213141516public class Test &#123; public static void main(String[] args) throws Exception &#123; ArrayList&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); list.add(1); //这样调用 add 方法只能存储整形，因为泛型类型的实例为 Integer list.getClass().getMethod(&quot;add&quot;, Object.class).invoke(list, &quot;asd&quot;); for (int i = 0; i &lt; list.size(); i++) &#123; System.out.println(list.get(i)); &#125; &#125;&#125; 在程序中定义了一个ArrayList泛型类型实例化为Integer对象，如果直接调用add()方法，那么只能存储整数数据，不过当我们利用反射调用add()方法的时候，却可以存储字符串，这说明了Integer泛型实例在编译之后被擦除掉了，只保留了原始类型。 如何理解类型擦除后保留的原始类型? 在上面，两次提到了原始类型，什么是原始类型？ 原始类型 就是擦除去了泛型信息，最后在字节码中的类型变量的真正类型，无论何时定义一个泛型，相应的原始类型都会被自动提供，类型变量擦除，并使用其限定类型（无限定的变量用Object）替换。 原始类型Object 123456789class Pair&lt;T&gt; &#123; private T value; public T getValue() &#123; return value; &#125; public void setValue(T value) &#123; this.value = value; &#125; &#125; Pair的原始类型为: 123456789class Pair &#123; private Object value; public Object getValue() &#123; return value; &#125; public void setValue(Object value) &#123; this.value = value; &#125; &#125; 因为在Pair&lt;T&gt;中，T 是一个无限定的类型变量，所以用Object替换，其结果就是一个普通的类，如同泛型加入Java语言之前的已经实现的样子。在程序中可以包含不同类型的Pair，如Pair&lt;String&gt;或Pair&lt;Integer&gt;，但是擦除类型后他们的就成为原始的Pair类型了，原始类型都是Object。 从上面章节，我们也可以明白ArrayList被擦除类型后，原始类型也变为Object，所以通过反射我们就可以存储字符串了。 如果类型变量有限定，那么原始类型就用第一个边界的类型变量类替换。 比如: Pair这样声明的话 1public class Pair&lt;T extends Comparable&gt; &#123;&#125; 那么原始类型就是Comparable。 要区分原始类型和泛型变量的类型。 在调用泛型方法时，可以指定泛型，也可以不指定泛型: 在不指定泛型的情况下，泛型变量的类型为该方法中的几种类型的同一父类的最小级，直到Object 在指定泛型的情况下，该方法的几种类型必须是该泛型的实例的类型或者其子类 12345678910111213141516171819public class Test &#123; public static void main(String[] args) &#123; /**不指定泛型的时候*/ int i = Test.add(1, 2); //这两个参数都是Integer，所以T为Integer类型 Number f = Test.add(1, 1.2); //这两个参数一个是Integer，一个是Float，所以取同一父类的最小级，为Number Object o = Test.add(1, &quot;asd&quot;); //这两个参数一个是Integer，一个是String，所以取同一父类的最小级，为Object /**指定泛型的时候*/ int a = Test.&lt;Integer&gt;add(1, 2); //指定了Integer，所以只能为Integer类型或者其子类 int b = Test.&lt;Integer&gt;add(1, 2.2); //编译错误，指定了Integer，不能为Float Number c = Test.&lt;Number&gt;add(1, 2.2); //指定为Number，所以可以为Integer和Float &#125; //这是一个简单的泛型方法 public static &lt;T&gt; T add(T x,T y)&#123; return y; &#125; &#125; 其实在泛型类中，不指定泛型的时候，也差不多，只不过这个时候的泛型为Object，就比如ArrayList中，如果不指定泛型，那么这个ArrayList可以存储任意的对象。 Object泛型 123456public static void main(String[] args) &#123; ArrayList list = new ArrayList(); list.add(1); list.add(&quot;121&quot;); list.add(new Date()); &#125; 如何理解泛型的编译期检查？ 既然说类型变量会在编译的时候擦除掉，那为什么我们往 ArrayList 创建的对象中添加整数会报错呢？不是说泛型变量String会在编译的时候变为Object类型吗？为什么不能存别的类型呢？既然类型擦除了，如何保证我们只能使用泛型变量限定的类型呢？ Java编译器是通过先检查代码中泛型的类型，然后在进行类型擦除，再进行编译。 例如： 123456public static void main(String[] args) &#123; ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); list.add(&quot;123&quot;); list.add(123);//编译错误 &#125; 在上面的程序中，使用add方法添加一个整型，在IDE中，直接会报错，说明这就是在编译之前的检查，因为如果是在编译之后检查，类型擦除后，原始类型为Object，是应该允许任意引用类型添加的。可实际上却不是这样的，这恰恰说明了关于泛型变量的使用，是会在编译之前检查的。 那么，这个类型检查是针对谁的呢？我们先看看参数化类型和原始类型的兼容。 以 ArrayList举例子，以前的写法: 1ArrayList list = new ArrayList(); 现在的写法: 1ArrayList&lt;String&gt; list = new ArrayList&lt;String&gt;(); 如果是与以前的代码兼容，各种引用传值之间，必然会出现如下的情况： 12ArrayList&lt;String&gt; list1 = new ArrayList(); //第一种 情况ArrayList list2 = new ArrayList&lt;String&gt;(); //第二种 情况 这样是没有错误的，不过会有个编译时警告。 不过在第一种情况，可以实现与完全使用泛型参数一样的效果，第二种则没有效果。 因为类型检查就是编译时完成的，new ArrayList()只是在内存中开辟了一个存储空间，可以存储任何类型对象，而真正涉及类型检查的是它的引用，因为我们是使用它引用list1来调用它的方法，比如说调用add方法，所以list1引用能完成泛型类型的检查。而引用list2没有使用泛型，所以不行。 举例子： 1234567891011121314151617181920public class Test &#123; public static void main(String[] args) &#123; ArrayList&lt;String&gt; list1 = new ArrayList(); list1.add(&quot;1&quot;); //编译通过 list1.add(1); //编译错误 String str1 = list1.get(0); //返回类型就是String ArrayList list2 = new ArrayList&lt;String&gt;(); list2.add(&quot;1&quot;); //编译通过 list2.add(1); //编译通过 Object object = list2.get(0); //返回类型就是Object new ArrayList&lt;String&gt;().add(&quot;11&quot;); //编译通过 new ArrayList&lt;String&gt;().add(22); //编译错误 String str2 = new ArrayList&lt;String&gt;().get(0); //返回类型就是String &#125; &#125; 通过上面的例子，我们可以明白，类型检查就是针对引用的，谁是一个引用，用这个引用调用泛型方法，就会对这个引用调用的方法进行类型检测，而无关它真正引用的对象。 泛型中参数话类型为什么不考虑继承关系？ 在Java中，像下面形式的引用传递是不允许的: 12ArrayList&lt;String&gt; list1 = new ArrayList&lt;Object&gt;(); //编译错误 ArrayList&lt;Object&gt; list2 = new ArrayList&lt;String&gt;(); //编译错误 我们先看第一种情况，将第一种情况拓展成下面的形式： 1234ArrayList&lt;Object&gt; list1 = new ArrayList&lt;Object&gt;(); list1.add(new Object()); list1.add(new Object()); ArrayList&lt;String&gt; list2 = list1; //编译错误 实际上，在第4行代码的时候，就会有编译错误。那么，我们先假设它编译没错。那么当我们使用list2引用用get()方法取值的时候，返回的都是String类型的对象（上面提到了，类型检测是根据引用来决定的），可是它里面实际上已经被我们存放了Object类型的对象，这样就会有ClassCastException了。所以为了避免这种极易出现的错误，Java不允许进行这样的引用传递。（这也是泛型出现的原因，就是为了解决类型转换的问题，我们不能违背它的初衷）。 再看第二种情况，将第二种情况拓展成下面的形式： 12345ArrayList&lt;String&gt; list1 = new ArrayList&lt;String&gt;(); list1.add(new String()); list1.add(new String());ArrayList&lt;Object&gt; list2 = list1; //编译错误 没错，这样的情况比第一种情况好的多，最起码，在我们用list2取值的时候不会出现ClassCastException，因为是从String转换为Object。可是，这样做有什么意义呢，泛型出现的原因，就是为了解决类型转换的问题。 我们使用了泛型，到头来，还是要自己强转，违背了泛型设计的初衷。所以java不允许这么干。再说，你如果又用list2往里面add()新的对象，那么到时候取得时候，我怎么知道我取出来的到底是String类型的，还是Object类型的呢？ 所以，要格外注意，泛型中的引用传递的问题。 如何理解泛型的多态？泛型的桥接方法 类型擦除会造成多态的冲突，而JVM解决方法就是桥接方法。 现在有这样一个泛型类： 123456789101112class Pair&lt;T&gt; &#123; private T value; public T getValue() &#123; return value; &#125; public void setValue(T value) &#123; this.value = value; &#125; &#125; 然后我们想要一个子类继承它。 123456789101112class DateInter extends Pair&lt;Date&gt; &#123; @Override public void setValue(Date value) &#123; super.setValue(value); &#125; @Override public Date getValue() &#123; return super.getValue(); &#125; &#125; 在这个子类中，我们设定父类的泛型类型为Pair&lt;Date&gt;，在子类中，我们覆盖了父类的两个方法，我们的原意是这样的：将父类的泛型类型限定为Date，那么父类里面的两个方法的参数都为Date类型。 1234567public Date getValue() &#123; return value; &#125; public void setValue(Date value) &#123; this.value = value; &#125; 所以，我们在子类中重写这两个方法一点问题也没有，实际上，从他们的@Override标签中也可以看到，一点问题也没有，实际上是这样的吗？ 分析：实际上，类型擦除后，父类的的泛型类型全部变为了原始类型Object，所以父类编译之后会变成下面的样子： 1234567891011class Pair &#123; private Object value; public Object getValue() &#123; return value; &#125; public void setValue(Object value) &#123; this.value = value; &#125; &#125; 再看子类的两个重写的方法的类型： 12345678@Override public void setValue(Date value) &#123; super.setValue(value); &#125; @Override public Date getValue() &#123; return super.getValue(); &#125; 先来分析setValue方法，父类的类型是Object，而子类的类型是Date，参数类型不一样，这如果实在普通的继承关系中，根本就不会是重写，而是重载。 我们在一个main方法测试一下： 12345public static void main(String[] args) throws ClassNotFoundException &#123; DateInter dateInter = new DateInter(); dateInter.setValue(new Date()); dateInter.setValue(new Object()); //编译错误 &#125; 如果是重载，那么子类中两个setValue方法，一个是参数Object类型，一个是Date类型，可是我们发现，根本就没有这样的一个子类继承自父类的Object类型参数的方法。所以说，却是是重写了，而不是重载了。 为什么会这样呢？ 原因是这样的，我们传入父类的泛型类型是Date，Pair&lt;Date&gt;，我们的本意是将泛型类变为如下： 123456789class Pair &#123; private Date value; public Date getValue() &#123; return value; &#125; public void setValue(Date value) &#123; this.value = value; &#125; &#125; 然后再子类中重写参数类型为Date的那两个方法，实现继承中的多态。 可是由于种种原因，虚拟机并不能将泛型类型变为Date，只能将类型擦除掉，变为原始类型Object。这样，我们的本意是进行重写，实现多态。可是类型擦除后，只能变为了重载。这样，类型擦除就和多态有了冲突。JVM知道你的本意吗？知道！！！可是它能直接实现吗，不能！！！如果真的不能的话，那我们怎么去重写我们想要的Date类型参数的方法啊。 于是JVM采用了一个特殊的方法，来完成这项功能，那就是桥方法。 首先，我们用javap -c className的方式反编译下DateInter子类的字节码，结果如下： 1234567891011121314151617181920212223242526272829303132333435class com.tao.test.DateInter extends com.tao.test.Pair&lt;java.util.Date&gt; &#123; com.tao.test.DateInter(); Code: 0: aload_0 1: invokespecial #8 // Method com/tao/test/Pair.&quot;&lt;init&gt;&quot;:()V 4: return public void setValue(java.util.Date); //我们重写的setValue方法 Code: 0: aload_0 1: aload_1 2: invokespecial #16 // Method com/tao/test/Pair.setValue:(Ljava/lang/Object;)V 5: return public java.util.Date getValue(); //我们重写的getValue方法 Code: 0: aload_0 1: invokespecial #23 // Method com/tao/test/Pair.getValue:()Ljava/lang/Object; 4: checkcast #26 // class java/util/Date 7: areturn public java.lang.Object getValue(); //编译时由编译器生成的桥方法 Code: 0: aload_0 1: invokevirtual #28 // Method getValue:()Ljava/util/Date 去调用我们重写的getValue方法; 4: areturn public void setValue(java.lang.Object); //编译时由编译器生成的桥方法 Code: 0: aload_0 1: aload_1 2: checkcast #26 // class java/util/Date 5: invokevirtual #30 // Method setValue:(Ljava/util/Date; 去调用我们重写的setValue方法)V 8: return &#125; 从编译的结果来看，我们本意重写setValue和getValue方法的子类，竟然有4个方法，其实不用惊奇，最后的两个方法，就是编译器自己生成的桥方法。可以看到桥方法的参数类型都是Object，也就是说，子类中真正覆盖父类两个方法的就是这两个我们看不到的桥方法。而打在我们自己定义的setvalue和getValue方法上面的@Oveerride只不过是假象。而桥方法的内部实现，就只是去调用我们自己重写的那两个方法。 所以，虚拟机巧妙的使用了桥方法，来解决了类型擦除和多态的冲突。 不过，要提到一点，这里面的setValue和getValue这两个桥方法的意义又有不同。 setValue方法是为了解决类型擦除与多态之间的冲突。 而getValue却有普遍的意义，怎么说呢，如果这是一个普通的继承关系： 那么父类的getValue方法如下： 123public Object getValue() &#123; return super.getValue(); &#125; 而子类重写的方法是： 123public Date getValue() &#123; return super.getValue(); &#125; 其实这在普通的类继承中也是普遍存在的重写，这就是协变。 并且，还有一点也许会有疑问，子类中的桥方法Object getValue()和Date getValue()是同时存在的，可是如果是常规的两个方法，他们的方法签名是一样的，也就是说虚拟机根本不能分别这两个方法。如果是我们自己编写Java代码，这样的代码是无法通过编译器的检查的，但是虚拟机却是允许这样做的，因为虚拟机通过参数类型和返回类型来确定一个方法，所以编译器为了实现泛型的多态允许自己做这个看起来“不合法”的事情，然后交给虚拟器去区别。 如何理解基本类型不能作为泛型类型？ 比如，我们没有ArrayList&lt;int&gt;，只有ArrayList&lt;Integer&gt;, 为何？ 因为当类型擦除后，ArrayList的原始类型变为Object，但是Object类型不能存储int值，只能引用Integer的值。 另外需要注意，我们能够使用list.add(1)是因为Java基础类型的自动装箱拆箱操作。 如何理解泛型类型不能实例化？ 不能实例化泛型类型, 这本质上是由于类型擦除决定的： 我们可以看到如下代码会在编译器中报错： 1T test = new T(); // ERROR 因为在 Java 编译期没法确定泛型参数化类型，也就找不到对应的类字节码文件，所以自然就不行了，此外由于T 被擦除为 Object，如果可以 new T() 则就变成了 new Object()，失去了本意。 如果我们确实需要实例化一个泛型，应该如何做呢？可以通过反射实现： 1234static &lt;T&gt; T newTclass (Class &lt; T &gt; clazz) throws InstantiationException, IllegalAccessException &#123; T obj = clazz.newInstance(); return obj;&#125; 泛型数组：能不能采用具体的泛型类型进行初始化？我们先来看下Oracle官网提供的一个例子： 1234567List&lt;String&gt;[] lsa = new List&lt;String&gt;[10]; // Not really allowed.Object o = lsa;Object[] oa = (Object[]) o;List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;();li.add(new Integer(3));oa[1] = li; // Unsound, but passes run time store checkString s = lsa[1].get(0); // Run-time error ClassCastException. 由于 JVM 泛型的擦除机制，所以上面代码可以给 oa[1] 赋值为 ArrayList 也不会出现异常，但是在取出数据的时候却要做一次类型转换，所以就会出现 ClassCastException，如果可以进行泛型数组的声明则上面说的这种情况在编译期不会出现任何警告和错误，只有在运行时才会出错，但是泛型的出现就是为了消灭 ClassCastException，所以如果 Java 支持泛型数组初始化操作就是搬起石头砸自己的脚。 而对于下面的代码来说是成立的： 1234567List&lt;?&gt;[] lsa = new List&lt;?&gt;[10]; // OK, array of unbounded wildcard type.Object o = lsa;Object[] oa = (Object[]) o;List&lt;Integer&gt; li = new ArrayList&lt;Integer&gt;();li.add(new Integer(3));oa[1] = li; // Correct.Integer i = (Integer) lsa[1].get(0); // OK 所以说采用通配符的方式初始化泛型数组是允许的，因为对于通配符的方式最后取出数据是要做显式类型转换的，符合预期逻辑。综述就是说Java 的泛型数组初始化时数组类型不能是具体的泛型类型，只能是通配符的形式，因为具体类型会导致可存入任意类型对象，在取出时会发生类型转换异常，会与泛型的设计思想冲突，而通配符形式本来就需要自己强转，符合预期。 Oracle 官方文档：https://docs.oracle.com/javase/tutorial/extra/generics/fineprint.html在新窗口打开 更进一步的，我们看看如下的代码： 123456List&lt;String&gt;[] list11 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 List&lt;String&gt;[] list12 = new ArrayList&lt;?&gt;[10]; //编译错误，需要强转类型 List&lt;String&gt;[] list13 = (List&lt;String&gt;[]) new ArrayList&lt;?&gt;[10]; //OK，但是会有警告 List&lt;?&gt;[] list14 = new ArrayList&lt;String&gt;[10]; //编译错误，非法创建 List&lt;?&gt;[] list15 = new ArrayList&lt;?&gt;[10]; //OK List&lt;String&gt;[] list6 = new ArrayList[10]; //OK，但是会有警告 因为在 Java 中是不能创建一个确切的泛型类型的数组的，除非是采用通配符的方式且要做显式类型转换才可以。 泛型数组：如何正确的初始化泛型数组实例？ 这个无论我们通过new ArrayList[10] 的形式还是通过泛型通配符的形式初始化泛型数组实例都是存在警告的，也就是说仅仅语法合格，运行时潜在的风险需要我们自己来承担，因此那些方式初始化泛型数组都不是最优雅的方式。 我们在使用到泛型数组的场景下应该尽量使用列表集合替换，此外也可以通过使用 java.lang.reflect.Array.newInstance(Class&lt;T&gt; componentType, int length) 方法来创建一个具有指定类型和维度的数组，如下： 1234567891011121314151617181920212223public class ArrayWithTypeToken&lt;T&gt; &#123; private T[] array; public ArrayWithTypeToken(Class&lt;T&gt; type, int size) &#123; array = (T[]) Array.newInstance(type, size); &#125; public void put(int index, T item) &#123; array[index] = item; &#125; public T get(int index) &#123; return array[index]; &#125; public T[] create() &#123; return array; &#125;&#125;//...ArrayWithTypeToken&lt;Integer&gt; arrayToken = new ArrayWithTypeToken&lt;Integer&gt;(Integer.class, 100);Integer[] array = arrayToken.create(); 所以使用反射来初始化泛型数组算是优雅实现，因为泛型类型 T在运行时才能被确定下来，我们能创建泛型数组也必然是在 Java 运行时想办法，而运行时能起作用的技术最好的就是反射了。 如何理解泛型类中的静态方法和静态变量？ 泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数 举例说明： 123456public class Test2&lt;T&gt; &#123; public static T one; //编译错误 public static T show(T one)&#123; //编译错误 return null; &#125; &#125; 因为泛型类中的泛型参数的实例化是在定义对象的时候指定的，而静态变量和静态方法不需要使用对象来调用。对象都没有创建，如何确定这个泛型参数是何种类型，所以当然是错误的。 但是要注意区分下面的一种情况： 123456public class Test2&lt;T&gt; &#123; public static &lt;T &gt;T show(T one)&#123; //这是正确的 return null; &#125; &#125; 因为这是一个泛型方法，在泛型方法中使用的T是自己在方法中定义的 T，而不是泛型类中的T。 如何理解异常中使用泛型？ 不能抛出也不能捕获泛型类的对象。事实上，泛型类扩展Throwable都不合法。例如：下面的定义将不会通过编译： 123public class Problem&lt;T&gt; extends Exception &#123;&#125; 为什么不能扩展Throwable，因为异常都是在运行时捕获和抛出的，而在编译的时候，泛型信息全都会被擦除掉，那么，假设上面的编译可行，那么，在看下面的定义： 1234567try&#123;&#125; catch(Problem&lt;Integer&gt; e1) &#123;&#125; catch(Problem&lt;Number&gt; e2) &#123;&#125; 类型信息被擦除后，那么两个地方的catch都变为原始类型Object，那么也就是说，这两个地方的catch变的一模一样,就相当于下面的这样 1234567try&#123;&#125; catch(Problem&lt;Object&gt; e1) &#123;&#125; catch(Problem&lt;Object&gt; e2) &#123;&#125; 这个当然就是不行的。 不能再catch子句中使用泛型变量 1234567public static &lt;T extends Throwable&gt; void doWork(Class&lt;T&gt; t) &#123; try &#123; ... &#125; catch(T e) &#123; //编译错误 ... &#125;&#125; 因为泛型信息在编译的时候已经变为原始类型，也就是说上面的T会变为原始类型Throwable，那么如果可以再catch子句中使用泛型变量，那么，下面的定义呢： 123456789public static &lt;T extends Throwable&gt; void doWork(Class&lt;T&gt; t)&#123; try &#123; &#125; catch(T e) &#123; //编译错误 &#125; catch(IndexOutOfBounds e) &#123; &#125; &#125; 根据异常捕获的原则，一定是子类在前面，父类在后面，那么上面就违背了这个原则。即使你在使用该静态方法的使用T是ArrayIndexOutofBounds，在编译之后还是会变成Throwable，ArrayIndexOutofBounds是IndexOutofBounds的子类，违背了异常捕获的原则。所以java为了避免这样的情况，禁止在catch子句中使用泛型变量。 但是在异常声明中可以使用类型变量。下面方法是合法的。 12345678public static&lt;T extends Throwable&gt; void doWork(T t) throws T &#123; try&#123; ... &#125; catch(Throwable realCause) &#123; t.initCause(realCause); throw t; &#125;&#125; 上面的这样使用是没问题的。 如何获取泛型的参数类型？ 既然类型被擦除了，那么如何获取泛型的参数类型呢？可以通过反射（java.lang.reflect.Type）获取泛型 java.lang.reflect.Type是Java中所有类型的公共高级接口, 代表了Java中的所有类型. Type体系中类型的包括：数组类型(GenericArrayType)、参数化类型(ParameterizedType)、类型变量(TypeVariable)、通配符类型(WildcardType)、原始类型(Class)、基本类型(Class), 以上这些类型都实现Type接口。 12345678910111213141516171819public class GenericType&lt;T&gt; &#123; private T data; public T getData() &#123; return data; &#125; public void setData(T data) &#123; this.data = data; &#125; public static void main(String[] args) &#123; GenericType&lt;String&gt; genericType = new GenericType&lt;String&gt;() &#123;&#125;; Type superclass = genericType.getClass().getGenericSuperclass(); //getActualTypeArguments 返回确切的泛型参数, 如Map&lt;String, Integer&gt;返回[String, Integer] Type type = ((ParameterizedType) superclass).getActualTypeArguments()[0]; System.out.println(type);//class java.lang.String &#125;&#125; 其中 ParameterizedType: 12345678910public interface ParameterizedType extends Type &#123; // 返回确切的泛型参数, 如Map&lt;String, Integer&gt;返回[String, Integer] Type[] getActualTypeArguments(); //返回当前class或interface声明的类型, 如List&lt;?&gt;返回List Type getRawType(); //返回所属类型. 如,当前类型为O&lt;T&gt;.I&lt;S&gt;, 则返回O&lt;T&gt;. 顶级类型将返回null Type getOwnerType();&#125; 参考文章 泛型作为Java基础知识点之一，网上知识点比较多也比较散，本文主要综合了网络上比较好的文章，方便你快速学习。（以下是一部分我参考的链接） https://blog.csdn.net/sunxianghuang/article/details/51982979 https://blog.csdn.net/LonelyRoamer/article/details/7868820 https://docs.oracle.com/javase/tutorial/extra/generics/index.html https://blog.csdn.net/s10461/article/details/53941091 https://www.cnblogs.com/iyangyuan/archive/2013/04/09/3011274.html https://www.cnblogs.com/rudy-laura/articles/3391013.html https://www.jianshu.com/p/986f732ed2f1 https://blog.csdn.net/u011240877/article/details/53545041","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"3.Java 基础 - 图谱 & Q/A","path":"/2023/12/25/3.Java-基础-图谱-Q-A/","content":"本文主要对Java基础知识体系小结，同时结合一些Q&amp;A进行理解。 参考文档 Thinking in Java (Java 编程思想) Gitbook中文文档 https://java.quanke.name/ Thinking in Java (Java 编程思想) Github https://github.com/quanke/think-in-java Thinking in Java (Java 编程思想) Gitbook2 https://www.gitbook.com/book/wizardforcel/thinking-in-java/details 知识体系 Q&amp;AJava 中应该使用什么数据类型来代表价格?如果不是特别关心内存和性能的话，使用BigDecimal，否则使用预定义精度的 double 类型。 怎么将 byte 转换为 String?可以使用 String 接收 byte[] 参数的构造器来进行转换，需要注意的点是要使用的正确的编码，否则会使用平台默认编码，这个编码可能跟原来的编码相同，也可能不同。 Java 中怎样将 bytes 转换为 long 类型?String接收bytes的构造器转成String，再Long.parseLong() 我们能将 int 强制转换为 byte 类型的变量吗? 如果该值大于 byte 类型的范围，将会出现什么现象?是的，我们可以做强制转换，但是 Java 中 int 是 32 位的，而 byte 是 8 位的，所以，如果强制转化是，int 类型的高 24 位将会被丢弃，byte 类型的范围是从 -128 到 127。 存在两个类，B 继承 A，C 继承 B，我们能将 B 转换为 C 么? 如 C &#x3D; (C) B；可以，向下转型。但是不建议使用，容易出现类型转型异常. 哪个类包含 clone 方法? 是 Cloneable 还是 Object?java.lang.Cloneable 是一个标示性接口，不包含任何方法，clone 方法在 object 类中定义。并且需要知道 clone() 方法是一个本地方法，这意味着它是由 c 或 c++ 或 其他本地语言实现的。 Java 中 ++ 操作符是线程安全的吗?不是线程安全的操作。它涉及到多个指令，如读取变量值，增加，然后存储回内存，这个过程可能会出现多个线程交差。还会存在竞态条件(读取-修改-写入)。 a &#x3D; a + b 与 a +&#x3D; b 的区别+= 隐式的将加操作的结果类型强制转换为持有结果的类型。如果两个整型相加，如 byte、short 或者 int，首先会将它们提升到 int 类型，然后在执行加法操作。 1234byte a = 127;byte b = 127;b = a + b; // error : cannot convert from int to byteb += a; // ok (因为 a+b 操作会将 a、b 提升为 int 类型，所以将 int 类型赋值给 byte 就会编译出错) 我能在不进行强制转换的情况下将一个 double 值赋值给 long 类型的变量吗?不行，你不能在没有强制类型转换的前提下将一个 double 值赋值给 long 类型的变量，因为 double 类型的范围比 long 类型更广，所以必须要进行强制转换。 3*0.1 &#x3D;&#x3D; 0.3 将会返回什么? true 还是 false?false，因为有些浮点数不能完全精确的表示出来。 int 和 Integer 哪个会占用更多的内存?Integer 对象会占用更多的内存。Integer 是一个对象，需要存储对象的元数据。但是 int 是一个原始类型的数据，所以占用的空间更少。 为什么 Java 中的 String 是不可变的(Immutable)?Java 中的 String 不可变是因为 Java 的设计者认为字符串使用非常频繁，将字符串设置为不可变可以允许多个客户端之间共享相同的字符串。更详细的内容参见答案。 我们能在 Switch 中使用 String 吗?从 Java 7 开始，我们可以在 switch case 中使用字符串，但这仅仅是一个语法糖。内部实现在 switch 中使用字符串的 hash code。 Java 中的构造器链是什么?当你从一个构造器中调用另一个构造器，就是Java 中的构造器链。这种情况只在重载了类的构造器的时候才会出现。 枚举类JDK1.5出现 每个枚举值都需要调用一次构造函数 什么是不可变对象(immutable object)? Java 中怎么创建一个不可变对象?不可变对象指对象一旦被创建，状态就不能再改变。任何修改都会创建一个新的对象，如 String、Integer及其它包装类。 如何在Java中写出Immutable的类? 要写出这样的类，需要遵循以下几个原则: 1)immutable对象的状态在创建之后就不能发生改变，任何对它的改变都应该产生一个新的对象。 2)Immutable类的所有的属性都应该是final的。 3)对象必须被正确的创建，比如: 对象引用在对象创建过程中不能泄露(leak)。 4)对象应该是final的，以此来限制子类继承父类，以避免子类改变了父类的immutable特性。 5)如果类中包含mutable类对象，那么返回给客户端的时候，返回该对象的一个拷贝，而不是该对象本身(该条可以归为第一条中的一个特例) 我们能创建一个包含可变对象的不可变对象吗?是的，我们是可以创建一个包含可变对象的不可变对象的，你只需要谨慎一点，不要共享可变对象的引用就可以了，如果需要变化时，就返回原对象的一个拷贝。最常见的例子就是对象中包含一个日期对象的引用。 有没有可能两个不相等的对象有相同的 hashcode?有可能，两个不相等的对象可能会有相同的 hashcode 值，这就是为什么在 hashmap 中会有冲突。相等 hashcode 值的规定只是说如果两个对象相等，必须有相同的hashcode 值，但是没有关于不相等对象的任何规定。 两个相同的对象会有不同的 hashcode 吗?不能，根据 hashcode 的规定，这是不可能的。 我们可以在 hashcode() 中使用随机数字吗?不行，因为对象的 hashcode 值必须是相同的。 Java 中，Comparator 与 Comparable 有什么不同?Comparable 接口用于定义对象的自然顺序，而 comparator 通常用于定义用户定制的顺序。Comparable 总是只有一个，但是可以有多个 comparator 来定义对象的顺序。 为什么在重写 equals 方法的时候需要重写 hashCode 方法?因为有强制的规范指定需要同时重写 hashcode 与 equals 是方法，许多容器类，如 HashMap、HashSet 都依赖于 hashcode 与 equals 的规定。 “a&#x3D;&#x3D;b”和”a.equals(b)”有什么区别?如果 a 和 b 都是对象，则 a&#x3D;&#x3D;b 是比较两个对象的引用，只有当 a 和 b 指向的是堆中的同一个对象才会返回 true，而 a.equals(b) 是进行逻辑比较，所以通常需要重写该方法来提供逻辑一致性的比较。例如，String 类重写 equals() 方法，所以可以用于两个不同对象，但是包含的字母相同的比较。 a.hashCode() 有什么用? 与 a.equals(b) 有什么关系?简介: hashCode() 方法是相应对象整型的 hash 值。它常用于基于 hash 的集合类，如 Hashtable、HashMap、LinkedHashMap等等。它与 equals() 方法关系特别紧密。根据 Java 规范，两个使用 equals() 方法来判断相等的对象，必须具有相同的 hashcode。 1、hashcode的作用 List和Set，如何保证Set不重复呢? 通过迭代使用equals方法来判断，数据量小还可以接受，数据量大怎么解决? 引入hashcode，实际上hashcode扮演的角色就是寻址，大大减少查询匹配次数。 2、hashcode重要吗 对于数组、List集合就是一个累赘。而对于hashmap, hashset, hashtable就异常重要了。 3、equals方法遵循的原则 对称性 若x.equals(y)为true，则y.equals(x)为true 自反性 x.equals(x)必须true 传递性 若x.equals(y)为true,y.equals(z)为true,则x.equals(z)必为true 一致性 只要x,y内容不变，无论调用多少次结果不变 其他 x.equals(null) 永远false，x.equals(和x数据类型不同)始终false final、finalize 和 finally 的不同之处? final 是一个修饰符，可以修饰变量、方法和类。如果 final 修饰变量，意味着该变量的值在初始化后不能被改变。 Java 技术允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在确定这个对象没有被引用时对这个对象调用的，但是什么时候调用 finalize 没有保证。 finally 是一个关键字，与 try 和 catch 一起用于异常的处理。finally 块一定会被执行，无论在 try 块中是否有发生异常。 Java 中的编译期常量是什么? 使用它又什么风险?变量也就是我们所说的编译期常量，这里的 public 可选的。实际上这些变量在编译时会被替换掉，因为编译器知道这些变量的值，并且知道这些变量在运行时不能改变。这种方式存在的一个问题是你使用了一个内部的或第三方库中的公有编译时常量，但是这个值后面被其他人改变了，但是你的客户端仍然在使用老的值，甚至你已经部署了一个新的jar。为了避免这种情况，当你在更新依赖 JAR 文件时，确保重新编译你的程序。 静态内部类与顶级类有什么区别?一个公共的顶级类的源文件名称与类名相同，而嵌套静态类没有这个要求。一个嵌套类位于顶级类内部，需要使用顶级类的名称来引用嵌套静态类，如 HashMap.Entry 是一个嵌套静态类，HashMap 是一个顶级类，Entry是一个嵌套静态类。 Java 中，Serializable 与 Externalizable 的区别?Serializable 接口是一个序列化 Java 类的接口，以便于它们可以在网络上传输或者可以将它们的状态保存在磁盘上，是 JVM 内嵌的默认序列化方式，成本高、脆弱而且不安全。Externalizable 允许你控制整个序列化过程，指定特定的二进制格式，增加安全机制。 说出 JDK 1.7 中的三个新特性?虽然 JDK 1.7 不像 JDK 5 和 8 一样的大版本，但是，还是有很多新的特性，如 try-with-resource 语句，这样你在使用流或者资源的时候，就不需要手动关闭，Java 会自动关闭。Fork-Join 池某种程度上实现 Java 版的 Map-reduce。允许 Switch 中有 String 变量和文本。菱形操作符(&lt;&gt;)用于泛型推断，不再需要在变量声明的右边申明泛型，因此可以写出可读写更强、更简洁的代码。另一个值得一提的特性是改善异常处理，如允许在同一个 catch 块中捕获多个异常。 说出 5 个 JDK 1.8 引入的新特性?Java 8 在 Java 历史上是一个开创新的版本，下面 JDK 8 中 5 个主要的特性: Lambda 表达式，允许像对象一样传递匿名函数 Stream API，充分利用现代多核 CPU，可以写出很简洁的代码 Date 与 Time API，最终，有一个稳定、简单的日期和时间库可供你使用 扩展方法，现在，接口中可以有静态、默认方法。 重复注解，现在你可以将相同的注解在同一类型上使用多次。 下述包含 Java 面试过程中关于 SOLID 的设计原则，OOP 基础，如类，对象，接口，继承，多态，封装，抽象以及更高级的一些概念，如组合、聚合及关联。也包含了 GOF 设计模式的问题。 接口是什么? 为什么要使用接口而不是直接使用具体类?接口用于定义 API。它定义了类必须得遵循的规则。同时，它提供了一种抽象，因为客户端只使用接口，这样可以有多重实现，如 List 接口，你可以使用可随机访问的 ArrayList，也可以使用方便插入和删除的 LinkedList。接口中不允许普通方法，以此来保证抽象，但是 Java 8 中你可以在接口声明静态方法和默认普通方法。 Java 中，抽象类与接口之间有什么不同?Java 中，抽象类和接口有很多不同之处，但是最重要的一个是 Java 中限制一个类只能继承一个类，但是可以实现多个接口。抽象类可以很好的定义一个家族类的默认行为，而接口能更好的定义类型，有助于后面实现多态机制 参见第六条。 Object有哪些公用方法?clone equals hashcode wait notify notifyall finalize toString getClass 除了clone和finalize其他均为公共方法。 11个方法，wait被重载了两次 equals与&#x3D;&#x3D;的区别区别1. ==是一个运算符 equals是Object类的方法 区别2. 比较时的区别 用于基本类型的变量比较时: ==用于比较值是否相等，equals不能直接用于基本数据类型的比较，需要转换为其对应的包装类型。 用于引用类型的比较时。==和equals都是比较栈内存中的地址是否相等 。相等为true 否则为false。但是通常会重写equals方法去实现对象内容的比较。 String、StringBuffer与StringBuilder的区别第一点: 可变和适用范围。String对象是不可变的，而StringBuffer和StringBuilder是可变字符序列。每次对String的操作相当于生成一个新的String对象，而对StringBuffer和StringBuilder的操作是对对象本身的操作，而不会生成新的对象，所以对于频繁改变内容的字符串避免使用String，因为频繁的生成对象将会对系统性能产生影响。 第二点: 线程安全。String由于有final修饰，是immutable的，安全性是简单而纯粹的。StringBuilder和StringBuffer的区别在于StringBuilder不保证同步，也就是说如果需要线程安全需要使用StringBuffer，不需要同步的StringBuilder效率更高。 switch能否用String做参数Java1.7开始支持，但实际这是一颗Java语法糖。除此之外，byte，short，int，枚举均可用于switch，而boolean和浮点型不可以。 接口与抽象类 一个子类只能继承一个抽象类, 但能实现多个接口 抽象类可以有构造方法, 接口没有构造方法 抽象类可以有普通成员变量, 接口没有普通成员变量 抽象类和接口都可有静态成员变量, 抽象类中静态成员变量访问类型任意，接口只能public static final(默认) 抽象类可以没有抽象方法, 抽象类可以有普通方法；接口在JDK8之前都是抽象方法，在JDK8可以有default方法，在JDK9中允许有私有普通方法 抽象类可以有静态方法；接口在JDK8之前不能有静态方法，在JDK8中可以有静态方法，且只能被接口类直接调用（不能被实现类的对象调用） 抽象类中的方法可以是public、protected; 接口方法在JDK8之前只有public abstract，在JDK8可以有default方法，在JDK9中允许有private方法 抽象类和最终类抽象类可以没有抽象方法, 最终类可以没有最终方法 最终类不能被继承, 最终方法不能被重写(可以重载) 异常相关的关键字 throw、throws、try...catch、finally throws 用在方法签名上, 以便抛出的异常可以被调用者处理 throw 方法内部通过throw抛出异常 try 用于检测包住的语句块, 若有异常, catch子句捕获并执行catch块 关于finally finally不管有没有异常都要处理 当try和catch中有return时，finally仍然会执行，finally比return先执行 不管有木有异常抛出, finally在return返回前执行 finally是在return后面的表达式运算后执行的(此时并没有返回运算后的值，而是先把要返回的值保存起来，管finally中的代码怎么样，返回的值都不会改变，仍然是之前保存的值)，所以函数返回值是在finally执行前确定的 注意: finally中最好不要包含return，否则程序会提前退出，返回值不是try或catch中保存的返回值 finally不执行的几种情况: 程序提前终止如调用了System.exit, 病毒，断电 受检查异常和运行时异常 受检查的异常(checked exceptions),其必须被try...catch语句块所捕获, 或者在方法签名里通过throws子句声明。受检查的异常必须在编译时被捕捉处理,命名为Checked Exception是因为Java编译器要进行检查, Java虚拟机也要进行检查, 以确保这个规则得到遵守。 常见的checked exception: ClassNotFoundException IOException FileNotFoundException EOFException 运行时异常(runtime exceptions), 需要程序员自己分析代码决定是否捕获和处理,比如空指针,被0除… 常见的runtime exception: NullPointerException ArithmeticException ClassCastException IllegalArgumentException IllegalStateException IndexOutOfBoundsException NoSuchElementException Error的，则属于严重错误，如系统崩溃、虚拟机错误、动态链接失败等，这些错误无法恢复或者不可能捕捉，将导致应用程序中断，Error不需要捕获。 super出现在父类的子类中。有三种存在方式 super.xxx(xxx为变量名或对象名)意思是获取父类中xxx的变量或引用 super.xxx(); (xxx为方法名)意思是直接访问并调用父类中的方法 super() 调用父类构造 注: super只能指代其直接父类 this() &amp; super()在构造方法中的区别 调用super()必须写在子类构造方法的第一行, 否则编译不通过 super从子类调用父类构造, this在同一类中调用其他构造均需要放在第一行 尽管可以用this调用一个构造器, 却不能调用2个 this和super不能出现在同一个构造器中, 否则编译不通过 this()、super()都指的对象,不可以在static环境中使用 本质this指向本对象的指针。super是一个关键字 构造内部类和静态内部类对象12345678910111213public class Enclosingone &#123;\tpublic class Insideone &#123;&#125;\tpublic static class Insideone&#123;&#125;&#125;public class Test &#123;\tpublic static void main(String[] args) &#123;\t// 构造内部类对象需要外部类的引用\tEnclosingone.Insideone obj1 = new Enclosingone().new Insideone();\t// 构造静态内部类的对象\tEnclosingone.Insideone obj2 = new Enclosingone.Insideone();\t&#125;&#125; 静态内部类不需要有指向外部类的引用。但非静态内部类需要持有对外部类的引用。非静态内部类能够访问外部类的静态和非静态成员。静态内部类不能访问外部类的非静态成员，只能访问外部类的静态成员。 序列化声明为static和transient类型的数据不能被序列化， 反序列化需要一个无参构造函数 Java移位运算符java中有三种移位运算符 &lt;&lt; :左移运算符,x &lt;&lt; 1,相当于x乘以2(不溢出的情况下),低位补0 &gt;&gt; :带符号右移,x &gt;&gt; 1,相当于x除以2,正数高位补0,负数高位补1 &gt;&gt;&gt; :无符号右移,忽略符号位,空位都以0补齐 形参&amp;实参形式参数可被视为local variable.形参和局部变量一样都不能离开方法。只有在方法中使用，不会在方法外可见。 形式参数只能用final修饰符，其它任何修饰符都会引起编译器错误。但是用这个修饰符也有一定的限制，就是在方法中不能对参数做任何修改。不过一般情况下，一个方法的形参不用final修饰。只有在特殊情况下，那就是: 方法内部类。一个方法内的内部类如果使用了这个方法的参数或者局部变量的话，这个参数或局部变量应该是final。 形参的值在调用时根据调用者更改，实参则用自身的值更改形参的值(指针、引用皆在此列)，也就是说真正被传递的是实参。 局部变量为什么要初始化局部变量是指类方法中的变量，必须初始化。局部变量运行时被分配在栈中，量大，生命周期短，如果虚拟机给每个局部变量都初始化一下，是一笔很大的开销，但变量不初始化为默认值就使用是不安全的。出于速度和安全性两个方面的综合考虑，解决方案就是虚拟机不初始化，但要求编写者一定要在使用前给变量赋值。 Java语言的鲁棒性Java在编译和运行程序时，都要对可能出现的问题进行检查，以消除错误的产生。它提供自动垃圾收集来进行内存管理，防止程序员在管理内存时容易产生的错误。通过集成的面向对象的例外处理机制，在编译时，Java揭示出可能出现但未被处理的异常，帮助程序员正确地进行选择以防止系统的崩溃。另外，Java在编译时还可捕获类型声明中的许多常见错误，防止动态运行时不匹配问题的出现。","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"2.Java 基础 - 知识点","path":"/2023/12/25/2.Java-基础-知识点/","content":"本文主要对Java基础知识点进行总结。 数据类型包装类型八个基本类型: boolean&#x2F;1 byte&#x2F;8 char&#x2F;16 short&#x2F;16 int&#x2F;32 float&#x2F;32 long&#x2F;64 double&#x2F;64 基本类型都有对应的包装类型，基本类型与其对应的包装类型之间的赋值使用自动装箱与拆箱完成。 12Integer x = 2; // 装箱int y = x; // 拆箱 缓存池new Integer(123) 与 Integer.valueOf(123) 的区别在于: new Integer(123) 每次都会新建一个对象 Integer.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。 123456Integer x = new Integer(123);Integer y = new Integer(123);System.out.println(x == y); // falseInteger z = Integer.valueOf(123);Integer k = Integer.valueOf(123);System.out.println(z == k); // true valueOf() 方法的实现比较简单，就是先判断值是否在缓存池中，如果在的话就直接返回缓存池的内容。 12345public static Integer valueOf(int i) &#123; if (i &gt;= IntegerCache.low &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i);&#125; 在 Java 8 中，Integer 缓存池的大小默认为 -128~127。 1234567891011121314151617181920212223242526272829static final int low = -128;static final int high;static final Integer cache[];static &#123; // high value may be configured by property int h = 127; String integerCacheHighPropValue = sun.misc.VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;); if (integerCacheHighPropValue != null) &#123; try &#123; int i = parseInt(integerCacheHighPropValue); i = Math.max(i, 127); // Maximum array size is Integer.MAX_VALUE h = Math.min(i, Integer.MAX_VALUE - (-low) -1); &#125; catch( NumberFormatException nfe) &#123; // If the property cannot be parsed into an int, ignore it. &#125; &#125; high = h; cache = new Integer[(high - low) + 1]; int j = low; for(int k = 0; k &lt; cache.length; k++) cache[k] = new Integer(j++); // range [-128, 127] must be interned (JLS7 5.1.7) assert IntegerCache.high &gt;= 127;&#125; 编译器会在缓冲池范围内的基本类型自动装箱过程调用 valueOf() 方法，因此多个 Integer 实例使用自动装箱来创建并且值相同，那么就会引用相同的对象。 123Integer m = 123;Integer n = 123;System.out.println(m == n); // true 基本类型对应的缓冲池如下: boolean values true and false all byte values short values between -128 and 127 int values between -128 and 127 char in the range \\u0000 to \\u007F 在使用这些基本类型对应的包装类型时，就可以直接使用缓冲池中的对象。 如果在缓冲池之外： 123Integer m = 323;Integer n = 323;System.out.println(m == n); // false String概览String 被声明为 final，因此它不可被继承。 内部使用 char 数组存储数据**(Java 9 之后，String 类的实现改用 byte 数组存储字符串)**，该数组被声明为 final，这意味着 value 数组初始化之后就不能再引用其它数组。并且 String 内部没有改变 value 数组的方法，因此可以保证 String 不可变。 1234public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence &#123; /** The value is used for character storage. */ private final char value[]; 不可变的好处1. 可以缓存 hash 值 因为 String 的 hash 值经常被使用，例如 String 用做 HashMap 的 key。不可变的特性可以使得 hash 值也不可变，因此只需要进行一次计算。 2. String Pool 的需要 如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。 3. 安全性 String 经常作为参数，String 不可变性可以保证参数不可变。例如在作为网络连接参数的情况下如果 String 是可变的，那么在网络连接过程中，String 被改变，改变 String 对象的那一方以为现在连接的是其它主机，而实际情况却不一定是。 4. 线程安全 String 不可变性天生具备线程安全，可以在多个线程中安全地使用。 Program Creek : Why String is immutable in Java? String, StringBuffer and StringBuilder1. 可变性 String 不可变 StringBuffer 和 StringBuilder 可变 2. 线程安全 String 不可变，因此是线程安全的 StringBuilder 不是线程安全的 StringBuffer 是线程安全的，内部使用 synchronized 进行同步 StackOverflow : String, StringBuffer, and StringBuilder String.intern()使用 String.intern() 可以保证相同内容的字符串变量引用同一的内存对象。 下面示例中，s1 和 s2 采用 new String() 的方式新建了两个不同对象，而 s3 是通过 s1.intern() 方法取得一个对象引用。intern() 首先把 s1 引用的对象放到 String Pool(字符串常量池)中，然后返回这个对象引用。因此 s3 和 s1 引用的是同一个字符串常量池的对象。 12345String s1 = new String(&quot;aaa&quot;);String s2 = new String(&quot;aaa&quot;);System.out.println(s1 == s2); // falseString s3 = s1.intern();System.out.println(s1.intern() == s3); // true 如果是采用 “bbb” 这种使用双引号的形式创建字符串实例，会自动地将新建的对象放入 String Pool 中。 123String s4 = &quot;bbb&quot;;String s5 = &quot;bbb&quot;;System.out.println(s4 == s5); // true HotSpot中字符串常量池保存哪里？永久代？方法区还是堆区？ 运行时常量池（Runtime Constant Pool）是虚拟机规范中是方法区的一部分，在加载类和结构到虚拟机后，就会创建对应的运行时常量池；而字符串常量池是这个过程中常量字符串的存放位置。所以从这个角度，字符串常量池属于虚拟机规范中的方法区，它是一个逻辑上的概念；而堆区，永久代以及元空间是实际的存放位置。 不同的虚拟机对虚拟机的规范（比如方法区）是不一样的，只有 HotSpot 才有永久代的概念。 HotSpot也是发展的，由于一些问题的存在，HotSpot考虑逐渐去永久代，对于不同版本的JDK，实际的存储位置是有差异的，具体看如下表格： JDK版本 是否有永久代，字符串常量池放在哪里？ 方法区逻辑上规范，由哪些实际的部分实现的？ jdk1.6及之前 有永久代，运行时常量池（包括字符串常量池），静态变量存放在永久代上 这个时期方法区在HotSpot中是由永久代来实现的，以至于这个时期说方法区就是指永久代 jdk1.7 有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中； 这个时期方法区在HotSpot中由永久代（类型信息、字段、方法、常量）和堆（字符串常量池、静态变量）共同实现 jdk1.8及之后 取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中 这个时期方法区在HotSpot中由本地内存的元空间（类型信息、字段、方法、常量）和堆（字符串常量池、静态变量）共同实现 运算参数传递Java 的参数是以值传递的形式传入方法中，而不是引用传递。 以下代码中 Dog dog 的 dog 是一个指针，存储的是对象的地址。在将一个参数传入一个方法时，本质上是将对象的地址以值的方式传递到形参中。因此在方法中改变指针引用的对象，那么这两个指针此时指向的是完全不同的对象，一方改变其所指向对象的内容对另一方没有影响。 1234567891011121314151617181920212223242526272829303132333435public class Dog &#123; String name; Dog(String name) &#123; this.name = name; &#125; String getName() &#123; return this.name; &#125; void setName(String name) &#123; this.name = name; &#125; String getObjectAddress() &#123; return super.toString(); &#125;&#125;public class PassByValueExample &#123; public static void main(String[] args) &#123; Dog dog = new Dog(&quot;A&quot;); System.out.println(dog.getObjectAddress()); // Dog@4554617c func(dog); System.out.println(dog.getObjectAddress()); // Dog@4554617c System.out.println(dog.getName()); // A &#125; private static void func(Dog dog) &#123; System.out.println(dog.getObjectAddress()); // Dog@4554617c dog = new Dog(&quot;B&quot;); System.out.println(dog.getObjectAddress()); // Dog@74a14482 System.out.println(dog.getName()); // B &#125;&#125; 但是如果在方法中改变对象的字段值会改变原对象该字段值，因为改变的是同一个地址指向的内容。 1234567891011class PassByValueExample &#123; public static void main(String[] args) &#123; Dog dog = new Dog(&quot;A&quot;); func(dog); System.out.println(dog.getName()); // B &#125; private static void func(Dog dog) &#123; dog.setName(&quot;B&quot;); &#125;&#125; StackOverflow: Is Java “pass-by-reference” or “pass-by-value”? float 与 double1.1 字面量属于 double 类型，不能直接将 1.1 直接赋值给 float 变量，因为这是向下转型。Java 不能隐式执行向下转型，因为这会使得精度降低。 1// float f = 1.1; 1.1f 字面量才是 float 类型。 1float f = 1.1f; 隐式类型转换因为字面量 1 是 int 类型，它比 short 类型精度要高，因此不能隐式地将 int 类型下转型为 short 类型。 12short s1 = 1;// s1 = s1 + 1; 但是使用 += 运算符可以执行隐式类型转换。 1s1 += 1; 上面的语句相当于将 s1 + 1 的计算结果进行了向下转型: 1s1 = (short) (s1 + 1); StackOverflow : Why don’t Java’s +&#x3D;, -&#x3D;, *&#x3D;, &#x2F;&#x3D; compound assignment operators require casting? switch从 Java 7 开始，可以在 switch 条件判断语句中使用 String 对象。 123456789String s = &quot;a&quot;;switch (s) &#123; case &quot;a&quot;: System.out.println(&quot;aaa&quot;); break; case &quot;b&quot;: System.out.println(&quot;bbb&quot;); break;&#125; switch 不支持 long，是因为 switch 的设计初衷是对那些只有少数的几个值进行等值判断，如果值过于复杂，那么还是用 if 比较合适。 123456789// long x = 111;// switch (x) &#123; // Incompatible types. Found: &#x27;long&#x27;, required: &#x27;char, byte, short, int, Character, Byte, Short, Integer, String, or an enum&#x27;// case 111:// System.out.println(111);// break;// case 222:// System.out.println(222);// break;// &#125; StackOverflow : Why can’t your switch statement data type be long, Java? 继承访问权限Java 中有三个访问权限修饰符: private、protected 以及 public，如果不加访问修饰符，表示包级可见。 可以对类或类中的成员(字段以及方法)加上访问修饰符。 类可见表示其它类可以用这个类创建实例对象。 成员可见表示其它类可以用这个类的实例对象访问到该成员； protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。 设计良好的模块会隐藏所有的实现细节，把它的 API 与它的实现清晰地隔离开来。模块之间只通过它们的 API 进行通信，一个模块不需要知道其他模块的内部工作情况，这个概念被称为信息隐藏或封装。因此访问权限应当尽可能地使每个类或者成员不被外界访问。 如果子类的方法重写了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。这是为了确保可以使用父类实例的地方都可以使用子类实例，也就是确保满足里氏替换原则。 字段决不能是公有的，因为这么做的话就失去了对这个字段修改行为的控制，客户端可以对其随意修改。例如下面的例子中，AccessExample 拥有 id 共有字段，如果在某个时刻，我们想要使用 int 去存储 id 字段，那么就需要去修改所有的客户端代码。 123public class AccessExample &#123; public String id;&#125; 可以使用公有的 getter 和 setter 方法来替换公有字段，这样的话就可以控制对字段的修改行为。 123456789101112public class AccessExample &#123; private int id; public String getId() &#123; return id + &quot;&quot;; &#125; public void setId(String id) &#123; this.id = Integer.valueOf(id); &#125;&#125; 但是也有例外，如果是包级私有的类或者私有的嵌套类，那么直接暴露成员不会有特别大的影响。 123456789101112131415public class AccessWithInnerClassExample &#123; private class InnerClass &#123; int x; &#125; private InnerClass innerClass; public AccessWithInnerClassExample() &#123; innerClass = new InnerClass(); &#125; public int getValue() &#123; return innerClass.x; // 直接访问 &#125;&#125; 抽象类与接口1. 抽象类 抽象类和抽象方法都使用 abstract 关键字进行声明。抽象类一般会包含抽象方法，抽象方法一定位于抽象类中。 抽象类和普通类最大的区别是，抽象类不能被实例化，需要继承抽象类才能实例化其子类。 1234567891011121314151617181920public abstract class AbstractClassExample &#123; protected int x; private int y; public abstract void func1(); public void func2() &#123; System.out.println(&quot;func2&quot;); &#125;&#125;public class AbstractExtendClassExample extends AbstractClassExample &#123; @Override public void func1() &#123; System.out.println(&quot;func1&quot;); &#125;&#125;// AbstractClassExample ac1 = new AbstractClassExample(); // &#x27;AbstractClassExample&#x27; is abstract; cannot be instantiatedAbstractClassExample ac2 = new AbstractExtendClassExample();ac2.func1(); 2. 接口 接口是抽象类的延伸，在 Java 8 之前，它可以看成是一个完全抽象的类，也就是说它不能有任何的方法实现。 从 Java 8 开始，接口也可以拥有默认的方法实现，这是因为不支持默认方法的接口的维护成本太高了。在 Java 8 之前，如果一个接口想要添加新的方法，那么要修改所有实现了该接口的类。 接口的成员(字段 + 方法)默认都是 public 的，并且不允许定义为 private 或者 protected。 接口的字段默认都是 static 和 final 的。 123456789101112131415161718192021222324public interface InterfaceExample &#123; void func1(); default void func2()&#123; System.out.println(&quot;func2&quot;); &#125; int x = 123; // int y; // Variable &#x27;y&#x27; might not have been initialized public int z = 0; // Modifier &#x27;public&#x27; is redundant for interface fields // private int k = 0; // Modifier &#x27;private&#x27; not allowed here // protected int l = 0; // Modifier &#x27;protected&#x27; not allowed here // private void fun3(); // Modifier &#x27;private&#x27; not allowed here&#125;public class InterfaceImplementExample implements InterfaceExample &#123; @Override public void func1() &#123; System.out.println(&quot;func1&quot;); &#125;&#125;// InterfaceExample ie1 = new InterfaceExample(); // &#x27;InterfaceExample&#x27; is abstract; cannot be instantiatedInterfaceExample ie2 = new InterfaceImplementExample();ie2.func1();System.out.println(InterfaceExample.x); 3. 比较 从设计层面上看，抽象类提供了一种 IS-A 关系，那么就必须满足里式替换原则，即子类对象必须能够替换掉所有父类对象。而接口更像是一种 LIKE-A 关系，它只是提供一种方法实现契约，并不要求接口和实现接口的类具有 IS-A 关系。 从使用上来看，一个类可以实现多个接口，但是不能继承多个抽象类。 接口的字段只能是 static 和 final 类型的，而抽象类的字段没有这种限制。 接口的成员只能是 public 的，而抽象类的成员可以有多种访问权限。 4. 使用选择 使用接口: 需要让不相关的类都实现一个方法，例如不相关的类都可以实现 Compareable 接口中的 compareTo() 方法； 需要使用多重继承。 使用抽象类: 需要在几个相关的类中共享代码。 需要能控制继承来的成员的访问权限，而不是都为 public。 需要继承非静态和非常量字段。 在很多情况下，接口优先于抽象类，因为接口没有抽象类严格的类层次结构要求，可以灵活地为一个类添加行为。并且从 Java 8 开始，接口也可以有默认的方法实现，使得修改接口的成本也变的很低。 深入理解 abstract class 和 interface When to Use Abstract Class and Interface super 访问父类的构造函数: 可以使用 super() 函数访问父类的构造函数，从而委托父类完成一些初始化的工作。 访问父类的成员: 如果子类重写了父类的中某个方法的实现，可以通过使用 super 关键字来引用父类的方法实现。 12345678910111213141516171819202122232425262728293031public class SuperExample &#123; protected int x; protected int y; public SuperExample(int x, int y) &#123; this.x = x; this.y = y; &#125; public void func() &#123; System.out.println(&quot;SuperExample.func()&quot;); &#125;&#125;public class SuperExtendExample extends SuperExample &#123; private int z; public SuperExtendExample(int x, int y, int z) &#123; super(x, y); this.z = z; &#125; @Override public void func() &#123; super.func(); System.out.println(&quot;SuperExtendExample.func()&quot;); &#125;&#125;SuperExample e = new SuperExtendExample(1, 2, 3);e.func();SuperExample.func()SuperExtendExample.func() Using the Keyword super 重写与重载1. 重写(Override) 存在于继承体系中，指子类实现了一个与父类在方法声明上完全相同的一个方法。 为了满足里式替换原则，重写有以下两个限制: 子类方法的访问权限必须大于等于父类方法； 子类方法的返回类型必须是父类方法返回类型或为其子类型。 使用 @Override 注解，可以让编译器帮忙检查是否满足上面的两个限制条件。 2. 重载(Overload) 存在于同一个类中，指一个方法与已经存在的方法名称上相同，但是参数类型、个数、顺序至少有一个不同。 应该注意的是，返回值不同，其它都相同不算是重载。 Object 通用方法概览123456789101112131415161718192021public final native Class&lt;?&gt; getClass()public native int hashCode()public boolean equals(Object obj)protected native Object clone() throws CloneNotSupportedExceptionpublic String toString()public final native void notify()public final native void notifyAll()public final native void wait(long timeout) throws InterruptedExceptionpublic final void wait(long timeout, int nanos) throws InterruptedExceptionpublic final void wait() throws InterruptedExceptionprotected void finalize() throws Throwable &#123;&#125; equals()1. 等价关系 (一)自反性 1x.equals(x); // true (二)对称性 1x.equals(y) == y.equals(x); // true (三)传递性 12if (x.equals(y) &amp;&amp; y.equals(z)) x.equals(z); // true; (四)一致性 多次调用 equals() 方法结果不变 1x.equals(y) == x.equals(y); // true (五)与 null 的比较 对任何不是 null 的对象 x 调用 x.equals(null) 结果都为 false 1x.equals(null); // false; 2. equals() 与 == 对于基本类型，== 判断两个值是否相等，基本类型没有 equals() 方法。 对于引用类型，== 判断两个变量是否引用同一个对象，而 equals() 判断引用的对象是否等价。 1234Integer x = new Integer(1);Integer y = new Integer(1);System.out.println(x.equals(y)); // trueSystem.out.println(x == y); // false 3. 实现 检查是否为同一个对象的引用，如果是直接返回 true； 检查是否是同一个类型，如果不是，直接返回 false； 将 Object 对象进行转型； 判断每个关键域是否相等。 1234567891011121314151617181920212223public class EqualExample &#123; private int x; private int y; private int z; public EqualExample(int x, int y, int z) &#123; this.x = x; this.y = y; this.z = z; &#125; @Override public boolean equals(Object o) &#123; if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; EqualExample that = (EqualExample) o; if (x != that.x) return false; if (y != that.y) return false; return z == that.z; &#125;&#125; hashCode()hashCode() 返回散列值，而 equals() 是用来判断两个对象是否等价。等价的两个对象散列值一定相同，但是散列值相同的两个对象不一定等价。 在覆盖 equals() 方法时应当总是覆盖 hashCode() 方法，保证等价的两个对象散列值也相等。 下面的代码中，新建了两个等价的对象，并将它们添加到 HashSet 中。我们希望将这两个对象当成一样的，只在集合中添加一个对象，但是因为 EqualExample 没有实现 hasCode() 方法，因此这两个对象的散列值是不同的，最终导致集合添加了两个等价的对象。 1234567EqualExample e1 = new EqualExample(1, 1, 1);EqualExample e2 = new EqualExample(1, 1, 1);System.out.println(e1.equals(e2)); // trueHashSet&lt;EqualExample&gt; set = new HashSet&lt;&gt;();set.add(e1);set.add(e2);System.out.println(set.size()); // 2 理想的散列函数应当具有均匀性，即不相等的对象应当均匀分布到所有可能的散列值上。这就要求了散列函数要把所有域的值都考虑进来，可以将每个域都当成 R 进制的某一位，然后组成一个 R 进制的整数。R 一般取 31，因为它是一个奇素数，如果是偶数的话，当出现乘法溢出，信息就会丢失，因为与 2 相乘相当于向左移一位。 一个数与 31 相乘可以转换成移位和减法: 31*x == (x&lt;&lt;5)-x，编译器会自动进行这个优化。 12345678@Overridepublic int hashCode() &#123; int result = 17; result = 31 * result + x; result = 31 * result + y; result = 31 * result + z; return result;&#125; toString()默认返回 ToStringExample@4554617c 这种形式，其中 @ 后面的数值为散列码的无符号十六进制表示。 12345678910public class ToStringExample &#123; private int number; public ToStringExample(int number) &#123; this.number = number; &#125;&#125;ToStringExample example = new ToStringExample(123);System.out.println(example.toString());ToStringExample@4554617c clone()1. cloneable clone() 是 Object 的 protected 方法，它不是 public，一个类不显式去重写 clone()，其它类就不能直接去调用该类实例的 clone() 方法。 123456public class CloneExample &#123; private int a; private int b;&#125;CloneExample e1 = new CloneExample();// CloneExample e2 = e1.clone(); // &#x27;clone()&#x27; has protected access in &#x27;java.lang.Object&#x27; 重写 clone() 得到以下实现: 12345678910111213141516public class CloneExample &#123; private int a; private int b; @Override protected CloneExample clone() throws CloneNotSupportedException &#123; return (CloneExample)super.clone(); &#125;&#125;CloneExample e1 = new CloneExample();try &#123; CloneExample e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;java.lang.CloneNotSupportedException: CloneExample 以上抛出了 CloneNotSupportedException，这是因为 CloneExample 没有实现 Cloneable 接口。 应该注意的是，clone() 方法并不是 Cloneable 接口的方法，而是 Object 的一个 protected 方法。Cloneable 接口只是规定，如果一个类没有实现 Cloneable 接口又调用了 clone() 方法，就会抛出 CloneNotSupportedException。 123456789public class CloneExample implements Cloneable &#123; private int a; private int b; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125;&#125; 2. 浅拷贝 拷贝对象和原始对象的引用类型引用同一个对象。 1234567891011121314151617181920212223242526272829303132public class ShallowCloneExample implements Cloneable &#123; private int[] arr; public ShallowCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected ShallowCloneExample clone() throws CloneNotSupportedException &#123; return (ShallowCloneExample) super.clone(); &#125;&#125;ShallowCloneExample e1 = new ShallowCloneExample();ShallowCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 222 3. 深拷贝 拷贝对象和原始对象的引用类型引用不同对象。 12345678910111213141516171819202122232425262728293031323334353637public class DeepCloneExample implements Cloneable &#123; private int[] arr; public DeepCloneExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125; @Override protected DeepCloneExample clone() throws CloneNotSupportedException &#123; DeepCloneExample result = (DeepCloneExample) super.clone(); result.arr = new int[arr.length]; for (int i = 0; i &lt; arr.length; i++) &#123; result.arr[i] = arr[i]; &#125; return result; &#125;&#125;DeepCloneExample e1 = new DeepCloneExample();DeepCloneExample e2 = null;try &#123; e2 = e1.clone();&#125; catch (CloneNotSupportedException e) &#123; e.printStackTrace();&#125;e1.set(2, 222);System.out.println(e2.get(2)); // 2 4. clone() 的替代方案 使用 clone() 方法来拷贝一个对象即复杂又有风险，它会抛出异常，并且还需要类型转换。Effective Java 书上讲到，最好不要去使用 clone()，可以使用拷贝构造函数或者拷贝工厂来拷贝一个对象。 1234567891011121314151617181920212223242526272829public class CloneConstructorExample &#123; private int[] arr; public CloneConstructorExample() &#123; arr = new int[10]; for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = i; &#125; &#125; public CloneConstructorExample(CloneConstructorExample original) &#123; arr = new int[original.arr.length]; for (int i = 0; i &lt; original.arr.length; i++) &#123; arr[i] = original.arr[i]; &#125; &#125; public void set(int index, int value) &#123; arr[index] = value; &#125; public int get(int index) &#123; return arr[index]; &#125;&#125;CloneConstructorExample e1 = new CloneConstructorExample();CloneConstructorExample e2 = new CloneConstructorExample(e1);e1.set(2, 222);System.out.println(e2.get(2)); // 2 关键字final1. 数据 声明数据为常量，可以是编译时常量，也可以是在运行时被初始化后不能被改变的常量。 对于基本类型，final 使数值不变； 对于引用类型，final 使引用不变，也就不能引用其它对象，但是被引用的对象本身是可以修改的。 1234final int x = 1;// x = 2; // cannot assign value to final variable &#x27;x&#x27;final A y = new A();y.a = 1; 2. 方法 声明方法不能被子类重写。 private 方法隐式地被指定为 final，如果在子类中定义的方法和基类中的一个 private 方法签名相同，此时子类的方法不是重写基类方法，而是在子类中定义了一个新的方法。 3. 类 声明类不允许被继承。 static1. 静态变量 静态变量: 又称为类变量，也就是说这个变量属于类的，类所有的实例都共享静态变量，可以直接通过类名来访问它；静态变量在内存中只存在一份。 实例变量: 每创建一个实例就会产生一个实例变量，它与该实例同生共死。 1234567891011public class A &#123; private int x; // 实例变量 private static int y; // 静态变量 public static void main(String[] args) &#123; // int x = A.x; // Non-static field &#x27;x&#x27; cannot be referenced from a static context A a = new A(); int x = a.x; int y = A.y; &#125;&#125; 2. 静态方法 静态方法在类加载的时候就存在了，它不依赖于任何实例。所以静态方法必须有实现，也就是说它不能是抽象方法(abstract)。 12345public abstract class A &#123; public static void func1()&#123; &#125; // public abstract static void func2(); // Illegal combination of modifiers: &#x27;abstract&#x27; and &#x27;static&#x27;&#125; 只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字。 12345678910public class A &#123; private static int x; private int y; public static void func1()&#123; int a = x; // int b = y; // Non-static field &#x27;y&#x27; cannot be referenced from a static context // int b = this.y; // &#x27;A.this&#x27; cannot be referenced from a static context &#125;&#125; 3. 静态语句块 静态语句块在类初始化时运行一次。 1234567891011public class A &#123; static &#123; System.out.println(&quot;123&quot;); &#125; public static void main(String[] args) &#123; A a1 = new A(); A a2 = new A(); &#125;&#125;123 4. 静态内部类 非静态内部类依赖于外部类的实例，而静态内部类不需要。 1234567891011121314public class OuterClass &#123; class InnerClass &#123; &#125; static class StaticInnerClass &#123; &#125; public static void main(String[] args) &#123; // InnerClass innerClass = new InnerClass(); // &#x27;OuterClass.this&#x27; cannot be referenced from a static context OuterClass outerClass = new OuterClass(); InnerClass innerClass = outerClass.new InnerClass(); StaticInnerClass staticInnerClass = new StaticInnerClass(); &#125;&#125; 静态内部类不能访问外部类的非静态的变量和方法。 5. 静态导包 在使用静态变量和方法时不用再指明 ClassName，从而简化代码，但可读性大大降低。 1import static com.xxx.ClassName.* 6. 初始化顺序 静态变量和静态语句块优先于实例变量和普通语句块，静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。 12345678public static String staticField = &quot;静态变量&quot;;static &#123; System.out.println(&quot;静态语句块&quot;);&#125;public String field = &quot;实例变量&quot;;&#123; System.out.println(&quot;普通语句块&quot;);&#125; 最后才是构造函数的初始化。 123public InitialOrderTest() &#123; System.out.println(&quot;构造函数&quot;);&#125; 存在继承的情况下，初始化顺序为: 父类(静态变量、静态语句块) 子类(静态变量、静态语句块) 父类(实例变量、普通语句块) 父类(构造函数) 子类(实例变量、普通语句块) 子类(构造函数) 反射每个类都有一个 Class 对象，包含了与类有关的信息。当编译一个新类时，会产生一个同名的 .class 文件，该文件内容保存着 Class 对象。 类加载相当于 Class 对象的加载。类在第一次使用时才动态加载到 JVM 中，可以使用 Class.forName(&quot;com.mysql.jdbc.Driver&quot;) 这种方式来控制类的加载，该方法会返回一个 Class 对象。 反射可以提供运行时的类信息，并且这个类可以在运行时才加载进来，甚至在编译时期该类的 .class 不存在也可以加载进来。 Class 和 java.lang.reflect 一起对反射提供了支持，java.lang.reflect 类库主要包含了以下三个类: Field : 可以使用 get() 和 set() 方法读取和修改 Field 对象关联的字段； Method : 可以使用 invoke() 方法调用与 Method 对象关联的方法； Constructor : 可以用 Constructor 创建新的对象。 Advantages of Using Reflection: Extensibility Features : An application may make use of external, user-defined classes by creating instances of extensibility objects using their fully-qualified names. Class Browsers and Visual Development Environments : A class browser needs to be able to enumerate the members of classes. Visual development environments can benefit from making use of type information available in reflection to aid the developer in writing correct code. Debuggers and Test Tools : Debuggers need to be able to examine private members on classes. Test harnesses can make use of reflection to systematically call a discoverable set APIs defined on a class, to insure a high level of code coverage in a test suite. Drawbacks of Reflection: Reflection is powerful, but should not be used indiscriminately. If it is possible to perform an operation without using reflection, then it is preferable to avoid using it. The following concerns should be kept in mind when accessing code via reflection. Performance Overhead : Because reflection involves types that are dynamically resolved, certain Java virtual machine optimizations can not be performed. Consequently, reflective operations have slower performance than their non-reflective counterparts, and should be avoided in sections of code which are called frequently in performance-sensitive applications. Security Restrictions : Reflection requires a runtime permission which may not be present when running under a security manager. This is in an important consideration for code which has to run in a restricted security context, such as in an Applet. Exposure of Internals :Since reflection allows code to perform operations that would be illegal in non-reflective code, such as accessing private fields and methods, the use of reflection can result in unexpected side-effects, which may render code dysfunctional and may destroy portability. Reflective code breaks abstractions and therefore may change behavior with upgrades of the platform. 相关文章：Java基础-反射机制详解 异常Throwable 可以用来表示任何可以作为异常抛出的类，分为两种: Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种: 受检异常 : 需要用 try...catch... 语句捕获并进行处理，并且可以从异常中恢复； 非受检异常 : 是程序运行时错误，例如除 0 会引发 ArithmeticException，此时程序崩溃并且无法恢复。 相关文章：Java 基础 - 异常机制详解 泛型123456public class Box&lt;T&gt; &#123; // T stands for &quot;Type&quot; private T t; public void set(T t) &#123; this.t = t; &#125; public T get() &#123; return t; &#125;&#125; 相关文章：Java 基础 - 泛型机制详解 注解Java 注解是附加在代码中的一些元信息，用于一些工具在编译、运行时进行解析和使用，起到说明、配置的功能。注解不会也不能影响代码的实际逻辑，仅仅起到辅助性的作用。 相关文章：Java 基础 - 注解机制详解 特性Java 各版本的新特性New highlights in Java SE 8 Lambda Expressions Pipelines and Streams Date and Time API Default Methods Type Annotations Nashhorn JavaScript Engine Concurrent Accumulators Parallel operations PermGen Error Removed New highlights in Java SE 7 Strings in Switch Statement Type Inference for Generic Instance Creation Multiple Exception Handling Support for Dynamic Languages Try with Resources Java nio Package Binary Literals, Underscore in literals Diamond Syntax Difference between Java 1.8 and Java 1.7? Java 8 特性 Java 与 C++ 的区别 Java 是纯粹的面向对象语言，所有的对象都继承自 java.lang.Object，C++ 为了兼容 C 即支持面向对象也支持面向过程。 Java 通过虚拟机从而实现跨平台特性，但是 C++ 依赖于特定的平台。 Java 没有指针，它的引用可以理解为安全指针，而 C++ 具有和 C 一样的指针。 Java 支持自动垃圾回收，而 C++ 需要手动回收。 Java 不支持多重继承，只能通过实现多个接口来达到相同目的，而 C++ 支持多重继承。 Java 不支持操作符重载，虽然可以对两个 String 对象支持加法运算，但是这是语言内置支持的操作，不属于操作符重载，而 C++ 可以。 Java 的 goto 是保留字，但是不可用，C++ 可以使用 goto。 Java 不支持条件编译，C++ 通过 #ifdef #ifndef 等预处理命令从而实现条件编译。 What are the main differences between Java and C++? JRE or JDK JRE is the JVM program, Java application need to run on JRE. JDK is a superset of JRE, JRE + tools for developing java programs. e.g, it provides the compiler “javac” 参考资料 Eckel B. Java 编程思想[M]. 机械工业出版社, 2002. Bloch J. Effective java[M]. Addison-Wesley Professional, 2017.","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"1.Java 基础 - 面向对象","path":"/2023/12/25/1.Java-基础-面向对象/","content":"本文主要介绍Java OOP 面向对象基础和相关类图。 三大特性封装利用抽象数据类型将数据和基于数据的操作封装在一起，使其构成一个不可分割的独立实体。数据被保护在抽象数据类型的内部，尽可能地隐藏内部的细节，只保留一些对外接口使之与外部发生联系。用户无需知道对象内部的细节，但可以通过对象对外提供的接口来访问该对象。 优点: 减少耦合: 可以独立地开发、测试、优化、使用、理解和修改 减轻维护的负担: 可以更容易被程序员理解，并且在调试的时候可以不影响其他模块 有效地调节性能: 可以通过剖析确定哪些模块影响了系统的性能 提高软件的可重用性 降低了构建大型系统的风险: 即使整个系统不可用，但是这些独立的模块却有可能是可用的 以下 Person 类封装 name、gender、age 等属性，外界只能通过 get() 方法获取一个 Person 对象的 name 属性和 gender 属性，而无法获取 age 属性，但是 age 属性可以供 work() 方法使用。 注意到 gender 属性使用 int 数据类型进行存储，封装使得用户注意不到这种实现细节。并且在需要修改 gender 属性使用的数据类型时，也可以在不影响客户端代码的情况下进行。 12345678910111213141516171819202122public class Person &#123; private String name; private int gender; private int age; public String getName() &#123; return name; &#125; public String getGender() &#123; return gender == 0 ? &quot;man&quot; : &quot;woman&quot;; &#125; public void work() &#123; if (18 &lt;= age &amp;&amp; age &lt;= 50) &#123; System.out.println(name + &quot; is working very hard!&quot;); &#125; else &#123; System.out.println(name + &quot; can&#x27;t work any more!&quot;); &#125; &#125;&#125; 继承继承实现了 IS-A 关系，例如 Cat 和 Animal 就是一种 IS-A 关系，因此 Cat 可以继承自 Animal，从而获得 Animal 非 private 的属性和方法。 继承应该遵循里氏替换原则，子类对象必须能够替换掉所有父类对象。 Cat 可以当做 Animal 来使用，也就是说可以使用 Animal 引用 Cat 对象。父类引用指向子类对象称为 向上转型 。 1Animal animal = new Cat(); 多态多态分为编译时多态和运行时多态: 编译时多态主要指方法的重载 运行时多态指程序中定义的对象引用所指向的具体类型在运行期间才确定 运行时多态有三个条件: 继承 覆盖(重写) 向上转型 下面的代码中，乐器类(Instrument)有两个子类: Wind 和 Percussion，它们都覆盖了父类的 play() 方法，并且在 main() 方法中使用父类 Instrument 来引用 Wind 和 Percussion 对象。在 Instrument 引用调用 play() 方法时，会执行实际引用对象所在类的 play() 方法，而不是 Instrument 类的方法。 12345678910111213141516171819202122232425262728public class Instrument &#123; public void play() &#123; System.out.println(&quot;Instrument is playing...&quot;); &#125;&#125;public class Wind extends Instrument &#123; public void play() &#123; System.out.println(&quot;Wind is playing...&quot;); &#125;&#125;public class Percussion extends Instrument &#123; public void play() &#123; System.out.println(&quot;Percussion is playing...&quot;); &#125;&#125;public class Music &#123; public static void main(String[] args) &#123; List&lt;Instrument&gt; instruments = new ArrayList&lt;&gt;(); instruments.add(new Wind()); instruments.add(new Percussion()); for(Instrument instrument : instruments) &#123; instrument.play(); &#125; &#125;&#125; 类图以下类图使用 PlantUML在新窗口打开 绘制，更多语法及使用请参考: http://plantuml.com/ 。 泛化关系 (Generalization)用来描述继承关系，在 Java 中使用 extends 关键字。 123456789101112@startumltitle Generalizationclass Vehicalclass Carclass TruckVehical &lt;|-- CarVehical &lt;|-- Truck@enduml 实现关系 (Realization)用来实现一个接口，在 Java 中使用 implements 关键字。 123456789101112@startumltitle Realizationinterface MoveBehaviorclass Flyclass RunMoveBehavior &lt;|.. FlyMoveBehavior &lt;|.. Run@enduml 聚合关系 (Aggregation)表示整体由部分组成，但是整体和部分不是强依赖的，整体不存在了部分还是会存在。 1234567891011121314@startumltitle Aggregationclass Computerclass Keyboardclass Mouseclass ScreenComputer o-- KeyboardComputer o-- MouseComputer o-- Screen@enduml 组合关系 (Composition)和聚合不同，组合中整体和部分是强依赖的，整体不存在了部分也不存在了。比如公司和部门，公司没了部门就不存在了。但是公司和员工就属于聚合关系了，因为公司没了员工还在。 123456789101112@startumltitle Compositionclass Companyclass DepartmentAclass DepartmentBCompany *-- DepartmentACompany *-- DepartmentB@enduml 关联关系 (Association)表示不同类对象之间有关联，这是一种静态关系，与运行过程的状态无关，在最开始就可以确定。因此也可以用 1 对 1、多对 1、多对多这种关联关系来表示。比如学生和学校就是一种关联关系，一个学校可以有很多学生，但是一个学生只属于一个学校，因此这是一种多对一的关系，在运行开始之前就可以确定。 12345678910@startumltitle Associationclass Schoolclass StudentSchool &quot;1&quot; - &quot;n&quot; Student@enduml 依赖关系 (Dependency)和关联关系不同的是，依赖关系是在运行过程中起作用的。A 类和 B 类是依赖关系主要有三种形式: A 类是 B 类中的(某中方法的)局部变量； A 类是 B 类方法当中的一个参数； A 类向 B 类发送消息，从而影响 B 类发生变化； 12345678910111213141516171819@startumltitle Dependencyclass Vehicle &#123; move(MoveBehavior)&#125;interface MoveBehavior &#123; move()&#125;note &quot;MoveBehavior.move()&quot; as NVehicle ..&gt; MoveBehaviorVehicle .. N@enduml # 参考资料 Java 编程思想 敏捷软件开发: 原则、模式与实践 面向对象设计的 SOLID 原则在新窗口打开 看懂 UML 类图和时序图在新窗口打开 UML 系列——时序图(顺序图)sequence diagram在新窗口打开 面向对象编程三大特性 —— 封装、继承、多态在新窗口打开 javaoop基础知识总结 https://blog.csdn.net/weixin_38173324/article/details/70037927 Java实现OOP(面向对象编程) https://www.cnblogs.com/AlanLee/p/6475334.html Java 抽象类与oop三大特征 http://www.cnblogs.com/wujing-hubei/p/6012105.html","tags":["Java","Java基础"],"categories":["Java","Java基础"]},{"title":"Spring Boot 无侵入式 实现 API 接口统一 JSON 格式返回","path":"/2023/12/25/Spring-Boot-无侵入式-实现-API-接口统一-JSON-格式返回/","content":"无侵入式 统一返回JSON格式其实本没有没打算写这篇博客的，但还是要写一下写这篇博客的起因是因为，现在呆着的这家公司居然没有统一的API返回格式?，询问主管他居然告诉我用HTTP状态码就够用了（fxxk），天哪HTTP状态码真的够用吗？ 在仔细的阅读了项目源码后发现，在API请求的是居然没有业务异常（黑人问好）。好吧 居然入坑了只能遵照项目风格了，懒得吐槽了。 因为项目已经开发了半年多了, 要是全部接口都做修改工作量还是挺大的, 只能用这种无侵入式的方案来解决. 项目源代码: https://github.com/469753862/galaxy-blogs/tree/master/code/responseResult 定义JSON格式定义返回JSON格式后端返回给前端一般情况下使用JSON格式, 定义如下 1234567&#123; &quot;code&quot;: 200, &quot;message&quot;: &quot;OK&quot;, &quot;data&quot;: &#123; &#125;&#125; code: 返回状态码 message: 返回信息的描述 data: 返回值 定义JavaBean字段定义状态码枚举类123456789101112131415161718192021@ToString@Getterpublic enum ResultStatus &#123; SUCCESS(HttpStatus.OK, 200, &quot;OK&quot;), BAD_REQUEST(HttpStatus.BAD_REQUEST, 400, &quot;Bad Request&quot;), INTERNAL_SERVER_ERROR(HttpStatus.INTERNAL_SERVER_ERROR, 500, &quot;Internal Server Error&quot;),; /** 返回的HTTP状态码, 符合http请求 */ private HttpStatus httpStatus; /** 业务异常码 */ private Integer code; /** 业务异常信息描述 */ private String message; ResultStatus(HttpStatus httpStatus, Integer code, String message) &#123; this.httpStatus = httpStatus; this.code = code; this.message = message; &#125;&#125; 状态码和信息以及http状态码就能一一对应了便于维护, 有同学有疑问了为什么要用到http状态码呀,因为我要兼容项目以前的代码, 没有其他原因, 当然其他同学不喜欢http状态码的可以吧源码中HttpStatus给删除了 定义返回体类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Getter@ToStringpublic class Result&lt;T&gt; &#123; /** 业务错误码 */ private Integer code; /** 信息描述 */ private String message; /** 返回参数 */ private T data; private Result(ResultStatus resultStatus, T data) &#123; this.code = resultStatus.getCode(); this.message = resultStatus.getMessage(); this.data = data; &#125; /** 业务成功返回业务代码和描述信息 */ public static Result&lt;Void&gt; success() &#123; return new Result&lt;Void&gt;(ResultStatus.SUCCESS, null); &#125; /** 业务成功返回业务代码,描述和返回的参数 */ public static &lt;T&gt; Result&lt;T&gt; success(T data) &#123; return new Result&lt;T&gt;(ResultStatus.SUCCESS, data); &#125; /** 业务成功返回业务代码,描述和返回的参数 */ public static &lt;T&gt; Result&lt;T&gt; success(ResultStatus resultStatus, T data) &#123; if (resultStatus == null) &#123; return success(data); &#125; return new Result&lt;T&gt;(resultStatus, data); &#125; /** 业务异常返回业务代码和描述信息 */ public static &lt;T&gt; Result&lt;T&gt; failure() &#123; return new Result&lt;T&gt;(ResultStatus.INTERNAL_SERVER_ERROR, null); &#125; /** 业务异常返回业务代码,描述和返回的参数 */ public static &lt;T&gt; Result&lt;T&gt; failure(ResultStatus resultStatus) &#123; return failure(resultStatus, null); &#125; /** 业务异常返回业务代码,描述和返回的参数 */ public static &lt;T&gt; Result&lt;T&gt; failure(ResultStatus resultStatus, T data) &#123; if (resultStatus == null) &#123; return new Result&lt;T&gt;(ResultStatus.INTERNAL_SERVER_ERROR, null); &#125; return new Result&lt;T&gt;(resultStatus, data); &#125;&#125; 因为使用构造方法进行创建对象太麻烦了, 我们使用静态方法来创建对象这样简单明了 Result实体返回测试1234567891011121314151617181920212223@RestController@RequestMapping(&quot;/hello&quot;)public class HelloController &#123; private static final HashMap&lt;String, Object&gt; INFO; static &#123; INFO = new HashMap&lt;&gt;(); INFO.put(&quot;name&quot;, &quot;galaxy&quot;); INFO.put(&quot;age&quot;, &quot;70&quot;); &#125; @GetMapping(&quot;/hello&quot;) public Map&lt;String, Object&gt; hello() &#123; return INFO; &#125; @GetMapping(&quot;/result&quot;) @ResponseBody public Result&lt;Map&lt;String, Object&gt;&gt; helloResult() &#123; return Result.success(INFO); &#125;&#125; 到这里我们已经简单的实现了统一JSON格式了, 但是我们也发现了一个问题了,想要返回统一的JSON格式需要返回Result&lt;Object&gt;才可以, 我明明返回Object可以了, 为什么要重复劳动, 有没有解决方法, 当然是有的啦, 下面我们开始优化我们的代码吧 统一返回JSON格式进阶-全局处理(@RestControllerAdvice)我师傅经常告诉我的一句话: “你就是一个小屁孩, 你遇到的问题都已经不知道有多少人遇到过了, 你会想到的问题, 已经有前辈想到过了. 你准备解决的问题, 已经有人把坑填了”。是不是很鸡汤, 是不是很励志, 让我对前辈们充满着崇拜, 事实上他对我说的是: “自己去百度”, 这五个大字, 其实这五个大字已经说明上明的B话了, 通过不断的百度和Google发现了很多的解决方案. 我们都知道使用@ResponseBody注解会把返回Object序列化成JSON字符串,就先从这个入手吧, 大致就是在序列化前把Object赋值给Result&lt;Object&gt;就可以了, 大家可以观摩org.springframework.web.servlet.mvc.method.annotation.ResponseBodyAdvice和org.springframework.web.bind.annotation.ResponseBody @ResponseBody继承类我们已经决定从@ResponseBody注解入手了就创建一个注解类继承@ResponseBody, 很干净什么都没有哈哈,@ResponseResultBody 可以标记在类和方法上这样我们就可以跟自由的进行使用了 1234567@Retention(RetentionPolicy.RUNTIME)@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Documented@ResponseBodypublic @interface ResponseResultBody &#123;&#125; ResponseBodyAdvice继承类12345678910111213141516171819202122232425@RestControllerAdvicepublic class ResponseResultBodyAdvice implements ResponseBodyAdvice&lt;Object&gt; &#123; private static final Class&lt;? extends Annotation&gt; ANNOTATION_TYPE = ResponseResultBody.class; /** * 判断类或者方法是否使用了 @ResponseResultBody */ @Override public boolean supports(MethodParameter returnType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType) &#123; return AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ANNOTATION_TYPE) || returnType.hasMethodAnnotation(ANNOTATION_TYPE); &#125; /** * 当类或者方法使用了 @ResponseResultBody 就会调用这个方法 */ @Override public Object beforeBodyWrite(Object body, MethodParameter returnType, MediaType selectedContentType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; selectedConverterType, ServerHttpRequest request, ServerHttpResponse response) &#123; // 防止重复包裹的问题出现 if (body instanceof Result) &#123; return body; &#125; return Result.success(body); &#125;&#125; RestControllerAdvice返回测试12345678910111213141516171819202122232425262728293031323334@RestController@RequestMapping(&quot;/helloResult&quot;)@ResponseResultBodypublic class HelloResultController &#123; private static final HashMap&lt;String, Object&gt; INFO; static &#123; INFO = new HashMap&lt;String, Object&gt;(); INFO.put(&quot;name&quot;, &quot;galaxy&quot;); INFO.put(&quot;age&quot;, &quot;70&quot;); &#125; @GetMapping(&quot;hello&quot;) public HashMap&lt;String, Object&gt; hello() &#123; return INFO; &#125; /** 测试重复包裹 */ @GetMapping(&quot;result&quot;) public Result&lt;Map&lt;String, Object&gt;&gt; helloResult() &#123; return Result.success(INFO); &#125; @GetMapping(&quot;helloError&quot;) public HashMap&lt;String, Object&gt; helloError() throws Exception &#123; throw new Exception(&quot;helloError&quot;); &#125; @GetMapping(&quot;helloMyError&quot;) public HashMap&lt;String, Object&gt; helloMyError() throws Exception &#123; throw new ResultException(); &#125;&#125; 是不是很神奇, 直接返回Object就可以统一JSON格式了, 就不用每个返回都返回Result&lt;T&gt;对象了,直接让SpringMVC帮助我们进行统一的管理, 简直完美 只想看接口哦, helloError和helloMyError是会直接抛出异常的接口,我好像没有对异常返回进行统一的处理哦 统一返回JSON格式进阶-异常处理(@ExceptionHandler))卧槽, 异常处理, 差点把这茬给忘了, 这个异常处理就有很多方法了,先看看我师傅的处理方式, 我刚拿到这个代码的时候很想吐槽, 对异常类的处理这么残暴的吗, 直接用PrintWriter直接输出结果, 果然是老师傅, 我要是有100个异常类, 不得要写100个 if else了. 赶紧改改睡吧 1234567891011121314151617181920212223242526272829@Configurationpublic class MyExceptionHandler implements HandlerExceptionResolver &#123; public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; PrintWriter out = getPrintWrite(response); if (ex instanceof XXXException) &#123; out.write(JsonUtil.formatJson(ResultEnum.PAY_ERROR.getCode(), ex.getMessage())); &#125; else &#123; out.write(JsonUtil.formatJson(ResultEnum.FAIL.getCode(), &quot;服务器异常&quot;)); &#125; if (null != out) &#123; out.close(); &#125; return mav; &#125; private PrintWriter getPrintWrite(HttpServletResponse response) &#123; PrintWriter out = null; try &#123; response.setHeader(&quot;Content-type&quot;, &quot;text/html;charset=UTF-8&quot;); response.setCharacterEncoding(&quot;UTF-8&quot;); out = response.getWriter(); &#125; catch (IOException e) &#123; log.error(&quot;PrintWriter is exception&quot;, e); &#125; return out; &#125;&#125; 上面的代码看看还是没有问题的, 别学过去哦, 异常处理@ResponseStatus(不推荐)@ResponseStatus用法如下,可用在Controller类和Controller方法上以及Exception类上但是这样的工作量还是挺大的 12345678910111213141516171819202122232425262728293031323334@RestController@RequestMapping(&quot;/error&quot;)@ResponseStatus(value = HttpStatus.INTERNAL_SERVER_ERROR, reason = &quot;Java的异常&quot;)public class HelloExceptionController &#123; private static final HashMap&lt;String, Object&gt; INFO; static &#123; INFO = new HashMap&lt;String, Object&gt;(); INFO.put(&quot;name&quot;, &quot;galaxy&quot;); INFO.put(&quot;age&quot;, &quot;70&quot;); &#125; @GetMapping() public HashMap&lt;String, Object&gt; helloError() throws Exception &#123; throw new Exception(&quot;helloError&quot;); &#125; @GetMapping(&quot;helloJavaError&quot;) @ResponseStatus(value = HttpStatus.INTERNAL_SERVER_ERROR, reason = &quot;Java的异常&quot;) public HashMap&lt;String, Object&gt; helloJavaError() throws Exception &#123; throw new Exception(&quot;helloError&quot;); &#125; @GetMapping(&quot;helloMyError&quot;) public HashMap&lt;String, Object&gt; helloMyError() throws Exception &#123; throw new MyException(); &#125;&#125;@ResponseStatus(value = HttpStatus.INTERNAL_SERVER_ERROR, reason = &quot;自己定义的异常&quot;)class MyException extends Exception &#123;&#125; 全局异常处理@ExceptionHandler(推荐)把ResponseResultBodyAdvice类进行改造一下,代码有点多了 主要参考了org.springframework.web.servlet.mvc.method.annotation.ResponseEntityExceptionHandler#handleException()方法, 有空可以看一下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Slf4j@RestControllerAdvicepublic class ResponseResultBodyAdvice implements ResponseBodyAdvice&lt;Object&gt; &#123; private static final Class&lt;? extends Annotation&gt; ANNOTATION_TYPE = ResponseResultBody.class; /** 判断类或者方法是否使用了 @ResponseResultBody */ @Override public boolean supports(MethodParameter returnType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; converterType) &#123; return AnnotatedElementUtils.hasAnnotation(returnType.getContainingClass(), ANNOTATION_TYPE) || returnType.hasMethodAnnotation(ANNOTATION_TYPE); &#125; /** 当类或者方法使用了 @ResponseResultBody 就会调用这个方法 */ @Override public Object beforeBodyWrite(Object body, MethodParameter returnType, MediaType selectedContentType, Class&lt;? extends HttpMessageConverter&lt;?&gt;&gt; selectedConverterType, ServerHttpRequest request, ServerHttpResponse response) &#123; if (body instanceof Result) &#123; return body; &#125; return Result.success(body); &#125; /** * 提供对标准Spring MVC异常的处理 * * @param ex the target exception * @param request the current request */ @ExceptionHandler(Exception.class) public final ResponseEntity&lt;Result&lt;?&gt;&gt; exceptionHandler(Exception ex, WebRequest request) &#123; log.error(&quot;ExceptionHandler: &#123;&#125;&quot;, ex.getMessage()); HttpHeaders headers = new HttpHeaders(); if (ex instanceof ResultException) &#123; return this.handleResultException((ResultException) ex, headers, request); &#125; // TODO: 2019/10/05 galaxy 这里可以自定义其他的异常拦截 return this.handleException(ex, headers, request); &#125; /** 对ResultException类返回返回结果的处理 */ protected ResponseEntity&lt;Result&lt;?&gt;&gt; handleResultException(ResultException ex, HttpHeaders headers, WebRequest request) &#123; Result&lt;?&gt; body = Result.failure(ex.getResultStatus()); HttpStatus status = ex.getResultStatus().getHttpStatus(); return this.handleExceptionInternal(ex, body, headers, status, request); &#125; /** 异常类的统一处理 */ protected ResponseEntity&lt;Result&lt;?&gt;&gt; handleException(Exception ex, HttpHeaders headers, WebRequest request) &#123; Result&lt;?&gt; body = Result.failure(); HttpStatus status = HttpStatus.INTERNAL_SERVER_ERROR; return this.handleExceptionInternal(ex, body, headers, status, request); &#125; /** * org.springframework.web.servlet.mvc.method.annotation.ResponseEntityExceptionHandler#handleExceptionInternal(java.lang.Exception, java.lang.Object, org.springframework.http.HttpHeaders, org.springframework.http.HttpStatus, org.springframework.web.context.request.WebRequest) * &lt;p&gt; * A single place to customize the response body of all exception types. * &lt;p&gt;The default implementation sets the &#123;@link WebUtils#ERROR_EXCEPTION_ATTRIBUTE&#125; * request attribute and creates a &#123;@link ResponseEntity&#125; from the given * body, headers, and status. */ protected ResponseEntity&lt;Result&lt;?&gt;&gt; handleExceptionInternal( Exception ex, Result&lt;?&gt; body, HttpHeaders headers, HttpStatus status, WebRequest request) &#123; if (HttpStatus.INTERNAL_SERVER_ERROR.equals(status)) &#123; request.setAttribute(WebUtils.ERROR_EXCEPTION_ATTRIBUTE, ex, WebRequest.SCOPE_REQUEST); &#125; return new ResponseEntity&lt;&gt;(body, headers, status); &#125;&#125;","tags":["框架","Spring","SpringBoot","分布式","微服务"],"categories":["框架","Spring","SpringBoot"]},{"title":"Redis 分布式锁使用不当，酿成一个重大事故","path":"/2023/12/25/Redis-分布式锁使用不当，酿成一个重大事故/","content":"基于Redis使用分布式锁在当今已经不是什么新鲜事了。 本篇文章主要是基于我们实际项目中因为redis分布式锁造成的事故分析及解决方案。我们项目中的抢购订单采用的是分布式锁来解决的，有一次，运营做了一个飞天茅台的抢购活动，库存100瓶，但是却超卖了100瓶！要知道，这个地球上飞天茅台的稀缺性啊！！！ 事故定为P0级重大事故…只能坦然接受。整个项目组被扣绩效了~~事故发生后，CTO指名点姓让我带头冲锋来处理。 好吧，冲~ 事故现场经过一番了解后，得知这个抢购活动接口以前从来没有出现过这种情况，但是这次为什么会超卖呢？ 原因在于：之前的抢购商品都不是什么稀缺性商品，而这次活动居然是飞天茅台，通过埋点数据分析，各项数据基本都是成倍增长，活动热烈程度可想而知！话不多说，直接上核心代码，机密部分做了伪代码处理。。。 12345678910111213141516171819202122232425262728public SeckillActivityRequestVO seckillHandle(SeckillActivityRequestVO request) &#123; SeckillActivityRequestVO response; String key = &quot;key:&quot; + request.getSeckillId; try &#123; Boolean lockFlag = redisTemplate.opsForValue().setIfAbsent(key, &quot;val&quot;, 10, TimeUnit.SECONDS); if (lockFlag) &#123; // HTTP请求用户服务进行用户相关的校验 // 用户活动校验 // 库存校验 Object stock = redisTemplate.opsForHash().get(key+&quot;:info&quot;, &quot;stock&quot;); assert stock != null; if (Integer.parseInt(stock.toString()) &lt;= 0) &#123; // 业务异常 &#125; else &#123; redisTemplate.opsForHash().increment(key+&quot;:info&quot;, &quot;stock&quot;, -1); // 生成订单 // 发布订单创建成功事件 // 构建响应VO &#125; &#125; &#125; finally &#123; // 释放锁 stringRedisTemplate.delete(&quot;key&quot;); // 构建响应VO &#125; return response;&#125; 以上代码，通过分布式锁过期时间有效期10s来保障业务逻辑有足够的执行时间；采用try-finally语句块保证锁一定会及时释放。业务代码内部也对库存进行了校验。看起来很安全啊~ 别急，继续分析。。。 事故原因飞天茅台抢购活动吸引了大量新用户下载注册我们的APP，其中，不乏很多羊毛党，采用专业的手段来注册新用户来薅羊毛和刷单。当然我们的用户系统提前做好了防备，接入阿里云人机验证、三要素认证以及自研的风控系统等各种十八般武艺，挡住了大量的非法用户。此处不禁点个赞~ 但也正因如此，让用户服务一直处于较高的运行负载中。 抢购活动开始的一瞬间，大量的用户校验请求打到了用户服务。导致用户服务网关出现了短暂的响应延迟，有些请求的响应时长超过了10s，但由于HTTP请求的响应超时我们设置的是30s，这就导致接口一直阻塞在用户校验那里，10s后，分布式锁已经失效了，此时有新的请求进来是可以拿到锁的，也就是说锁被覆盖了。这些阻塞的接口执行完之后，又会执行释放锁的逻辑，这就把其他线程的锁释放了，导致新的请求也可以竞争到锁~这真是一个极其恶劣的循环。这个时候只能依赖库存校验，但是偏偏库存校验不是非原子性的，采用的是get and compare 的方式，超卖的悲剧就这样发生了~~~ 事故分析仔细分析下来，可以发现，这个抢购接口在高并发场景下，是有严重的安全隐患的，主要集中在三个地方： 没有其他系统风险容错处理 由于用户服务吃紧，网关响应延迟，但没有任何应对方式，这是超卖的导火索。 看似安全的分布式锁其实一点都不安全 虽然采用了set key value [EX seconds] [PX milliseconds] [NX|XX]的方式，但是如果线程A执行的时间较长没有来得及释放，锁就过期了，此时线程B是可以获取到锁的。当线程A执行完成之后，释放锁，实际上就把线程B的锁释放掉了。这个时候，线程C又是可以获取到锁的，而此时如果线程B执行完释放锁实际上就是释放的线程C设置的锁。这是超卖的直接原因。 非原子性的库存校验 非原子性的库存校验导致在并发场景下，库存校验的结果不准确。这是超卖的根本原因。 通过以上分析，问题的根本原因在于库存校验严重依赖了分布式锁。因为在分布式锁正常set、del的情况下，库存校验是没有问题的。但是，当分布式锁不安全可靠的时候，库存校验就没有用了。 解决方案知道了原因之后，我们就可以对症下药了。 实现相对安全的分布式锁相对安全的定义：set、del是一一映射的，不会出现把其他现成的锁del的情况。从实际情况的角度来看，即使能做到set、del一一映射，也无法保障业务的绝对安全。因为锁的过期时间始终是有界的，除非不设置过期时间或者把过期时间设置的很长，但这样做也会带来其他问题。故没有意义。要想实现相对安全的分布式锁，必须依赖key的value值。在释放锁的时候，通过value值的唯一性来保证不会勿删。我们基于LUA脚本实现原子性的get and compare，如下： 12345public void safedUnLock(String key, String val) &#123; String luaScript = &quot;local in = ARGV[1] local curr=redis.call(&#x27;get&#x27;, KEYS[1]) if in==curr then redis.call(&#x27;del&#x27;, KEYS[1]) end return &#x27;OK&#x27;&quot;&quot;; RedisScript&lt;String&gt; redisScript = RedisScript.of(luaScript); redisTemplate.execute(redisScript, Collections.singletonList(key), Collections.singleton(val));&#125; 我们通过LUA脚本来实现安全地解锁。 实现安全的库存校验如果我们对于并发有比较深入的了解的话，会发现想 get and compare&#x2F; read and save 等操作，都是非原子性的。如果要实现原子性，我们也可以借助LUA脚本来实现。但就我们这个例子中，由于抢购活动一单只能下1瓶，因此可以不用基于LUA脚本实现而是基于redis本身的原子性。原因在于： 12// redis会返回操作之后的结果，这个过程是原子性的Long currStock = redisTemplate.opsForHash().increment(&quot;key&quot;, &quot;stock&quot;, -1); 发现没有，代码中的库存校验完全是“画蛇添足”。 改进之后的代码经过以上的分析之后，我们决定新建一个DistributedLocker类专门用于处理分布式锁。 123456789101112131415161718192021222324252627public SeckillActivityRequestVO seckillHandle(SeckillActivityRequestVO request) &#123; SeckillActivityRequestVO response; String key = &quot;key:&quot; + request.getSeckillId(); String val = UUID.randomUUID().toString(); try &#123; Boolean lockFlag = distributedLocker.lock(key, val, 10, TimeUnit.SECONDS); if (!lockFlag) &#123; // 业务异常 &#125; // 用户活动校验 // 库存校验，基于redis本身的原子性来保证 Long currStock = stringRedisTemplate.opsForHash().increment(key + &quot;:info&quot;, &quot;stock&quot;, -1); if (currStock &lt; 0) &#123; // 说明库存已经扣减完了。 // 业务异常。 log.error(&quot;[抢购下单] 无库存&quot;); &#125; else &#123; // 生成订单 // 发布订单创建成功事件 // 构建响应 &#125; &#125; finally &#123; distributedLocker.safedUnLock(key, val); // 构建响应 &#125; return response;&#125; 深度思考分布式锁有必要么改进之后，其实可以发现，我们借助于redis本身的原子性扣减库存，也是可以保证不会超卖的。对的。但是如果没有这一层锁的话，那么所有请求进来都会走一遍业务逻辑，由于依赖了其他系统，此时就会造成对其他系统的压力增大。这会增加的性能损耗和服务不稳定性，得不偿失。基于分布式锁可以在一定程度上拦截一些流量。 分布式锁的选型有人提出用RedLock来实现分布式锁。RedLock的可靠性更高，但其代价是牺牲一定的性能。在本场景，这点可靠性的提升远不如性能的提升带来的性价比高。如果对于可靠性极高要求的场景，则可以采用RedLock来实现。 再次思考分布式锁有必要么由于bug需要紧急修复上线，因此我们将其优化并在测试环境进行了压测之后，就立马热部署上线了。实际证明，这个优化是成功的，性能方面略微提升了一些，并在分布式锁失效的情况下，没有出现超卖的情况。然而，还有没有优化空间呢？有的！由于服务是集群部署，我们可以将库存均摊到集群中的每个服务器上，通过广播通知到集群的各个服务器。网关层基于用户ID做hash算法来决定请求到哪一台服务器。这样就可以基于应用缓存来实现库存的扣减和判断。性能又进一步提升了！ 12345678910111213141516171819202122232425// 通过消息提前初始化好，借助ConcurrentHashMap实现高效线程安全private static ConcurrentHashMap&lt;Long, Boolean&gt; SECKILL_FLAG_MAP = new ConcurrentHashMap&lt;&gt;();// 通过消息提前设置好。由于AtomicInteger本身具备原子性，因此这里可以直接使用HashMapprivate static Map&lt;Long, AtomicInteger&gt; SECKILL_STOCK_MAP = new HashMap&lt;&gt;();...public SeckillActivityRequestVO seckillHandle(SeckillActivityRequestVO request) &#123; SeckillActivityRequestVO response; Long seckillId = request.getSeckillId(); if(!SECKILL_FLAG_MAP.get(requestseckillId)) &#123; // 业务异常 &#125; // 用户活动校验 // 库存校验 if(SECKILL_STOCK_MAP.get(seckillId).decrementAndGet() &lt; 0) &#123; SECKILL_FLAG_MAP.put(seckillId, false); // 业务异常 &#125; // 生成订单 // 发布订单创建成功事件 // 构建响应 return response;&#125; 通过以上的改造，我们就完全不需要依赖redis了。性能和安全性两方面都能进一步得到提升！当然，此方案没有考虑到机器的动态扩容、缩容等复杂场景，如果还要考虑这些话，则不如直接考虑分布式锁的解决方案。 总结稀缺商品超卖绝对是重大事故。如果超卖数量多的话，甚至会给平台带来非常严重的经营影响和社会影响。经过本次事故，让我意识到对于项目中的任何一行代码都不能掉以轻心，否则在某些场景下，这些正常工作的代码就会变成致命杀手！对于一个开发者而言，则设计开发方案时，一定要将方案考虑周全。怎样才能将方案考虑周全？唯有持续不断地学习！","tags":["Redis","NoSQL","分布式锁"],"categories":["DataBase","NoSQL"]},{"title":"Java中如何更优雅的处理空值","path":"/2023/12/25/Java中如何更优雅的处理空值/","content":"导语在笔者几年的开发经验中，经常看到项目中存在到处空值判断的情况，这些判断，会让人觉得摸不着头绪，它的出现很有可能和当前的业务逻辑并没有关系。但它会让你很头疼。 有时候，更可怕的是系统因为这些空值的情况，会抛出空指针异常，导致业务系统发生问题。 此篇文章，我总结了几种关于空值的处理手法，希望对读者有帮助。 业务中的空值场景存在一个UserSearchService用来提供用户查询的功能: 12345public interface UserSearchService&#123; List&lt;User&gt; listUser(); User get(Integer id); &#125; 问题现场对于面向对象语言来讲，抽象层级特别的重要。尤其是对接口的抽象，它在设计和开发中占很大的比重，我们在开发时希望尽量面向接口编程。 对于以上描述的接口方法来看，大概可以推断出可能它包含了以下两个含义: listUser(): 查询用户列表 get(Integer id): 查询单个用户 在所有的开发中，XP推崇的TDD模式可以很好的引导我们对接口的定义，所以我们将TDD作为开发代码的”推动者”。 对于以上的接口，当我们使用TDD进行测试用例先行时，发现了潜在的问题： listUser() 如果没有数据，那它是返回空集合还是null呢？ get(Integer id) 如果没有这个对象，是抛异常还是返回null呢？ 深入listUser研究我们先来讨论 1listUser() 这个接口，我经常看到如下实现: 1234567public List&lt;User&gt; listUser()&#123; List&lt;User&gt; userList = userListRepostity.selectByExample(new UserExample()); if(CollectionUtils.isEmpty(userList))&#123;//spring util工具类 return null; &#125; return userList; &#125; 这段代码返回是null,从我多年的开发经验来讲，对于集合这样返回值，最好不要返回null，因为如果返回了null，会给调用者带来很多麻烦。你将会把这种调用风险交给调用者来控制。 如果调用者是一个谨慎的人，他会进行是否为null的条件判断。如果他并非谨慎，或者他是一个面向接口编程的狂热分子(当然，面向接口编程是正确的方向)，他会按照自己的理解去调用接口，而不进行是否为null的条件判断，如果这样的话，是非常危险的，它很有可能出现空指针异常！ 根据墨菲定律来判断: “很有可能出现的问题，在将来一定会出现!” 基于此，我们将它进行优化: 1234567public List&lt;User&gt; listUser()&#123; List&lt;User&gt; userList = userListRepostity.selectByExample(new UserExample()); if(CollectionUtils.isEmpty(userList))&#123; return Lists.newArrayList();//guava类库提供的方式 &#125; return userList; &#125; 对于接口(List listUser())，它一定会返回List，即使没有数据，它仍然会返回List（集合中没有任何元素）; 通过以上的修改，我们成功的避免了有可能发生的空指针异常，这样的写法更安全！ 深入研究get方法对于接口 1User get(Integer id) 你能看到的现象是，我给出id，它一定会给我返回User.但事实真的很有可能不是这样的。 我看到过的实现: 123public User get(Integer id)&#123; return userRepository.selectByPrimaryKey(id);//从数据库中通过id直接获取实体对象 &#125; 相信很多人也都会这样写。 通过代码的时候得知它的返回值很有可能是null! 但我们通过的接口是分辨不出来的! 这个是个非常危险的事情。尤其对于调用者来说！ 我给出的建议是，需要在接口明明时补充文档,比如对于异常的说明,使用注解@exception: 1234567891011public interface UserSearchService&#123; /** * 根据用户id获取用户信息 * @param id 用户id * @return 用户实体 * @exception UserNotFoundException */ User get(Integer id); &#125; 我们把接口定义加上了说明之后，调用者会看到，如果调用此接口，很有可能抛出“UserNotFoundException(找不到用户)”这样的异常。 这种方式可以在调用者调用接口的时候看到接口的定义，但是，这种方式是”弱提示”的！ 如果调用者忽略了注释，有可能就对业务系统产生了风险，这个风险有可能导致一个亿！ 除了以上这种”弱提示”的方式，还有一种方式是，返回值是有可能为空的。那要怎么办呢？ 我认为我们需要增加一个接口，用来描述这种场景. 引入jdk8的Optional,或者使用guava的Optional.看如下定义: 123456789public interface UserSearchService&#123; /** * 根据用户id获取用户信息 * @param id 用户id * @return 用户实体,此实体有可能是缺省值 */ Optional&lt;User&gt; getOptional(Integer id); &#125; Optional有两个含义: 存在 or 缺省。 那么通过阅读接口getOptional()，我们可以很快的了解返回值的意图，这个其实是我们想看到的，它去除了二义性。 它的实现可以写成: 123public Optional&lt;User&gt; getOptional(Integer id)&#123; return Optional.ofNullable(userRepository.selectByPrimaryKey(id)); &#125; 深入入参通过上述的所有接口的描述，你能确定入参id一定是必传的吗？我觉得答案应该是：不能确定。除非接口的文档注释上加以说明。 那如何约束入参呢? 我给大家推荐两种方式： 强制约束 文档性约束（弱提示） 1.强制约束，我们可以通过jsr 303进行严格的约束声明: 12345678910111213141516public interface UserSearchService&#123; /** * 根据用户id获取用户信息 * @param id 用户id * @return 用户实体 * @exception UserNotFoundException */ User get(@NotNull Integer id); /** * 根据用户id获取用户信息 * @param id 用户id * @return 用户实体,此实体有可能是缺省值 */ Optional&lt;User&gt; getOptional(@NotNull Integer id); &#125; 当然，这样写，要配合AOP的操作进行验证，但让spring已经提供了很好的集成方案，在此我就不在赘述了。 2.文档性约束 在很多时候，我们会遇到遗留代码，对于遗留代码，整体性改造的可能性很小。 我们更希望通过阅读接口的实现，来进行接口的说明。 jsr 305规范，给了我们一个描述接口入参的一个方式(需要引入库 com.google.code.findbugs:jsr305): 可以使用注解: @Nullable @Nonnull @CheckForNull 进行接口说明。比如: 1234567891011121314151617public interface UserSearchService&#123; /** * 根据用户id获取用户信息 * @param id 用户id * @return 用户实体 * @exception UserNotFoundException */ @CheckForNull User get(@NonNull Integer id); /** * 根据用户id获取用户信息 * @param id 用户id * @return 用户实体,此实体有可能是缺省值 */ Optional&lt;User&gt; getOptional(@NonNull Integer id); &#125; 小结通过 空集合返回值,Optional,jsr 303，jsr 305这几种方式，可以让我们的代码可读性更强，出错率更低！ 空集合返回值 ：如果有集合这样返回值时，除非真的有说服自己的理由，否则，一定要返回空集合，而不是null Optional: 如果你的代码是jdk8，就引入它！如果不是，则使用Guava的Optional,或者升级jdk版本！它很大程度的能增加了接口的可读性！ jsr 303: 如果新的项目正在开发，不防加上这个试试！一定有一种特别爽的感觉! jsr 305: 如果老的项目在你的手上，你可以尝试的加上这种文档型注解，有助于你后期的重构，或者新功能增加了，对于老接口的理解! 空对象模式场景我们来看一个DTO转化的场景，对象: 1234567891011@Data static class PersonDTO&#123; private String dtoName; private String dtoAge; &#125; @Data static class Person&#123; private String name; private String age; &#125; 需求是将Person对象转化成PersonDTO，然后进行返回。 当然对于实际操作来讲，返回如果Person为空，将返回null,但是PersonDTO是不能返回null的（尤其Rest接口返回的这种DTO）。 在这里，我们只关注转化操作，看如下代码: 1234567891011121314@Test public void shouldConvertDTO()&#123; PersonDTO personDTO = new PersonDTO(); Person person = new Person(); if(!Objects.isNull(person))&#123; personDTO.setDtoAge(person.getAge()); personDTO.setDtoName(person.getName()); &#125;else&#123; personDTO.setDtoAge(&quot;&quot;); personDTO.setDtoName(&quot;&quot;); &#125; &#125; 优化修改这样的数据转化，我们认识可读性非常差，每个字段的判断，如果是空就设置为空字符串(“”) 换一种思维方式进行思考，我们是拿到Person这个类的数据，然后进行赋值操作(setXXX),其实是不关系Person的具体实现是谁的。 那我们可以创建一个Person子类: 1234567891011static class NullPerson extends Person&#123; @Override public String getAge() &#123; return &quot;&quot;; &#125; @Override public String getName() &#123; return &quot;&quot;; &#125; &#125; 它作为Person的一种特例而存在，如果当Person为空的时候，则返回一些get*的默认行为. 所以代码可以修改为: 12345678910111213@Test public void shouldConvertDTO()&#123; PersonDTO personDTO = new PersonDTO(); Person person = getPerson(); personDTO.setDtoAge(person.getAge()); personDTO.setDtoName(person.getName()); &#125; private Person getPerson()&#123; return new NullPerson();//如果Person是null ,则返回空对象 &#125; 其中getPerson()方法，可以用来根据业务逻辑获取Person有可能的对象（对当前例子来讲，如果Person不存在，返回Person的的特例NUllPerson），如果修改成这样，代码的可读性就会变的很强了。 使用Optional可以进行优化空对象模式，它的弊端在于需要创建一个特例对象，但是如果特例的情况比较多，我们是不是需要创建多个特例对象呢，虽然我们也使用了面向对象的多态特性，但是，业务的复杂性如果真的让我们创建多个特例对象，我们还是要再三考虑一下这种模式，它可能会带来代码的复杂性。 对于上述代码，还可以使用Optional进行优化。 1234567891011121314@Test public void shouldConvertDTO()&#123; PersonDTO personDTO = new PersonDTO(); Optional.ofNullable(getPerson()).ifPresent(person -&gt; &#123; personDTO.setDtoAge(person.getAge()); personDTO.setDtoName(person.getName()); &#125;); &#125; private Person getPerson()&#123; return null; &#125; Optional对空值的使用，我觉得更为贴切，它只适用于”是否存在”的场景。 如果只对控制的存在判断，我建议使用Optional. Optioanl的正确使用Optional如此强大，它表达了计算机最原始的特性(0 or 1),那它如何正确的被使用呢! Optional不要作为参数如果你写了一个public方法，这个方法规定了一些输入参数，这些参数中有一些是可以传入null的，那这时候是否可以使用Optional呢？ 我给的建议是: 一定不要这样使用! 举个例子: 123public interface UserService&#123; List&lt;User&gt; listUser(Optional&lt;String&gt; username); &#125; 这个例子的方法 listUser,可能在告诉我们需要根据username查询所有数据集合，如果username是空，也要返回所有的用户集合. 当我们看到这个方法的时候，会觉得有一些歧义: “如果username是absent,是返回空集合吗？还是返回全部的用户数据集合？” Optioanl是一种分支的判断，那我们究竟是关注 Optional还是Optional.get()呢？ 我给大家的建议是，如果不想要这样的歧义，就不要使用它！ 如果你真的想表达两个含义，就給它拆分出两个接口: 1234public interface UserService&#123; List&lt;User&gt; listUser(String username); List&lt;User&gt; listUser(); &#125; 我觉得这样的语义更强，并且更能满足 软件设计原则中的 “单一职责”。 如果你觉得你的入参真的有必要可能传null,那请使用jsr 303或者jsr 305进行说明和验证! 请记住! Optional不能作为入参的参数! Optional作为返回值当个实体的返回那Optioanl可以做为返回值吗？ 其实它是非常满足是否存在这个语义的。 你如说，你要根据id获取用户信息，这个用户有可能存在或者不存在。 你可以这样使用: 123public interface UserService&#123; Optional&lt;User&gt; get(Integer id); &#125; 当调用这个方法的时候，调用者很清楚get方法返回的数据，有可能不存在，这样可以做一些更合理的判断，更好的防止空指针的错误！ 当然，如果业务方真的需要根据id必须查询出User的话，就不要这样使用了，请说明，你要抛出的异常. 只有当考虑它返回null是合理的情况下，才进行Optional的返回 集合实体的返回不是所有的返回值都可以这样用的！如果你返回的是集合： 123public interface UserService&#123; Optional&lt;List&lt;User&gt;&gt; listUser(); &#125; 这样的返回结果，会让调用者不知所措，是否我判断Optional之后，还用进行isEmpty的判断呢？ 这样带来的返回值歧义！我认为是没有必要的。 我们要约定，对于List这种集合返回值，如果集合真的是null的，请返回空集合(Lists.newArrayList); 使用Optional变量1Optional&lt;User&gt; userOpt = ... 如果有这样的变量userOpt,请记住 ： 一定不能直接使用get ，如果这样用，就丧失了Optional本身的含义 （ 比如userOp.get() ） 不要直接使用getOrThrow ,如果你有这样的需求：获取不到就抛异常。那就要考虑，是否是调用的接口设计的是否合理 getter中的使用对于一个java bean,所有的属性都有可能返回null,那是否需要改写所有的getter成为Optional类型呢？ 我给大家的建议是，不要这样滥用Optional. 即便 我java bean中的getter是符合Optional的，但是因为java bean 太多了，这样会导致你的代码有50%以上进行Optinal的判断，这样便污染了代码。(我想说，其实你的实体中的字段应该都是由业务含义的，会认真的思考过它存在的价值的，不能因为Optional的存在而滥用) 我们应该更关注于业务，而不只是空值的判断。 请不要在getter中滥用Optional. 小结可以这样总结Optional的使用： 当使用值为空的情况，并非源于错误时，可以使用Optional! Optional不要用于集合操作! 不要滥用Optional,比如在java bean的getter中!","tags":["Java"],"categories":["Java"]},{"title":"Java 性能优化：35 个小细节，提升你的 Java 代码运行效率","path":"/2023/12/25/Java-性能优化：35-个小细节，提升你的-Java-代码运行效率/","content":"前言代码优化 ，一个很重要的课题。可能有些人觉得没用，一些细小的地方有什么好修改的，改与不改对于代码的运行效率有什么影响呢？这个问题我是这么考虑的，就像大海里面的鲸鱼一样，它吃一条小虾米有用吗？没用，但是，吃的小虾米一多之后，鲸鱼就被喂饱了。 代码优化也是一样，如果项目着眼于尽快无BUG上线，那么此时可以抓大放小，代码的细节可以不精打细磨；但是如果有足够的时间开发、维护代码，这时候就必须考虑每个可以优化的细节了，一个一个细小的优化点累积起来，对于代码的运行效率绝对是有提升的。 代码优化的目标是 1.减小代码的体积 2.提高代码运行的效率 代码优化细节1、尽量指定类、方法的final修饰符 带有final修饰符的类是不可派生的。在Java核心API中，有许多应用final的例子，例如java.lang.String，整个类都是final的。为类指定final修饰符可以让类不可以被继承，为方法指定final修饰符可以让方法不可以被重写。如果指定了一个类为final，则该类所有的方法都是final的。Java编译器会寻找机会内联所有的final方法，内联对于提升Java运行效率作用重大，具体参见Java运行期优化。 此举能够使性能平均提高50% 。 2、尽量重用对象 特别是String对象的使用，出现字符串连接时应该使用StringBuilder&#x2F;StringBuffer代替。由于Java虚拟机不仅要花时间生成对象，以后可能还需要花时间对这些对象进行垃圾回收和处理，因此，生成过多的对象将会给程序的性能带来很大的影响。 3、尽可能使用局部变量 调用方法时传递的参数以及在调用中创建的临时变量都保存在栈中速度较快，其他变量，如静态变量、实例变量等，都在堆中创建，速度较慢。另外，栈中创建的变量，随着方法的运行结束，这些内容就没了，不需要额外的垃圾回收。 4、及时关闭流 Java编程过程中，进行数据库连接、I&#x2F;O流操作时务必小心，在使用完毕后，及时关闭以释放资源。因为对这些大对象的操作会造成系统大的开销，稍有不慎，将会导致严重的后果。 5、尽量减少对变量的重复计算 明确一个概念，对方法的调用，即使方法中只有一句语句，也是有消耗的，包括创建栈帧、调用方法时保护现场、调用方法完毕时恢复现场等。所以例如下面的操作： 123for (int i = 0; i &lt; list.size(); i++) &#123; // todo ...&#125; 建议替换为： 123for (int i = 0, int length = list.size(); i &lt; length; i++) &#123; // todo ...&#125; 这样，在list.size()很大的时候，就减少了很多的消耗 6、尽量采用懒加载的策略，即在需要的时候才创建 例如： 1234String str = &quot;aaa&quot;;if (i == 1) &#123;\tlist.add(str);&#125; 建议替换为： 1234if (i == 1) &#123;\tString str = &quot;aaa&quot;;\tlist.add(str);&#125; 7、慎用异常 异常对性能不利。抛出异常首先要创建一个新的对象，Throwable接口的构造函数调用名为fillInStackTrace()的本地同步方法，fillInStackTrace()方法检查堆栈，收集调用跟踪信息。只要有异常被抛出，Java虚拟机就必须调整调用堆栈，因为在处理过程中创建了一个新的对象。异常只能用于错误处理，不应该用来控制程序流程。 8、不要在循环中使用try…catch…，应该把其放在最外层 除非不得已。如果毫无理由地这么写了，只要你的领导资深一点、有强迫症一点，八成就要骂你为什么写出这种垃圾代码来了。 9、如果能估计到待添加的内容长度，为底层以数组方式实现的集合、工具类指定初始长度 比如ArrayList、LinkedLlist、StringBuilder、StringBuffer、HashMap、HashSet等等，以StringBuilder为例： （1）StringBuilder() &#x2F;&#x2F; 默认分配16个字符的空间 （2）StringBuilder(int size) &#x2F;&#x2F; 默认分配size个字符的空间 （3）StringBuilder(String str) &#x2F;&#x2F; 默认分配16个字符+str.length()个字符空间 可以通过类（这里指的不仅仅是上面的StringBuilder）的来设定它的初始化容量，这样可以明显地提升性能。比如StringBuilder吧，length表示当前的StringBuilder能保持的字符数量。因为当StringBuilder达到最大容量的时候，它会将自身容量增加到当前的2倍再加2，无论何时只要StringBuilder达到它的最大容量，它就不得不创建一个新的字符数组然后将旧的字符数组内容拷贝到新字符数组中—-这是十分耗费性能的一个操作。试想，如果能预估到字符数组中大概要存放5000个字符而不指定长度，最接近5000的2次幂是4096，每次扩容加的2不管，那么： （1）在4096 的基础上，再申请8194个大小的字符数组，加起来相当于一次申请了12290个大小的字符数组，如果一开始能指定5000个大小的字符数组，就节省了一倍以上的空间； （2）把原来的4096个字符拷贝到新的的字符数组中去。 这样，既浪费内存空间又降低代码运行效率。所以，给底层以数组实现的集合、工具类设置一个合理的初始化容量是错不了的，这会带来立竿见影的效果。但是，注意，像HashMap这种是以数组+链表实现的集合，别把初始大小和你估计的大小设置得一样，因为一个table上只连接一个对象的可能性几乎为0。初始大小建议设置为2的N次幂，如果能估计到有2000个元素，设置成new HashMap(128)、new HashMap(256)都可以。 10、当复制大量数据时，使用System.arraycopy()命令 11、乘法和除法使用移位操作 例如： 1234for (val = 0; val &lt; 100000; val += 5) &#123;\ta = val * 8;\tb = val / 2;&#125; 用移位操作可以极大地提高性能，因为在计算机底层，对位的操作是最方便、最快的，因此建议修改为： 1234for (val = 0; val &lt; 100000; val += 5) &#123;\ta = val &lt;&lt; 3;\tb = val &gt;&gt; 1;&#125; 移位操作虽然快，但是可能会使代码不太好理解，因此最好加上相应的注释。 12、循环内不要不断创建对象引用 例如： 123for (int i = 1; i &lt;= count; i++) &#123;\tObject obj = new Object();&#125; 这种做法会导致内存中有count份Object对象引用存在，count很大的话，就耗费内存了，建议为改为： 1234Object obj = null;for (int i = 0; i &lt;= count; i++) &#123; obj = new Object(); &#125; 这样的话，内存中只有一份Object对象引用，每次new Object()的时候，Object对象引用指向不同的Object罢了，但是内存中只有一份，这样就大大节省了内存空间了。 13、基于效率和类型检查的考虑，应该尽可能使用array，无法确定数组大小时才使用ArrayList 14、尽量使用HashMap、ArrayList、StringBuilder，除非线程安全需要，否则不推荐使用Hashtable、Vector、StringBuffer，后三者由于使用同步机制而导致了性能开销 15、不要将数组声明为public static final 因为这毫无意义，这样只是定义了引用为static final，数组的内容还是可以随意改变的，将数组声明为public更是一个安全漏洞，这意味着这个数组可以被外部类所改变。 16、尽量在合适的场合使用单例 使用单例可以减轻加载的负担、缩短加载的时间、提高加载的效率，但并不是所有地方都适用于单例，简单来说，单例主要适用于以下三个方面： （1）控制资源的使用，通过线程同步来控制资源的并发访问 （2）控制实例的产生，以达到节约资源的目的 （3）控制数据的共享，在不建立直接关联的条件下，让多个不相关的进程或线程之间实现通信 17、尽量避免随意使用静态变量 要知道，当某个对象被定义为static的变量所引用，那么gc通常是不会回收这个对象所占有的堆内存的，如： 123public class A &#123;\tprivate static B b = new B();&#125; 此时静态变量b的生命周期与A类相同，如果A类不被卸载，那么引用B指向的B对象会常驻内存，直到程序终止 18、及时清除不再需要的会话 为了清除不再活动的会话，许多应用服务器都有默认的会话超时时间，一般为30分钟。当应用服务器需要保存更多的会话时，如果内存不足，那么操作系统会把部分数据转移到磁盘，应用服务器也可能根据MRU（最近最频繁使用）算法把部分不活跃的会话转储到磁盘，甚至可能抛出内存不足的异常。如果会话要被转储到磁盘，那么必须要先被序列化，在大规模集群中，对对象进行序列化的代价是很昂贵的。因此，当会话不再需要时，应当及时调用HttpSession的invalidate()方法清除会话。 19、实现RandomAccess接口的集合比如ArrayList，应当使用最普通的for循环而不是foreach循环来遍历 这是JDK推荐给用户的。JDK API对于RandomAccess接口的解释是：实现RandomAccess接口用来表明其支持快速随机访问，此接口的主要目的是允许一般的算法更改其行为，从而将其应用到随机或连续访问列表时能提供良好的性能。实际经验表明，实现RandomAccess接口的类实例，假如是随机访问的，使用普通for循环效率将高于使用foreach循环；反过来，如果是顺序访问的，则使用Iterator会效率更高。可以使用类似如下的代码作判断 12345678910if (list instanceof RandomAccess) &#123; for (int i = 0; i &lt; list.size(); i++) &#123; &#125;&#125; else &#123; Iterator&lt;?&gt; iterator = list.iterable(); while (iterator.hasNext()) &#123; iterator.next() &#125;&#125; foreach循环的底层实现原理就是迭代器Iterator，参见Java语法糖1：可变长度参数以及foreach循环原理。所以后半句”反过来，如果是顺序访问的，则使用Iterator会效率更高”的意思就是顺序访问的那些类实例，使用foreach循环去遍历。 20、使用同步代码块替代同步方法 这点在多线程模块中的synchronized锁方法块一文中已经讲得很清楚了，除非能确定一整个方法都是需要进行同步的，否则尽量使用同步代码块，避免对那些不需要进行同步的代码也进行了同步，影响了代码执行效率。 21、将常量声明为static final，并以大写命名 这样在编译期间就可以把这些内容放入常量池中，避免运行期间计算生成常量的值。另外，将常量的名字以大写命名也可以方便区分出常量与变量 22、不要创建一些不使用的对象，不要导入一些不使用的类 这毫无意义，如果代码中出现”The value of the local variable i is not used”、”The import java.util is never used”，那么请删除这些无用的内容 23、程序运行过程中避免使用反射 关于，请参见反射。反射是Java提供给用户一个很强大的功能，功能强大往往意味着效率不高。不建议在程序运行过程中使用尤其是频繁使用反射机制，特别是Method的invoke方法，如果确实有必要，一种建议性的做法是将那些需要通过反射加载的类在项目启动的时候通过反射实例化出一个对象并放入内存—-用户只关心和对端交互的时候获取最快的响应速度，并不关心对端的项目启动花多久时间。 24、使用数据库连接池和线程池 这两个池都是用于重用对象的，前者可以避免频繁地打开和关闭连接，后者可以避免频繁地创建和销毁线程 25、使用带缓冲的输入输出流进行IO操作 带缓冲的输入输出流，即BufferedReader、BufferedWriter、BufferedInputStream、BufferedOutputStream，这可以极大地提升IO效率 26、顺序插入和随机访问比较多的场景使用ArrayList，元素删除和中间插入比较多的场景使用LinkedList这个，理解ArrayList和LinkedList的原理就知道了 27、不要让public方法中有太多的形参 public方法即对外提供的方法，如果给这些方法太多形参的话主要有两点坏处： 1、违反了面向对象的编程思想，Java讲求一切都是对象，太多的形参，和面向对象的编程思想并不契合 2、参数太多势必导致方法调用的出错概率增加 至于这个”太多”指的是多少个，3、4个吧。比如我们用JDBC写一个insertStudentInfo方法，有10个学生信息字段要插如Student表中，可以把这10个参数封装在一个实体类中，作为insert方法的形参。 28、字符串变量和字符串常量equals的时候将字符串常量写在前面 这是一个比较常见的小技巧了，如果有以下代码： 12345678String str = &quot;123&quot;;if (str.equals(&quot;123&quot;)) &#123; // todo...&#125;// 建议修改为：String str = &quot;123&quot;;if (&quot;123&quot;.equals(str)) &#123; // todo ...&#125; 这么做主要是可以避免空指针异常 29、请知道，在java中if (i &#x3D;&#x3D; 1)和if (1 &#x3D;&#x3D; i)是没有区别的，但从阅读习惯上讲，建议使用前者 平时有人问，”if (i &#x3D;&#x3D; 1)”和”if (1&#x3D;&#x3D; i)”有没有区别，这就要从C&#x2F;C++讲起。 在C&#x2F;C++中，”if (i &#x3D;&#x3D; 1)”判断条件成立，是以0与非0为基准的，0表示false，非0表示true，如果有这么一段代码： 123456int i = 2;if (i == 1) &#123; // todo ...&#125; else &#123;\t// todo ...&#125; C&#x2F;C++判断”i&#x3D;&#x3D;1″不成立，所以以0表示，即false。但是如果： 123456int i = 2;if (i = 1) &#123; // todo ... &#125; else &#123; // todo ... &#125; 万一程序员一个不小心，把”if (i &#x3D;&#x3D; 1)”写成”if (i &#x3D; 1)”，这样就有问题了。在if之内将i赋值为1，if判断里面的内容非0，返回的就是true了，但是明明i为2，比较的值是1，应该返回的false。这种情况在C&#x2F;C++的开发中是很可能发生的并且会导致一些难以理解的错误产生，所以，为了避免开发者在if语句中不正确的赋值操作，建议将if语句写为： 123456int i = 2;if (1 == i) &#123; // todo ... &#125; else &#123; // todo ... &#125; 这样，即使开发者不小心写成了”1 &#x3D; i”，C&#x2F;C++编译器也可以第一时间检查出来，因为我们可以对一个变量赋值i为1，但是不能对一个常量赋值1为i。 但是，在Java中，C&#x2F;C++这种”if (i &#x3D; 1)”的语法是不可能出现的，因为一旦写了这种语法，Java就会编译报错”Type mismatch: cannot convert from int to boolean”。但是，尽管Java的”if (i &#x3D;&#x3D; 1)”和”if (1 &#x3D;&#x3D; i)”在语义上没有任何区别，但是从阅读习惯上讲，建议使用前者会更好些。 30、不要对数组使用toString()方法 看一下对数组使用toString()打印出来的是什么： 1234public static void main(String[] args) &#123; int[] is = new int[]&#123;1, 2, 3&#125;;\tSystem.out.println(is.toString());&#125; 结果是： 1[I@18a992f 本意是想打印出数组内容，却有可能因为数组引用is为空而导致空指针异常。不过虽然对数组toString()没有意义，但是对集合toString()是可以打印出集合里面的内容的，因为集合的父类AbstractCollections重写了Object的toString()方法。 31、不要对超出范围的基本数据类型做向下强制转型 这绝不会得到想要的结果： 12345public static void main(String[] args) &#123; long l = 12345678901234L; int i = (int)l; System.out.println(i);&#125; 我们可能期望得到其中的某几位，但是结果却是： 11942892530 解释一下。Java中long是8个字节64位的，所以12345678901234在计算机中的表示应该是： 10000 0000 0000 0000 0000 1011 0011 1010 0111 0011 1100 1110 0010 1111 1111 0010 一个int型数据是4个字节32位的，从低位取出上面这串二进制数据的前32位是： 10111 0011 1100 1110 0010 1111 1111 0010 这串二进制表示为十进制1942892530，所以就是我们上面的控制台上输出的内容。从这个例子上还能顺便得到两个结论 1、整型默认的数据类型是int，long l &#x3D; 12345678901234L，这个数字已经超出了int的范围了，所以最后有一个L，表示这是一个long型数。顺便，浮点型的默认类型是double，所以定义float的时候要写成””float f &#x3D; 3.5f” 2、接下来再写一句”int ii &#x3D; l + i;”会报错，因为long + int是一个long，不能赋值给int 32、公用的集合类中不使用的数据一定要及时remove掉 如果一个集合类是公用的（也就是说不是方法里面的属性），那么这个集合里面的元素是不会自动释放的，因为始终有引用指向它们。所以，如果公用集合里面的某些数据不使用而不去remove掉它们，那么将会造成这个公用集合不断增大，使得系统有内存泄露的隐患。 33、把一个基本数据类型转为字符串，基本数据类型.toString()是最快的方式、String.valueOf(数据)次之、数据+””最慢 把一个基本数据类型转为一般有三种方式，我有一个Integer型数据i，可以使用i.toString()、String.valueOf(i)、i+””三种方式，三种方式的效率如何，看一个测试： 12345678910111213141516171819202122public static void main(String[] args) &#123; int loopTime = 50000;\tInteger i = 0;\tlong startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++) &#123; String str = String.valueOf(i); &#125;\tSystem.out.println(&quot;String.valueOf()：&quot; + (System.currentTimeMillis() - startTime) + &quot;ms&quot;); startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++) &#123;\tString str = i.toString();\t&#125;\tSystem.out.println(&quot;Integer.toString()：&quot; + (System.currentTimeMillis() - startTime) + &quot;ms&quot;); startTime = System.currentTimeMillis(); for (int j = 0; j &lt; loopTime; j++) &#123; String str = i + &quot;&quot;;\t&#125;\tSystem.out.println(&quot;i + \\&quot;\\&quot;：&quot; + (System.currentTimeMillis() - startTime) + &quot;ms&quot;);&#125; 运行结果为： 123String.valueOf()：11ms Integer.toString()：5ms i + &quot;&quot;：25ms 所以以后遇到把一个基本数据类型转为String的时候，优先考虑使用toString()方法。至于为什么，很简单： 1、String.valueOf()方法底层调用了Integer.toString()方法，但是会在调用前做空判断 2、Integer.toString()方法就不说了，直接调用了 3、i + “”底层使用了StringBuilder实现，先用append方法拼接，再用toString()方法获取字符串 三者对比下来，明显是2最快、1次之、3最慢 34、使用最有效率的方式去遍历Map 遍历Map的方式有很多，通常场景下我们需要的是遍历Map中的Key和Value，那么推荐使用的、效率最高的方式是： 1234567891011public static void main(String[] args) &#123;\tHashMap&lt;String, String&gt; hm = new HashMap&lt;String, String&gt;(); hm.put(&quot;111&quot;, &quot;222&quot;); Set&lt;Map.Entry&lt;String, String&gt;&gt; entrySet = hm.entrySet(); Iterator&lt;Map.Entry&lt;String, String&gt;&gt; iter = entrySet.iterator(); while (iter.hasNext()) &#123; Map.Entry&lt;String, String&gt; entry = iter.next(); System.out.println(entry.getKey() + &quot;\\t&quot; + entry.getValue());\t&#125;&#125; 如果你只是想遍历一下这个Map的key值，那用”Set keySet &#x3D; hm.keySet();”会比较合适一些 35、对资源的close()建议分开操作 意思是，比如我有这么一段代码： 123456try&#123;\tXXX.close();\tYYY.close();&#125; catch (Exception e) &#123; // todo ...&#125; 建议修改为： 1234567891011try &#123; XXX.close(); &#125; catch (Exception e) &#123; // todo ... &#125;try &#123; YYY.close(); &#125; catch (Exception e) &#123; // todo ... &#125; 虽然有些麻烦，却能避免资源泄露。我想，如果没有修改过的代码，万一XXX.close()抛异常了，那么就进入了cath块中了，YYY.close()不会执行，YYY这块资源就不会回收了，一直占用着，这样的代码一多，是可能引起资源句柄泄露的。而改为上面的写法之后，就保证了无论如何XXX和YYY都会被close掉。","tags":["Java","性能优化"],"categories":["Java"]},{"title":"使用基于 SpringMVC 的透明 RPC 开发微服务","path":"/2023/12/25/使用基于-SpringMVC-的透明-RPC-开发微服务/","content":"来源：fredal.xin&#x2F;develop-with-transparent-rpc 我司目前 RPC 框架是基于 Java Rest 的方式开发的，形式上可以参考 SpringCloud Feign 的实现。Rest 风格随着微服务的架构兴起，Spring MVC 几乎成为了 Rest 开发的规范，同时对于 Spring 的使用者门槛也比较低。 REST 与 RPC 风格的开发方式RPC 框架采用类 Feign 方式的一个简单的实现例子如下： 12345@RpcClient(schemaId=&quot;hello&quot;)public interface Hello &#123; @GetMapping(&quot;/message&quot;) HelloMessage hello(@RequestParam String name);&#125; 而服务提供者直接使用 spring mvc 来暴露服务接口： 123456789101112@RestControllerpublic class HelloController &#123; @Autowired private HelloService helloService; @GetMapping(&quot;/message&quot;) public HelloMessage getMessage(@RequestParam(name=&quot;name&quot;)String name) &#123; HelloMessage hello = helloService.gen(name); return hello; &#125;&#125; 基于 REST 风格开发的方式有很多优点。一是使用门槛较低，服务端完全基于 Spring MVC，客户端 api 的书写方式也兼容了大部分 Spring 的注解，包括@RequestParam、@RequestBody 等。二是带来的解耦特性，微服务应用注重服务自治，对外则提供松耦合的 REST 接口，这种方式更灵活，可以减轻历史包袱带来的痛点，同时除了提供给类 SDK 的消费者服务外，还可提供浏览器等非 SDK 的消费者服务。 当然这种方式在实际运用中也带来了很多麻烦。首先，不一致的客户端与服务端 API 带来了出错的可能性，Controller 接口的返回值类型与 RpcClient 的返回值类型可能写的不一致从而导致反序列化失败。其次，RpcClient 的书写虽然兼容了 Spring 的注解，但对于某些开发同学仍然存在不小的门槛，例如写 url param 时@RequestParam 注解常常忘写，写 body param 时候@RequestBody 注解忘记写，用@RequestBody 注解来标注 String 参数，方法类型不指定等等（基本上和使用 Feign 的门槛一样）。 还有一点，就是比起常见的 RPC 方式，REST 方式相当于多写了一层 Controller，而不是直接将 Service 暴露成接口。DDD 实践中，将一个巨石应用拆分成各个限界上下文时，往往是对旧代码的 Service 方法进行拆分，REST 风格意味着需要多写 Controller 接入表示层，而在内部微服务应用间相互调用的场景下，暴露应用服务层甚至领域服务层给调用者可能是更简便的方法，在满足 DDD 的同时更符合 RPC 的语义。 那么我们希望能通过一种基于透明 RPC 风格的开发方式来优雅简便地开发微服务。 首先我们希望服务接口的定义能更简便，不用写多余的注解和信息： 1234@RpcClient(schemaId=&quot;hello&quot;)public interface Hello &#123; HelloMessage hello(String name);&#125; 然后我们就可以实现这个服务，并通过使用注解的方式简单的发布服务： 1234567@RpcService(schemaId=&quot;hello&quot;)public class HelloImpl implements Hello&#123; @Override HelloMessage hello(String name)&#123; return new HelloMessage(name); &#125;&#125; 这样客户端在引用 Hello 接口后可以直接使用里面的 hello()方法调用到服务端的实现类 HelloImpl 中，从而获得一个 HelloMessage 对象。相比之前的 REST 实现方式，在简洁性以及一致性上都得到了提升。 隐式的服务契约服务契约指客户端与服务端之间对于接口的描述定义。REST 风格开发方式中，我们使用 Spring MVC annotation 来声明接口的请求、返回参数。但是在透明 RPC 开发方式中，理论上我们可以不用写任何 RESTful 的 annotation 的，这时候怎么去定义服务契约呢。 其实这里运用了隐式的服务契约，可以不事先定义契约和接口，而是直接定义实现类，根据实现类去自动生成默认的契约，注册到服务中心。 默认的服务契约内容包括方法类型的选择、URL 地址以及参数注解的处理。方法类型的判断基于入参类型，如果入参类型中包含自定义类型、Object 或者集合等适合放在 Body 中的类型，则会判断为使用 POST 方法，而如果入参仅有 String 或者基本类型等，则判断使用 GET 方法。POST 方法会将所有参数作为 Body 进行传送，而 GET 方法则将参数作为 URL PARAM 进行传送。URL 地址的默认规则为/类名/方法类型+方法名，未被注解的方法都会按此 URL 注册到服务中心。 服务端的 REST 编程模型我们可以发现，两种开发风格最大的改变是服务端编程模型的改变，从 REST 风格的 SpringMVC 编程模型变成了透明 RPC 编程模型。我们应该怎样去实现这一步呢？ 我们目前的运行架构如上图，服务端的编程模型完全基于 Spring MVC，通信模型则是基于 servlet 的。我们期望服务端的编程模型可以转换为 RPC，那么势必需要我们对通信模型做一定的改造。 从 DispatcherServlet 说起那么首先，我们需要对 Spring MVC 实现的 servlet 规范 DispatcherServlet 做一定的了解，知道它是怎么处理一个请求的。 DispatcherServlet 主要包含三部分逻辑，映射处理器(HandlerMapping)，映射适配器(HandlerAdapter)，视图处理器(ViewResolver)。DispatcherServlet 通过 HandlerMapping 找到合适的 Handler，再通过 HandlerAdapter 进行适配，最终返回 ModelAndView 经由 ViewResolver 处理返回给前端。 回到主题上，我们想要改造这部分通信模型从而能够实现 RPC 的编程模型有两种办法，一是直接编写一个新的 Servlet，实现 REST over Servlet 的效果，从而对服务端通信逻辑得到一个完整的控制，这样我们可以为服务端添加自定义的运行模型(服务端限流、调用链处理等)。二是仅仅修改一部分 HandlerMapping 的代码，将请求映射变得可以适配 RPC 的编程模型。 鉴于工作量与现实条件，我们选择后一种方法，继续沿用 DispatcherServlet，但改造部分 HandlerMapping 的代码。 首先我们会通过 Scanner 扫描到标注了@RpcClient 注解的接口以及其实现类，我们会将其注册到 HandlerMapping 中，所以首先我们要看 HandlerMapping 中有没有能扩展注册逻辑的地方。 接着我们再考虑处理请求的事儿，我们需要 HandlerMapping 能够做到在没有 Spring Annotation 的情况下也能为不同的参数选择不同的 argumentResolver 参数处理器，这一点在 springMVC 中是通过标注注解来区分的(RequestMapping、RequestBody 等)，所以我们还需要看看 HandlerMapping 中有没有能扩展参数注解逻辑的地方。 带着这两点目的，我们先来看 HandlerMapping 的逻辑。 HandlerMapping 的初始化HandlerMapping 的初始化源码比较长，我们直接一笔略过不是很重要的部分了。首先 RequestMappingHandlerMapping 的父类 AbstractHandlerMethodMapping 类实现了 InitializingBean 接口，在属性初始化完成后会调用 afterPropertiesSet()方法，在该方法中调用 initHandlerMethods()进行 HandlerMethod 初始化。InitHandlerMethods 方法中使用 detectHandlerMethods 方法从 bean 中根据 bean name 查找 handlerMethod，此方法中调用 registerHandlerMethod 来注册正常的 handlerMethod。 123protected void registerHandlerMethod(Object handler, Method method, T mapping) &#123; this.mappingRegistry.register(mapping, handler, method); &#125; 我们发现这个方法是 protected 的，那么第一步我们找到了去哪注册我们的 RPC 方法到 RequestMappingHandlerMapping 中。接口可以看到入参是 handler 方法，但在 handlerMapping 中真正被注册的 handlerMethod 对象，显然这部分逻辑在 mappingRegistry 的 register 方法中。register 方法中我们找到了转换的关键方法： 1HandlerMethod handlerMethod = createHandlerMethod(handler, method); 此方法中调用了 handlerMethod 对象的构造器来构造一个 handlerMethod对象。handlerMethod 的属性中包含一个叫 parameters 的 methodParameter 对象数组。我们知道 handlerMethod 对象对应的是一个实现方法，那么 methodParameter 对象对应的就是入参了。 接着往 methodParameter 对象里看，发现了一个叫 parameterAnnotations 的 Annotation 数组，看样子这就是我们第二个需要关注的地方了。那么总结一下，滤去无需关注的部分，handlerMapping 的初始化整个如下图所示： HandlerAdapter 的请求处理这边 dispatcherServlet 在真正处理请求的时候是用 handlerAdapter 去处理再返回 ModelAndView 对象的，但是所有相关对象都是注册在 handlerMapping 中。 我们直接来看看 RequestMappingHandlerAdapter 的处理逻辑吧，handlerAdapter 在 handle 方法中调用 handleInternal 方法，并调用 invokeHandlerMethod 方法，此方法中使用 createInvocableHandlerMethod 方法将 handlerMethod 对象包装成了一个 servletInvocableHandlerMethod 对象，此对象最终调用 invokeAndHandle 方法完成对应请求逻辑的处理。我们只关注 invokeAndHandle 里面的 invokeForRequest 方法，该方法作为对入参的处理正是我们的目标。最终我们看到了此方法中的 getMethodArgumentValues 方法中的一段对入参注解的处理逻辑: 12345678910if (this.argumentResolvers.supportsParameter(parameter)) &#123; try &#123; args[i] = this.argumentResolvers.resolveArgument(parameter, mavContainer, request, this.dataBinderFactory); &#125; catch (Exception var9) &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug(this.getArgumentResolutionErrorMessage(&quot;Error resolving argument&quot;, i), var9); &#125; throw var9; &#125;&#125; 显然，这里使用 supportsParameter 方法来作为判断依据选择 argumentResolver，里层的逻辑就是一个简单的遍历选择真正支持入参的参数处理器。实际上 RequestMappingHandlerAdapte 在初始化时候就注册了一堆参数处理器： 1234567891011121314151617 private List&lt;HandlerMethodReturnValueHandler&gt; getDefaultReturnValueHandlers() &#123; List&lt;HandlerMethodReturnValueHandler&gt; handlers = new ArrayList&lt;HandlerMethodReturnValueHandler&gt;(); // Single-purpose return value types handlers.add(new ModelAndViewMethodReturnValueHandler()); handlers.add(new ModelMethodProcessor()); handlers.add(new ViewMethodReturnValueHandler()); handlers.add(new ResponseBodyEmitterReturnValueHandler(getMessageConverters())); handlers.add(new StreamingResponseBodyReturnValueHandler()); handlers.add(new HttpEntityMethodProcessor(getMessageConverters(), this.contentNegotiationManager, this.requestResponseBodyAdvice)); handlers.add(new HttpHeadersReturnValueHandler()); handlers.add(new CallableMethodReturnValueHandler()); handlers.add(new DeferredResultMethodReturnValueHandler()); handlers.add(new AsyncTaskMethodReturnValueHandler(this.beanFactory));\t//...&#125; 我们调个眼熟的 RequestResponseBodyMethodProcessor 来看看其 supportsParameter 方法: 1234@Overridepublic boolean supportsParameter(MethodParameter parameter) &#123; return parameter.hasParameterAnnotation(RequestBody.class);&#125; 这里直接调用了 MethodParameter 自身的 public 方法 hasParameterAnnotation 方法来判断是否有相应的注解，比如有 RequestBody 注解那么我们就选用 RequestResponseBodyMethodProcessor 来作为其参数处理器。 还是滤去无用逻辑，整个流程如下： 服务端的 RPC 编程模型以上我们了解了 DispatcherServlet 在 REST 编程模型中是部分逻辑，现在我们依据之前讲的改造部分 HandlerMapping 的代码从而使其适配 RPC 编程模型。 RPC 方法注册首先我们需要将方法注册到 handlerMapping，而这点由上述 RequestHandlerMapping 的初始化流程得知直接调用 registerHandlerMethod 方法即可。结合我们的扫描逻辑，大致代码如下： 1234567891011121314151617181920212223242526272829303132333435public class RpcRequestMappingHandlerMapping extends RequestMappingHandlerMapping&#123;\tpublic void registerRpcToMvc(final String prefix) &#123; final AdvancedApiToMvcScanner scanner = new AdvancedApiToMvcScanner(RpcService.class); scanner.setBasePackage(basePackage); Map&lt;Class&lt;?&gt;, Set&lt;MethodTemplate&gt;&gt; mvcMap; //扫描到注解了@RpcService的接口及method元信息 try &#123; mvcMap = scanner.scan(); &#125; catch (final IOException e) &#123; throw new FatalBeanException(&quot;failed to scan&quot;); &#125; for (final Class&lt;?&gt; clazz : mvcMap.keySet()) &#123; final Set&lt;MethodTemplate&gt; methodTemplates = mvcMap.get(clazz); for (final MethodTemplate methodTemplate : methodTemplates) &#123; if (methodTemplate == null) &#123; continue; &#125; final Method method = methodTemplate.getMethod(); Http.HttpMethod httpMethod; String uriTemplate = null; //隐式契约：方法类型和url地址 httpMethod = MvcFuncUtil.judgeMethodType(method); uriTemplate = MvcFuncUtil.genMvcFuncName(clazz, httpMethod.name(), method); final RequestMappingInfo requestMappingInfo = RequestMappingInfo .paths(this.resolveEmbeddedValuesInPatterns(new String[]&#123;uriTemplate&#125;)) .methods(RequestMethod.valueOf(httpMethod.name())) .build(); //注册到spring mvc this.registerHandlerMethod(handler, method, requestMappingInfo); &#125; &#125; &#125;&#125; 我们自定义了注册方法，只需在容器启动时调用即可。 RPC 请求处理以上所说，光完成注册是不够的，我们需要对入参注解做一些处理，例如我们虽然没有写注解@RequestBody User user，我们仍然希望 handlerAdapter 在处理的时候能够以为我们写了，并用 RequestResponseBodyMethodProcessor 参数解析器来进行处理。 我们直接重写 RequestMappingHandlerMapping 的 createHandlerMethod 方法： 1234567891011@Overrideprotected HandlerMethod createHandlerMethod(Object handler, Method method) &#123; HandlerMethod handlerMethod; if (handler instanceof String) &#123; String beanName = (String) handler; handlerMethod = new HandlerMethod(beanName, this.getApplicationContext().getAutowireCapableBeanFactory(), method); &#125; else &#123; handlerMethod = new HandlerMethod(handler, method); &#125; return new RpcHandlerMethod(handlerMethod);&#125; 我们自定义了自己的 HandlerMethod 对象： 12345678910111213141516public class RpcHandlerMethod extends HandlerMethod &#123; protected RpcHandlerMethod(HandlerMethod handlerMethod) &#123; super(handlerMethod); initMethodParameters(); &#125; private void initMethodParameters() &#123; MethodParameter[] methodParameters = super.getMethodParameters(); Annotation[][] parameterAnnotations = null; for (int i = 0; i &lt; methodParameters.length; i++) &#123; SynthesizingMethodParameter methodParameter = (SynthesizingMethodParameter) methodParameters[i]; methodParameters[i] = new RpcMethodParameter(methodParameter); &#125; &#125;&#125; 很容易看到，这里的重点是初始化了自定义的 MethodParameter 对象： 12345678910111213141516171819202122232425262728public class RpcMethodParameter extends SynthesizingMethodParameter &#123; private volatile Annotation[] annotations; protected RpcMethodParameter(SynthesizingMethodParameter original) &#123; super(original); this.annotations = initParameterAnnotations(); &#125; private Annotation[] initParameterAnnotations() &#123; List&lt;Annotation&gt; annotationList = new ArrayList&lt;&gt;(); final Class&lt;?&gt; parameterType = this.getParameterType(); if (MvcFuncUtil.isRequestParamClass(parameterType)) &#123; annotationList.add(MvcFuncUtil.newRequestParam(MvcFuncUtil.genMvcParamName(this.getParameterIndex()))); &#125; else if (MvcFuncUtil.isRequestBodyClass(parameterType)) &#123; annotationList.add(MvcFuncUtil.newRequestBody()); &#125; return annotationList.toArray(new Annotation[]&#123;&#125;); &#125; @Override public Annotation[] getParameterAnnotations() &#123; if (annotations != null &amp;&amp; annotations.length &gt; 0) &#123; return annotations; &#125; return super.getParameterAnnotations(); &#125;&#125; 自定义的 MethodParameter 对象中重写了 getParameterAnnotations 方法，而次方法正是 argumentResolver 用来判断自己是否适合该参数的方法。我们做了些改造使得合适的参数会被合适的参数解析器”误以为”加了对应的注解，从而自己会去进行正常的参数处理逻辑。整个处理流程如下，粉红色部分也正是我们所扩展的点了： RPC 编程模型经过改造之后，我们已经可以实现文章开头所描述的透明 RPC 来开发微服务了，整个运行架构变成了下面这样：","tags":["框架","Spring","分布式","微服务","SpringMVC"],"categories":["框架","Spring","SpringMVC"]},{"title":"图文讲解哈希表","path":"/2023/12/25/图文讲解哈希表/","content":"今天我们来说一种新的数据结构散列（哈希）表，散列是应用非常广泛的数据结构，在我们的刷题过程中，散列表的出场率特别高。所以我们快来一起把散列表的内些事给整明白吧，文章框架如下。 说散列表之前，我们先设想以下场景。 袁厨穿越回了古代，凭借从现代学习的做饭手艺，开了一个袁记菜馆，正值开业初期，店里生意十分火爆，但是顾客结账时就犯难了，由于菜品太多，每当结账时，老板娘总是按照菜单一个一个找价格（遍历查找），每次都要找半天，所以结账的地方总是排起长队，顾客们表示用户体验很差。袁厨一想这不是办法啊，太浪费大家时间了，所以袁厨就先把菜单按照首字母排序（二分查找），然后查找的时候根据首字母查找，这样结账的时候就能大大提高检索效率啦！但是呢？工作日顾客不多，老板娘完全应付的过来，但是每逢节假日，还是会排起长队。那么有没有什么更好的办法呢？对呀！我们把所有的价格都背下来不就可以了吗？每个菜的价格我们都了如指掌，结账的时候我们只需把每道菜的价格相加即可。所以袁厨和老板娘加班加点的进行背诵。下次再结账的时候一说吃了什么菜，我们立马就知道价格啦。自此以后收银台再也没有出现过长队啦，袁记菜馆开着开着一不小心就成了天下第一饭店。 下面我们来看一下袁记菜馆老板娘进化史。 上面的后期结账的过程则模拟了我们的散列表查找，那么在计算机中是如何使用进行查找的呢？ 散列表查找步骤散列表，最有用的基本数据结构之一。是根据关键码的值直接进行访问的数据结构，散列表的实现常常叫做散列（hasing）。散列是一种用于以常数平均时间执行插入、删除和查找的技术，下面我们来看一下散列过程。 我们的整个散列过程主要分为两步 （1）通过散列函数计算记录的散列地址，并按此散列地址存储该记录。就好比麻辣鱼，我们就让它在川菜区，糖醋鱼，我们就让它在鲁菜区。但是我们需要注意的是，无论什么记录我们都需要用同一个散列函数计算地址，然后再存储。 （2)当我们查找时，我们通过同样的散列函数计算记录的散列地址，按此散列地址访问该记录。因为我们存和取的时候用的都是一个散列函数，因此结果肯定相同。 刚才我们在散列过程中提到了散列函数，那么散列函数是什么呢？ 我们假设某个函数为 f，使得 存储位置 &#x3D; f (key) 那样我们就能通过查找关键字不需要比较就可获得需要的记录的存储位置。这种存储技术被称为散列技术。散列技术是在通过记录的存储位置和它的关键字之间建立一个确定的对应关系 f ,使得每个关键字 key 都对应一个存储位置 f(key)。见下图 这里的 f 就是我们所说的散列函数（哈希）函数。我们利用散列技术将记录存储在一块连续的存储空间中，这块连续存储空间就是我们本文的主人公——散列(哈希) 上图为我们描述了用散列函数将关键字映射到散列表，但是大家有没有考虑到这种情况，那就是将关键字映射到同一个槽中的情况，即 f(k4) &#x3D; f(k3) 时。这种情况我们将其称之为冲突，k3 和 k4 则被称之为散列函数 f 的同义词，如果产生这种情况，则会让我们查找错误。幸运的是我们能找到有效的方法解决冲突。 首先我们可以对哈希函数下手，我们可以精心设计哈希函数，让其尽可能少的产生冲突，所以我们创建哈希函数时应遵循以下规则 （1）必须是一致的，假设你输入辣子鸡丁时得到的是在看，那么每次输入辣子鸡丁时，得到的也必须为在看。如果不是这样，散列表将毫无用处。 （2）计算简单，假设我们设计了一个算法，可以保证所有关键字都不会冲突，但是这个算法计算复杂，会耗费很多时间，这样的话就大大降低了查找效率，反而得不偿失。所以咱们散列函数的计算时间不应该超过其他查找技术与关键字的比较时间，不然的话我们干嘛不使用其他查找技术呢? （3）散列地址分布均匀我们刚才说了冲突的带来的问题，所以我们最好的办法就是让散列地址尽量均匀分布在存储空间中，这样即保证空间的有效利用，又减少了处理冲突而消耗的时间。 现在我们已经对散列表，散列函数等知识有所了解啦，那么我们来看几种常用的散列函数构造方法。这些方法的共同点为都是将原来的数字按某种规律变成了另一个数字。所以是很容易理解的。 散列函数构造方法直接定址法如果我们对盈利为0-9的菜品设计哈希表，我们则直接可以根据作为地址，则 f(key) &#x3D; key; 即下面这种情况。 有没有感觉上面的图很熟悉，没错我们经常用的数组其实就是一张哈希表，关键码就是数组的索引下标，然后我们通过下标直接访问数组中的元素。 另外我们假设每道菜的成本为50块，那我们还可以根据盈利+成本来作为地址，那么则 f(key) &#x3D; key + 50。也就是说我们可以根据线性函数值作为散列地址。 f(key) &#x3D; a * key + b a,b均为常数 优点：简单、均匀、无冲突。 应用场景：需要事先知道关键字的分布情况，适合查找表较小且连续的情况 数字分析法该方法也是十分简单的方法，就是分析我们的关键字，取其中一段，或对其位移，叠加，用作地址。比如我们的学号，前 6 位都是一样的，但是后面 3 位都不相同，我们则可以用学号作为键，后面的 3 位做为我们的散列地址。如果我们这样还是容易产生冲突，则可以对抽取数字再进行处理。我们的目的只有一个，提供一个散列函数将关键字合理的分配到散列表的各位置。这里我们提到了一种新的方式抽取，这也是在散列函数中经常用到的手段。 优点：简单、均匀、适用于关键字位数较大的情况 应用场景：关键字位数较大，知道关键字分布情况且关键字的若干位较均匀 折叠法其实这个方法也很简单，也是处理我们的关键字然后用作我们的散列地址，主要思路是将关键字从左到右分割成位数相等的几部分，然后叠加求和，并按散列表表长，取后几位作为散列地址。 比如我们的关键字是123456789，则我们分为三部分 123 ，456 ，789 然后将其相加得 1368 然后我们再取其后三位 368 作为我们的散列地址。 优点：事先不需要知道关键字情况 应用场景：适合关键字位数较多的情况 除法散列法在用来设计散列函数的除法散列法中，通过取 key 除以 p 的余数，将关键字映射到 p 个槽中的某一个上，对于散列表长度为 m 的散列函数公式为 f(k) &#x3D; k mod p (p &lt;&#x3D; m) 例如，如果散列表长度为 12，即 m &#x3D; 12 ，我们的参数 p 也设为12，那 k &#x3D; 100时 f(k) &#x3D; 100 % 12 &#x3D; 4 由于只需要做一次除法操作，所以除法散列法是非常快的。 由上面的公式可以看出，该方法的重点在于 p 的取值，如果 p 值选的不好，就可能会容易产生同义词。见下面这种情况。我们哈希表长度为6，我们选择6为p值，则有可能产生这种情况，所有关键字都得到了0这个地址数。 那我们在选用除法散列法时选取 p 值时应该遵循怎样的规则呢？ m 不应为 2 的幂，因为如果 m &#x3D; 2^p ，则 f(k) 就是 k 的 p 个最低位数字。例 12 % 8 &#x3D; 4 ，12的二进制表示位1100，后三位为100。 若散列表长为 m ,通常 p 为 小于或等于表长（最好接近m）的最小质数或不包含小于 20 质因子的合数。 合数：合数是指在大于1的整数中除了能被1和本身整除外，还能被其他数（0除外）整除的数。 质因子：质因子（或质因数）在数论里是指能整除给定正整数的质数。 注：这里的2，3，5为质因子 还是上面的例子，我们根据规则选择 5 为 p 值，我们再来看。这时我们发现只有 6 和 36 冲突，相对来说就好了很多。 优点：计算效率高，灵活 应用场景：不知道关键字分布情况 乘法散列法构造散列函数的乘法散列法主要包含两个步骤 用关键字 k 乘上常数 A(0 &lt; A &lt; 1)，并提取 k A 的小数部分 用 m 乘以这个值，再向下取整 散列函数为 f (k) &#x3D; ⌊ m(kA mod 1) ⌋ 这里的 kA mod 1 的含义是取 keyA 的小数部分，即 kA - ⌊kA⌋ 。 优点：对 m 的选择不是特别关键一般选择它为 2 的某个幂次（m &#x3D; 2 ^ p ,p为某个整数） 应用场景：不知道关键字情况 平方取中法这个方法就比较简单了，假设关键字是 321，那么他的平方就是 103041，再抽取中间的 3 位就是 030 或 304 用作散列地址。再比如关键字是 1234 那么它的平方就是 1522756 ，抽取中间 3 位就是 227 用作散列地址. 优点：灵活，适用范围广泛 适用场景：不知道关键字分布，而位数又不是很大的情况。 随机数法故名思意，取关键字的随机函数值为它的散列地址。也就是 **f(key) &#x3D; random(key)**。这里的random是随机函数。（具体解析见随机探测法） 适用场景：关键字的长度不等时 上面我们的例子都是通过数字进行举例，那么如果是字符串可不可以作为键呢？当然也是可以的，各种各样的符号我们都可以转换成某种数字来对待，比如我们经常接触的ASCII 码，所以是同样适用的。 以上就是常用的散列函数构造方法，其实他们的中心思想是一致的，将关键字经过加工处理之后变成另外一个数字，而这个数字就是我们的存储位置，是不是有一种间谍传递情报的感觉。 一个好的哈希函数可以帮助我们尽可能少的产生冲突，但是也不能完全避免产生冲突，那么遇到冲突时应该怎么做呢？下面给大家带来几种常用的处理散列冲突的方法。 处理散列冲突的方法我们在使用 hash 函数之后发现关键字 key1 不等于 key2 ，但是 f(key1) &#x3D; f(key2)，即有冲突，那么该怎么办呢？不急我们慢慢往下看。 开放地址法了解开放地址法之前我们先设想以下场景。 袁记菜馆内，铃铃铃，铃铃铃 电话铃响了 大鹏：老袁，给我订个包间，我今天要去带几个客户去你那谈生意。 袁厨：大鹏啊，你常用的那个包间被人订走啦。 大鹏：老袁你这不仗义呀，咋没给我留住呀，那你给我找个空房间吧。 袁厨：好滴老哥 哦，穿越回古代就没有电话啦，那看来穿越的时候得带着几个手机了。 上面的场景其实就是一种处理冲突的方法—–开放地址法 开放地址法就是一旦发生冲突，就去寻找下一个空的散列地址，只要列表足够大，空的散列地址总能找到，并将记录存入，为了使用开放寻址法插入一个元素，需要连续地检查散列表，或称为探查，我们常用的有线性探测，二次探测，随机探测。 线性探测法下面我们先来看一下线性探测，公式： 我们来看一个例子，我们的关键字集合为{12，67，56，16，25，37，22，29，15，47，48，21}，表长为12，我们再用散列函数 f(key) &#x3D; key mod 12。 我们求出每个 key 的 f(key)见下表 我们查看上表发现，前五位的 f(key) 都不相同，即没有冲突，可以直接存入，但是到了第六位 f(37) &#x3D; f(25) &#x3D; 1,那我们就需要利用上面的公式 f(37) &#x3D; f (f(37) + 1 ) mod 12 &#x3D; 2，这其实就是我们的订包间的做法。下面我们看一下将上面的所有数存入哈希表是什么情况吧。 注：蓝色为计算哈希值，红色为存入哈希表 我们把这种解决冲突的开放地址法称为线性探测法。下面我们通过视频来模拟一下线性探测法的存储过程。 &lt;video id&#x3D;”video” controls&#x3D;””src&#x3D;”http://mpvideo.qpic.cn/0bf23udbgaagw4aa2n5tqrpvnxodcpoqmeya.f10002.mp4?dis_k=7098b34ae4d0d564f208a7d543987175&amp;dis_t=1609338638&amp;spec_id=MzU4MDUyMDQyNQ%3D%3D1609338634&amp;vid=wxv_1612509429344567297&amp;format_id=10002“ preload&#x3D;”none”&gt; 另外我们在解决冲突的时候，会遇到 48 和 37 虽然不是同义词，却争夺一个地址的情况，我们称其为堆积。因为堆积使得我们需要不断的处理冲突，插入和查找效率都会大大降低。 通过上面的视频我们应该了解了线性探测的执行过程了，那么我们考虑一下这种情况，若是我们的最后一位不为21，为 34 时会有什么事情发生呢？ 此时他第一次会落在下标为 10 的位置，那么如果继续使用线性探测的话，则需要通过不断取余后得到结果，数据量小还好，要是很大的话那也太慢了吧，但是明明他的前面就有一个空房间呀，如果向前移动只需移动一次即可。不要着急，前辈们已经帮我们想好了解决方法 二次探测法其实理解了我们的上个例子之后，这个一下就能整明白了，根本不用费脑子，这个方法就是更改了一下di的取值 注：这里的是 -1^2 为负值 而不是 （-1)^2 所以对于我们的34来说，当di &#x3D; -1时，就可以找到空位置了。 二次探测法的目的就是为了不让关键字聚集在某一块区域。另外还有一种有趣的方法，位移量采用随机函数计算得到，接着往下看吧. 随机探测法大家看到这是不又有新问题了，刚才我们在散列函数构造规则的第一条中说 （1）必须是一致的，假设你输入辣子鸡丁时得到的是在看，那么每次输入辣子鸡丁时，得到的也必须为在看。如果不是这样，散列表将毫无用处。 咦？怎么又是在看哈哈，那么问题来了，我们使用随机数作为他的偏移量，那么我们查找的时候岂不是查不到了？因为我们 di 是随机生成的呀，这里的随机其实是伪随机数，伪随机数含义为，我们设置随机种子相同，则不断调用随机函数可以生成不会重复的数列，我们在查找时，用同样的随机种子，它每次得到的数列是相同的，那么相同的 di 就能得到相同的散列地址。 随机种子（Random Seed）是计算机专业术语，一种以随机数作为对象的以真随机数（种子）为初始条件的随机数。一般计算机的随机数都是伪随机数，以一个真随机数（种子）作为初始条件，然后用一定的算法不停迭代产生随机数 通过上面的测试是不是一下就秒懂啦，使用相同的随机种子，生成的数列是相同的。所以为什么我们可以使用随机数作为它的偏移量。 下面我们再来看一下其他的函数处理散列冲突的方法 再哈希法这个方法其实也特别简单，利用不同的哈希函数再求得一个哈希地址，直到不出现冲突为止。 f,(key) &#x3D; RH,( key ) (i &#x3D; 1,2,3,4…..k) 这里的RH,就是不同的散列函数，你可以把我们之前说过的那些散列函数都用上，每当发生冲突时就换一个散列函数，相信总有一个能够解决冲突的。这种方法能使关键字不产生聚集，但是代价就是增加了计算时间。是不是很简单啊。 链地址法下面我们再设想以下情景。 袁记菜馆内，铃铃铃，铃铃铃电话铃又响了，那个大鹏又来订房间了。 大鹏：老袁啊，我一会去你那吃个饭，还是上回那个包间 袁厨：大鹏你下回能不能早点说啊，又没人订走了，这回是老王订的 大鹏：老王这个老东西啊，反正也是熟人，你再给我整个桌子，我拼在他后面吧 不好意思啊各位同学，信鸽最近太贵了还没来得及买。上面的情景就是模拟我们的新的处理冲突的方法链地址法。 上面我们都是遇到冲突之后，就换地方。那么我们有没有不换地方的办法呢？那就是我们现在说的链地址法。 还记得我们说过的同义词吗？就是 key 不同 f(key) 相同的情况，我们将这些同义词存储在一个单链表中，这种表叫做同义词子表，散列表中只存储同义词子表的头指针。我们还是用刚才的例子，关键字集合为{12，67，56，16，25，37，22，29，15，47，48，21}，表长为12，我们再用散列函数 f(key) &#x3D; key mod 12。我们用了链地址法之后就再也不存在冲突了，无论有多少冲突，我们只需在同义词子表中添加结点即可。下面我们看下链地址法的存储情况。 链地址法虽然能够不产生冲突，但是也带来了查找时需要遍历单链表的性能消耗，有得必有失嘛。 公共溢出区法下面我们再来看一种新的方法，这回大鹏又要来吃饭了。 袁记菜馆内….. 袁厨：呦，这是什么风把你给刮来了，咋没开你的大奔啊。 大鹏：哎呀妈呀，别那么多废话了，我快饿死了，你快给我找个位置，我要吃点饭。 袁厨：你来的，太不巧了，咱们的店已经满了，你先去旁边的小屋看会电视，等有空了我再叫你。小屋里面还有几个和你一样来晚的，你们一起看吧。 大鹏：电视？看电视？ 上面的情景就是模拟我们的公共溢出区法，这也是很好理解的，你不是冲突吗？那冲突的各位我先给你安排个地方呆着，这样你就有地方住了。我们为所有冲突的关键字建立了一个公共的溢出区来存放。 那么我们怎么进行查找呢？我们首先通过散列函数计算出散列地址后，先于基本表对比，如果不相等再到溢出表去顺序查找。这种解决冲突的方法，对于冲突很少的情况性能还是非常高的。 散列表查找算法(线性探测法)下面我们来看一下散列表查找算法的实现 首先需要定义散列列表的结构以及一些相关常数，其中elem代表散列表数据存储数组，count代表的是当前插入元素个数，size代表哈希表容量，NULLKEY散列表初始值，然后我们如果查找成功就返回索引，如果不存在该元素就返回元素不存在。 我们将哈希表初始化，为数组元素赋初值。 插入操作的具体步骤： （1）通过哈希函数(除法散列法)，将key转化为数组下标 （2）如果该下标中没有元素，则插入，否则说明有冲突，则利用线性探测法处理冲突。详细步骤见注释 查找操作的具体步骤： （1）通过哈希函数（同插入时一样），将key转化成数组下标 （2）通过数组下标找到key值，如果key一致，则查找成功，否则利用线性探测法继续查找。 下面我们来看一下完整代码 散列表性能分析如果没有冲突的话，散列查找是我们查找中效率最高的，时间复杂度为O(1),但是没有冲突的情况是一种理想情况，那么散列查找的平均查找长度取决于哪些方面呢？ 1.散列函数是否均匀我们在上文说到，可以通过设计散列函数减少冲突，但是由于不同的散列函数对一组关键字产生冲突可能性是相同的，因此我们可以不考虑它对平均查找长度的影响。 2.处理冲突的方法相同关键字，相同散列函数，不同处理冲突方式，会使平均查找长度不同，比如我们线性探测有时会堆积，则不如二次探测法好，因为链地址法处理冲突时不会产生任何堆积，因而具有最佳的平均查找性能 3.散列表的装填因子本来想在上文中提到装填因子的，但是后来发现即使没有说明也不影响我们对哈希表的理解，下面我们来看一下装填因子的总结 装填因子 α &#x3D; 填入表中的记录数 &#x2F; 散列表长度 散列因子则代表着散列表的装满程度，表中记录越多，α就越大，产生冲突的概率就越大。我们上面提到的例子中 表的长度为12，填入记录数为6，那么此时的 α &#x3D; 6 &#x2F; 12 &#x3D; 0.5 所以说当我们的 α 比较大时再填入元素那么产生冲突的可能性就非常大了。所以说散列表的平均查找长度取决于装填因子，而不是取决于记录数。所以说我们需要做的就是选择一个合适的装填因子以便将平均查找长度限定在一个范围之内。","tags":["算法","数据结构","哈希表"],"categories":["算法","数据结构"]},{"title":"SQL优化最干货总结","path":"/2023/12/25/SQL优化最干货总结/","content":"前言BATJTMD等大厂的面试难度越来越高，但无论从大厂还是到小公司，一直未变的一个重点就是对SQL优化经验的考察。一提到数据库，先“说一说你对SQL优化的见解吧？”。 SQL优化已经成为衡量程序猿优秀与否的硬性指标，甚至在各大厂招聘岗位职能上都有明码标注，如果是你，在这个问题上能吊打面试官还是会被吊打呢？ 目录 前言 SELECT语句 - 语法顺序： SELECT语句 - 执行顺序： SQL优化策略 一、避免不走索引的场景 二、SELECT语句其他优化 三、增删改 DML 语句优化 四、查询条件优化 五、建表优化 有朋友疑问到，SQL优化真的有这么重要么？如下图所示，SQL优化在提升系统性能中是：（成本最低 &amp;&amp; 优化效果最明显） 的途径。如果你的团队在SQL优化这方面搞得很优秀，对你们整个大型系统可用性方面无疑是一个质的跨越，真的能让你们老板省下不止几沓子钱。 优化成本：硬件&gt;系统配置&gt;数据库表结构&gt;SQL及索引。 优化效果：硬件&lt;系统配置&lt;数据库表结构&lt;SQL及索引。 123456789101112131415String result = &quot;嗯，不错，&quot;; if (&quot;SQL优化经验足&quot;) &#123; if (&quot;熟悉事务锁&quot;) &#123; if (&quot;并发场景处理666&quot;) &#123; if (&quot;会打王者荣耀&quot;) &#123; result += &quot;明天入职&quot; &#125; &#125; &#125;&#125; else &#123; result += &quot;先回去等消息吧&quot;;&#125; Logger.info(&quot;面试官：&quot; + result ); 别看了，上面这是一道送命题。 好了我们言归正传，首先，对于MySQL层优化我一般遵从五个原则： 减少数据访问：设置合理的字段类型，启用压缩，通过索引访问等减少磁盘IO 返回更少的数据：只返回需要的字段和数据分页处理 减少磁盘io及网络io 减少交互次数：批量DML操作，函数存储等减少数据连接次数 减少服务器CPU开销：尽量减少数据库排序操作以及全表查询，减少cpu 内存占用 利用更多资源：使用表分区，可以增加并行操作，更大限度利用cpu资源 总结到SQL优化中，就三点: 最大化利用索引； 尽可能避免全表扫描； 减少无效数据的查询； 理解SQL优化原理 ，首先要搞清楚SQL执行顺序： SELECT语句 - 语法顺序：123456789101. SELECT 2. DISTINCT &lt;select_list&gt;3. FROM &lt;left_table&gt;4. &lt;join_type&gt; JOIN &lt;right_table&gt;5. ON &lt;join_condition&gt;6. WHERE &lt;where_condition&gt;7. GROUP BY &lt;group_by_list&gt;8. HAVING &lt;having_condition&gt;9. ORDER BY &lt;order_by_condition&gt;10.LIMIT &lt;limit_number&gt; SELECT语句 - 执行顺序： FROM&lt;表名&gt; # 选取表，将多个表数据通过笛卡尔积变成一个表。ON&lt;筛选条件&gt; # 对笛卡尔积的虚表进行筛选JOIN &lt;join, left join, right join…&gt;&lt;join表&gt; # 指定join，用于添加数据到on之后的虚表中，例如left join会将左表的剩余数据添加到虚表中WHERE&lt;where条件&gt; # 对上述虚表进行筛选GROUP BY&lt;分组条件&gt; # 分组&lt;SUM()等聚合函数&gt; # 用于having子句进行判断，在书写上这类聚合函数是写在having判断里面的HAVING&lt;分组筛选&gt; # 对分组后的结果进行聚合筛选SELECT&lt;返回数据列表&gt; # 返回的单列必须在group by子句中，聚合函数除外DISTINCT# 数据除重ORDER BY&lt;排序条件&gt; # 排序LIMIT&lt;行数限制&gt; SQL优化策略 声明：以下SQL优化策略适用于数据量较大的场景下，如果数据量较小，没必要以此为准，以免画蛇添足。 一、避免不走索引的场景1. 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描。如下： 1SELECT * FROM t WHERE username LIKE &#x27;%陈%&#x27; 优化方式：尽量在字段后面使用模糊查询。如下： 1SELECT * FROM t WHERE username LIKE &#x27;陈%&#x27; 如果需求是要在前面使用模糊查询， 使用MySQL内置函数INSTR(str,substr) 来匹配，作用类似于java中的indexOf()，查询字符串出现的角标位置 使用FullText全文索引，用match against 检索 数据量较大的情况，建议引用ElasticSearch、solr，亿级数据量检索速度秒级 当表数据量较少（几千条儿那种），别整花里胡哨的，直接用like ‘%xx%’。 2. 尽量避免使用in 和not in，会导致引擎走全表扫描。如下： 1SELECT * FROM t WHERE id IN (2,3) 优化方式：如果是连续数值，可以用between代替。如下： 1SELECT * FROM t WHERE id BETWEEN 2 AND 3 如果是子查询，可以用exists代替。如下： 1234-- 不走索引select * from A where A.id in (select id from B);-- 走索引select * from A where exists (select * from B where B.id = A.id); 3. 尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描。如下： 1SELECT * FROM t WHERE id = 1 OR id = 3 优化方式：可以用union代替or。如下： 123SELECT * FROM t WHERE id = 1 UNIONSELECT * FROM t WHERE id = 3 4. 尽量避免进行null值的判断，会导致数据库引擎放弃索引进行全表扫描。如下： 1SELECT * FROM t WHERE score IS NULL 优化方式：可以给字段添加默认值0，对0值进行判断。如下： 1SELECT * FROM t WHERE score = 0 5.尽量避免在where条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描。可以将表达式、函数操作移动到等号右侧。如下： 1234-- 全表扫描SELECT * FROM T WHERE score/10 = 9-- 走索引SELECT * FROM T WHERE score = 10*9 6. 当数据量大时，避免使用where 1&#x3D;1的条件。通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描。如下： 1SELECT username, age, sex FROM T WHERE 1=1 优化方式：用代码拼装sql时进行判断，没 where 条件就去掉 where，有where条件就加 and。 7. 查询条件不能用 &lt;&gt; 或者 !&#x3D;使用索引列作为条件进行查询时，需要避免使用&lt;&gt;或者!&#x3D;等判断条件。如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替。 8. where条件仅包含复合索引非前置列如下：复合（联合）索引包含key_part1，key_part2，key_part3三列，但SQL语句没有包含索引前置列”key_part1”，按照MySQL联合索引的最左匹配原则，不会走联合索引。 1select col1 from table where key_part2=1 and key_part3=2 9. 隐式类型转换造成不使用索引如下SQL语句由于索引对列类型为varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引。 1select col1 from table where col_varchar=123; 10. order by 条件要与where中条件一致，否则order by不会利用索引进行排序12345-- 不走age索引SELECT * FROM t order by age; -- 走age索引SELECT * FROM t where age &gt; 0 order by age; 对于上面的语句，数据库的处理顺序是： 第一步：根据where条件和统计信息生成执行计划，得到数据。 第二步：将得到的数据排序。当执行处理数据（order by）时，数据库会先查看第一步的执行计划，看order by 的字段是否在执行计划中利用了索引。如果是，则可以利用索引顺序而直接取得已经排好序的数据。如果不是，则重新进行排序操作。 第三步：返回排序后的数据。 当order by 中的字段出现在where条件中时，才会利用索引而不再二次排序，更准确的说，order by 中的字段在执行计划中利用了索引时，不用排序操作。 这个结论不仅对order by有效，对其他需要排序的操作也有效。比如group by 、union 、distinct等。 11. 正确使用hint优化语句MySQL中可以使用hint指定优化器在执行时选择或忽略特定的索引。一般而言，处于版本变更带来的表结构索引变化，更建议避免使用hint，而是通过Analyze table多收集统计信息。但在特定场合下，指定hint可以排除其他索引干扰而指定更优的执行计划。 USE INDEX 在你查询语句中表名的后面，添加 USE INDEX 来提供希望 MySQL 去参考的索引列表，就可以让 MySQL 不再考虑其他可用的索引。例子: SELECT col1 FROM table USE INDEX (mod_time, name)… IGNORE INDEX 如果只是单纯的想让 MySQL 忽略一个或者多个索引，可以使用 IGNORE INDEX 作为 Hint。例子: SELECT col1 FROM table IGNORE INDEX (priority) … FORCE INDEX 为强制 MySQL 使用一个特定的索引，可在查询中使用FORCE INDEX 作为Hint。例子: SELECT col1 FROM table FORCE INDEX (mod_time) … 在查询的时候，数据库系统会自动分析查询语句，并选择一个最合适的索引。但是很多时候，数据库系统的查询优化器并不一定总是能使用最优索引。如果我们知道如何选择索引，可以使用FORCE INDEX强制查询使用指定的索引。 例如： 1SELECT * FROM students FORCE INDEX (idx_class_id) WHERE class_id = 1 ORDER BY id DESC; 二、SELECT语句其他优化**1. 避免出现select **首先，select * 操作在任何类型数据库中都不是一个好的SQL编写习惯。 使用select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的I&#x2F;O,内存和CPU消耗。 建议提出业务实际需要的列数，将指定列名以取代select *。 2. 避免出现不确定结果的函数特定针对主从复制这类业务场景。由于原理上从库复制的是主库执行的语句，使用如now()、rand()、sysdate()、current_user()等不确定结果的函数很容易导致主库与从库相应的数据不一致。另外不确定值的函数,产生的SQL语句无法利用query cache。 3.多表关联查询时，小表在前，大表在后。在MySQL中，执行 from 后的表关联查询是从左往右执行的（Oracle相反），第一张表会涉及到全表扫描，所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前100行就符合返回条件并return了。 例如：表1有50条数据，表2有30亿条数据；如果全表扫描表2，你品，那就先去吃个饭再说吧是吧。 4. 使用表的别名当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。 5. 用where字句替换HAVING字句避免使用HAVING字句，因为HAVING只会在检索出所有记录之后才对结果集进行过滤，而where则是在聚合前刷选记录，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在where字句中。 where和having的区别：where后面不能使用组函数 6.调整Where字句中的连接顺序MySQL采用从左往右，自上而下的顺序解析where子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集。 三、增删改 DML 语句优化1. 大批量插入数据如果同时执行大量的插入，建议使用多个值的INSERT语句(方法二)。这比使用分开INSERT语句快（方法一），一般情况下批量插入效率有几倍的差别。 方法一： 12345insert into T values(1,2); insert into T values(1,3); insert into T values(1,4); 方法二： 1Insert into T values(1,2),(1,3),(1,4); 选择后一种方法的原因有三。 减少SQL语句解析的操作，MySQL没有类似Oracle的share pool，采用方法二，只需要解析一次就能进行数据的插入操作； 在特定场景可以减少对DB连接次数 SQL语句较短，可以减少网络传输的IO。 2. 适当使用commit适当使用commit可以释放事务占用的资源而减少消耗，commit后能释放的资源如下： 事务占用的undo数据块； 事务在redo log中记录的数据块； 释放事务施加的，减少锁争用影响性能。特别是在需要使用delete删除大量数据的时候，必须分解删除量并定期commit。 3. 避免重复查询更新的数据针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL并不支持PostgreSQL那样的UPDATE RETURNING语法，在MySQL中可以通过变量实现。 例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么，简单方法实现： 123Update t1 set time=now() where col1=1; Select time from t1 where id =1; 使用变量，可以重写为以下方式： 123Update t1 set time=now () where col1=1 and @now: = now (); Select @now; 前后二者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当t1表数据量较大时，后者比前者快很多。 4.查询优先还是更新（insert、update、delete）优先MySQL 还允许改变语句调度的优先级，它可以使来自多个客户端的查询更好地协作，这样单个客户端就不会由于锁定而等待很长时间。改变优先级还可以确保特定类型的查询被处理得更快。我们首先应该确定应用的类型，判断应用是以查询为主还是以更新为主的，是确保查询效率还是确保更新的效率，决定是查询优先还是更新优先。 下面我们提到的改变调度策略的方法主要是针对只存在表锁的存储引擎，比如 MyISAM 、MEMROY、MERGE，对于Innodb 存储引擎，语句的执行是由获得行锁的顺序决定的。MySQL 的默认的调度策略可用总结如下： 1）写入操作优先于读取操作。 2）对某张数据表的写入操作某一时刻只能发生一次，写入请求按照它们到达的次序来处理。 3）对某张数据表的多个读取操作可以同时地进行。MySQL 提供了几个语句调节符，允许你修改它的调度策略： LOW_PRIORITY关键字应用于DELETE、INSERT、LOAD DATA、REPLACE和UPDATE； HIGH_PRIORITY关键字应用于SELECT和INSERT语句； DELAYED关键字应用于INSERT和REPLACE语句。 如果写入操作是一个 LOW_PRIORITY（低优先级）请求，那么系统就不会认为它的优先级高于读取操作。在这种情况下，如果写入者在等待的时候，第二个读取者到达了，那么就允许第二个读取者插到写入者之前。只有在没有其它的读取者的时候，才允许写入者开始操作。这种调度修改可能存在 LOW_PRIORITY写入操作永远被阻塞的情况。 SELECT 查询的HIGH_PRIORITY（高优先级）关键字也类似。它允许SELECT 插入正在等待的写入操作之前，即使在正常情况下写入操作的优先级更高。另外一种影响是，高优先级的 SELECT 在正常的 SELECT 语句之前执行，因为这些语句会被写入操作阻塞。如果希望所有支持LOW_PRIORITY 选项的语句都默认地按照低优先级来处理，那么 请使用–low-priority-updates 选项来启动服务器。通过使用 INSERTHIGH_PRIORITY 来把 INSERT 语句提高到正常的写入优先级，可以消除该选项对单个INSERT语句的影响。 四、查询条件优化1. 对于复杂的查询，可以使用中间临时表 暂存数据2. 优化group by语句默认情况下，MySQL 会对GROUP BY分组的所有值进行排序，如 “GROUP BY col1，col2，….;” 查询的方法如同在查询中指定 “ORDER BY col1，col2，…;” 如果显式包括一个包含相同的列的 ORDER BY子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。 因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL禁止排序。例如： 1SELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ; 3. 优化join语句MySQL中可以通过子查询来使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接(JOIN)..替代。 例子：假设要将所有没有订单记录的用户取出来，可以用下面这个查询完成： 1SELECT col1 FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo ) 如果使用连接(JOIN).. 来完成这个查询工作，速度将会有所提升。尤其是当 salesinfo表中对 CustomerID 建有索引的话，性能将会更好，查询如下： 123SELECT col1 FROM customerinfo LEFT JOIN salesinfoON customerinfo.CustomerID=salesinfo.CustomerID WHERE salesinfo.CustomerID IS NULL 连接(JOIN).. 之所以更有效率一些，是因为 MySQL 不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。 4. 优化union查询MySQL通过创建并填充临时表的方式来执行union查询。除非确实要消除重复的行，否则建议使用union all。原因在于如果没有all这个关键词，MySQL会给临时表加上distinct选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高。 高效： 12345SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION ALL SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= &#x27;TEST&#x27;; 低效： 12345SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= &#x27;TEST&#x27;; 5.拆分复杂SQL为多个小SQL，避免大事务 简单的SQL容易使用到MySQL的QUERY CACHE； 减少锁表时间特别是使用MyISAM存储引擎的表； 可以使用多核CPU。 6. 使用truncate代替delete当删除全表中记录时，使用delete语句的操作会被记录到undo块中，删除记录也记录binlog，当确认需要删除全表时，会产生很大量的binlog并占用大量的undo数据块，此时既没有很好的效率也占用了大量的资源。 使用truncate替代，不会记录可恢复的信息，数据不能被恢复。也因此使用truncate操作有其极少的资源占用与极快的时间。另外，使用truncate可以回收表的水位，使自增字段值归零。 7. 使用合理的分页方式以提高分页效率使用合理的分页方式以提高分页效率 针对展现等分页需求，合适的分页方式能够提高分页的效率。 案例1： 12select * from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15; 上述例子通过一次性根据过滤条件取出所有字段进行排序返回。数据访问开销&#x3D;索引IO+索引全部记录结果对应的表数据IO。因此，该种写法越翻到后面执行效率越差，时间越长，尤其表数据量很大的时候。 适用场景：当中间结果集很小（10000行以下）或者查询条件复杂（指涉及多个不同查询字段或者多表连接）时适用。 案例2： 123select t.* from (select id from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15) a, t where a.id = t.id; 上述例子必须满足t表主键是id列，且有覆盖索引secondary key:(thread_id, deleted, gmt_create)。通过先根据过滤条件利用覆盖索引取出主键id进行排序，再进行join操作取出其他字段。数据访问开销&#x3D;索引IO+索引分页后结果（例子中是15行）对应的表数据IO。因此，该写法每次翻页消耗的资源和时间都基本相同，就像翻第一页一样。 适用场景：当查询和排序字段（即where子句和order by子句涉及的字段）有对应覆盖索引时，且中间结果集很大的情况时适用。 五、建表优化1. 在表中建立索引，优先考虑where、order by使用到的字段。2. 尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。 这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 3. 查询数据量大的表 会造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段分页进行查询，循环遍历，将结果合并处理进行展示。要查询100000到100050的数据，如下： 12SELECT * FROM (SELECT ROW_NUMBER() OVER(ORDER BY ID ASC) AS rowid,* FROM infoTab)t WHERE t.rowid &gt; 100000 AND t.rowid &lt;= 100050 4. 用varchar&#x2F;nvarchar 代替 char&#x2F;nchar尽可能的使用 varchar&#x2F;nvarchar 代替 char&#x2F;nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。","tags":["MySQL","DataBase","SQL优化"],"categories":["DataBase"]},{"title":"TCP/IP简述","path":"/2023/12/25/TCP-IP简述/","content":"一、TCP&#x2F;IP模型TCP&#x2F;IP协议模型（Transmission Control Protocol&#x2F;Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。 基于TCP&#x2F;IP的参考模型将协议分成四个层次，它们分别是链路层、网络层、传输层和应用层。下图表示TCP&#x2F;IP模型与OSI模型各层的对照关系。 TCP&#x2F;IP协议族按照层次由上到下，层层包装。最上面的是应用层，这里面有http，ftp 等等我们熟悉的协议。而第二层则是传输层，著名的TCP和UDP协议就在这个层次。第三层是网络层，IP协议就在这里，它负责对数据加上IP地址和其他的数据以确定传输的目标。第四层是数据链路层，这个层次为待传送的数据加入一个以太网协议头，并进行CRC编码，为最后的数据传输做准备。 上图清楚地表示了TCP&#x2F;IP协议中每个层的作用，而TCP&#x2F;IP协议通信的过程其实就对应着数据入栈与出栈的过程。入栈的过程，数据发送方每层不断地封装首部与尾部，添加一些传输的信息，确保能传输到目的地。出栈的过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。 上图以HTTP协议为例，具体说明。 二、数据链路层物理层负责0、1比特流与物理设备电压高低、光的闪灭之间的互换。数据链路层负责将0、1序列划分为数据帧从一个节点传输到临近的另一个节点,这些节点是通过MAC来唯一标识的(MAC,物理地址，一个主机会有一个MAC地址)。 封装成帧: 把网络层数据报加头和尾，封装成帧,帧头中包括源MAC地址和目的MAC地址。 透明传输: 零比特填充、转义字符。 可靠传输: 在出错率很低的链路上很少用，但是无线链路WLAN会保证可靠传输。 差错检测(CRC): 接收者检测错误,如果发现差错，丢弃该帧。 三、网络层1、IP协议IP协议是TCP&#x2F;IP协议的核心，所有的TCP，UDP，IMCP，IGMP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP或UDP要做的事情。 1.1 IP地址在数据链路层中我们一般通过MAC地址来识别不同的节点，而在IP层我们也要有一个类似的地址标识，这就是IP地址。 32位IP地址分为网络位和地址位，这样做可以减少路由器中路由表记录的数目，有了网络地址，就可以限定拥有相同网络地址的终端都在同一个范围内，那么路由表只需要维护一条这个网络地址的方向，就可以找到相应的这些终端了。 A类IP地址: 0.0.0.0127.0.0.0B类IP地址:128.0.0.1191.255.0.0C类IP地址:192.168.0.0~239.255.255.0 1.2 IP协议头 这里只介绍:八位的TTL字段。这个字段规定该数据包在穿过多少个路由之后才会被抛弃。某个IP数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃。 这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64。 2、ARP及RARP协议ARP 是根据IP地址获取MAC地址的一种协议。 ARP（地址解析）协议是一种解析协议，本来主机是完全不知道这个IP对应的是哪个主机的哪个接口，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存）。 如果查询的IP－MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机。 而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。 RARP协议的工作与此相反，不做赘述。 3、ICMP协议IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。 当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这也就是为什么说建立在IP层以上的协议是可能做到安全的原因。 四、pingping可以说是ICMP的最著名的应用，是TCP&#x2F;IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。 例如：当我们某一个网站上不去的时候。通常会ping一下这个网站。ping会回显出一些有用的信息。一般的信息如下: ping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请求，受到请求的主机则用类型码为8的ICMP回应。 五、TracerouteTraceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。 Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL&#x3D;1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL&#x3D;2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。 六、TCP&#x2F;UDPTCP&#x2F;UDP都是是传输层协议，但是两者具有不同的特性，同时也具有不同的应用场景，下面以图表的形式对比分析。 面向报文 面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。 面向字节流 面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。 关于拥塞控制，流量控制，是TCP的重点，后面讲解。 TCP和UDP协议的一些应用 什么时候应该使用TCP？ 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 什么时候应该使用UDP？ 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 七、DNSDNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。 八、TCP连接的建立与终止1、三次握手TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP&#x2F;IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP窗口大小信息。 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认； 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 为什么要三次握手？ 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。 于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 2、四次挥手当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。 第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了； 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求； 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态； 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 为什么要四次分手？ TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。 为什么要等待2MSL？ MSL：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。原因有二： 保证TCP协议的全双工连接能够可靠关闭 保证这次连接的重复数据段从网络中消失 第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。 第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。 九、TCP流量控制如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。 利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。 设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd &#x3D; 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。 从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd &#x3D; 300 ，第二次又减到了 rwnd &#x3D; 100 ，最后减到 rwnd &#x3D; 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK &#x3D; 1 ，只有在ACK&#x3D;1时确认号字段才有意义。 TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。 十、TCP拥塞控制发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。 发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始算法： 当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。 通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。 每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd&#x3D;1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd &#x3D; ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。拥塞避免 拥塞避免 让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。 这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。 如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。 2、快重传和快恢复快重传快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。 接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。 显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。 但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。 快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。 由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 快恢复与快重传配合使用的还有快恢复算法，其过程有以下两个要点： 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。 与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。","tags":["计算机网络","TCP/IP"],"categories":["计算机网络"]},{"title":"Java 泛型 T，E，K，V，?，傻傻分不清？","path":"/2023/12/24/Java-泛型-T，E，K，V，-，傻傻分不清？/","content":"前言Java 泛型（generics）是 JDK 5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许开发者在编译时检测到非法的类型。 泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。 泛型带来的好处在没有泛型的情况的下，通过对类型 Object 的引用来实现参数的“任意化”，“任意化”带来的缺点是要做显式的强制类型转换，而这种转换是要求开发者对实际参数类型可以预知的情况下进行的。对于强制类型转换错误的情况，编译器可能不提示错误，在运行的时候才出现异常，这是本身就是一个安全隐患。 那么泛型的好处就是在编译的时候能够检查类型安全，并且所有的强制转换都是自动和隐式的。 12345678910111213141516171819202122232425262728293031323334353637public class GlmapperGeneric&lt;T&gt; &#123; private T t; public void set(T t) &#123; this.t = t; &#125; public T get() &#123; return t; &#125; public static void main(String[] args) &#123; // do nothing &#125; /** * 不指定类型 */ public void noSpecifyType() &#123; GlmapperGeneric glmapperGeneric = new GlmapperGeneric(); glmapperGeneric.set(&quot;test&quot;); // 需要强制类型转换 String test = (String) glmapperGeneric.get(); System.out.println(test); &#125; /** * 指定类型 */ public void specifyType() &#123; GlmapperGeneric&lt;String&gt; glmapperGeneric = new GlmapperGeneric(); glmapperGeneric.set(&quot;test&quot;); // 不需要强制类型转换 String test = glmapperGeneric.get(); System.out.println(test); &#125;&#125; 上面这段代码中的 specifyType 方法中 省去了强制转换，可以在编译时候检查类型安全，可以用在类，方法，接口上。 泛型中通配符我们在定义泛型类，泛型方法，泛型接口的时候经常会碰见很多不同的通配符，比如 T，E，K，V 等等，这些通配符又都是什么意思呢？ 常用的 T，E，K，V，？本质上这些个都是通配符，没啥区别，只不过是编码时的一种约定俗成的东西。比如上述代码中的 T ，我们可以换成 A-Z 之间的任何一个 字母都可以，并不会影响程序的正常运行，但是如果换成其他的字母代替 T ，在可读性上可能会弱一些。通常情况下，T，E，K，V，？是这样约定的： ？表示不确定的 java 类型 T (type) 表示具体的一个java类型 K V (key value) 分别代表java键值中的Key Value E (element) 代表Element ？无界通配符先从一个小例子看起 。 我有一个父类 Animal 和几个子类，如狗、猫等，现在我需要一个动物的列表，我的第一个想法是像这样的： 1List&lt;Animal&gt; listAnimals 但是老板的想法确实这样的： 1List&lt;? extends Animal&gt; listAnimals 为什么要使用通配符而不是简单的泛型呢？通配符其实在声明局部变量时是没有什么意义的，但是当你为一个方法声明一个参数时，它是非常重要的。 123456789101112131415161718192021static int countLegs (List&lt;? extends Animal &gt; animals ) &#123; int retVal = 0; for ( Animal animal : animals ) &#123; retVal += animal.countLegs(); &#125; return retVal;&#125;static int countLegs1 (List&lt; Animal &gt; animals ) &#123; int retVal = 0; for ( Animal animal : animals ) &#123; retVal += animal.countLegs(); &#125; return retVal;&#125;public static void main(String[] args) &#123; List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;(); // 不会报错 countLegs( dogs ); // 报错 countLegs1(dogs);&#125; 当调用 countLegs1 时，就会飘红，提示的错误信息如下： 所以，对于不确定或者不关心实际要操作的类型，可以使用无限制通配符（尖括号里一个问号，即 &lt;?&gt; ），表示可以持有任何类型。像 countLegs 方法中，限定了上届，但是不关心具体类型是什么，所以对于传入的 Animal 的所有子类都可以支持，并且不会报错。而 countLegs1 就不行。 上界通配符 &lt; ? extends E&gt; 上界：用 extends 关键字声明，表示参数化的类型可能是所指定的类型，或者是此类型的子类。 在类型参数中使用 extends 表示这个泛型中的参数必须是 E 或者 E 的子类，这样有两个好处： 如果传入的类型不是 E 或者 E 的子类，编译不成功 泛型中可以使用 E 的方法，要不然还得强转成 E 才能使用 12345private &lt;K extends A, E extends B&gt; E test(K arg1, E arg2) &#123; E result = arg2; arg2.compareTo(arg1); //..... return result;&#125; 类型参数列表中如果有多个类型参数上限，用逗号分开 下界通配符 &lt; ? super E&gt; 下界: 用 super 进行声明，表示参数化的类型可能是所指定的类型，或者是此类型的父类型，直至 Object 在类型参数中使用 super 表示这个泛型中的参数必须是 E 或者 E 的父类。 1234567891011121314private &lt;T&gt; void test(List&lt;? super T&gt; dst, List&lt;T&gt; src) &#123; for (T t : src) &#123; dst.add(t); &#125;&#125;public static void main(String[] args) &#123; List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;(); List&lt;Animal&gt; animals = new ArrayList&lt;&gt;(); new Test3().test(animals,dogs);&#125;// Dog 是 Animal 的子类class Dog extends Animal &#123;&#125; dst 类型 “大于等于” src 的类型，这里的“大于等于”是指 dst 表示的范围比 src 要大，因此装得下 dst 的容器也就能装 src 。 ？和 T 的区别 ？和 T 都表示不确定的类型，区别在于我们可以对 T 进行操作，但是对 ？不行，比如如下这种 ： 1234// 可以T t = operate();// 不可以？car = operate(); 简单总结下： T 是一个 确定的 类型，通常用于泛型类和泛型方法的定义，？是一个 不确定 的类型，通常用于泛型方法的调用代码和形参，不能用于定义类和泛型方法。 区别1：通过 T 来 确保 泛型参数的一致性12345// 通过 T 来 确保 泛型参数的一致性public &lt;T extends Number&gt; voidtest(List&lt;T&gt; dest, List&lt;T&gt; src)//通配符是 不确定的，所以这个方法不能保证两个 List 具有相同的元素类型public void test(List&lt;? extends Number&gt; dest, List&lt;? extends Number&gt; src) 像下面的代码中，约定的 T 是 Number 的子类才可以，但是申明时是用的 String ，所以就会飘红报错。 不能保证两个 List 具有相同的元素类型的情况 1234GlmapperGeneric&lt;String&gt; glmapperGeneric = new GlmapperGeneric&lt;&gt;();List&lt;String&gt; dest = new ArrayList&lt;&gt;();List&lt;Number&gt; src = new ArrayList&lt;&gt;();glmapperGeneric.testNon(dest,src); 上面的代码在编译器并不会报错，但是当进入到 testNon 方法内部操作时（比如赋值），对于 dest 和 src 而言，就还是需要进行类型转换。 区别2：类型参数可以多重限定而通配符不行 使用 &amp; 符号设定多重边界（Multi Bounds)，指定泛型类型 T 必须是 MultiLimitInterfaceA 和 MultiLimitInterfaceB 的共有子类型，此时变量 t 就具有了所有限定的方法和属性。对于通配符来说，因为它不是一个确定的类型，所以不能进行多重限定。 区别3：通配符可以使用超类限定而类型参数不行类型参数 T 只具有 一种 类型限定方式： 1T extends A 但是通配符 ? 可以进行 两种限定： 1? extends A? super A ** Class 和 Class&lt;?&gt; 区别**前面介绍了 ？和 T 的区别，那么对于，Class 和 &lt;Class 又有什么区别呢？Class 和 Class 最常见的是在反射场景下的使用，这里以用一段发射的代码来说明下。 123// 通过反射的方式生成 multiLimit // 对象，这里比较明显的是，我们需要使用强制类型转换MultiLimit multiLimit = (MultiLimit)Class.forName(&quot;com.glmapper.bridge.boot.generic.MultiLimit&quot;).newInstance(); 对于上述代码，在运行期，如果反射的类型不是 MultiLimit 类，那么一定会报 java.lang.ClassCastException 错误。 对于这种情况，则可以使用下面的代码来代替，使得在在编译期就能直接 检查到类型的问题： Class 在实例化的时候，T 要替换成具体类。Class&lt;?&gt; 它是个通配泛型，? 可以代表任何类型，所以主要用于声明时的限制情况。比如，我们可以这样做申明： 1234// 可以public Class&lt;?&gt; clazz;// 不可以，因为 T 需要指定类型public Class&lt;T&gt; clazzT; 所以当不知道定声明什么类型的 Class 的时候可以定义一 个Class&lt;?&gt;。 那如果也想 public Class clazzT; 这样的话，就必须让当前的类也指定 T ， 123public class Test3&lt;T&gt; &#123; public Class&lt;?&gt; clazz; // 不会报错 public Class&lt;T&gt; clazzT; 小结本文零碎整理了下 JAVA 泛型中的一些点，不是很全，仅供参考。","tags":["Java","泛型"],"categories":["Java"]},{"title":"Docker从入门到干活，看这一篇足矣","path":"/2023/12/24/Docker从入门到干活，看这一篇足矣/","content":"1. 容器简介1.1. 什么是 Linux 容器Linux容器是与系统其他部分隔离开的一系列进程，从另一个镜像运行，并由该镜像提供支持进程所需的全部文件。 容器提供的镜像包含了应用的所有依赖项，因而在从开发到测试再到生产的整个过程中，它都具有可移植性和一致性。 更加详细地来说，请您假定您在开发一个应用。您使用的是一台笔记本电脑，而且您的开发环境具有特定的配置。其他开发人员身处的环境配置可能稍有不同。您正在开发的应用依赖于您当前的配置，还要依赖于某些特定文件。 与此同时，您的企业还拥有标准化的测试和生产环境，且具有自身的配置和一系列支持文件。 您希望尽可能多在本地模拟这些环境，而不产生重新创建服务器环境的开销。 因此，您要如何确保应用能够在这些环境中运行和通过质量检测，并且在部署过程中不出现令人头疼的问题，也无需重新编写代码和进行故障修复？答案就是使用容器。 容器可以确保您的应用拥有必需的配置和文件，使得这些应用能够在从开发到测试、再到生产的整个流程中顺利运行，而不出现任何不良问题。这样可以避免危机，做到皆大欢喜。 虽然这只是简化的示例，但在需要很高的可移植性、可配置性和隔离的情况下，我们可以利用 Linux 容器通过很多方式解决难题。 无论基础架构是在企业内部还是在云端，或者混合使用两者，容器都能满足您的需求。 1.2. 容器不就是虚拟化吗是，但也不竟然。我们用一种简单方式来思考一下： 虚拟化使得许多操作系统可同时在单个系统上运行。 容器则可共享同一个操作系统内核，将应用进程与系统其他部分隔离开。 图 - 普通虚拟化技术和Docker的对比 这意味着什么？首先，让多个操作系统在单个虚拟机监控程序上运行以实现虚拟化，并不能达成和使用容器同等的轻量级效果。 事实上，在仅拥有容量有限的有限资源时，您需要能够可以进行密集部署的轻量级应用。 Linux 容器可从单个操作系统运行，在所有容器中共享该操作系统，因此应用和服务能够保持轻量级，并行快速运行。 1.3. 容器发展简史 我们现在称为容器技术的概念最初出现在 2000 年，当时称为 FreeBSD jail，这种技术可将 FreeBSD 系统分区为多个子系统（也称为 Jail）。 Jail 是作为安全环境而开发的，系统管理员可与企业内部或外部的多个用户共享这些 Jail。 Jail 的目的是让进程在经过修改的 chroot 环境中创建，而不会脱离和影响整个系统 — 在 chroot 环境中，对文件系统、网络和用户的访问都实现了虚拟化。 尽管 Jail 在实施方面存在局限性，但最终人们找到了脱离这种隔离环境的方法。 但这个概念非常有吸引力。 2001 年，通过 Jacques Gélinas 的 VServer 项目，隔离环境的实施进入了 Linux 领域。 正如 Gélinas 所说，这项工作的目的是“在高度独立且安全的单一环境中运行多个通用 Linux 服务器 [sic]。” 在完成了这项针对 Linux 中多个受控制用户空间的基础性工作后，Linux 容器开始逐渐成形并最终发展成了现在的模样。 2. 什么是 Docker？“Docker” 一词指代多种事物，包括开源社区项目、开源项目使用的工具、主导支持此类项目的公司 Docker Inc. 以及该公司官方支持的工具。技术产品和公司使用同一名称，的确让人有点困惑。 🎍 IT 软件中所说的 “Docker” ，是指容器化技术，用于支持创建和使用 Linux 容器。 🎍 开源 Docker 社区致力于改进这类技术，并免费提供给所有用户，使之获益。 🎍 Docker Inc. 公司凭借 Docker 社区产品起家，它主要负责提升社区版本的安全性，并将改进后的版本与更广泛的技术社区分享。此外，它还专门对这些技术产品进行完善和安全固化，以服务于企业客户。 借助 Docker ，您可将容器当做重量轻、模块化的虚拟机使用。同时，您还将获得高度的灵活性，从而实现对容器的高效创建、部署及复制，并能将其从一个环境顺利迁移至另一个环境。 2.1. Docker 如何工作？Docker 技术使用 Linux 内核和内核功能（例如 Cgroups 和 namespaces）来分隔进程，以便各进程相互独立运行。 这种独立性正是采用容器的目的所在；它可以独立运行多种进程、多个应用程序，更加充分地发挥基础设施的作用，同时保持各个独立系统的安全性。 容器工具（包括 Docker）可提供基于镜像的部署模式。这使得它能够轻松跨多种环境，与其依赖程序共享应用或服务组。Docker 还可在这一容器环境中自动部署应用程序（或者合并多种流程，以构建单个应用程序）。 此外，由于这些工具基于 Linux 容器构建，使得 Docker 既易于使用，又别具一格 —— 它可为用户提供前所未有的高度应用程访问权限、快速部署以及版本控制和分发能力。 2.2. Docker 技术是否与传统的 Linux 容器相同？否。Docker 技术最初是基于 LXC 技术构建（大多数人都会将这一技术与“传统的” Linux 容器联系在一起），但后来它逐渐摆脱了对这种技术的依赖。 就轻量级 虚拟化 这一功能来看，LXC 非常有用，但它无法提供出色的开发人员或用户体验。除了运行容器之外，Docker 技术还具备其他多项功能，包括简化用于构建容器、传输镜像以及控制镜像版本的流程。 传统的 Linux 容器使用 init 系统来管理多种进程。这意味着，所有应用程序都作为一个整体运行。与此相反，Docker 技术鼓励应用程序各自独立运行其进程，并提供相应工具以实现这一功能。这种精细化运作模式自有其优势。 2.3. docker的目标docker的主要目标是”Build,Ship and Run any App,Angwhere”,构建，运输，处处运行 构建：做一个docker镜像 运输：docker pull 运行：启动一个容器 每一个容器，他都有自己的文件系统rootfs. 3. 安装Docker环境说明 123456789# 需要两台几点进行安装[root@docker01 ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@docker01 ~]# uname -r 3.10.0-327.el7.x86_64[root@docker01 ~]# hostname -I10.0.0.100 172.16.1.100 [root@docker02 ~]# hostname -I10.0.0.101 172.16.1.101 在两个节点上都进行操作 123wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.reposed -i &#x27;s#download.docker.com#mirrors.ustc.edu.cn/docker-ce#g&#x27; /etc/yum.repos.d/docker-ce.repoyum install docker-ce -y 修改在docker01配置： 1234567# 修改启动文件，监听远程端口vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://10.0.0.100:2375systemctl daemon-reloadsystemctl enable docker.service systemctl restart docker.service# ps -ef检查进行，是否启动 在docker02测试 123456789[root@docker02 ~]# docker -H 10.0.0.100 infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.12.0-ceStorage Driver: devicemapper··· 3.1. Docker基础命令操作查看docker相关信息 1234567891011121314151617[root@docker01 ~]# docker version Client: Version: 17.12.0-ce API version: 1.35 Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:10:14 2017 OS/Arch: linux/amd64Server: Engine: Version: 17.12.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:12:46 2017 OS/Arch: linux/amd64 Experimental: false 配置docker镜像加速 1234vi /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 3.2. 启动第一个容器12345678910[root@docker01 ~]# docker run -d -p 80:80 nginxUnable to find image &#x27;nginx:latest&#x27; locallylatest: Pulling from library/nginxe7bb522d92ff: Pull complete 6edc05228666: Pull complete cd866a17e81f: Pull complete Digest: sha256:285b49d42c703fdf257d1e2422765c4ba9d3e37768d6ea83d7fe2043dad6e63dStatus: Downloaded newer image for nginx:latest8d8f81da12b5c10af6ba1a5d07f4abc041cb95b01f3d632c3d638922800b0b4d# 容器启动后，在浏览器进行访问测试 参数说明 3.3. Docker镜像生命周期 4. Docker镜像相关操作4.1. 搜索官方仓库镜像1234[root@docker01 ~]# docker search centosNAME DESCRIPTION STARS OFFICIAL AUTOMATEDcentos The official build of CentOS. 3992 [OK] ansible/centos7-ansible Ansible on Centos7 105 [OK] 列表说明 4.2. 获取镜像根据镜像名称拉取镜像 1234[root@docker01 ~]# docker pull centosUsing default tag: latestlatest: Pulling from library/centosaf4b0a2388c6: Downloading 34.65MB/73.67MB 查看当前主机镜像列表 1234[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB 拉第三方镜像方法 1docker pull index.tenxcloud.com/tenxcloud/httpd 4.3. 导出镜像123456[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB# 导出[root@docker01 ~]# docker image save centos &gt; docker-centos.tar.gz 4.4. 删除镜像1234[root@docker01 ~]# docker image rm centos:latest[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEnginx latest 3f8a4339aadd 5 weeks ago 108MB 4.5. 导入镜像1234567[root@docker01 ~]# docker image load -i docker-centos.tar.gz e15afa4858b6: Loading layer 215.8MB/215.8MBLoaded image: centos:latest[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB 4.6. 查看镜像的详细信息1[root@docker01 ~]# docker image inspect centos 5. 容器的日常管理5.1. 容器的起&#x2F;停最简单的运行一个容器 1[root@docker01 ~]# docker run nginx 创建容器，两步走（不常用） 1234[root@docker01 ~]# docker create centos:latest /bin/bashbb7f32368ecf0492adb59e20032ab2e6cf6a563a0e6751e58930ee5f7aaef204[root@docker01 ~]# docker start stupefied_nobelstupefied_nobel 快速启动容器方法 1[root@docker01 ~]# docker run centos:latest /usr/bin/sleep 20; 容器内的第一个进程必须一直处于运行的状态，否则这个容器，就会处于退出状态！ 查看正在运行的容器 12345[root@docker01 ~]# docker container ls 或[root@docker01 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8708e93fd767 nginx &quot;nginx -g &#x27;daemon of…&quot; 6 seconds ago Up 4 seconds 80/tcp keen_lewin 查看你容器详细信息&#x2F;ip 1[root@docker01 ~]# docker container inspect 容器名称/id 查看你所有容器（包括未运行的） 12345[root@docker01 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8708e93fd767 nginx &quot;nginx -g &#x27;daemon of…&quot; 4 minutes ago Exited (0) 59 seconds ago keen_lewinf9f3e6af7508 nginx &quot;nginx -g &#x27;daemon of…&quot; 5 minutes ago Exited (0) 5 minutes ago optimistic_haibt8d8f81da12b5 nginx &quot;nginx -g &#x27;daemon of…&quot; 3 hours ago Exited (0) 3 hours ago lucid_bohr 停止容器 123[root@docker01 ~]# docker stop 容器名称/id 或[root@docker01 ~]# docker container kill 容器名称/id 5.2. 进入容器方法启动时进去方法 123[root@docker01 ~]# docker run -it #参数：-it 可交互终端[root@docker01 ~]# docker run -it nginx:latest /bin/bashroot@79241093859e:/# 退出&#x2F;离开容器 1ctrl+p &amp; ctrl+q 启动后进入容器的方法 启动一个docker 12345[root@docker01 ~]# docker run -it centos:latest [root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 13 1 0 15:47 pts/0 00:00:00 ps -ef attach进入容器，使用pts&#x2F;0 ，会让所用通过此方法进如放入用户看到同样的操作。 12345[root@docker01 ~]# docker attach 1bf0f43c4d2f[root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 14 1 0 15:49 pts/0 00:00:00 ps -ef 自命名启动一个容器 –name 12345[root@docker01 ~]# docker attach 1bf0f43c4d2f[root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 14 1 0 15:49 pts/0 00:00:00 ps -ef exec 进入容器方法（推荐使用） 1234567[root@docker01 ~]# docker exec -it clsn1 /bin/bash [root@b20fa75b4b40 /]# 重新分配一个终端[root@b20fa75b4b40 /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 16:11 pts/0 00:00:00 /bin/bashroot 13 0 0 16:14 pts/1 00:00:00 /bin/bashroot 26 13 0 16:14 pts/1 00:00:00 ps -ef 5.3. 删除所有容器12[root@docker01 ~]# docker rm -f `docker ps -a -q`# -f 强制删除 5.4. 启动时进行端口映射-p参数端口映射 12[root@docker01 ~]# docker run -d -p 8888:80 nginx:latest 287bec5c60263166c03e1fc5b0b8262fe76507be3dfae4ce5cd2ee2d1e8a89a9 不同指定映射方法 随机映射 1docker run -P （大P）# 需要镜像支持 6. Docker 数据卷的管理6.1. 挂载时创建卷挂载卷 12[root@docker01 ~]# docker run -d -p 80:80 -v /data:/usr/share/nginx/html nginx:latest079786c1e297b5c5031e7a841160c74e91d4ad06516505043c60dbb78a259d09 容器内站点目录: &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html 在宿主机写入数据，查看 123[root@docker01 ~]# echo &quot;http://www.nmtui.com&quot; &gt;/data/index.html[root@docker01 ~]# curl 10.0.0.100http://www.nmtui.com 设置共享卷，使用同一个卷启动一个新的容器 1234[root@docker01 ~]# docker run -d -p 8080:80 -v /data:/usr/share/nginx/html nginx:latest 351f0bd78d273604bd0971b186979aa0f3cbf45247274493d2490527babb4e42[root@docker01 ~]# curl 10.0.0.100:8080http://www.nmtui.com 查看卷列表 12[root@docker01 ~]# docker volume lsDRIVER VOLUME NAME 6.2. 创建卷后挂载创建一个卷 12345[root@docker01 ~]# docker volume create f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521[root@docker01 ~]# docker volume ls DRIVER VOLUME NAMElocal f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521 指定卷名 1234[root@docker01 ~]# docker volume ls DRIVER VOLUME NAMElocal clsnlocal f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521 查看卷路径 123456789101112[root@docker01 ~]# docker volume inspect clsn [ &#123; &quot;CreatedAt&quot;: &quot;2018-02-01T00:39:25+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/clsn/_data&quot;, &quot;Name&quot;: &quot;clsn&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;] 使用卷创建 123456[root@docker01 ~]# docker run -d -p 9000:80 -v clsn:/usr/share/nginx/html nginx:latest 1434559cff996162da7ce71820ed8f5937fb7c02113bbc84e965845c219d3503# 宿主机测试[root@docker01 ~]# echo &#x27;blog.nmtui.com&#x27; &gt;/var/lib/docker/volumes/clsn/_data/index.html [root@docker01 ~]# curl 10.0.0.100:9000blog.nmtui.com 设置卷 12[root@docker01 ~]# docker run -d -P --volumes-from 079786c1e297 nginx:latest b54b9c9930b417ab3257c6e4a8280b54fae57043c0b76b9dc60b4788e92369fb 查看使用的端口 123456789101112[root@docker01 ~]# netstat -lntup Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1400/sshd tcp 0 0 10.0.0.100:2375 0.0.0.0:* LISTEN 26218/dockerd tcp6 0 0 :::9000 :::* LISTEN 32015/docker-proxy tcp6 0 0 :::8080 :::* LISTEN 31853/docker-proxy tcp6 0 0 :::80 :::* LISTEN 31752/docker-proxy tcp6 0 0 :::22 :::* LISTEN 1400/sshd tcp6 0 0 :::32769 :::* LISTEN 32300/docker-proxy [root@docker01 ~]# curl 10.0.0.100:32769http://www.nmtui.com 6.3. 手动将容器保存为镜像本次是基于docker官方centos 6.8 镜像创建 官方镜像列表： https://hub.docker.com/explore/ 启动一个centos6.8的镜像 123456[root@docker01 ~]# docker pull centos:6.8[root@docker01 ~]# docker run -it -p 1022:22 centos:6.8 /bin/bash# 在容器种安装sshd服务，并修改系统密码[root@582051b2b92b ~]# yum install openssh-server -y [root@582051b2b92b ~]# echo &quot;root:123456&quot; |chpasswd[root@582051b2b92b ~]# /etc/init.d/sshd start 启动完成后镜像ssh连接测试 将容器提交为镜像 1[root@docker01 ~]# docker commit brave_mcclintock centos6-ssh 使用新的镜像启动容器 12[root@docker01 ~]# docker run -d -p 1122:22 centos6-ssh:latest /usr/sbin/sshd -D 5b8161fda2a9f2c39c196c67e2eb9274977e7723fe51c4f08a0190217ae93094 在容器安装httpd服务 1[root@5b8161fda2a9 /]# yum install httpd -y 编写启动脚本脚本 123456[root@5b8161fda2a9 /]# cat init.sh #!/bin/bash /etc/init.d/httpd start /usr/sbin/sshd -D[root@5b8161fda2a9 /]# chmod +x init.sh # 注意执行权限 再次提交为新的镜像 12[root@docker01 ~]# docker commit 5b8161fda2a9 centos6-httpd sha256:705d67a786cac040800b8485cf046fd57b1828b805c515377fc3e9cea3a481c1 启动镜像，做好端口映射。并在浏览器中测试访问 12[root@docker01 ~]# docker run -d -p 1222:22 -p 80:80 centos6-httpd /init.sh 46fa6a06644e31701dc019fb3a8c3b6ef008d4c2c10d46662a97664f838d8c2c 7. Dockerfile自动构建docker镜像官方构建dockerffile文件参考 https://github.com/CentOS/CentOS-Dockerfiles 7.1. Dockerfile指令集dockerfile主要组成部分： 基础镜像信息 FROM centos:6.8 制作镜像操作指令RUN yum insatll openssh-server -y 容器启动时执行指令 CMD [“&#x2F;bin&#x2F;bash”] dockerfile常用指令： FROM 这个镜像的妈妈是谁？（指定基础镜像） MAINTAINER 告诉别人，谁负责养它？（指定维护者信息，可以没有） RUN 你想让它干啥（在命令前面加上RUN即可） ADD 给它点创业资金（COPY文件，会自动解压） WORKDIR 我是cd,今天刚化了妆（设置当前工作目录） VOLUME 给它一个存放行李的地方（设置卷，挂载主机目录） EXPOSE 它要打开的门是啥（指定对外的端口） CMD 奔跑吧，兄弟！（指定容器启动后的要干的事情） dockerfile其他指令： COPY 复制文件 ENV 环境变量 ENTRYPOINT 容器启动后执行的命令 7.2. 创建一个Dockerfile创建第一个Dockerfile文件 123456789# 创建目录[root@docker01 base]# cd /opt/base# 创建Dcokerfile文件，注意大小写[root@docker01 base]# vim DockerfileFROM centos:6.8RUN yum install openssh-server -y RUN echo &quot;root:123456&quot; |chpasswdRUN /etc/init.d/sshd start CMD [&quot;/usr/sbin/sshd&quot;,&quot;-D&quot;] 使用自构建的镜像启动 12[root@docker01 base]# docker image build -t centos6.8-ssh . -t 为镜像标签打标签 . 表示当前路径 使用自构建的镜像启动 12[root@docker01 base]# docker run -d -p 2022:22 centos6.8-ssh-b dc3027d3c15dac881e8e2aeff80724216f3ac725f142daa66484f7cb5d074e7a 7.3. 使用Dcokerfile安装kodexplorerDockerfile文件内容 12345678FROM centos:6.8RUN yum install wget unzip php php-gd php-mbstring -y &amp;&amp; yum clean all# 设置工作目录，之后的操作都在这个目录中WORKDIR /var/www/html/RUN wget -c http://static.kodcloud.com/update/download/kodexplorer4.25.zipRUN unzip kodexplorer4.25.zip &amp;&amp; rm -f kodexplorer4.25.zipRUN chown -R apache.apache .CMD [&quot;/usr/sbin/apachectl&quot;,&quot;-D&quot;,&quot;FOREGROUND&quot;] 更多的Dockerfile可以参考官方方法。 8. Docker中的镜像分层参考文档： http://www.maiziedu.com/wiki/cloud/dockerimage/ Docker 支持通过扩展现有镜像，创建新的镜像。实际上，Docker Hub 中 99% 的镜像都是通过在 base 镜像中安装和配置需要的软件构建出来的。 从上图可以看到，新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。 8.1. Docker 镜像为什么分层镜像分层最大的一个好处就是共享资源。 比如说有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。 如果多个容器共享一份基础镜像，当某个容器修改了基础镜像的内容，比如 &#x2F;etc 下的文件，这时其他容器的 &#x2F;etc 是不会被修改的，修改只会被限制在单个容器内。这就是容器 Copy-on-Write 特性。 8.2. 可写的容器层当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。 所有对容器的改动 - 无论添加、删除、还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的所有镜像层都是只读的。 8.3. 容器层的细节说明镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统。如果不同层中有一个相同路径的文件，比如 &#x2F;a，上层的 &#x2F;a 会覆盖下层的 &#x2F;a，也就是说用户只能访问到上层中的文件 &#x2F;a。在容器层中，用户看到的是一个叠加之后的文件系统。 文件操作的 只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。 这样就解释了我们前面提出的问题：容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。 9. 使用docker运行zabbix-server9.1. 容器间的互联在运行zabbix之前务必要了解容器间互联的方法 123456# 创建一个nginx容器docker run -d -p 80:80 nginx# 创建容器，做link，并进入容器中docker run -it --link quirky_brown:web01 centos-ssh /bin/bash# 在容器中访问nginx容器可以ping通ping web01 命令执行过程 12345678910111213141516171819# 启动apache容器[root@docker01 ~]# docker run -d httpd:2.4 3f1f7fc554720424327286bd2b04aeab1b084a3fb011a785b0deab6a34e56955^[[A[root@docker01 docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1f7fc55472 httpd:2.4 &quot;httpd-foreground&quot; 6 seconds ago Up 5 seconds 80/tcp determined_clarke# 拉取一个busybox 镜像[root@docker01 ~]# docker pull busybox # 启动容器[root@docker01 ~]# docker run -it --link determined_clarke:web busybox:latest /bin/sh / # # 使用新的容器访问最初的web容器/ # ping web PING web (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.058 ms^C--- web ping statistics ---1 packets transmitted, 1 packets received, 0% packet lossround-trip min/avg/max = 0.058/0.058/0.058 ms 9.2. 启动zabbix容器1、启动一个mysql的容器 1234567docker run --name mysql-server -t \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ -d mysql:5.7 \\ --character-set-server=utf8 --collation-server=utf8_bin 2、启动java-gateway容器监控java服务 12docker run --name zabbix-java-gateway -t \\ -d zabbix/zabbix-java-gateway:latest 3、启动zabbix-mysql容器使用link连接mysql与java-gateway。 1234567891011docker run --name zabbix-server-mysql -t \\ -e DB_SERVER_HOST=&quot;mysql-server&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ -e ZBX_JAVAGATEWAY=&quot;zabbix-java-gateway&quot; \\ --link mysql-server:mysql \\ --link zabbix-java-gateway:zabbix-java-gateway \\ -p 10051:10051 \\ -d zabbix/zabbix-server-mysql:latest 4、启动zabbix web显示，使用link连接zabbix-mysql与mysql。 12345678910docker run --name zabbix-web-nginx-mysql -t \\ -e DB_SERVER_HOST=&quot;mysql-server&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ --link mysql-server:mysql \\ --link zabbix-server-mysql:zabbix-server \\ -p 80:80 \\ -d zabbix/zabbix-web-nginx-mysql:latest 9.3. 关于zabbix API关于zabbix API可以参考官方文档： https://www.zabbix.com/documentation/3.4/zh/manual/api 1、获取token方法 123456789101112# 获取token[root@docker02 ~]# curl -s -X POST -H &#x27;Content-Type:application/json&#x27; -d &#x27;&#123;&quot;jsonrpc&quot;: &quot;2.0&quot;,&quot;method&quot;: &quot;user.login&quot;,&quot;params&quot;: &#123;&quot;user&quot;: &quot;Admin&quot;,&quot;password&quot;: &quot;zabbix&quot;&#125;,&quot;id&quot;: 1&#125;&#x27; http://10.0.0.100/api_jsonrpc.php&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;result&quot;:&quot;d3be707f9e866ec5d0d1c242292cbebd&quot;,&quot;id&quot;:1&#125; 10. docker 仓库（registry）10.1. 创建一个普通仓库1、创建仓库 1docker run -d -p 5000:5000 --restart=always --name registry -v /opt/myregistry:/var/lib/registry registry 2、修改配置文件，使之支持http 12345[root@docker01 ~]# cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;insecure-registries&quot;: [&quot;10.0.0.100:5000&quot;]&#125; 重启docker让修改生效 1[root@docker01 ~]# systemctl restart docker.service 3、修改镜像标签 123456[root@docker01 ~]# docker tag busybox:latest 10.0.0.100:5000/clsn/busybox:1.0[root@docker01 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos6-ssh latest 3c2b1e57a0f5 18 hours ago 393MBhttpd 2.4 2e202f453940 6 days ago 179MB10.0.0.100:5000/clsn/busybox 1.0 5b0d59026729 8 days ago 1.15MB 4、将新打标签的镜像上传镜像到仓库 1[root@docker01 ~]# docker push 10.0.0.100:5000/clsn/busybox 10.2. 带basic认证的仓库1、安装加密工具 1[root@docker01 clsn]# yum install httpd-tools -y 2、设置认证密码 12mkdir /opt/registry-var/auth/ -phtpasswd -Bbn clsn 123456 &gt; /opt/registry-var/auth/htpasswd 3、启动容器，在启动时传入认证参数 1docker run -d -p 5000:5000 -v /opt/registry-var/auth/:/auth/ -e &quot;REGISTRY_AUTH=htpasswd&quot; -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd registry 4、使用验证用户测试 12345678910111213141516171819202122232425# 登陆用户[root@docker01 ~]# docker login 10.0.0.100:5000 Username: clsn Password: 123456Login Succeeded# 推送镜像到仓库[root@docker01 ~]# docker push 10.0.0.100:5000/clsn/busybox The push refers to repository [10.0.0.100:5000/clsn/busybox]4febd3792a1f: Pushed 1.0: digest: sha256:4cee1979ba0bf7db9fc5d28fb7b798ca69ae95a47c5fecf46327720df4ff352d size: 527#认证文件的保存位置[root@docker01 ~]# cat .docker/config.json &#123; &quot;auths&quot;: &#123; &quot;10.0.0.100:5000&quot;: &#123; &quot;auth&quot;: &quot;Y2xzbjoxMjM0NTY=&quot; &#125;, &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;Y2xzbjpIenNAMTk5Ng==&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/17.12.0-ce (linux)&quot; &#125;&#125; 至此，一个简单的docker镜像仓库搭建完成 11. docker-compose编排工具11.1. 安装docker-compose1234# 下载pip软件yum install -y python2-pip# 下载 docker-composepip install docker-compose 国内开启pip 下载加速： http://mirrors.aliyun.com/help/pypi 1234567mkdir ~/.pip/cat &gt; ~/.pip/pip.conf &lt;&lt;&#x27;EOF&#x27;[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.comEOF 11.2. 编排启动镜像1、创建文件目录 12[root@docker01 ~]# mkdir /opt/my_wordpress/[root@docker01 ~]# cd /opt/my_wordpress/ 2、编写编排文件 1234567891011121314151617181920212223242526[root@docker01 my_wordpress]# vim docker-compose.ymlversion: &#x27;3&#x27;services: db: image: mysql:5.7 volumes: - /data/db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - /data/web_data:/var/www/html ports: - &quot;8000:80&quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress 3、启动 123[root@docker01 my_wordpress]# docker-compose up #启动方法：docker-compose up #后台启动方法：docker-compose up -d 4、浏览器上访问http://10.0.0.100:8000 进行wordpress的安装即可 11.3. haproxy代理后端docker容器1、修改编排脚本 1234567891011121314151617181920212223242526[root@docker01 my_wordpress]# cat docker-compose.yml version: &#x27;3&#x27;services: db: image: mysql:5.7 volumes: - /data/db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - /data/web_data:/var/www/html ports: - &quot;80&quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress 2、同时启动两台wordpress 1234[root@docker01 my_wordpress]# docker-compose scale wordpress=2 WARNING: The scale command is deprecated. Use the up command with the --scale flag instead.Starting mywordpress_wordpress_1 ... doneCreating mywordpress_wordpress_2 ... done 3、安装haproxy 1[root@docker01 ~]# yum install haproxy -y 4、修改haproxy配置文件 关于配置文件的详细说明，参考： https://www.cnblogs.com/MacoLee/p/5853413.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@docker01 ~]#cp /etc/haproxy/haproxy.cfg&#123;,.bak&#125;[root@docker01 ~]# vim /etc/haproxy/haproxy.cfgglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/stats level admin #支持命令行控制defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000listen stats mode http bind 0.0.0.0:8888 stats enable stats uri /haproxy-status stats auth admin:123456frontend frontend_www_example_com bind 10.0.0.100:8000 mode http option httplog log global default_backend backend_www_example_combackend backend_www_example_com option forwardfor header X-REAL-IP option httpchk HEAD / HTTP/1.0 balance roundrobin server web-node1 10.0.0.100:32768 check inter 2000 rise 30 fall 15 server web-node2 10.0.0.100:32769 check inter 2000 rise 30 fall 15 5、启动haproxy 12systemctl start haproxysystemctl enable haproxy 6、使用浏览器访问hapeoxy监听的8000端口可以看到负载的情况 7、使用浏览器访问 http://10.0.0.100:8888/haproxy-status 可以看到后端节点的监控状况， 11.4. 安装socat 直接操作socket控制haproxy1、安装软件 1yum install socat.x86_64 -y 2、查看帮助 1[root@docker01 web_data]# echo &quot;help&quot;|socat stdio /var/lib/haproxy/stats 3、下线后端节点 1echo &quot;disable server backend_www_example_com/web-node2&quot;|socat stdio /var/lib/haproxy/stats 4、上线后端节点 1echo &quot;enable server backend_www_example_com/web-node3&quot;|socat stdio /var/lib/haproxy/stats 5、编写php测试页，放到&#x2F;data&#x2F;web_data下，在浏览器中访问可以查看当前的节点 123456789101112[root@docker01 web_data]# vim check.php&lt;html&gt; &lt;head&gt; &lt;title&gt;PHP测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;?php echo &#x27;&lt;p&gt;Hello World &lt;/p&gt;&#x27;; ?&gt; &lt;?php echo &quot;访问的服务器地址是:&quot;.&quot;&lt;fontcolor=red&gt;&quot;.$_SERVER[&#x27;SERVER_ADDR&#x27;].&quot;&lt;/font&gt;&quot;.&quot;&lt;br&gt;&quot;; echo&quot;访问的服务器域名是:&quot;.&quot;&lt;fontcolor=red&gt;&quot;.$_SERVER[&#x27;SERVER_NAME&#x27;].&quot;&lt;/font&gt;&quot;.&quot;&lt;br&gt;&quot;; ?&gt; &lt;/body&gt;&lt;/html&gt; 12. 重启docker服务，容器全部退出的解决办法12.1. 在启动是指定自动重启1docker run --restart=always 12.1. 修改docker默认配置文件12# 添加上下面这行&quot;live-restore&quot;: true docker server配置文件 &#x2F;etc&#x2F;docker&#x2F;daemon.json 参考 1234567[root@docker02 ~]# cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;graph&quot;: &quot;/opt/mydocker&quot;, # 修改数据的存放目录到/opt/mydocker/，原/var/lib/docker/ &quot;insecure-registries&quot;: [&quot;10.0.0.100:5000&quot;], &quot;live-restore&quot;: true&#125; 重启生效，只对在此之后启动的容器生效 1[root@docker01 ~]# systemctl restart docker.service 13. Docker网络类型 13.1. docker的网络类型 Bridge默认docker网络隔离基于网络命名空间，在物理机上创建docker容器时会为每一个docker容器分配网络命名空间，并且把容器IP桥接到物理机的虚拟网桥上。 13.2. 不为容器配置网络功能此模式下创建容器是不会为容器配置任何网络参数的，如：容器网卡、IP、通信路由等，全部需要自己去配置。 123456[root@docker01 ~]# docker run -it --network none busybox:latest /bin/sh / # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 13.3. 与其他容器共享网络配置(Container）此模式和host模式很类似，只是此模式创建容器共享的是其他容器的IP和端口而不是物理机，此模式容器自身是不会配置网络和端口，创建此模式容器进去后，你会发现里边的IP是你所指定的那个容器IP并且端口也是共享的，而且其它还是互相隔离的，如进程等。 12345678910[root@docker01 ~]# docker run -it --network container:mywordpress_db_1 busybox:latest /bin/sh / # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever105: eth0@if106: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff inet 172.18.0.3/16 brd 172.18.255.255 scope global eth0 valid_lft forever preferred_lft forever 13.4. 使用宿主机网络此模式创建的容器没有自己独立的网络命名空间，是和物理机共享一个Network Namespace，并且共享物理机的所有端口与IP，并且这个模式认为是不安全的。 1[root@docker01 ~]# docker run -it --network host busybox:latest /bin/shshell 13.5. 查看网络列表123456[root@docker01 ~]# docker network list NETWORK ID NAME DRIVER SCOPEb15e8a720d3b bridge bridge local345d65b4c2a0 host host localbc5e2a32bb55 mywordpress_default bridge localebf76eea91bb none null local 用PIPEWORK为docker容器配置独立IP 参考文档： blog.csdn.net&#x2F;design321&#x2F;article&#x2F;details&#x2F;48264825 官方网站： github.com&#x2F;jpetazzo&#x2F;pipework 宿主环境：centos7.2 1、安装pipework 1234wget https://github.com/jpetazzo/pipework/archive/master.zipunzip master.zip cp pipework-master/pipework /usr/local/bin/chmod +x /usr/local/bin/pipework 2、配置桥接网卡 安装桥接工具 1yum install bridge-utils.x86_64 -y 修改网卡配置，实现桥接 1234567891011121314151617181920# 修改eth0配置，让br0实现桥接[root@docker01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE=EthernetBOOTPROTO=staticNAME=eth0DEVICE=eth0ONBOOT=yesBRIDGE=br0[root@docker01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 TYPE=BridgeBOOTPROTO=staticNAME=br0DEVICE=br0ONBOOT=yesIPADDR=10.0.0.100NETMASK=255.255.255.0GATEWAY=10.0.0.254DNS1=223.5.5.5# 重启网络[root@docker01 ~]# /etc/init.d/network restart 3、运行一个容器镜像测试： 1pipework br0 $(docker run -d -it -p 6880:80 --name httpd_pw httpd) 10.0.0.220/24@10.0.0.254 在其他主机上测试端口及连通性 12345[root@docker01 ~]# curl 10.0.0.220&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;[root@docker01 ~]# ping 10.0.0.220 -c 1PING 10.0.0.220 (10.0.0.220) 56(84) bytes of data.64 bytes from 10.0.0.220: icmp_seq=1 ttl=64 time=0.043 ms 4、再运行一个容器，设置网路类型为none： 1pipework br0 $(docker run -d -it --net=none --name test httpd:2.4) 10.0.0.221/24@10.0.0.254 进行访问测试 12[root@docker01 ~]# curl 10.0.0.221&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 5、重启容器后需要再次指定： 12pipework br0 testduliip 172.16.146.113/24@172.16.146.1pipework br0 testduliip01 172.16.146.112/24@172.16.146.1 Dcoker跨主机通信之overlay可以参考： cnblogs.com&#x2F;CloudMan6&#x2F;p&#x2F;7270551.html 13.6. Docker跨主机通信之macvlan创建网络 12[root@docker01 ~]# docker network create --driver macvlan --subnet 10.1.0.0/24 --gateway 10.1.0.254 -o parent=eth0 macvlan_133a1f41dcc074f91b5bd45e7dfedabfb2b8ec82db16542f05213839a119b62ca 设置网卡为混杂模式 1ip link set eth0 promisc on 创建使用macvlan网络容器 1[root@docker02 ~]# docker run -it --network macvlan_1 --ip=10.1.0.222 busybox /b 14. docker企业级镜像仓库harbor容器管理 123[root@docker01 harbor]# pwd/opt/harbor[root@docker01 harbor]# docker-compose stop 1、安装docker、docker-compose 下载 harbor 12cd /opt &amp;&amp; https://storage.googleapis.com/harbor-releases/harbor-offline-installer-v1.3.0.tgztar xf harbor-offline-installer-v1.3.0.tgz 2、修改主机及web界面密码 12345[root@docker01 harbor]# vim harbor.cfg ··· hostname = 10.0.0.100 harbor_admin_password = Harbor12345 ··· 3、执行安装脚本 1[root@docker01 harbor]# ./install.sh 浏览器访问 http://10.0.0.11 添加一个项目 4、镜像推送到仓库的指定项目 1234567891011[root@docker02 ~]# docker tag centos:6.8 10.0.0.100/clsn/centos6.8:1.0[root@docker02 ~]# [root@docker02 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZEbusybox latest 5b0d59026729 8 days ago 1.15MB10.0.0.100/clsn/centos6.8 1.0 6704d778b3ba 2 months ago 195MBcentos 6.8 6704d778b3ba 2 months ago 195MB[root@docker02 ~]# docker login 10.0.0.100Username: adminPassword: Login Succeeded 5、推送镜像 123[root@docker02 ~]# docker push 10.0.0.100/clsn/centos6.8 The push refers to repository [10.0.0.100/clsn/centos6.8]e00c9229b481: Pushing 13.53MB/194.5MB 6、在web界面里查看 14.1. 使用容器的建议 不要以拆分方式进行应用程序发布 不要创建大型镜像 不要在单个容器中运行多个进程 不要再镜像内保存凭证，不要依赖IP地址 以非root用户运行进程 不要使用“最新”标签 不要利用运行中的容器创建镜像 不要使用单层镜像 不要将数据存放在容器内 14.2. 关于Docker容器的监控容器的基本信息 包括容器的数量、ID、名称、镜像、启动命令、端口等信息 容器的运行状态 统计各状态的容器的数量，包括运行中、暂停、停止及异常退出 容器的用量信息 统计容器的CPU使用率、内存使用量、块设备I&#x2F;O使用量、网络使用情况等资源的使用情况 参考文献 redhat.com&#x2F;zh&#x2F;topics&#x2F;containers&#x2F;whats-a-linux-container redhat.com&#x2F;zh&#x2F;topics&#x2F;containers&#x2F;what-is-docker blog.51cto.com&#x2F;dihaifeng&#x2F;1713512 cnblogs.com&#x2F;Bourbon-tian&#x2F;p&#x2F;6867796.html cnblogs.com&#x2F;CloudMan6&#x2F;p&#x2F;6806193.html","tags":["开发工具","Docker"],"categories":["开发工具"]},{"title":"MySQL大表优化方案","path":"/2023/12/24/MySQL大表优化方案/","content":"当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化： 单表优化除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量： 字段 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED VARCHAR的长度只分配真正需要的空间 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP而非DATETIME， 单表不要有太多字段，建议在20以内 避免使用NULL字段，很难查询优化且占用额外索引空间 用整型来存IP 索引 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描 值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段 字符字段只建前缀索引 字符字段最好不要做主键 不用外键，由程序保证约束 尽量不用UNIQUE，由程序保证约束 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引 查询SQL 可通过开启慢查询日志来找出较慢的SQL 不做列运算：SELECT id WHERE age + 1 &#x3D; 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边 sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库 不用SELECT * OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内 不用函数和触发器，在应用程序实现 避免%xxx式查询 少用JOIN 使用同类型进行比较，比如用’123’和’123’比，123和123比 尽量避免在WHERE子句中使用!&#x3D;或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大 引擎目前广泛使用的是MyISAM和InnoDB两种引擎： MyISAMMyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是： 不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁 不支持事务 不支持外键 不支持崩溃后的安全恢复 在表有读取查询的同时，支持往表中插入新纪录 支持BLOB和TEXT的前500个字符索引，支持全文索引 支持延迟更新索引，极大提升写入性能 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用 InnoDBInnoDB在MySQL 5.5后成为默认索引，它的特点是： 支持行锁，采用MVCC来支持高并发 支持事务 支持外键 支持崩溃后的安全恢复 不支持全文索引 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 系统调优参数可以使用下面几个工具来做基准测试： sysbench：一个模块化，跨平台以及多线程的性能测试工具 iibench-mysql：基于 Java 的 MySQL&#x2F;Percona&#x2F;MariaDB 索引进行插入性能测试工具 tpcc-mysql：Percona开发的TPC-C测试工具 具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数： back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500 wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时 max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限 thread_concurrency：并发线程数，设为CPU核数的两倍 skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问 key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询show status like ‘key_read%’，保证key_reads &#x2F; key_read_requests在0.1%以下最好 innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询show status like ‘Innodb_buffer_pool_read%’，保证 (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) &#x2F; Innodb_buffer_pool_read_requests越高越好 innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小 innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率(Qcache_hits&#x2F;(Qcache_hits+Qcache_inserts)*100))进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大.可以通过命令show status like ‘Qcache_%’查看目前系统Query catch使用大小 read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能 sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小 read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值 thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的 table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM 升级硬件Scale up，这个不多说了，根据MySQL是CPU密集型还是I&#x2F;O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能 读写分离也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离 缓存缓存可以发生在这些层次： MySQL内部：在系统调优参数介绍了相关设置 数据访问层：比如MyBatis针对SQL语句做缓存，而Hibernate可以精确到单个记录，这里缓存的对象主要是持久化对象Persistence Object 应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象Data Transfer Object Web层：针对web页面做缓存 浏览器客户端：用户端的缓存 可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式： 直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如Spring Cache的工作方式。这种实现非常简单，同步好，但效率一般。 回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。 表分区MySQL在5.1版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码 对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对SQL层来说是一个完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引 用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过EXPLAIN PARTITIONS来查看某条SQL语句会落在那些分区上，从而进行SQL优化，如下图5条记录落在两个分区上： 12345678mysql&gt; explain partitions select count(1) from user_partition where id in (1,2,3,4,5);+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| 1 | SIMPLE | user_partition | p1,p4 | range | PRIMARY | PRIMARY | 8 | NULL | 5 | Using where; Using index |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+1 row in set (0.00 sec) 分区的好处是： 可以让单表存储更多的数据 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作 部分查询能够从查询条件确定只落在少数分区上，速度会很快 分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备 可以使用分区表赖避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争 可以备份和恢复单个分区 分区的限制和缺点： 一个表最多只能有1024个分区 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来 分区表无法使用外键约束 NULL值会使分区过滤无效 所有分区必须使用相同的存储引擎 分区的类型： RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区 LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL中有效的、产生非负整数值的任何表达式 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值 分区适合的场景有： 最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示： 1234567891011121314CREATE TABLE members ( firstname VARCHAR(25) NOT NULL, lastname VARCHAR(25) NOT NULL, username VARCHAR(16) NOT NULL, email VARCHAR(35), joined DATE NOT NULL)PARTITION BY RANGE( YEAR(joined) ) ( PARTITION p0 VALUES LESS THAN (1960), PARTITION p1 VALUES LESS THAN (1970), PARTITION p2 VALUES LESS THAN (1980), PARTITION p3 VALUES LESS THAN (1990), PARTITION p4 VALUES LESS THAN MAXVALUE); 查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存 另外MySQL有一种早期的简单的分区实现 - 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代 垂直拆分垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联 比如原始的用户表是： 垂直拆分后是： 垂直拆分的优点是： 可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I&#x2F;O次数(每次查询时读取的Block 就少) 可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起 数据维护简单 缺点是： 主键出现冗余，需要管理冗余列 会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力 依然存在单表数据量过大的问题（需要水平拆分） 事务处理复杂 水平拆分概述水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。 前面的表分区本质上也是一种特殊的库内分表 库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决 前面垂直拆分的用户表如果进行水平拆分，结果是： 实际情况中往往会是垂直拆分和水平拆分的结合，即将Users_A_M和Users_N_Z再拆成Users和UserExtras，这样一共四张表 水平拆分的优点是: 不存在单库大数据和高并发的性能瓶颈 应用端改造较少 提高了系统的稳定性和负载能力 缺点是： 分片事务一致性难以解决 跨节点Join性能差，逻辑复杂 数据多次扩展难度跟维护量极大 分片原则 能不分就不分，参考单表优化 分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询SQL跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量 分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性Hash分片，这几种分片都有利于扩容 尽量不要在一个事务中的SQL跨越多个分片，分布式事务一直是个不好处理的问题 查询条件尽量优化，尽量避免Select * 的方式，大量数据结果集下，会消耗大量带宽和CPU资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。 通过数据冗余和表分区赖降低跨库Join的可能 这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤，比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。 总体上来说，分片的选择是取决于最频繁的查询SQL的条件，因为不带任何Where语句的查询SQL，会遍历所有的分片，性能相对最差，因此这种SQL越多，对系统的影响越大，所以我们要尽量避免这种SQL的产生。 解决方案由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。 客户端架构通过修改数据访问层，如JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以Jar包的方式呈现 这是一个客户端架构的例子： 可以看到分片的实现是和应用服务器在一起的，通过修改Spring JDBC层来实现 客户端架构的优点是： 应用直连数据库，降低外围系统依赖所带来的宕机风险 集成成本低，无需额外运维的组件 缺点是： 限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心 将分片逻辑的压力放在应用服务器上，造成额外风险 代理架构通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件 这是一个代理架构的例子： 代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要Zookeeper之类的服务组件来管理 代理架构的优点是： 能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强 对于应用服务器透明且没有增加任何额外负载 缺点是： 需部署和运维独立的代理中间件，成本高 应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险 各方案比较 出品方 架构模型 支持数据库 分库 分表 读写分离 外部依赖 是否开源 实现语言 支持语言 最后更新 Github星数 MySQL Fabric MySQL官方 代理架构 MySQL 有 有 有 无 是 python 无限制 4个月前 35 Cobar 阿里巴巴 代理架构 MySQL 有 无 无 无 是 Java 无限制 两年前 1287 Cobar Client 阿里巴巴 客户端架构 MySQL 有 无 无 无 是 Java Java 三年前 344 TDDL 淘宝 客户端架构 无限制 有 有 有 Diamond 只开源部分 Java Java 未知 519 Atlas 奇虎360 代理架构 MySQL 有 有 有 无 是 C 无限制 10个月前 1941 Heisenberg 百度熊照 代理架构 MySQL 有 有 有 无 是 Java 无限制 2个月前 197 TribeDB 个人 代理架构 MySQL 有 有 有 无 是 NodeJS 无限制 3个月前 126 ShardingJDBC 当当 客户端架构 MySQL 有 有 有 无 是 Java Java 当天 1144 Shark 个人 客户端架构 MySQL 有 有 无 无 是 Java Java 两天前 84 KingShard 个人 代理架构 MySQL 有 有 有 无 是 Golang 无限制 两天前 1836 OneProxy 平民软件 代理架构 MySQL 有 有 有 无 否 未知 无限制 未知 未知 MyCat 社区 代理架构 MySQL 有 有 有 无 是 Java 无限制 两天前 1270 Vitess Youtube 代理架构 MySQL 有 有 有 无 是 Golang 无限制 当天 3636 Mixer 个人 代理架构 MySQL 有 有 无 无 是 Golang 无限制 9个月前 472 JetPants Tumblr 客户端架构 MySQL 有 有 无 无 是 Ruby Ruby 10个月前 957 HibernateShard Hibernate 客户端架构 无限制 有 有 无 无 是 Java Java 4年前 57 MybatisShard MakerSoft 客户端架构 无限制 有 有 无 无 是 Java Java 11个月前 119 Gizzard Twitter 代理架构 无限制 有 有 无 无 是 Java 无限制 3年前 2087 如此多的方案，如何进行选择？可以按以下思路来考虑： 确定是使用代理架构还是客户端架构。中小型规模或是比较简单的场景倾向于选择客户端架构，复杂场景或大规模系统倾向选择代理架构 具体功能是否满足，比如需要跨节点ORDER BY，那么支持该功能的优先考虑 不考虑一年内没有更新的产品，说明开发停滞，甚至无人维护和技术支持 最好按大公司-&gt;社区-&gt;小公司-&gt;个人这样的出品方顺序来选择 选择口碑较好的，比如github星数、使用者数量质量和使用者反馈 开源的优先，往往项目有特殊需求可能需要改动源代码 按照上述思路，推荐以下选择： 客户端架构：ShardingJDBC 代理架构：MyCat或者Atlas 兼容MySQL且可水平扩展的数据库目前也有一些开源数据库兼容MySQL协议，如： TiDB Cubrid 但其工业品质和MySQL尚有差距，且需要较大的运维投入，如果想将原始的MySQL迁移到可水平扩展的新数据库中，可以考虑一些云数据库： 阿里云PetaData 阿里云OceanBase 腾讯云DCDB NoSQL在MySQL上做Sharding是一种戴着镣铐的跳舞，事实上很多大表本身对MySQL这种RDBMS的需求并不大，并不要求ACID，可以考虑将这些表迁移到NoSQL，彻底解决水平扩展问题，例如： 日志类、监控类、统计类数据 非结构化或弱结构化数据 对事务要求不强，且无太多关联操作的数据","tags":["MySQL","DataBase","SQL优化"],"categories":["DataBase"]},{"title":"MyBatis 的执行流程","path":"/2023/12/24/MyBatis-的执行流程！/","content":"概要在MyBatis中，利用编程式进行数据查询，主要就是下面几行代码： 123SqlSession session = sqlSessionFactory.openSession();UserMapper userMapper = session.getMapper(UserMapper.class);List&lt;LwUser&gt; userList = userMapper.listUserByUserName(&quot;孤狼1号&quot;); 第一行是获取一个SqlSession对象在上一篇文章分析过了，第二行就是获取UserMapper接口，第三行一行代码就实现了整个查询语句的流程，接下来我们就来仔细分析一下第二和第三步。 获取Mapper接口(getMapper)第二步是通过SqlSession对象是获取一个Mapper接口，这个流程还是相对简单的，下面就是我们调用session.getMapper方法之后的运行时序图： 1、在调用getMapper之后，会去Configuration对象中获取Mapper对象，因为在项目启动的时候就会把Mapper接口加载并解析存储到Configuration对象 2、通过Configuration对象中的MapperRegistry对象属性，继续调用getMapper方法 3、根据type类型，从MapperRegistry对象中的knownMappers获取到当前类型对应的代理工厂类，然后通过代理工厂类生成对应Mapper的代理类 4、最终获取到我们接口对应的代理类MapperProxy对象 而MapperProxy可以看到实现了InvocationHandler，使用的就是JDK动态代理。 至此获取Mapper流程结束了，那么就有一个问题了MapperRegistry对象内的HashMap属性knownMappers中的数据是什么时候存进去的呢？ Mapper接口和映射文件是何时关联的Mapper接口及其映射文件是在加载mybatis-config配置文件的时候存储进去的，下面就是时序图： 1、首先我们会手动调用SqlSessionFactoryBuilder方法中的build()方法： 2、然后会构造一个XMLConfigBuilder对象，并调用其parse方法： 3、然后会继续调用自己的parseConfiguration来解析配置文件，这里面就会分别去解析全局配置文件的顶级节点，其他的我们先不看，我们直接看最后解析mappers节点 4、继续调用自己的mapperElement来解析mappers文件（这个方法比较长，为了方便截图完整，所以把字体缩小了1号），可以看到，这里面分了四种方式来解析mappers节点的配置，对应了4种mapper配置方式，而其中红框内的两种方式是直接配置的xml映射文件，蓝框内的两种方式是解析直接配置Mapper接口的方式，从这里也可以说明，不论配置哪种方式，最终MyBatis都会将xml映射文件和Mapper接口进行关联。 5、我们先看第2种和第3中（直接配置xml映射文件的解析方式），会构建一个XMLMapperBuilder对象并调用其parse方法。 当然，这个还是会被解析的，后面执行查询的时候会再次通过不断遍历去全部解析完毕，不过有一点需要注意的是，互相引用这种是会导致解析失败报错的，所以在开发过程中我们应该避免循环依赖的产生。 6、解析完映射文件之后，调用自身方法bindMapperForNamespace，开始绑定Mapper接口和映射文件： 7、调用Configuration对象的addMapper 8、调用Configuration对象的属性MapperRegistry内的addMapper方法，这个方法就是正式将Mapper接口添加到knownMappers，所以上面getMapper可以直接获取： 到这里我们就完成了Mapper接口和xml映射文件的绑定 9、注意上面红框里面的代码，又调用了一次parse方法，这个parse方法主要是解析注解，比如下面的语句： 12@Select(&quot;select * from lw_user&quot;)List&lt;LwUser&gt; listAllUser(); 所以这个方法里面会去解析@Select等注解，需要注意的是，parse方法里面会同时再解析一次xml映射文件，因为上面我们提到了mappers节点有4种配置方式，其中两种配置的是Mapper接口，而配置Mapper接口会直接先调用addMapper接口，并没有解析映射文件，所以进入注解解析方法parse之中会需要再尝试解析一次XML映射文件。 解析完成之后，还会对Mapper接口中的方法进行解析，并将每个方法的全限定类名作为key存入存入Configuration中的mappedStatements属性。 需要指出的是，这里存储的时候，同一个value会存储2次，**一个全限定名作为key，另一个就是只用方法名(sql语句的id)来作为key**： 所以最终mappedStatements会是下面的情况： 事实上如果我们通过接口的方式来编程的话，最后来getStatement的时候，都是根据全限定名来取的，所以即使有重名对我们也没有影响，而之所以要这么做的原因其实还是为了兼容早期版本的用法，那就是不通过接口，而是直接通过方法名的方式来进行查询： 1session.selectList(&quot;com.lonelyWolf.mybatis.mapper.UserMapper.listAllUser&quot;); 这里如果shortName没有重复的话，是可以直接通过简写来查询的： 1session.selectList(&quot;listAllUser&quot;); 但是通过简写来查询一旦shortName重复了就会抛出以下异常： 这里的异常其实就是StrickMap的get方法抛出来的： sql执行流程分析上面我们讲到了，获取到的Mapper接口实际上被包装成为了代理对象，所以我们执行查询语句肯定是执行的代理对象方法，接下来我们就以Mapper接口的代理对象MapperProxy来分析一下查询流程。 整个sql执行流程可以分为两大步骤： 一、寻找sql 二、执行sql语句 寻找sql首先还是来看一下寻找sql语句的时序图： 1、了解代理模式的应该都知道，调用被代理对象的方法之后实际上执行的就是代理对象的invoke方法 2、因为我们这里并没有调用Object类中的方法，所以肯定走的else。else中会继续调用MapperProxy内部类MapperMethodInvoker中的方法cachedInvoker，这里面会有一个判断，判断一下我们是不是default方法，因为Jdk1.8中接口中可以新增default方法，而default方法是并不是一个抽象方法，所以也需要特殊处理（刚开始会从缓存里面取，缓存相关知识我们这里先不讲，后面会单独写一篇来分析一下缓存)）。 3、接下来，是构造一个MapperMethod对象,这个对象封装了Mapper接口中对应的方法信息以及对应的sql语句信息： 这里面就会把要执行的sql语句，请求参数，方法返回值全部解析封装成MapperMethod对象，然后后面就可以开始准备执行sql语句了 执行sql语句还是先来看一下执行Sql语句的时序图： 1、我们继续上面的流程进入execute方法： 2、这里面会根据语句类型以及返回值类型来决定如何执行，本人这里返回的是一个集合，故而我们进入executeForMany方法： 3、这里面首先会将前面存好的参数进行一次转换，然后绕了这么一圈，回到了起点SqlSession对象，继续调用selectList方法： 3、接下来又讲流程委派给了Execute去执行query方法，最终又会去调用queryFromDatabase方法： 4、到这里之后，终于要进入正题了，一般带了这种do开头的方法就是真正做事的，Spring中很多地方也是采用的这种命名方式： 注意，前面我们的sql语句还是占位符的方式，并没有将参数设置进去，所以这里在return上面一行调用prepareStatement方法创建Statement对象的时候会去设置参数，替换占位符。参数如何设置我们先跳过，等把流程执行完了我们在单独分析参数映射和结果集映射。 5、继续进入PreparedStatementHandler对象的query方法，可以看到，这一步就是调用了jdbc操作对象PreparedStatement中的execute方法，最后一步就是转换结果集然后返回。 到这里，整个SQL语句执行流程分析就结束了，中途有一些参数的存储以及转换并没有深入进去，因为参数的转换并不是核心，只要清楚整个数据的流转流程，我们自己也可以有自己的实现方式，只要存起来最后我们能重新解析读出来就行。 参数映射现在我们来看一下上面在执行查询之前参数是如何进行设置的，我们先进入prepareStatement方法： 我们发现，最终是调用了StatementHandler中的parameterize进行参数设置，接下来这里为了节省篇幅，我们不会一步步点进去，直接进入设置参数的方法： 上面的BaseTypeHandler是一个抽象类，setNonNullParameter并没有实现，都是交给子类去实现，而每一个子类就是对应了数据库的一种类型。下图中就是默认的一个子类StringTypeHandler，里面没什么其他逻辑，就是设置参数。 可以看到String里面调用了jdbc中的setString方法，而如果是int也会调用setInt方法。看到这些子类如果大家之前阅读过我前面讲的MyBatis参数配置，应该就很明显可以知道，这些子类就是系统默认提供的一些typeHandler。而这些默认的typeHandler会默认被注册并和Java对象进行绑定： 正是因为MyBatis中默认提供了常用数据类型的映射，所以我们写Sql的时候才可以省略参数映射关系，可以直接采用下面的方式，系统可以根据我们参数的类型，自动选择合适的typeHander进行映射： 1select user_id,user_name from lw_user where user_name=#&#123;userName&#125; 上面这条语句实际上和下面这条是等价的： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR&#125; 或者说我们可以直接指定typeHandler： 1select user_id,user_name from lw_user where user_name = #&#123;userName,jdbcType=VARCHAR,typeHandler=org.apache.ibatis.type.IntegerTypeHandler&#125; 这里因为我们配置了typeHandler，所以会优先以配置的typeHandler为主不会再去读取默认的映射，如果类型不匹配就会直接报错了： 看到这里很多人应该就知道了，如果我们自己自定义一个typeHandler，然后就可以配置成我们自己的自定义类。所以接下来就让我们看看如何自定义一个typeHandler 自定义typeHandler自定义typeHandler需要实现BaseTypeHandler接口，BaseTypeHandler有4个方法，包括结果集映射，为了节省篇幅，代码没有写上来： 1234567891011121314151617package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; 然后我们改写一下上面的查询语句： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125; 然后执行，可以看到，自定义的typeHandler生效了： 结果集映射接下来让我们看看结果集的映射，回到上面执行sql流程的最后一个方法： 1resultSetHandler.handleResultSets(ps) 结果集映射里面的逻辑相对来说还是挺复杂的，因为要考虑到非常多的情况，这里我们就不会去深究每一个细节，直接进入到正式解析结果集的代码，下面的5个代码片段就是一个简单的但是完整的解析流程： 从上面的代码片段我们也可以看到，实际上解析结果集还是很复杂的，就如我们上一篇介绍的复杂查询一样，一个查询可以不断嵌套其他查询，还有延迟加载等等一些复杂的特性的处理，所以逻辑分支是有很多，但是不管怎么处理，最后的核心还是上面的一套流程，最终还是会调用typeHandler来获取查询到的结果。 是的，你没猜错，这个就是上面我们映射参数的typeHandler，因为typeHandler里面不只是一个设置参数方法，还有获取结果集方法(上面设置参数的时候省略了)。 自定义typeHandler结果集所以说我们还是用上面那个MyTypeHandler 例子来重写一下取值方法(省略了设置参数方法)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; /** * 设置参数 */ @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;设置参数-&gt;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; /** * 根据列名获取结果 */ @Override public String getNullableResult(ResultSet resultSet, String columnName) throws SQLException &#123; System.out.println(&quot;根据columnName获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnName); &#125; /** * 根据列的下标来获取结果 */ @Override public String getNullableResult(ResultSet resultSet, int columnIndex) throws SQLException &#123; System.out.println(&quot;根据columnIndex获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnIndex); &#125; /** * 处理存储过程的结果集 */ @Override public String getNullableResult(CallableStatement callableStatement, int columnIndex) throws SQLException &#123; return callableStatement.getString(columnIndex); &#125;&#125; 改写Mapper映射文件配置： 12345678&lt;resultMap id=&quot;MyUserResultMap&quot; type=&quot;lwUser&quot;&gt; &lt;result column=&quot;user_id&quot; property=&quot;userId&quot; jdbcType=&quot;VARCHAR&quot; typeHandler=&quot;com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&quot; /&gt; &lt;result column=&quot;user_name&quot; property=&quot;userName&quot; jdbcType=&quot;VARCHAR&quot; /&gt;&lt;/resultMap&gt;&lt;select id=&quot;listUserByUserName&quot; parameterType=&quot;String&quot; resultMap=&quot;MyUserResultMap&quot;&gt; select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125;&lt;/select&gt; 执行之后输出如下： 因为我们属性上面只配置了一个属性，所以只输出了一次。 工作流程图上面介绍了代码的流转，可能绕来绕去有点晕，所以我们来画一个主要的对象之间流程图来更加清晰的展示一下MyBatis主要工作流程： 从上面的工作流程图上我们可以看到，SqlSession下面还有4大对象，这4大对象也很重要，后面学习拦截器的时候就是针对这4大对象进行的拦截，关于这4大对象的具体详情，我们下一篇文章再展开分析。 总结本文主要分析了MyBatis的SQL执行流程。在分析流程的过程中，我们也举例论证了如何自定义typeHandler来实现自定义的参数映射和结果集映射，不过MyBatis中提供的默认映射其实可以满足大部分的需求，如果我们对某些属性需要特殊处理，那么就可以采用自定义的typeHandler来实现，相信如果本文如果读懂了，以下几点大家应该至少会有一个清晰的认识： 1、Mapper接口和映射文件是如何进行绑定的 2、MyBatis中SQL语句的执行流程 3、自定义MyBatis中的参数设置处理器typeHandler 4、自定义MyBatis中结果集处理器typeHandler 当然，其中很多细节并没有提到，而看源码我们也并不需要追求每一行代码都能看懂，就比如我们一个稍微复杂一点的业务系统，即使我们是项目开发者如果某一个模块不是本人负责的，恐怕也很难搞清楚每一行代码的含义。所以对于MyBatis及其他框架的源码中也是一样，首先应该从大局入手，掌握整体流程和设计思想，然后如果对某些实现细节感兴趣，再深入进行了解。","tags":["MyBatis","框架"],"categories":["框架"]},{"title":"用“状态模式”代替if-else","path":"/2023/12/24/用“状态模式”代替if-else/","content":"简介 状态模式是行为型设计模式的一种。其设计理念是当对象的内部状态发生改变时，随之改变其行为。状态和行为之间是一一对应的。 该模式主要用于，对象的行为依赖于它的状态，并且其行为是随着状态的改变而切换时。 状态模式UML类图类图讲解 State：抽象状态接口（也可以定义成抽象类），该接口封装了所有状态所对应的行为。ConcreteStateA&#x2F;B：具体状态类，该类实现了抽象状态接口，会根据自身对应的状态来实现接口中定义的方法，还有另一个功能是指明如何过渡到下一个状态。Context：环境（上下文）角色，该类负责状态的切换，还持有一个State实例，代表当前环境所处状态。 案例讲解案例：通过状态模式来实现自助售卖机的功能。 状态接口12345678public interface State &#123; // 挑选商品 void choose(); // 付款 boolean payment(); // 分发商品 void dispenseCommodity();&#125; 挑选商品状态类123456789101112131415161718192021222324252627282930public class ChooseGoods implements State &#123; VendingMachine machine; public ChooseGoods(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; if (machine.getCount() &gt; 0) &#123; System.out.println(&quot;商品挑选成功，请及时付款！&quot;); machine.setState(machine.getPaymentState()); &#125; else &#123; System.out.println(&quot;很遗憾，商品售罄了！&quot;); machine.setState(machine.getEmptyState()); &#125; &#125; @Override public boolean payment() &#123; System.out.println(&quot;请先挑选商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先挑选商品！&quot;); &#125;&#125; 付款状态类12345678910111213141516171819202122232425262728293031public class PaymentState implements State &#123; VendingMachine machine; public PaymentState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;商品已选购完成请勿重复挑选&quot;); &#125; @Override public boolean payment() &#123; Random random = new Random(); int num = random.nextInt(10); if(num % 2 == 0)&#123; System.out.println(&quot;付款成功！&quot;); machine.setState(machine.getDispenseCommodityState()); return true; &#125; System.out.println(&quot;付款失败，请重新支付！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先完成支付！&quot;); &#125;&#125; 商品售罄状态类123456789101112131415161718192021222324public class EmptyState implements State &#123; VendingMachine machine; public EmptyState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125;&#125; 分发商品状态类12345678910111213141516171819202122232425public class DispenseCommodityState implements State &#123; VendingMachine machine; public DispenseCommodityState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); machine.setState(machine.getChooseGoods()); &#125;&#125; 自动售货机 &#x3D;&gt; Context角色123456789101112131415161718192021222324252627282930313233public class VendingMachine &#123; // 表示当前状态 private State state = null; // 商品数量 private int count = 0; private State chooseGoods = new ChooseGoods(this); private State paymentState = new PaymentState(this); private State dispenseCommodityState = new DispenseCommodityState(this); private State emptyState = new EmptyState(this); public VendingMachine(int count) &#123; this.count = count; this.state = this.getChooseGoods(); &#125; // 购买商品 public void purchase() &#123; // 挑选商品 state.choose(); // 支付成功 if (state.payment()) &#123; // 分发商品 state.dispenseCommodity(); &#125; &#125; // 获取商品后将商品减一 public int getCount() &#123; return count--; &#125; // get和set方法 ... &#125; 客户端测试类12345678910public class Client &#123; public static void main(String[] args) &#123; VendingMachine machine = new VendingMachine(1); for (int i = 1; i &lt; 4; i++) &#123; System.out.println(&quot;第&quot; + i + &quot;次购买。&quot;); machine.purchase(); &#125; &#125;&#125; 执行结果总结1、状态模式将每个状态所对应的行为封装到一个类中，大大提高了代码的可读性。并且通过这样的设计还可以消除多余的if-else语句，方便代码的维护。 2、状态模式符合“开闭原则”，容易增加和删除状态。 3、任何事情都有利弊，状态模式也不例外。其最显著的问题是，每个状态都要对应一个类，当状态过多时会产生大量的类，从而加大维护成本。 4、应用场景：当一个需求有很多状态，并且状态之间会进行转换，不同状态还对应不同的行为时就可以考虑使用“状态模式”。","tags":["设计模式"],"categories":["设计模式"]},{"title":"Google 开源的 Guava 工具库","path":"/2023/12/24/Google-开源的-Guava-工具库/","content":"目前Google Guava在实际应用中非常广泛，本篇博客将以博主对Guava使用的认识以及在项目中的经验来给大家分享！正如标题所言，学习使用Google Guava可以让你快乐编程，写出优雅的JAVA代码！ 以面向对象思想处理字符串:Joiner&#x2F;Splitter&#x2F;CharMatcher JDK提供的String还不够好么？ 也许还不够友好，至少让我们用起来还不够爽，还得操心！ 举个栗子，比如String提供的split方法，我们得关心空字符串吧，还得考虑返回的结果中存在null元素吧，只提供了前后trim的方法（如果我想对中间元素进行trim呢）。 那么，看下面的代码示例，guava让你不必在操心这些： 123456789101112131415// 连接器private static final Joiner joiner = Joiner.on(&quot;,&quot;).skipNulls();// 分割器private static final Splitter splitter = Splitter.on(&quot;,&quot;).trimResults().omitEmptyStrings();public static void main(String[] args) &#123; // 把集合/数组中的元素 join 在一起 String join = joiner.join(Lists.newArrayList(&quot;a&quot;, null, &quot;b&quot;)); System.out.println(&quot;join=&quot; + join); for(String tmp : splitter.split(&quot;a, ,b,,&quot;)) &#123; System.out.println(&quot;|&quot; + tmp + &quot;|&quot;); &#125;&#125; Joiner&#x2F;Splitter Joiner是连接器，Splitter是分割器，通常我们会把它们定义为static final，利用on生成对象后在应用到String进行处理，这是可以复用的。要知道apache commons StringUtils提供的都是static method。 更加重要的是，guava提供的Joiner&#x2F;Splitter是经过充分测试，它的稳定性和效率要比apache高出不少，这个你可以自行测试下~ 发现没有我们想对String做什么操作，就是生成自己定制化的Joiner&#x2F;Splitter，多么直白，简单，流畅的API！ 对于Joiner，常用的方法是 跳过NULL元素：skipNulls() &#x2F; 对于NULL元素使用其他替代：useForNull(String) 对于Splitter，常用的方法是：trimResults()&#x2F;omitEmptyStrings()。注意拆分的方式，有字符串，还有正则，还有固定长度分割（太贴心了！） 其实除了Joiner&#x2F;Splitter外，guava还提供了字符串匹配器：CharMatcher 123456789101112private static final CharMatcher charMatcherDigit = CharMatcher.DIGIT;private static final Charmatcher charMatcherAny = CharMatcher.ANY;public static void main(String[] args) &#123; // 只保留匹配的字符，其他移除 System.out.println(charMatcherDigit.retainFrom(&quot;abc2def134f~&quot;)); // 移除匹配的字符 System.out.println(charMatcherDigit.removeFrom(&quot;yes,i love you 1314&quot;)); System.out.println(charMatcherAny.inRange(&#x27;a&#x27;, &#x27;f&#x27;).or(charMatcherAny.is(&#x27;a&#x27;)).replaceFrom(&quot;abcdefg&quot;,&quot;*&quot;));&#125; CharMatcher CharMatcher，将字符的匹配和处理解耦，并提供丰富的方法供你使用！ 对基本类型进行支持 guava对JDK提供的原生类型操作进行了扩展，使得功能更加强大！ 1234567891011121314151617// 快速完成到集合的转换List&lt;Integer&gt; list = Ints.asList(1, 3, 5, 7, 9);System.out.println(Ints.join(&quot;,&quot;, 1, 3, 1, 4));// 原生类型数据快速合并int[] newIntArray = Ints.concat(new int[]&#123;1, 2&#125;, new int[]&#123;2, 3, 4&#125;);System.out.println(newIntArray.length);// 最大/最小System.out.println(Ints.max(newIntArray) + &quot;,&quot; + Ints.min(newIntArray));// 是否包含System.out.println(Ints.contains(newArray, 6));// 集合到数组的转换int[] someArray = Ints.toArray(list); Ints guava提供了 Bytes&#x2F;Shorts&#x2F;Ints&#x2F;Iongs&#x2F;Floats&#x2F;Doubles&#x2F;Chars&#x2F;Booleans 这些基本数据类型的扩展支持，只有你想不到的，没有它没有的！ 对JDK集合的有效补充灰色地带:Multiset JDK的集合，提供了有序且可以重复的List，无序且不可以重复的Set。那这里其实对于集合涉及到了2个概念，一个order，一个dups。那么List vs Set，and then some ? Multiset Multiset是什么，我想上面的图，你应该了解它的概念了。Multiset就是无序的，但是可以重复的集合，它就是游离在List&#x2F;Set之间的“灰色地带”！（至于有序的，不允许重复的集合嘛，guava还没有提供，当然在未来应该会提供UniqueList，我猜的，哈哈） 来看一个Multiset的示例： 12345678910Multiset&lt;String&gt; multiset = HashMultiset.create();multiset.add(&quot;a&quot;);multiset.add(&quot;a&quot;);multiset.add(&quot;b&quot;);multiset.add(&quot;c&quot;);multiset.add(&quot;b&quot;);System.out.println(multiset.size());System.out.println(multiset.count(&quot;a&quot;)); Multiset Code Multiset自带一个有用的功能，就是可以跟踪每个对象的数量。 Immutable vs unmodifiable来我们先看一个unmodifiable的例子： 1234567891011121314// List 的不可变设置List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// 这种视图，不够安全，不是真正意义上的快照，怎么能随着而变化呢？List&lt;String&gt; readOnlyList = Collections.unmodifiableList(list);// readOnlyList.add(&quot;c&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionlist.acc(&quot;c&quot;);System.out.println(reaOnlyList.size()); // 3 unmodifiable 你看到JDK提供的unmodifiable的缺陷了吗？ 实际上，Collections.unmodifiableXxx所返回的集合和源集合是同一个对象，只不过可以对集合做出改变的API都被override，会抛出UnsupportedOperationException。 也即是说我们改变源集合，导致不可变视图（unmodifiable View）也会发生变化，oh my god! 当然，在不使用guava的情况下，我们是怎么避免上面的问题的呢？ 1234567// List 的不可变性设置List&lt;String&gt; list = new ArrayList&lt;~&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// new Object ; CopyList&lt;String&gt; readOnList = Collections.unmodifiableList(new ArrayList&lt;String&gt;(list)); defensive copies 上面揭示了一个概念：Defensive Copies，保护性拷贝。 OK，unmodifiable看上去没有问题呢，但是guava依然觉得可以改进，于是提出了Immutable的概念，来看： 12345678910// guava 是如何做的呢？List&lt;String&gt; immutable = ImmutabeList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);// immutable.add(&quot;d&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionList&lt;String&gt; immutable2 = ImmutableList.copyOf(list);list.add(&quot;d&quot;);// 视图不随着源而改变 guava 只读设置安全可靠 简单易用System.out.println(&quot;list size:&quot; + list.size() + &quot; immutable2.size:&quot; + immutables.size()); Immutable 就一个copyOf，你不会忘记，如此cheap~ 用Google官方的说法是：we’re using just one class,just say exactly what we mean，很了不起吗（不仅仅是个概念，Immutable在COPY阶段还考虑了线程的并发性等，很智能的！），O(∩_∩)O哈哈~ guava提供了很多Immutable集合，比如 ImmutableList&#x2F;ImmutableSet&#x2F;ImmutableSortedSet&#x2F;ImmutableMap&#x2F;…… 看一个ImmutableMap的例子： 123ImmutableMap&lt;String, String&gt; immutableMap = ImmutableMap.of(&quot;name&quot;, &quot;hubert&quot;, &quot;sex&quot;, &quot;man&quot;);immutableMap.put(&quot;wife&quot;, &quot;no...&quot;); // UnsupportedOperationException ImmutableMap 可不可以一对多：Multimap JDK提供给我们的Map是一个键，一个值，一对一的，那么在实际开发中，显然存在一个KEY多个VALUE的情况（比如一个分类下的书本），我们往往这样表达：Map&lt;k,List&lt;v&gt;&gt;，好像有点臃肿！臃肿也就算了，更加不爽的事，我们还得判断KEY是否存在来决定是否new 一个LIST出来，有点麻烦！更加麻烦的事情还在后头，比如遍历，比如删除，so hard…… 来看guava如何替你解决这个大麻烦的： 1234567Multimap&lt;String, String&gt; multiMap = ArrayListMultimap.create();multiMap.put(&quot;hubert&quot;, &quot;man&quot;);multiMap.put(&quot;hubert&quot;, &quot;yes&quot;);multiMap.put(&quot;lucy&quot;, &quot;woman&quot;);System.out.println(multiMap.get(&quot;hubert&quot;)); //collection Multimap 友情提示下，guava所有的集合都有create方法，这样的好处在于简单，而且我们不必在重复泛型信息了。 get()&#x2F;keys()&#x2F;keySet()&#x2F;values()&#x2F;entries()&#x2F;asMap()都是非常有用的返回view collection的方法。 Multimap的实现类有： ArrayListMultimap&#x2F;HashMultimap&#x2F;LinkedHashMultimap&#x2F;TreeMultimap&#x2F;ImmutableMultimap&#x2F;…… 可不可以双向：BiMap JDK提供的MAP让我们可以find value by key，那么能不能通过find key by value呢，能不能KEY和VALUE都是唯一的呢。这是一个双向的概念，即forward+backward。 在实际场景中有这样的需求吗？比如通过用户ID找到mail，也需要通过mail找回用户名。没有guava的时候，我们需要create forward map AND create backward map，and now just let guava do that for you. 12345678910111213BiMap&lt;String, String&gt; biMap = HashBiMap.create();biMap.put(&quot;name&quot;, &quot;hubert&quot;);// java.lang.IllegaArgumentException: value already present: hubert// value 重复会报错biMap.put(&quot;nick&quot;, &quot;hubert&quot;);// 强制覆盖 name:hubertbiMap.forcePut(&quot;nick&quot;, &quot;hubert&quot;);biMap.put(&quot;123&quot;, &quot;hubertwongcn@163.com&quot;);System.out.println(biMap.inverse().get(&quot;hubertwongcn@163.com&quot;)); // 123 BiMap biMap &#x2F; biMap.inverse() &#x2F; biMap.inverse().inverse() 它们是什么关系呢？ 你可以稍微看一下BiMap的源码实现，实际上，当你创建BiMap的时候，在内部维护了2个map，一个forward map，一个backward map，并且设置了它们之间的关系。 因此，biMap.inverse() !&#x3D; biMap ；biMap.inverse().inverse() &#x3D;&#x3D; biMap 可不可以多个KEY：Table 我们知道数据库除了主键外，还提供了复合索引，而且实际中这样的多级关系查找也是比较多的，当然我们可以利用嵌套的Map来实现：Map&lt;k1,Map&lt;k2,v2&gt;&gt;。为了让我们的代码看起来不那么丑陋，guava为我们提供了Table。 1234567Table&lt;String, String, Integer&gt; table = HashBaseTable.create();table.put(&quot;张三&quot;, &quot;计算机&quot;, 80);table.put(&quot;张三&quot;, &quot;数学&quot;, 90);table.put(&quot;张三&quot;, &quot;语文&quot;, 70);table.put(&quot;李四&quot;, &quot;计算机&quot;, 70);table.put(&quot;李四&quot;, &quot;数学&quot;, 60);table.put(&quot;李四&quot;, &quot;语文&quot;, 100); Table Table涉及到3个概念：rowKey,columnKey,value，并提供了多种视图以及操作方法让你更加轻松的处理多个KEY的场景。 函数式编程：Functions12345678910111213141516171819202122List&lt;String&gt; list = Lists.newArrayList(&quot;hello world&quot;, &quot;yes&quot;, &quot;hubert&quot;);Function&lt;String, String&gt; f1 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.length() &lt;= 5 ? s : s.substring(0, 5); &#125;&#125;;Function&lt;String, String&gt; f2 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.toUpperCase(); &#125;&#125;;Function&lt;String, String&gt; f3 = Functions.compose(f1, f2);Collection&lt;String&gt; collection = Collections2.transform(list, f3);for(String s : collection) &#123; System.out.println(s);&#125; Functions 上面的代码是为了完成将List集合中的元素，先截取5个长度，然后转成大写。 函数式编程的好处在于在集合遍历操作中提供自定义Function的操作，比如transform转换。我们再也不需要一遍遍的遍历集合，显著的简化了代码！ 12345678910Iterables.transform(Iterable, Function);Iterators.transform(Iterator, Function);Collections2.transform(Collection, Function);Lists.transform(List, Function);Maps.transformValues(Map, Function);Multimaps.transformValues(Multimap, Function);Multimaps.transformValues(ListMultimap, Funtion);Tables.transformValues(Table, Function);Maps.transformEntries(Map, EntryTransformer);// ... 对集合的transform操作可以通过Function完成 断言：Predicate12345678910111213List&lt;String&gt; list = Lists.newArrayList(&quot;moom&quot;, &quot;dad&quot;, &quot;refer&quot;, &quot;yes&quot;);Collection&lt;String&gt; collection = Collections2.filter(list, new Predicate&lt;String&gt;)) &#123; @Override public boolean apply(String s) &#123; // 业务逻辑 return new StringBuilder(s).reverse().toString().equals(s); &#125;&#125;;for(String s : collection) &#123; System.out.println(s);&#125; Predicate最常用的功能就是运用在集合的过滤当中！ 12345678Iterables.filter(Iterable, Predicate);Iterators.filter(Iterator, Predicate);Collectios2.filter(Collection, Predicate);Sets.filter(Set, Predicate);Sets.filter(SortedSet, Predicate);Maps.filterKeys(Map, Predicate);Multimaps.filterKeys(Multimap, Predicate);// ... filter 需要注意的是Lists并没有提供filter方法，不过你可以使用Collections2.filter完成！ check null and other：Optional、Preconditions在guava中，对于null的处理手段是快速失败，你可以看看guava的源码，很多方法的第一行就是：Preconditions.checkNotNull(elements); 要知道null是模糊的概念，是成功呢，还是失败呢，还是别的什么含义呢？ 12345678910111213public static void test(String name, int age, Map&lt;String, String&gt; extInfo) &#123; Preconditions.checkNotNull(name, &quot;name must be given!&quot;); Preconditions.checkArgument(age &gt;= 18, &quot;the game you can not play it, your age is under 18!&quot;); Map&lt;String, String&gt; defaulExtInfo = Maps.newHashMap(); defaultExtInfo.put(&quot;sex&quot;, &quot;man&quot;); extInfo = Optional.fromNullable(extInfo).or(defaultExtInfo); for(Map.Entry&lt;String, Stirng&gt; entry : extInfo.entrySet())) &#123; System.out.println(entry.getKey() + &quot;:&quot; + entry.getValue()); &#125;&#125; Preconditions&#x2F;Optional Cache is king 对于大多数互联网项目而言，缓存的重要性，不言而喻！ 如果我们的应用系统，并不想使用一些第三方缓存组件（如redis），我们仅仅想在本地有一个功能足够强大的缓存，很可惜JDK提供的那些SET&#x2F;MAP还不行！ 12345678910111213141516171819202122232425// 定义缓存的实现private static final CacheLoader&lt;Long, User&gt; userCacheLoader = new CacheLoader&lt;Long, User&gt;() &#123; @Override public User load(Long along) throws Exception &#123; // 模拟从数据库/Redis/缓存中加载数据 User user = new User(); user.setId(along); user.setName(Thread.currentThread().getName() + &quot;-&quot; new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;).format(new Date()) + &quot;-&quot; + along); System.out.println(&quot;load:&quot; + user); return user; &#125;&#125;;// 定义缓存的策略，提供对外访问缓存private static final LoadingCache&lt;Long, User&gt; userCacheData = CacheBuilder.newBuilder() .expireAfterAccess(2, TimeUnit.SECONDS) .expireAfterWrite(2, TimeUnit.SECONDS) .refreshAfterWrite(3, TimeUnit.SECONS) .maximumSize(10000L) .bulid(userCacheLoader); CacheLoader 首先，这是一个本地缓存，guava提供的cache是一个简洁、高效，易于维护的。为什么这么说呢？因为并没有一个单独的线程用于刷新 OR 清理cache，对于cache的操作，都是通过访问&#x2F;读写带来的，也就是说在读写中完成缓存的刷新操作！ 其次，我们看到了，我们非常通俗的告诉cache，我们的缓存策略是什么，SO EASY！在如此简单的背后，是guava帮助我们做了很多事情，比如线程安全。 让异步回调更加简单 JDK中提供了Future&#x2F;FutureTask&#x2F;Callable来对异步回调进行支持，但是还是看上去挺复杂的，能不能更加简单呢？比如注册一个监听回调。 12345678910111213141516171819202122232425262728// JDK 所提供的线程池ExecutorService es = Executors.newFixedThreadPool(3);// 经过guava封装的带有监听回调功能的线程池ListeningExecutorService listeningExecutorService = MoreExecutors.listeningDecorator(es);ListenableFuture listenableFuture = listeningExecutorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; if (new Random().nextInt(3) == 2) &#123; throw new NullPointerException(); &#125; return 1; &#125;&#125;);FutureCallback futureCallback = new FutureCallback&lt;Integer&gt; &#123; @Override public void onSuccess(final Integer o) &#123; System.out.println(&quot;------&quot; + o); &#125; @Override public void onFailure(final Throwable throwable) &#123; System.out.println(&quot;======&quot; + throwable.getMessage()); &#125;&#125;;Futures.addCallback(listenableFuture, futureCallback); 异步回调 我们可以通过guava对JDK提供的线程池进行装饰，让其具有异步回调监听功能，然后在设置监听器即可！ Summary到这里，这篇文章也只介绍了guava的冰山一角，其实还有很多内容： guava package 比如反射、注解、网络、并发、IO等等","tags":["工具","开源","Google"],"categories":["工具"]}]