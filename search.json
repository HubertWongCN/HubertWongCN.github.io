[{"title":"SQL优化最干货总结","path":"/2023/12/25/SQL优化最干货总结/","content":"前言BATJTMD等大厂的面试难度越来越高，但无论从大厂还是到小公司，一直未变的一个重点就是对SQL优化经验的考察。一提到数据库，先“说一说你对SQL优化的见解吧？”。 SQL优化已经成为衡量程序猿优秀与否的硬性指标，甚至在各大厂招聘岗位职能上都有明码标注，如果是你，在这个问题上能吊打面试官还是会被吊打呢？ 目录 前言 SELECT语句 - 语法顺序： SELECT语句 - 执行顺序： SQL优化策略 一、避免不走索引的场景 二、SELECT语句其他优化 三、增删改 DML 语句优化 四、查询条件优化 五、建表优化 有朋友疑问到，SQL优化真的有这么重要么？如下图所示，SQL优化在提升系统性能中是：（成本最低 &amp;&amp; 优化效果最明显） 的途径。如果你的团队在SQL优化这方面搞得很优秀，对你们整个大型系统可用性方面无疑是一个质的跨越，真的能让你们老板省下不止几沓子钱。 优化成本：硬件&gt;系统配置&gt;数据库表结构&gt;SQL及索引。 优化效果：硬件&lt;系统配置&lt;数据库表结构&lt;SQL及索引。 123456789101112131415String result = &quot;嗯，不错，&quot;; if (&quot;SQL优化经验足&quot;) &#123; if (&quot;熟悉事务锁&quot;) &#123; if (&quot;并发场景处理666&quot;) &#123; if (&quot;会打王者荣耀&quot;) &#123; result += &quot;明天入职&quot; &#125; &#125; &#125;&#125; else &#123; result += &quot;先回去等消息吧&quot;;&#125; Logger.info(&quot;面试官：&quot; + result ); 别看了，上面这是一道送命题。 好了我们言归正传，首先，对于MySQL层优化我一般遵从五个原则： 减少数据访问：设置合理的字段类型，启用压缩，通过索引访问等减少磁盘IO 返回更少的数据：只返回需要的字段和数据分页处理 减少磁盘io及网络io 减少交互次数：批量DML操作，函数存储等减少数据连接次数 减少服务器CPU开销：尽量减少数据库排序操作以及全表查询，减少cpu 内存占用 利用更多资源：使用表分区，可以增加并行操作，更大限度利用cpu资源 总结到SQL优化中，就三点: 最大化利用索引； 尽可能避免全表扫描； 减少无效数据的查询； 理解SQL优化原理 ，首先要搞清楚SQL执行顺序： SELECT语句 - 语法顺序：123456789101. SELECT 2. DISTINCT &lt;select_list&gt;3. FROM &lt;left_table&gt;4. &lt;join_type&gt; JOIN &lt;right_table&gt;5. ON &lt;join_condition&gt;6. WHERE &lt;where_condition&gt;7. GROUP BY &lt;group_by_list&gt;8. HAVING &lt;having_condition&gt;9. ORDER BY &lt;order_by_condition&gt;10.LIMIT &lt;limit_number&gt; SELECT语句 - 执行顺序： FROM&lt;表名&gt; # 选取表，将多个表数据通过笛卡尔积变成一个表。ON&lt;筛选条件&gt; # 对笛卡尔积的虚表进行筛选JOIN &lt;join, left join, right join…&gt;&lt;join表&gt; # 指定join，用于添加数据到on之后的虚表中，例如left join会将左表的剩余数据添加到虚表中WHERE&lt;where条件&gt; # 对上述虚表进行筛选GROUP BY&lt;分组条件&gt; # 分组&lt;SUM()等聚合函数&gt; # 用于having子句进行判断，在书写上这类聚合函数是写在having判断里面的HAVING&lt;分组筛选&gt; # 对分组后的结果进行聚合筛选SELECT&lt;返回数据列表&gt; # 返回的单列必须在group by子句中，聚合函数除外DISTINCT# 数据除重ORDER BY&lt;排序条件&gt; # 排序LIMIT&lt;行数限制&gt; SQL优化策略 声明：以下SQL优化策略适用于数据量较大的场景下，如果数据量较小，没必要以此为准，以免画蛇添足。 一、避免不走索引的场景1. 尽量避免在字段开头模糊查询，会导致数据库引擎放弃索引进行全表扫描。如下： 1SELECT * FROM t WHERE username LIKE &#x27;%陈%&#x27; 优化方式：尽量在字段后面使用模糊查询。如下： 1SELECT * FROM t WHERE username LIKE &#x27;陈%&#x27; 如果需求是要在前面使用模糊查询， 使用MySQL内置函数INSTR(str,substr) 来匹配，作用类似于java中的indexOf()，查询字符串出现的角标位置 使用FullText全文索引，用match against 检索 数据量较大的情况，建议引用ElasticSearch、solr，亿级数据量检索速度秒级 当表数据量较少（几千条儿那种），别整花里胡哨的，直接用like ‘%xx%’。 2. 尽量避免使用in 和not in，会导致引擎走全表扫描。如下： 1SELECT * FROM t WHERE id IN (2,3) 优化方式：如果是连续数值，可以用between代替。如下： 1SELECT * FROM t WHERE id BETWEEN 2 AND 3 如果是子查询，可以用exists代替。如下： 1234-- 不走索引select * from A where A.id in (select id from B);-- 走索引select * from A where exists (select * from B where B.id = A.id); 3. 尽量避免使用 or，会导致数据库引擎放弃索引进行全表扫描。如下： 1SELECT * FROM t WHERE id = 1 OR id = 3 优化方式：可以用union代替or。如下： 123SELECT * FROM t WHERE id = 1 UNIONSELECT * FROM t WHERE id = 3 4. 尽量避免进行null值的判断，会导致数据库引擎放弃索引进行全表扫描。如下： 1SELECT * FROM t WHERE score IS NULL 优化方式：可以给字段添加默认值0，对0值进行判断。如下： 1SELECT * FROM t WHERE score = 0 5.尽量避免在where条件中等号的左侧进行表达式、函数操作，会导致数据库引擎放弃索引进行全表扫描。可以将表达式、函数操作移动到等号右侧。如下： 1234-- 全表扫描SELECT * FROM T WHERE score/10 = 9-- 走索引SELECT * FROM T WHERE score = 10*9 6. 当数据量大时，避免使用where 1&#x3D;1的条件。通常为了方便拼装查询条件，我们会默认使用该条件，数据库引擎会放弃索引进行全表扫描。如下： 1SELECT username, age, sex FROM T WHERE 1=1 优化方式：用代码拼装sql时进行判断，没 where 条件就去掉 where，有where条件就加 and。 7. 查询条件不能用 &lt;&gt; 或者 !&#x3D;使用索引列作为条件进行查询时，需要避免使用&lt;&gt;或者!&#x3D;等判断条件。如确实业务需要，使用到不等于符号，需要在重新评估索引建立，避免在此字段上建立索引，改由查询条件中其他索引字段代替。 8. where条件仅包含复合索引非前置列如下：复合（联合）索引包含key_part1，key_part2，key_part3三列，但SQL语句没有包含索引前置列”key_part1”，按照MySQL联合索引的最左匹配原则，不会走联合索引。 1select col1 from table where key_part2=1 and key_part3=2 9. 隐式类型转换造成不使用索引如下SQL语句由于索引对列类型为varchar，但给定的值为数值，涉及隐式类型转换，造成不能正确走索引。 1select col1 from table where col_varchar=123; 10. order by 条件要与where中条件一致，否则order by不会利用索引进行排序12345-- 不走age索引SELECT * FROM t order by age; -- 走age索引SELECT * FROM t where age &gt; 0 order by age; 对于上面的语句，数据库的处理顺序是： 第一步：根据where条件和统计信息生成执行计划，得到数据。 第二步：将得到的数据排序。当执行处理数据（order by）时，数据库会先查看第一步的执行计划，看order by 的字段是否在执行计划中利用了索引。如果是，则可以利用索引顺序而直接取得已经排好序的数据。如果不是，则重新进行排序操作。 第三步：返回排序后的数据。 当order by 中的字段出现在where条件中时，才会利用索引而不再二次排序，更准确的说，order by 中的字段在执行计划中利用了索引时，不用排序操作。 这个结论不仅对order by有效，对其他需要排序的操作也有效。比如group by 、union 、distinct等。 11. 正确使用hint优化语句MySQL中可以使用hint指定优化器在执行时选择或忽略特定的索引。一般而言，处于版本变更带来的表结构索引变化，更建议避免使用hint，而是通过Analyze table多收集统计信息。但在特定场合下，指定hint可以排除其他索引干扰而指定更优的执行计划。 USE INDEX 在你查询语句中表名的后面，添加 USE INDEX 来提供希望 MySQL 去参考的索引列表，就可以让 MySQL 不再考虑其他可用的索引。例子: SELECT col1 FROM table USE INDEX (mod_time, name)… IGNORE INDEX 如果只是单纯的想让 MySQL 忽略一个或者多个索引，可以使用 IGNORE INDEX 作为 Hint。例子: SELECT col1 FROM table IGNORE INDEX (priority) … FORCE INDEX 为强制 MySQL 使用一个特定的索引，可在查询中使用FORCE INDEX 作为Hint。例子: SELECT col1 FROM table FORCE INDEX (mod_time) … 在查询的时候，数据库系统会自动分析查询语句，并选择一个最合适的索引。但是很多时候，数据库系统的查询优化器并不一定总是能使用最优索引。如果我们知道如何选择索引，可以使用FORCE INDEX强制查询使用指定的索引。 例如： 1SELECT * FROM students FORCE INDEX (idx_class_id) WHERE class_id = 1 ORDER BY id DESC; 二、SELECT语句其他优化**1. 避免出现select **首先，select * 操作在任何类型数据库中都不是一个好的SQL编写习惯。 使用select * 取出全部列，会让优化器无法完成索引覆盖扫描这类优化，会影响优化器对执行计划的选择，也会增加网络带宽消耗，更会带来额外的I&#x2F;O,内存和CPU消耗。 建议提出业务实际需要的列数，将指定列名以取代select *。 2. 避免出现不确定结果的函数特定针对主从复制这类业务场景。由于原理上从库复制的是主库执行的语句，使用如now()、rand()、sysdate()、current_user()等不确定结果的函数很容易导致主库与从库相应的数据不一致。另外不确定值的函数,产生的SQL语句无法利用query cache。 3.多表关联查询时，小表在前，大表在后。在MySQL中，执行 from 后的表关联查询是从左往右执行的（Oracle相反），第一张表会涉及到全表扫描，所以将小表放在前面，先扫小表，扫描快效率较高，在扫描后面的大表，或许只扫描大表的前100行就符合返回条件并return了。 例如：表1有50条数据，表2有30亿条数据；如果全表扫描表2，你品，那就先去吃个饭再说吧是吧。 4. 使用表的别名当在SQL语句中连接多个表时，请使用表的别名并把别名前缀于每个列名上。这样就可以减少解析的时间并减少哪些友列名歧义引起的语法错误。 5. 用where字句替换HAVING字句避免使用HAVING字句，因为HAVING只会在检索出所有记录之后才对结果集进行过滤，而where则是在聚合前刷选记录，如果能通过where字句限制记录的数目，那就能减少这方面的开销。HAVING中的条件一般用于聚合函数的过滤，除此之外，应该将条件写在where字句中。 where和having的区别：where后面不能使用组函数 6.调整Where字句中的连接顺序MySQL采用从左往右，自上而下的顺序解析where子句。根据这个原理，应将过滤数据多的条件往前放，最快速度缩小结果集。 三、增删改 DML 语句优化1. 大批量插入数据如果同时执行大量的插入，建议使用多个值的INSERT语句(方法二)。这比使用分开INSERT语句快（方法一），一般情况下批量插入效率有几倍的差别。 方法一： 12345insert into T values(1,2); insert into T values(1,3); insert into T values(1,4); 方法二： 1Insert into T values(1,2),(1,3),(1,4); 选择后一种方法的原因有三。 减少SQL语句解析的操作，MySQL没有类似Oracle的share pool，采用方法二，只需要解析一次就能进行数据的插入操作； 在特定场景可以减少对DB连接次数 SQL语句较短，可以减少网络传输的IO。 2. 适当使用commit适当使用commit可以释放事务占用的资源而减少消耗，commit后能释放的资源如下： 事务占用的undo数据块； 事务在redo log中记录的数据块； 释放事务施加的，减少锁争用影响性能。特别是在需要使用delete删除大量数据的时候，必须分解删除量并定期commit。 3. 避免重复查询更新的数据针对业务中经常出现的更新行同时又希望获得改行信息的需求，MySQL并不支持PostgreSQL那样的UPDATE RETURNING语法，在MySQL中可以通过变量实现。 例如，更新一行记录的时间戳，同时希望查询当前记录中存放的时间戳是什么，简单方法实现： 123Update t1 set time=now() where col1=1; Select time from t1 where id =1; 使用变量，可以重写为以下方式： 123Update t1 set time=now () where col1=1 and @now: = now (); Select @now; 前后二者都需要两次网络来回，但使用变量避免了再次访问数据表，特别是当t1表数据量较大时，后者比前者快很多。 4.查询优先还是更新（insert、update、delete）优先MySQL 还允许改变语句调度的优先级，它可以使来自多个客户端的查询更好地协作，这样单个客户端就不会由于锁定而等待很长时间。改变优先级还可以确保特定类型的查询被处理得更快。我们首先应该确定应用的类型，判断应用是以查询为主还是以更新为主的，是确保查询效率还是确保更新的效率，决定是查询优先还是更新优先。 下面我们提到的改变调度策略的方法主要是针对只存在表锁的存储引擎，比如 MyISAM 、MEMROY、MERGE，对于Innodb 存储引擎，语句的执行是由获得行锁的顺序决定的。MySQL 的默认的调度策略可用总结如下： 1）写入操作优先于读取操作。 2）对某张数据表的写入操作某一时刻只能发生一次，写入请求按照它们到达的次序来处理。 3）对某张数据表的多个读取操作可以同时地进行。MySQL 提供了几个语句调节符，允许你修改它的调度策略： LOW_PRIORITY关键字应用于DELETE、INSERT、LOAD DATA、REPLACE和UPDATE； HIGH_PRIORITY关键字应用于SELECT和INSERT语句； DELAYED关键字应用于INSERT和REPLACE语句。 如果写入操作是一个 LOW_PRIORITY（低优先级）请求，那么系统就不会认为它的优先级高于读取操作。在这种情况下，如果写入者在等待的时候，第二个读取者到达了，那么就允许第二个读取者插到写入者之前。只有在没有其它的读取者的时候，才允许写入者开始操作。这种调度修改可能存在 LOW_PRIORITY写入操作永远被阻塞的情况。 SELECT 查询的HIGH_PRIORITY（高优先级）关键字也类似。它允许SELECT 插入正在等待的写入操作之前，即使在正常情况下写入操作的优先级更高。另外一种影响是，高优先级的 SELECT 在正常的 SELECT 语句之前执行，因为这些语句会被写入操作阻塞。如果希望所有支持LOW_PRIORITY 选项的语句都默认地按照低优先级来处理，那么 请使用–low-priority-updates 选项来启动服务器。通过使用 INSERTHIGH_PRIORITY 来把 INSERT 语句提高到正常的写入优先级，可以消除该选项对单个INSERT语句的影响。 四、查询条件优化1. 对于复杂的查询，可以使用中间临时表 暂存数据2. 优化group by语句默认情况下，MySQL 会对GROUP BY分组的所有值进行排序，如 “GROUP BY col1，col2，….;” 查询的方法如同在查询中指定 “ORDER BY col1，col2，…;” 如果显式包括一个包含相同的列的 ORDER BY子句，MySQL 可以毫不减速地对它进行优化，尽管仍然进行排序。 因此，如果查询包括 GROUP BY 但你并不想对分组的值进行排序，你可以指定 ORDER BY NULL禁止排序。例如： 1SELECT col1, col2, COUNT(*) FROM table GROUP BY col1, col2 ORDER BY NULL ; 3. 优化join语句MySQL中可以通过子查询来使用 SELECT 语句来创建一个单列的查询结果，然后把这个结果作为过滤条件用在另一个查询中。使用子查询可以一次性的完成很多逻辑上需要多个步骤才能完成的 SQL 操作，同时也可以避免事务或者表锁死，并且写起来也很容易。但是，有些情况下，子查询可以被更有效率的连接(JOIN)..替代。 例子：假设要将所有没有订单记录的用户取出来，可以用下面这个查询完成： 1SELECT col1 FROM customerinfo WHERE CustomerID NOT in (SELECT CustomerID FROM salesinfo ) 如果使用连接(JOIN).. 来完成这个查询工作，速度将会有所提升。尤其是当 salesinfo表中对 CustomerID 建有索引的话，性能将会更好，查询如下： 123SELECT col1 FROM customerinfo LEFT JOIN salesinfoON customerinfo.CustomerID=salesinfo.CustomerID WHERE salesinfo.CustomerID IS NULL 连接(JOIN).. 之所以更有效率一些，是因为 MySQL 不需要在内存中创建临时表来完成这个逻辑上的需要两个步骤的查询工作。 4. 优化union查询MySQL通过创建并填充临时表的方式来执行union查询。除非确实要消除重复的行，否则建议使用union all。原因在于如果没有all这个关键词，MySQL会给临时表加上distinct选项，这会导致对整个临时表的数据做唯一性校验，这样做的消耗相当高。 高效： 12345SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION ALL SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= &#x27;TEST&#x27;; 低效： 12345SELECT COL1, COL2, COL3 FROM TABLE WHERE COL1 = 10 UNION SELECT COL1, COL2, COL3 FROM TABLE WHERE COL3= &#x27;TEST&#x27;; 5.拆分复杂SQL为多个小SQL，避免大事务 简单的SQL容易使用到MySQL的QUERY CACHE； 减少锁表时间特别是使用MyISAM存储引擎的表； 可以使用多核CPU。 6. 使用truncate代替delete当删除全表中记录时，使用delete语句的操作会被记录到undo块中，删除记录也记录binlog，当确认需要删除全表时，会产生很大量的binlog并占用大量的undo数据块，此时既没有很好的效率也占用了大量的资源。 使用truncate替代，不会记录可恢复的信息，数据不能被恢复。也因此使用truncate操作有其极少的资源占用与极快的时间。另外，使用truncate可以回收表的水位，使自增字段值归零。 7. 使用合理的分页方式以提高分页效率使用合理的分页方式以提高分页效率 针对展现等分页需求，合适的分页方式能够提高分页的效率。 案例1： 12select * from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15; 上述例子通过一次性根据过滤条件取出所有字段进行排序返回。数据访问开销&#x3D;索引IO+索引全部记录结果对应的表数据IO。因此，该种写法越翻到后面执行效率越差，时间越长，尤其表数据量很大的时候。 适用场景：当中间结果集很小（10000行以下）或者查询条件复杂（指涉及多个不同查询字段或者多表连接）时适用。 案例2： 123select t.* from (select id from t where thread_id = 10000 and deleted = 0 order by gmt_create asc limit 0, 15) a, t where a.id = t.id; 上述例子必须满足t表主键是id列，且有覆盖索引secondary key:(thread_id, deleted, gmt_create)。通过先根据过滤条件利用覆盖索引取出主键id进行排序，再进行join操作取出其他字段。数据访问开销&#x3D;索引IO+索引分页后结果（例子中是15行）对应的表数据IO。因此，该写法每次翻页消耗的资源和时间都基本相同，就像翻第一页一样。 适用场景：当查询和排序字段（即where子句和order by子句涉及的字段）有对应覆盖索引时，且中间结果集很大的情况时适用。 五、建表优化1. 在表中建立索引，优先考虑where、order by使用到的字段。2. 尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。 这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。 3. 查询数据量大的表 会造成查询缓慢。主要的原因是扫描行数过多。这个时候可以通过程序，分段分页进行查询，循环遍历，将结果合并处理进行展示。要查询100000到100050的数据，如下： 12SELECT * FROM (SELECT ROW_NUMBER() OVER(ORDER BY ID ASC) AS rowid,* FROM infoTab)t WHERE t.rowid &gt; 100000 AND t.rowid &lt;= 100050 4. 用varchar&#x2F;nvarchar 代替 char&#x2F;nchar尽可能的使用 varchar&#x2F;nvarchar 代替 char&#x2F;nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。 不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。","tags":["MySQL","DataBase","SQL优化"],"categories":["DataBase"]},{"title":"TCP/IP简述","path":"/2023/12/25/TCP-IP简述/","content":"一、TCP&#x2F;IP模型TCP&#x2F;IP协议模型（Transmission Control Protocol&#x2F;Internet Protocol），包含了一系列构成互联网基础的网络协议，是Internet的核心协议。 基于TCP&#x2F;IP的参考模型将协议分成四个层次，它们分别是链路层、网络层、传输层和应用层。下图表示TCP&#x2F;IP模型与OSI模型各层的对照关系。 TCP&#x2F;IP协议族按照层次由上到下，层层包装。最上面的是应用层，这里面有http，ftp 等等我们熟悉的协议。而第二层则是传输层，著名的TCP和UDP协议就在这个层次。第三层是网络层，IP协议就在这里，它负责对数据加上IP地址和其他的数据以确定传输的目标。第四层是数据链路层，这个层次为待传送的数据加入一个以太网协议头，并进行CRC编码，为最后的数据传输做准备。 上图清楚地表示了TCP&#x2F;IP协议中每个层的作用，而TCP&#x2F;IP协议通信的过程其实就对应着数据入栈与出栈的过程。入栈的过程，数据发送方每层不断地封装首部与尾部，添加一些传输的信息，确保能传输到目的地。出栈的过程，数据接收方每层不断地拆除首部与尾部，得到最终传输的数据。 上图以HTTP协议为例，具体说明。 二、数据链路层物理层负责0、1比特流与物理设备电压高低、光的闪灭之间的互换。数据链路层负责将0、1序列划分为数据帧从一个节点传输到临近的另一个节点,这些节点是通过MAC来唯一标识的(MAC,物理地址，一个主机会有一个MAC地址)。 封装成帧: 把网络层数据报加头和尾，封装成帧,帧头中包括源MAC地址和目的MAC地址。 透明传输: 零比特填充、转义字符。 可靠传输: 在出错率很低的链路上很少用，但是无线链路WLAN会保证可靠传输。 差错检测(CRC): 接收者检测错误,如果发现差错，丢弃该帧。 三、网络层1、IP协议IP协议是TCP&#x2F;IP协议的核心，所有的TCP，UDP，IMCP，IGMP的数据都以IP数据格式传输。要注意的是，IP不是可靠的协议，这是说，IP协议没有提供一种数据未传达以后的处理机制，这被认为是上层协议：TCP或UDP要做的事情。 1.1 IP地址在数据链路层中我们一般通过MAC地址来识别不同的节点，而在IP层我们也要有一个类似的地址标识，这就是IP地址。 32位IP地址分为网络位和地址位，这样做可以减少路由器中路由表记录的数目，有了网络地址，就可以限定拥有相同网络地址的终端都在同一个范围内，那么路由表只需要维护一条这个网络地址的方向，就可以找到相应的这些终端了。 A类IP地址: 0.0.0.0127.0.0.0B类IP地址:128.0.0.1191.255.0.0C类IP地址:192.168.0.0~239.255.255.0 1.2 IP协议头 这里只介绍:八位的TTL字段。这个字段规定该数据包在穿过多少个路由之后才会被抛弃。某个IP数据包每穿过一个路由器，该数据包的TTL数值就会减少1，当该数据包的TTL成为零，它就会被自动抛弃。 这个字段的最大值也就是255，也就是说一个协议包也就在路由器里面穿行255次就会被抛弃了，根据系统的不同，这个数字也不一样，一般是32或者是64。 2、ARP及RARP协议ARP 是根据IP地址获取MAC地址的一种协议。 ARP（地址解析）协议是一种解析协议，本来主机是完全不知道这个IP对应的是哪个主机的哪个接口，当主机要发送一个IP包的时候，会首先查一下自己的ARP高速缓存（就是一个IP-MAC地址对应表缓存）。 如果查询的IP－MAC值对不存在，那么主机就向网络发送一个ARP协议广播包，这个广播包里面就有待查询的IP地址，而直接收到这份广播的包的所有主机都会查询自己的IP地址，如果收到广播包的某一个主机发现自己符合条件，那么就准备好一个包含自己的MAC地址的ARP包传送给发送ARP广播的主机。 而广播主机拿到ARP包后会更新自己的ARP缓存（就是存放IP-MAC对应表的地方）。发送广播的主机就会用新的ARP缓存数据准备好数据链路层的的数据包发送工作。 RARP协议的工作与此相反，不做赘述。 3、ICMP协议IP协议并不是一个可靠的协议，它不保证数据被送达，那么，自然的，保证数据送达的工作应该由其他的模块来完成。其中一个重要的模块就是ICMP(网络控制报文)协议。ICMP不是高层协议，而是IP层的协议。 当传送IP数据包发生错误。比如主机不可达，路由不可达等等，ICMP协议将会把错误信息封包，然后传送回给主机。给主机一个处理错误的机会，这也就是为什么说建立在IP层以上的协议是可能做到安全的原因。 四、pingping可以说是ICMP的最著名的应用，是TCP&#x2F;IP协议的一部分。利用“ping”命令可以检查网络是否连通，可以很好地帮助我们分析和判定网络故障。 例如：当我们某一个网站上不去的时候。通常会ping一下这个网站。ping会回显出一些有用的信息。一般的信息如下: ping这个单词源自声纳定位，而这个程序的作用也确实如此，它利用ICMP协议包来侦测另一个主机是否可达。原理是用类型码为0的ICMP发请求，受到请求的主机则用类型码为8的ICMP回应。 五、TracerouteTraceroute是用来侦测主机到目的主机之间所经路由情况的重要工具，也是最便利的工具。 Traceroute的原理是非常非常的有意思，它收到到目的主机的IP后，首先给目的主机发送一个TTL&#x3D;1的UDP数据包，而经过的第一个路由器收到这个数据包以后，就自动把TTL减1，而TTL变为0以后，路由器就把这个包给抛弃了，并同时产生 一个主机不可达的ICMP数据报给主机。主机收到这个数据报以后再发一个TTL&#x3D;2的UDP数据报给目的主机，然后刺激第二个路由器给主机发ICMP数据 报。如此往复直到到达目的主机。这样，traceroute就拿到了所有的路由器IP。 六、TCP&#x2F;UDPTCP&#x2F;UDP都是是传输层协议，但是两者具有不同的特性，同时也具有不同的应用场景，下面以图表的形式对比分析。 面向报文 面向报文的传输方式是应用层交给UDP多长的报文，UDP就照样发送，即一次发送一个报文。因此，应用程序必须选择合适大小的报文。若报文太长，则IP层需要分片，降低效率。若太短，会是IP太小。 面向字节流 面向字节流的话，虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序看成是一连串的无结构的字节流。TCP有一个缓冲，当应用程序传送的数据块太长，TCP就可以把它划分短一些再传送。 关于拥塞控制，流量控制，是TCP的重点，后面讲解。 TCP和UDP协议的一些应用 什么时候应该使用TCP？ 当对网络通讯质量有要求的时候，比如：整个数据要准确无误的传递给对方，这往往用于一些要求可靠的应用，比如HTTP、HTTPS、FTP等传输文件的协议，POP、SMTP等邮件传输的协议。 什么时候应该使用UDP？ 当对网络通讯质量要求不高的时候，要求网络通讯速度能尽量的快，这时就可以使用UDP。 七、DNSDNS（Domain Name System，域名系统），因特网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。通过主机名，最终得到该主机名对应的IP地址的过程叫做域名解析（或主机名解析）。DNS协议运行在UDP协议之上，使用端口号53。 八、TCP连接的建立与终止1、三次握手TCP是面向连接的，无论哪一方向另一方发送数据之前，都必须先在双方之间建立一条连接。在TCP&#x2F;IP协议中，TCP协议提供可靠的连接服务，连接是通过三次握手进行初始化的。三次握手的目的是同步连接双方的序列号和确认号并交换 TCP窗口大小信息。 第一次握手：建立连接。客户端发送连接请求报文段，将SYN位置为1，Sequence Number为x；然后，客户端进入SYN_SEND状态，等待服务器的确认； 第二次握手：服务器收到SYN报文段。服务器收到客户端的SYN报文段，需要对这个SYN报文段进行确认，设置Acknowledgment Number为x+1(Sequence Number+1)；同时，自己自己还要发送SYN请求信息，将SYN位置为1，Sequence Number为y；服务器端将上述所有信息放到一个报文段（即SYN+ACK报文段）中，一并发送给客户端，此时服务器进入SYN_RECV状态； 第三次握手：客户端收到服务器的SYN+ACK报文段。然后将Acknowledgment Number设置为y+1，向服务器发送ACK报文段，这个报文段发送完毕以后，客户端和服务器端都进入ESTABLISHED状态，完成TCP三次握手。 为什么要三次握手？ 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。 具体例子：“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。 于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。” 2、四次挥手当客户端和服务器通过三次握手建立了TCP连接以后，当数据传送完毕，肯定是要断开TCP连接的啊。那对于TCP的断开连接，这里就有了神秘的“四次分手”。 第一次分手：主机1（可以使客户端，也可以是服务器端），设置Sequence Number，向主机2发送一个FIN报文段；此时，主机1进入FIN_WAIT_1状态；这表示主机1没有数据要发送给主机2了； 第二次分手：主机2收到了主机1发送的FIN报文段，向主机1回一个ACK报文段，Acknowledgment Number为Sequence Number加1；主机1进入FIN_WAIT_2状态；主机2告诉主机1，我“同意”你的关闭请求； 第三次分手：主机2向主机1发送FIN报文段，请求关闭连接，同时主机2进入LAST_ACK状态； 第四次分手：主机1收到主机2发送的FIN报文段，向主机2发送ACK报文段，然后主机1进入TIME_WAIT状态；主机2收到主机1的ACK报文段以后，就关闭连接；此时，主机1等待2MSL后依然没有收到回复，则证明Server端已正常关闭，那好，主机1也可以关闭连接了。 为什么要四次分手？ TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。 为什么要等待2MSL？ MSL：报文段最大生存时间，它是任何报文段被丢弃前在网络内的最长时间。原因有二： 保证TCP协议的全双工连接能够可靠关闭 保证这次连接的重复数据段从网络中消失 第一点：如果主机1直接CLOSED了，那么由于IP协议的不可靠性或者是其它网络原因，导致主机2没有收到主机1最后回复的ACK。那么主机2就会在超时之后继续发送FIN，此时由于主机1已经CLOSED了，就找不到与重发的FIN对应的连接。所以，主机1不是直接进入CLOSED，而是要保持TIME_WAIT，当再次收到FIN的时候，能够保证对方收到ACK，最后正确的关闭连接。 第二点：如果主机1直接CLOSED，然后又再向主机2发起一个新连接，我们不能保证这个新连接与刚关闭的连接的端口号是不同的。也就是说有可能新连接和老连接的端口号是相同的。一般来说不会发生什么问题，但是还是有特殊情况出现：假设新连接和已经关闭的老连接端口号是一样的，如果前一次连接的某些数据仍然滞留在网络中，这些延迟数据在建立新连接之后才到达主机2，由于新连接和老连接的端口号是一样的，TCP协议就认为那个延迟的数据是属于新连接的，这样就和真正的新连接的数据包发生混淆了。所以TCP连接还要在TIME_WAIT状态等待2倍MSL，这样可以保证本次连接的所有数据都从网络中消失。 九、TCP流量控制如果发送方把数据发送得过快，接收方可能会来不及接收，这就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。 利用滑动窗口机制可以很方便地在TCP连接上实现对发送方的流量控制。 设A向B发送数据。在连接建立时，B告诉了A：“我的接收窗口是 rwnd &#x3D; 400 ”(这里的 rwnd 表示 receiver window) 。因此，发送方的发送窗口不能超过接收方给出的接收窗口的数值。请注意，TCP的窗口单位是字节，不是报文段。假设每一个报文段为100字节长，而数据报文段序号的初始值设为1。大写ACK表示首部中的确认位ACK，小写ack表示确认字段的值ack。 从图中可以看出，B进行了三次流量控制。第一次把窗口减少到 rwnd &#x3D; 300 ，第二次又减到了 rwnd &#x3D; 100 ，最后减到 rwnd &#x3D; 0 ，即不允许发送方再发送数据了。这种使发送方暂停发送的状态将持续到主机B重新发出一个新的窗口值为止。B向A发送的三个报文段都设置了 ACK &#x3D; 1 ，只有在ACK&#x3D;1时确认号字段才有意义。 TCP为每一个连接设有一个持续计时器(persistence timer)。只要TCP连接的一方收到对方的零窗口通知，就启动持续计时器。若持续计时器设置的时间到期，就发送一个零窗口控测报文段（携1字节的数据），那么收到这个报文段的一方就重新设置持续计时器。 十、TCP拥塞控制发送方维持一个拥塞窗口 cwnd ( congestion window )的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。 发送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。 慢开始算法： 当主机开始发送数据时，如果立即所大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。因此，较好的方法是 先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。 通常在刚刚开始发送报文段时，先把拥塞窗口 cwnd 设置为一个最大报文段MSS的数值。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口 cwnd ，可以使分组注入到网络的速率更加合理。 每经过一个传输轮次，拥塞窗口 cwnd 就加倍。一个传输轮次所经历的时间其实就是往返时间RTT。不过“传输轮次”更加强调：把拥塞窗口cwnd所允许发送的报文段都连续发送出去，并收到了对已发送的最后一个字节的确认。 另，慢开始的“慢”并不是指cwnd的增长速率慢，而是指在TCP开始发送报文段时先设置cwnd&#x3D;1，使得发送方在开始时只发送一个报文段（目的是试探一下网络的拥塞情况），然后再逐渐增大cwnd。 为了防止拥塞窗口cwnd增长过大引起网络拥塞，还需要设置一个慢开始门限ssthresh状态变量。慢开始门限ssthresh的用法如下： 当 cwnd &lt; ssthresh 时，使用上述的慢开始算法。 当 cwnd &gt; ssthresh 时，停止使用慢开始算法而改用拥塞避免算法。 当 cwnd &#x3D; ssthresh 时，既可使用慢开始算法，也可使用拥塞控制避免算法。拥塞避免 拥塞避免 让拥塞窗口cwnd缓慢地增大，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口cwnd按线性规律缓慢增长，比慢开始算法的拥塞窗口增长速率缓慢得多。 无论在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有收到确认），就要把慢开始门限ssthresh设置为出现拥塞时的发送 方窗口值的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。 这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生 拥塞的路由器有足够时间把队列中积压的分组处理完毕。 如下图，用具体数值说明了上述拥塞控制的过程。现在发送窗口的大小和拥塞窗口一样大。 2、快重传和快恢复快重传快重传算法首先要求接收方每收到一个失序的报文段后就立即发出重复确认（为的是使发送方及早知道有报文段没有到达对方）而不要等到自己发送数据时才进行捎带确认。 接收方收到了M1和M2后都分别发出了确认。现在假定接收方没有收到M3但接着收到了M4。 显然，接收方不能确认M4，因为M4是收到的失序报文段。根据 可靠传输原理，接收方可以什么都不做，也可以在适当时机发送一次对M2的确认。 但按照快重传算法的规定，接收方应及时发送对M2的重复确认，这样做可以让 发送方及早知道报文段M3没有到达接收方。发送方接着发送了M5和M6。接收方收到这两个报文后，也还要再次发出对M2的重复确认。这样，发送方共收到了 接收方的四个对M2的确认，其中后三个都是重复确认。 快重传算法还规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必 继续等待M3设置的重传计时器到期。 由于发送方尽早重传未被确认的报文段，因此采用快重传后可以使整个网络吞吐量提高约20%。 快恢复与快重传配合使用的还有快恢复算法，其过程有以下两个要点： 当发送方连续收到三个重复确认，就执行“乘法减小”算法，把慢开始门限ssthresh减半。 与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为 慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。","tags":["计算机网络","TCP/IP"],"categories":["计算机网络"]},{"title":"Java 泛型 T，E，K，V，?，傻傻分不清？","path":"/2023/12/24/Java-泛型-T，E，K，V，-，傻傻分不清？/","content":"前言Java 泛型（generics）是 JDK 5 中引入的一个新特性, 泛型提供了编译时类型安全检测机制，该机制允许开发者在编译时检测到非法的类型。 泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。 泛型带来的好处在没有泛型的情况的下，通过对类型 Object 的引用来实现参数的“任意化”，“任意化”带来的缺点是要做显式的强制类型转换，而这种转换是要求开发者对实际参数类型可以预知的情况下进行的。对于强制类型转换错误的情况，编译器可能不提示错误，在运行的时候才出现异常，这是本身就是一个安全隐患。 那么泛型的好处就是在编译的时候能够检查类型安全，并且所有的强制转换都是自动和隐式的。 12345678910111213141516171819202122232425262728293031323334353637public class GlmapperGeneric&lt;T&gt; &#123; private T t; public void set(T t) &#123; this.t = t; &#125; public T get() &#123; return t; &#125; public static void main(String[] args) &#123; // do nothing &#125; /** * 不指定类型 */ public void noSpecifyType() &#123; GlmapperGeneric glmapperGeneric = new GlmapperGeneric(); glmapperGeneric.set(&quot;test&quot;); // 需要强制类型转换 String test = (String) glmapperGeneric.get(); System.out.println(test); &#125; /** * 指定类型 */ public void specifyType() &#123; GlmapperGeneric&lt;String&gt; glmapperGeneric = new GlmapperGeneric(); glmapperGeneric.set(&quot;test&quot;); // 不需要强制类型转换 String test = glmapperGeneric.get(); System.out.println(test); &#125;&#125; 上面这段代码中的 specifyType 方法中 省去了强制转换，可以在编译时候检查类型安全，可以用在类，方法，接口上。 泛型中通配符我们在定义泛型类，泛型方法，泛型接口的时候经常会碰见很多不同的通配符，比如 T，E，K，V 等等，这些通配符又都是什么意思呢？ 常用的 T，E，K，V，？本质上这些个都是通配符，没啥区别，只不过是编码时的一种约定俗成的东西。比如上述代码中的 T ，我们可以换成 A-Z 之间的任何一个 字母都可以，并不会影响程序的正常运行，但是如果换成其他的字母代替 T ，在可读性上可能会弱一些。通常情况下，T，E，K，V，？是这样约定的： ？表示不确定的 java 类型 T (type) 表示具体的一个java类型 K V (key value) 分别代表java键值中的Key Value E (element) 代表Element ？无界通配符先从一个小例子看起 。 我有一个父类 Animal 和几个子类，如狗、猫等，现在我需要一个动物的列表，我的第一个想法是像这样的： 1List&lt;Animal&gt; listAnimals 但是老板的想法确实这样的： 1List&lt;? extends Animal&gt; listAnimals 为什么要使用通配符而不是简单的泛型呢？通配符其实在声明局部变量时是没有什么意义的，但是当你为一个方法声明一个参数时，它是非常重要的。 123456789101112131415161718192021static int countLegs (List&lt;? extends Animal &gt; animals ) &#123; int retVal = 0; for ( Animal animal : animals ) &#123; retVal += animal.countLegs(); &#125; return retVal;&#125;static int countLegs1 (List&lt; Animal &gt; animals ) &#123; int retVal = 0; for ( Animal animal : animals ) &#123; retVal += animal.countLegs(); &#125; return retVal;&#125;public static void main(String[] args) &#123; List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;(); // 不会报错 countLegs( dogs ); // 报错 countLegs1(dogs);&#125; 当调用 countLegs1 时，就会飘红，提示的错误信息如下： 所以，对于不确定或者不关心实际要操作的类型，可以使用无限制通配符（尖括号里一个问号，即 &lt;?&gt; ），表示可以持有任何类型。像 countLegs 方法中，限定了上届，但是不关心具体类型是什么，所以对于传入的 Animal 的所有子类都可以支持，并且不会报错。而 countLegs1 就不行。 上界通配符 &lt; ? extends E&gt; 上界：用 extends 关键字声明，表示参数化的类型可能是所指定的类型，或者是此类型的子类。 在类型参数中使用 extends 表示这个泛型中的参数必须是 E 或者 E 的子类，这样有两个好处： 如果传入的类型不是 E 或者 E 的子类，编译不成功 泛型中可以使用 E 的方法，要不然还得强转成 E 才能使用 12345private &lt;K extends A, E extends B&gt; E test(K arg1, E arg2) &#123; E result = arg2; arg2.compareTo(arg1); //..... return result;&#125; 类型参数列表中如果有多个类型参数上限，用逗号分开 下界通配符 &lt; ? super E&gt; 下界: 用 super 进行声明，表示参数化的类型可能是所指定的类型，或者是此类型的父类型，直至 Object 在类型参数中使用 super 表示这个泛型中的参数必须是 E 或者 E 的父类。 1234567891011121314private &lt;T&gt; void test(List&lt;? super T&gt; dst, List&lt;T&gt; src) &#123; for (T t : src) &#123; dst.add(t); &#125;&#125;public static void main(String[] args) &#123; List&lt;Dog&gt; dogs = new ArrayList&lt;&gt;(); List&lt;Animal&gt; animals = new ArrayList&lt;&gt;(); new Test3().test(animals,dogs);&#125;// Dog 是 Animal 的子类class Dog extends Animal &#123;&#125; dst 类型 “大于等于” src 的类型，这里的“大于等于”是指 dst 表示的范围比 src 要大，因此装得下 dst 的容器也就能装 src 。 ？和 T 的区别 ？和 T 都表示不确定的类型，区别在于我们可以对 T 进行操作，但是对 ？不行，比如如下这种 ： 1234// 可以T t = operate();// 不可以？car = operate(); 简单总结下： T 是一个 确定的 类型，通常用于泛型类和泛型方法的定义，？是一个 不确定 的类型，通常用于泛型方法的调用代码和形参，不能用于定义类和泛型方法。 区别1：通过 T 来 确保 泛型参数的一致性12345// 通过 T 来 确保 泛型参数的一致性public &lt;T extends Number&gt; voidtest(List&lt;T&gt; dest, List&lt;T&gt; src)//通配符是 不确定的，所以这个方法不能保证两个 List 具有相同的元素类型public void test(List&lt;? extends Number&gt; dest, List&lt;? extends Number&gt; src) 像下面的代码中，约定的 T 是 Number 的子类才可以，但是申明时是用的 String ，所以就会飘红报错。 不能保证两个 List 具有相同的元素类型的情况 1234GlmapperGeneric&lt;String&gt; glmapperGeneric = new GlmapperGeneric&lt;&gt;();List&lt;String&gt; dest = new ArrayList&lt;&gt;();List&lt;Number&gt; src = new ArrayList&lt;&gt;();glmapperGeneric.testNon(dest,src); 上面的代码在编译器并不会报错，但是当进入到 testNon 方法内部操作时（比如赋值），对于 dest 和 src 而言，就还是需要进行类型转换。 区别2：类型参数可以多重限定而通配符不行 使用 &amp; 符号设定多重边界（Multi Bounds)，指定泛型类型 T 必须是 MultiLimitInterfaceA 和 MultiLimitInterfaceB 的共有子类型，此时变量 t 就具有了所有限定的方法和属性。对于通配符来说，因为它不是一个确定的类型，所以不能进行多重限定。 区别3：通配符可以使用超类限定而类型参数不行类型参数 T 只具有 一种 类型限定方式： 1T extends A 但是通配符 ? 可以进行 两种限定： 1? extends A? super A ** Class 和 Class&lt;?&gt; 区别**前面介绍了 ？和 T 的区别，那么对于，Class 和 &lt;Class 又有什么区别呢？Class 和 Class 最常见的是在反射场景下的使用，这里以用一段发射的代码来说明下。 123// 通过反射的方式生成 multiLimit // 对象，这里比较明显的是，我们需要使用强制类型转换MultiLimit multiLimit = (MultiLimit)Class.forName(&quot;com.glmapper.bridge.boot.generic.MultiLimit&quot;).newInstance(); 对于上述代码，在运行期，如果反射的类型不是 MultiLimit 类，那么一定会报 java.lang.ClassCastException 错误。 对于这种情况，则可以使用下面的代码来代替，使得在在编译期就能直接 检查到类型的问题： Class 在实例化的时候，T 要替换成具体类。Class&lt;?&gt; 它是个通配泛型，? 可以代表任何类型，所以主要用于声明时的限制情况。比如，我们可以这样做申明： 1234// 可以public Class&lt;?&gt; clazz;// 不可以，因为 T 需要指定类型public Class&lt;T&gt; clazzT; 所以当不知道定声明什么类型的 Class 的时候可以定义一 个Class&lt;?&gt;。 那如果也想 public Class clazzT; 这样的话，就必须让当前的类也指定 T ， 123public class Test3&lt;T&gt; &#123; public Class&lt;?&gt; clazz; // 不会报错 public Class&lt;T&gt; clazzT; 小结本文零碎整理了下 JAVA 泛型中的一些点，不是很全，仅供参考。","tags":["Java","泛型"],"categories":["Java"]},{"title":"Docker从入门到干活，看这一篇足矣","path":"/2023/12/24/Docker从入门到干活，看这一篇足矣/","content":"1. 容器简介1.1. 什么是 Linux 容器Linux容器是与系统其他部分隔离开的一系列进程，从另一个镜像运行，并由该镜像提供支持进程所需的全部文件。 容器提供的镜像包含了应用的所有依赖项，因而在从开发到测试再到生产的整个过程中，它都具有可移植性和一致性。 更加详细地来说，请您假定您在开发一个应用。您使用的是一台笔记本电脑，而且您的开发环境具有特定的配置。其他开发人员身处的环境配置可能稍有不同。您正在开发的应用依赖于您当前的配置，还要依赖于某些特定文件。 与此同时，您的企业还拥有标准化的测试和生产环境，且具有自身的配置和一系列支持文件。 您希望尽可能多在本地模拟这些环境，而不产生重新创建服务器环境的开销。 因此，您要如何确保应用能够在这些环境中运行和通过质量检测，并且在部署过程中不出现令人头疼的问题，也无需重新编写代码和进行故障修复？答案就是使用容器。 容器可以确保您的应用拥有必需的配置和文件，使得这些应用能够在从开发到测试、再到生产的整个流程中顺利运行，而不出现任何不良问题。这样可以避免危机，做到皆大欢喜。 虽然这只是简化的示例，但在需要很高的可移植性、可配置性和隔离的情况下，我们可以利用 Linux 容器通过很多方式解决难题。 无论基础架构是在企业内部还是在云端，或者混合使用两者，容器都能满足您的需求。 1.2. 容器不就是虚拟化吗是，但也不竟然。我们用一种简单方式来思考一下： 虚拟化使得许多操作系统可同时在单个系统上运行。 容器则可共享同一个操作系统内核，将应用进程与系统其他部分隔离开。 图 - 普通虚拟化技术和Docker的对比 这意味着什么？首先，让多个操作系统在单个虚拟机监控程序上运行以实现虚拟化，并不能达成和使用容器同等的轻量级效果。 事实上，在仅拥有容量有限的有限资源时，您需要能够可以进行密集部署的轻量级应用。 Linux 容器可从单个操作系统运行，在所有容器中共享该操作系统，因此应用和服务能够保持轻量级，并行快速运行。 1.3. 容器发展简史 我们现在称为容器技术的概念最初出现在 2000 年，当时称为 FreeBSD jail，这种技术可将 FreeBSD 系统分区为多个子系统（也称为 Jail）。 Jail 是作为安全环境而开发的，系统管理员可与企业内部或外部的多个用户共享这些 Jail。 Jail 的目的是让进程在经过修改的 chroot 环境中创建，而不会脱离和影响整个系统 — 在 chroot 环境中，对文件系统、网络和用户的访问都实现了虚拟化。 尽管 Jail 在实施方面存在局限性，但最终人们找到了脱离这种隔离环境的方法。 但这个概念非常有吸引力。 2001 年，通过 Jacques Gélinas 的 VServer 项目，隔离环境的实施进入了 Linux 领域。 正如 Gélinas 所说，这项工作的目的是“在高度独立且安全的单一环境中运行多个通用 Linux 服务器 [sic]。” 在完成了这项针对 Linux 中多个受控制用户空间的基础性工作后，Linux 容器开始逐渐成形并最终发展成了现在的模样。 2. 什么是 Docker？“Docker” 一词指代多种事物，包括开源社区项目、开源项目使用的工具、主导支持此类项目的公司 Docker Inc. 以及该公司官方支持的工具。技术产品和公司使用同一名称，的确让人有点困惑。 🎍 IT 软件中所说的 “Docker” ，是指容器化技术，用于支持创建和使用 Linux 容器。 🎍 开源 Docker 社区致力于改进这类技术，并免费提供给所有用户，使之获益。 🎍 Docker Inc. 公司凭借 Docker 社区产品起家，它主要负责提升社区版本的安全性，并将改进后的版本与更广泛的技术社区分享。此外，它还专门对这些技术产品进行完善和安全固化，以服务于企业客户。 借助 Docker ，您可将容器当做重量轻、模块化的虚拟机使用。同时，您还将获得高度的灵活性，从而实现对容器的高效创建、部署及复制，并能将其从一个环境顺利迁移至另一个环境。 2.1. Docker 如何工作？Docker 技术使用 Linux 内核和内核功能（例如 Cgroups 和 namespaces）来分隔进程，以便各进程相互独立运行。 这种独立性正是采用容器的目的所在；它可以独立运行多种进程、多个应用程序，更加充分地发挥基础设施的作用，同时保持各个独立系统的安全性。 容器工具（包括 Docker）可提供基于镜像的部署模式。这使得它能够轻松跨多种环境，与其依赖程序共享应用或服务组。Docker 还可在这一容器环境中自动部署应用程序（或者合并多种流程，以构建单个应用程序）。 此外，由于这些工具基于 Linux 容器构建，使得 Docker 既易于使用，又别具一格 —— 它可为用户提供前所未有的高度应用程访问权限、快速部署以及版本控制和分发能力。 2.2. Docker 技术是否与传统的 Linux 容器相同？否。Docker 技术最初是基于 LXC 技术构建（大多数人都会将这一技术与“传统的” Linux 容器联系在一起），但后来它逐渐摆脱了对这种技术的依赖。 就轻量级 虚拟化 这一功能来看，LXC 非常有用，但它无法提供出色的开发人员或用户体验。除了运行容器之外，Docker 技术还具备其他多项功能，包括简化用于构建容器、传输镜像以及控制镜像版本的流程。 传统的 Linux 容器使用 init 系统来管理多种进程。这意味着，所有应用程序都作为一个整体运行。与此相反，Docker 技术鼓励应用程序各自独立运行其进程，并提供相应工具以实现这一功能。这种精细化运作模式自有其优势。 2.3. docker的目标docker的主要目标是”Build,Ship and Run any App,Angwhere”,构建，运输，处处运行 构建：做一个docker镜像 运输：docker pull 运行：启动一个容器 每一个容器，他都有自己的文件系统rootfs. 3. 安装Docker环境说明 123456789# 需要两台几点进行安装[root@docker01 ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@docker01 ~]# uname -r 3.10.0-327.el7.x86_64[root@docker01 ~]# hostname -I10.0.0.100 172.16.1.100 [root@docker02 ~]# hostname -I10.0.0.101 172.16.1.101 在两个节点上都进行操作 123wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.reposed -i &#x27;s#download.docker.com#mirrors.ustc.edu.cn/docker-ce#g&#x27; /etc/yum.repos.d/docker-ce.repoyum install docker-ce -y 修改在docker01配置： 1234567# 修改启动文件，监听远程端口vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://10.0.0.100:2375systemctl daemon-reloadsystemctl enable docker.service systemctl restart docker.service# ps -ef检查进行，是否启动 在docker02测试 123456789[root@docker02 ~]# docker -H 10.0.0.100 infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.12.0-ceStorage Driver: devicemapper··· 3.1. Docker基础命令操作查看docker相关信息 1234567891011121314151617[root@docker01 ~]# docker version Client: Version: 17.12.0-ce API version: 1.35 Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:10:14 2017 OS/Arch: linux/amd64Server: Engine: Version: 17.12.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:12:46 2017 OS/Arch: linux/amd64 Experimental: false 配置docker镜像加速 1234vi /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 3.2. 启动第一个容器12345678910[root@docker01 ~]# docker run -d -p 80:80 nginxUnable to find image &#x27;nginx:latest&#x27; locallylatest: Pulling from library/nginxe7bb522d92ff: Pull complete 6edc05228666: Pull complete cd866a17e81f: Pull complete Digest: sha256:285b49d42c703fdf257d1e2422765c4ba9d3e37768d6ea83d7fe2043dad6e63dStatus: Downloaded newer image for nginx:latest8d8f81da12b5c10af6ba1a5d07f4abc041cb95b01f3d632c3d638922800b0b4d# 容器启动后，在浏览器进行访问测试 参数说明 3.3. Docker镜像生命周期 4. Docker镜像相关操作4.1. 搜索官方仓库镜像1234[root@docker01 ~]# docker search centosNAME DESCRIPTION STARS OFFICIAL AUTOMATEDcentos The official build of CentOS. 3992 [OK] ansible/centos7-ansible Ansible on Centos7 105 [OK] 列表说明 4.2. 获取镜像根据镜像名称拉取镜像 1234[root@docker01 ~]# docker pull centosUsing default tag: latestlatest: Pulling from library/centosaf4b0a2388c6: Downloading 34.65MB/73.67MB 查看当前主机镜像列表 1234[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB 拉第三方镜像方法 1docker pull index.tenxcloud.com/tenxcloud/httpd 4.3. 导出镜像123456[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB# 导出[root@docker01 ~]# docker image save centos &gt; docker-centos.tar.gz 4.4. 删除镜像1234[root@docker01 ~]# docker image rm centos:latest[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEnginx latest 3f8a4339aadd 5 weeks ago 108MB 4.5. 导入镜像1234567[root@docker01 ~]# docker image load -i docker-centos.tar.gz e15afa4858b6: Loading layer 215.8MB/215.8MBLoaded image: centos:latest[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB 4.6. 查看镜像的详细信息1[root@docker01 ~]# docker image inspect centos 5. 容器的日常管理5.1. 容器的起&#x2F;停最简单的运行一个容器 1[root@docker01 ~]# docker run nginx 创建容器，两步走（不常用） 1234[root@docker01 ~]# docker create centos:latest /bin/bashbb7f32368ecf0492adb59e20032ab2e6cf6a563a0e6751e58930ee5f7aaef204[root@docker01 ~]# docker start stupefied_nobelstupefied_nobel 快速启动容器方法 1[root@docker01 ~]# docker run centos:latest /usr/bin/sleep 20; 容器内的第一个进程必须一直处于运行的状态，否则这个容器，就会处于退出状态！ 查看正在运行的容器 12345[root@docker01 ~]# docker container ls 或[root@docker01 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8708e93fd767 nginx &quot;nginx -g &#x27;daemon of…&quot; 6 seconds ago Up 4 seconds 80/tcp keen_lewin 查看你容器详细信息&#x2F;ip 1[root@docker01 ~]# docker container inspect 容器名称/id 查看你所有容器（包括未运行的） 12345[root@docker01 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8708e93fd767 nginx &quot;nginx -g &#x27;daemon of…&quot; 4 minutes ago Exited (0) 59 seconds ago keen_lewinf9f3e6af7508 nginx &quot;nginx -g &#x27;daemon of…&quot; 5 minutes ago Exited (0) 5 minutes ago optimistic_haibt8d8f81da12b5 nginx &quot;nginx -g &#x27;daemon of…&quot; 3 hours ago Exited (0) 3 hours ago lucid_bohr 停止容器 123[root@docker01 ~]# docker stop 容器名称/id 或[root@docker01 ~]# docker container kill 容器名称/id 5.2. 进入容器方法启动时进去方法 123[root@docker01 ~]# docker run -it #参数：-it 可交互终端[root@docker01 ~]# docker run -it nginx:latest /bin/bashroot@79241093859e:/# 退出&#x2F;离开容器 1ctrl+p &amp; ctrl+q 启动后进入容器的方法 启动一个docker 12345[root@docker01 ~]# docker run -it centos:latest [root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 13 1 0 15:47 pts/0 00:00:00 ps -ef attach进入容器，使用pts&#x2F;0 ，会让所用通过此方法进如放入用户看到同样的操作。 12345[root@docker01 ~]# docker attach 1bf0f43c4d2f[root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 14 1 0 15:49 pts/0 00:00:00 ps -ef 自命名启动一个容器 –name 12345[root@docker01 ~]# docker attach 1bf0f43c4d2f[root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 14 1 0 15:49 pts/0 00:00:00 ps -ef exec 进入容器方法（推荐使用） 1234567[root@docker01 ~]# docker exec -it clsn1 /bin/bash [root@b20fa75b4b40 /]# 重新分配一个终端[root@b20fa75b4b40 /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 16:11 pts/0 00:00:00 /bin/bashroot 13 0 0 16:14 pts/1 00:00:00 /bin/bashroot 26 13 0 16:14 pts/1 00:00:00 ps -ef 5.3. 删除所有容器12[root@docker01 ~]# docker rm -f `docker ps -a -q`# -f 强制删除 5.4. 启动时进行端口映射-p参数端口映射 12[root@docker01 ~]# docker run -d -p 8888:80 nginx:latest 287bec5c60263166c03e1fc5b0b8262fe76507be3dfae4ce5cd2ee2d1e8a89a9 不同指定映射方法 随机映射 1docker run -P （大P）# 需要镜像支持 6. Docker 数据卷的管理6.1. 挂载时创建卷挂载卷 12[root@docker01 ~]# docker run -d -p 80:80 -v /data:/usr/share/nginx/html nginx:latest079786c1e297b5c5031e7a841160c74e91d4ad06516505043c60dbb78a259d09 容器内站点目录: &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html 在宿主机写入数据，查看 123[root@docker01 ~]# echo &quot;http://www.nmtui.com&quot; &gt;/data/index.html[root@docker01 ~]# curl 10.0.0.100http://www.nmtui.com 设置共享卷，使用同一个卷启动一个新的容器 1234[root@docker01 ~]# docker run -d -p 8080:80 -v /data:/usr/share/nginx/html nginx:latest 351f0bd78d273604bd0971b186979aa0f3cbf45247274493d2490527babb4e42[root@docker01 ~]# curl 10.0.0.100:8080http://www.nmtui.com 查看卷列表 12[root@docker01 ~]# docker volume lsDRIVER VOLUME NAME 6.2. 创建卷后挂载创建一个卷 12345[root@docker01 ~]# docker volume create f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521[root@docker01 ~]# docker volume ls DRIVER VOLUME NAMElocal f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521 指定卷名 1234[root@docker01 ~]# docker volume ls DRIVER VOLUME NAMElocal clsnlocal f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521 查看卷路径 123456789101112[root@docker01 ~]# docker volume inspect clsn [ &#123; &quot;CreatedAt&quot;: &quot;2018-02-01T00:39:25+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/clsn/_data&quot;, &quot;Name&quot;: &quot;clsn&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;] 使用卷创建 123456[root@docker01 ~]# docker run -d -p 9000:80 -v clsn:/usr/share/nginx/html nginx:latest 1434559cff996162da7ce71820ed8f5937fb7c02113bbc84e965845c219d3503# 宿主机测试[root@docker01 ~]# echo &#x27;blog.nmtui.com&#x27; &gt;/var/lib/docker/volumes/clsn/_data/index.html [root@docker01 ~]# curl 10.0.0.100:9000blog.nmtui.com 设置卷 12[root@docker01 ~]# docker run -d -P --volumes-from 079786c1e297 nginx:latest b54b9c9930b417ab3257c6e4a8280b54fae57043c0b76b9dc60b4788e92369fb 查看使用的端口 123456789101112[root@docker01 ~]# netstat -lntup Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1400/sshd tcp 0 0 10.0.0.100:2375 0.0.0.0:* LISTEN 26218/dockerd tcp6 0 0 :::9000 :::* LISTEN 32015/docker-proxy tcp6 0 0 :::8080 :::* LISTEN 31853/docker-proxy tcp6 0 0 :::80 :::* LISTEN 31752/docker-proxy tcp6 0 0 :::22 :::* LISTEN 1400/sshd tcp6 0 0 :::32769 :::* LISTEN 32300/docker-proxy [root@docker01 ~]# curl 10.0.0.100:32769http://www.nmtui.com 6.3. 手动将容器保存为镜像本次是基于docker官方centos 6.8 镜像创建 官方镜像列表： https://hub.docker.com/explore/ 启动一个centos6.8的镜像 123456[root@docker01 ~]# docker pull centos:6.8[root@docker01 ~]# docker run -it -p 1022:22 centos:6.8 /bin/bash# 在容器种安装sshd服务，并修改系统密码[root@582051b2b92b ~]# yum install openssh-server -y [root@582051b2b92b ~]# echo &quot;root:123456&quot; |chpasswd[root@582051b2b92b ~]# /etc/init.d/sshd start 启动完成后镜像ssh连接测试 将容器提交为镜像 1[root@docker01 ~]# docker commit brave_mcclintock centos6-ssh 使用新的镜像启动容器 12[root@docker01 ~]# docker run -d -p 1122:22 centos6-ssh:latest /usr/sbin/sshd -D 5b8161fda2a9f2c39c196c67e2eb9274977e7723fe51c4f08a0190217ae93094 在容器安装httpd服务 1[root@5b8161fda2a9 /]# yum install httpd -y 编写启动脚本脚本 123456[root@5b8161fda2a9 /]# cat init.sh #!/bin/bash /etc/init.d/httpd start /usr/sbin/sshd -D[root@5b8161fda2a9 /]# chmod +x init.sh # 注意执行权限 再次提交为新的镜像 12[root@docker01 ~]# docker commit 5b8161fda2a9 centos6-httpd sha256:705d67a786cac040800b8485cf046fd57b1828b805c515377fc3e9cea3a481c1 启动镜像，做好端口映射。并在浏览器中测试访问 12[root@docker01 ~]# docker run -d -p 1222:22 -p 80:80 centos6-httpd /init.sh 46fa6a06644e31701dc019fb3a8c3b6ef008d4c2c10d46662a97664f838d8c2c 7. Dockerfile自动构建docker镜像官方构建dockerffile文件参考 https://github.com/CentOS/CentOS-Dockerfiles 7.1. Dockerfile指令集dockerfile主要组成部分： 基础镜像信息 FROM centos:6.8 制作镜像操作指令RUN yum insatll openssh-server -y 容器启动时执行指令 CMD [“&#x2F;bin&#x2F;bash”] dockerfile常用指令： FROM 这个镜像的妈妈是谁？（指定基础镜像） MAINTAINER 告诉别人，谁负责养它？（指定维护者信息，可以没有） RUN 你想让它干啥（在命令前面加上RUN即可） ADD 给它点创业资金（COPY文件，会自动解压） WORKDIR 我是cd,今天刚化了妆（设置当前工作目录） VOLUME 给它一个存放行李的地方（设置卷，挂载主机目录） EXPOSE 它要打开的门是啥（指定对外的端口） CMD 奔跑吧，兄弟！（指定容器启动后的要干的事情） dockerfile其他指令： COPY 复制文件 ENV 环境变量 ENTRYPOINT 容器启动后执行的命令 7.2. 创建一个Dockerfile创建第一个Dockerfile文件 123456789# 创建目录[root@docker01 base]# cd /opt/base# 创建Dcokerfile文件，注意大小写[root@docker01 base]# vim DockerfileFROM centos:6.8RUN yum install openssh-server -y RUN echo &quot;root:123456&quot; |chpasswdRUN /etc/init.d/sshd start CMD [&quot;/usr/sbin/sshd&quot;,&quot;-D&quot;] 使用自构建的镜像启动 12[root@docker01 base]# docker image build -t centos6.8-ssh . -t 为镜像标签打标签 . 表示当前路径 使用自构建的镜像启动 12[root@docker01 base]# docker run -d -p 2022:22 centos6.8-ssh-b dc3027d3c15dac881e8e2aeff80724216f3ac725f142daa66484f7cb5d074e7a 7.3. 使用Dcokerfile安装kodexplorerDockerfile文件内容 12345678FROM centos:6.8RUN yum install wget unzip php php-gd php-mbstring -y &amp;&amp; yum clean all# 设置工作目录，之后的操作都在这个目录中WORKDIR /var/www/html/RUN wget -c http://static.kodcloud.com/update/download/kodexplorer4.25.zipRUN unzip kodexplorer4.25.zip &amp;&amp; rm -f kodexplorer4.25.zipRUN chown -R apache.apache .CMD [&quot;/usr/sbin/apachectl&quot;,&quot;-D&quot;,&quot;FOREGROUND&quot;] 更多的Dockerfile可以参考官方方法。 8. Docker中的镜像分层参考文档： http://www.maiziedu.com/wiki/cloud/dockerimage/ Docker 支持通过扩展现有镜像，创建新的镜像。实际上，Docker Hub 中 99% 的镜像都是通过在 base 镜像中安装和配置需要的软件构建出来的。 从上图可以看到，新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。 8.1. Docker 镜像为什么分层镜像分层最大的一个好处就是共享资源。 比如说有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。 如果多个容器共享一份基础镜像，当某个容器修改了基础镜像的内容，比如 &#x2F;etc 下的文件，这时其他容器的 &#x2F;etc 是不会被修改的，修改只会被限制在单个容器内。这就是容器 Copy-on-Write 特性。 8.2. 可写的容器层当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。 所有对容器的改动 - 无论添加、删除、还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的所有镜像层都是只读的。 8.3. 容器层的细节说明镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统。如果不同层中有一个相同路径的文件，比如 &#x2F;a，上层的 &#x2F;a 会覆盖下层的 &#x2F;a，也就是说用户只能访问到上层中的文件 &#x2F;a。在容器层中，用户看到的是一个叠加之后的文件系统。 文件操作的 只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。 这样就解释了我们前面提出的问题：容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。 9. 使用docker运行zabbix-server9.1. 容器间的互联在运行zabbix之前务必要了解容器间互联的方法 123456# 创建一个nginx容器docker run -d -p 80:80 nginx# 创建容器，做link，并进入容器中docker run -it --link quirky_brown:web01 centos-ssh /bin/bash# 在容器中访问nginx容器可以ping通ping web01 命令执行过程 12345678910111213141516171819# 启动apache容器[root@docker01 ~]# docker run -d httpd:2.4 3f1f7fc554720424327286bd2b04aeab1b084a3fb011a785b0deab6a34e56955^[[A[root@docker01 docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1f7fc55472 httpd:2.4 &quot;httpd-foreground&quot; 6 seconds ago Up 5 seconds 80/tcp determined_clarke# 拉取一个busybox 镜像[root@docker01 ~]# docker pull busybox # 启动容器[root@docker01 ~]# docker run -it --link determined_clarke:web busybox:latest /bin/sh / # # 使用新的容器访问最初的web容器/ # ping web PING web (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.058 ms^C--- web ping statistics ---1 packets transmitted, 1 packets received, 0% packet lossround-trip min/avg/max = 0.058/0.058/0.058 ms 9.2. 启动zabbix容器1、启动一个mysql的容器 1234567docker run --name mysql-server -t \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ -d mysql:5.7 \\ --character-set-server=utf8 --collation-server=utf8_bin 2、启动java-gateway容器监控java服务 12docker run --name zabbix-java-gateway -t \\ -d zabbix/zabbix-java-gateway:latest 3、启动zabbix-mysql容器使用link连接mysql与java-gateway。 1234567891011docker run --name zabbix-server-mysql -t \\ -e DB_SERVER_HOST=&quot;mysql-server&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ -e ZBX_JAVAGATEWAY=&quot;zabbix-java-gateway&quot; \\ --link mysql-server:mysql \\ --link zabbix-java-gateway:zabbix-java-gateway \\ -p 10051:10051 \\ -d zabbix/zabbix-server-mysql:latest 4、启动zabbix web显示，使用link连接zabbix-mysql与mysql。 12345678910docker run --name zabbix-web-nginx-mysql -t \\ -e DB_SERVER_HOST=&quot;mysql-server&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ --link mysql-server:mysql \\ --link zabbix-server-mysql:zabbix-server \\ -p 80:80 \\ -d zabbix/zabbix-web-nginx-mysql:latest 9.3. 关于zabbix API关于zabbix API可以参考官方文档： https://www.zabbix.com/documentation/3.4/zh/manual/api 1、获取token方法 123456789101112# 获取token[root@docker02 ~]# curl -s -X POST -H &#x27;Content-Type:application/json&#x27; -d &#x27;&#123;&quot;jsonrpc&quot;: &quot;2.0&quot;,&quot;method&quot;: &quot;user.login&quot;,&quot;params&quot;: &#123;&quot;user&quot;: &quot;Admin&quot;,&quot;password&quot;: &quot;zabbix&quot;&#125;,&quot;id&quot;: 1&#125;&#x27; http://10.0.0.100/api_jsonrpc.php&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;result&quot;:&quot;d3be707f9e866ec5d0d1c242292cbebd&quot;,&quot;id&quot;:1&#125; 10. docker 仓库（registry）10.1. 创建一个普通仓库1、创建仓库 1docker run -d -p 5000:5000 --restart=always --name registry -v /opt/myregistry:/var/lib/registry registry 2、修改配置文件，使之支持http 12345[root@docker01 ~]# cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;insecure-registries&quot;: [&quot;10.0.0.100:5000&quot;]&#125; 重启docker让修改生效 1[root@docker01 ~]# systemctl restart docker.service 3、修改镜像标签 123456[root@docker01 ~]# docker tag busybox:latest 10.0.0.100:5000/clsn/busybox:1.0[root@docker01 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos6-ssh latest 3c2b1e57a0f5 18 hours ago 393MBhttpd 2.4 2e202f453940 6 days ago 179MB10.0.0.100:5000/clsn/busybox 1.0 5b0d59026729 8 days ago 1.15MB 4、将新打标签的镜像上传镜像到仓库 1[root@docker01 ~]# docker push 10.0.0.100:5000/clsn/busybox 10.2. 带basic认证的仓库1、安装加密工具 1[root@docker01 clsn]# yum install httpd-tools -y 2、设置认证密码 12mkdir /opt/registry-var/auth/ -phtpasswd -Bbn clsn 123456 &gt; /opt/registry-var/auth/htpasswd 3、启动容器，在启动时传入认证参数 1docker run -d -p 5000:5000 -v /opt/registry-var/auth/:/auth/ -e &quot;REGISTRY_AUTH=htpasswd&quot; -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd registry 4、使用验证用户测试 12345678910111213141516171819202122232425# 登陆用户[root@docker01 ~]# docker login 10.0.0.100:5000 Username: clsn Password: 123456Login Succeeded# 推送镜像到仓库[root@docker01 ~]# docker push 10.0.0.100:5000/clsn/busybox The push refers to repository [10.0.0.100:5000/clsn/busybox]4febd3792a1f: Pushed 1.0: digest: sha256:4cee1979ba0bf7db9fc5d28fb7b798ca69ae95a47c5fecf46327720df4ff352d size: 527#认证文件的保存位置[root@docker01 ~]# cat .docker/config.json &#123; &quot;auths&quot;: &#123; &quot;10.0.0.100:5000&quot;: &#123; &quot;auth&quot;: &quot;Y2xzbjoxMjM0NTY=&quot; &#125;, &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;Y2xzbjpIenNAMTk5Ng==&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/17.12.0-ce (linux)&quot; &#125;&#125; 至此，一个简单的docker镜像仓库搭建完成 11. docker-compose编排工具11.1. 安装docker-compose1234# 下载pip软件yum install -y python2-pip# 下载 docker-composepip install docker-compose 国内开启pip 下载加速： http://mirrors.aliyun.com/help/pypi 1234567mkdir ~/.pip/cat &gt; ~/.pip/pip.conf &lt;&lt;&#x27;EOF&#x27;[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.comEOF 11.2. 编排启动镜像1、创建文件目录 12[root@docker01 ~]# mkdir /opt/my_wordpress/[root@docker01 ~]# cd /opt/my_wordpress/ 2、编写编排文件 1234567891011121314151617181920212223242526[root@docker01 my_wordpress]# vim docker-compose.ymlversion: &#x27;3&#x27;services: db: image: mysql:5.7 volumes: - /data/db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - /data/web_data:/var/www/html ports: - &quot;8000:80&quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress 3、启动 123[root@docker01 my_wordpress]# docker-compose up #启动方法：docker-compose up #后台启动方法：docker-compose up -d 4、浏览器上访问http://10.0.0.100:8000 进行wordpress的安装即可 11.3. haproxy代理后端docker容器1、修改编排脚本 1234567891011121314151617181920212223242526[root@docker01 my_wordpress]# cat docker-compose.yml version: &#x27;3&#x27;services: db: image: mysql:5.7 volumes: - /data/db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - /data/web_data:/var/www/html ports: - &quot;80&quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress 2、同时启动两台wordpress 1234[root@docker01 my_wordpress]# docker-compose scale wordpress=2 WARNING: The scale command is deprecated. Use the up command with the --scale flag instead.Starting mywordpress_wordpress_1 ... doneCreating mywordpress_wordpress_2 ... done 3、安装haproxy 1[root@docker01 ~]# yum install haproxy -y 4、修改haproxy配置文件 关于配置文件的详细说明，参考： https://www.cnblogs.com/MacoLee/p/5853413.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@docker01 ~]#cp /etc/haproxy/haproxy.cfg&#123;,.bak&#125;[root@docker01 ~]# vim /etc/haproxy/haproxy.cfgglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/stats level admin #支持命令行控制defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000listen stats mode http bind 0.0.0.0:8888 stats enable stats uri /haproxy-status stats auth admin:123456frontend frontend_www_example_com bind 10.0.0.100:8000 mode http option httplog log global default_backend backend_www_example_combackend backend_www_example_com option forwardfor header X-REAL-IP option httpchk HEAD / HTTP/1.0 balance roundrobin server web-node1 10.0.0.100:32768 check inter 2000 rise 30 fall 15 server web-node2 10.0.0.100:32769 check inter 2000 rise 30 fall 15 5、启动haproxy 12systemctl start haproxysystemctl enable haproxy 6、使用浏览器访问hapeoxy监听的8000端口可以看到负载的情况 7、使用浏览器访问 http://10.0.0.100:8888/haproxy-status 可以看到后端节点的监控状况， 11.4. 安装socat 直接操作socket控制haproxy1、安装软件 1yum install socat.x86_64 -y 2、查看帮助 1[root@docker01 web_data]# echo &quot;help&quot;|socat stdio /var/lib/haproxy/stats 3、下线后端节点 1echo &quot;disable server backend_www_example_com/web-node2&quot;|socat stdio /var/lib/haproxy/stats 4、上线后端节点 1echo &quot;enable server backend_www_example_com/web-node3&quot;|socat stdio /var/lib/haproxy/stats 5、编写php测试页，放到&#x2F;data&#x2F;web_data下，在浏览器中访问可以查看当前的节点 123456789101112[root@docker01 web_data]# vim check.php&lt;html&gt; &lt;head&gt; &lt;title&gt;PHP测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;?php echo &#x27;&lt;p&gt;Hello World &lt;/p&gt;&#x27;; ?&gt; &lt;?php echo &quot;访问的服务器地址是:&quot;.&quot;&lt;fontcolor=red&gt;&quot;.$_SERVER[&#x27;SERVER_ADDR&#x27;].&quot;&lt;/font&gt;&quot;.&quot;&lt;br&gt;&quot;; echo&quot;访问的服务器域名是:&quot;.&quot;&lt;fontcolor=red&gt;&quot;.$_SERVER[&#x27;SERVER_NAME&#x27;].&quot;&lt;/font&gt;&quot;.&quot;&lt;br&gt;&quot;; ?&gt; &lt;/body&gt;&lt;/html&gt; 12. 重启docker服务，容器全部退出的解决办法12.1. 在启动是指定自动重启1docker run --restart=always 12.1. 修改docker默认配置文件12# 添加上下面这行&quot;live-restore&quot;: true docker server配置文件 &#x2F;etc&#x2F;docker&#x2F;daemon.json 参考 1234567[root@docker02 ~]# cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;graph&quot;: &quot;/opt/mydocker&quot;, # 修改数据的存放目录到/opt/mydocker/，原/var/lib/docker/ &quot;insecure-registries&quot;: [&quot;10.0.0.100:5000&quot;], &quot;live-restore&quot;: true&#125; 重启生效，只对在此之后启动的容器生效 1[root@docker01 ~]# systemctl restart docker.service 13. Docker网络类型 13.1. docker的网络类型 Bridge默认docker网络隔离基于网络命名空间，在物理机上创建docker容器时会为每一个docker容器分配网络命名空间，并且把容器IP桥接到物理机的虚拟网桥上。 13.2. 不为容器配置网络功能此模式下创建容器是不会为容器配置任何网络参数的，如：容器网卡、IP、通信路由等，全部需要自己去配置。 123456[root@docker01 ~]# docker run -it --network none busybox:latest /bin/sh / # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 13.3. 与其他容器共享网络配置(Container）此模式和host模式很类似，只是此模式创建容器共享的是其他容器的IP和端口而不是物理机，此模式容器自身是不会配置网络和端口，创建此模式容器进去后，你会发现里边的IP是你所指定的那个容器IP并且端口也是共享的，而且其它还是互相隔离的，如进程等。 12345678910[root@docker01 ~]# docker run -it --network container:mywordpress_db_1 busybox:latest /bin/sh / # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever105: eth0@if106: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff inet 172.18.0.3/16 brd 172.18.255.255 scope global eth0 valid_lft forever preferred_lft forever 13.4. 使用宿主机网络此模式创建的容器没有自己独立的网络命名空间，是和物理机共享一个Network Namespace，并且共享物理机的所有端口与IP，并且这个模式认为是不安全的。 1[root@docker01 ~]# docker run -it --network host busybox:latest /bin/shshell 13.5. 查看网络列表123456[root@docker01 ~]# docker network list NETWORK ID NAME DRIVER SCOPEb15e8a720d3b bridge bridge local345d65b4c2a0 host host localbc5e2a32bb55 mywordpress_default bridge localebf76eea91bb none null local 用PIPEWORK为docker容器配置独立IP 参考文档： blog.csdn.net&#x2F;design321&#x2F;article&#x2F;details&#x2F;48264825 官方网站： github.com&#x2F;jpetazzo&#x2F;pipework 宿主环境：centos7.2 1、安装pipework 1234wget https://github.com/jpetazzo/pipework/archive/master.zipunzip master.zip cp pipework-master/pipework /usr/local/bin/chmod +x /usr/local/bin/pipework 2、配置桥接网卡 安装桥接工具 1yum install bridge-utils.x86_64 -y 修改网卡配置，实现桥接 1234567891011121314151617181920# 修改eth0配置，让br0实现桥接[root@docker01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE=EthernetBOOTPROTO=staticNAME=eth0DEVICE=eth0ONBOOT=yesBRIDGE=br0[root@docker01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 TYPE=BridgeBOOTPROTO=staticNAME=br0DEVICE=br0ONBOOT=yesIPADDR=10.0.0.100NETMASK=255.255.255.0GATEWAY=10.0.0.254DNS1=223.5.5.5# 重启网络[root@docker01 ~]# /etc/init.d/network restart 3、运行一个容器镜像测试： 1pipework br0 $(docker run -d -it -p 6880:80 --name httpd_pw httpd) 10.0.0.220/24@10.0.0.254 在其他主机上测试端口及连通性 12345[root@docker01 ~]# curl 10.0.0.220&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;[root@docker01 ~]# ping 10.0.0.220 -c 1PING 10.0.0.220 (10.0.0.220) 56(84) bytes of data.64 bytes from 10.0.0.220: icmp_seq=1 ttl=64 time=0.043 ms 4、再运行一个容器，设置网路类型为none： 1pipework br0 $(docker run -d -it --net=none --name test httpd:2.4) 10.0.0.221/24@10.0.0.254 进行访问测试 12[root@docker01 ~]# curl 10.0.0.221&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 5、重启容器后需要再次指定： 12pipework br0 testduliip 172.16.146.113/24@172.16.146.1pipework br0 testduliip01 172.16.146.112/24@172.16.146.1 Dcoker跨主机通信之overlay可以参考： cnblogs.com&#x2F;CloudMan6&#x2F;p&#x2F;7270551.html 13.6. Docker跨主机通信之macvlan创建网络 12[root@docker01 ~]# docker network create --driver macvlan --subnet 10.1.0.0/24 --gateway 10.1.0.254 -o parent=eth0 macvlan_133a1f41dcc074f91b5bd45e7dfedabfb2b8ec82db16542f05213839a119b62ca 设置网卡为混杂模式 1ip link set eth0 promisc on 创建使用macvlan网络容器 1[root@docker02 ~]# docker run -it --network macvlan_1 --ip=10.1.0.222 busybox /b 14. docker企业级镜像仓库harbor容器管理 123[root@docker01 harbor]# pwd/opt/harbor[root@docker01 harbor]# docker-compose stop 1、安装docker、docker-compose 下载 harbor 12cd /opt &amp;&amp; https://storage.googleapis.com/harbor-releases/harbor-offline-installer-v1.3.0.tgztar xf harbor-offline-installer-v1.3.0.tgz 2、修改主机及web界面密码 12345[root@docker01 harbor]# vim harbor.cfg ··· hostname = 10.0.0.100 harbor_admin_password = Harbor12345 ··· 3、执行安装脚本 1[root@docker01 harbor]# ./install.sh 浏览器访问 http://10.0.0.11 添加一个项目 4、镜像推送到仓库的指定项目 1234567891011[root@docker02 ~]# docker tag centos:6.8 10.0.0.100/clsn/centos6.8:1.0[root@docker02 ~]# [root@docker02 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZEbusybox latest 5b0d59026729 8 days ago 1.15MB10.0.0.100/clsn/centos6.8 1.0 6704d778b3ba 2 months ago 195MBcentos 6.8 6704d778b3ba 2 months ago 195MB[root@docker02 ~]# docker login 10.0.0.100Username: adminPassword: Login Succeeded 5、推送镜像 123[root@docker02 ~]# docker push 10.0.0.100/clsn/centos6.8 The push refers to repository [10.0.0.100/clsn/centos6.8]e00c9229b481: Pushing 13.53MB/194.5MB 6、在web界面里查看 14.1. 使用容器的建议 不要以拆分方式进行应用程序发布 不要创建大型镜像 不要在单个容器中运行多个进程 不要再镜像内保存凭证，不要依赖IP地址 以非root用户运行进程 不要使用“最新”标签 不要利用运行中的容器创建镜像 不要使用单层镜像 不要将数据存放在容器内 14.2. 关于Docker容器的监控容器的基本信息 包括容器的数量、ID、名称、镜像、启动命令、端口等信息 容器的运行状态 统计各状态的容器的数量，包括运行中、暂停、停止及异常退出 容器的用量信息 统计容器的CPU使用率、内存使用量、块设备I&#x2F;O使用量、网络使用情况等资源的使用情况 参考文献 redhat.com&#x2F;zh&#x2F;topics&#x2F;containers&#x2F;whats-a-linux-container redhat.com&#x2F;zh&#x2F;topics&#x2F;containers&#x2F;what-is-docker blog.51cto.com&#x2F;dihaifeng&#x2F;1713512 cnblogs.com&#x2F;Bourbon-tian&#x2F;p&#x2F;6867796.html cnblogs.com&#x2F;CloudMan6&#x2F;p&#x2F;6806193.html","tags":["开发工具","Docker"],"categories":["开发工具"]},{"title":"MySQL大表优化方案","path":"/2023/12/24/MySQL大表优化方案/","content":"当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化： 单表优化除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量： 字段 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED VARCHAR的长度只分配真正需要的空间 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP而非DATETIME， 单表不要有太多字段，建议在20以内 避免使用NULL字段，很难查询优化且占用额外索引空间 用整型来存IP 索引 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描 值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段 字符字段只建前缀索引 字符字段最好不要做主键 不用外键，由程序保证约束 尽量不用UNIQUE，由程序保证约束 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引 查询SQL 可通过开启慢查询日志来找出较慢的SQL 不做列运算：SELECT id WHERE age + 1 &#x3D; 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边 sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库 不用SELECT * OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内 不用函数和触发器，在应用程序实现 避免%xxx式查询 少用JOIN 使用同类型进行比较，比如用’123’和’123’比，123和123比 尽量避免在WHERE子句中使用!&#x3D;或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大 引擎目前广泛使用的是MyISAM和InnoDB两种引擎： MyISAMMyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是： 不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁 不支持事务 不支持外键 不支持崩溃后的安全恢复 在表有读取查询的同时，支持往表中插入新纪录 支持BLOB和TEXT的前500个字符索引，支持全文索引 支持延迟更新索引，极大提升写入性能 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用 InnoDBInnoDB在MySQL 5.5后成为默认索引，它的特点是： 支持行锁，采用MVCC来支持高并发 支持事务 支持外键 支持崩溃后的安全恢复 不支持全文索引 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 系统调优参数可以使用下面几个工具来做基准测试： sysbench：一个模块化，跨平台以及多线程的性能测试工具 iibench-mysql：基于 Java 的 MySQL&#x2F;Percona&#x2F;MariaDB 索引进行插入性能测试工具 tpcc-mysql：Percona开发的TPC-C测试工具 具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数： back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500 wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时 max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限 thread_concurrency：并发线程数，设为CPU核数的两倍 skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问 key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询show status like ‘key_read%’，保证key_reads &#x2F; key_read_requests在0.1%以下最好 innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询show status like ‘Innodb_buffer_pool_read%’，保证 (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) &#x2F; Innodb_buffer_pool_read_requests越高越好 innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小 innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率(Qcache_hits&#x2F;(Qcache_hits+Qcache_inserts)*100))进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大.可以通过命令show status like ‘Qcache_%’查看目前系统Query catch使用大小 read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能 sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小 read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值 thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的 table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM 升级硬件Scale up，这个不多说了，根据MySQL是CPU密集型还是I&#x2F;O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能 读写分离也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离 缓存缓存可以发生在这些层次： MySQL内部：在系统调优参数介绍了相关设置 数据访问层：比如MyBatis针对SQL语句做缓存，而Hibernate可以精确到单个记录，这里缓存的对象主要是持久化对象Persistence Object 应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象Data Transfer Object Web层：针对web页面做缓存 浏览器客户端：用户端的缓存 可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式： 直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如Spring Cache的工作方式。这种实现非常简单，同步好，但效率一般。 回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。 表分区MySQL在5.1版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码 对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对SQL层来说是一个完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引 用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过EXPLAIN PARTITIONS来查看某条SQL语句会落在那些分区上，从而进行SQL优化，如下图5条记录落在两个分区上： 12345678mysql&gt; explain partitions select count(1) from user_partition where id in (1,2,3,4,5);+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| 1 | SIMPLE | user_partition | p1,p4 | range | PRIMARY | PRIMARY | 8 | NULL | 5 | Using where; Using index |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+1 row in set (0.00 sec) 分区的好处是： 可以让单表存储更多的数据 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作 部分查询能够从查询条件确定只落在少数分区上，速度会很快 分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备 可以使用分区表赖避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争 可以备份和恢复单个分区 分区的限制和缺点： 一个表最多只能有1024个分区 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来 分区表无法使用外键约束 NULL值会使分区过滤无效 所有分区必须使用相同的存储引擎 分区的类型： RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区 LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL中有效的、产生非负整数值的任何表达式 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值 分区适合的场景有： 最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示： 1234567891011121314CREATE TABLE members ( firstname VARCHAR(25) NOT NULL, lastname VARCHAR(25) NOT NULL, username VARCHAR(16) NOT NULL, email VARCHAR(35), joined DATE NOT NULL)PARTITION BY RANGE( YEAR(joined) ) ( PARTITION p0 VALUES LESS THAN (1960), PARTITION p1 VALUES LESS THAN (1970), PARTITION p2 VALUES LESS THAN (1980), PARTITION p3 VALUES LESS THAN (1990), PARTITION p4 VALUES LESS THAN MAXVALUE); 查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存 另外MySQL有一种早期的简单的分区实现 - 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代 垂直拆分垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联 比如原始的用户表是： 垂直拆分后是： 垂直拆分的优点是： 可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I&#x2F;O次数(每次查询时读取的Block 就少) 可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起 数据维护简单 缺点是： 主键出现冗余，需要管理冗余列 会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力 依然存在单表数据量过大的问题（需要水平拆分） 事务处理复杂 水平拆分概述水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。 前面的表分区本质上也是一种特殊的库内分表 库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决 前面垂直拆分的用户表如果进行水平拆分，结果是： 实际情况中往往会是垂直拆分和水平拆分的结合，即将Users_A_M和Users_N_Z再拆成Users和UserExtras，这样一共四张表 水平拆分的优点是: 不存在单库大数据和高并发的性能瓶颈 应用端改造较少 提高了系统的稳定性和负载能力 缺点是： 分片事务一致性难以解决 跨节点Join性能差，逻辑复杂 数据多次扩展难度跟维护量极大 分片原则 能不分就不分，参考单表优化 分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询SQL跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量 分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性Hash分片，这几种分片都有利于扩容 尽量不要在一个事务中的SQL跨越多个分片，分布式事务一直是个不好处理的问题 查询条件尽量优化，尽量避免Select * 的方式，大量数据结果集下，会消耗大量带宽和CPU资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。 通过数据冗余和表分区赖降低跨库Join的可能 这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤，比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。 总体上来说，分片的选择是取决于最频繁的查询SQL的条件，因为不带任何Where语句的查询SQL，会遍历所有的分片，性能相对最差，因此这种SQL越多，对系统的影响越大，所以我们要尽量避免这种SQL的产生。 解决方案由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。 客户端架构通过修改数据访问层，如JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以Jar包的方式呈现 这是一个客户端架构的例子： 可以看到分片的实现是和应用服务器在一起的，通过修改Spring JDBC层来实现 客户端架构的优点是： 应用直连数据库，降低外围系统依赖所带来的宕机风险 集成成本低，无需额外运维的组件 缺点是： 限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心 将分片逻辑的压力放在应用服务器上，造成额外风险 代理架构通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件 这是一个代理架构的例子： 代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要Zookeeper之类的服务组件来管理 代理架构的优点是： 能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强 对于应用服务器透明且没有增加任何额外负载 缺点是： 需部署和运维独立的代理中间件，成本高 应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险 各方案比较 出品方 架构模型 支持数据库 分库 分表 读写分离 外部依赖 是否开源 实现语言 支持语言 最后更新 Github星数 MySQL Fabric MySQL官方 代理架构 MySQL 有 有 有 无 是 python 无限制 4个月前 35 Cobar 阿里巴巴 代理架构 MySQL 有 无 无 无 是 Java 无限制 两年前 1287 Cobar Client 阿里巴巴 客户端架构 MySQL 有 无 无 无 是 Java Java 三年前 344 TDDL 淘宝 客户端架构 无限制 有 有 有 Diamond 只开源部分 Java Java 未知 519 Atlas 奇虎360 代理架构 MySQL 有 有 有 无 是 C 无限制 10个月前 1941 Heisenberg 百度熊照 代理架构 MySQL 有 有 有 无 是 Java 无限制 2个月前 197 TribeDB 个人 代理架构 MySQL 有 有 有 无 是 NodeJS 无限制 3个月前 126 ShardingJDBC 当当 客户端架构 MySQL 有 有 有 无 是 Java Java 当天 1144 Shark 个人 客户端架构 MySQL 有 有 无 无 是 Java Java 两天前 84 KingShard 个人 代理架构 MySQL 有 有 有 无 是 Golang 无限制 两天前 1836 OneProxy 平民软件 代理架构 MySQL 有 有 有 无 否 未知 无限制 未知 未知 MyCat 社区 代理架构 MySQL 有 有 有 无 是 Java 无限制 两天前 1270 Vitess Youtube 代理架构 MySQL 有 有 有 无 是 Golang 无限制 当天 3636 Mixer 个人 代理架构 MySQL 有 有 无 无 是 Golang 无限制 9个月前 472 JetPants Tumblr 客户端架构 MySQL 有 有 无 无 是 Ruby Ruby 10个月前 957 HibernateShard Hibernate 客户端架构 无限制 有 有 无 无 是 Java Java 4年前 57 MybatisShard MakerSoft 客户端架构 无限制 有 有 无 无 是 Java Java 11个月前 119 Gizzard Twitter 代理架构 无限制 有 有 无 无 是 Java 无限制 3年前 2087 如此多的方案，如何进行选择？可以按以下思路来考虑： 确定是使用代理架构还是客户端架构。中小型规模或是比较简单的场景倾向于选择客户端架构，复杂场景或大规模系统倾向选择代理架构 具体功能是否满足，比如需要跨节点ORDER BY，那么支持该功能的优先考虑 不考虑一年内没有更新的产品，说明开发停滞，甚至无人维护和技术支持 最好按大公司-&gt;社区-&gt;小公司-&gt;个人这样的出品方顺序来选择 选择口碑较好的，比如github星数、使用者数量质量和使用者反馈 开源的优先，往往项目有特殊需求可能需要改动源代码 按照上述思路，推荐以下选择： 客户端架构：ShardingJDBC 代理架构：MyCat或者Atlas 兼容MySQL且可水平扩展的数据库目前也有一些开源数据库兼容MySQL协议，如： TiDB Cubrid 但其工业品质和MySQL尚有差距，且需要较大的运维投入，如果想将原始的MySQL迁移到可水平扩展的新数据库中，可以考虑一些云数据库： 阿里云PetaData 阿里云OceanBase 腾讯云DCDB NoSQL在MySQL上做Sharding是一种戴着镣铐的跳舞，事实上很多大表本身对MySQL这种RDBMS的需求并不大，并不要求ACID，可以考虑将这些表迁移到NoSQL，彻底解决水平扩展问题，例如： 日志类、监控类、统计类数据 非结构化或弱结构化数据 对事务要求不强，且无太多关联操作的数据","tags":["MySQL","DataBase","SQL优化"],"categories":["DataBase"]},{"title":"MyBatis 的执行流程","path":"/2023/12/24/MyBatis-的执行流程！/","content":"概要在MyBatis中，利用编程式进行数据查询，主要就是下面几行代码： 123SqlSession session = sqlSessionFactory.openSession();UserMapper userMapper = session.getMapper(UserMapper.class);List&lt;LwUser&gt; userList = userMapper.listUserByUserName(&quot;孤狼1号&quot;); 第一行是获取一个SqlSession对象在上一篇文章分析过了，第二行就是获取UserMapper接口，第三行一行代码就实现了整个查询语句的流程，接下来我们就来仔细分析一下第二和第三步。 获取Mapper接口(getMapper)第二步是通过SqlSession对象是获取一个Mapper接口，这个流程还是相对简单的，下面就是我们调用session.getMapper方法之后的运行时序图： 1、在调用getMapper之后，会去Configuration对象中获取Mapper对象，因为在项目启动的时候就会把Mapper接口加载并解析存储到Configuration对象 2、通过Configuration对象中的MapperRegistry对象属性，继续调用getMapper方法 3、根据type类型，从MapperRegistry对象中的knownMappers获取到当前类型对应的代理工厂类，然后通过代理工厂类生成对应Mapper的代理类 4、最终获取到我们接口对应的代理类MapperProxy对象 而MapperProxy可以看到实现了InvocationHandler，使用的就是JDK动态代理。 至此获取Mapper流程结束了，那么就有一个问题了MapperRegistry对象内的HashMap属性knownMappers中的数据是什么时候存进去的呢？ Mapper接口和映射文件是何时关联的Mapper接口及其映射文件是在加载mybatis-config配置文件的时候存储进去的，下面就是时序图： 1、首先我们会手动调用SqlSessionFactoryBuilder方法中的build()方法： 2、然后会构造一个XMLConfigBuilder对象，并调用其parse方法： 3、然后会继续调用自己的parseConfiguration来解析配置文件，这里面就会分别去解析全局配置文件的顶级节点，其他的我们先不看，我们直接看最后解析mappers节点 4、继续调用自己的mapperElement来解析mappers文件（这个方法比较长，为了方便截图完整，所以把字体缩小了1号），可以看到，这里面分了四种方式来解析mappers节点的配置，对应了4种mapper配置方式，而其中红框内的两种方式是直接配置的xml映射文件，蓝框内的两种方式是解析直接配置Mapper接口的方式，从这里也可以说明，不论配置哪种方式，最终MyBatis都会将xml映射文件和Mapper接口进行关联。 5、我们先看第2种和第3中（直接配置xml映射文件的解析方式），会构建一个XMLMapperBuilder对象并调用其parse方法。 当然，这个还是会被解析的，后面执行查询的时候会再次通过不断遍历去全部解析完毕，不过有一点需要注意的是，互相引用这种是会导致解析失败报错的，所以在开发过程中我们应该避免循环依赖的产生。 6、解析完映射文件之后，调用自身方法bindMapperForNamespace，开始绑定Mapper接口和映射文件： 7、调用Configuration对象的addMapper 8、调用Configuration对象的属性MapperRegistry内的addMapper方法，这个方法就是正式将Mapper接口添加到knownMappers，所以上面getMapper可以直接获取： 到这里我们就完成了Mapper接口和xml映射文件的绑定 9、注意上面红框里面的代码，又调用了一次parse方法，这个parse方法主要是解析注解，比如下面的语句： 12@Select(&quot;select * from lw_user&quot;)List&lt;LwUser&gt; listAllUser(); 所以这个方法里面会去解析@Select等注解，需要注意的是，parse方法里面会同时再解析一次xml映射文件，因为上面我们提到了mappers节点有4种配置方式，其中两种配置的是Mapper接口，而配置Mapper接口会直接先调用addMapper接口，并没有解析映射文件，所以进入注解解析方法parse之中会需要再尝试解析一次XML映射文件。 解析完成之后，还会对Mapper接口中的方法进行解析，并将每个方法的全限定类名作为key存入存入Configuration中的mappedStatements属性。 需要指出的是，这里存储的时候，同一个value会存储2次，**一个全限定名作为key，另一个就是只用方法名(sql语句的id)来作为key**： 所以最终mappedStatements会是下面的情况： 事实上如果我们通过接口的方式来编程的话，最后来getStatement的时候，都是根据全限定名来取的，所以即使有重名对我们也没有影响，而之所以要这么做的原因其实还是为了兼容早期版本的用法，那就是不通过接口，而是直接通过方法名的方式来进行查询： 1session.selectList(&quot;com.lonelyWolf.mybatis.mapper.UserMapper.listAllUser&quot;); 这里如果shortName没有重复的话，是可以直接通过简写来查询的： 1session.selectList(&quot;listAllUser&quot;); 但是通过简写来查询一旦shortName重复了就会抛出以下异常： 这里的异常其实就是StrickMap的get方法抛出来的： sql执行流程分析上面我们讲到了，获取到的Mapper接口实际上被包装成为了代理对象，所以我们执行查询语句肯定是执行的代理对象方法，接下来我们就以Mapper接口的代理对象MapperProxy来分析一下查询流程。 整个sql执行流程可以分为两大步骤： 一、寻找sql 二、执行sql语句 寻找sql首先还是来看一下寻找sql语句的时序图： 1、了解代理模式的应该都知道，调用被代理对象的方法之后实际上执行的就是代理对象的invoke方法 2、因为我们这里并没有调用Object类中的方法，所以肯定走的else。else中会继续调用MapperProxy内部类MapperMethodInvoker中的方法cachedInvoker，这里面会有一个判断，判断一下我们是不是default方法，因为Jdk1.8中接口中可以新增default方法，而default方法是并不是一个抽象方法，所以也需要特殊处理（刚开始会从缓存里面取，缓存相关知识我们这里先不讲，后面会单独写一篇来分析一下缓存)）。 3、接下来，是构造一个MapperMethod对象,这个对象封装了Mapper接口中对应的方法信息以及对应的sql语句信息： 这里面就会把要执行的sql语句，请求参数，方法返回值全部解析封装成MapperMethod对象，然后后面就可以开始准备执行sql语句了 执行sql语句还是先来看一下执行Sql语句的时序图： 1、我们继续上面的流程进入execute方法： 2、这里面会根据语句类型以及返回值类型来决定如何执行，本人这里返回的是一个集合，故而我们进入executeForMany方法： 3、这里面首先会将前面存好的参数进行一次转换，然后绕了这么一圈，回到了起点SqlSession对象，继续调用selectList方法： 3、接下来又讲流程委派给了Execute去执行query方法，最终又会去调用queryFromDatabase方法： 4、到这里之后，终于要进入正题了，一般带了这种do开头的方法就是真正做事的，Spring中很多地方也是采用的这种命名方式： 注意，前面我们的sql语句还是占位符的方式，并没有将参数设置进去，所以这里在return上面一行调用prepareStatement方法创建Statement对象的时候会去设置参数，替换占位符。参数如何设置我们先跳过，等把流程执行完了我们在单独分析参数映射和结果集映射。 5、继续进入PreparedStatementHandler对象的query方法，可以看到，这一步就是调用了jdbc操作对象PreparedStatement中的execute方法，最后一步就是转换结果集然后返回。 到这里，整个SQL语句执行流程分析就结束了，中途有一些参数的存储以及转换并没有深入进去，因为参数的转换并不是核心，只要清楚整个数据的流转流程，我们自己也可以有自己的实现方式，只要存起来最后我们能重新解析读出来就行。 参数映射现在我们来看一下上面在执行查询之前参数是如何进行设置的，我们先进入prepareStatement方法： 我们发现，最终是调用了StatementHandler中的parameterize进行参数设置，接下来这里为了节省篇幅，我们不会一步步点进去，直接进入设置参数的方法： 上面的BaseTypeHandler是一个抽象类，setNonNullParameter并没有实现，都是交给子类去实现，而每一个子类就是对应了数据库的一种类型。下图中就是默认的一个子类StringTypeHandler，里面没什么其他逻辑，就是设置参数。 可以看到String里面调用了jdbc中的setString方法，而如果是int也会调用setInt方法。看到这些子类如果大家之前阅读过我前面讲的MyBatis参数配置，应该就很明显可以知道，这些子类就是系统默认提供的一些typeHandler。而这些默认的typeHandler会默认被注册并和Java对象进行绑定： 正是因为MyBatis中默认提供了常用数据类型的映射，所以我们写Sql的时候才可以省略参数映射关系，可以直接采用下面的方式，系统可以根据我们参数的类型，自动选择合适的typeHander进行映射： 1select user_id,user_name from lw_user where user_name=#&#123;userName&#125; 上面这条语句实际上和下面这条是等价的： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR&#125; 或者说我们可以直接指定typeHandler： 1select user_id,user_name from lw_user where user_name = #&#123;userName,jdbcType=VARCHAR,typeHandler=org.apache.ibatis.type.IntegerTypeHandler&#125; 这里因为我们配置了typeHandler，所以会优先以配置的typeHandler为主不会再去读取默认的映射，如果类型不匹配就会直接报错了： 看到这里很多人应该就知道了，如果我们自己自定义一个typeHandler，然后就可以配置成我们自己的自定义类。所以接下来就让我们看看如何自定义一个typeHandler 自定义typeHandler自定义typeHandler需要实现BaseTypeHandler接口，BaseTypeHandler有4个方法，包括结果集映射，为了节省篇幅，代码没有写上来： 1234567891011121314151617package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; 然后我们改写一下上面的查询语句： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125; 然后执行，可以看到，自定义的typeHandler生效了： 结果集映射接下来让我们看看结果集的映射，回到上面执行sql流程的最后一个方法： 1resultSetHandler.handleResultSets(ps) 结果集映射里面的逻辑相对来说还是挺复杂的，因为要考虑到非常多的情况，这里我们就不会去深究每一个细节，直接进入到正式解析结果集的代码，下面的5个代码片段就是一个简单的但是完整的解析流程： 从上面的代码片段我们也可以看到，实际上解析结果集还是很复杂的，就如我们上一篇介绍的复杂查询一样，一个查询可以不断嵌套其他查询，还有延迟加载等等一些复杂的特性的处理，所以逻辑分支是有很多，但是不管怎么处理，最后的核心还是上面的一套流程，最终还是会调用typeHandler来获取查询到的结果。 是的，你没猜错，这个就是上面我们映射参数的typeHandler，因为typeHandler里面不只是一个设置参数方法，还有获取结果集方法(上面设置参数的时候省略了)。 自定义typeHandler结果集所以说我们还是用上面那个MyTypeHandler 例子来重写一下取值方法(省略了设置参数方法)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; /** * 设置参数 */ @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;设置参数-&gt;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; /** * 根据列名获取结果 */ @Override public String getNullableResult(ResultSet resultSet, String columnName) throws SQLException &#123; System.out.println(&quot;根据columnName获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnName); &#125; /** * 根据列的下标来获取结果 */ @Override public String getNullableResult(ResultSet resultSet, int columnIndex) throws SQLException &#123; System.out.println(&quot;根据columnIndex获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnIndex); &#125; /** * 处理存储过程的结果集 */ @Override public String getNullableResult(CallableStatement callableStatement, int columnIndex) throws SQLException &#123; return callableStatement.getString(columnIndex); &#125;&#125; 改写Mapper映射文件配置： 12345678&lt;resultMap id=&quot;MyUserResultMap&quot; type=&quot;lwUser&quot;&gt; &lt;result column=&quot;user_id&quot; property=&quot;userId&quot; jdbcType=&quot;VARCHAR&quot; typeHandler=&quot;com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&quot; /&gt; &lt;result column=&quot;user_name&quot; property=&quot;userName&quot; jdbcType=&quot;VARCHAR&quot; /&gt;&lt;/resultMap&gt;&lt;select id=&quot;listUserByUserName&quot; parameterType=&quot;String&quot; resultMap=&quot;MyUserResultMap&quot;&gt; select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125;&lt;/select&gt; 执行之后输出如下： 因为我们属性上面只配置了一个属性，所以只输出了一次。 工作流程图上面介绍了代码的流转，可能绕来绕去有点晕，所以我们来画一个主要的对象之间流程图来更加清晰的展示一下MyBatis主要工作流程： 从上面的工作流程图上我们可以看到，SqlSession下面还有4大对象，这4大对象也很重要，后面学习拦截器的时候就是针对这4大对象进行的拦截，关于这4大对象的具体详情，我们下一篇文章再展开分析。 总结本文主要分析了MyBatis的SQL执行流程。在分析流程的过程中，我们也举例论证了如何自定义typeHandler来实现自定义的参数映射和结果集映射，不过MyBatis中提供的默认映射其实可以满足大部分的需求，如果我们对某些属性需要特殊处理，那么就可以采用自定义的typeHandler来实现，相信如果本文如果读懂了，以下几点大家应该至少会有一个清晰的认识： 1、Mapper接口和映射文件是如何进行绑定的 2、MyBatis中SQL语句的执行流程 3、自定义MyBatis中的参数设置处理器typeHandler 4、自定义MyBatis中结果集处理器typeHandler 当然，其中很多细节并没有提到，而看源码我们也并不需要追求每一行代码都能看懂，就比如我们一个稍微复杂一点的业务系统，即使我们是项目开发者如果某一个模块不是本人负责的，恐怕也很难搞清楚每一行代码的含义。所以对于MyBatis及其他框架的源码中也是一样，首先应该从大局入手，掌握整体流程和设计思想，然后如果对某些实现细节感兴趣，再深入进行了解。","tags":["MyBatis","框架"],"categories":["框架"]},{"title":"用“状态模式”代替if-else","path":"/2023/12/24/用“状态模式”代替if-else/","content":"简介 状态模式是行为型设计模式的一种。其设计理念是当对象的内部状态发生改变时，随之改变其行为。状态和行为之间是一一对应的。 该模式主要用于，对象的行为依赖于它的状态，并且其行为是随着状态的改变而切换时。 状态模式UML类图类图讲解 State：抽象状态接口（也可以定义成抽象类），该接口封装了所有状态所对应的行为。ConcreteStateA&#x2F;B：具体状态类，该类实现了抽象状态接口，会根据自身对应的状态来实现接口中定义的方法，还有另一个功能是指明如何过渡到下一个状态。Context：环境（上下文）角色，该类负责状态的切换，还持有一个State实例，代表当前环境所处状态。 案例讲解案例：通过状态模式来实现自助售卖机的功能。 状态接口12345678public interface State &#123; // 挑选商品 void choose(); // 付款 boolean payment(); // 分发商品 void dispenseCommodity();&#125; 挑选商品状态类123456789101112131415161718192021222324252627282930public class ChooseGoods implements State &#123; VendingMachine machine; public ChooseGoods(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; if (machine.getCount() &gt; 0) &#123; System.out.println(&quot;商品挑选成功，请及时付款！&quot;); machine.setState(machine.getPaymentState()); &#125; else &#123; System.out.println(&quot;很遗憾，商品售罄了！&quot;); machine.setState(machine.getEmptyState()); &#125; &#125; @Override public boolean payment() &#123; System.out.println(&quot;请先挑选商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先挑选商品！&quot;); &#125;&#125; 付款状态类12345678910111213141516171819202122232425262728293031public class PaymentState implements State &#123; VendingMachine machine; public PaymentState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;商品已选购完成请勿重复挑选&quot;); &#125; @Override public boolean payment() &#123; Random random = new Random(); int num = random.nextInt(10); if(num % 2 == 0)&#123; System.out.println(&quot;付款成功！&quot;); machine.setState(machine.getDispenseCommodityState()); return true; &#125; System.out.println(&quot;付款失败，请重新支付！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先完成支付！&quot;); &#125;&#125; 商品售罄状态类123456789101112131415161718192021222324public class EmptyState implements State &#123; VendingMachine machine; public EmptyState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125;&#125; 分发商品状态类12345678910111213141516171819202122232425public class DispenseCommodityState implements State &#123; VendingMachine machine; public DispenseCommodityState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); machine.setState(machine.getChooseGoods()); &#125;&#125; 自动售货机 &#x3D;&gt; Context角色123456789101112131415161718192021222324252627282930313233public class VendingMachine &#123; // 表示当前状态 private State state = null; // 商品数量 private int count = 0; private State chooseGoods = new ChooseGoods(this); private State paymentState = new PaymentState(this); private State dispenseCommodityState = new DispenseCommodityState(this); private State emptyState = new EmptyState(this); public VendingMachine(int count) &#123; this.count = count; this.state = this.getChooseGoods(); &#125; // 购买商品 public void purchase() &#123; // 挑选商品 state.choose(); // 支付成功 if (state.payment()) &#123; // 分发商品 state.dispenseCommodity(); &#125; &#125; // 获取商品后将商品减一 public int getCount() &#123; return count--; &#125; // get和set方法 ... &#125; 客户端测试类12345678910public class Client &#123; public static void main(String[] args) &#123; VendingMachine machine = new VendingMachine(1); for (int i = 1; i &lt; 4; i++) &#123; System.out.println(&quot;第&quot; + i + &quot;次购买。&quot;); machine.purchase(); &#125; &#125;&#125; 执行结果总结1、状态模式将每个状态所对应的行为封装到一个类中，大大提高了代码的可读性。并且通过这样的设计还可以消除多余的if-else语句，方便代码的维护。 2、状态模式符合“开闭原则”，容易增加和删除状态。 3、任何事情都有利弊，状态模式也不例外。其最显著的问题是，每个状态都要对应一个类，当状态过多时会产生大量的类，从而加大维护成本。 4、应用场景：当一个需求有很多状态，并且状态之间会进行转换，不同状态还对应不同的行为时就可以考虑使用“状态模式”。","tags":["设计模式"],"categories":["设计模式"]},{"title":"Google 开源的 Guava 工具库","path":"/2023/12/24/Google-开源的-Guava-工具库/","content":"目前Google Guava在实际应用中非常广泛，本篇博客将以博主对Guava使用的认识以及在项目中的经验来给大家分享！正如标题所言，学习使用Google Guava可以让你快乐编程，写出优雅的JAVA代码！ 以面向对象思想处理字符串:Joiner&#x2F;Splitter&#x2F;CharMatcher JDK提供的String还不够好么？ 也许还不够友好，至少让我们用起来还不够爽，还得操心！ 举个栗子，比如String提供的split方法，我们得关心空字符串吧，还得考虑返回的结果中存在null元素吧，只提供了前后trim的方法（如果我想对中间元素进行trim呢）。 那么，看下面的代码示例，guava让你不必在操心这些： 123456789101112131415// 连接器private static final Joiner joiner = Joiner.on(&quot;,&quot;).skipNulls();// 分割器private static final Splitter splitter = Splitter.on(&quot;,&quot;).trimResults().omitEmptyStrings();public static void main(String[] args) &#123; // 把集合/数组中的元素 join 在一起 String join = joiner.join(Lists.newArrayList(&quot;a&quot;, null, &quot;b&quot;)); System.out.println(&quot;join=&quot; + join); for(String tmp : splitter.split(&quot;a, ,b,,&quot;)) &#123; System.out.println(&quot;|&quot; + tmp + &quot;|&quot;); &#125;&#125; Joiner&#x2F;Splitter Joiner是连接器，Splitter是分割器，通常我们会把它们定义为static final，利用on生成对象后在应用到String进行处理，这是可以复用的。要知道apache commons StringUtils提供的都是static method。 更加重要的是，guava提供的Joiner&#x2F;Splitter是经过充分测试，它的稳定性和效率要比apache高出不少，这个你可以自行测试下~ 发现没有我们想对String做什么操作，就是生成自己定制化的Joiner&#x2F;Splitter，多么直白，简单，流畅的API！ 对于Joiner，常用的方法是 跳过NULL元素：skipNulls() &#x2F; 对于NULL元素使用其他替代：useForNull(String) 对于Splitter，常用的方法是：trimResults()&#x2F;omitEmptyStrings()。注意拆分的方式，有字符串，还有正则，还有固定长度分割（太贴心了！） 其实除了Joiner&#x2F;Splitter外，guava还提供了字符串匹配器：CharMatcher 123456789101112private static final CharMatcher charMatcherDigit = CharMatcher.DIGIT;private static final Charmatcher charMatcherAny = CharMatcher.ANY;public static void main(String[] args) &#123; // 只保留匹配的字符，其他移除 System.out.println(charMatcherDigit.retainFrom(&quot;abc2def134f~&quot;)); // 移除匹配的字符 System.out.println(charMatcherDigit.removeFrom(&quot;yes,i love you 1314&quot;)); System.out.println(charMatcherAny.inRange(&#x27;a&#x27;, &#x27;f&#x27;).or(charMatcherAny.is(&#x27;a&#x27;)).replaceFrom(&quot;abcdefg&quot;,&quot;*&quot;));&#125; CharMatcher CharMatcher，将字符的匹配和处理解耦，并提供丰富的方法供你使用！ 对基本类型进行支持 guava对JDK提供的原生类型操作进行了扩展，使得功能更加强大！ 1234567891011121314151617// 快速完成到集合的转换List&lt;Integer&gt; list = Ints.asList(1, 3, 5, 7, 9);System.out.println(Ints.join(&quot;,&quot;, 1, 3, 1, 4));// 原生类型数据快速合并int[] newIntArray = Ints.concat(new int[]&#123;1, 2&#125;, new int[]&#123;2, 3, 4&#125;);System.out.println(newIntArray.length);// 最大/最小System.out.println(Ints.max(newIntArray) + &quot;,&quot; + Ints.min(newIntArray));// 是否包含System.out.println(Ints.contains(newArray, 6));// 集合到数组的转换int[] someArray = Ints.toArray(list); Ints guava提供了 Bytes&#x2F;Shorts&#x2F;Ints&#x2F;Iongs&#x2F;Floats&#x2F;Doubles&#x2F;Chars&#x2F;Booleans 这些基本数据类型的扩展支持，只有你想不到的，没有它没有的！ 对JDK集合的有效补充灰色地带:Multiset JDK的集合，提供了有序且可以重复的List，无序且不可以重复的Set。那这里其实对于集合涉及到了2个概念，一个order，一个dups。那么List vs Set，and then some ? Multiset Multiset是什么，我想上面的图，你应该了解它的概念了。Multiset就是无序的，但是可以重复的集合，它就是游离在List&#x2F;Set之间的“灰色地带”！（至于有序的，不允许重复的集合嘛，guava还没有提供，当然在未来应该会提供UniqueList，我猜的，哈哈） 来看一个Multiset的示例： 12345678910Multiset&lt;String&gt; multiset = HashMultiset.create();multiset.add(&quot;a&quot;);multiset.add(&quot;a&quot;);multiset.add(&quot;b&quot;);multiset.add(&quot;c&quot;);multiset.add(&quot;b&quot;);System.out.println(multiset.size());System.out.println(multiset.count(&quot;a&quot;)); Multiset Code Multiset自带一个有用的功能，就是可以跟踪每个对象的数量。 Immutable vs unmodifiable来我们先看一个unmodifiable的例子： 1234567891011121314// List 的不可变设置List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// 这种视图，不够安全，不是真正意义上的快照，怎么能随着而变化呢？List&lt;String&gt; readOnlyList = Collections.unmodifiableList(list);// readOnlyList.add(&quot;c&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionlist.acc(&quot;c&quot;);System.out.println(reaOnlyList.size()); // 3 unmodifiable 你看到JDK提供的unmodifiable的缺陷了吗？ 实际上，Collections.unmodifiableXxx所返回的集合和源集合是同一个对象，只不过可以对集合做出改变的API都被override，会抛出UnsupportedOperationException。 也即是说我们改变源集合，导致不可变视图（unmodifiable View）也会发生变化，oh my god! 当然，在不使用guava的情况下，我们是怎么避免上面的问题的呢？ 1234567// List 的不可变性设置List&lt;String&gt; list = new ArrayList&lt;~&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// new Object ; CopyList&lt;String&gt; readOnList = Collections.unmodifiableList(new ArrayList&lt;String&gt;(list)); defensive copies 上面揭示了一个概念：Defensive Copies，保护性拷贝。 OK，unmodifiable看上去没有问题呢，但是guava依然觉得可以改进，于是提出了Immutable的概念，来看： 12345678910// guava 是如何做的呢？List&lt;String&gt; immutable = ImmutabeList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);// immutable.add(&quot;d&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionList&lt;String&gt; immutable2 = ImmutableList.copyOf(list);list.add(&quot;d&quot;);// 视图不随着源而改变 guava 只读设置安全可靠 简单易用System.out.println(&quot;list size:&quot; + list.size() + &quot; immutable2.size:&quot; + immutables.size()); Immutable 就一个copyOf，你不会忘记，如此cheap~ 用Google官方的说法是：we’re using just one class,just say exactly what we mean，很了不起吗（不仅仅是个概念，Immutable在COPY阶段还考虑了线程的并发性等，很智能的！），O(∩_∩)O哈哈~ guava提供了很多Immutable集合，比如 ImmutableList&#x2F;ImmutableSet&#x2F;ImmutableSortedSet&#x2F;ImmutableMap&#x2F;…… 看一个ImmutableMap的例子： 123ImmutableMap&lt;String, String&gt; immutableMap = ImmutableMap.of(&quot;name&quot;, &quot;hubert&quot;, &quot;sex&quot;, &quot;man&quot;);immutableMap.put(&quot;wife&quot;, &quot;no...&quot;); // UnsupportedOperationException ImmutableMap 可不可以一对多：Multimap JDK提供给我们的Map是一个键，一个值，一对一的，那么在实际开发中，显然存在一个KEY多个VALUE的情况（比如一个分类下的书本），我们往往这样表达：Map&lt;k,List&lt;v&gt;&gt;，好像有点臃肿！臃肿也就算了，更加不爽的事，我们还得判断KEY是否存在来决定是否new 一个LIST出来，有点麻烦！更加麻烦的事情还在后头，比如遍历，比如删除，so hard…… 来看guava如何替你解决这个大麻烦的： 1234567Multimap&lt;String, String&gt; multiMap = ArrayListMultimap.create();multiMap.put(&quot;hubert&quot;, &quot;man&quot;);multiMap.put(&quot;hubert&quot;, &quot;yes&quot;);multiMap.put(&quot;lucy&quot;, &quot;woman&quot;);System.out.println(multiMap.get(&quot;hubert&quot;)); //collection Multimap 友情提示下，guava所有的集合都有create方法，这样的好处在于简单，而且我们不必在重复泛型信息了。 get()&#x2F;keys()&#x2F;keySet()&#x2F;values()&#x2F;entries()&#x2F;asMap()都是非常有用的返回view collection的方法。 Multimap的实现类有： ArrayListMultimap&#x2F;HashMultimap&#x2F;LinkedHashMultimap&#x2F;TreeMultimap&#x2F;ImmutableMultimap&#x2F;…… 可不可以双向：BiMap JDK提供的MAP让我们可以find value by key，那么能不能通过find key by value呢，能不能KEY和VALUE都是唯一的呢。这是一个双向的概念，即forward+backward。 在实际场景中有这样的需求吗？比如通过用户ID找到mail，也需要通过mail找回用户名。没有guava的时候，我们需要create forward map AND create backward map，and now just let guava do that for you. 12345678910111213BiMap&lt;String, String&gt; biMap = HashBiMap.create();biMap.put(&quot;name&quot;, &quot;hubert&quot;);// java.lang.IllegaArgumentException: value already present: hubert// value 重复会报错biMap.put(&quot;nick&quot;, &quot;hubert&quot;);// 强制覆盖 name:hubertbiMap.forcePut(&quot;nick&quot;, &quot;hubert&quot;);biMap.put(&quot;123&quot;, &quot;hubertwongcn@163.com&quot;);System.out.println(biMap.inverse().get(&quot;hubertwongcn@163.com&quot;)); // 123 BiMap biMap &#x2F; biMap.inverse() &#x2F; biMap.inverse().inverse() 它们是什么关系呢？ 你可以稍微看一下BiMap的源码实现，实际上，当你创建BiMap的时候，在内部维护了2个map，一个forward map，一个backward map，并且设置了它们之间的关系。 因此，biMap.inverse() !&#x3D; biMap ；biMap.inverse().inverse() &#x3D;&#x3D; biMap 可不可以多个KEY：Table 我们知道数据库除了主键外，还提供了复合索引，而且实际中这样的多级关系查找也是比较多的，当然我们可以利用嵌套的Map来实现：Map&lt;k1,Map&lt;k2,v2&gt;&gt;。为了让我们的代码看起来不那么丑陋，guava为我们提供了Table。 1234567Table&lt;String, String, Integer&gt; table = HashBaseTable.create();table.put(&quot;张三&quot;, &quot;计算机&quot;, 80);table.put(&quot;张三&quot;, &quot;数学&quot;, 90);table.put(&quot;张三&quot;, &quot;语文&quot;, 70);table.put(&quot;李四&quot;, &quot;计算机&quot;, 70);table.put(&quot;李四&quot;, &quot;数学&quot;, 60);table.put(&quot;李四&quot;, &quot;语文&quot;, 100); Table Table涉及到3个概念：rowKey,columnKey,value，并提供了多种视图以及操作方法让你更加轻松的处理多个KEY的场景。 函数式编程：Functions12345678910111213141516171819202122List&lt;String&gt; list = Lists.newArrayList(&quot;hello world&quot;, &quot;yes&quot;, &quot;hubert&quot;);Function&lt;String, String&gt; f1 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.length() &lt;= 5 ? s : s.substring(0, 5); &#125;&#125;;Function&lt;String, String&gt; f2 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.toUpperCase(); &#125;&#125;;Function&lt;String, String&gt; f3 = Functions.compose(f1, f2);Collection&lt;String&gt; collection = Collections2.transform(list, f3);for(String s : collection) &#123; System.out.println(s);&#125; Functions 上面的代码是为了完成将List集合中的元素，先截取5个长度，然后转成大写。 函数式编程的好处在于在集合遍历操作中提供自定义Function的操作，比如transform转换。我们再也不需要一遍遍的遍历集合，显著的简化了代码！ 12345678910Iterables.transform(Iterable, Function);Iterators.transform(Iterator, Function);Collections2.transform(Collection, Function);Lists.transform(List, Function);Maps.transformValues(Map, Function);Multimaps.transformValues(Multimap, Function);Multimaps.transformValues(ListMultimap, Funtion);Tables.transformValues(Table, Function);Maps.transformEntries(Map, EntryTransformer);// ... 对集合的transform操作可以通过Function完成 断言：Predicate12345678910111213List&lt;String&gt; list = Lists.newArrayList(&quot;moom&quot;, &quot;dad&quot;, &quot;refer&quot;, &quot;yes&quot;);Collection&lt;String&gt; collection = Collections2.filter(list, new Predicate&lt;String&gt;)) &#123; @Override public boolean apply(String s) &#123; // 业务逻辑 return new StringBuilder(s).reverse().toString().equals(s); &#125;&#125;;for(String s : collection) &#123; System.out.println(s);&#125; Predicate最常用的功能就是运用在集合的过滤当中！ 12345678Iterables.filter(Iterable, Predicate);Iterators.filter(Iterator, Predicate);Collectios2.filter(Collection, Predicate);Sets.filter(Set, Predicate);Sets.filter(SortedSet, Predicate);Maps.filterKeys(Map, Predicate);Multimaps.filterKeys(Multimap, Predicate);// ... filter 需要注意的是Lists并没有提供filter方法，不过你可以使用Collections2.filter完成！ check null and other：Optional、Preconditions在guava中，对于null的处理手段是快速失败，你可以看看guava的源码，很多方法的第一行就是：Preconditions.checkNotNull(elements); 要知道null是模糊的概念，是成功呢，还是失败呢，还是别的什么含义呢？ 12345678910111213public static void test(String name, int age, Map&lt;String, String&gt; extInfo) &#123; Preconditions.checkNotNull(name, &quot;name must be given!&quot;); Preconditions.checkArgument(age &gt;= 18, &quot;the game you can not play it, your age is under 18!&quot;); Map&lt;String, String&gt; defaulExtInfo = Maps.newHashMap(); defaultExtInfo.put(&quot;sex&quot;, &quot;man&quot;); extInfo = Optional.fromNullable(extInfo).or(defaultExtInfo); for(Map.Entry&lt;String, Stirng&gt; entry : extInfo.entrySet())) &#123; System.out.println(entry.getKey() + &quot;:&quot; + entry.getValue()); &#125;&#125; Preconditions&#x2F;Optional Cache is king 对于大多数互联网项目而言，缓存的重要性，不言而喻！ 如果我们的应用系统，并不想使用一些第三方缓存组件（如redis），我们仅仅想在本地有一个功能足够强大的缓存，很可惜JDK提供的那些SET&#x2F;MAP还不行！ 12345678910111213141516171819202122232425// 定义缓存的实现private static final CacheLoader&lt;Long, User&gt; userCacheLoader = new CacheLoader&lt;Long, User&gt;() &#123; @Override public User load(Long along) throws Exception &#123; // 模拟从数据库/Redis/缓存中加载数据 User user = new User(); user.setId(along); user.setName(Thread.currentThread().getName() + &quot;-&quot; new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;).format(new Date()) + &quot;-&quot; + along); System.out.println(&quot;load:&quot; + user); return user; &#125;&#125;;// 定义缓存的策略，提供对外访问缓存private static final LoadingCache&lt;Long, User&gt; userCacheData = CacheBuilder.newBuilder() .expireAfterAccess(2, TimeUnit.SECONDS) .expireAfterWrite(2, TimeUnit.SECONDS) .refreshAfterWrite(3, TimeUnit.SECONS) .maximumSize(10000L) .bulid(userCacheLoader); CacheLoader 首先，这是一个本地缓存，guava提供的cache是一个简洁、高效，易于维护的。为什么这么说呢？因为并没有一个单独的线程用于刷新 OR 清理cache，对于cache的操作，都是通过访问&#x2F;读写带来的，也就是说在读写中完成缓存的刷新操作！ 其次，我们看到了，我们非常通俗的告诉cache，我们的缓存策略是什么，SO EASY！在如此简单的背后，是guava帮助我们做了很多事情，比如线程安全。 让异步回调更加简单 JDK中提供了Future&#x2F;FutureTask&#x2F;Callable来对异步回调进行支持，但是还是看上去挺复杂的，能不能更加简单呢？比如注册一个监听回调。 12345678910111213141516171819202122232425262728// JDK 所提供的线程池ExecutorService es = Executors.newFixedThreadPool(3);// 经过guava封装的带有监听回调功能的线程池ListeningExecutorService listeningExecutorService = MoreExecutors.listeningDecorator(es);ListenableFuture listenableFuture = listeningExecutorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; if (new Random().nextInt(3) == 2) &#123; throw new NullPointerException(); &#125; return 1; &#125;&#125;);FutureCallback futureCallback = new FutureCallback&lt;Integer&gt; &#123; @Override public void onSuccess(final Integer o) &#123; System.out.println(&quot;------&quot; + o); &#125; @Override public void onFailure(final Throwable throwable) &#123; System.out.println(&quot;======&quot; + throwable.getMessage()); &#125;&#125;;Futures.addCallback(listenableFuture, futureCallback); 异步回调 我们可以通过guava对JDK提供的线程池进行装饰，让其具有异步回调监听功能，然后在设置监听器即可！ Summary到这里，这篇文章也只介绍了guava的冰山一角，其实还有很多内容： guava package 比如反射、注解、网络、并发、IO等等","tags":["工具","开源","Google"],"categories":["工具"]}]