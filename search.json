[{"title":"MySQL大表优化方案","path":"/2023/12/24/MySQL大表优化方案/","content":"当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化： 单表优化除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量： 字段 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED VARCHAR的长度只分配真正需要的空间 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP而非DATETIME， 单表不要有太多字段，建议在20以内 避免使用NULL字段，很难查询优化且占用额外索引空间 用整型来存IP 索引 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描 值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段 字符字段只建前缀索引 字符字段最好不要做主键 不用外键，由程序保证约束 尽量不用UNIQUE，由程序保证约束 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引 查询SQL 可通过开启慢查询日志来找出较慢的SQL 不做列运算：SELECT id WHERE age + 1 &#x3D; 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边 sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库 不用SELECT * OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内 不用函数和触发器，在应用程序实现 避免%xxx式查询 少用JOIN 使用同类型进行比较，比如用’123’和’123’比，123和123比 尽量避免在WHERE子句中使用!&#x3D;或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大 引擎目前广泛使用的是MyISAM和InnoDB两种引擎： MyISAMMyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是： 不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁 不支持事务 不支持外键 不支持崩溃后的安全恢复 在表有读取查询的同时，支持往表中插入新纪录 支持BLOB和TEXT的前500个字符索引，支持全文索引 支持延迟更新索引，极大提升写入性能 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用 InnoDBInnoDB在MySQL 5.5后成为默认索引，它的特点是： 支持行锁，采用MVCC来支持高并发 支持事务 支持外键 支持崩溃后的安全恢复 不支持全文索引 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 系统调优参数可以使用下面几个工具来做基准测试： sysbench：一个模块化，跨平台以及多线程的性能测试工具 iibench-mysql：基于 Java 的 MySQL&#x2F;Percona&#x2F;MariaDB 索引进行插入性能测试工具 tpcc-mysql：Percona开发的TPC-C测试工具 具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数： back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500 wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时 max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限 thread_concurrency：并发线程数，设为CPU核数的两倍 skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问 key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询show status like ‘key_read%’，保证key_reads &#x2F; key_read_requests在0.1%以下最好 innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询show status like ‘Innodb_buffer_pool_read%’，保证 (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) &#x2F; Innodb_buffer_pool_read_requests越高越好 innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小 innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率(Qcache_hits&#x2F;(Qcache_hits+Qcache_inserts)*100))进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大.可以通过命令show status like ‘Qcache_%’查看目前系统Query catch使用大小 read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能 sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小 read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值 thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的 table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM 升级硬件Scale up，这个不多说了，根据MySQL是CPU密集型还是I&#x2F;O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能 读写分离也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离 缓存缓存可以发生在这些层次： MySQL内部：在系统调优参数介绍了相关设置 数据访问层：比如MyBatis针对SQL语句做缓存，而Hibernate可以精确到单个记录，这里缓存的对象主要是持久化对象Persistence Object 应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象Data Transfer Object Web层：针对web页面做缓存 浏览器客户端：用户端的缓存 可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式： 直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如Spring Cache的工作方式。这种实现非常简单，同步好，但效率一般。 回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。 表分区MySQL在5.1版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码 对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对SQL层来说是一个完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引 用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过EXPLAIN PARTITIONS来查看某条SQL语句会落在那些分区上，从而进行SQL优化，如下图5条记录落在两个分区上： 12345678mysql&gt; explain partitions select count(1) from user_partition where id in (1,2,3,4,5);+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| 1 | SIMPLE | user_partition | p1,p4 | range | PRIMARY | PRIMARY | 8 | NULL | 5 | Using where; Using index |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+1 row in set (0.00 sec) 分区的好处是： 可以让单表存储更多的数据 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作 部分查询能够从查询条件确定只落在少数分区上，速度会很快 分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备 可以使用分区表赖避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争 可以备份和恢复单个分区 分区的限制和缺点： 一个表最多只能有1024个分区 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来 分区表无法使用外键约束 NULL值会使分区过滤无效 所有分区必须使用相同的存储引擎 分区的类型： RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区 LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL中有效的、产生非负整数值的任何表达式 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值 分区适合的场景有： 最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示： 1234567891011121314CREATE TABLE members ( firstname VARCHAR(25) NOT NULL, lastname VARCHAR(25) NOT NULL, username VARCHAR(16) NOT NULL, email VARCHAR(35), joined DATE NOT NULL)PARTITION BY RANGE( YEAR(joined) ) ( PARTITION p0 VALUES LESS THAN (1960), PARTITION p1 VALUES LESS THAN (1970), PARTITION p2 VALUES LESS THAN (1980), PARTITION p3 VALUES LESS THAN (1990), PARTITION p4 VALUES LESS THAN MAXVALUE); 查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存 另外MySQL有一种早期的简单的分区实现 - 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代 垂直拆分垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联 比如原始的用户表是： 垂直拆分后是： 垂直拆分的优点是： 可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I&#x2F;O次数(每次查询时读取的Block 就少) 可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起 数据维护简单 缺点是： 主键出现冗余，需要管理冗余列 会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力 依然存在单表数据量过大的问题（需要水平拆分） 事务处理复杂 水平拆分概述水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。 前面的表分区本质上也是一种特殊的库内分表 库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决 前面垂直拆分的用户表如果进行水平拆分，结果是： 实际情况中往往会是垂直拆分和水平拆分的结合，即将Users_A_M和Users_N_Z再拆成Users和UserExtras，这样一共四张表 水平拆分的优点是: 不存在单库大数据和高并发的性能瓶颈 应用端改造较少 提高了系统的稳定性和负载能力 缺点是： 分片事务一致性难以解决 跨节点Join性能差，逻辑复杂 数据多次扩展难度跟维护量极大 分片原则 能不分就不分，参考单表优化 分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询SQL跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量 分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性Hash分片，这几种分片都有利于扩容 尽量不要在一个事务中的SQL跨越多个分片，分布式事务一直是个不好处理的问题 查询条件尽量优化，尽量避免Select * 的方式，大量数据结果集下，会消耗大量带宽和CPU资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。 通过数据冗余和表分区赖降低跨库Join的可能 这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤，比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。 总体上来说，分片的选择是取决于最频繁的查询SQL的条件，因为不带任何Where语句的查询SQL，会遍历所有的分片，性能相对最差，因此这种SQL越多，对系统的影响越大，所以我们要尽量避免这种SQL的产生。 解决方案由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。 客户端架构通过修改数据访问层，如JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以Jar包的方式呈现 这是一个客户端架构的例子： 可以看到分片的实现是和应用服务器在一起的，通过修改Spring JDBC层来实现 客户端架构的优点是： 应用直连数据库，降低外围系统依赖所带来的宕机风险 集成成本低，无需额外运维的组件 缺点是： 限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心 将分片逻辑的压力放在应用服务器上，造成额外风险 代理架构通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件 这是一个代理架构的例子： 代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要Zookeeper之类的服务组件来管理 代理架构的优点是： 能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强 对于应用服务器透明且没有增加任何额外负载 缺点是： 需部署和运维独立的代理中间件，成本高 应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险 各方案比较 出品方 架构模型 支持数据库 分库 分表 读写分离 外部依赖 是否开源 实现语言 支持语言 最后更新 Github星数 MySQL Fabric MySQL官方 代理架构 MySQL 有 有 有 无 是 python 无限制 4个月前 35 Cobar 阿里巴巴 代理架构 MySQL 有 无 无 无 是 Java 无限制 两年前 1287 Cobar Client 阿里巴巴 客户端架构 MySQL 有 无 无 无 是 Java Java 三年前 344 TDDL 淘宝 客户端架构 无限制 有 有 有 Diamond 只开源部分 Java Java 未知 519 Atlas 奇虎360 代理架构 MySQL 有 有 有 无 是 C 无限制 10个月前 1941 Heisenberg 百度熊照 代理架构 MySQL 有 有 有 无 是 Java 无限制 2个月前 197 TribeDB 个人 代理架构 MySQL 有 有 有 无 是 NodeJS 无限制 3个月前 126 ShardingJDBC 当当 客户端架构 MySQL 有 有 有 无 是 Java Java 当天 1144 Shark 个人 客户端架构 MySQL 有 有 无 无 是 Java Java 两天前 84 KingShard 个人 代理架构 MySQL 有 有 有 无 是 Golang 无限制 两天前 1836 OneProxy 平民软件 代理架构 MySQL 有 有 有 无 否 未知 无限制 未知 未知 MyCat 社区 代理架构 MySQL 有 有 有 无 是 Java 无限制 两天前 1270 Vitess Youtube 代理架构 MySQL 有 有 有 无 是 Golang 无限制 当天 3636 Mixer 个人 代理架构 MySQL 有 有 无 无 是 Golang 无限制 9个月前 472 JetPants Tumblr 客户端架构 MySQL 有 有 无 无 是 Ruby Ruby 10个月前 957 HibernateShard Hibernate 客户端架构 无限制 有 有 无 无 是 Java Java 4年前 57 MybatisShard MakerSoft 客户端架构 无限制 有 有 无 无 是 Java Java 11个月前 119 Gizzard Twitter 代理架构 无限制 有 有 无 无 是 Java 无限制 3年前 2087 如此多的方案，如何进行选择？可以按以下思路来考虑： 确定是使用代理架构还是客户端架构。中小型规模或是比较简单的场景倾向于选择客户端架构，复杂场景或大规模系统倾向选择代理架构 具体功能是否满足，比如需要跨节点ORDER BY，那么支持该功能的优先考虑 不考虑一年内没有更新的产品，说明开发停滞，甚至无人维护和技术支持 最好按大公司-&gt;社区-&gt;小公司-&gt;个人这样的出品方顺序来选择 选择口碑较好的，比如github星数、使用者数量质量和使用者反馈 开源的优先，往往项目有特殊需求可能需要改动源代码 按照上述思路，推荐以下选择： 客户端架构：ShardingJDBC 代理架构：MyCat或者Atlas 兼容MySQL且可水平扩展的数据库目前也有一些开源数据库兼容MySQL协议，如： TiDB Cubrid 但其工业品质和MySQL尚有差距，且需要较大的运维投入，如果想将原始的MySQL迁移到可水平扩展的新数据库中，可以考虑一些云数据库： 阿里云PetaData 阿里云OceanBase 腾讯云DCDB NoSQL在MySQL上做Sharding是一种戴着镣铐的跳舞，事实上很多大表本身对MySQL这种RDBMS的需求并不大，并不要求ACID，可以考虑将这些表迁移到NoSQL，彻底解决水平扩展问题，例如： 日志类、监控类、统计类数据 非结构化或弱结构化数据 对事务要求不强，且无太多关联操作的数据","tags":["MySQL","DataBase"],"categories":["DataBase"]},{"title":"MyBatis 的执行流程","path":"/2023/12/24/MyBatis-的执行流程！/","content":"概要在MyBatis中，利用编程式进行数据查询，主要就是下面几行代码： 123SqlSession session = sqlSessionFactory.openSession();UserMapper userMapper = session.getMapper(UserMapper.class);List&lt;LwUser&gt; userList = userMapper.listUserByUserName(&quot;孤狼1号&quot;); 第一行是获取一个SqlSession对象在上一篇文章分析过了，第二行就是获取UserMapper接口，第三行一行代码就实现了整个查询语句的流程，接下来我们就来仔细分析一下第二和第三步。 获取Mapper接口(getMapper)第二步是通过SqlSession对象是获取一个Mapper接口，这个流程还是相对简单的，下面就是我们调用session.getMapper方法之后的运行时序图： 1、在调用getMapper之后，会去Configuration对象中获取Mapper对象，因为在项目启动的时候就会把Mapper接口加载并解析存储到Configuration对象 2、通过Configuration对象中的MapperRegistry对象属性，继续调用getMapper方法 3、根据type类型，从MapperRegistry对象中的knownMappers获取到当前类型对应的代理工厂类，然后通过代理工厂类生成对应Mapper的代理类 4、最终获取到我们接口对应的代理类MapperProxy对象 而MapperProxy可以看到实现了InvocationHandler，使用的就是JDK动态代理。 至此获取Mapper流程结束了，那么就有一个问题了MapperRegistry对象内的HashMap属性knownMappers中的数据是什么时候存进去的呢？ Mapper接口和映射文件是何时关联的Mapper接口及其映射文件是在加载mybatis-config配置文件的时候存储进去的，下面就是时序图： 1、首先我们会手动调用SqlSessionFactoryBuilder方法中的build()方法： 2、然后会构造一个XMLConfigBuilder对象，并调用其parse方法： 3、然后会继续调用自己的parseConfiguration来解析配置文件，这里面就会分别去解析全局配置文件的顶级节点，其他的我们先不看，我们直接看最后解析mappers节点 4、继续调用自己的mapperElement来解析mappers文件（这个方法比较长，为了方便截图完整，所以把字体缩小了1号），可以看到，这里面分了四种方式来解析mappers节点的配置，对应了4种mapper配置方式，而其中红框内的两种方式是直接配置的xml映射文件，蓝框内的两种方式是解析直接配置Mapper接口的方式，从这里也可以说明，不论配置哪种方式，最终MyBatis都会将xml映射文件和Mapper接口进行关联。 5、我们先看第2种和第3中（直接配置xml映射文件的解析方式），会构建一个XMLMapperBuilder对象并调用其parse方法。 当然，这个还是会被解析的，后面执行查询的时候会再次通过不断遍历去全部解析完毕，不过有一点需要注意的是，互相引用这种是会导致解析失败报错的，所以在开发过程中我们应该避免循环依赖的产生。 6、解析完映射文件之后，调用自身方法bindMapperForNamespace，开始绑定Mapper接口和映射文件： 7、调用Configuration对象的addMapper 8、调用Configuration对象的属性MapperRegistry内的addMapper方法，这个方法就是正式将Mapper接口添加到knownMappers，所以上面getMapper可以直接获取： 到这里我们就完成了Mapper接口和xml映射文件的绑定 9、注意上面红框里面的代码，又调用了一次parse方法，这个parse方法主要是解析注解，比如下面的语句： 12@Select(&quot;select * from lw_user&quot;)List&lt;LwUser&gt; listAllUser(); 所以这个方法里面会去解析@Select等注解，需要注意的是，parse方法里面会同时再解析一次xml映射文件，因为上面我们提到了mappers节点有4种配置方式，其中两种配置的是Mapper接口，而配置Mapper接口会直接先调用addMapper接口，并没有解析映射文件，所以进入注解解析方法parse之中会需要再尝试解析一次XML映射文件。 解析完成之后，还会对Mapper接口中的方法进行解析，并将每个方法的全限定类名作为key存入存入Configuration中的mappedStatements属性。 需要指出的是，这里存储的时候，同一个value会存储2次，**一个全限定名作为key，另一个就是只用方法名(sql语句的id)来作为key**： 所以最终mappedStatements会是下面的情况： 事实上如果我们通过接口的方式来编程的话，最后来getStatement的时候，都是根据全限定名来取的，所以即使有重名对我们也没有影响，而之所以要这么做的原因其实还是为了兼容早期版本的用法，那就是不通过接口，而是直接通过方法名的方式来进行查询： 1session.selectList(&quot;com.lonelyWolf.mybatis.mapper.UserMapper.listAllUser&quot;); 这里如果shortName没有重复的话，是可以直接通过简写来查询的： 1session.selectList(&quot;listAllUser&quot;); 但是通过简写来查询一旦shortName重复了就会抛出以下异常： 这里的异常其实就是StrickMap的get方法抛出来的： sql执行流程分析上面我们讲到了，获取到的Mapper接口实际上被包装成为了代理对象，所以我们执行查询语句肯定是执行的代理对象方法，接下来我们就以Mapper接口的代理对象MapperProxy来分析一下查询流程。 整个sql执行流程可以分为两大步骤： 一、寻找sql 二、执行sql语句 寻找sql首先还是来看一下寻找sql语句的时序图： 1、了解代理模式的应该都知道，调用被代理对象的方法之后实际上执行的就是代理对象的invoke方法 2、因为我们这里并没有调用Object类中的方法，所以肯定走的else。else中会继续调用MapperProxy内部类MapperMethodInvoker中的方法cachedInvoker，这里面会有一个判断，判断一下我们是不是default方法，因为Jdk1.8中接口中可以新增default方法，而default方法是并不是一个抽象方法，所以也需要特殊处理（刚开始会从缓存里面取，缓存相关知识我们这里先不讲，后面会单独写一篇来分析一下缓存)）。 3、接下来，是构造一个MapperMethod对象,这个对象封装了Mapper接口中对应的方法信息以及对应的sql语句信息： 这里面就会把要执行的sql语句，请求参数，方法返回值全部解析封装成MapperMethod对象，然后后面就可以开始准备执行sql语句了 执行sql语句还是先来看一下执行Sql语句的时序图： 1、我们继续上面的流程进入execute方法： 2、这里面会根据语句类型以及返回值类型来决定如何执行，本人这里返回的是一个集合，故而我们进入executeForMany方法： 3、这里面首先会将前面存好的参数进行一次转换，然后绕了这么一圈，回到了起点SqlSession对象，继续调用selectList方法： 3、接下来又讲流程委派给了Execute去执行query方法，最终又会去调用queryFromDatabase方法： 4、到这里之后，终于要进入正题了，一般带了这种do开头的方法就是真正做事的，Spring中很多地方也是采用的这种命名方式： 注意，前面我们的sql语句还是占位符的方式，并没有将参数设置进去，所以这里在return上面一行调用prepareStatement方法创建Statement对象的时候会去设置参数，替换占位符。参数如何设置我们先跳过，等把流程执行完了我们在单独分析参数映射和结果集映射。 5、继续进入PreparedStatementHandler对象的query方法，可以看到，这一步就是调用了jdbc操作对象PreparedStatement中的execute方法，最后一步就是转换结果集然后返回。 到这里，整个SQL语句执行流程分析就结束了，中途有一些参数的存储以及转换并没有深入进去，因为参数的转换并不是核心，只要清楚整个数据的流转流程，我们自己也可以有自己的实现方式，只要存起来最后我们能重新解析读出来就行。 参数映射现在我们来看一下上面在执行查询之前参数是如何进行设置的，我们先进入prepareStatement方法： 我们发现，最终是调用了StatementHandler中的parameterize进行参数设置，接下来这里为了节省篇幅，我们不会一步步点进去，直接进入设置参数的方法： 上面的BaseTypeHandler是一个抽象类，setNonNullParameter并没有实现，都是交给子类去实现，而每一个子类就是对应了数据库的一种类型。下图中就是默认的一个子类StringTypeHandler，里面没什么其他逻辑，就是设置参数。 可以看到String里面调用了jdbc中的setString方法，而如果是int也会调用setInt方法。看到这些子类如果大家之前阅读过我前面讲的MyBatis参数配置，应该就很明显可以知道，这些子类就是系统默认提供的一些typeHandler。而这些默认的typeHandler会默认被注册并和Java对象进行绑定： 正是因为MyBatis中默认提供了常用数据类型的映射，所以我们写Sql的时候才可以省略参数映射关系，可以直接采用下面的方式，系统可以根据我们参数的类型，自动选择合适的typeHander进行映射： 1select user_id,user_name from lw_user where user_name=#&#123;userName&#125; 上面这条语句实际上和下面这条是等价的： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR&#125; 或者说我们可以直接指定typeHandler： 1select user_id,user_name from lw_user where user_name = #&#123;userName,jdbcType=VARCHAR,typeHandler=org.apache.ibatis.type.IntegerTypeHandler&#125; 这里因为我们配置了typeHandler，所以会优先以配置的typeHandler为主不会再去读取默认的映射，如果类型不匹配就会直接报错了： 看到这里很多人应该就知道了，如果我们自己自定义一个typeHandler，然后就可以配置成我们自己的自定义类。所以接下来就让我们看看如何自定义一个typeHandler 自定义typeHandler自定义typeHandler需要实现BaseTypeHandler接口，BaseTypeHandler有4个方法，包括结果集映射，为了节省篇幅，代码没有写上来： 1234567891011121314151617package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; 然后我们改写一下上面的查询语句： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125; 然后执行，可以看到，自定义的typeHandler生效了： 结果集映射接下来让我们看看结果集的映射，回到上面执行sql流程的最后一个方法： 1resultSetHandler.handleResultSets(ps) 结果集映射里面的逻辑相对来说还是挺复杂的，因为要考虑到非常多的情况，这里我们就不会去深究每一个细节，直接进入到正式解析结果集的代码，下面的5个代码片段就是一个简单的但是完整的解析流程： 从上面的代码片段我们也可以看到，实际上解析结果集还是很复杂的，就如我们上一篇介绍的复杂查询一样，一个查询可以不断嵌套其他查询，还有延迟加载等等一些复杂的特性的处理，所以逻辑分支是有很多，但是不管怎么处理，最后的核心还是上面的一套流程，最终还是会调用typeHandler来获取查询到的结果。 是的，你没猜错，这个就是上面我们映射参数的typeHandler，因为typeHandler里面不只是一个设置参数方法，还有获取结果集方法(上面设置参数的时候省略了)。 自定义typeHandler结果集所以说我们还是用上面那个MyTypeHandler 例子来重写一下取值方法(省略了设置参数方法)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; /** * 设置参数 */ @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;设置参数-&gt;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; /** * 根据列名获取结果 */ @Override public String getNullableResult(ResultSet resultSet, String columnName) throws SQLException &#123; System.out.println(&quot;根据columnName获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnName); &#125; /** * 根据列的下标来获取结果 */ @Override public String getNullableResult(ResultSet resultSet, int columnIndex) throws SQLException &#123; System.out.println(&quot;根据columnIndex获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnIndex); &#125; /** * 处理存储过程的结果集 */ @Override public String getNullableResult(CallableStatement callableStatement, int columnIndex) throws SQLException &#123; return callableStatement.getString(columnIndex); &#125;&#125; 改写Mapper映射文件配置： 12345678&lt;resultMap id=&quot;MyUserResultMap&quot; type=&quot;lwUser&quot;&gt; &lt;result column=&quot;user_id&quot; property=&quot;userId&quot; jdbcType=&quot;VARCHAR&quot; typeHandler=&quot;com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&quot; /&gt; &lt;result column=&quot;user_name&quot; property=&quot;userName&quot; jdbcType=&quot;VARCHAR&quot; /&gt;&lt;/resultMap&gt;&lt;select id=&quot;listUserByUserName&quot; parameterType=&quot;String&quot; resultMap=&quot;MyUserResultMap&quot;&gt; select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125;&lt;/select&gt; 执行之后输出如下： 因为我们属性上面只配置了一个属性，所以只输出了一次。 工作流程图上面介绍了代码的流转，可能绕来绕去有点晕，所以我们来画一个主要的对象之间流程图来更加清晰的展示一下MyBatis主要工作流程： 从上面的工作流程图上我们可以看到，SqlSession下面还有4大对象，这4大对象也很重要，后面学习拦截器的时候就是针对这4大对象进行的拦截，关于这4大对象的具体详情，我们下一篇文章再展开分析。 总结本文主要分析了MyBatis的SQL执行流程。在分析流程的过程中，我们也举例论证了如何自定义typeHandler来实现自定义的参数映射和结果集映射，不过MyBatis中提供的默认映射其实可以满足大部分的需求，如果我们对某些属性需要特殊处理，那么就可以采用自定义的typeHandler来实现，相信如果本文如果读懂了，以下几点大家应该至少会有一个清晰的认识： 1、Mapper接口和映射文件是如何进行绑定的 2、MyBatis中SQL语句的执行流程 3、自定义MyBatis中的参数设置处理器typeHandler 4、自定义MyBatis中结果集处理器typeHandler 当然，其中很多细节并没有提到，而看源码我们也并不需要追求每一行代码都能看懂，就比如我们一个稍微复杂一点的业务系统，即使我们是项目开发者如果某一个模块不是本人负责的，恐怕也很难搞清楚每一行代码的含义。所以对于MyBatis及其他框架的源码中也是一样，首先应该从大局入手，掌握整体流程和设计思想，然后如果对某些实现细节感兴趣，再深入进行了解。","tags":["MyBatis","框架"],"categories":["框架"]},{"title":"用“状态模式”代替if-else","path":"/2023/12/24/用“状态模式”代替if-else/","content":"简介 状态模式是行为型设计模式的一种。其设计理念是当对象的内部状态发生改变时，随之改变其行为。状态和行为之间是一一对应的。 该模式主要用于，对象的行为依赖于它的状态，并且其行为是随着状态的改变而切换时。 状态模式UML类图类图讲解 State：抽象状态接口（也可以定义成抽象类），该接口封装了所有状态所对应的行为。ConcreteStateA&#x2F;B：具体状态类，该类实现了抽象状态接口，会根据自身对应的状态来实现接口中定义的方法，还有另一个功能是指明如何过渡到下一个状态。Context：环境（上下文）角色，该类负责状态的切换，还持有一个State实例，代表当前环境所处状态。 案例讲解案例：通过状态模式来实现自助售卖机的功能。 状态接口12345678public interface State &#123; // 挑选商品 void choose(); // 付款 boolean payment(); // 分发商品 void dispenseCommodity();&#125; 挑选商品状态类123456789101112131415161718192021222324252627282930public class ChooseGoods implements State &#123; VendingMachine machine; public ChooseGoods(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; if (machine.getCount() &gt; 0) &#123; System.out.println(&quot;商品挑选成功，请及时付款！&quot;); machine.setState(machine.getPaymentState()); &#125; else &#123; System.out.println(&quot;很遗憾，商品售罄了！&quot;); machine.setState(machine.getEmptyState()); &#125; &#125; @Override public boolean payment() &#123; System.out.println(&quot;请先挑选商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先挑选商品！&quot;); &#125;&#125; 付款状态类12345678910111213141516171819202122232425262728293031public class PaymentState implements State &#123; VendingMachine machine; public PaymentState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;商品已选购完成请勿重复挑选&quot;); &#125; @Override public boolean payment() &#123; Random random = new Random(); int num = random.nextInt(10); if(num % 2 == 0)&#123; System.out.println(&quot;付款成功！&quot;); machine.setState(machine.getDispenseCommodityState()); return true; &#125; System.out.println(&quot;付款失败，请重新支付！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先完成支付！&quot;); &#125;&#125; 商品售罄状态类123456789101112131415161718192021222324public class EmptyState implements State &#123; VendingMachine machine; public EmptyState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125;&#125; 分发商品状态类12345678910111213141516171819202122232425public class DispenseCommodityState implements State &#123; VendingMachine machine; public DispenseCommodityState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); machine.setState(machine.getChooseGoods()); &#125;&#125; 自动售货机 &#x3D;&gt; Context角色123456789101112131415161718192021222324252627282930313233public class VendingMachine &#123; // 表示当前状态 private State state = null; // 商品数量 private int count = 0; private State chooseGoods = new ChooseGoods(this); private State paymentState = new PaymentState(this); private State dispenseCommodityState = new DispenseCommodityState(this); private State emptyState = new EmptyState(this); public VendingMachine(int count) &#123; this.count = count; this.state = this.getChooseGoods(); &#125; // 购买商品 public void purchase() &#123; // 挑选商品 state.choose(); // 支付成功 if (state.payment()) &#123; // 分发商品 state.dispenseCommodity(); &#125; &#125; // 获取商品后将商品减一 public int getCount() &#123; return count--; &#125; // get和set方法 ... &#125; 客户端测试类12345678910public class Client &#123; public static void main(String[] args) &#123; VendingMachine machine = new VendingMachine(1); for (int i = 1; i &lt; 4; i++) &#123; System.out.println(&quot;第&quot; + i + &quot;次购买。&quot;); machine.purchase(); &#125; &#125;&#125; 执行结果总结1、状态模式将每个状态所对应的行为封装到一个类中，大大提高了代码的可读性。并且通过这样的设计还可以消除多余的if-else语句，方便代码的维护。 2、状态模式符合“开闭原则”，容易增加和删除状态。 3、任何事情都有利弊，状态模式也不例外。其最显著的问题是，每个状态都要对应一个类，当状态过多时会产生大量的类，从而加大维护成本。 4、应用场景：当一个需求有很多状态，并且状态之间会进行转换，不同状态还对应不同的行为时就可以考虑使用“状态模式”。","tags":["设计模式"],"categories":["设计模式"]},{"title":"Google 开源的 Guava 工具库","path":"/2023/12/24/Google-开源的-Guava-工具库/","content":"目前Google Guava在实际应用中非常广泛，本篇博客将以博主对Guava使用的认识以及在项目中的经验来给大家分享！正如标题所言，学习使用Google Guava可以让你快乐编程，写出优雅的JAVA代码！ 以面向对象思想处理字符串:Joiner&#x2F;Splitter&#x2F;CharMatcher JDK提供的String还不够好么？ 也许还不够友好，至少让我们用起来还不够爽，还得操心！ 举个栗子，比如String提供的split方法，我们得关心空字符串吧，还得考虑返回的结果中存在null元素吧，只提供了前后trim的方法（如果我想对中间元素进行trim呢）。 那么，看下面的代码示例，guava让你不必在操心这些： 123456789101112131415// 连接器private static final Joiner joiner = Joiner.on(&quot;,&quot;).skipNulls();// 分割器private static final Splitter splitter = Splitter.on(&quot;,&quot;).trimResults().omitEmptyStrings();public static void main(String[] args) &#123; // 把集合/数组中的元素 join 在一起 String join = joiner.join(Lists.newArrayList(&quot;a&quot;, null, &quot;b&quot;)); System.out.println(&quot;join=&quot; + join); for(String tmp : splitter.split(&quot;a, ,b,,&quot;)) &#123; System.out.println(&quot;|&quot; + tmp + &quot;|&quot;); &#125;&#125; Joiner&#x2F;Splitter Joiner是连接器，Splitter是分割器，通常我们会把它们定义为static final，利用on生成对象后在应用到String进行处理，这是可以复用的。要知道apache commons StringUtils提供的都是static method。 更加重要的是，guava提供的Joiner&#x2F;Splitter是经过充分测试，它的稳定性和效率要比apache高出不少，这个你可以自行测试下~ 发现没有我们想对String做什么操作，就是生成自己定制化的Joiner&#x2F;Splitter，多么直白，简单，流畅的API！ 对于Joiner，常用的方法是 跳过NULL元素：skipNulls() &#x2F; 对于NULL元素使用其他替代：useForNull(String) 对于Splitter，常用的方法是：trimResults()&#x2F;omitEmptyStrings()。注意拆分的方式，有字符串，还有正则，还有固定长度分割（太贴心了！） 其实除了Joiner&#x2F;Splitter外，guava还提供了字符串匹配器：CharMatcher 123456789101112private static final CharMatcher charMatcherDigit = CharMatcher.DIGIT;private static final Charmatcher charMatcherAny = CharMatcher.ANY;public static void main(String[] args) &#123; // 只保留匹配的字符，其他移除 System.out.println(charMatcherDigit.retainFrom(&quot;abc2def134f~&quot;)); // 移除匹配的字符 System.out.println(charMatcherDigit.removeFrom(&quot;yes,i love you 1314&quot;)); System.out.println(charMatcherAny.inRange(&#x27;a&#x27;, &#x27;f&#x27;).or(charMatcherAny.is(&#x27;a&#x27;)).replaceFrom(&quot;abcdefg&quot;,&quot;*&quot;));&#125; CharMatcher CharMatcher，将字符的匹配和处理解耦，并提供丰富的方法供你使用！ 对基本类型进行支持 guava对JDK提供的原生类型操作进行了扩展，使得功能更加强大！ 1234567891011121314151617// 快速完成到集合的转换List&lt;Integer&gt; list = Ints.asList(1, 3, 5, 7, 9);System.out.println(Ints.join(&quot;,&quot;, 1, 3, 1, 4));// 原生类型数据快速合并int[] newIntArray = Ints.concat(new int[]&#123;1, 2&#125;, new int[]&#123;2, 3, 4&#125;);System.out.println(newIntArray.length);// 最大/最小System.out.println(Ints.max(newIntArray) + &quot;,&quot; + Ints.min(newIntArray));// 是否包含System.out.println(Ints.contains(newArray, 6));// 集合到数组的转换int[] someArray = Ints.toArray(list); Ints guava提供了 Bytes&#x2F;Shorts&#x2F;Ints&#x2F;Iongs&#x2F;Floats&#x2F;Doubles&#x2F;Chars&#x2F;Booleans 这些基本数据类型的扩展支持，只有你想不到的，没有它没有的！ 对JDK集合的有效补充灰色地带:Multiset JDK的集合，提供了有序且可以重复的List，无序且不可以重复的Set。那这里其实对于集合涉及到了2个概念，一个order，一个dups。那么List vs Set，and then some ? Multiset Multiset是什么，我想上面的图，你应该了解它的概念了。Multiset就是无序的，但是可以重复的集合，它就是游离在List&#x2F;Set之间的“灰色地带”！（至于有序的，不允许重复的集合嘛，guava还没有提供，当然在未来应该会提供UniqueList，我猜的，哈哈） 来看一个Multiset的示例： 12345678910Multiset&lt;String&gt; multiset = HashMultiset.create();multiset.add(&quot;a&quot;);multiset.add(&quot;a&quot;);multiset.add(&quot;b&quot;);multiset.add(&quot;c&quot;);multiset.add(&quot;b&quot;);System.out.println(multiset.size());System.out.println(multiset.count(&quot;a&quot;)); Multiset Code Multiset自带一个有用的功能，就是可以跟踪每个对象的数量。 Immutable vs unmodifiable来我们先看一个unmodifiable的例子： 1234567891011121314// List 的不可变设置List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// 这种视图，不够安全，不是真正意义上的快照，怎么能随着而变化呢？List&lt;String&gt; readOnlyList = Collections.unmodifiableList(list);// readOnlyList.add(&quot;c&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionlist.acc(&quot;c&quot;);System.out.println(reaOnlyList.size()); // 3 unmodifiable 你看到JDK提供的unmodifiable的缺陷了吗？ 实际上，Collections.unmodifiableXxx所返回的集合和源集合是同一个对象，只不过可以对集合做出改变的API都被override，会抛出UnsupportedOperationException。 也即是说我们改变源集合，导致不可变视图（unmodifiable View）也会发生变化，oh my god! 当然，在不使用guava的情况下，我们是怎么避免上面的问题的呢？ 1234567// List 的不可变性设置List&lt;String&gt; list = new ArrayList&lt;~&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// new Object ; CopyList&lt;String&gt; readOnList = Collections.unmodifiableList(new ArrayList&lt;String&gt;(list)); defensive copies 上面揭示了一个概念：Defensive Copies，保护性拷贝。 OK，unmodifiable看上去没有问题呢，但是guava依然觉得可以改进，于是提出了Immutable的概念，来看： 12345678910// guava 是如何做的呢？List&lt;String&gt; immutable = ImmutabeList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);// immutable.add(&quot;d&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionList&lt;String&gt; immutable2 = ImmutableList.copyOf(list);list.add(&quot;d&quot;);// 视图不随着源而改变 guava 只读设置安全可靠 简单易用System.out.println(&quot;list size:&quot; + list.size() + &quot; immutable2.size:&quot; + immutables.size()); Immutable 就一个copyOf，你不会忘记，如此cheap~ 用Google官方的说法是：we’re using just one class,just say exactly what we mean，很了不起吗（不仅仅是个概念，Immutable在COPY阶段还考虑了线程的并发性等，很智能的！），O(∩_∩)O哈哈~ guava提供了很多Immutable集合，比如 ImmutableList&#x2F;ImmutableSet&#x2F;ImmutableSortedSet&#x2F;ImmutableMap&#x2F;…… 看一个ImmutableMap的例子： 123ImmutableMap&lt;String, String&gt; immutableMap = ImmutableMap.of(&quot;name&quot;, &quot;hubert&quot;, &quot;sex&quot;, &quot;man&quot;);immutableMap.put(&quot;wife&quot;, &quot;no...&quot;); // UnsupportedOperationException ImmutableMap 可不可以一对多：Multimap JDK提供给我们的Map是一个键，一个值，一对一的，那么在实际开发中，显然存在一个KEY多个VALUE的情况（比如一个分类下的书本），我们往往这样表达：Map&lt;k,List&lt;v&gt;&gt;，好像有点臃肿！臃肿也就算了，更加不爽的事，我们还得判断KEY是否存在来决定是否new 一个LIST出来，有点麻烦！更加麻烦的事情还在后头，比如遍历，比如删除，so hard…… 来看guava如何替你解决这个大麻烦的： 1234567Multimap&lt;String, String&gt; multiMap = ArrayListMultimap.create();multiMap.put(&quot;hubert&quot;, &quot;man&quot;);multiMap.put(&quot;hubert&quot;, &quot;yes&quot;);multiMap.put(&quot;lucy&quot;, &quot;woman&quot;);System.out.println(multiMap.get(&quot;hubert&quot;)); //collection Multimap 友情提示下，guava所有的集合都有create方法，这样的好处在于简单，而且我们不必在重复泛型信息了。 get()&#x2F;keys()&#x2F;keySet()&#x2F;values()&#x2F;entries()&#x2F;asMap()都是非常有用的返回view collection的方法。 Multimap的实现类有： ArrayListMultimap&#x2F;HashMultimap&#x2F;LinkedHashMultimap&#x2F;TreeMultimap&#x2F;ImmutableMultimap&#x2F;…… 可不可以双向：BiMap JDK提供的MAP让我们可以find value by key，那么能不能通过find key by value呢，能不能KEY和VALUE都是唯一的呢。这是一个双向的概念，即forward+backward。 在实际场景中有这样的需求吗？比如通过用户ID找到mail，也需要通过mail找回用户名。没有guava的时候，我们需要create forward map AND create backward map，and now just let guava do that for you. 12345678910111213BiMap&lt;String, String&gt; biMap = HashBiMap.create();biMap.put(&quot;name&quot;, &quot;hubert&quot;);// java.lang.IllegaArgumentException: value already present: hubert// value 重复会报错biMap.put(&quot;nick&quot;, &quot;hubert&quot;);// 强制覆盖 name:hubertbiMap.forcePut(&quot;nick&quot;, &quot;hubert&quot;);biMap.put(&quot;123&quot;, &quot;hubertwongcn@163.com&quot;);System.out.println(biMap.inverse().get(&quot;hubertwongcn@163.com&quot;)); // 123 BiMap biMap &#x2F; biMap.inverse() &#x2F; biMap.inverse().inverse() 它们是什么关系呢？ 你可以稍微看一下BiMap的源码实现，实际上，当你创建BiMap的时候，在内部维护了2个map，一个forward map，一个backward map，并且设置了它们之间的关系。 因此，biMap.inverse() !&#x3D; biMap ；biMap.inverse().inverse() &#x3D;&#x3D; biMap 可不可以多个KEY：Table 我们知道数据库除了主键外，还提供了复合索引，而且实际中这样的多级关系查找也是比较多的，当然我们可以利用嵌套的Map来实现：Map&lt;k1,Map&lt;k2,v2&gt;&gt;。为了让我们的代码看起来不那么丑陋，guava为我们提供了Table。 1234567Table&lt;String, String, Integer&gt; table = HashBaseTable.create();table.put(&quot;张三&quot;, &quot;计算机&quot;, 80);table.put(&quot;张三&quot;, &quot;数学&quot;, 90);table.put(&quot;张三&quot;, &quot;语文&quot;, 70);table.put(&quot;李四&quot;, &quot;计算机&quot;, 70);table.put(&quot;李四&quot;, &quot;数学&quot;, 60);table.put(&quot;李四&quot;, &quot;语文&quot;, 100); Table Table涉及到3个概念：rowKey,columnKey,value，并提供了多种视图以及操作方法让你更加轻松的处理多个KEY的场景。 函数式编程：Functions12345678910111213141516171819202122List&lt;String&gt; list = Lists.newArrayList(&quot;hello world&quot;, &quot;yes&quot;, &quot;hubert&quot;);Function&lt;String, String&gt; f1 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.length() &lt;= 5 ? s : s.substring(0, 5); &#125;&#125;;Function&lt;String, String&gt; f2 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.toUpperCase(); &#125;&#125;;Function&lt;String, String&gt; f3 = Functions.compose(f1, f2);Collection&lt;String&gt; collection = Collections2.transform(list, f3);for(String s : collection) &#123; System.out.println(s);&#125; Functions 上面的代码是为了完成将List集合中的元素，先截取5个长度，然后转成大写。 函数式编程的好处在于在集合遍历操作中提供自定义Function的操作，比如transform转换。我们再也不需要一遍遍的遍历集合，显著的简化了代码！ 12345678910Iterables.transform(Iterable, Function);Iterators.transform(Iterator, Function);Collections2.transform(Collection, Function);Lists.transform(List, Function);Maps.transformValues(Map, Function);Multimaps.transformValues(Multimap, Function);Multimaps.transformValues(ListMultimap, Funtion);Tables.transformValues(Table, Function);Maps.transformEntries(Map, EntryTransformer);// ... 对集合的transform操作可以通过Function完成 断言：Predicate12345678910111213List&lt;String&gt; list = Lists.newArrayList(&quot;moom&quot;, &quot;dad&quot;, &quot;refer&quot;, &quot;yes&quot;);Collection&lt;String&gt; collection = Collections2.filter(list, new Predicate&lt;String&gt;)) &#123; @Override public boolean apply(String s) &#123; // 业务逻辑 return new StringBuilder(s).reverse().toString().equals(s); &#125;&#125;;for(String s : collection) &#123; System.out.println(s);&#125; Predicate最常用的功能就是运用在集合的过滤当中！ 12345678Iterables.filter(Iterable, Predicate);Iterators.filter(Iterator, Predicate);Collectios2.filter(Collection, Predicate);Sets.filter(Set, Predicate);Sets.filter(SortedSet, Predicate);Maps.filterKeys(Map, Predicate);Multimaps.filterKeys(Multimap, Predicate);// ... filter 需要注意的是Lists并没有提供filter方法，不过你可以使用Collections2.filter完成！ check null and other：Optional、Preconditions在guava中，对于null的处理手段是快速失败，你可以看看guava的源码，很多方法的第一行就是：Preconditions.checkNotNull(elements); 要知道null是模糊的概念，是成功呢，还是失败呢，还是别的什么含义呢？ 12345678910111213public static void test(String name, int age, Map&lt;String, String&gt; extInfo) &#123; Preconditions.checkNotNull(name, &quot;name must be given!&quot;); Preconditions.checkArgument(age &gt;= 18, &quot;the game you can not play it, your age is under 18!&quot;); Map&lt;String, String&gt; defaulExtInfo = Maps.newHashMap(); defaultExtInfo.put(&quot;sex&quot;, &quot;man&quot;); extInfo = Optional.fromNullable(extInfo).or(defaultExtInfo); for(Map.Entry&lt;String, Stirng&gt; entry : extInfo.entrySet())) &#123; System.out.println(entry.getKey() + &quot;:&quot; + entry.getValue()); &#125;&#125; Preconditions&#x2F;Optional Cache is king 对于大多数互联网项目而言，缓存的重要性，不言而喻！ 如果我们的应用系统，并不想使用一些第三方缓存组件（如redis），我们仅仅想在本地有一个功能足够强大的缓存，很可惜JDK提供的那些SET&#x2F;MAP还不行！ 12345678910111213141516171819202122232425// 定义缓存的实现private static final CacheLoader&lt;Long, User&gt; userCacheLoader = new CacheLoader&lt;Long, User&gt;() &#123; @Override public User load(Long along) throws Exception &#123; // 模拟从数据库/Redis/缓存中加载数据 User user = new User(); user.setId(along); user.setName(Thread.currentThread().getName() + &quot;-&quot; new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;).format(new Date()) + &quot;-&quot; + along); System.out.println(&quot;load:&quot; + user); return user; &#125;&#125;;// 定义缓存的策略，提供对外访问缓存private static final LoadingCache&lt;Long, User&gt; userCacheData = CacheBuilder.newBuilder() .expireAfterAccess(2, TimeUnit.SECONDS) .expireAfterWrite(2, TimeUnit.SECONDS) .refreshAfterWrite(3, TimeUnit.SECONS) .maximumSize(10000L) .bulid(userCacheLoader); CacheLoader 首先，这是一个本地缓存，guava提供的cache是一个简洁、高效，易于维护的。为什么这么说呢？因为并没有一个单独的线程用于刷新 OR 清理cache，对于cache的操作，都是通过访问&#x2F;读写带来的，也就是说在读写中完成缓存的刷新操作！ 其次，我们看到了，我们非常通俗的告诉cache，我们的缓存策略是什么，SO EASY！在如此简单的背后，是guava帮助我们做了很多事情，比如线程安全。 让异步回调更加简单 JDK中提供了Future&#x2F;FutureTask&#x2F;Callable来对异步回调进行支持，但是还是看上去挺复杂的，能不能更加简单呢？比如注册一个监听回调。 12345678910111213141516171819202122232425262728// JDK 所提供的线程池ExecutorService es = Executors.newFixedThreadPool(3);// 经过guava封装的带有监听回调功能的线程池ListeningExecutorService listeningExecutorService = MoreExecutors.listeningDecorator(es);ListenableFuture listenableFuture = listeningExecutorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; if (new Random().nextInt(3) == 2) &#123; throw new NullPointerException(); &#125; return 1; &#125;&#125;);FutureCallback futureCallback = new FutureCallback&lt;Integer&gt; &#123; @Override public void onSuccess(final Integer o) &#123; System.out.println(&quot;------&quot; + o); &#125; @Override public void onFailure(final Throwable throwable) &#123; System.out.println(&quot;======&quot; + throwable.getMessage()); &#125;&#125;;Futures.addCallback(listenableFuture, futureCallback); 异步回调 我们可以通过guava对JDK提供的线程池进行装饰，让其具有异步回调监听功能，然后在设置监听器即可！ Summary到这里，这篇文章也只介绍了guava的冰山一角，其实还有很多内容： guava package 比如反射、注解、网络、并发、IO等等","tags":["工具","开源","Google"],"categories":["工具"]}]