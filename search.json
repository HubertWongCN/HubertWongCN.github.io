[{"title":"Docker从入门到干活，看这一篇足矣","path":"/2023/12/24/Docker从入门到干活，看这一篇足矣/","content":"1. 容器简介1.1. 什么是 Linux 容器Linux容器是与系统其他部分隔离开的一系列进程，从另一个镜像运行，并由该镜像提供支持进程所需的全部文件。 容器提供的镜像包含了应用的所有依赖项，因而在从开发到测试再到生产的整个过程中，它都具有可移植性和一致性。 更加详细地来说，请您假定您在开发一个应用。您使用的是一台笔记本电脑，而且您的开发环境具有特定的配置。其他开发人员身处的环境配置可能稍有不同。您正在开发的应用依赖于您当前的配置，还要依赖于某些特定文件。 与此同时，您的企业还拥有标准化的测试和生产环境，且具有自身的配置和一系列支持文件。 您希望尽可能多在本地模拟这些环境，而不产生重新创建服务器环境的开销。 因此，您要如何确保应用能够在这些环境中运行和通过质量检测，并且在部署过程中不出现令人头疼的问题，也无需重新编写代码和进行故障修复？答案就是使用容器。 容器可以确保您的应用拥有必需的配置和文件，使得这些应用能够在从开发到测试、再到生产的整个流程中顺利运行，而不出现任何不良问题。这样可以避免危机，做到皆大欢喜。 虽然这只是简化的示例，但在需要很高的可移植性、可配置性和隔离的情况下，我们可以利用 Linux 容器通过很多方式解决难题。 无论基础架构是在企业内部还是在云端，或者混合使用两者，容器都能满足您的需求。 1.2. 容器不就是虚拟化吗是，但也不竟然。我们用一种简单方式来思考一下： 虚拟化使得许多操作系统可同时在单个系统上运行。 容器则可共享同一个操作系统内核，将应用进程与系统其他部分隔离开。 图 - 普通虚拟化技术和Docker的对比 这意味着什么？首先，让多个操作系统在单个虚拟机监控程序上运行以实现虚拟化，并不能达成和使用容器同等的轻量级效果。 事实上，在仅拥有容量有限的有限资源时，您需要能够可以进行密集部署的轻量级应用。 Linux 容器可从单个操作系统运行，在所有容器中共享该操作系统，因此应用和服务能够保持轻量级，并行快速运行。 1.3. 容器发展简史 我们现在称为容器技术的概念最初出现在 2000 年，当时称为 FreeBSD jail，这种技术可将 FreeBSD 系统分区为多个子系统（也称为 Jail）。 Jail 是作为安全环境而开发的，系统管理员可与企业内部或外部的多个用户共享这些 Jail。 Jail 的目的是让进程在经过修改的 chroot 环境中创建，而不会脱离和影响整个系统 — 在 chroot 环境中，对文件系统、网络和用户的访问都实现了虚拟化。 尽管 Jail 在实施方面存在局限性，但最终人们找到了脱离这种隔离环境的方法。 但这个概念非常有吸引力。 2001 年，通过 Jacques Gélinas 的 VServer 项目，隔离环境的实施进入了 Linux 领域。 正如 Gélinas 所说，这项工作的目的是“在高度独立且安全的单一环境中运行多个通用 Linux 服务器 [sic]。” 在完成了这项针对 Linux 中多个受控制用户空间的基础性工作后，Linux 容器开始逐渐成形并最终发展成了现在的模样。 2. 什么是 Docker？“Docker” 一词指代多种事物，包括开源社区项目、开源项目使用的工具、主导支持此类项目的公司 Docker Inc. 以及该公司官方支持的工具。技术产品和公司使用同一名称，的确让人有点困惑。 🎍 IT 软件中所说的 “Docker” ，是指容器化技术，用于支持创建和使用 Linux 容器。 🎍 开源 Docker 社区致力于改进这类技术，并免费提供给所有用户，使之获益。 🎍 Docker Inc. 公司凭借 Docker 社区产品起家，它主要负责提升社区版本的安全性，并将改进后的版本与更广泛的技术社区分享。此外，它还专门对这些技术产品进行完善和安全固化，以服务于企业客户。 借助 Docker ，您可将容器当做重量轻、模块化的虚拟机使用。同时，您还将获得高度的灵活性，从而实现对容器的高效创建、部署及复制，并能将其从一个环境顺利迁移至另一个环境。 2.1. Docker 如何工作？Docker 技术使用 Linux 内核和内核功能（例如 Cgroups 和 namespaces）来分隔进程，以便各进程相互独立运行。 这种独立性正是采用容器的目的所在；它可以独立运行多种进程、多个应用程序，更加充分地发挥基础设施的作用，同时保持各个独立系统的安全性。 容器工具（包括 Docker）可提供基于镜像的部署模式。这使得它能够轻松跨多种环境，与其依赖程序共享应用或服务组。Docker 还可在这一容器环境中自动部署应用程序（或者合并多种流程，以构建单个应用程序）。 此外，由于这些工具基于 Linux 容器构建，使得 Docker 既易于使用，又别具一格 —— 它可为用户提供前所未有的高度应用程访问权限、快速部署以及版本控制和分发能力。 2.2. Docker 技术是否与传统的 Linux 容器相同？否。Docker 技术最初是基于 LXC 技术构建（大多数人都会将这一技术与“传统的” Linux 容器联系在一起），但后来它逐渐摆脱了对这种技术的依赖。 就轻量级 虚拟化 这一功能来看，LXC 非常有用，但它无法提供出色的开发人员或用户体验。除了运行容器之外，Docker 技术还具备其他多项功能，包括简化用于构建容器、传输镜像以及控制镜像版本的流程。 传统的 Linux 容器使用 init 系统来管理多种进程。这意味着，所有应用程序都作为一个整体运行。与此相反，Docker 技术鼓励应用程序各自独立运行其进程，并提供相应工具以实现这一功能。这种精细化运作模式自有其优势。 2.3. docker的目标docker的主要目标是”Build,Ship and Run any App,Angwhere”,构建，运输，处处运行 构建：做一个docker镜像 运输：docker pull 运行：启动一个容器 每一个容器，他都有自己的文件系统rootfs. 3. 安装Docker环境说明 123456789# 需要两台几点进行安装[root@docker01 ~]# cat /etc/redhat-release CentOS Linux release 7.2.1511 (Core) [root@docker01 ~]# uname -r 3.10.0-327.el7.x86_64[root@docker01 ~]# hostname -I10.0.0.100 172.16.1.100 [root@docker02 ~]# hostname -I10.0.0.101 172.16.1.101 在两个节点上都进行操作 123wget -O /etc/yum.repos.d/docker-ce.repo https://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.reposed -i &#x27;s#download.docker.com#mirrors.ustc.edu.cn/docker-ce#g&#x27; /etc/yum.repos.d/docker-ce.repoyum install docker-ce -y 修改在docker01配置： 1234567# 修改启动文件，监听远程端口vim /usr/lib/systemd/system/docker.serviceExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://10.0.0.100:2375systemctl daemon-reloadsystemctl enable docker.service systemctl restart docker.service# ps -ef检查进行，是否启动 在docker02测试 123456789[root@docker02 ~]# docker -H 10.0.0.100 infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.12.0-ceStorage Driver: devicemapper··· 3.1. Docker基础命令操作查看docker相关信息 1234567891011121314151617[root@docker01 ~]# docker version Client: Version: 17.12.0-ce API version: 1.35 Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:10:14 2017 OS/Arch: linux/amd64Server: Engine: Version: 17.12.0-ce API version: 1.35 (minimum version 1.12) Go version: go1.9.2 Git commit: c97c6d6 Built: Wed Dec 27 20:12:46 2017 OS/Arch: linux/amd64 Experimental: false 配置docker镜像加速 1234vi /etc/docker/daemon.json&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 3.2. 启动第一个容器12345678910[root@docker01 ~]# docker run -d -p 80:80 nginxUnable to find image &#x27;nginx:latest&#x27; locallylatest: Pulling from library/nginxe7bb522d92ff: Pull complete 6edc05228666: Pull complete cd866a17e81f: Pull complete Digest: sha256:285b49d42c703fdf257d1e2422765c4ba9d3e37768d6ea83d7fe2043dad6e63dStatus: Downloaded newer image for nginx:latest8d8f81da12b5c10af6ba1a5d07f4abc041cb95b01f3d632c3d638922800b0b4d# 容器启动后，在浏览器进行访问测试 参数说明 3.3. Docker镜像生命周期 4. Docker镜像相关操作4.1. 搜索官方仓库镜像1234[root@docker01 ~]# docker search centosNAME DESCRIPTION STARS OFFICIAL AUTOMATEDcentos The official build of CentOS. 3992 [OK] ansible/centos7-ansible Ansible on Centos7 105 [OK] 列表说明 4.2. 获取镜像根据镜像名称拉取镜像 1234[root@docker01 ~]# docker pull centosUsing default tag: latestlatest: Pulling from library/centosaf4b0a2388c6: Downloading 34.65MB/73.67MB 查看当前主机镜像列表 1234[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB 拉第三方镜像方法 1docker pull index.tenxcloud.com/tenxcloud/httpd 4.3. 导出镜像123456[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB# 导出[root@docker01 ~]# docker image save centos &gt; docker-centos.tar.gz 4.4. 删除镜像1234[root@docker01 ~]# docker image rm centos:latest[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEnginx latest 3f8a4339aadd 5 weeks ago 108MB 4.5. 导入镜像1234567[root@docker01 ~]# docker image load -i docker-centos.tar.gz e15afa4858b6: Loading layer 215.8MB/215.8MBLoaded image: centos:latest[root@docker01 ~]# docker image list REPOSITORY TAG IMAGE ID CREATED SIZEcentos latest ff426288ea90 3 weeks ago 207MBnginx latest 3f8a4339aadd 5 weeks ago 108MB 4.6. 查看镜像的详细信息1[root@docker01 ~]# docker image inspect centos 5. 容器的日常管理5.1. 容器的起&#x2F;停最简单的运行一个容器 1[root@docker01 ~]# docker run nginx 创建容器，两步走（不常用） 1234[root@docker01 ~]# docker create centos:latest /bin/bashbb7f32368ecf0492adb59e20032ab2e6cf6a563a0e6751e58930ee5f7aaef204[root@docker01 ~]# docker start stupefied_nobelstupefied_nobel 快速启动容器方法 1[root@docker01 ~]# docker run centos:latest /usr/bin/sleep 20; 容器内的第一个进程必须一直处于运行的状态，否则这个容器，就会处于退出状态！ 查看正在运行的容器 12345[root@docker01 ~]# docker container ls 或[root@docker01 ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8708e93fd767 nginx &quot;nginx -g &#x27;daemon of…&quot; 6 seconds ago Up 4 seconds 80/tcp keen_lewin 查看你容器详细信息&#x2F;ip 1[root@docker01 ~]# docker container inspect 容器名称/id 查看你所有容器（包括未运行的） 12345[root@docker01 ~]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES8708e93fd767 nginx &quot;nginx -g &#x27;daemon of…&quot; 4 minutes ago Exited (0) 59 seconds ago keen_lewinf9f3e6af7508 nginx &quot;nginx -g &#x27;daemon of…&quot; 5 minutes ago Exited (0) 5 minutes ago optimistic_haibt8d8f81da12b5 nginx &quot;nginx -g &#x27;daemon of…&quot; 3 hours ago Exited (0) 3 hours ago lucid_bohr 停止容器 123[root@docker01 ~]# docker stop 容器名称/id 或[root@docker01 ~]# docker container kill 容器名称/id 5.2. 进入容器方法启动时进去方法 123[root@docker01 ~]# docker run -it #参数：-it 可交互终端[root@docker01 ~]# docker run -it nginx:latest /bin/bashroot@79241093859e:/# 退出&#x2F;离开容器 1ctrl+p &amp; ctrl+q 启动后进入容器的方法 启动一个docker 12345[root@docker01 ~]# docker run -it centos:latest [root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 13 1 0 15:47 pts/0 00:00:00 ps -ef attach进入容器，使用pts&#x2F;0 ，会让所用通过此方法进如放入用户看到同样的操作。 12345[root@docker01 ~]# docker attach 1bf0f43c4d2f[root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 14 1 0 15:49 pts/0 00:00:00 ps -ef 自命名启动一个容器 –name 12345[root@docker01 ~]# docker attach 1bf0f43c4d2f[root@1bf0f43c4d2f /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 15:47 pts/0 00:00:00 /bin/bashroot 14 1 0 15:49 pts/0 00:00:00 ps -ef exec 进入容器方法（推荐使用） 1234567[root@docker01 ~]# docker exec -it clsn1 /bin/bash [root@b20fa75b4b40 /]# 重新分配一个终端[root@b20fa75b4b40 /]# ps -ef UID PID PPID C STIME TTY TIME CMDroot 1 0 0 16:11 pts/0 00:00:00 /bin/bashroot 13 0 0 16:14 pts/1 00:00:00 /bin/bashroot 26 13 0 16:14 pts/1 00:00:00 ps -ef 5.3. 删除所有容器12[root@docker01 ~]# docker rm -f `docker ps -a -q`# -f 强制删除 5.4. 启动时进行端口映射-p参数端口映射 12[root@docker01 ~]# docker run -d -p 8888:80 nginx:latest 287bec5c60263166c03e1fc5b0b8262fe76507be3dfae4ce5cd2ee2d1e8a89a9 不同指定映射方法 随机映射 1docker run -P （大P）# 需要镜像支持 6. Docker 数据卷的管理6.1. 挂载时创建卷挂载卷 12[root@docker01 ~]# docker run -d -p 80:80 -v /data:/usr/share/nginx/html nginx:latest079786c1e297b5c5031e7a841160c74e91d4ad06516505043c60dbb78a259d09 容器内站点目录: &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html 在宿主机写入数据，查看 123[root@docker01 ~]# echo &quot;http://www.nmtui.com&quot; &gt;/data/index.html[root@docker01 ~]# curl 10.0.0.100http://www.nmtui.com 设置共享卷，使用同一个卷启动一个新的容器 1234[root@docker01 ~]# docker run -d -p 8080:80 -v /data:/usr/share/nginx/html nginx:latest 351f0bd78d273604bd0971b186979aa0f3cbf45247274493d2490527babb4e42[root@docker01 ~]# curl 10.0.0.100:8080http://www.nmtui.com 查看卷列表 12[root@docker01 ~]# docker volume lsDRIVER VOLUME NAME 6.2. 创建卷后挂载创建一个卷 12345[root@docker01 ~]# docker volume create f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521[root@docker01 ~]# docker volume ls DRIVER VOLUME NAMElocal f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521 指定卷名 1234[root@docker01 ~]# docker volume ls DRIVER VOLUME NAMElocal clsnlocal f3b95f7bd17da220e63d4e70850b8d7fb3e20f8ad02043423a39fdd072b83521 查看卷路径 123456789101112[root@docker01 ~]# docker volume inspect clsn [ &#123; &quot;CreatedAt&quot;: &quot;2018-02-01T00:39:25+08:00&quot;, &quot;Driver&quot;: &quot;local&quot;, &quot;Labels&quot;: &#123;&#125;, &quot;Mountpoint&quot;: &quot;/var/lib/docker/volumes/clsn/_data&quot;, &quot;Name&quot;: &quot;clsn&quot;, &quot;Options&quot;: &#123;&#125;, &quot;Scope&quot;: &quot;local&quot; &#125;] 使用卷创建 123456[root@docker01 ~]# docker run -d -p 9000:80 -v clsn:/usr/share/nginx/html nginx:latest 1434559cff996162da7ce71820ed8f5937fb7c02113bbc84e965845c219d3503# 宿主机测试[root@docker01 ~]# echo &#x27;blog.nmtui.com&#x27; &gt;/var/lib/docker/volumes/clsn/_data/index.html [root@docker01 ~]# curl 10.0.0.100:9000blog.nmtui.com 设置卷 12[root@docker01 ~]# docker run -d -P --volumes-from 079786c1e297 nginx:latest b54b9c9930b417ab3257c6e4a8280b54fae57043c0b76b9dc60b4788e92369fb 查看使用的端口 123456789101112[root@docker01 ~]# netstat -lntup Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1400/sshd tcp 0 0 10.0.0.100:2375 0.0.0.0:* LISTEN 26218/dockerd tcp6 0 0 :::9000 :::* LISTEN 32015/docker-proxy tcp6 0 0 :::8080 :::* LISTEN 31853/docker-proxy tcp6 0 0 :::80 :::* LISTEN 31752/docker-proxy tcp6 0 0 :::22 :::* LISTEN 1400/sshd tcp6 0 0 :::32769 :::* LISTEN 32300/docker-proxy [root@docker01 ~]# curl 10.0.0.100:32769http://www.nmtui.com 6.3. 手动将容器保存为镜像本次是基于docker官方centos 6.8 镜像创建 官方镜像列表： https://hub.docker.com/explore/ 启动一个centos6.8的镜像 123456[root@docker01 ~]# docker pull centos:6.8[root@docker01 ~]# docker run -it -p 1022:22 centos:6.8 /bin/bash# 在容器种安装sshd服务，并修改系统密码[root@582051b2b92b ~]# yum install openssh-server -y [root@582051b2b92b ~]# echo &quot;root:123456&quot; |chpasswd[root@582051b2b92b ~]# /etc/init.d/sshd start 启动完成后镜像ssh连接测试 将容器提交为镜像 1[root@docker01 ~]# docker commit brave_mcclintock centos6-ssh 使用新的镜像启动容器 12[root@docker01 ~]# docker run -d -p 1122:22 centos6-ssh:latest /usr/sbin/sshd -D 5b8161fda2a9f2c39c196c67e2eb9274977e7723fe51c4f08a0190217ae93094 在容器安装httpd服务 1[root@5b8161fda2a9 /]# yum install httpd -y 编写启动脚本脚本 123456[root@5b8161fda2a9 /]# cat init.sh #!/bin/bash /etc/init.d/httpd start /usr/sbin/sshd -D[root@5b8161fda2a9 /]# chmod +x init.sh # 注意执行权限 再次提交为新的镜像 12[root@docker01 ~]# docker commit 5b8161fda2a9 centos6-httpd sha256:705d67a786cac040800b8485cf046fd57b1828b805c515377fc3e9cea3a481c1 启动镜像，做好端口映射。并在浏览器中测试访问 12[root@docker01 ~]# docker run -d -p 1222:22 -p 80:80 centos6-httpd /init.sh 46fa6a06644e31701dc019fb3a8c3b6ef008d4c2c10d46662a97664f838d8c2c 7. Dockerfile自动构建docker镜像官方构建dockerffile文件参考 https://github.com/CentOS/CentOS-Dockerfiles 7.1. Dockerfile指令集dockerfile主要组成部分： 基础镜像信息 FROM centos:6.8 制作镜像操作指令RUN yum insatll openssh-server -y 容器启动时执行指令 CMD [“&#x2F;bin&#x2F;bash”] dockerfile常用指令： FROM 这个镜像的妈妈是谁？（指定基础镜像） MAINTAINER 告诉别人，谁负责养它？（指定维护者信息，可以没有） RUN 你想让它干啥（在命令前面加上RUN即可） ADD 给它点创业资金（COPY文件，会自动解压） WORKDIR 我是cd,今天刚化了妆（设置当前工作目录） VOLUME 给它一个存放行李的地方（设置卷，挂载主机目录） EXPOSE 它要打开的门是啥（指定对外的端口） CMD 奔跑吧，兄弟！（指定容器启动后的要干的事情） dockerfile其他指令： COPY 复制文件 ENV 环境变量 ENTRYPOINT 容器启动后执行的命令 7.2. 创建一个Dockerfile创建第一个Dockerfile文件 123456789# 创建目录[root@docker01 base]# cd /opt/base# 创建Dcokerfile文件，注意大小写[root@docker01 base]# vim DockerfileFROM centos:6.8RUN yum install openssh-server -y RUN echo &quot;root:123456&quot; |chpasswdRUN /etc/init.d/sshd start CMD [&quot;/usr/sbin/sshd&quot;,&quot;-D&quot;] 使用自构建的镜像启动 12[root@docker01 base]# docker image build -t centos6.8-ssh . -t 为镜像标签打标签 . 表示当前路径 使用自构建的镜像启动 12[root@docker01 base]# docker run -d -p 2022:22 centos6.8-ssh-b dc3027d3c15dac881e8e2aeff80724216f3ac725f142daa66484f7cb5d074e7a 7.3. 使用Dcokerfile安装kodexplorerDockerfile文件内容 12345678FROM centos:6.8RUN yum install wget unzip php php-gd php-mbstring -y &amp;&amp; yum clean all# 设置工作目录，之后的操作都在这个目录中WORKDIR /var/www/html/RUN wget -c http://static.kodcloud.com/update/download/kodexplorer4.25.zipRUN unzip kodexplorer4.25.zip &amp;&amp; rm -f kodexplorer4.25.zipRUN chown -R apache.apache .CMD [&quot;/usr/sbin/apachectl&quot;,&quot;-D&quot;,&quot;FOREGROUND&quot;] 更多的Dockerfile可以参考官方方法。 8. Docker中的镜像分层参考文档： http://www.maiziedu.com/wiki/cloud/dockerimage/ Docker 支持通过扩展现有镜像，创建新的镜像。实际上，Docker Hub 中 99% 的镜像都是通过在 base 镜像中安装和配置需要的软件构建出来的。 从上图可以看到，新镜像是从 base 镜像一层一层叠加生成的。每安装一个软件，就在现有镜像的基础上增加一层。 8.1. Docker 镜像为什么分层镜像分层最大的一个好处就是共享资源。 比如说有多个镜像都从相同的 base 镜像构建而来，那么 Docker Host 只需在磁盘上保存一份 base 镜像；同时内存中也只需加载一份 base 镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。 如果多个容器共享一份基础镜像，当某个容器修改了基础镜像的内容，比如 &#x2F;etc 下的文件，这时其他容器的 &#x2F;etc 是不会被修改的，修改只会被限制在单个容器内。这就是容器 Copy-on-Write 特性。 8.2. 可写的容器层当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称作“容器层”，“容器层”之下的都叫“镜像层”。 所有对容器的改动 - 无论添加、删除、还是修改文件都只会发生在容器层中。只有容器层是可写的，容器层下面的所有镜像层都是只读的。 8.3. 容器层的细节说明镜像层数量可能会很多，所有镜像层会联合在一起组成一个统一的文件系统。如果不同层中有一个相同路径的文件，比如 &#x2F;a，上层的 &#x2F;a 会覆盖下层的 &#x2F;a，也就是说用户只能访问到上层中的文件 &#x2F;a。在容器层中，用户看到的是一个叠加之后的文件系统。 文件操作的 只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。 这样就解释了我们前面提出的问题：容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。 9. 使用docker运行zabbix-server9.1. 容器间的互联在运行zabbix之前务必要了解容器间互联的方法 123456# 创建一个nginx容器docker run -d -p 80:80 nginx# 创建容器，做link，并进入容器中docker run -it --link quirky_brown:web01 centos-ssh /bin/bash# 在容器中访问nginx容器可以ping通ping web01 命令执行过程 12345678910111213141516171819# 启动apache容器[root@docker01 ~]# docker run -d httpd:2.4 3f1f7fc554720424327286bd2b04aeab1b084a3fb011a785b0deab6a34e56955^[[A[root@docker01 docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES3f1f7fc55472 httpd:2.4 &quot;httpd-foreground&quot; 6 seconds ago Up 5 seconds 80/tcp determined_clarke# 拉取一个busybox 镜像[root@docker01 ~]# docker pull busybox # 启动容器[root@docker01 ~]# docker run -it --link determined_clarke:web busybox:latest /bin/sh / # # 使用新的容器访问最初的web容器/ # ping web PING web (172.17.0.2): 56 data bytes64 bytes from 172.17.0.2: seq=0 ttl=64 time=0.058 ms^C--- web ping statistics ---1 packets transmitted, 1 packets received, 0% packet lossround-trip min/avg/max = 0.058/0.058/0.058 ms 9.2. 启动zabbix容器1、启动一个mysql的容器 1234567docker run --name mysql-server -t \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ -d mysql:5.7 \\ --character-set-server=utf8 --collation-server=utf8_bin 2、启动java-gateway容器监控java服务 12docker run --name zabbix-java-gateway -t \\ -d zabbix/zabbix-java-gateway:latest 3、启动zabbix-mysql容器使用link连接mysql与java-gateway。 1234567891011docker run --name zabbix-server-mysql -t \\ -e DB_SERVER_HOST=&quot;mysql-server&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ -e ZBX_JAVAGATEWAY=&quot;zabbix-java-gateway&quot; \\ --link mysql-server:mysql \\ --link zabbix-java-gateway:zabbix-java-gateway \\ -p 10051:10051 \\ -d zabbix/zabbix-server-mysql:latest 4、启动zabbix web显示，使用link连接zabbix-mysql与mysql。 12345678910docker run --name zabbix-web-nginx-mysql -t \\ -e DB_SERVER_HOST=&quot;mysql-server&quot; \\ -e MYSQL_DATABASE=&quot;zabbix&quot; \\ -e MYSQL_USER=&quot;zabbix&quot; \\ -e MYSQL_PASSWORD=&quot;zabbix_pwd&quot; \\ -e MYSQL_ROOT_PASSWORD=&quot;root_pwd&quot; \\ --link mysql-server:mysql \\ --link zabbix-server-mysql:zabbix-server \\ -p 80:80 \\ -d zabbix/zabbix-web-nginx-mysql:latest 9.3. 关于zabbix API关于zabbix API可以参考官方文档： https://www.zabbix.com/documentation/3.4/zh/manual/api 1、获取token方法 123456789101112# 获取token[root@docker02 ~]# curl -s -X POST -H &#x27;Content-Type:application/json&#x27; -d &#x27;&#123;&quot;jsonrpc&quot;: &quot;2.0&quot;,&quot;method&quot;: &quot;user.login&quot;,&quot;params&quot;: &#123;&quot;user&quot;: &quot;Admin&quot;,&quot;password&quot;: &quot;zabbix&quot;&#125;,&quot;id&quot;: 1&#125;&#x27; http://10.0.0.100/api_jsonrpc.php&#123;&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;result&quot;:&quot;d3be707f9e866ec5d0d1c242292cbebd&quot;,&quot;id&quot;:1&#125; 10. docker 仓库（registry）10.1. 创建一个普通仓库1、创建仓库 1docker run -d -p 5000:5000 --restart=always --name registry -v /opt/myregistry:/var/lib/registry registry 2、修改配置文件，使之支持http 12345[root@docker01 ~]# cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;insecure-registries&quot;: [&quot;10.0.0.100:5000&quot;]&#125; 重启docker让修改生效 1[root@docker01 ~]# systemctl restart docker.service 3、修改镜像标签 123456[root@docker01 ~]# docker tag busybox:latest 10.0.0.100:5000/clsn/busybox:1.0[root@docker01 ~]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZEcentos6-ssh latest 3c2b1e57a0f5 18 hours ago 393MBhttpd 2.4 2e202f453940 6 days ago 179MB10.0.0.100:5000/clsn/busybox 1.0 5b0d59026729 8 days ago 1.15MB 4、将新打标签的镜像上传镜像到仓库 1[root@docker01 ~]# docker push 10.0.0.100:5000/clsn/busybox 10.2. 带basic认证的仓库1、安装加密工具 1[root@docker01 clsn]# yum install httpd-tools -y 2、设置认证密码 12mkdir /opt/registry-var/auth/ -phtpasswd -Bbn clsn 123456 &gt; /opt/registry-var/auth/htpasswd 3、启动容器，在启动时传入认证参数 1docker run -d -p 5000:5000 -v /opt/registry-var/auth/:/auth/ -e &quot;REGISTRY_AUTH=htpasswd&quot; -e &quot;REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm&quot; -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd registry 4、使用验证用户测试 12345678910111213141516171819202122232425# 登陆用户[root@docker01 ~]# docker login 10.0.0.100:5000 Username: clsn Password: 123456Login Succeeded# 推送镜像到仓库[root@docker01 ~]# docker push 10.0.0.100:5000/clsn/busybox The push refers to repository [10.0.0.100:5000/clsn/busybox]4febd3792a1f: Pushed 1.0: digest: sha256:4cee1979ba0bf7db9fc5d28fb7b798ca69ae95a47c5fecf46327720df4ff352d size: 527#认证文件的保存位置[root@docker01 ~]# cat .docker/config.json &#123; &quot;auths&quot;: &#123; &quot;10.0.0.100:5000&quot;: &#123; &quot;auth&quot;: &quot;Y2xzbjoxMjM0NTY=&quot; &#125;, &quot;https://index.docker.io/v1/&quot;: &#123; &quot;auth&quot;: &quot;Y2xzbjpIenNAMTk5Ng==&quot; &#125; &#125;, &quot;HttpHeaders&quot;: &#123; &quot;User-Agent&quot;: &quot;Docker-Client/17.12.0-ce (linux)&quot; &#125;&#125; 至此，一个简单的docker镜像仓库搭建完成 11. docker-compose编排工具11.1. 安装docker-compose1234# 下载pip软件yum install -y python2-pip# 下载 docker-composepip install docker-compose 国内开启pip 下载加速： http://mirrors.aliyun.com/help/pypi 1234567mkdir ~/.pip/cat &gt; ~/.pip/pip.conf &lt;&lt;&#x27;EOF&#x27;[global]index-url = https://mirrors.aliyun.com/pypi/simple/[install]trusted-host=mirrors.aliyun.comEOF 11.2. 编排启动镜像1、创建文件目录 12[root@docker01 ~]# mkdir /opt/my_wordpress/[root@docker01 ~]# cd /opt/my_wordpress/ 2、编写编排文件 1234567891011121314151617181920212223242526[root@docker01 my_wordpress]# vim docker-compose.ymlversion: &#x27;3&#x27;services: db: image: mysql:5.7 volumes: - /data/db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - /data/web_data:/var/www/html ports: - &quot;8000:80&quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress 3、启动 123[root@docker01 my_wordpress]# docker-compose up #启动方法：docker-compose up #后台启动方法：docker-compose up -d 4、浏览器上访问http://10.0.0.100:8000 进行wordpress的安装即可 11.3. haproxy代理后端docker容器1、修改编排脚本 1234567891011121314151617181920212223242526[root@docker01 my_wordpress]# cat docker-compose.yml version: &#x27;3&#x27;services: db: image: mysql:5.7 volumes: - /data/db_data:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: somewordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: depends_on: - db image: wordpress:latest volumes: - /data/web_data:/var/www/html ports: - &quot;80&quot; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress 2、同时启动两台wordpress 1234[root@docker01 my_wordpress]# docker-compose scale wordpress=2 WARNING: The scale command is deprecated. Use the up command with the --scale flag instead.Starting mywordpress_wordpress_1 ... doneCreating mywordpress_wordpress_2 ... done 3、安装haproxy 1[root@docker01 ~]# yum install haproxy -y 4、修改haproxy配置文件 关于配置文件的详细说明，参考： https://www.cnblogs.com/MacoLee/p/5853413.html 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[root@docker01 ~]#cp /etc/haproxy/haproxy.cfg&#123;,.bak&#125;[root@docker01 ~]# vim /etc/haproxy/haproxy.cfgglobal log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/stats level admin #支持命令行控制defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000listen stats mode http bind 0.0.0.0:8888 stats enable stats uri /haproxy-status stats auth admin:123456frontend frontend_www_example_com bind 10.0.0.100:8000 mode http option httplog log global default_backend backend_www_example_combackend backend_www_example_com option forwardfor header X-REAL-IP option httpchk HEAD / HTTP/1.0 balance roundrobin server web-node1 10.0.0.100:32768 check inter 2000 rise 30 fall 15 server web-node2 10.0.0.100:32769 check inter 2000 rise 30 fall 15 5、启动haproxy 12systemctl start haproxysystemctl enable haproxy 6、使用浏览器访问hapeoxy监听的8000端口可以看到负载的情况 7、使用浏览器访问 http://10.0.0.100:8888/haproxy-status 可以看到后端节点的监控状况， 11.4. 安装socat 直接操作socket控制haproxy1、安装软件 1yum install socat.x86_64 -y 2、查看帮助 1[root@docker01 web_data]# echo &quot;help&quot;|socat stdio /var/lib/haproxy/stats 3、下线后端节点 1echo &quot;disable server backend_www_example_com/web-node2&quot;|socat stdio /var/lib/haproxy/stats 4、上线后端节点 1echo &quot;enable server backend_www_example_com/web-node3&quot;|socat stdio /var/lib/haproxy/stats 5、编写php测试页，放到&#x2F;data&#x2F;web_data下，在浏览器中访问可以查看当前的节点 123456789101112[root@docker01 web_data]# vim check.php&lt;html&gt; &lt;head&gt; &lt;title&gt;PHP测试&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;?php echo &#x27;&lt;p&gt;Hello World &lt;/p&gt;&#x27;; ?&gt; &lt;?php echo &quot;访问的服务器地址是:&quot;.&quot;&lt;fontcolor=red&gt;&quot;.$_SERVER[&#x27;SERVER_ADDR&#x27;].&quot;&lt;/font&gt;&quot;.&quot;&lt;br&gt;&quot;; echo&quot;访问的服务器域名是:&quot;.&quot;&lt;fontcolor=red&gt;&quot;.$_SERVER[&#x27;SERVER_NAME&#x27;].&quot;&lt;/font&gt;&quot;.&quot;&lt;br&gt;&quot;; ?&gt; &lt;/body&gt;&lt;/html&gt; 12. 重启docker服务，容器全部退出的解决办法12.1. 在启动是指定自动重启1docker run --restart=always 12.1. 修改docker默认配置文件12# 添加上下面这行&quot;live-restore&quot;: true docker server配置文件 &#x2F;etc&#x2F;docker&#x2F;daemon.json 参考 1234567[root@docker02 ~]# cat /etc/docker/daemon.json &#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;graph&quot;: &quot;/opt/mydocker&quot;, # 修改数据的存放目录到/opt/mydocker/，原/var/lib/docker/ &quot;insecure-registries&quot;: [&quot;10.0.0.100:5000&quot;], &quot;live-restore&quot;: true&#125; 重启生效，只对在此之后启动的容器生效 1[root@docker01 ~]# systemctl restart docker.service 13. Docker网络类型 13.1. docker的网络类型 Bridge默认docker网络隔离基于网络命名空间，在物理机上创建docker容器时会为每一个docker容器分配网络命名空间，并且把容器IP桥接到物理机的虚拟网桥上。 13.2. 不为容器配置网络功能此模式下创建容器是不会为容器配置任何网络参数的，如：容器网卡、IP、通信路由等，全部需要自己去配置。 123456[root@docker01 ~]# docker run -it --network none busybox:latest /bin/sh / # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 13.3. 与其他容器共享网络配置(Container）此模式和host模式很类似，只是此模式创建容器共享的是其他容器的IP和端口而不是物理机，此模式容器自身是不会配置网络和端口，创建此模式容器进去后，你会发现里边的IP是你所指定的那个容器IP并且端口也是共享的，而且其它还是互相隔离的，如进程等。 12345678910[root@docker01 ~]# docker run -it --network container:mywordpress_db_1 busybox:latest /bin/sh / # ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever105: eth0@if106: &lt;BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN&gt; mtu 1500 qdisc noqueue link/ether 02:42:ac:12:00:03 brd ff:ff:ff:ff:ff:ff inet 172.18.0.3/16 brd 172.18.255.255 scope global eth0 valid_lft forever preferred_lft forever 13.4. 使用宿主机网络此模式创建的容器没有自己独立的网络命名空间，是和物理机共享一个Network Namespace，并且共享物理机的所有端口与IP，并且这个模式认为是不安全的。 1[root@docker01 ~]# docker run -it --network host busybox:latest /bin/shshell 13.5. 查看网络列表123456[root@docker01 ~]# docker network list NETWORK ID NAME DRIVER SCOPEb15e8a720d3b bridge bridge local345d65b4c2a0 host host localbc5e2a32bb55 mywordpress_default bridge localebf76eea91bb none null local 用PIPEWORK为docker容器配置独立IP 参考文档： blog.csdn.net&#x2F;design321&#x2F;article&#x2F;details&#x2F;48264825 官方网站： github.com&#x2F;jpetazzo&#x2F;pipework 宿主环境：centos7.2 1、安装pipework 1234wget https://github.com/jpetazzo/pipework/archive/master.zipunzip master.zip cp pipework-master/pipework /usr/local/bin/chmod +x /usr/local/bin/pipework 2、配置桥接网卡 安装桥接工具 1yum install bridge-utils.x86_64 -y 修改网卡配置，实现桥接 1234567891011121314151617181920# 修改eth0配置，让br0实现桥接[root@docker01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE=EthernetBOOTPROTO=staticNAME=eth0DEVICE=eth0ONBOOT=yesBRIDGE=br0[root@docker01 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 TYPE=BridgeBOOTPROTO=staticNAME=br0DEVICE=br0ONBOOT=yesIPADDR=10.0.0.100NETMASK=255.255.255.0GATEWAY=10.0.0.254DNS1=223.5.5.5# 重启网络[root@docker01 ~]# /etc/init.d/network restart 3、运行一个容器镜像测试： 1pipework br0 $(docker run -d -it -p 6880:80 --name httpd_pw httpd) 10.0.0.220/24@10.0.0.254 在其他主机上测试端口及连通性 12345[root@docker01 ~]# curl 10.0.0.220&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;[root@docker01 ~]# ping 10.0.0.220 -c 1PING 10.0.0.220 (10.0.0.220) 56(84) bytes of data.64 bytes from 10.0.0.220: icmp_seq=1 ttl=64 time=0.043 ms 4、再运行一个容器，设置网路类型为none： 1pipework br0 $(docker run -d -it --net=none --name test httpd:2.4) 10.0.0.221/24@10.0.0.254 进行访问测试 12[root@docker01 ~]# curl 10.0.0.221&lt;html&gt;&lt;body&gt;&lt;h1&gt;It works!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 5、重启容器后需要再次指定： 12pipework br0 testduliip 172.16.146.113/24@172.16.146.1pipework br0 testduliip01 172.16.146.112/24@172.16.146.1 Dcoker跨主机通信之overlay可以参考： cnblogs.com&#x2F;CloudMan6&#x2F;p&#x2F;7270551.html 13.6. Docker跨主机通信之macvlan创建网络 12[root@docker01 ~]# docker network create --driver macvlan --subnet 10.1.0.0/24 --gateway 10.1.0.254 -o parent=eth0 macvlan_133a1f41dcc074f91b5bd45e7dfedabfb2b8ec82db16542f05213839a119b62ca 设置网卡为混杂模式 1ip link set eth0 promisc on 创建使用macvlan网络容器 1[root@docker02 ~]# docker run -it --network macvlan_1 --ip=10.1.0.222 busybox /b 14. docker企业级镜像仓库harbor容器管理 123[root@docker01 harbor]# pwd/opt/harbor[root@docker01 harbor]# docker-compose stop 1、安装docker、docker-compose 下载 harbor 12cd /opt &amp;&amp; https://storage.googleapis.com/harbor-releases/harbor-offline-installer-v1.3.0.tgztar xf harbor-offline-installer-v1.3.0.tgz 2、修改主机及web界面密码 12345[root@docker01 harbor]# vim harbor.cfg ··· hostname = 10.0.0.100 harbor_admin_password = Harbor12345 ··· 3、执行安装脚本 1[root@docker01 harbor]# ./install.sh 浏览器访问 http://10.0.0.11 添加一个项目 4、镜像推送到仓库的指定项目 1234567891011[root@docker02 ~]# docker tag centos:6.8 10.0.0.100/clsn/centos6.8:1.0[root@docker02 ~]# [root@docker02 ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZEbusybox latest 5b0d59026729 8 days ago 1.15MB10.0.0.100/clsn/centos6.8 1.0 6704d778b3ba 2 months ago 195MBcentos 6.8 6704d778b3ba 2 months ago 195MB[root@docker02 ~]# docker login 10.0.0.100Username: adminPassword: Login Succeeded 5、推送镜像 123[root@docker02 ~]# docker push 10.0.0.100/clsn/centos6.8 The push refers to repository [10.0.0.100/clsn/centos6.8]e00c9229b481: Pushing 13.53MB/194.5MB 6、在web界面里查看 14.1. 使用容器的建议 不要以拆分方式进行应用程序发布 不要创建大型镜像 不要在单个容器中运行多个进程 不要再镜像内保存凭证，不要依赖IP地址 以非root用户运行进程 不要使用“最新”标签 不要利用运行中的容器创建镜像 不要使用单层镜像 不要将数据存放在容器内 14.2. 关于Docker容器的监控容器的基本信息 包括容器的数量、ID、名称、镜像、启动命令、端口等信息 容器的运行状态 统计各状态的容器的数量，包括运行中、暂停、停止及异常退出 容器的用量信息 统计容器的CPU使用率、内存使用量、块设备I&#x2F;O使用量、网络使用情况等资源的使用情况 参考文献 redhat.com&#x2F;zh&#x2F;topics&#x2F;containers&#x2F;whats-a-linux-container redhat.com&#x2F;zh&#x2F;topics&#x2F;containers&#x2F;what-is-docker blog.51cto.com&#x2F;dihaifeng&#x2F;1713512 cnblogs.com&#x2F;Bourbon-tian&#x2F;p&#x2F;6867796.html cnblogs.com&#x2F;CloudMan6&#x2F;p&#x2F;6806193.html","tags":["开发工具","Docker"],"categories":["开发工具"]},{"title":"MySQL大表优化方案","path":"/2023/12/24/MySQL大表优化方案/","content":"当MySQL单表记录数过大时，增删改查性能都会急剧下降，可以参考以下步骤来优化： 单表优化除非单表数据未来会一直不断上涨，否则不要一开始就考虑拆分，拆分会带来逻辑、部署、运维的各种复杂度，一般以整型值为主的表在千万级以下，字符串为主的表在五百万以下是没有太大问题的。而事实上很多时候MySQL单表的性能依然有不少优化空间，甚至能正常支撑千万级以上的数据量： 字段 尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED VARCHAR的长度只分配真正需要的空间 使用枚举或整数代替字符串类型 尽量使用TIMESTAMP而非DATETIME， 单表不要有太多字段，建议在20以内 避免使用NULL字段，很难查询优化且占用额外索引空间 用整型来存IP 索引 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描 值分布很稀少的字段不适合建索引，例如”性别”这种只有两三个值的字段 字符字段只建前缀索引 字符字段最好不要做主键 不用外键，由程序保证约束 尽量不用UNIQUE，由程序保证约束 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引 查询SQL 可通过开启慢查询日志来找出较慢的SQL 不做列运算：SELECT id WHERE age + 1 &#x3D; 10，任何对列的操作都将导致表扫描，它包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至等号右边 sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间；一条大sql可以堵死整个库 不用SELECT * OR改写成IN：OR的效率是n级别，IN的效率是log(n)级别，in的个数建议控制在200以内 不用函数和触发器，在应用程序实现 避免%xxx式查询 少用JOIN 使用同类型进行比较，比如用’123’和’123’比，123和123比 尽量避免在WHERE子句中使用!&#x3D;或&lt;&gt;操作符，否则将引擎放弃使用索引而进行全表扫描 对于连续数值，使用BETWEEN不用IN：SELECT id FROM t WHERE num BETWEEN 1 AND 5 列表数据不要拿全表，要使用LIMIT来分页，每页数量也不要太大 引擎目前广泛使用的是MyISAM和InnoDB两种引擎： MyISAMMyISAM引擎是MySQL 5.1及之前版本的默认引擎，它的特点是： 不支持行锁，读取时对需要读到的所有表加锁，写入时则对表加排它锁 不支持事务 不支持外键 不支持崩溃后的安全恢复 在表有读取查询的同时，支持往表中插入新纪录 支持BLOB和TEXT的前500个字符索引，支持全文索引 支持延迟更新索引，极大提升写入性能 对于不会进行修改的表，支持压缩表，极大减少磁盘空间占用 InnoDBInnoDB在MySQL 5.5后成为默认索引，它的特点是： 支持行锁，采用MVCC来支持高并发 支持事务 支持外键 支持崩溃后的安全恢复 不支持全文索引 总体来讲，MyISAM适合SELECT密集型的表，而InnoDB适合INSERT和UPDATE密集型的表 系统调优参数可以使用下面几个工具来做基准测试： sysbench：一个模块化，跨平台以及多线程的性能测试工具 iibench-mysql：基于 Java 的 MySQL&#x2F;Percona&#x2F;MariaDB 索引进行插入性能测试工具 tpcc-mysql：Percona开发的TPC-C测试工具 具体的调优参数内容较多，具体可参考官方文档，这里介绍一些比较重要的参数： back_log：back_log值指出在MySQL暂时停止回答新请求之前的短时间内多少个请求可以被存在堆栈中。也就是说，如果MySql的连接数据达到max_connections时，新来的请求将会被存在堆栈中，以等待某一连接释放资源，该堆栈的数量即back_log，如果等待连接的数量超过back_log，将不被授予连接资源。可以从默认的50升至500 wait_timeout：数据库连接闲置时间，闲置连接会占用内存资源。可以从默认的8小时减到半小时 max_user_connection: 最大连接数，默认为0无上限，最好设一个合理上限 thread_concurrency：并发线程数，设为CPU核数的两倍 skip_name_resolve：禁止对外部连接进行DNS解析，消除DNS解析时间，但需要所有远程主机用IP访问 key_buffer_size：索引块的缓存大小，增加会提升索引处理速度，对MyISAM表性能影响最大。对于内存4G左右，可设为256M或384M，通过查询show status like ‘key_read%’，保证key_reads &#x2F; key_read_requests在0.1%以下最好 innodb_buffer_pool_size：缓存数据块和索引块，对InnoDB表性能影响最大。通过查询show status like ‘Innodb_buffer_pool_read%’，保证 (Innodb_buffer_pool_read_requests – Innodb_buffer_pool_reads) &#x2F; Innodb_buffer_pool_read_requests越高越好 innodb_additional_mem_pool_size：InnoDB存储引擎用来存放数据字典信息以及一些内部数据结构的内存空间大小，当数据库对象非常多的时候，适当调整该参数的大小以确保所有数据都能存放在内存中提高访问效率，当过小的时候，MySQL会记录Warning信息到数据库的错误日志中，这时就需要该调整这个参数大小 innodb_log_buffer_size：InnoDB存储引擎的事务日志所使用的缓冲区，一般来说不建议超过32MB query_cache_size：缓存MySQL中的ResultSet，也就是一条SQL语句执行的结果集，所以仅仅只能针对select语句。当某个表的数据有任何任何变化，都会导致所有引用了该表的select语句在Query Cache中的缓存数据失效。所以，当我们的数据变化非常频繁的情况下，使用Query Cache可能会得不偿失。根据命中率(Qcache_hits&#x2F;(Qcache_hits+Qcache_inserts)*100))进行调整，一般不建议太大，256MB可能已经差不多了，大型的配置型静态数据可适当调大.可以通过命令show status like ‘Qcache_%’查看目前系统Query catch使用大小 read_buffer_size：MySql读入缓冲区大小。对表进行顺序扫描的请求将分配一个读入缓冲区，MySql会为它分配一段内存缓冲区。如果对表的顺序扫描请求非常频繁，可以通过增加该变量值以及内存缓冲区大小提高其性能 sort_buffer_size：MySql执行排序使用的缓冲大小。如果想要增加ORDER BY的速度，首先看是否可以让MySQL使用索引而不是额外的排序阶段。如果不能，可以尝试增加sort_buffer_size变量的大小 read_rnd_buffer_size：MySql的随机读缓冲区大小。当按任意顺序读取行时(例如，按照排序顺序)，将分配一个随机读缓存区。进行排序查询时，MySql会首先扫描一遍该缓冲，以避免磁盘搜索，提高查询速度，如果需要排序大量数据，可适当调高该值。但MySql会为每个客户连接发放该缓冲空间，所以应尽量适当设置该值，以避免内存开销过大。 record_buffer：每个进行一个顺序扫描的线程为其扫描的每张表分配这个大小的一个缓冲区。如果你做很多顺序扫描，可能想要增加该值 thread_cache_size：保存当前没有与连接关联但是准备为后面新的连接服务的线程，可以快速响应连接的线程请求而无需创建新的 table_cache：类似于thread_cache_size，但用来缓存表文件，对InnoDB效果不大，主要用于MyISAM 升级硬件Scale up，这个不多说了，根据MySQL是CPU密集型还是I&#x2F;O密集型，通过提升CPU和内存、使用SSD，都能显著提升MySQL性能 读写分离也是目前常用的优化，从库读主库写，一般不要采用双主或多主引入很多复杂性，尽量采用文中的其他方案来提高性能。同时目前很多拆分的解决方案同时也兼顾考虑了读写分离 缓存缓存可以发生在这些层次： MySQL内部：在系统调优参数介绍了相关设置 数据访问层：比如MyBatis针对SQL语句做缓存，而Hibernate可以精确到单个记录，这里缓存的对象主要是持久化对象Persistence Object 应用服务层：这里可以通过编程手段对缓存做到更精准的控制和更多的实现策略，这里缓存的对象是数据传输对象Data Transfer Object Web层：针对web页面做缓存 浏览器客户端：用户端的缓存 可以根据实际情况在一个层次或多个层次结合加入缓存。这里重点介绍下服务层的缓存实现，目前主要有两种方式： 直写式（Write Through）：在数据写入数据库后，同时更新缓存，维持数据库与缓存的一致性。这也是当前大多数应用缓存框架如Spring Cache的工作方式。这种实现非常简单，同步好，但效率一般。 回写式（Write Back）：当有数据要写入数据库时，只会更新缓存，然后异步批量的将缓存数据同步到数据库上。这种实现比较复杂，需要较多的应用逻辑，同时可能会产生数据库与缓存的不同步，但效率非常高。 表分区MySQL在5.1版引入的分区是一种简单的水平拆分，用户需要在建表的时候加上分区参数，对应用是透明的无需修改代码 对用户来说，分区表是一个独立的逻辑表，但是底层由多个物理子表组成，实现分区的代码实际上是通过对一组底层表的对象封装，但对SQL层来说是一个完全封装底层的黑盒子。MySQL实现分区的方式也意味着索引也是按照分区的子表定义，没有全局索引 用户的SQL语句是需要针对分区表做优化，SQL条件中要带上分区条件的列，从而使查询定位到少量的分区上，否则就会扫描全部分区，可以通过EXPLAIN PARTITIONS来查看某条SQL语句会落在那些分区上，从而进行SQL优化，如下图5条记录落在两个分区上： 12345678mysql&gt; explain partitions select count(1) from user_partition where id in (1,2,3,4,5);+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+| 1 | SIMPLE | user_partition | p1,p4 | range | PRIMARY | PRIMARY | 8 | NULL | 5 | Using where; Using index |+----+-------------+----------------+------------+-------+---------------+---------+---------+------+------+--------------------------+1 row in set (0.00 sec) 分区的好处是： 可以让单表存储更多的数据 分区表的数据更容易维护，可以通过清楚整个分区批量删除大量数据，也可以增加新的分区来支持新插入的数据。另外，还可以对一个独立分区进行优化、检查、修复等操作 部分查询能够从查询条件确定只落在少数分区上，速度会很快 分区表的数据还可以分布在不同的物理设备上，从而搞笑利用多个硬件设备 可以使用分区表赖避免某些特殊瓶颈，例如InnoDB单个索引的互斥访问、ext3文件系统的inode锁竞争 可以备份和恢复单个分区 分区的限制和缺点： 一个表最多只能有1024个分区 如果分区字段中有主键或者唯一索引的列，那么所有主键列和唯一索引列都必须包含进来 分区表无法使用外键约束 NULL值会使分区过滤无效 所有分区必须使用相同的存储引擎 分区的类型： RANGE分区：基于属于一个给定连续区间的列值，把多行分配给分区 LIST分区：类似于按RANGE分区，区别在于LIST分区是基于列值匹配一个离散值集合中的某个值来进行选择 HASH分区：基于用户定义的表达式的返回值来进行选择的分区，该表达式使用将要插入到表中的这些行的列值进行计算。这个函数可以包含MySQL中有效的、产生非负整数值的任何表达式 KEY分区：类似于按HASH分区，区别在于KEY分区只支持计算一列或多列，且MySQL服务器提供其自身的哈希函数。必须有一列或多列包含整数值 分区适合的场景有： 最适合的场景数据的时间序列性比较强，则可以按时间来分区，如下所示： 1234567891011121314CREATE TABLE members ( firstname VARCHAR(25) NOT NULL, lastname VARCHAR(25) NOT NULL, username VARCHAR(16) NOT NULL, email VARCHAR(35), joined DATE NOT NULL)PARTITION BY RANGE( YEAR(joined) ) ( PARTITION p0 VALUES LESS THAN (1960), PARTITION p1 VALUES LESS THAN (1970), PARTITION p2 VALUES LESS THAN (1980), PARTITION p3 VALUES LESS THAN (1990), PARTITION p4 VALUES LESS THAN MAXVALUE); 查询时加上时间范围条件效率会非常高，同时对于不需要的历史数据能很容的批量删除。 如果数据有明显的热点，而且除了这部分数据，其他数据很少被访问到，那么可以将热点数据单独放在一个分区，让这个分区的数据能够有机会都缓存在内存中，查询时只访问一个很小的分区表，能够有效使用索引和缓存 另外MySQL有一种早期的简单的分区实现 - 合并表（merge table），限制较多且缺乏优化，不建议使用，应该用新的分区机制来替代 垂直拆分垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数一般情况下是相同的，只是字段不一样，使用主键关联 比如原始的用户表是： 垂直拆分后是： 垂直拆分的优点是： 可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I&#x2F;O次数(每次查询时读取的Block 就少) 可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起 数据维护简单 缺点是： 主键出现冗余，需要管理冗余列 会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力 依然存在单表数据量过大的问题（需要水平拆分） 事务处理复杂 水平拆分概述水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。 前面的表分区本质上也是一种特殊的库内分表 库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决 前面垂直拆分的用户表如果进行水平拆分，结果是： 实际情况中往往会是垂直拆分和水平拆分的结合，即将Users_A_M和Users_N_Z再拆成Users和UserExtras，这样一共四张表 水平拆分的优点是: 不存在单库大数据和高并发的性能瓶颈 应用端改造较少 提高了系统的稳定性和负载能力 缺点是： 分片事务一致性难以解决 跨节点Join性能差，逻辑复杂 数据多次扩展难度跟维护量极大 分片原则 能不分就不分，参考单表优化 分片数量尽量少，分片尽量均匀分布在多个数据结点上，因为一个查询SQL跨分片越多，则总体性能越差，虽然要好于所有数据在一个分片的结果，只在必要的时候进行扩容，增加分片数量 分片规则需要慎重选择做好提前规划，分片规则的选择，需要考虑数据的增长模式，数据的访问模式，分片关联性问题，以及分片扩容问题，最近的分片策略为范围分片，枚举分片，一致性Hash分片，这几种分片都有利于扩容 尽量不要在一个事务中的SQL跨越多个分片，分布式事务一直是个不好处理的问题 查询条件尽量优化，尽量避免Select * 的方式，大量数据结果集下，会消耗大量带宽和CPU资源，查询尽量避免返回大量结果集，并且尽量为频繁使用的查询语句建立索引。 通过数据冗余和表分区赖降低跨库Join的可能 这里特别强调一下分片规则的选择问题，如果某个表的数据有明显的时间特征，比如订单、交易记录等，则他们通常比较合适用时间范围分片，因为具有时效性的数据，我们往往关注其近期的数据，查询条件中往往带有时间字段进行过滤，比较好的方案是，当前活跃的数据，采用跨度比较短的时间段进行分片，而历史性的数据，则采用比较长的跨度存储。 总体上来说，分片的选择是取决于最频繁的查询SQL的条件，因为不带任何Where语句的查询SQL，会遍历所有的分片，性能相对最差，因此这种SQL越多，对系统的影响越大，所以我们要尽量避免这种SQL的产生。 解决方案由于水平拆分牵涉的逻辑比较复杂，当前也有了不少比较成熟的解决方案。这些方案分为两大类：客户端架构和代理架构。 客户端架构通过修改数据访问层，如JDBC、Data Source、MyBatis，通过配置来管理多个数据源，直连数据库，并在模块内完成数据的分片整合，一般以Jar包的方式呈现 这是一个客户端架构的例子： 可以看到分片的实现是和应用服务器在一起的，通过修改Spring JDBC层来实现 客户端架构的优点是： 应用直连数据库，降低外围系统依赖所带来的宕机风险 集成成本低，无需额外运维的组件 缺点是： 限于只能在数据库访问层上做文章，扩展性一般，对于比较复杂的系统可能会力不从心 将分片逻辑的压力放在应用服务器上，造成额外风险 代理架构通过独立的中间件来统一管理所有数据源和数据分片整合，后端数据库集群对前端应用程序透明，需要独立部署和运维代理组件 这是一个代理架构的例子： 代理组件为了分流和防止单点，一般以集群形式存在，同时可能需要Zookeeper之类的服务组件来管理 代理架构的优点是： 能够处理非常复杂的需求，不受数据库访问层原来实现的限制，扩展性强 对于应用服务器透明且没有增加任何额外负载 缺点是： 需部署和运维独立的代理中间件，成本高 应用需经过代理来连接数据库，网络上多了一跳，性能有损失且有额外风险 各方案比较 出品方 架构模型 支持数据库 分库 分表 读写分离 外部依赖 是否开源 实现语言 支持语言 最后更新 Github星数 MySQL Fabric MySQL官方 代理架构 MySQL 有 有 有 无 是 python 无限制 4个月前 35 Cobar 阿里巴巴 代理架构 MySQL 有 无 无 无 是 Java 无限制 两年前 1287 Cobar Client 阿里巴巴 客户端架构 MySQL 有 无 无 无 是 Java Java 三年前 344 TDDL 淘宝 客户端架构 无限制 有 有 有 Diamond 只开源部分 Java Java 未知 519 Atlas 奇虎360 代理架构 MySQL 有 有 有 无 是 C 无限制 10个月前 1941 Heisenberg 百度熊照 代理架构 MySQL 有 有 有 无 是 Java 无限制 2个月前 197 TribeDB 个人 代理架构 MySQL 有 有 有 无 是 NodeJS 无限制 3个月前 126 ShardingJDBC 当当 客户端架构 MySQL 有 有 有 无 是 Java Java 当天 1144 Shark 个人 客户端架构 MySQL 有 有 无 无 是 Java Java 两天前 84 KingShard 个人 代理架构 MySQL 有 有 有 无 是 Golang 无限制 两天前 1836 OneProxy 平民软件 代理架构 MySQL 有 有 有 无 否 未知 无限制 未知 未知 MyCat 社区 代理架构 MySQL 有 有 有 无 是 Java 无限制 两天前 1270 Vitess Youtube 代理架构 MySQL 有 有 有 无 是 Golang 无限制 当天 3636 Mixer 个人 代理架构 MySQL 有 有 无 无 是 Golang 无限制 9个月前 472 JetPants Tumblr 客户端架构 MySQL 有 有 无 无 是 Ruby Ruby 10个月前 957 HibernateShard Hibernate 客户端架构 无限制 有 有 无 无 是 Java Java 4年前 57 MybatisShard MakerSoft 客户端架构 无限制 有 有 无 无 是 Java Java 11个月前 119 Gizzard Twitter 代理架构 无限制 有 有 无 无 是 Java 无限制 3年前 2087 如此多的方案，如何进行选择？可以按以下思路来考虑： 确定是使用代理架构还是客户端架构。中小型规模或是比较简单的场景倾向于选择客户端架构，复杂场景或大规模系统倾向选择代理架构 具体功能是否满足，比如需要跨节点ORDER BY，那么支持该功能的优先考虑 不考虑一年内没有更新的产品，说明开发停滞，甚至无人维护和技术支持 最好按大公司-&gt;社区-&gt;小公司-&gt;个人这样的出品方顺序来选择 选择口碑较好的，比如github星数、使用者数量质量和使用者反馈 开源的优先，往往项目有特殊需求可能需要改动源代码 按照上述思路，推荐以下选择： 客户端架构：ShardingJDBC 代理架构：MyCat或者Atlas 兼容MySQL且可水平扩展的数据库目前也有一些开源数据库兼容MySQL协议，如： TiDB Cubrid 但其工业品质和MySQL尚有差距，且需要较大的运维投入，如果想将原始的MySQL迁移到可水平扩展的新数据库中，可以考虑一些云数据库： 阿里云PetaData 阿里云OceanBase 腾讯云DCDB NoSQL在MySQL上做Sharding是一种戴着镣铐的跳舞，事实上很多大表本身对MySQL这种RDBMS的需求并不大，并不要求ACID，可以考虑将这些表迁移到NoSQL，彻底解决水平扩展问题，例如： 日志类、监控类、统计类数据 非结构化或弱结构化数据 对事务要求不强，且无太多关联操作的数据","tags":["MySQL","DataBase"],"categories":["DataBase"]},{"title":"MyBatis 的执行流程","path":"/2023/12/24/MyBatis-的执行流程！/","content":"概要在MyBatis中，利用编程式进行数据查询，主要就是下面几行代码： 123SqlSession session = sqlSessionFactory.openSession();UserMapper userMapper = session.getMapper(UserMapper.class);List&lt;LwUser&gt; userList = userMapper.listUserByUserName(&quot;孤狼1号&quot;); 第一行是获取一个SqlSession对象在上一篇文章分析过了，第二行就是获取UserMapper接口，第三行一行代码就实现了整个查询语句的流程，接下来我们就来仔细分析一下第二和第三步。 获取Mapper接口(getMapper)第二步是通过SqlSession对象是获取一个Mapper接口，这个流程还是相对简单的，下面就是我们调用session.getMapper方法之后的运行时序图： 1、在调用getMapper之后，会去Configuration对象中获取Mapper对象，因为在项目启动的时候就会把Mapper接口加载并解析存储到Configuration对象 2、通过Configuration对象中的MapperRegistry对象属性，继续调用getMapper方法 3、根据type类型，从MapperRegistry对象中的knownMappers获取到当前类型对应的代理工厂类，然后通过代理工厂类生成对应Mapper的代理类 4、最终获取到我们接口对应的代理类MapperProxy对象 而MapperProxy可以看到实现了InvocationHandler，使用的就是JDK动态代理。 至此获取Mapper流程结束了，那么就有一个问题了MapperRegistry对象内的HashMap属性knownMappers中的数据是什么时候存进去的呢？ Mapper接口和映射文件是何时关联的Mapper接口及其映射文件是在加载mybatis-config配置文件的时候存储进去的，下面就是时序图： 1、首先我们会手动调用SqlSessionFactoryBuilder方法中的build()方法： 2、然后会构造一个XMLConfigBuilder对象，并调用其parse方法： 3、然后会继续调用自己的parseConfiguration来解析配置文件，这里面就会分别去解析全局配置文件的顶级节点，其他的我们先不看，我们直接看最后解析mappers节点 4、继续调用自己的mapperElement来解析mappers文件（这个方法比较长，为了方便截图完整，所以把字体缩小了1号），可以看到，这里面分了四种方式来解析mappers节点的配置，对应了4种mapper配置方式，而其中红框内的两种方式是直接配置的xml映射文件，蓝框内的两种方式是解析直接配置Mapper接口的方式，从这里也可以说明，不论配置哪种方式，最终MyBatis都会将xml映射文件和Mapper接口进行关联。 5、我们先看第2种和第3中（直接配置xml映射文件的解析方式），会构建一个XMLMapperBuilder对象并调用其parse方法。 当然，这个还是会被解析的，后面执行查询的时候会再次通过不断遍历去全部解析完毕，不过有一点需要注意的是，互相引用这种是会导致解析失败报错的，所以在开发过程中我们应该避免循环依赖的产生。 6、解析完映射文件之后，调用自身方法bindMapperForNamespace，开始绑定Mapper接口和映射文件： 7、调用Configuration对象的addMapper 8、调用Configuration对象的属性MapperRegistry内的addMapper方法，这个方法就是正式将Mapper接口添加到knownMappers，所以上面getMapper可以直接获取： 到这里我们就完成了Mapper接口和xml映射文件的绑定 9、注意上面红框里面的代码，又调用了一次parse方法，这个parse方法主要是解析注解，比如下面的语句： 12@Select(&quot;select * from lw_user&quot;)List&lt;LwUser&gt; listAllUser(); 所以这个方法里面会去解析@Select等注解，需要注意的是，parse方法里面会同时再解析一次xml映射文件，因为上面我们提到了mappers节点有4种配置方式，其中两种配置的是Mapper接口，而配置Mapper接口会直接先调用addMapper接口，并没有解析映射文件，所以进入注解解析方法parse之中会需要再尝试解析一次XML映射文件。 解析完成之后，还会对Mapper接口中的方法进行解析，并将每个方法的全限定类名作为key存入存入Configuration中的mappedStatements属性。 需要指出的是，这里存储的时候，同一个value会存储2次，**一个全限定名作为key，另一个就是只用方法名(sql语句的id)来作为key**： 所以最终mappedStatements会是下面的情况： 事实上如果我们通过接口的方式来编程的话，最后来getStatement的时候，都是根据全限定名来取的，所以即使有重名对我们也没有影响，而之所以要这么做的原因其实还是为了兼容早期版本的用法，那就是不通过接口，而是直接通过方法名的方式来进行查询： 1session.selectList(&quot;com.lonelyWolf.mybatis.mapper.UserMapper.listAllUser&quot;); 这里如果shortName没有重复的话，是可以直接通过简写来查询的： 1session.selectList(&quot;listAllUser&quot;); 但是通过简写来查询一旦shortName重复了就会抛出以下异常： 这里的异常其实就是StrickMap的get方法抛出来的： sql执行流程分析上面我们讲到了，获取到的Mapper接口实际上被包装成为了代理对象，所以我们执行查询语句肯定是执行的代理对象方法，接下来我们就以Mapper接口的代理对象MapperProxy来分析一下查询流程。 整个sql执行流程可以分为两大步骤： 一、寻找sql 二、执行sql语句 寻找sql首先还是来看一下寻找sql语句的时序图： 1、了解代理模式的应该都知道，调用被代理对象的方法之后实际上执行的就是代理对象的invoke方法 2、因为我们这里并没有调用Object类中的方法，所以肯定走的else。else中会继续调用MapperProxy内部类MapperMethodInvoker中的方法cachedInvoker，这里面会有一个判断，判断一下我们是不是default方法，因为Jdk1.8中接口中可以新增default方法，而default方法是并不是一个抽象方法，所以也需要特殊处理（刚开始会从缓存里面取，缓存相关知识我们这里先不讲，后面会单独写一篇来分析一下缓存)）。 3、接下来，是构造一个MapperMethod对象,这个对象封装了Mapper接口中对应的方法信息以及对应的sql语句信息： 这里面就会把要执行的sql语句，请求参数，方法返回值全部解析封装成MapperMethod对象，然后后面就可以开始准备执行sql语句了 执行sql语句还是先来看一下执行Sql语句的时序图： 1、我们继续上面的流程进入execute方法： 2、这里面会根据语句类型以及返回值类型来决定如何执行，本人这里返回的是一个集合，故而我们进入executeForMany方法： 3、这里面首先会将前面存好的参数进行一次转换，然后绕了这么一圈，回到了起点SqlSession对象，继续调用selectList方法： 3、接下来又讲流程委派给了Execute去执行query方法，最终又会去调用queryFromDatabase方法： 4、到这里之后，终于要进入正题了，一般带了这种do开头的方法就是真正做事的，Spring中很多地方也是采用的这种命名方式： 注意，前面我们的sql语句还是占位符的方式，并没有将参数设置进去，所以这里在return上面一行调用prepareStatement方法创建Statement对象的时候会去设置参数，替换占位符。参数如何设置我们先跳过，等把流程执行完了我们在单独分析参数映射和结果集映射。 5、继续进入PreparedStatementHandler对象的query方法，可以看到，这一步就是调用了jdbc操作对象PreparedStatement中的execute方法，最后一步就是转换结果集然后返回。 到这里，整个SQL语句执行流程分析就结束了，中途有一些参数的存储以及转换并没有深入进去，因为参数的转换并不是核心，只要清楚整个数据的流转流程，我们自己也可以有自己的实现方式，只要存起来最后我们能重新解析读出来就行。 参数映射现在我们来看一下上面在执行查询之前参数是如何进行设置的，我们先进入prepareStatement方法： 我们发现，最终是调用了StatementHandler中的parameterize进行参数设置，接下来这里为了节省篇幅，我们不会一步步点进去，直接进入设置参数的方法： 上面的BaseTypeHandler是一个抽象类，setNonNullParameter并没有实现，都是交给子类去实现，而每一个子类就是对应了数据库的一种类型。下图中就是默认的一个子类StringTypeHandler，里面没什么其他逻辑，就是设置参数。 可以看到String里面调用了jdbc中的setString方法，而如果是int也会调用setInt方法。看到这些子类如果大家之前阅读过我前面讲的MyBatis参数配置，应该就很明显可以知道，这些子类就是系统默认提供的一些typeHandler。而这些默认的typeHandler会默认被注册并和Java对象进行绑定： 正是因为MyBatis中默认提供了常用数据类型的映射，所以我们写Sql的时候才可以省略参数映射关系，可以直接采用下面的方式，系统可以根据我们参数的类型，自动选择合适的typeHander进行映射： 1select user_id,user_name from lw_user where user_name=#&#123;userName&#125; 上面这条语句实际上和下面这条是等价的： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR&#125; 或者说我们可以直接指定typeHandler： 1select user_id,user_name from lw_user where user_name = #&#123;userName,jdbcType=VARCHAR,typeHandler=org.apache.ibatis.type.IntegerTypeHandler&#125; 这里因为我们配置了typeHandler，所以会优先以配置的typeHandler为主不会再去读取默认的映射，如果类型不匹配就会直接报错了： 看到这里很多人应该就知道了，如果我们自己自定义一个typeHandler，然后就可以配置成我们自己的自定义类。所以接下来就让我们看看如何自定义一个typeHandler 自定义typeHandler自定义typeHandler需要实现BaseTypeHandler接口，BaseTypeHandler有4个方法，包括结果集映射，为了节省篇幅，代码没有写上来： 1234567891011121314151617package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; 然后我们改写一下上面的查询语句： 1select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125; 然后执行，可以看到，自定义的typeHandler生效了： 结果集映射接下来让我们看看结果集的映射，回到上面执行sql流程的最后一个方法： 1resultSetHandler.handleResultSets(ps) 结果集映射里面的逻辑相对来说还是挺复杂的，因为要考虑到非常多的情况，这里我们就不会去深究每一个细节，直接进入到正式解析结果集的代码，下面的5个代码片段就是一个简单的但是完整的解析流程： 从上面的代码片段我们也可以看到，实际上解析结果集还是很复杂的，就如我们上一篇介绍的复杂查询一样，一个查询可以不断嵌套其他查询，还有延迟加载等等一些复杂的特性的处理，所以逻辑分支是有很多，但是不管怎么处理，最后的核心还是上面的一套流程，最终还是会调用typeHandler来获取查询到的结果。 是的，你没猜错，这个就是上面我们映射参数的typeHandler，因为typeHandler里面不只是一个设置参数方法，还有获取结果集方法(上面设置参数的时候省略了)。 自定义typeHandler结果集所以说我们还是用上面那个MyTypeHandler 例子来重写一下取值方法(省略了设置参数方法)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.lonelyWolf.mybatis.typeHandler;import org.apache.ibatis.type.BaseTypeHandler;import org.apache.ibatis.type.JdbcType;import java.sql.CallableStatement;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;public class MyTypeHandler extends BaseTypeHandler&lt;String&gt; &#123; /** * 设置参数 */ @Override public void setNonNullParameter(PreparedStatement preparedStatement, int index, String param, JdbcType jdbcType) throws SQLException &#123; System.out.println(&quot;设置参数-&gt;自定义typeHandler生效了&quot;); preparedStatement.setString(index,param); &#125; /** * 根据列名获取结果 */ @Override public String getNullableResult(ResultSet resultSet, String columnName) throws SQLException &#123; System.out.println(&quot;根据columnName获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnName); &#125; /** * 根据列的下标来获取结果 */ @Override public String getNullableResult(ResultSet resultSet, int columnIndex) throws SQLException &#123; System.out.println(&quot;根据columnIndex获取结果-&gt;自定义typeHandler生效了&quot;); return resultSet.getString(columnIndex); &#125; /** * 处理存储过程的结果集 */ @Override public String getNullableResult(CallableStatement callableStatement, int columnIndex) throws SQLException &#123; return callableStatement.getString(columnIndex); &#125;&#125; 改写Mapper映射文件配置： 12345678&lt;resultMap id=&quot;MyUserResultMap&quot; type=&quot;lwUser&quot;&gt; &lt;result column=&quot;user_id&quot; property=&quot;userId&quot; jdbcType=&quot;VARCHAR&quot; typeHandler=&quot;com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&quot; /&gt; &lt;result column=&quot;user_name&quot; property=&quot;userName&quot; jdbcType=&quot;VARCHAR&quot; /&gt;&lt;/resultMap&gt;&lt;select id=&quot;listUserByUserName&quot; parameterType=&quot;String&quot; resultMap=&quot;MyUserResultMap&quot;&gt; select user_id,user_name from lw_user where user_name=#&#123;userName,jdbcType=VARCHAR,typeHandler=com.lonelyWolf.mybatis.typeHandler.MyTypeHandler&#125;&lt;/select&gt; 执行之后输出如下： 因为我们属性上面只配置了一个属性，所以只输出了一次。 工作流程图上面介绍了代码的流转，可能绕来绕去有点晕，所以我们来画一个主要的对象之间流程图来更加清晰的展示一下MyBatis主要工作流程： 从上面的工作流程图上我们可以看到，SqlSession下面还有4大对象，这4大对象也很重要，后面学习拦截器的时候就是针对这4大对象进行的拦截，关于这4大对象的具体详情，我们下一篇文章再展开分析。 总结本文主要分析了MyBatis的SQL执行流程。在分析流程的过程中，我们也举例论证了如何自定义typeHandler来实现自定义的参数映射和结果集映射，不过MyBatis中提供的默认映射其实可以满足大部分的需求，如果我们对某些属性需要特殊处理，那么就可以采用自定义的typeHandler来实现，相信如果本文如果读懂了，以下几点大家应该至少会有一个清晰的认识： 1、Mapper接口和映射文件是如何进行绑定的 2、MyBatis中SQL语句的执行流程 3、自定义MyBatis中的参数设置处理器typeHandler 4、自定义MyBatis中结果集处理器typeHandler 当然，其中很多细节并没有提到，而看源码我们也并不需要追求每一行代码都能看懂，就比如我们一个稍微复杂一点的业务系统，即使我们是项目开发者如果某一个模块不是本人负责的，恐怕也很难搞清楚每一行代码的含义。所以对于MyBatis及其他框架的源码中也是一样，首先应该从大局入手，掌握整体流程和设计思想，然后如果对某些实现细节感兴趣，再深入进行了解。","tags":["MyBatis","框架"],"categories":["框架"]},{"title":"用“状态模式”代替if-else","path":"/2023/12/24/用“状态模式”代替if-else/","content":"简介 状态模式是行为型设计模式的一种。其设计理念是当对象的内部状态发生改变时，随之改变其行为。状态和行为之间是一一对应的。 该模式主要用于，对象的行为依赖于它的状态，并且其行为是随着状态的改变而切换时。 状态模式UML类图类图讲解 State：抽象状态接口（也可以定义成抽象类），该接口封装了所有状态所对应的行为。ConcreteStateA&#x2F;B：具体状态类，该类实现了抽象状态接口，会根据自身对应的状态来实现接口中定义的方法，还有另一个功能是指明如何过渡到下一个状态。Context：环境（上下文）角色，该类负责状态的切换，还持有一个State实例，代表当前环境所处状态。 案例讲解案例：通过状态模式来实现自助售卖机的功能。 状态接口12345678public interface State &#123; // 挑选商品 void choose(); // 付款 boolean payment(); // 分发商品 void dispenseCommodity();&#125; 挑选商品状态类123456789101112131415161718192021222324252627282930public class ChooseGoods implements State &#123; VendingMachine machine; public ChooseGoods(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; if (machine.getCount() &gt; 0) &#123; System.out.println(&quot;商品挑选成功，请及时付款！&quot;); machine.setState(machine.getPaymentState()); &#125; else &#123; System.out.println(&quot;很遗憾，商品售罄了！&quot;); machine.setState(machine.getEmptyState()); &#125; &#125; @Override public boolean payment() &#123; System.out.println(&quot;请先挑选商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先挑选商品！&quot;); &#125;&#125; 付款状态类12345678910111213141516171819202122232425262728293031public class PaymentState implements State &#123; VendingMachine machine; public PaymentState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;商品已选购完成请勿重复挑选&quot;); &#125; @Override public boolean payment() &#123; Random random = new Random(); int num = random.nextInt(10); if(num % 2 == 0)&#123; System.out.println(&quot;付款成功！&quot;); machine.setState(machine.getDispenseCommodityState()); return true; &#125; System.out.println(&quot;付款失败，请重新支付！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请先完成支付！&quot;); &#125;&#125; 商品售罄状态类123456789101112131415161718192021222324public class EmptyState implements State &#123; VendingMachine machine; public EmptyState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;对不起商品已售罄！&quot;); &#125;&#125; 分发商品状态类12345678910111213141516171819202122232425public class DispenseCommodityState implements State &#123; VendingMachine machine; public DispenseCommodityState(VendingMachine machine) &#123; this.machine = machine; &#125; @Override public void choose() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); &#125; @Override public boolean payment() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); return false; &#125; @Override public void dispenseCommodity() &#123; System.out.println(&quot;请及时取走您的商品！&quot;); machine.setState(machine.getChooseGoods()); &#125;&#125; 自动售货机 &#x3D;&gt; Context角色123456789101112131415161718192021222324252627282930313233public class VendingMachine &#123; // 表示当前状态 private State state = null; // 商品数量 private int count = 0; private State chooseGoods = new ChooseGoods(this); private State paymentState = new PaymentState(this); private State dispenseCommodityState = new DispenseCommodityState(this); private State emptyState = new EmptyState(this); public VendingMachine(int count) &#123; this.count = count; this.state = this.getChooseGoods(); &#125; // 购买商品 public void purchase() &#123; // 挑选商品 state.choose(); // 支付成功 if (state.payment()) &#123; // 分发商品 state.dispenseCommodity(); &#125; &#125; // 获取商品后将商品减一 public int getCount() &#123; return count--; &#125; // get和set方法 ... &#125; 客户端测试类12345678910public class Client &#123; public static void main(String[] args) &#123; VendingMachine machine = new VendingMachine(1); for (int i = 1; i &lt; 4; i++) &#123; System.out.println(&quot;第&quot; + i + &quot;次购买。&quot;); machine.purchase(); &#125; &#125;&#125; 执行结果总结1、状态模式将每个状态所对应的行为封装到一个类中，大大提高了代码的可读性。并且通过这样的设计还可以消除多余的if-else语句，方便代码的维护。 2、状态模式符合“开闭原则”，容易增加和删除状态。 3、任何事情都有利弊，状态模式也不例外。其最显著的问题是，每个状态都要对应一个类，当状态过多时会产生大量的类，从而加大维护成本。 4、应用场景：当一个需求有很多状态，并且状态之间会进行转换，不同状态还对应不同的行为时就可以考虑使用“状态模式”。","tags":["设计模式"],"categories":["设计模式"]},{"title":"Google 开源的 Guava 工具库","path":"/2023/12/24/Google-开源的-Guava-工具库/","content":"目前Google Guava在实际应用中非常广泛，本篇博客将以博主对Guava使用的认识以及在项目中的经验来给大家分享！正如标题所言，学习使用Google Guava可以让你快乐编程，写出优雅的JAVA代码！ 以面向对象思想处理字符串:Joiner&#x2F;Splitter&#x2F;CharMatcher JDK提供的String还不够好么？ 也许还不够友好，至少让我们用起来还不够爽，还得操心！ 举个栗子，比如String提供的split方法，我们得关心空字符串吧，还得考虑返回的结果中存在null元素吧，只提供了前后trim的方法（如果我想对中间元素进行trim呢）。 那么，看下面的代码示例，guava让你不必在操心这些： 123456789101112131415// 连接器private static final Joiner joiner = Joiner.on(&quot;,&quot;).skipNulls();// 分割器private static final Splitter splitter = Splitter.on(&quot;,&quot;).trimResults().omitEmptyStrings();public static void main(String[] args) &#123; // 把集合/数组中的元素 join 在一起 String join = joiner.join(Lists.newArrayList(&quot;a&quot;, null, &quot;b&quot;)); System.out.println(&quot;join=&quot; + join); for(String tmp : splitter.split(&quot;a, ,b,,&quot;)) &#123; System.out.println(&quot;|&quot; + tmp + &quot;|&quot;); &#125;&#125; Joiner&#x2F;Splitter Joiner是连接器，Splitter是分割器，通常我们会把它们定义为static final，利用on生成对象后在应用到String进行处理，这是可以复用的。要知道apache commons StringUtils提供的都是static method。 更加重要的是，guava提供的Joiner&#x2F;Splitter是经过充分测试，它的稳定性和效率要比apache高出不少，这个你可以自行测试下~ 发现没有我们想对String做什么操作，就是生成自己定制化的Joiner&#x2F;Splitter，多么直白，简单，流畅的API！ 对于Joiner，常用的方法是 跳过NULL元素：skipNulls() &#x2F; 对于NULL元素使用其他替代：useForNull(String) 对于Splitter，常用的方法是：trimResults()&#x2F;omitEmptyStrings()。注意拆分的方式，有字符串，还有正则，还有固定长度分割（太贴心了！） 其实除了Joiner&#x2F;Splitter外，guava还提供了字符串匹配器：CharMatcher 123456789101112private static final CharMatcher charMatcherDigit = CharMatcher.DIGIT;private static final Charmatcher charMatcherAny = CharMatcher.ANY;public static void main(String[] args) &#123; // 只保留匹配的字符，其他移除 System.out.println(charMatcherDigit.retainFrom(&quot;abc2def134f~&quot;)); // 移除匹配的字符 System.out.println(charMatcherDigit.removeFrom(&quot;yes,i love you 1314&quot;)); System.out.println(charMatcherAny.inRange(&#x27;a&#x27;, &#x27;f&#x27;).or(charMatcherAny.is(&#x27;a&#x27;)).replaceFrom(&quot;abcdefg&quot;,&quot;*&quot;));&#125; CharMatcher CharMatcher，将字符的匹配和处理解耦，并提供丰富的方法供你使用！ 对基本类型进行支持 guava对JDK提供的原生类型操作进行了扩展，使得功能更加强大！ 1234567891011121314151617// 快速完成到集合的转换List&lt;Integer&gt; list = Ints.asList(1, 3, 5, 7, 9);System.out.println(Ints.join(&quot;,&quot;, 1, 3, 1, 4));// 原生类型数据快速合并int[] newIntArray = Ints.concat(new int[]&#123;1, 2&#125;, new int[]&#123;2, 3, 4&#125;);System.out.println(newIntArray.length);// 最大/最小System.out.println(Ints.max(newIntArray) + &quot;,&quot; + Ints.min(newIntArray));// 是否包含System.out.println(Ints.contains(newArray, 6));// 集合到数组的转换int[] someArray = Ints.toArray(list); Ints guava提供了 Bytes&#x2F;Shorts&#x2F;Ints&#x2F;Iongs&#x2F;Floats&#x2F;Doubles&#x2F;Chars&#x2F;Booleans 这些基本数据类型的扩展支持，只有你想不到的，没有它没有的！ 对JDK集合的有效补充灰色地带:Multiset JDK的集合，提供了有序且可以重复的List，无序且不可以重复的Set。那这里其实对于集合涉及到了2个概念，一个order，一个dups。那么List vs Set，and then some ? Multiset Multiset是什么，我想上面的图，你应该了解它的概念了。Multiset就是无序的，但是可以重复的集合，它就是游离在List&#x2F;Set之间的“灰色地带”！（至于有序的，不允许重复的集合嘛，guava还没有提供，当然在未来应该会提供UniqueList，我猜的，哈哈） 来看一个Multiset的示例： 12345678910Multiset&lt;String&gt; multiset = HashMultiset.create();multiset.add(&quot;a&quot;);multiset.add(&quot;a&quot;);multiset.add(&quot;b&quot;);multiset.add(&quot;c&quot;);multiset.add(&quot;b&quot;);System.out.println(multiset.size());System.out.println(multiset.count(&quot;a&quot;)); Multiset Code Multiset自带一个有用的功能，就是可以跟踪每个对象的数量。 Immutable vs unmodifiable来我们先看一个unmodifiable的例子： 1234567891011121314// List 的不可变设置List&lt;String&gt; list = new ArrayList&lt;String&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// 这种视图，不够安全，不是真正意义上的快照，怎么能随着而变化呢？List&lt;String&gt; readOnlyList = Collections.unmodifiableList(list);// readOnlyList.add(&quot;c&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionlist.acc(&quot;c&quot;);System.out.println(reaOnlyList.size()); // 3 unmodifiable 你看到JDK提供的unmodifiable的缺陷了吗？ 实际上，Collections.unmodifiableXxx所返回的集合和源集合是同一个对象，只不过可以对集合做出改变的API都被override，会抛出UnsupportedOperationException。 也即是说我们改变源集合，导致不可变视图（unmodifiable View）也会发生变化，oh my god! 当然，在不使用guava的情况下，我们是怎么避免上面的问题的呢？ 1234567// List 的不可变性设置List&lt;String&gt; list = new ArrayList&lt;~&gt;();list.add(&quot;a&quot;);list.add(&quot;b&quot;);// new Object ; CopyList&lt;String&gt; readOnList = Collections.unmodifiableList(new ArrayList&lt;String&gt;(list)); defensive copies 上面揭示了一个概念：Defensive Copies，保护性拷贝。 OK，unmodifiable看上去没有问题呢，但是guava依然觉得可以改进，于是提出了Immutable的概念，来看： 12345678910// guava 是如何做的呢？List&lt;String&gt; immutable = ImmutabeList.of(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;);// immutable.add(&quot;d&quot;);// 抛异常：java.lang.UnsupportedOperationExceptionList&lt;String&gt; immutable2 = ImmutableList.copyOf(list);list.add(&quot;d&quot;);// 视图不随着源而改变 guava 只读设置安全可靠 简单易用System.out.println(&quot;list size:&quot; + list.size() + &quot; immutable2.size:&quot; + immutables.size()); Immutable 就一个copyOf，你不会忘记，如此cheap~ 用Google官方的说法是：we’re using just one class,just say exactly what we mean，很了不起吗（不仅仅是个概念，Immutable在COPY阶段还考虑了线程的并发性等，很智能的！），O(∩_∩)O哈哈~ guava提供了很多Immutable集合，比如 ImmutableList&#x2F;ImmutableSet&#x2F;ImmutableSortedSet&#x2F;ImmutableMap&#x2F;…… 看一个ImmutableMap的例子： 123ImmutableMap&lt;String, String&gt; immutableMap = ImmutableMap.of(&quot;name&quot;, &quot;hubert&quot;, &quot;sex&quot;, &quot;man&quot;);immutableMap.put(&quot;wife&quot;, &quot;no...&quot;); // UnsupportedOperationException ImmutableMap 可不可以一对多：Multimap JDK提供给我们的Map是一个键，一个值，一对一的，那么在实际开发中，显然存在一个KEY多个VALUE的情况（比如一个分类下的书本），我们往往这样表达：Map&lt;k,List&lt;v&gt;&gt;，好像有点臃肿！臃肿也就算了，更加不爽的事，我们还得判断KEY是否存在来决定是否new 一个LIST出来，有点麻烦！更加麻烦的事情还在后头，比如遍历，比如删除，so hard…… 来看guava如何替你解决这个大麻烦的： 1234567Multimap&lt;String, String&gt; multiMap = ArrayListMultimap.create();multiMap.put(&quot;hubert&quot;, &quot;man&quot;);multiMap.put(&quot;hubert&quot;, &quot;yes&quot;);multiMap.put(&quot;lucy&quot;, &quot;woman&quot;);System.out.println(multiMap.get(&quot;hubert&quot;)); //collection Multimap 友情提示下，guava所有的集合都有create方法，这样的好处在于简单，而且我们不必在重复泛型信息了。 get()&#x2F;keys()&#x2F;keySet()&#x2F;values()&#x2F;entries()&#x2F;asMap()都是非常有用的返回view collection的方法。 Multimap的实现类有： ArrayListMultimap&#x2F;HashMultimap&#x2F;LinkedHashMultimap&#x2F;TreeMultimap&#x2F;ImmutableMultimap&#x2F;…… 可不可以双向：BiMap JDK提供的MAP让我们可以find value by key，那么能不能通过find key by value呢，能不能KEY和VALUE都是唯一的呢。这是一个双向的概念，即forward+backward。 在实际场景中有这样的需求吗？比如通过用户ID找到mail，也需要通过mail找回用户名。没有guava的时候，我们需要create forward map AND create backward map，and now just let guava do that for you. 12345678910111213BiMap&lt;String, String&gt; biMap = HashBiMap.create();biMap.put(&quot;name&quot;, &quot;hubert&quot;);// java.lang.IllegaArgumentException: value already present: hubert// value 重复会报错biMap.put(&quot;nick&quot;, &quot;hubert&quot;);// 强制覆盖 name:hubertbiMap.forcePut(&quot;nick&quot;, &quot;hubert&quot;);biMap.put(&quot;123&quot;, &quot;hubertwongcn@163.com&quot;);System.out.println(biMap.inverse().get(&quot;hubertwongcn@163.com&quot;)); // 123 BiMap biMap &#x2F; biMap.inverse() &#x2F; biMap.inverse().inverse() 它们是什么关系呢？ 你可以稍微看一下BiMap的源码实现，实际上，当你创建BiMap的时候，在内部维护了2个map，一个forward map，一个backward map，并且设置了它们之间的关系。 因此，biMap.inverse() !&#x3D; biMap ；biMap.inverse().inverse() &#x3D;&#x3D; biMap 可不可以多个KEY：Table 我们知道数据库除了主键外，还提供了复合索引，而且实际中这样的多级关系查找也是比较多的，当然我们可以利用嵌套的Map来实现：Map&lt;k1,Map&lt;k2,v2&gt;&gt;。为了让我们的代码看起来不那么丑陋，guava为我们提供了Table。 1234567Table&lt;String, String, Integer&gt; table = HashBaseTable.create();table.put(&quot;张三&quot;, &quot;计算机&quot;, 80);table.put(&quot;张三&quot;, &quot;数学&quot;, 90);table.put(&quot;张三&quot;, &quot;语文&quot;, 70);table.put(&quot;李四&quot;, &quot;计算机&quot;, 70);table.put(&quot;李四&quot;, &quot;数学&quot;, 60);table.put(&quot;李四&quot;, &quot;语文&quot;, 100); Table Table涉及到3个概念：rowKey,columnKey,value，并提供了多种视图以及操作方法让你更加轻松的处理多个KEY的场景。 函数式编程：Functions12345678910111213141516171819202122List&lt;String&gt; list = Lists.newArrayList(&quot;hello world&quot;, &quot;yes&quot;, &quot;hubert&quot;);Function&lt;String, String&gt; f1 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.length() &lt;= 5 ? s : s.substring(0, 5); &#125;&#125;;Function&lt;String, String&gt; f2 = new Function&lt;String, String&gt;() &#123; @Override public String apply(String s) &#123; return s.toUpperCase(); &#125;&#125;;Function&lt;String, String&gt; f3 = Functions.compose(f1, f2);Collection&lt;String&gt; collection = Collections2.transform(list, f3);for(String s : collection) &#123; System.out.println(s);&#125; Functions 上面的代码是为了完成将List集合中的元素，先截取5个长度，然后转成大写。 函数式编程的好处在于在集合遍历操作中提供自定义Function的操作，比如transform转换。我们再也不需要一遍遍的遍历集合，显著的简化了代码！ 12345678910Iterables.transform(Iterable, Function);Iterators.transform(Iterator, Function);Collections2.transform(Collection, Function);Lists.transform(List, Function);Maps.transformValues(Map, Function);Multimaps.transformValues(Multimap, Function);Multimaps.transformValues(ListMultimap, Funtion);Tables.transformValues(Table, Function);Maps.transformEntries(Map, EntryTransformer);// ... 对集合的transform操作可以通过Function完成 断言：Predicate12345678910111213List&lt;String&gt; list = Lists.newArrayList(&quot;moom&quot;, &quot;dad&quot;, &quot;refer&quot;, &quot;yes&quot;);Collection&lt;String&gt; collection = Collections2.filter(list, new Predicate&lt;String&gt;)) &#123; @Override public boolean apply(String s) &#123; // 业务逻辑 return new StringBuilder(s).reverse().toString().equals(s); &#125;&#125;;for(String s : collection) &#123; System.out.println(s);&#125; Predicate最常用的功能就是运用在集合的过滤当中！ 12345678Iterables.filter(Iterable, Predicate);Iterators.filter(Iterator, Predicate);Collectios2.filter(Collection, Predicate);Sets.filter(Set, Predicate);Sets.filter(SortedSet, Predicate);Maps.filterKeys(Map, Predicate);Multimaps.filterKeys(Multimap, Predicate);// ... filter 需要注意的是Lists并没有提供filter方法，不过你可以使用Collections2.filter完成！ check null and other：Optional、Preconditions在guava中，对于null的处理手段是快速失败，你可以看看guava的源码，很多方法的第一行就是：Preconditions.checkNotNull(elements); 要知道null是模糊的概念，是成功呢，还是失败呢，还是别的什么含义呢？ 12345678910111213public static void test(String name, int age, Map&lt;String, String&gt; extInfo) &#123; Preconditions.checkNotNull(name, &quot;name must be given!&quot;); Preconditions.checkArgument(age &gt;= 18, &quot;the game you can not play it, your age is under 18!&quot;); Map&lt;String, String&gt; defaulExtInfo = Maps.newHashMap(); defaultExtInfo.put(&quot;sex&quot;, &quot;man&quot;); extInfo = Optional.fromNullable(extInfo).or(defaultExtInfo); for(Map.Entry&lt;String, Stirng&gt; entry : extInfo.entrySet())) &#123; System.out.println(entry.getKey() + &quot;:&quot; + entry.getValue()); &#125;&#125; Preconditions&#x2F;Optional Cache is king 对于大多数互联网项目而言，缓存的重要性，不言而喻！ 如果我们的应用系统，并不想使用一些第三方缓存组件（如redis），我们仅仅想在本地有一个功能足够强大的缓存，很可惜JDK提供的那些SET&#x2F;MAP还不行！ 12345678910111213141516171819202122232425// 定义缓存的实现private static final CacheLoader&lt;Long, User&gt; userCacheLoader = new CacheLoader&lt;Long, User&gt;() &#123; @Override public User load(Long along) throws Exception &#123; // 模拟从数据库/Redis/缓存中加载数据 User user = new User(); user.setId(along); user.setName(Thread.currentThread().getName() + &quot;-&quot; new SimpleDateFormat(&quot;yyyy-MM-dd hh:mm:ss&quot;).format(new Date()) + &quot;-&quot; + along); System.out.println(&quot;load:&quot; + user); return user; &#125;&#125;;// 定义缓存的策略，提供对外访问缓存private static final LoadingCache&lt;Long, User&gt; userCacheData = CacheBuilder.newBuilder() .expireAfterAccess(2, TimeUnit.SECONDS) .expireAfterWrite(2, TimeUnit.SECONDS) .refreshAfterWrite(3, TimeUnit.SECONS) .maximumSize(10000L) .bulid(userCacheLoader); CacheLoader 首先，这是一个本地缓存，guava提供的cache是一个简洁、高效，易于维护的。为什么这么说呢？因为并没有一个单独的线程用于刷新 OR 清理cache，对于cache的操作，都是通过访问&#x2F;读写带来的，也就是说在读写中完成缓存的刷新操作！ 其次，我们看到了，我们非常通俗的告诉cache，我们的缓存策略是什么，SO EASY！在如此简单的背后，是guava帮助我们做了很多事情，比如线程安全。 让异步回调更加简单 JDK中提供了Future&#x2F;FutureTask&#x2F;Callable来对异步回调进行支持，但是还是看上去挺复杂的，能不能更加简单呢？比如注册一个监听回调。 12345678910111213141516171819202122232425262728// JDK 所提供的线程池ExecutorService es = Executors.newFixedThreadPool(3);// 经过guava封装的带有监听回调功能的线程池ListeningExecutorService listeningExecutorService = MoreExecutors.listeningDecorator(es);ListenableFuture listenableFuture = listeningExecutorService.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; if (new Random().nextInt(3) == 2) &#123; throw new NullPointerException(); &#125; return 1; &#125;&#125;);FutureCallback futureCallback = new FutureCallback&lt;Integer&gt; &#123; @Override public void onSuccess(final Integer o) &#123; System.out.println(&quot;------&quot; + o); &#125; @Override public void onFailure(final Throwable throwable) &#123; System.out.println(&quot;======&quot; + throwable.getMessage()); &#125;&#125;;Futures.addCallback(listenableFuture, futureCallback); 异步回调 我们可以通过guava对JDK提供的线程池进行装饰，让其具有异步回调监听功能，然后在设置监听器即可！ Summary到这里，这篇文章也只介绍了guava的冰山一角，其实还有很多内容： guava package 比如反射、注解、网络、并发、IO等等","tags":["工具","开源","Google"],"categories":["工具"]}]